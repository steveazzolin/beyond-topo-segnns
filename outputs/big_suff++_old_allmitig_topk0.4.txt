
[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 10:50:00 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:00 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:13 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:15 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:17 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:19 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:50:20 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 145...
[0m[1;37mINFO[0m: [1mCheckpoint 145: 
-----------------------------------
Train ACCURACY: 0.8262
Train Loss: 0.6051
ID Validation ACCURACY: 0.8323
ID Validation Loss: 0.6014
ID Test ACCURACY: 0.8310
ID Test Loss: 0.6067
OOD Validation ACCURACY: 0.9170
OOD Validation Loss: 0.4932
OOD Test ACCURACY: 0.4637
OOD Test Loss: 1.0723

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 143...
[0m[1;37mINFO[0m: [1mCheckpoint 143: 
-----------------------------------
Train ACCURACY: 0.7144
Train Loss: 0.8206
ID Validation ACCURACY: 0.7340
ID Validation Loss: 0.8001
ID Test ACCURACY: 0.7170
ID Test Loss: 0.8173
OOD Validation ACCURACY: 0.9300
OOD Validation Loss: 0.5214
OOD Test ACCURACY: 0.3587
OOD Test Loss: 1.3356

[0m[1;37mINFO[0m: [1mChartInfo 0.8310 0.4637 0.7170 0.3587 0.7340 0.9300[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.580
WIoU for r=0.3 = 0.674
F1 for r=0.6 = 0.551
WIoU for r=0.6 = 0.691
F1 for r=0.9 = 0.464
WIoU for r=0.9 = 0.690
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.690
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.825
WIoU for r=0.3 = 0.966
F1 for r=0.6 = 0.704
WIoU for r=0.6 = 1.000
F1 for r=0.9 = 0.585
WIoU for r=0.9 = 1.000
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 1.000
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.359
WIoU for r=0.3 = 0.389
F1 for r=0.6 = 0.389
WIoU for r=0.6 = 0.376
F1 for r=0.9 = 0.510
WIoU for r=0.9 = 0.377
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.377


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.581
Model XAI F1 of binarized graphs for r=0.3 =  0.5799624999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.6738862499999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.43
SUFF++ for r=0.3 class 0 = 0.539 +- 0.232 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.3 class 1 = 0.666 +- 0.232 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.3 class 2 = 0.586 +- 0.232 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.3 all KL = 0.721 +- 0.232 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.3 all L1 = 0.598 +- 0.150 (in-sample avg dev_std = 0.321)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.736
Model XAI F1 of binarized graphs for r=0.6 =  0.55144125
Model XAI WIoU of binarized graphs for r=0.6 =  0.6908150000000001
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.556
SUFF++ for r=0.6 class 0 = 0.434 +- 0.264 (in-sample avg dev_std = 0.377)
SUFF++ for r=0.6 class 1 = 0.605 +- 0.264 (in-sample avg dev_std = 0.377)
SUFF++ for r=0.6 class 2 = 0.518 +- 0.264 (in-sample avg dev_std = 0.377)
SUFF++ for r=0.6 all KL = 0.595 +- 0.264 (in-sample avg dev_std = 0.377)
SUFF++ for r=0.6 all L1 = 0.521 +- 0.152 (in-sample avg dev_std = 0.377)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.822
Model XAI F1 of binarized graphs for r=0.9 =  0.46436000000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.6901824999999999
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.702
SUFF++ for r=0.9 class 0 = 0.666 +- 0.195 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.9 class 1 = 0.766 +- 0.195 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.9 class 2 = 0.702 +- 0.195 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.9 all KL = 0.818 +- 0.195 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.9 all L1 = 0.712 +- 0.170 (in-sample avg dev_std = 0.301)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.595
Model XAI F1 of binarized graphs for r=0.3 =  0.82485
Model XAI WIoU of binarized graphs for r=0.3 =  0.9660637500000001
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.46
SUFF++ for r=0.3 class 0 = 0.65 +- 0.237 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.3 class 1 = 0.77 +- 0.237 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.3 class 2 = 0.688 +- 0.237 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.3 all KL = 0.763 +- 0.237 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.3 all L1 = 0.702 +- 0.165 (in-sample avg dev_std = 0.417)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.915
Model XAI F1 of binarized graphs for r=0.6 =  0.7039587499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.9997800000000001
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.815
SUFF++ for r=0.6 class 0 = 0.703 +- 0.219 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.6 class 1 = 0.839 +- 0.219 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.6 class 2 = 0.621 +- 0.219 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.6 all KL = 0.76 +- 0.219 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.6 all L1 = 0.721 +- 0.182 (in-sample avg dev_std = 0.337)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.918
Model XAI F1 of binarized graphs for r=0.9 =  0.584855
Model XAI WIoU of binarized graphs for r=0.9 =  0.9997800000000001
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.849
SUFF++ for r=0.9 class 0 = 0.817 +- 0.197 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.9 class 1 = 0.926 +- 0.197 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.9 class 2 = 0.816 +- 0.197 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.9 all KL = 0.887 +- 0.197 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.9 all L1 = 0.852 +- 0.163 (in-sample avg dev_std = 0.216)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.368
Model XAI F1 of binarized graphs for r=0.3 =  0.35891999999999996
Model XAI WIoU of binarized graphs for r=0.3 =  0.38876374999999996
len(reference) = 794
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.359
SUFF++ for r=0.3 class 0 = 0.792 +- 0.064 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.3 class 1 = 0.801 +- 0.064 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.3 class 2 = 0.762 +- 0.064 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.3 all KL = 0.92 +- 0.064 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.3 all L1 = 0.784 +- 0.084 (in-sample avg dev_std = 0.241)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.451
Model XAI F1 of binarized graphs for r=0.6 =  0.38903000000000004
Model XAI WIoU of binarized graphs for r=0.6 =  0.37554249999999995
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.403
SUFF++ for r=0.6 class 0 = 0.687 +- 0.206 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.6 class 1 = 0.767 +- 0.206 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.6 class 2 = 0.683 +- 0.206 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.6 all KL = 0.832 +- 0.206 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.6 all L1 = 0.711 +- 0.166 (in-sample avg dev_std = 0.279)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.546
Model XAI F1 of binarized graphs for r=0.9 =  0.509745
Model XAI WIoU of binarized graphs for r=0.9 =  0.37674124999999997
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.53
SUFF++ for r=0.9 class 0 = 0.714 +- 0.117 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.9 class 1 = 0.788 +- 0.117 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.9 class 2 = 0.771 +- 0.117 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.9 all KL = 0.889 +- 0.117 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.9 all L1 = 0.757 +- 0.141 (in-sample avg dev_std = 0.242)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.581
Model XAI F1 of binarized graphs for r=0.3 =  0.5799624999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.6738862499999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.332
NEC for r=0.3 class 0 = 0.445 +- 0.248 (in-sample avg dev_std = 0.288)
NEC for r=0.3 class 1 = 0.403 +- 0.248 (in-sample avg dev_std = 0.288)
NEC for r=0.3 class 2 = 0.413 +- 0.248 (in-sample avg dev_std = 0.288)
NEC for r=0.3 all KL = 0.289 +- 0.248 (in-sample avg dev_std = 0.288)
NEC for r=0.3 all L1 = 0.42 +- 0.162 (in-sample avg dev_std = 0.288)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.738
Model XAI F1 of binarized graphs for r=0.6 =  0.55144125
Model XAI WIoU of binarized graphs for r=0.6 =  0.6908150000000001
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.429
NEC for r=0.6 class 0 = 0.579 +- 0.293 (in-sample avg dev_std = 0.341)
NEC for r=0.6 class 1 = 0.467 +- 0.293 (in-sample avg dev_std = 0.341)
NEC for r=0.6 class 2 = 0.498 +- 0.293 (in-sample avg dev_std = 0.341)
NEC for r=0.6 all KL = 0.446 +- 0.293 (in-sample avg dev_std = 0.341)
NEC for r=0.6 all L1 = 0.514 +- 0.171 (in-sample avg dev_std = 0.341)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.822
Model XAI F1 of binarized graphs for r=0.9 =  0.46436000000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.6901824999999999
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.499
NEC for r=0.9 class 0 = 0.532 +- 0.252 (in-sample avg dev_std = 0.365)
NEC for r=0.9 class 1 = 0.44 +- 0.252 (in-sample avg dev_std = 0.365)
NEC for r=0.9 class 2 = 0.429 +- 0.252 (in-sample avg dev_std = 0.365)
NEC for r=0.9 all KL = 0.364 +- 0.252 (in-sample avg dev_std = 0.365)
NEC for r=0.9 all L1 = 0.466 +- 0.157 (in-sample avg dev_std = 0.365)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.82
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.6901824999999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.518
NEC for r=1.0 class 0 = 0.525 +- 0.255 (in-sample avg dev_std = 0.358)
NEC for r=1.0 class 1 = 0.427 +- 0.255 (in-sample avg dev_std = 0.358)
NEC for r=1.0 class 2 = 0.413 +- 0.255 (in-sample avg dev_std = 0.358)
NEC for r=1.0 all KL = 0.341 +- 0.255 (in-sample avg dev_std = 0.358)
NEC for r=1.0 all L1 = 0.454 +- 0.158 (in-sample avg dev_std = 0.358)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.595
Model XAI F1 of binarized graphs for r=0.3 =  0.82485
Model XAI WIoU of binarized graphs for r=0.3 =  0.9660637500000001
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.248
NEC for r=0.3 class 0 = 0.476 +- 0.288 (in-sample avg dev_std = 0.201)
NEC for r=0.3 class 1 = 0.429 +- 0.288 (in-sample avg dev_std = 0.201)
NEC for r=0.3 class 2 = 0.397 +- 0.288 (in-sample avg dev_std = 0.201)
NEC for r=0.3 all KL = 0.315 +- 0.288 (in-sample avg dev_std = 0.201)
NEC for r=0.3 all L1 = 0.434 +- 0.188 (in-sample avg dev_std = 0.201)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.915
Model XAI F1 of binarized graphs for r=0.6 =  0.7039587499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.9997800000000001
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.606
NEC for r=0.6 class 0 = 0.454 +- 0.233 (in-sample avg dev_std = 0.485)
NEC for r=0.6 class 1 = 0.357 +- 0.233 (in-sample avg dev_std = 0.485)
NEC for r=0.6 class 2 = 0.346 +- 0.233 (in-sample avg dev_std = 0.485)
NEC for r=0.6 all KL = 0.379 +- 0.233 (in-sample avg dev_std = 0.485)
NEC for r=0.6 all L1 = 0.386 +- 0.161 (in-sample avg dev_std = 0.485)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.918
Model XAI F1 of binarized graphs for r=0.9 =  0.584855
Model XAI WIoU of binarized graphs for r=0.9 =  0.9997800000000001
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.682
NEC for r=0.9 class 0 = 0.4 +- 0.280 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 1 = 0.288 +- 0.280 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 2 = 0.277 +- 0.280 (in-sample avg dev_std = 0.461)
NEC for r=0.9 all KL = 0.311 +- 0.280 (in-sample avg dev_std = 0.461)
NEC for r=0.9 all L1 = 0.322 +- 0.152 (in-sample avg dev_std = 0.461)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.918
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  0.9997800000000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.675
NEC for r=1.0 class 0 = 0.372 +- 0.271 (in-sample avg dev_std = 0.444)
NEC for r=1.0 class 1 = 0.282 +- 0.271 (in-sample avg dev_std = 0.444)
NEC for r=1.0 class 2 = 0.254 +- 0.271 (in-sample avg dev_std = 0.444)
NEC for r=1.0 all KL = 0.283 +- 0.271 (in-sample avg dev_std = 0.444)
NEC for r=1.0 all L1 = 0.303 +- 0.147 (in-sample avg dev_std = 0.444)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.373
Model XAI F1 of binarized graphs for r=0.3 =  0.35891999999999996
Model XAI WIoU of binarized graphs for r=0.3 =  0.38876374999999996
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.358
NEC for r=0.3 class 0 = 0.205 +- 0.095 (in-sample avg dev_std = 0.182)
NEC for r=0.3 class 1 = 0.212 +- 0.095 (in-sample avg dev_std = 0.182)
NEC for r=0.3 class 2 = 0.226 +- 0.095 (in-sample avg dev_std = 0.182)
NEC for r=0.3 all KL = 0.083 +- 0.095 (in-sample avg dev_std = 0.182)
NEC for r=0.3 all L1 = 0.215 +- 0.136 (in-sample avg dev_std = 0.182)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.451
Model XAI F1 of binarized graphs for r=0.6 =  0.38903000000000004
Model XAI WIoU of binarized graphs for r=0.6 =  0.37554249999999995
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.437
NEC for r=0.6 class 0 = 0.421 +- 0.235 (in-sample avg dev_std = 0.345)
NEC for r=0.6 class 1 = 0.315 +- 0.235 (in-sample avg dev_std = 0.345)
NEC for r=0.6 class 2 = 0.336 +- 0.235 (in-sample avg dev_std = 0.345)
NEC for r=0.6 all KL = 0.24 +- 0.235 (in-sample avg dev_std = 0.345)
NEC for r=0.6 all L1 = 0.358 +- 0.178 (in-sample avg dev_std = 0.345)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.545
Model XAI F1 of binarized graphs for r=0.9 =  0.509745
Model XAI WIoU of binarized graphs for r=0.9 =  0.37674124999999997
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.524
NEC for r=0.9 class 0 = 0.402 +- 0.163 (in-sample avg dev_std = 0.359)
NEC for r=0.9 class 1 = 0.299 +- 0.163 (in-sample avg dev_std = 0.359)
NEC for r=0.9 class 2 = 0.371 +- 0.163 (in-sample avg dev_std = 0.359)
NEC for r=0.9 all KL = 0.218 +- 0.163 (in-sample avg dev_std = 0.359)
NEC for r=0.9 all L1 = 0.359 +- 0.132 (in-sample avg dev_std = 0.359)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.562
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.37674124999999997
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.541
NEC for r=1.0 class 0 = 0.417 +- 0.152 (in-sample avg dev_std = 0.333)
NEC for r=1.0 class 1 = 0.301 +- 0.152 (in-sample avg dev_std = 0.333)
NEC for r=1.0 class 2 = 0.373 +- 0.152 (in-sample avg dev_std = 0.333)
NEC for r=1.0 all KL = 0.213 +- 0.152 (in-sample avg dev_std = 0.333)
NEC for r=1.0 all L1 = 0.365 +- 0.131 (in-sample avg dev_std = 0.333)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 10:53:23 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:23 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:36 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:38 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:40 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:41 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:53:43 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 121...
[0m[1;37mINFO[0m: [1mCheckpoint 121: 
-----------------------------------
Train ACCURACY: 0.8421
Train Loss: 0.5965
ID Validation ACCURACY: 0.8433
ID Validation Loss: 0.6107
ID Test ACCURACY: 0.8473
ID Test Loss: 0.5920
OOD Validation ACCURACY: 0.9083
OOD Validation Loss: 0.5036
OOD Test ACCURACY: 0.8173
OOD Test Loss: 0.6549

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 123...
[0m[1;37mINFO[0m: [1mCheckpoint 123: 
-----------------------------------
Train ACCURACY: 0.7853
Train Loss: 0.6555
ID Validation ACCURACY: 0.7847
ID Validation Loss: 0.6702
ID Test ACCURACY: 0.7860
ID Test Loss: 0.6564
OOD Validation ACCURACY: 0.9187
OOD Validation Loss: 0.5682
OOD Test ACCURACY: 0.8620
OOD Test Loss: 0.4867

[0m[1;37mINFO[0m: [1mChartInfo 0.8473 0.8173 0.7860 0.8620 0.7847 0.9187[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.708
WIoU for r=0.3 = 0.760
F1 for r=0.6 = 0.612
WIoU for r=0.6 = 0.815
F1 for r=0.9 = 0.476
WIoU for r=0.9 = 0.818
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.818
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.866
WIoU for r=0.3 = 0.943
F1 for r=0.6 = 0.796
WIoU for r=0.6 = 1.000
F1 for r=0.9 = 0.618
WIoU for r=0.9 = 1.000
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 1.000
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.708
WIoU for r=0.3 = 0.720
F1 for r=0.6 = 0.729
WIoU for r=0.6 = 0.764
F1 for r=0.9 = 0.594
WIoU for r=0.9 = 0.765
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.765


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.627
Model XAI F1 of binarized graphs for r=0.3 =  0.7075537499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.760325
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.46
SUFF++ for r=0.3 class 0 = 0.59 +- 0.233 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.3 class 1 = 0.502 +- 0.233 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.3 class 2 = 0.643 +- 0.233 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.3 all KL = 0.657 +- 0.233 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.3 all L1 = 0.579 +- 0.162 (in-sample avg dev_std = 0.420)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.765
Model XAI F1 of binarized graphs for r=0.6 =  0.61167375
Model XAI WIoU of binarized graphs for r=0.6 =  0.8153374999999999
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.533
SUFF++ for r=0.6 class 0 = 0.477 +- 0.242 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.6 class 1 = 0.526 +- 0.242 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.6 class 2 = 0.658 +- 0.242 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.6 all KL = 0.618 +- 0.242 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.6 all L1 = 0.556 +- 0.174 (in-sample avg dev_std = 0.399)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.82
Model XAI F1 of binarized graphs for r=0.9 =  0.47555375
Model XAI WIoU of binarized graphs for r=0.9 =  0.817585
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.708
SUFF++ for r=0.9 class 0 = 0.708 +- 0.206 (in-sample avg dev_std = 0.309)
SUFF++ for r=0.9 class 1 = 0.74 +- 0.206 (in-sample avg dev_std = 0.309)
SUFF++ for r=0.9 class 2 = 0.738 +- 0.206 (in-sample avg dev_std = 0.309)
SUFF++ for r=0.9 all KL = 0.813 +- 0.206 (in-sample avg dev_std = 0.309)
SUFF++ for r=0.9 all L1 = 0.729 +- 0.201 (in-sample avg dev_std = 0.309)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.631
Model XAI F1 of binarized graphs for r=0.3 =  0.8664750000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.9428299999999998
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.56
SUFF++ for r=0.3 class 0 = 0.766 +- 0.193 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.3 class 1 = 0.754 +- 0.193 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.3 class 2 = 0.723 +- 0.193 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.3 all KL = 0.802 +- 0.193 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.3 all L1 = 0.747 +- 0.154 (in-sample avg dev_std = 0.380)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.839
Model XAI F1 of binarized graphs for r=0.6 =  0.79626625
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.768
SUFF++ for r=0.6 class 0 = 0.687 +- 0.200 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.6 class 1 = 0.853 +- 0.200 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.6 class 2 = 0.808 +- 0.200 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.6 all KL = 0.838 +- 0.200 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.6 all L1 = 0.782 +- 0.153 (in-sample avg dev_std = 0.336)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.93
Model XAI F1 of binarized graphs for r=0.9 =  0.6178087499999999
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.913
SUFF++ for r=0.9 class 0 = 0.928 +- 0.130 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.9 class 1 = 0.961 +- 0.130 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.9 class 2 = 0.942 +- 0.130 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.9 all KL = 0.954 +- 0.130 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.9 all L1 = 0.944 +- 0.099 (in-sample avg dev_std = 0.155)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.651
Model XAI F1 of binarized graphs for r=0.3 =  0.7078437500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.7195100000000001
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.506
SUFF++ for r=0.3 class 0 = 0.689 +- 0.234 (in-sample avg dev_std = 0.479)
SUFF++ for r=0.3 class 1 = 0.71 +- 0.234 (in-sample avg dev_std = 0.479)
SUFF++ for r=0.3 class 2 = 0.588 +- 0.234 (in-sample avg dev_std = 0.479)
SUFF++ for r=0.3 all KL = 0.699 +- 0.234 (in-sample avg dev_std = 0.479)
SUFF++ for r=0.3 all L1 = 0.661 +- 0.159 (in-sample avg dev_std = 0.479)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.8
Model XAI F1 of binarized graphs for r=0.6 =  0.7290537500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.7644024999999999
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.785
SUFF++ for r=0.6 class 0 = 0.689 +- 0.140 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.6 class 1 = 0.814 +- 0.140 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.6 class 2 = 0.795 +- 0.140 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.6 all KL = 0.862 +- 0.140 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.6 all L1 = 0.765 +- 0.140 (in-sample avg dev_std = 0.321)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.8
Model XAI F1 of binarized graphs for r=0.9 =  0.5941075
Model XAI WIoU of binarized graphs for r=0.9 =  0.7654637500000001
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.769
SUFF++ for r=0.9 class 0 = 0.839 +- 0.227 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 class 1 = 0.912 +- 0.227 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 class 2 = 0.745 +- 0.227 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 all KL = 0.872 +- 0.227 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 all L1 = 0.83 +- 0.168 (in-sample avg dev_std = 0.296)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.629
Model XAI F1 of binarized graphs for r=0.3 =  0.7075537499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.760325
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.358
NEC for r=0.3 class 0 = 0.528 +- 0.271 (in-sample avg dev_std = 0.361)
NEC for r=0.3 class 1 = 0.524 +- 0.271 (in-sample avg dev_std = 0.361)
NEC for r=0.3 class 2 = 0.538 +- 0.271 (in-sample avg dev_std = 0.361)
NEC for r=0.3 all KL = 0.475 +- 0.271 (in-sample avg dev_std = 0.361)
NEC for r=0.3 all L1 = 0.53 +- 0.156 (in-sample avg dev_std = 0.361)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.766
Model XAI F1 of binarized graphs for r=0.6 =  0.61167375
Model XAI WIoU of binarized graphs for r=0.6 =  0.8153374999999999
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.428
NEC for r=0.6 class 0 = 0.542 +- 0.267 (in-sample avg dev_std = 0.363)
NEC for r=0.6 class 1 = 0.493 +- 0.267 (in-sample avg dev_std = 0.363)
NEC for r=0.6 class 2 = 0.528 +- 0.267 (in-sample avg dev_std = 0.363)
NEC for r=0.6 all KL = 0.483 +- 0.267 (in-sample avg dev_std = 0.363)
NEC for r=0.6 all L1 = 0.521 +- 0.156 (in-sample avg dev_std = 0.363)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.819
Model XAI F1 of binarized graphs for r=0.9 =  0.47555375
Model XAI WIoU of binarized graphs for r=0.9 =  0.817585
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.469
NEC for r=0.9 class 0 = 0.517 +- 0.255 (in-sample avg dev_std = 0.368)
NEC for r=0.9 class 1 = 0.467 +- 0.255 (in-sample avg dev_std = 0.368)
NEC for r=0.9 class 2 = 0.51 +- 0.255 (in-sample avg dev_std = 0.368)
NEC for r=0.9 all KL = 0.433 +- 0.255 (in-sample avg dev_std = 0.368)
NEC for r=0.9 all L1 = 0.498 +- 0.154 (in-sample avg dev_std = 0.368)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.846
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.817585
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.483
NEC for r=1.0 class 0 = 0.507 +- 0.278 (in-sample avg dev_std = 0.364)
NEC for r=1.0 class 1 = 0.45 +- 0.278 (in-sample avg dev_std = 0.364)
NEC for r=1.0 class 2 = 0.499 +- 0.278 (in-sample avg dev_std = 0.364)
NEC for r=1.0 all KL = 0.427 +- 0.278 (in-sample avg dev_std = 0.364)
NEC for r=1.0 all L1 = 0.485 +- 0.157 (in-sample avg dev_std = 0.364)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.631
Model XAI F1 of binarized graphs for r=0.3 =  0.8664750000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.9428299999999998
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.332
NEC for r=0.3 class 0 = 0.597 +- 0.168 (in-sample avg dev_std = 0.330)
NEC for r=0.3 class 1 = 0.641 +- 0.168 (in-sample avg dev_std = 0.330)
NEC for r=0.3 class 2 = 0.637 +- 0.168 (in-sample avg dev_std = 0.330)
NEC for r=0.3 all KL = 0.616 +- 0.168 (in-sample avg dev_std = 0.330)
NEC for r=0.3 all L1 = 0.625 +- 0.086 (in-sample avg dev_std = 0.330)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.839
Model XAI F1 of binarized graphs for r=0.6 =  0.79626625
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.533
NEC for r=0.6 class 0 = 0.504 +- 0.240 (in-sample avg dev_std = 0.496)
NEC for r=0.6 class 1 = 0.42 +- 0.240 (in-sample avg dev_std = 0.496)
NEC for r=0.6 class 2 = 0.461 +- 0.240 (in-sample avg dev_std = 0.496)
NEC for r=0.6 all KL = 0.471 +- 0.240 (in-sample avg dev_std = 0.496)
NEC for r=0.6 all L1 = 0.462 +- 0.147 (in-sample avg dev_std = 0.496)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.929
Model XAI F1 of binarized graphs for r=0.9 =  0.6178087499999999
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.664
NEC for r=0.9 class 0 = 0.441 +- 0.321 (in-sample avg dev_std = 0.522)
NEC for r=0.9 class 1 = 0.293 +- 0.321 (in-sample avg dev_std = 0.522)
NEC for r=0.9 class 2 = 0.435 +- 0.321 (in-sample avg dev_std = 0.522)
NEC for r=0.9 all KL = 0.446 +- 0.321 (in-sample avg dev_std = 0.522)
NEC for r=0.9 all L1 = 0.39 +- 0.167 (in-sample avg dev_std = 0.522)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.918
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  1.0
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.671
NEC for r=1.0 class 0 = 0.438 +- 0.334 (in-sample avg dev_std = 0.520)
NEC for r=1.0 class 1 = 0.284 +- 0.334 (in-sample avg dev_std = 0.520)
NEC for r=1.0 class 2 = 0.438 +- 0.334 (in-sample avg dev_std = 0.520)
NEC for r=1.0 all KL = 0.433 +- 0.334 (in-sample avg dev_std = 0.520)
NEC for r=1.0 all L1 = 0.387 +- 0.172 (in-sample avg dev_std = 0.520)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.649
Model XAI F1 of binarized graphs for r=0.3 =  0.7078437500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.7195100000000001
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.334
NEC for r=0.3 class 0 = 0.682 +- 0.333 (in-sample avg dev_std = 0.364)
NEC for r=0.3 class 1 = 0.338 +- 0.333 (in-sample avg dev_std = 0.364)
NEC for r=0.3 class 2 = 0.702 +- 0.333 (in-sample avg dev_std = 0.364)
NEC for r=0.3 all KL = 0.588 +- 0.333 (in-sample avg dev_std = 0.364)
NEC for r=0.3 all L1 = 0.578 +- 0.236 (in-sample avg dev_std = 0.364)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.794
Model XAI F1 of binarized graphs for r=0.6 =  0.7290537500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.7644024999999999
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.466
NEC for r=0.6 class 0 = 0.615 +- 0.278 (in-sample avg dev_std = 0.479)
NEC for r=0.6 class 1 = 0.39 +- 0.278 (in-sample avg dev_std = 0.479)
NEC for r=0.6 class 2 = 0.625 +- 0.278 (in-sample avg dev_std = 0.479)
NEC for r=0.6 all KL = 0.571 +- 0.278 (in-sample avg dev_std = 0.479)
NEC for r=0.6 all L1 = 0.546 +- 0.171 (in-sample avg dev_std = 0.479)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.8
Model XAI F1 of binarized graphs for r=0.9 =  0.5941075
Model XAI WIoU of binarized graphs for r=0.9 =  0.7654637500000001
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.591
NEC for r=0.9 class 0 = 0.513 +- 0.303 (in-sample avg dev_std = 0.506)
NEC for r=0.9 class 1 = 0.327 +- 0.303 (in-sample avg dev_std = 0.506)
NEC for r=0.9 class 2 = 0.565 +- 0.303 (in-sample avg dev_std = 0.506)
NEC for r=0.9 all KL = 0.482 +- 0.303 (in-sample avg dev_std = 0.506)
NEC for r=0.9 all L1 = 0.471 +- 0.171 (in-sample avg dev_std = 0.506)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.794
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.7654637500000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.598
NEC for r=1.0 class 0 = 0.492 +- 0.310 (in-sample avg dev_std = 0.512)
NEC for r=1.0 class 1 = 0.3 +- 0.310 (in-sample avg dev_std = 0.512)
NEC for r=1.0 class 2 = 0.564 +- 0.310 (in-sample avg dev_std = 0.512)
NEC for r=1.0 all KL = 0.466 +- 0.310 (in-sample avg dev_std = 0.512)
NEC for r=1.0 all L1 = 0.455 +- 0.170 (in-sample avg dev_std = 0.512)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 10:56:47 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/22/2024 10:56:47 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/22/2024 10:56:59 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/22/2024 10:57:01 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/22/2024 10:57:03 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/22/2024 10:57:05 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 10:57:07 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 126...
[0m[1;37mINFO[0m: [1mCheckpoint 126: 
-----------------------------------
Train ACCURACY: 0.7628
Train Loss: 0.6801
ID Validation ACCURACY: 0.7620
ID Validation Loss: 0.6814
ID Test ACCURACY: 0.7597
ID Test Loss: 0.6915
OOD Validation ACCURACY: 0.8410
OOD Validation Loss: 0.6740
OOD Test ACCURACY: 0.3683
OOD Test Loss: 1.2832

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 109...
[0m[1;37mINFO[0m: [1mCheckpoint 109: 
-----------------------------------
Train ACCURACY: 0.7704
Train Loss: 0.6946
ID Validation ACCURACY: 0.7610
ID Validation Loss: 0.7185
ID Test ACCURACY: 0.7720
ID Test Loss: 0.6991
OOD Validation ACCURACY: 0.8720
OOD Validation Loss: 0.5789
OOD Test ACCURACY: 0.3457
OOD Test Loss: 1.2457

[0m[1;37mINFO[0m: [1mChartInfo 0.7597 0.3683 0.7720 0.3457 0.7610 0.8720[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.715
WIoU for r=0.3 = 0.708
F1 for r=0.6 = 0.612
WIoU for r=0.6 = 0.803
F1 for r=0.9 = 0.474
WIoU for r=0.9 = 0.806
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.806
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.838
WIoU for r=0.3 = 0.881
F1 for r=0.6 = 0.766
WIoU for r=0.6 = 1.000
F1 for r=0.9 = 0.608
WIoU for r=0.9 = 1.000
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 1.000
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.382
WIoU for r=0.3 = 0.302
F1 for r=0.6 = 0.566
WIoU for r=0.6 = 0.461
F1 for r=0.9 = 0.568
WIoU for r=0.9 = 0.481
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.481


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.399
Model XAI F1 of binarized graphs for r=0.3 =  0.7152612500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.70780375
len(reference) = 796
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.371
SUFF++ for r=0.3 class 0 = 0.76 +- 0.211 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.3 class 1 = 0.806 +- 0.211 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.3 class 2 = 0.707 +- 0.211 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.3 all KL = 0.872 +- 0.211 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.3 all L1 = 0.757 +- 0.143 (in-sample avg dev_std = 0.246)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.595
Model XAI F1 of binarized graphs for r=0.6 =  0.61248875
Model XAI WIoU of binarized graphs for r=0.6 =  0.8026375
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.471
SUFF++ for r=0.6 class 0 = 0.611 +- 0.317 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.6 class 1 = 0.745 +- 0.317 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.6 class 2 = 0.599 +- 0.317 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.6 all KL = 0.694 +- 0.317 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.6 all L1 = 0.652 +- 0.190 (in-sample avg dev_std = 0.387)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.719
Model XAI F1 of binarized graphs for r=0.9 =  0.47395250000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.8057037499999998
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.657
SUFF++ for r=0.9 class 0 = 0.779 +- 0.246 (in-sample avg dev_std = 0.359)
SUFF++ for r=0.9 class 1 = 0.814 +- 0.246 (in-sample avg dev_std = 0.359)
SUFF++ for r=0.9 class 2 = 0.784 +- 0.246 (in-sample avg dev_std = 0.359)
SUFF++ for r=0.9 all KL = 0.823 +- 0.246 (in-sample avg dev_std = 0.359)
SUFF++ for r=0.9 all L1 = 0.793 +- 0.193 (in-sample avg dev_std = 0.359)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.339
Model XAI F1 of binarized graphs for r=0.3 =  0.83793125
Model XAI WIoU of binarized graphs for r=0.3 =  0.88058875
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.328
SUFF++ for r=0.3 class 0 = 0.866 +- 0.051 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.3 class 1 = 0.866 +- 0.051 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.3 class 2 = 0.865 +- 0.051 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.3 all KL = 0.959 +- 0.051 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.3 all L1 = 0.865 +- 0.090 (in-sample avg dev_std = 0.201)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.502
Model XAI F1 of binarized graphs for r=0.6 =  0.7662062499999999
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.411
SUFF++ for r=0.6 class 0 = 0.742 +- 0.314 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.6 class 1 = 0.79 +- 0.314 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.6 class 2 = 0.718 +- 0.314 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.6 all KL = 0.768 +- 0.314 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.6 all L1 = 0.75 +- 0.181 (in-sample avg dev_std = 0.334)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.79
Model XAI F1 of binarized graphs for r=0.9 =  0.6081675
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.749
SUFF++ for r=0.9 class 0 = 0.868 +- 0.280 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 class 1 = 0.886 +- 0.280 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 class 2 = 0.858 +- 0.280 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 all KL = 0.849 +- 0.280 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 all L1 = 0.871 +- 0.195 (in-sample avg dev_std = 0.346)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.337
Model XAI F1 of binarized graphs for r=0.3 =  0.38189625
Model XAI WIoU of binarized graphs for r=0.3 =  0.30185249999999997
len(reference) = 789
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.326
SUFF++ for r=0.3 class 0 = 0.831 +- 0.044 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.3 class 1 = 0.824 +- 0.044 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.3 class 2 = 0.807 +- 0.044 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.3 all KL = 0.951 +- 0.044 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.3 all L1 = 0.82 +- 0.084 (in-sample avg dev_std = 0.168)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.343
Model XAI F1 of binarized graphs for r=0.6 =  0.5662287500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.46058374999999996
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.338
SUFF++ for r=0.6 class 0 = 0.821 +- 0.123 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.6 class 1 = 0.856 +- 0.123 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.6 class 2 = 0.773 +- 0.123 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.6 all KL = 0.935 +- 0.123 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.6 all L1 = 0.816 +- 0.116 (in-sample avg dev_std = 0.190)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.36
Model XAI F1 of binarized graphs for r=0.9 =  0.5681274999999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.4812875
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.361
SUFF++ for r=0.9 class 0 = 0.801 +- 0.185 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 class 1 = 0.861 +- 0.185 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 class 2 = 0.739 +- 0.185 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 all KL = 0.895 +- 0.185 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 all L1 = 0.799 +- 0.174 (in-sample avg dev_std = 0.237)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.398
Model XAI F1 of binarized graphs for r=0.3 =  0.7152612500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.70780375
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.359
NEC for r=0.3 class 0 = 0.28 +- 0.225 (in-sample avg dev_std = 0.217)
NEC for r=0.3 class 1 = 0.243 +- 0.225 (in-sample avg dev_std = 0.217)
NEC for r=0.3 class 2 = 0.312 +- 0.225 (in-sample avg dev_std = 0.217)
NEC for r=0.3 all KL = 0.143 +- 0.225 (in-sample avg dev_std = 0.217)
NEC for r=0.3 all L1 = 0.279 +- 0.161 (in-sample avg dev_std = 0.217)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.595
Model XAI F1 of binarized graphs for r=0.6 =  0.61248875
Model XAI WIoU of binarized graphs for r=0.6 =  0.8026375
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.448
NEC for r=0.6 class 0 = 0.414 +- 0.338 (in-sample avg dev_std = 0.380)
NEC for r=0.6 class 1 = 0.291 +- 0.338 (in-sample avg dev_std = 0.380)
NEC for r=0.6 class 2 = 0.423 +- 0.338 (in-sample avg dev_std = 0.380)
NEC for r=0.6 all KL = 0.32 +- 0.338 (in-sample avg dev_std = 0.380)
NEC for r=0.6 all L1 = 0.376 +- 0.185 (in-sample avg dev_std = 0.380)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.719
Model XAI F1 of binarized graphs for r=0.9 =  0.47395250000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.8057037499999998
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.499
NEC for r=0.9 class 0 = 0.471 +- 0.327 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 1 = 0.329 +- 0.327 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 2 = 0.503 +- 0.327 (in-sample avg dev_std = 0.432)
NEC for r=0.9 all KL = 0.403 +- 0.327 (in-sample avg dev_std = 0.432)
NEC for r=0.9 all L1 = 0.434 +- 0.176 (in-sample avg dev_std = 0.432)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.757
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.8057037499999998
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.509
NEC for r=1.0 class 0 = 0.486 +- 0.335 (in-sample avg dev_std = 0.427)
NEC for r=1.0 class 1 = 0.376 +- 0.335 (in-sample avg dev_std = 0.427)
NEC for r=1.0 class 2 = 0.535 +- 0.335 (in-sample avg dev_std = 0.427)
NEC for r=1.0 all KL = 0.453 +- 0.335 (in-sample avg dev_std = 0.427)
NEC for r=1.0 all L1 = 0.466 +- 0.188 (in-sample avg dev_std = 0.427)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.339
Model XAI F1 of binarized graphs for r=0.3 =  0.83793125
Model XAI WIoU of binarized graphs for r=0.3 =  0.88058875
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.333
NEC for r=0.3 class 0 = 0.183 +- 0.078 (in-sample avg dev_std = 0.179)
NEC for r=0.3 class 1 = 0.234 +- 0.078 (in-sample avg dev_std = 0.179)
NEC for r=0.3 class 2 = 0.273 +- 0.078 (in-sample avg dev_std = 0.179)
NEC for r=0.3 all KL = 0.075 +- 0.078 (in-sample avg dev_std = 0.179)
NEC for r=0.3 all L1 = 0.23 +- 0.119 (in-sample avg dev_std = 0.179)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.502
Model XAI F1 of binarized graphs for r=0.6 =  0.7662062499999999
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.456
NEC for r=0.6 class 0 = 0.316 +- 0.277 (in-sample avg dev_std = 0.395)
NEC for r=0.6 class 1 = 0.243 +- 0.277 (in-sample avg dev_std = 0.395)
NEC for r=0.6 class 2 = 0.311 +- 0.277 (in-sample avg dev_std = 0.395)
NEC for r=0.6 all KL = 0.237 +- 0.277 (in-sample avg dev_std = 0.395)
NEC for r=0.6 all L1 = 0.291 +- 0.162 (in-sample avg dev_std = 0.395)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.79
Model XAI F1 of binarized graphs for r=0.9 =  0.6081675
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.649
NEC for r=0.9 class 0 = 0.393 +- 0.361 (in-sample avg dev_std = 0.499)
NEC for r=0.9 class 1 = 0.261 +- 0.361 (in-sample avg dev_std = 0.499)
NEC for r=0.9 class 2 = 0.346 +- 0.361 (in-sample avg dev_std = 0.499)
NEC for r=0.9 all KL = 0.444 +- 0.361 (in-sample avg dev_std = 0.499)
NEC for r=0.9 all L1 = 0.334 +- 0.189 (in-sample avg dev_std = 0.499)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.853
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  1.0
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.698
NEC for r=1.0 class 0 = 0.361 +- 0.365 (in-sample avg dev_std = 0.515)
NEC for r=1.0 class 1 = 0.253 +- 0.365 (in-sample avg dev_std = 0.515)
NEC for r=1.0 class 2 = 0.367 +- 0.365 (in-sample avg dev_std = 0.515)
NEC for r=1.0 all KL = 0.45 +- 0.365 (in-sample avg dev_std = 0.515)
NEC for r=1.0 all L1 = 0.328 +- 0.184 (in-sample avg dev_std = 0.515)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.336
Model XAI F1 of binarized graphs for r=0.3 =  0.38189625
Model XAI WIoU of binarized graphs for r=0.3 =  0.30185249999999997
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.314
NEC for r=0.3 class 0 = 0.188 +- 0.066 (in-sample avg dev_std = 0.156)
NEC for r=0.3 class 1 = 0.184 +- 0.066 (in-sample avg dev_std = 0.156)
NEC for r=0.3 class 2 = 0.211 +- 0.066 (in-sample avg dev_std = 0.156)
NEC for r=0.3 all KL = 0.059 +- 0.066 (in-sample avg dev_std = 0.156)
NEC for r=0.3 all L1 = 0.194 +- 0.115 (in-sample avg dev_std = 0.156)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.343
Model XAI F1 of binarized graphs for r=0.6 =  0.5662287500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.46058374999999996
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.324
NEC for r=0.6 class 0 = 0.175 +- 0.126 (in-sample avg dev_std = 0.178)
NEC for r=0.6 class 1 = 0.193 +- 0.126 (in-sample avg dev_std = 0.178)
NEC for r=0.6 class 2 = 0.251 +- 0.126 (in-sample avg dev_std = 0.178)
NEC for r=0.6 all KL = 0.072 +- 0.126 (in-sample avg dev_std = 0.178)
NEC for r=0.6 all L1 = 0.207 +- 0.115 (in-sample avg dev_std = 0.178)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.36
Model XAI F1 of binarized graphs for r=0.9 =  0.5681274999999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.4812875
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.339
NEC for r=0.9 class 0 = 0.262 +- 0.196 (in-sample avg dev_std = 0.331)
NEC for r=0.9 class 1 = 0.286 +- 0.196 (in-sample avg dev_std = 0.331)
NEC for r=0.9 class 2 = 0.377 +- 0.196 (in-sample avg dev_std = 0.331)
NEC for r=0.9 all KL = 0.181 +- 0.196 (in-sample avg dev_std = 0.331)
NEC for r=0.9 all L1 = 0.308 +- 0.159 (in-sample avg dev_std = 0.331)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.364
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.48053874999999996
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.345
NEC for r=1.0 class 0 = 0.323 +- 0.210 (in-sample avg dev_std = 0.364)
NEC for r=1.0 class 1 = 0.319 +- 0.210 (in-sample avg dev_std = 0.364)
NEC for r=1.0 class 2 = 0.391 +- 0.210 (in-sample avg dev_std = 0.364)
NEC for r=1.0 all KL = 0.225 +- 0.210 (in-sample avg dev_std = 0.364)
NEC for r=1.0 all L1 = 0.345 +- 0.162 (in-sample avg dev_std = 0.364)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 11:00:14 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:14 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:26 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:28 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:30 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:32 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:00:34 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 130...
[0m[1;37mINFO[0m: [1mCheckpoint 130: 
-----------------------------------
Train ACCURACY: 0.6617
Train Loss: 0.9206
ID Validation ACCURACY: 0.6773
ID Validation Loss: 0.9239
ID Test ACCURACY: 0.6760
ID Test Loss: 0.9039
OOD Validation ACCURACY: 0.8727
OOD Validation Loss: 0.8769
OOD Test ACCURACY: 0.6407
OOD Test Loss: 1.0474

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 130...
[0m[1;37mINFO[0m: [1mCheckpoint 130: 
-----------------------------------
Train ACCURACY: 0.6617
Train Loss: 0.9206
ID Validation ACCURACY: 0.6773
ID Validation Loss: 0.9239
ID Test ACCURACY: 0.6760
ID Test Loss: 0.9039
OOD Validation ACCURACY: 0.8727
OOD Validation Loss: 0.8769
OOD Test ACCURACY: 0.6407
OOD Test Loss: 1.0474

[0m[1;37mINFO[0m: [1mChartInfo 0.6760 0.6407 0.6760 0.6407 0.6773 0.8727[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.625
WIoU for r=0.3 = 0.622
F1 for r=0.6 = 0.569
WIoU for r=0.6 = 0.656
F1 for r=0.9 = 0.468
WIoU for r=0.9 = 0.659
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.659
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.739
WIoU for r=0.3 = 0.623
F1 for r=0.6 = 0.704
WIoU for r=0.6 = 0.666
F1 for r=0.9 = 0.587
WIoU for r=0.9 = 0.666
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 0.666
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.644
WIoU for r=0.3 = 0.518
F1 for r=0.6 = 0.735
WIoU for r=0.6 = 0.543
F1 for r=0.9 = 0.593
WIoU for r=0.9 = 0.543
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.543


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.46
Model XAI F1 of binarized graphs for r=0.3 =  0.625065
Model XAI WIoU of binarized graphs for r=0.3 =  0.6216087499999999
len(reference) = 794
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.385
SUFF++ for r=0.3 class 0 = 0.771 +- 0.084 (in-sample avg dev_std = 0.215)
SUFF++ for r=0.3 class 1 = 0.811 +- 0.084 (in-sample avg dev_std = 0.215)
SUFF++ for r=0.3 class 2 = 0.747 +- 0.084 (in-sample avg dev_std = 0.215)
SUFF++ for r=0.3 all KL = 0.925 +- 0.084 (in-sample avg dev_std = 0.215)
SUFF++ for r=0.3 all L1 = 0.777 +- 0.097 (in-sample avg dev_std = 0.215)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.615
Model XAI F1 of binarized graphs for r=0.6 =  0.5692975
Model XAI WIoU of binarized graphs for r=0.6 =  0.6562025
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.527
SUFF++ for r=0.6 class 0 = 0.781 +- 0.197 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.6 class 1 = 0.83 +- 0.197 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.6 class 2 = 0.687 +- 0.197 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.6 all KL = 0.862 +- 0.197 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.6 all L1 = 0.765 +- 0.145 (in-sample avg dev_std = 0.296)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.631
Model XAI F1 of binarized graphs for r=0.9 =  0.46774
Model XAI WIoU of binarized graphs for r=0.9 =  0.65856375
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.603
SUFF++ for r=0.9 class 0 = 0.908 +- 0.152 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 class 1 = 0.918 +- 0.152 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 class 2 = 0.814 +- 0.152 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 all KL = 0.93 +- 0.152 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 all L1 = 0.879 +- 0.139 (in-sample avg dev_std = 0.231)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.491
Model XAI F1 of binarized graphs for r=0.3 =  0.7394762500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.6230175
len(reference) = 794
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.473
SUFF++ for r=0.3 class 0 = 0.844 +- 0.031 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.3 class 1 = 0.961 +- 0.031 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.3 class 2 = 0.851 +- 0.031 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.3 all KL = 0.973 +- 0.031 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.3 all L1 = 0.884 +- 0.085 (in-sample avg dev_std = 0.145)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.87
Model XAI F1 of binarized graphs for r=0.6 =  0.7041737499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.6661500000000001
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.783
SUFF++ for r=0.6 class 0 = 0.911 +- 0.183 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.6 class 1 = 0.969 +- 0.183 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.6 class 2 = 0.773 +- 0.183 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.6 all KL = 0.925 +- 0.183 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.6 all L1 = 0.884 +- 0.149 (in-sample avg dev_std = 0.204)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.876
Model XAI F1 of binarized graphs for r=0.9 =  0.5871487499999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.6657925
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.804
SUFF++ for r=0.9 class 0 = 0.937 +- 0.230 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.9 class 1 = 0.944 +- 0.230 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.9 class 2 = 0.837 +- 0.230 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.9 all KL = 0.909 +- 0.230 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.9 all L1 = 0.906 +- 0.178 (in-sample avg dev_std = 0.207)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.584
Model XAI F1 of binarized graphs for r=0.3 =  0.6441187500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.51755
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.421
SUFF++ for r=0.3 class 0 = 0.815 +- 0.064 (in-sample avg dev_std = 0.206)
SUFF++ for r=0.3 class 1 = 0.879 +- 0.064 (in-sample avg dev_std = 0.206)
SUFF++ for r=0.3 class 2 = 0.823 +- 0.064 (in-sample avg dev_std = 0.206)
SUFF++ for r=0.3 all KL = 0.95 +- 0.064 (in-sample avg dev_std = 0.206)
SUFF++ for r=0.3 all L1 = 0.838 +- 0.088 (in-sample avg dev_std = 0.206)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.661
Model XAI F1 of binarized graphs for r=0.6 =  0.7349875
Model XAI WIoU of binarized graphs for r=0.6 =  0.5433437499999999
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.668
SUFF++ for r=0.6 class 0 = 0.901 +- 0.058 (in-sample avg dev_std = 0.212)
SUFF++ for r=0.6 class 1 = 0.939 +- 0.058 (in-sample avg dev_std = 0.212)
SUFF++ for r=0.6 class 2 = 0.834 +- 0.058 (in-sample avg dev_std = 0.212)
SUFF++ for r=0.6 all KL = 0.961 +- 0.058 (in-sample avg dev_std = 0.212)
SUFF++ for r=0.6 all L1 = 0.89 +- 0.105 (in-sample avg dev_std = 0.212)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.664
Model XAI F1 of binarized graphs for r=0.9 =  0.5931237500000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.5433437499999999
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.672
SUFF++ for r=0.9 class 0 = 0.978 +- 0.092 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.9 class 1 = 0.979 +- 0.092 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.9 class 2 = 0.924 +- 0.092 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.9 all KL = 0.98 +- 0.092 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.9 all L1 = 0.96 +- 0.085 (in-sample avg dev_std = 0.127)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.458
Model XAI F1 of binarized graphs for r=0.3 =  0.625065
Model XAI WIoU of binarized graphs for r=0.3 =  0.6216087499999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.354
NEC for r=0.3 class 0 = 0.221 +- 0.110 (in-sample avg dev_std = 0.134)
NEC for r=0.3 class 1 = 0.134 +- 0.110 (in-sample avg dev_std = 0.134)
NEC for r=0.3 class 2 = 0.256 +- 0.110 (in-sample avg dev_std = 0.134)
NEC for r=0.3 all KL = 0.067 +- 0.110 (in-sample avg dev_std = 0.134)
NEC for r=0.3 all L1 = 0.204 +- 0.135 (in-sample avg dev_std = 0.134)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.615
Model XAI F1 of binarized graphs for r=0.6 =  0.5692975
Model XAI WIoU of binarized graphs for r=0.6 =  0.6562025
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.385
NEC for r=0.6 class 0 = 0.2 +- 0.251 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 1 = 0.149 +- 0.251 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 2 = 0.344 +- 0.251 (in-sample avg dev_std = 0.237)
NEC for r=0.6 all KL = 0.142 +- 0.251 (in-sample avg dev_std = 0.237)
NEC for r=0.6 all L1 = 0.232 +- 0.182 (in-sample avg dev_std = 0.237)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.632
Model XAI F1 of binarized graphs for r=0.9 =  0.46774
Model XAI WIoU of binarized graphs for r=0.9 =  0.65856375
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.438
NEC for r=0.9 class 0 = 0.173 +- 0.250 (in-sample avg dev_std = 0.277)
NEC for r=0.9 class 1 = 0.14 +- 0.250 (in-sample avg dev_std = 0.277)
NEC for r=0.9 class 2 = 0.368 +- 0.250 (in-sample avg dev_std = 0.277)
NEC for r=0.9 all KL = 0.15 +- 0.250 (in-sample avg dev_std = 0.277)
NEC for r=0.9 all L1 = 0.229 +- 0.186 (in-sample avg dev_std = 0.277)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.661
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.65856375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.433
NEC for r=1.0 class 0 = 0.181 +- 0.256 (in-sample avg dev_std = 0.274)
NEC for r=1.0 class 1 = 0.143 +- 0.256 (in-sample avg dev_std = 0.274)
NEC for r=1.0 class 2 = 0.384 +- 0.256 (in-sample avg dev_std = 0.274)
NEC for r=1.0 all KL = 0.16 +- 0.256 (in-sample avg dev_std = 0.274)
NEC for r=1.0 all L1 = 0.238 +- 0.197 (in-sample avg dev_std = 0.274)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.495
Model XAI F1 of binarized graphs for r=0.3 =  0.7394762500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.6230175
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.459
NEC for r=0.3 class 0 = 0.256 +- 0.047 (in-sample avg dev_std = 0.045)
NEC for r=0.3 class 1 = 0.018 +- 0.047 (in-sample avg dev_std = 0.045)
NEC for r=0.3 class 2 = 0.24 +- 0.047 (in-sample avg dev_std = 0.045)
NEC for r=0.3 all KL = 0.044 +- 0.047 (in-sample avg dev_std = 0.045)
NEC for r=0.3 all L1 = 0.172 +- 0.136 (in-sample avg dev_std = 0.045)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.87
Model XAI F1 of binarized graphs for r=0.6 =  0.7041737499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.6661500000000001
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.605
NEC for r=0.6 class 0 = 0.14 +- 0.203 (in-sample avg dev_std = 0.226)
NEC for r=0.6 class 1 = 0.013 +- 0.203 (in-sample avg dev_std = 0.226)
NEC for r=0.6 class 2 = 0.305 +- 0.203 (in-sample avg dev_std = 0.226)
NEC for r=0.6 all KL = 0.097 +- 0.203 (in-sample avg dev_std = 0.226)
NEC for r=0.6 all L1 = 0.153 +- 0.169 (in-sample avg dev_std = 0.226)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.876
Model XAI F1 of binarized graphs for r=0.9 =  0.5871487499999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.6657925
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.662
NEC for r=0.9 class 0 = 0.145 +- 0.341 (in-sample avg dev_std = 0.360)
NEC for r=0.9 class 1 = 0.019 +- 0.341 (in-sample avg dev_std = 0.360)
NEC for r=0.9 class 2 = 0.395 +- 0.341 (in-sample avg dev_std = 0.360)
NEC for r=0.9 all KL = 0.22 +- 0.341 (in-sample avg dev_std = 0.360)
NEC for r=0.9 all L1 = 0.187 +- 0.207 (in-sample avg dev_std = 0.360)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.889
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  0.66579375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.669
NEC for r=1.0 class 0 = 0.143 +- 0.357 (in-sample avg dev_std = 0.372)
NEC for r=1.0 class 1 = 0.02 +- 0.357 (in-sample avg dev_std = 0.372)
NEC for r=1.0 class 2 = 0.414 +- 0.357 (in-sample avg dev_std = 0.372)
NEC for r=1.0 all KL = 0.24 +- 0.357 (in-sample avg dev_std = 0.372)
NEC for r=1.0 all L1 = 0.193 +- 0.217 (in-sample avg dev_std = 0.372)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.584
Model XAI F1 of binarized graphs for r=0.3 =  0.6441187500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.51755
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.425
NEC for r=0.3 class 0 = 0.224 +- 0.068 (in-sample avg dev_std = 0.088)
NEC for r=0.3 class 1 = 0.035 +- 0.068 (in-sample avg dev_std = 0.088)
NEC for r=0.3 class 2 = 0.152 +- 0.068 (in-sample avg dev_std = 0.088)
NEC for r=0.3 all KL = 0.036 +- 0.068 (in-sample avg dev_std = 0.088)
NEC for r=0.3 all L1 = 0.139 +- 0.133 (in-sample avg dev_std = 0.088)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.661
Model XAI F1 of binarized graphs for r=0.6 =  0.7349875
Model XAI WIoU of binarized graphs for r=0.6 =  0.5433437499999999
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.499
NEC for r=0.6 class 0 = 0.156 +- 0.085 (in-sample avg dev_std = 0.173)
NEC for r=0.6 class 1 = 0.034 +- 0.085 (in-sample avg dev_std = 0.173)
NEC for r=0.6 class 2 = 0.178 +- 0.085 (in-sample avg dev_std = 0.173)
NEC for r=0.6 all KL = 0.043 +- 0.085 (in-sample avg dev_std = 0.173)
NEC for r=0.6 all L1 = 0.124 +- 0.129 (in-sample avg dev_std = 0.173)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.664
Model XAI F1 of binarized graphs for r=0.9 =  0.5931237500000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.5433437499999999
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.558
NEC for r=0.9 class 0 = 0.12 +- 0.149 (in-sample avg dev_std = 0.235)
NEC for r=0.9 class 1 = 0.025 +- 0.149 (in-sample avg dev_std = 0.235)
NEC for r=0.9 class 2 = 0.215 +- 0.149 (in-sample avg dev_std = 0.235)
NEC for r=0.9 all KL = 0.069 +- 0.149 (in-sample avg dev_std = 0.235)
NEC for r=0.9 all L1 = 0.122 +- 0.143 (in-sample avg dev_std = 0.235)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.659
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.5433437499999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.554
NEC for r=1.0 class 0 = 0.118 +- 0.167 (in-sample avg dev_std = 0.237)
NEC for r=1.0 class 1 = 0.022 +- 0.167 (in-sample avg dev_std = 0.237)
NEC for r=1.0 class 2 = 0.21 +- 0.167 (in-sample avg dev_std = 0.237)
NEC for r=1.0 all KL = 0.072 +- 0.167 (in-sample avg dev_std = 0.237)
NEC for r=1.0 all L1 = 0.119 +- 0.144 (in-sample avg dev_std = 0.237)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 11:03:42 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/22/2024 11:03:42 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/22/2024 11:03:54 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/22/2024 11:03:56 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/22/2024 11:03:58 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/22/2024 11:04:00 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/22/2024 11:04:01 AM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/22/2024 11:04:01 AM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 11:04:01 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:04:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:04:01 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:04:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:04:01 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:04:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:04:01 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:04:01 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:04:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:04:01 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:04:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:04:01 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:04:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:04:01 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:04:01 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:04:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:04:01 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:04:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:04:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:04:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:04:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:04:02 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:04:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:04:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:04:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:04:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:04:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:04:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:04:02 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:04:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:04:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:04:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:04:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:04:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:04:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:04:02 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 100...
[0m[1;37mINFO[0m: [1mCheckpoint 100: 
-----------------------------------
Train ACCURACY: 0.7857
Train Loss: 0.6983
ID Validation ACCURACY: 0.7850
ID Validation Loss: 0.7149
ID Test ACCURACY: 0.7927
ID Test Loss: 0.7110
OOD Validation ACCURACY: 0.9283
OOD Validation Loss: 0.6407
OOD Test ACCURACY: 0.7653
OOD Test Loss: 0.9856

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 100...
[0m[1;37mINFO[0m: [1mCheckpoint 100: 
-----------------------------------
Train ACCURACY: 0.7857
Train Loss: 0.6983
ID Validation ACCURACY: 0.7850
ID Validation Loss: 0.7149
ID Test ACCURACY: 0.7927
ID Test Loss: 0.7110
OOD Validation ACCURACY: 0.9283
OOD Validation Loss: 0.6407
OOD Test ACCURACY: 0.7653
OOD Test Loss: 0.9856

[0m[1;37mINFO[0m: [1mChartInfo 0.7927 0.7653 0.7927 0.7653 0.7850 0.9283[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.622
WIoU for r=0.3 = 0.639
F1 for r=0.6 = 0.596
WIoU for r=0.6 = 0.690
F1 for r=0.9 = 0.474
WIoU for r=0.9 = 0.690
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.690
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.825
WIoU for r=0.3 = 0.972
F1 for r=0.6 = 0.739
WIoU for r=0.6 = 1.000
F1 for r=0.9 = 0.603
WIoU for r=0.9 = 1.000
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 1.000
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.588
WIoU for r=0.3 = 0.622
F1 for r=0.6 = 0.723
WIoU for r=0.6 = 0.690
F1 for r=0.9 = 0.594
WIoU for r=0.9 = 0.688
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.688


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.529
Model XAI F1 of binarized graphs for r=0.3 =  0.6223675
Model XAI WIoU of binarized graphs for r=0.3 =  0.63895875
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.415
SUFF++ for r=0.3 class 0 = 0.682 +- 0.196 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.3 class 1 = 0.585 +- 0.196 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.3 class 2 = 0.599 +- 0.196 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.3 all KL = 0.753 +- 0.196 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.3 all L1 = 0.621 +- 0.136 (in-sample avg dev_std = 0.382)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.726
Model XAI F1 of binarized graphs for r=0.6 =  0.5955075
Model XAI WIoU of binarized graphs for r=0.6 =  0.6900875
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.584
SUFF++ for r=0.6 class 0 = 0.716 +- 0.205 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.6 class 1 = 0.619 +- 0.205 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.6 class 2 = 0.617 +- 0.205 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.6 all KL = 0.781 +- 0.205 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.6 all L1 = 0.649 +- 0.153 (in-sample avg dev_std = 0.304)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.77
Model XAI F1 of binarized graphs for r=0.9 =  0.47393625
Model XAI WIoU of binarized graphs for r=0.9 =  0.690255
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.734
SUFF++ for r=0.9 class 0 = 0.791 +- 0.161 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 class 1 = 0.751 +- 0.161 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 class 2 = 0.756 +- 0.161 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 all KL = 0.88 +- 0.161 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 all L1 = 0.766 +- 0.136 (in-sample avg dev_std = 0.239)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.63
Model XAI F1 of binarized graphs for r=0.3 =  0.82549125
Model XAI WIoU of binarized graphs for r=0.3 =  0.9718049999999999
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.532
SUFF++ for r=0.3 class 0 = 0.812 +- 0.083 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.3 class 1 = 0.8 +- 0.083 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.3 class 2 = 0.798 +- 0.083 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.3 all KL = 0.923 +- 0.083 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.3 all L1 = 0.803 +- 0.121 (in-sample avg dev_std = 0.251)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.905
Model XAI F1 of binarized graphs for r=0.6 =  0.7386837499999999
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.74
SUFF++ for r=0.6 class 0 = 0.827 +- 0.167 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.6 class 1 = 0.796 +- 0.167 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.6 class 2 = 0.608 +- 0.167 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.6 all KL = 0.849 +- 0.167 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.6 all L1 = 0.743 +- 0.159 (in-sample avg dev_std = 0.321)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.931
Model XAI F1 of binarized graphs for r=0.9 =  0.6026900000000001
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.913
SUFF++ for r=0.9 class 0 = 0.934 +- 0.103 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.9 class 1 = 0.935 +- 0.103 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.9 class 2 = 0.879 +- 0.103 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.9 all KL = 0.953 +- 0.103 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.9 all L1 = 0.916 +- 0.104 (in-sample avg dev_std = 0.183)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.449
Model XAI F1 of binarized graphs for r=0.3 =  0.58823875
Model XAI WIoU of binarized graphs for r=0.3 =  0.62189
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.374
SUFF++ for r=0.3 class 0 = 0.702 +- 0.178 (in-sample avg dev_std = 0.344)
SUFF++ for r=0.3 class 1 = 0.698 +- 0.178 (in-sample avg dev_std = 0.344)
SUFF++ for r=0.3 class 2 = 0.701 +- 0.178 (in-sample avg dev_std = 0.344)
SUFF++ for r=0.3 all KL = 0.827 +- 0.178 (in-sample avg dev_std = 0.344)
SUFF++ for r=0.3 all L1 = 0.701 +- 0.137 (in-sample avg dev_std = 0.344)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.696
Model XAI F1 of binarized graphs for r=0.6 =  0.7233349999999998
Model XAI WIoU of binarized graphs for r=0.6 =  0.68979625
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.656
SUFF++ for r=0.6 class 0 = 0.752 +- 0.199 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.6 class 1 = 0.713 +- 0.199 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.6 class 2 = 0.701 +- 0.199 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.6 all KL = 0.815 +- 0.199 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.6 all L1 = 0.722 +- 0.160 (in-sample avg dev_std = 0.323)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.73
Model XAI F1 of binarized graphs for r=0.9 =  0.5941075
Model XAI WIoU of binarized graphs for r=0.9 =  0.687765
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.733
SUFF++ for r=0.9 class 0 = 0.901 +- 0.108 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.9 class 1 = 0.925 +- 0.108 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.9 class 2 = 0.863 +- 0.108 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.9 all KL = 0.942 +- 0.108 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.9 all L1 = 0.896 +- 0.138 (in-sample avg dev_std = 0.184)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.529
Model XAI F1 of binarized graphs for r=0.3 =  0.6223675
Model XAI WIoU of binarized graphs for r=0.3 =  0.63895875
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.396
NEC for r=0.3 class 0 = 0.345 +- 0.209 (in-sample avg dev_std = 0.316)
NEC for r=0.3 class 1 = 0.396 +- 0.209 (in-sample avg dev_std = 0.316)
NEC for r=0.3 class 2 = 0.388 +- 0.209 (in-sample avg dev_std = 0.316)
NEC for r=0.3 all KL = 0.243 +- 0.209 (in-sample avg dev_std = 0.316)
NEC for r=0.3 all L1 = 0.377 +- 0.159 (in-sample avg dev_std = 0.316)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.728
Model XAI F1 of binarized graphs for r=0.6 =  0.5955075
Model XAI WIoU of binarized graphs for r=0.6 =  0.6900875
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.444
NEC for r=0.6 class 0 = 0.409 +- 0.220 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 1 = 0.439 +- 0.220 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 2 = 0.43 +- 0.220 (in-sample avg dev_std = 0.351)
NEC for r=0.6 all KL = 0.3 +- 0.220 (in-sample avg dev_std = 0.351)
NEC for r=0.6 all L1 = 0.427 +- 0.134 (in-sample avg dev_std = 0.351)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.77
Model XAI F1 of binarized graphs for r=0.9 =  0.47393625
Model XAI WIoU of binarized graphs for r=0.9 =  0.690255
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.5
NEC for r=0.9 class 0 = 0.434 +- 0.227 (in-sample avg dev_std = 0.376)
NEC for r=0.9 class 1 = 0.423 +- 0.227 (in-sample avg dev_std = 0.376)
NEC for r=0.9 class 2 = 0.445 +- 0.227 (in-sample avg dev_std = 0.376)
NEC for r=0.9 all KL = 0.328 +- 0.227 (in-sample avg dev_std = 0.376)
NEC for r=0.9 all L1 = 0.434 +- 0.151 (in-sample avg dev_std = 0.376)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.795
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.690255
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.507
NEC for r=1.0 class 0 = 0.406 +- 0.244 (in-sample avg dev_std = 0.372)
NEC for r=1.0 class 1 = 0.404 +- 0.244 (in-sample avg dev_std = 0.372)
NEC for r=1.0 class 2 = 0.44 +- 0.244 (in-sample avg dev_std = 0.372)
NEC for r=1.0 all KL = 0.313 +- 0.244 (in-sample avg dev_std = 0.372)
NEC for r=1.0 all L1 = 0.417 +- 0.159 (in-sample avg dev_std = 0.372)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.629
Model XAI F1 of binarized graphs for r=0.3 =  0.82549125
Model XAI WIoU of binarized graphs for r=0.3 =  0.9718049999999999
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.493
NEC for r=0.3 class 0 = 0.282 +- 0.131 (in-sample avg dev_std = 0.160)
NEC for r=0.3 class 1 = 0.307 +- 0.131 (in-sample avg dev_std = 0.160)
NEC for r=0.3 class 2 = 0.22 +- 0.131 (in-sample avg dev_std = 0.160)
NEC for r=0.3 all KL = 0.101 +- 0.131 (in-sample avg dev_std = 0.160)
NEC for r=0.3 all L1 = 0.27 +- 0.142 (in-sample avg dev_std = 0.160)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.905
Model XAI F1 of binarized graphs for r=0.6 =  0.7386837499999999
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.636
NEC for r=0.6 class 0 = 0.315 +- 0.196 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 1 = 0.166 +- 0.196 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 2 = 0.442 +- 0.196 (in-sample avg dev_std = 0.353)
NEC for r=0.6 all KL = 0.198 +- 0.196 (in-sample avg dev_std = 0.353)
NEC for r=0.6 all L1 = 0.308 +- 0.173 (in-sample avg dev_std = 0.353)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.931
Model XAI F1 of binarized graphs for r=0.9 =  0.6026900000000001
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.674
NEC for r=0.9 class 0 = 0.287 +- 0.242 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 1 = 0.11 +- 0.242 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 2 = 0.428 +- 0.242 (in-sample avg dev_std = 0.393)
NEC for r=0.9 all KL = 0.218 +- 0.242 (in-sample avg dev_std = 0.393)
NEC for r=0.9 all L1 = 0.276 +- 0.192 (in-sample avg dev_std = 0.393)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.931
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  1.0
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.698
NEC for r=1.0 class 0 = 0.252 +- 0.250 (in-sample avg dev_std = 0.384)
NEC for r=1.0 class 1 = 0.097 +- 0.250 (in-sample avg dev_std = 0.384)
NEC for r=1.0 class 2 = 0.411 +- 0.250 (in-sample avg dev_std = 0.384)
NEC for r=1.0 all KL = 0.205 +- 0.250 (in-sample avg dev_std = 0.384)
NEC for r=1.0 all L1 = 0.254 +- 0.187 (in-sample avg dev_std = 0.384)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.45
Model XAI F1 of binarized graphs for r=0.3 =  0.58823875
Model XAI WIoU of binarized graphs for r=0.3 =  0.62189
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.492
NEC for r=0.3 class 0 = 0.327 +- 0.198 (in-sample avg dev_std = 0.267)
NEC for r=0.3 class 1 = 0.353 +- 0.198 (in-sample avg dev_std = 0.267)
NEC for r=0.3 class 2 = 0.315 +- 0.198 (in-sample avg dev_std = 0.267)
NEC for r=0.3 all KL = 0.182 +- 0.198 (in-sample avg dev_std = 0.267)
NEC for r=0.3 all L1 = 0.331 +- 0.165 (in-sample avg dev_std = 0.267)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.699
Model XAI F1 of binarized graphs for r=0.6 =  0.7233349999999998
Model XAI WIoU of binarized graphs for r=0.6 =  0.68979625
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.535
NEC for r=0.6 class 0 = 0.472 +- 0.243 (in-sample avg dev_std = 0.335)
NEC for r=0.6 class 1 = 0.386 +- 0.243 (in-sample avg dev_std = 0.335)
NEC for r=0.6 class 2 = 0.438 +- 0.243 (in-sample avg dev_std = 0.335)
NEC for r=0.6 all KL = 0.343 +- 0.243 (in-sample avg dev_std = 0.335)
NEC for r=0.6 all L1 = 0.433 +- 0.158 (in-sample avg dev_std = 0.335)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.724
Model XAI F1 of binarized graphs for r=0.9 =  0.5941075
Model XAI WIoU of binarized graphs for r=0.9 =  0.687765
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.616
NEC for r=0.9 class 0 = 0.4 +- 0.264 (in-sample avg dev_std = 0.399)
NEC for r=0.9 class 1 = 0.338 +- 0.264 (in-sample avg dev_std = 0.399)
NEC for r=0.9 class 2 = 0.46 +- 0.264 (in-sample avg dev_std = 0.399)
NEC for r=0.9 all KL = 0.354 +- 0.264 (in-sample avg dev_std = 0.399)
NEC for r=0.9 all L1 = 0.401 +- 0.153 (in-sample avg dev_std = 0.399)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.755
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.687765
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.615
NEC for r=1.0 class 0 = 0.396 +- 0.286 (in-sample avg dev_std = 0.429)
NEC for r=1.0 class 1 = 0.33 +- 0.286 (in-sample avg dev_std = 0.429)
NEC for r=1.0 class 2 = 0.461 +- 0.286 (in-sample avg dev_std = 0.429)
NEC for r=1.0 all KL = 0.378 +- 0.286 (in-sample avg dev_std = 0.429)
NEC for r=1.0 all L1 = 0.397 +- 0.158 (in-sample avg dev_std = 0.429)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.721, 0.595, 0.818, 1.0], 'all_L1': [0.598, 0.521, 0.712, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.657, 0.618, 0.813, 1.0], 'all_L1': [0.579, 0.556, 0.729, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.872, 0.694, 0.823, 1.0], 'all_L1': [0.757, 0.652, 0.793, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.925, 0.862, 0.93, 1.0], 'all_L1': [0.777, 0.765, 0.879, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.753, 0.781, 0.88, 1.0], 'all_L1': [0.621, 0.649, 0.766, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.289, 0.446, 0.364, 0.341], 'all_L1': [0.42, 0.514, 0.466, 0.454]}), defaultdict(<class 'list'>, {'all_KL': [0.475, 0.483, 0.433, 0.427], 'all_L1': [0.53, 0.521, 0.498, 0.485]}), defaultdict(<class 'list'>, {'all_KL': [0.143, 0.32, 0.403, 0.453], 'all_L1': [0.279, 0.376, 0.434, 0.466]}), defaultdict(<class 'list'>, {'all_KL': [0.067, 0.142, 0.15, 0.16], 'all_L1': [0.204, 0.232, 0.229, 0.238]}), defaultdict(<class 'list'>, {'all_KL': [0.243, 0.3, 0.328, 0.313], 'all_L1': [0.377, 0.427, 0.434, 0.417]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.763, 0.76, 0.887, 1.0], 'all_L1': [0.702, 0.721, 0.852, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.802, 0.838, 0.954, 1.0], 'all_L1': [0.747, 0.782, 0.944, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.959, 0.768, 0.849, 1.0], 'all_L1': [0.865, 0.75, 0.871, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.973, 0.925, 0.909, 1.0], 'all_L1': [0.884, 0.884, 0.906, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.923, 0.849, 0.953, 1.0], 'all_L1': [0.803, 0.743, 0.916, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.315, 0.379, 0.311, 0.283], 'all_L1': [0.434, 0.386, 0.322, 0.303]}), defaultdict(<class 'list'>, {'all_KL': [0.616, 0.471, 0.446, 0.433], 'all_L1': [0.625, 0.462, 0.39, 0.387]}), defaultdict(<class 'list'>, {'all_KL': [0.075, 0.237, 0.444, 0.45], 'all_L1': [0.23, 0.291, 0.334, 0.328]}), defaultdict(<class 'list'>, {'all_KL': [0.044, 0.097, 0.22, 0.24], 'all_L1': [0.172, 0.153, 0.187, 0.193]}), defaultdict(<class 'list'>, {'all_KL': [0.101, 0.198, 0.218, 0.205], 'all_L1': [0.27, 0.308, 0.276, 0.254]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.92, 0.832, 0.889, 1.0], 'all_L1': [0.784, 0.711, 0.757, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.699, 0.862, 0.872, 1.0], 'all_L1': [0.661, 0.765, 0.83, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.951, 0.935, 0.895, 1.0], 'all_L1': [0.82, 0.816, 0.799, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.95, 0.961, 0.98, 1.0], 'all_L1': [0.838, 0.89, 0.96, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.827, 0.815, 0.942, 1.0], 'all_L1': [0.701, 0.722, 0.896, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.083, 0.24, 0.218, 0.213], 'all_L1': [0.215, 0.358, 0.359, 0.365]}), defaultdict(<class 'list'>, {'all_KL': [0.588, 0.571, 0.482, 0.466], 'all_L1': [0.578, 0.546, 0.471, 0.455]}), defaultdict(<class 'list'>, {'all_KL': [0.059, 0.072, 0.181, 0.225], 'all_L1': [0.194, 0.207, 0.308, 0.345]}), defaultdict(<class 'list'>, {'all_KL': [0.036, 0.043, 0.069, 0.072], 'all_L1': [0.139, 0.124, 0.122, 0.119]}), defaultdict(<class 'list'>, {'all_KL': [0.182, 0.343, 0.354, 0.378], 'all_L1': [0.331, 0.433, 0.401, 0.397]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.666 +- 0.083, 0.629 +- 0.085, 0.776 +- 0.059, 1.000 +- 0.000
suff++ class all_KL  =  0.786 +- 0.099, 0.710 +- 0.100, 0.853 +- 0.046, 1.000 +- 0.000
suff++_acc_int  =  0.412 +- 0.032, 0.534 +- 0.037, 0.681 +- 0.046
nec class all_L1  =  0.362 +- 0.113, 0.414 +- 0.106, 0.412 +- 0.095, 0.412 +- 0.090
nec class all_KL  =  0.243 +- 0.139, 0.338 +- 0.121, 0.336 +- 0.099, 0.339 +- 0.103
nec_acc_int  =  0.360 +- 0.021, 0.427 +- 0.022, 0.481 +- 0.024, 0.490 +- 0.031

Eval split val
suff++ class all_L1  =  0.800 +- 0.069, 0.776 +- 0.057, 0.898 +- 0.033, 1.000 +- 0.000
suff++ class all_KL  =  0.884 +- 0.085, 0.828 +- 0.060, 0.910 +- 0.040, 1.000 +- 0.000
suff++_acc_int  =  0.471 +- 0.080, 0.703 +- 0.148, 0.845 +- 0.063
nec class all_L1  =  0.346 +- 0.164, 0.320 +- 0.103, 0.302 +- 0.068, 0.293 +- 0.066
nec class all_KL  =  0.230 +- 0.215, 0.276 +- 0.133, 0.328 +- 0.101, 0.322 +- 0.101
nec_acc_int  =  0.373 +- 0.090, 0.567 +- 0.065, 0.666 +- 0.011, 0.682 +- 0.013

Eval split test
suff++ class all_L1  =  0.761 +- 0.069, 0.781 +- 0.066, 0.848 +- 0.072, 1.000 +- 0.000
suff++ class all_KL  =  0.869 +- 0.096, 0.881 +- 0.057, 0.916 +- 0.040, 1.000 +- 0.000
suff++_acc_int  =  0.397 +- 0.062, 0.570 +- 0.170, 0.613 +- 0.150
nec class all_L1  =  0.291 +- 0.156, 0.334 +- 0.152, 0.332 +- 0.118, 0.336 +- 0.115
nec class all_KL  =  0.190 +- 0.205, 0.254 +- 0.193, 0.261 +- 0.143, 0.271 +- 0.138
nec_acc_int  =  0.385 +- 0.066, 0.452 +- 0.072, 0.525 +- 0.098, 0.531 +- 0.097


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.514 +- 0.022, 0.521 +- 0.015, 0.594 +- 0.022, 0.706 +- 0.045
Faith. Armon (L1)= 		  =  0.449 +- 0.079, 0.481 +- 0.065, 0.527 +- 0.083, 0.577 +- 0.099
Faith. GMean (L1)= 	  =  0.479 +- 0.051, 0.500 +- 0.042, 0.558 +- 0.056, 0.637 +- 0.077
Faith. Aritm (KL)= 		  =  0.515 +- 0.026, 0.524 +- 0.019, 0.594 +- 0.029, 0.669 +- 0.052
Faith. Armon (KL)= 		  =  0.340 +- 0.145, 0.433 +- 0.104, 0.469 +- 0.110, 0.497 +- 0.123
Faith. GMean (KL)= 	  =  0.409 +- 0.104, 0.473 +- 0.067, 0.525 +- 0.078, 0.574 +- 0.097

Eval split val
Faith. Aritm (L1)= 		  =  0.573 +- 0.058, 0.548 +- 0.039, 0.600 +- 0.039, 0.646 +- 0.033
Faith. Armon (L1)= 		  =  0.454 +- 0.139, 0.440 +- 0.106, 0.447 +- 0.080, 0.449 +- 0.080
Faith. GMean (L1)= 	  =  0.507 +- 0.102, 0.488 +- 0.077, 0.517 +- 0.063, 0.538 +- 0.062
Faith. Aritm (KL)= 		  =  0.557 +- 0.077, 0.552 +- 0.056, 0.619 +- 0.049, 0.661 +- 0.050
Faith. Armon (KL)= 		  =  0.310 +- 0.230, 0.394 +- 0.148, 0.472 +- 0.108, 0.479 +- 0.114
Faith. GMean (KL)= 	  =  0.395 +- 0.181, 0.460 +- 0.113, 0.539 +- 0.082, 0.561 +- 0.088

Eval split test
Faith. Aritm (L1)= 		  =  0.526 +- 0.048, 0.557 +- 0.055, 0.590 +- 0.049, 0.668 +- 0.057
Faith. Armon (L1)= 		  =  0.391 +- 0.132, 0.441 +- 0.150, 0.461 +- 0.133, 0.491 +- 0.144
Faith. GMean (L1)= 	  =  0.450 +- 0.095, 0.491 +- 0.110, 0.517 +- 0.100, 0.568 +- 0.115
Faith. Aritm (KL)= 		  =  0.530 +- 0.057, 0.567 +- 0.080, 0.588 +- 0.062, 0.635 +- 0.069
Faith. Armon (KL)= 		  =  0.254 +- 0.207, 0.352 +- 0.224, 0.383 +- 0.171, 0.407 +- 0.174
Faith. GMean (KL)= 	  =  0.345 +- 0.162, 0.428 +- 0.181, 0.466 +- 0.136, 0.500 +- 0.143
Computed for split load_split = id



Completed in  0:17:08.819913  for LECIGIN GOODMotif/basis



DONE LECI GOODMotif/basis

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 11:07:37 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:07:38 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 127...
[0m[1;37mINFO[0m: [1mCheckpoint 127: 
-----------------------------------
Train ACCURACY: 0.7105
Train Loss: 0.8749
ID Validation ACCURACY: 0.7120
ID Validation Loss: 0.8554
ID Test ACCURACY: 0.6983
ID Test Loss: 0.8801
OOD Validation ACCURACY: 0.7767
OOD Validation Loss: 0.8949
OOD Test ACCURACY: 0.6193
OOD Test Loss: 0.9061

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 135...
[0m[1;37mINFO[0m: [1mCheckpoint 135: 
-----------------------------------
Train ACCURACY: 0.6873
Train Loss: 0.9207
ID Validation ACCURACY: 0.6927
ID Validation Loss: 0.8984
ID Test ACCURACY: 0.6867
ID Test Loss: 0.9202
OOD Validation ACCURACY: 0.7963
OOD Validation Loss: 0.9221
OOD Test ACCURACY: 0.5000
OOD Test Loss: 1.1613

[0m[1;37mINFO[0m: [1mChartInfo 0.6983 0.6193 0.6867 0.5000 0.6927 0.7963[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.720
WIoU for r=0.3 = 0.676
F1 for r=0.6 = 0.625
WIoU for r=0.6 = 0.750
F1 for r=0.9 = 0.481
WIoU for r=0.9 = 0.743
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.742
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.668
WIoU for r=0.3 = 0.997
F1 for r=0.6 = 0.409
WIoU for r=0.6 = 0.997
F1 for r=0.9 = 0.295
WIoU for r=0.9 = 0.997
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.997
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.752
WIoU for r=0.3 = 0.823
F1 for r=0.6 = 0.542
WIoU for r=0.6 = 0.786
F1 for r=0.9 = 0.424
WIoU for r=0.9 = 0.783
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.782


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.36
Model XAI F1 of binarized graphs for r=0.3 =  0.720325
Model XAI WIoU of binarized graphs for r=0.3 =  0.6758325
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.349
SUFF++ for r=0.3 class 0 = 0.744 +- 0.142 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.3 class 1 = 0.854 +- 0.142 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.3 class 2 = 0.82 +- 0.142 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.3 all KL = 0.914 +- 0.142 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.3 all L1 = 0.806 +- 0.115 (in-sample avg dev_std = 0.194)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.514
Model XAI F1 of binarized graphs for r=0.6 =  0.6247775
Model XAI WIoU of binarized graphs for r=0.6 =  0.749675
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.439
SUFF++ for r=0.6 class 0 = 0.652 +- 0.156 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.6 class 1 = 0.802 +- 0.156 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.6 class 2 = 0.719 +- 0.156 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.6 all KL = 0.837 +- 0.156 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.6 all L1 = 0.724 +- 0.130 (in-sample avg dev_std = 0.277)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.613
Model XAI F1 of binarized graphs for r=0.9 =  0.48133875
Model XAI WIoU of binarized graphs for r=0.9 =  0.7426724999999998
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.562
SUFF++ for r=0.9 class 0 = 0.749 +- 0.126 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.9 class 1 = 0.761 +- 0.126 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.9 class 2 = 0.736 +- 0.126 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.9 all KL = 0.872 +- 0.126 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.9 all L1 = 0.748 +- 0.140 (in-sample avg dev_std = 0.267)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.598
Model XAI F1 of binarized graphs for r=0.3 =  0.6684275
Model XAI WIoU of binarized graphs for r=0.3 =  0.9973650000000001
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.338
SUFF++ for r=0.3 class 0 = 0.612 +- 0.263 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.3 class 1 = 0.769 +- 0.263 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.3 class 2 = 0.649 +- 0.263 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.3 all KL = 0.746 +- 0.263 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.3 all L1 = 0.676 +- 0.153 (in-sample avg dev_std = 0.231)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.779
Model XAI F1 of binarized graphs for r=0.6 =  0.40870874999999995
Model XAI WIoU of binarized graphs for r=0.6 =  0.9973650000000001
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.443
SUFF++ for r=0.6 class 0 = 0.669 +- 0.143 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.6 class 1 = 0.667 +- 0.143 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.6 class 2 = 0.703 +- 0.143 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.6 all KL = 0.815 +- 0.143 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.6 all L1 = 0.68 +- 0.096 (in-sample avg dev_std = 0.250)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.759
Model XAI F1 of binarized graphs for r=0.9 =  0.29499375
Model XAI WIoU of binarized graphs for r=0.9 =  0.9973650000000001
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.649
SUFF++ for r=0.9 class 0 = 0.806 +- 0.062 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.9 class 1 = 0.818 +- 0.062 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.9 class 2 = 0.852 +- 0.062 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.9 all KL = 0.941 +- 0.062 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.9 all L1 = 0.825 +- 0.112 (in-sample avg dev_std = 0.179)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.381
Model XAI F1 of binarized graphs for r=0.3 =  0.7518837500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.8232237499999999
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.36
SUFF++ for r=0.3 class 0 = 0.684 +- 0.168 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.3 class 1 = 0.862 +- 0.168 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.3 class 2 = 0.77 +- 0.168 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.3 all KL = 0.876 +- 0.168 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.3 all L1 = 0.774 +- 0.150 (in-sample avg dev_std = 0.213)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.484
Model XAI F1 of binarized graphs for r=0.6 =  0.54238875
Model XAI WIoU of binarized graphs for r=0.6 =  0.7856062500000001
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.49
SUFF++ for r=0.6 class 0 = 0.682 +- 0.176 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.6 class 1 = 0.767 +- 0.176 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.6 class 2 = 0.726 +- 0.176 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.6 all KL = 0.84 +- 0.176 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.6 all L1 = 0.726 +- 0.141 (in-sample avg dev_std = 0.289)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.685
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.78251125
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.619
SUFF++ for r=0.9 class 0 = 0.8 +- 0.067 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.9 class 1 = 0.828 +- 0.067 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.9 class 2 = 0.843 +- 0.067 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.9 all KL = 0.944 +- 0.067 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.9 all L1 = 0.824 +- 0.111 (in-sample avg dev_std = 0.163)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.359
Model XAI F1 of binarized graphs for r=0.3 =  0.720325
Model XAI WIoU of binarized graphs for r=0.3 =  0.6758325
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.327
NEC for r=0.3 class 0 = 0.271 +- 0.164 (in-sample avg dev_std = 0.143)
NEC for r=0.3 class 1 = 0.177 +- 0.164 (in-sample avg dev_std = 0.143)
NEC for r=0.3 class 2 = 0.181 +- 0.164 (in-sample avg dev_std = 0.143)
NEC for r=0.3 all KL = 0.093 +- 0.164 (in-sample avg dev_std = 0.143)
NEC for r=0.3 all L1 = 0.21 +- 0.128 (in-sample avg dev_std = 0.143)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.515
Model XAI F1 of binarized graphs for r=0.6 =  0.6247775
Model XAI WIoU of binarized graphs for r=0.6 =  0.749675
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.415
NEC for r=0.6 class 0 = 0.347 +- 0.204 (in-sample avg dev_std = 0.228)
NEC for r=0.6 class 1 = 0.209 +- 0.204 (in-sample avg dev_std = 0.228)
NEC for r=0.6 class 2 = 0.311 +- 0.204 (in-sample avg dev_std = 0.228)
NEC for r=0.6 all KL = 0.177 +- 0.204 (in-sample avg dev_std = 0.228)
NEC for r=0.6 all L1 = 0.289 +- 0.133 (in-sample avg dev_std = 0.228)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.611
Model XAI F1 of binarized graphs for r=0.9 =  0.48133875
Model XAI WIoU of binarized graphs for r=0.9 =  0.7426724999999998
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.405
NEC for r=0.9 class 0 = 0.406 +- 0.218 (in-sample avg dev_std = 0.233)
NEC for r=0.9 class 1 = 0.244 +- 0.218 (in-sample avg dev_std = 0.233)
NEC for r=0.9 class 2 = 0.324 +- 0.218 (in-sample avg dev_std = 0.233)
NEC for r=0.9 all KL = 0.208 +- 0.218 (in-sample avg dev_std = 0.233)
NEC for r=0.9 all L1 = 0.324 +- 0.140 (in-sample avg dev_std = 0.233)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.729
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.74215375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.431
NEC for r=1.0 class 0 = 0.393 +- 0.226 (in-sample avg dev_std = 0.249)
NEC for r=1.0 class 1 = 0.275 +- 0.226 (in-sample avg dev_std = 0.249)
NEC for r=1.0 class 2 = 0.363 +- 0.226 (in-sample avg dev_std = 0.249)
NEC for r=1.0 all KL = 0.248 +- 0.226 (in-sample avg dev_std = 0.249)
NEC for r=1.0 all L1 = 0.343 +- 0.130 (in-sample avg dev_std = 0.249)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.595
Model XAI F1 of binarized graphs for r=0.3 =  0.6684275
Model XAI WIoU of binarized graphs for r=0.3 =  0.9973650000000001
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.342
NEC for r=0.3 class 0 = 0.376 +- 0.252 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 1 = 0.283 +- 0.252 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 2 = 0.362 +- 0.252 (in-sample avg dev_std = 0.220)
NEC for r=0.3 all KL = 0.261 +- 0.252 (in-sample avg dev_std = 0.220)
NEC for r=0.3 all L1 = 0.341 +- 0.149 (in-sample avg dev_std = 0.220)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.779
Model XAI F1 of binarized graphs for r=0.6 =  0.40870874999999995
Model XAI WIoU of binarized graphs for r=0.6 =  0.9973650000000001
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.372
NEC for r=0.6 class 0 = 0.346 +- 0.146 (in-sample avg dev_std = 0.262)
NEC for r=0.6 class 1 = 0.366 +- 0.146 (in-sample avg dev_std = 0.262)
NEC for r=0.6 class 2 = 0.346 +- 0.146 (in-sample avg dev_std = 0.262)
NEC for r=0.6 all KL = 0.219 +- 0.146 (in-sample avg dev_std = 0.262)
NEC for r=0.6 all L1 = 0.352 +- 0.085 (in-sample avg dev_std = 0.262)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.759
Model XAI F1 of binarized graphs for r=0.9 =  0.29499375
Model XAI WIoU of binarized graphs for r=0.9 =  0.9973650000000001
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.393
NEC for r=0.9 class 0 = 0.339 +- 0.083 (in-sample avg dev_std = 0.238)
NEC for r=0.9 class 1 = 0.407 +- 0.083 (in-sample avg dev_std = 0.238)
NEC for r=0.9 class 2 = 0.29 +- 0.083 (in-sample avg dev_std = 0.238)
NEC for r=0.9 all KL = 0.171 +- 0.083 (in-sample avg dev_std = 0.238)
NEC for r=0.9 all L1 = 0.345 +- 0.092 (in-sample avg dev_std = 0.238)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.755
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.9973650000000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.403
NEC for r=1.0 class 0 = 0.343 +- 0.077 (in-sample avg dev_std = 0.237)
NEC for r=1.0 class 1 = 0.407 +- 0.077 (in-sample avg dev_std = 0.237)
NEC for r=1.0 class 2 = 0.291 +- 0.077 (in-sample avg dev_std = 0.237)
NEC for r=1.0 all KL = 0.167 +- 0.077 (in-sample avg dev_std = 0.237)
NEC for r=1.0 all L1 = 0.346 +- 0.089 (in-sample avg dev_std = 0.237)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.381
Model XAI F1 of binarized graphs for r=0.3 =  0.7518837500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.8232237499999999
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.285
NEC for r=0.3 class 0 = 0.322 +- 0.203 (in-sample avg dev_std = 0.153)
NEC for r=0.3 class 1 = 0.235 +- 0.203 (in-sample avg dev_std = 0.153)
NEC for r=0.3 class 2 = 0.244 +- 0.203 (in-sample avg dev_std = 0.153)
NEC for r=0.3 all KL = 0.149 +- 0.203 (in-sample avg dev_std = 0.153)
NEC for r=0.3 all L1 = 0.266 +- 0.148 (in-sample avg dev_std = 0.153)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.484
Model XAI F1 of binarized graphs for r=0.6 =  0.54238875
Model XAI WIoU of binarized graphs for r=0.6 =  0.7856062500000001
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.405
NEC for r=0.6 class 0 = 0.358 +- 0.216 (in-sample avg dev_std = 0.262)
NEC for r=0.6 class 1 = 0.228 +- 0.216 (in-sample avg dev_std = 0.262)
NEC for r=0.6 class 2 = 0.27 +- 0.216 (in-sample avg dev_std = 0.262)
NEC for r=0.6 all KL = 0.193 +- 0.216 (in-sample avg dev_std = 0.262)
NEC for r=0.6 all L1 = 0.284 +- 0.154 (in-sample avg dev_std = 0.262)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.685
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.78251125
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.447
NEC for r=0.9 class 0 = 0.361 +- 0.218 (in-sample avg dev_std = 0.294)
NEC for r=0.9 class 1 = 0.289 +- 0.218 (in-sample avg dev_std = 0.294)
NEC for r=0.9 class 2 = 0.347 +- 0.218 (in-sample avg dev_std = 0.294)
NEC for r=0.9 all KL = 0.263 +- 0.218 (in-sample avg dev_std = 0.294)
NEC for r=0.9 all L1 = 0.332 +- 0.121 (in-sample avg dev_std = 0.294)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.611
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.78244
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.454
NEC for r=1.0 class 0 = 0.376 +- 0.190 (in-sample avg dev_std = 0.300)
NEC for r=1.0 class 1 = 0.283 +- 0.190 (in-sample avg dev_std = 0.300)
NEC for r=1.0 class 2 = 0.347 +- 0.190 (in-sample avg dev_std = 0.300)
NEC for r=1.0 all KL = 0.236 +- 0.190 (in-sample avg dev_std = 0.300)
NEC for r=1.0 all L1 = 0.335 +- 0.140 (in-sample avg dev_std = 0.300)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 11:11:24 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:11:24 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 155...
[0m[1;37mINFO[0m: [1mCheckpoint 155: 
-----------------------------------
Train ACCURACY: 0.7914
Train Loss: 0.6697
ID Validation ACCURACY: 0.8063
ID Validation Loss: 0.6802
ID Test ACCURACY: 0.7953
ID Test Loss: 0.6929
OOD Validation ACCURACY: 0.8873
OOD Validation Loss: 0.6953
OOD Test ACCURACY: 0.6320
OOD Test Loss: 0.9917

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 155...
[0m[1;37mINFO[0m: [1mCheckpoint 155: 
-----------------------------------
Train ACCURACY: 0.7914
Train Loss: 0.6697
ID Validation ACCURACY: 0.8063
ID Validation Loss: 0.6802
ID Test ACCURACY: 0.7953
ID Test Loss: 0.6929
OOD Validation ACCURACY: 0.8873
OOD Validation Loss: 0.6953
OOD Test ACCURACY: 0.6320
OOD Test Loss: 0.9917

[0m[1;37mINFO[0m: [1mChartInfo 0.7953 0.6320 0.7953 0.6320 0.8063 0.8873[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.716
WIoU for r=0.3 = 0.742
F1 for r=0.6 = 0.624
WIoU for r=0.6 = 0.796
F1 for r=0.9 = 0.481
WIoU for r=0.9 = 0.797
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.797
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.668
WIoU for r=0.3 = 0.996
F1 for r=0.6 = 0.409
WIoU for r=0.6 = 0.996
F1 for r=0.9 = 0.295
WIoU for r=0.9 = 0.996
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.996
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.695
WIoU for r=0.3 = 0.828
F1 for r=0.6 = 0.556
WIoU for r=0.6 = 0.895
F1 for r=0.9 = 0.423
WIoU for r=0.9 = 0.881
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.880


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.411
Model XAI F1 of binarized graphs for r=0.3 =  0.7158500000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.742175
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.4
SUFF++ for r=0.3 class 0 = 0.747 +- 0.195 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.3 class 1 = 0.846 +- 0.195 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.3 class 2 = 0.782 +- 0.195 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.3 all KL = 0.9 +- 0.195 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.3 all L1 = 0.792 +- 0.139 (in-sample avg dev_std = 0.230)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.613
Model XAI F1 of binarized graphs for r=0.6 =  0.62408
Model XAI WIoU of binarized graphs for r=0.6 =  0.7959062499999999
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.512
SUFF++ for r=0.6 class 0 = 0.567 +- 0.284 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 class 1 = 0.752 +- 0.284 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 class 2 = 0.581 +- 0.284 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 all KL = 0.711 +- 0.284 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 all L1 = 0.634 +- 0.173 (in-sample avg dev_std = 0.396)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.744
Model XAI F1 of binarized graphs for r=0.9 =  0.48128875
Model XAI WIoU of binarized graphs for r=0.9 =  0.796695
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.723
SUFF++ for r=0.9 class 0 = 0.771 +- 0.209 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.9 class 1 = 0.83 +- 0.209 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.9 class 2 = 0.675 +- 0.209 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.9 all KL = 0.819 +- 0.209 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.9 all L1 = 0.759 +- 0.189 (in-sample avg dev_std = 0.366)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.723
Model XAI F1 of binarized graphs for r=0.3 =  0.66841125
Model XAI WIoU of binarized graphs for r=0.3 =  0.99614625
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.357
SUFF++ for r=0.3 class 0 = 0.496 +- 0.392 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.3 class 1 = 0.768 +- 0.392 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.3 class 2 = 0.574 +- 0.392 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.3 all KL = 0.665 +- 0.392 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.3 all L1 = 0.611 +- 0.238 (in-sample avg dev_std = 0.272)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.89
Model XAI F1 of binarized graphs for r=0.6 =  0.40923874999999993
Model XAI WIoU of binarized graphs for r=0.6 =  0.99614625
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.538
SUFF++ for r=0.6 class 0 = 0.536 +- 0.321 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.6 class 1 = 0.72 +- 0.321 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.6 class 2 = 0.495 +- 0.321 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.6 all KL = 0.625 +- 0.321 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.6 all L1 = 0.582 +- 0.171 (in-sample avg dev_std = 0.423)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.902
Model XAI F1 of binarized graphs for r=0.9 =  0.2951625
Model XAI WIoU of binarized graphs for r=0.9 =  0.99614625
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.722
SUFF++ for r=0.9 class 0 = 0.778 +- 0.216 (in-sample avg dev_std = 0.308)
SUFF++ for r=0.9 class 1 = 0.807 +- 0.216 (in-sample avg dev_std = 0.308)
SUFF++ for r=0.9 class 2 = 0.699 +- 0.216 (in-sample avg dev_std = 0.308)
SUFF++ for r=0.9 all KL = 0.843 +- 0.216 (in-sample avg dev_std = 0.308)
SUFF++ for r=0.9 all L1 = 0.761 +- 0.175 (in-sample avg dev_std = 0.308)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.468
Model XAI F1 of binarized graphs for r=0.3 =  0.69463
Model XAI WIoU of binarized graphs for r=0.3 =  0.8281125
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.434
SUFF++ for r=0.3 class 0 = 0.684 +- 0.179 (in-sample avg dev_std = 0.306)
SUFF++ for r=0.3 class 1 = 0.823 +- 0.179 (in-sample avg dev_std = 0.306)
SUFF++ for r=0.3 class 2 = 0.777 +- 0.179 (in-sample avg dev_std = 0.306)
SUFF++ for r=0.3 all KL = 0.866 +- 0.179 (in-sample avg dev_std = 0.306)
SUFF++ for r=0.3 all L1 = 0.763 +- 0.125 (in-sample avg dev_std = 0.306)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.566
Model XAI F1 of binarized graphs for r=0.6 =  0.5563075
Model XAI WIoU of binarized graphs for r=0.6 =  0.8949700000000002
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.635
SUFF++ for r=0.6 class 0 = 0.647 +- 0.258 (in-sample avg dev_std = 0.447)
SUFF++ for r=0.6 class 1 = 0.751 +- 0.258 (in-sample avg dev_std = 0.447)
SUFF++ for r=0.6 class 2 = 0.619 +- 0.258 (in-sample avg dev_std = 0.447)
SUFF++ for r=0.6 all KL = 0.713 +- 0.258 (in-sample avg dev_std = 0.447)
SUFF++ for r=0.6 all L1 = 0.673 +- 0.156 (in-sample avg dev_std = 0.447)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.561
Model XAI F1 of binarized graphs for r=0.9 =  0.42330375000000003
Model XAI WIoU of binarized graphs for r=0.9 =  0.8809375
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.653
SUFF++ for r=0.9 class 0 = 0.747 +- 0.308 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.9 class 1 = 0.781 +- 0.308 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.9 class 2 = 0.726 +- 0.308 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.9 all KL = 0.748 +- 0.308 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.9 all L1 = 0.752 +- 0.251 (in-sample avg dev_std = 0.364)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.412
Model XAI F1 of binarized graphs for r=0.3 =  0.7158500000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.742175
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.287
NEC for r=0.3 class 0 = 0.241 +- 0.198 (in-sample avg dev_std = 0.188)
NEC for r=0.3 class 1 = 0.242 +- 0.198 (in-sample avg dev_std = 0.188)
NEC for r=0.3 class 2 = 0.234 +- 0.198 (in-sample avg dev_std = 0.188)
NEC for r=0.3 all KL = 0.108 +- 0.198 (in-sample avg dev_std = 0.188)
NEC for r=0.3 all L1 = 0.239 +- 0.141 (in-sample avg dev_std = 0.188)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.616
Model XAI F1 of binarized graphs for r=0.6 =  0.62408
Model XAI WIoU of binarized graphs for r=0.6 =  0.7959062499999999
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.39
NEC for r=0.6 class 0 = 0.373 +- 0.300 (in-sample avg dev_std = 0.335)
NEC for r=0.6 class 1 = 0.292 +- 0.300 (in-sample avg dev_std = 0.335)
NEC for r=0.6 class 2 = 0.406 +- 0.300 (in-sample avg dev_std = 0.335)
NEC for r=0.6 all KL = 0.262 +- 0.300 (in-sample avg dev_std = 0.335)
NEC for r=0.6 all L1 = 0.357 +- 0.167 (in-sample avg dev_std = 0.335)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.736
Model XAI F1 of binarized graphs for r=0.9 =  0.48128875
Model XAI WIoU of binarized graphs for r=0.9 =  0.796695
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.456
NEC for r=0.9 class 0 = 0.412 +- 0.299 (in-sample avg dev_std = 0.386)
NEC for r=0.9 class 1 = 0.28 +- 0.299 (in-sample avg dev_std = 0.386)
NEC for r=0.9 class 2 = 0.439 +- 0.299 (in-sample avg dev_std = 0.386)
NEC for r=0.9 all KL = 0.298 +- 0.299 (in-sample avg dev_std = 0.386)
NEC for r=0.9 all L1 = 0.377 +- 0.167 (in-sample avg dev_std = 0.386)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.827
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.796695
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.465
NEC for r=1.0 class 0 = 0.445 +- 0.320 (in-sample avg dev_std = 0.377)
NEC for r=1.0 class 1 = 0.28 +- 0.320 (in-sample avg dev_std = 0.377)
NEC for r=1.0 class 2 = 0.507 +- 0.320 (in-sample avg dev_std = 0.377)
NEC for r=1.0 all KL = 0.352 +- 0.320 (in-sample avg dev_std = 0.377)
NEC for r=1.0 all L1 = 0.41 +- 0.187 (in-sample avg dev_std = 0.377)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.726
Model XAI F1 of binarized graphs for r=0.3 =  0.66841125
Model XAI WIoU of binarized graphs for r=0.3 =  0.99614625
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.326
NEC for r=0.3 class 0 = 0.483 +- 0.390 (in-sample avg dev_std = 0.225)
NEC for r=0.3 class 1 = 0.272 +- 0.390 (in-sample avg dev_std = 0.225)
NEC for r=0.3 class 2 = 0.449 +- 0.390 (in-sample avg dev_std = 0.225)
NEC for r=0.3 all KL = 0.333 +- 0.390 (in-sample avg dev_std = 0.225)
NEC for r=0.3 all L1 = 0.402 +- 0.223 (in-sample avg dev_std = 0.225)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.89
Model XAI F1 of binarized graphs for r=0.6 =  0.40923874999999993
Model XAI WIoU of binarized graphs for r=0.6 =  0.99614625
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.406
NEC for r=0.6 class 0 = 0.479 +- 0.343 (in-sample avg dev_std = 0.377)
NEC for r=0.6 class 1 = 0.314 +- 0.343 (in-sample avg dev_std = 0.377)
NEC for r=0.6 class 2 = 0.609 +- 0.343 (in-sample avg dev_std = 0.377)
NEC for r=0.6 all KL = 0.424 +- 0.343 (in-sample avg dev_std = 0.377)
NEC for r=0.6 all L1 = 0.469 +- 0.189 (in-sample avg dev_std = 0.377)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.902
Model XAI F1 of binarized graphs for r=0.9 =  0.2951625
Model XAI WIoU of binarized graphs for r=0.9 =  0.99614625
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.492
NEC for r=0.9 class 0 = 0.407 +- 0.251 (in-sample avg dev_std = 0.402)
NEC for r=0.9 class 1 = 0.32 +- 0.251 (in-sample avg dev_std = 0.402)
NEC for r=0.9 class 2 = 0.499 +- 0.251 (in-sample avg dev_std = 0.402)
NEC for r=0.9 all KL = 0.306 +- 0.251 (in-sample avg dev_std = 0.402)
NEC for r=0.9 all L1 = 0.41 +- 0.147 (in-sample avg dev_std = 0.402)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.906
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.99614625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.477
NEC for r=1.0 class 0 = 0.402 +- 0.227 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 1 = 0.334 +- 0.227 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 2 = 0.473 +- 0.227 (in-sample avg dev_std = 0.402)
NEC for r=1.0 all KL = 0.287 +- 0.227 (in-sample avg dev_std = 0.402)
NEC for r=1.0 all L1 = 0.404 +- 0.136 (in-sample avg dev_std = 0.402)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.464
Model XAI F1 of binarized graphs for r=0.3 =  0.69463
Model XAI WIoU of binarized graphs for r=0.3 =  0.8281125
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.362
NEC for r=0.3 class 0 = 0.315 +- 0.217 (in-sample avg dev_std = 0.241)
NEC for r=0.3 class 1 = 0.196 +- 0.217 (in-sample avg dev_std = 0.241)
NEC for r=0.3 class 2 = 0.22 +- 0.217 (in-sample avg dev_std = 0.241)
NEC for r=0.3 all KL = 0.13 +- 0.217 (in-sample avg dev_std = 0.241)
NEC for r=0.3 all L1 = 0.243 +- 0.154 (in-sample avg dev_std = 0.241)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.566
Model XAI F1 of binarized graphs for r=0.6 =  0.5563075
Model XAI WIoU of binarized graphs for r=0.6 =  0.8949700000000002
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.457
NEC for r=0.6 class 0 = 0.424 +- 0.309 (in-sample avg dev_std = 0.365)
NEC for r=0.6 class 1 = 0.228 +- 0.309 (in-sample avg dev_std = 0.365)
NEC for r=0.6 class 2 = 0.353 +- 0.309 (in-sample avg dev_std = 0.365)
NEC for r=0.6 all KL = 0.287 +- 0.309 (in-sample avg dev_std = 0.365)
NEC for r=0.6 all L1 = 0.333 +- 0.200 (in-sample avg dev_std = 0.365)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.561
Model XAI F1 of binarized graphs for r=0.9 =  0.42330375000000003
Model XAI WIoU of binarized graphs for r=0.9 =  0.8809375
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.499
NEC for r=0.9 class 0 = 0.387 +- 0.322 (in-sample avg dev_std = 0.465)
NEC for r=0.9 class 1 = 0.323 +- 0.322 (in-sample avg dev_std = 0.465)
NEC for r=0.9 class 2 = 0.469 +- 0.322 (in-sample avg dev_std = 0.465)
NEC for r=0.9 all KL = 0.368 +- 0.322 (in-sample avg dev_std = 0.465)
NEC for r=0.9 all L1 = 0.393 +- 0.232 (in-sample avg dev_std = 0.465)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.641
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.8795725
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.482
NEC for r=1.0 class 0 = 0.373 +- 0.339 (in-sample avg dev_std = 0.469)
NEC for r=1.0 class 1 = 0.32 +- 0.339 (in-sample avg dev_std = 0.469)
NEC for r=1.0 class 2 = 0.504 +- 0.339 (in-sample avg dev_std = 0.469)
NEC for r=1.0 all KL = 0.395 +- 0.339 (in-sample avg dev_std = 0.469)
NEC for r=1.0 all L1 = 0.399 +- 0.241 (in-sample avg dev_std = 0.469)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 11:15:07 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:15:07 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 161...
[0m[1;37mINFO[0m: [1mCheckpoint 161: 
-----------------------------------
Train ACCURACY: 0.8127
Train Loss: 0.6933
ID Validation ACCURACY: 0.8250
ID Validation Loss: 0.6967
ID Test ACCURACY: 0.8160
ID Test Loss: 0.7190
OOD Validation ACCURACY: 0.7427
OOD Validation Loss: 0.7788
OOD Test ACCURACY: 0.6297
OOD Test Loss: 1.0397

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 143...
[0m[1;37mINFO[0m: [1mCheckpoint 143: 
-----------------------------------
Train ACCURACY: 0.6826
Train Loss: 0.8286
ID Validation ACCURACY: 0.6890
ID Validation Loss: 0.8200
ID Test ACCURACY: 0.6757
ID Test Loss: 0.8402
OOD Validation ACCURACY: 0.8280
OOD Validation Loss: 0.7303
OOD Test ACCURACY: 0.5997
OOD Test Loss: 1.3990

[0m[1;37mINFO[0m: [1mChartInfo 0.8160 0.6297 0.6757 0.5997 0.6890 0.8280[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.673
WIoU for r=0.3 = 0.696
F1 for r=0.6 = 0.610
WIoU for r=0.6 = 0.759
F1 for r=0.9 = 0.473
WIoU for r=0.9 = 0.761
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.761
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.594
WIoU for r=0.3 = 0.956
F1 for r=0.6 = 0.363
WIoU for r=0.6 = 0.956
F1 for r=0.9 = 0.270
WIoU for r=0.9 = 0.956
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.956
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.619
WIoU for r=0.3 = 0.751
F1 for r=0.6 = 0.517
WIoU for r=0.6 = 0.814
F1 for r=0.9 = 0.422
WIoU for r=0.9 = 0.827
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.827


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.59
Model XAI F1 of binarized graphs for r=0.3 =  0.67336375
Model XAI WIoU of binarized graphs for r=0.3 =  0.6956325
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.43
SUFF++ for r=0.3 class 0 = 0.656 +- 0.172 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.3 class 1 = 0.6 +- 0.172 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.3 class 2 = 0.716 +- 0.172 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.3 all KL = 0.805 +- 0.172 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.3 all L1 = 0.657 +- 0.133 (in-sample avg dev_std = 0.297)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.744
Model XAI F1 of binarized graphs for r=0.6 =  0.6102387499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.75902625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.576
SUFF++ for r=0.6 class 0 = 0.622 +- 0.230 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.6 class 1 = 0.697 +- 0.230 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.6 class 2 = 0.628 +- 0.230 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.6 all KL = 0.74 +- 0.230 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.6 all L1 = 0.649 +- 0.132 (in-sample avg dev_std = 0.360)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.811
Model XAI F1 of binarized graphs for r=0.9 =  0.47329375
Model XAI WIoU of binarized graphs for r=0.9 =  0.7607900000000001
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.732
SUFF++ for r=0.9 class 0 = 0.773 +- 0.183 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 class 1 = 0.831 +- 0.183 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 class 2 = 0.744 +- 0.183 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 all KL = 0.864 +- 0.183 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 all L1 = 0.783 +- 0.172 (in-sample avg dev_std = 0.271)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.683
Model XAI F1 of binarized graphs for r=0.3 =  0.59393125
Model XAI WIoU of binarized graphs for r=0.3 =  0.95625375
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.393
SUFF++ for r=0.3 class 0 = 0.53 +- 0.294 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.3 class 1 = 0.543 +- 0.294 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.3 class 2 = 0.65 +- 0.294 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.3 all KL = 0.671 +- 0.294 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.3 all L1 = 0.575 +- 0.167 (in-sample avg dev_std = 0.242)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.724
Model XAI F1 of binarized graphs for r=0.6 =  0.36283874999999993
Model XAI WIoU of binarized graphs for r=0.6 =  0.95625375
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.527
SUFF++ for r=0.6 class 0 = 0.678 +- 0.239 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.6 class 1 = 0.664 +- 0.239 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.6 class 2 = 0.667 +- 0.239 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.6 all KL = 0.749 +- 0.239 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.6 all L1 = 0.67 +- 0.127 (in-sample avg dev_std = 0.355)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.733
Model XAI F1 of binarized graphs for r=0.9 =  0.27000875
Model XAI WIoU of binarized graphs for r=0.9 =  0.95625375
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.701
SUFF++ for r=0.9 class 0 = 0.866 +- 0.136 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.9 class 1 = 0.918 +- 0.136 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.9 class 2 = 0.837 +- 0.136 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.9 all KL = 0.934 +- 0.136 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.9 all L1 = 0.873 +- 0.123 (in-sample avg dev_std = 0.234)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.744
Model XAI F1 of binarized graphs for r=0.3 =  0.61897125
Model XAI WIoU of binarized graphs for r=0.3 =  0.7514687499999999
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.496
SUFF++ for r=0.3 class 0 = 0.588 +- 0.197 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.3 class 1 = 0.582 +- 0.197 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.3 class 2 = 0.696 +- 0.197 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.3 all KL = 0.741 +- 0.197 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.3 all L1 = 0.622 +- 0.136 (in-sample avg dev_std = 0.354)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.717
Model XAI F1 of binarized graphs for r=0.6 =  0.5169725
Model XAI WIoU of binarized graphs for r=0.6 =  0.8141849999999999
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.589
SUFF++ for r=0.6 class 0 = 0.625 +- 0.241 (in-sample avg dev_std = 0.410)
SUFF++ for r=0.6 class 1 = 0.669 +- 0.241 (in-sample avg dev_std = 0.410)
SUFF++ for r=0.6 class 2 = 0.637 +- 0.241 (in-sample avg dev_std = 0.410)
SUFF++ for r=0.6 all KL = 0.717 +- 0.241 (in-sample avg dev_std = 0.410)
SUFF++ for r=0.6 all L1 = 0.644 +- 0.134 (in-sample avg dev_std = 0.410)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.634
Model XAI F1 of binarized graphs for r=0.9 =  0.42243749999999997
Model XAI WIoU of binarized graphs for r=0.9 =  0.8266850000000001
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.548
SUFF++ for r=0.9 class 0 = 0.727 +- 0.334 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.9 class 1 = 0.709 +- 0.334 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.9 class 2 = 0.666 +- 0.334 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.9 all KL = 0.697 +- 0.334 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.9 all L1 = 0.7 +- 0.245 (in-sample avg dev_std = 0.388)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.586
Model XAI F1 of binarized graphs for r=0.3 =  0.67336375
Model XAI WIoU of binarized graphs for r=0.3 =  0.6956325
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.39
NEC for r=0.3 class 0 = 0.414 +- 0.218 (in-sample avg dev_std = 0.223)
NEC for r=0.3 class 1 = 0.43 +- 0.218 (in-sample avg dev_std = 0.223)
NEC for r=0.3 class 2 = 0.364 +- 0.218 (in-sample avg dev_std = 0.223)
NEC for r=0.3 all KL = 0.255 +- 0.218 (in-sample avg dev_std = 0.223)
NEC for r=0.3 all L1 = 0.403 +- 0.168 (in-sample avg dev_std = 0.223)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.741
Model XAI F1 of binarized graphs for r=0.6 =  0.6102387499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.75902625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.438
NEC for r=0.6 class 0 = 0.424 +- 0.292 (in-sample avg dev_std = 0.318)
NEC for r=0.6 class 1 = 0.37 +- 0.292 (in-sample avg dev_std = 0.318)
NEC for r=0.6 class 2 = 0.432 +- 0.292 (in-sample avg dev_std = 0.318)
NEC for r=0.6 all KL = 0.313 +- 0.292 (in-sample avg dev_std = 0.318)
NEC for r=0.6 all L1 = 0.409 +- 0.156 (in-sample avg dev_std = 0.318)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.81
Model XAI F1 of binarized graphs for r=0.9 =  0.47329375
Model XAI WIoU of binarized graphs for r=0.9 =  0.7607900000000001
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.474
NEC for r=0.9 class 0 = 0.43 +- 0.279 (in-sample avg dev_std = 0.357)
NEC for r=0.9 class 1 = 0.328 +- 0.279 (in-sample avg dev_std = 0.357)
NEC for r=0.9 class 2 = 0.458 +- 0.279 (in-sample avg dev_std = 0.357)
NEC for r=0.9 all KL = 0.321 +- 0.279 (in-sample avg dev_std = 0.357)
NEC for r=0.9 all L1 = 0.405 +- 0.161 (in-sample avg dev_std = 0.357)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.826
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.7607900000000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.477
NEC for r=1.0 class 0 = 0.414 +- 0.295 (in-sample avg dev_std = 0.351)
NEC for r=1.0 class 1 = 0.314 +- 0.295 (in-sample avg dev_std = 0.351)
NEC for r=1.0 class 2 = 0.471 +- 0.295 (in-sample avg dev_std = 0.351)
NEC for r=1.0 all KL = 0.328 +- 0.295 (in-sample avg dev_std = 0.351)
NEC for r=1.0 all L1 = 0.399 +- 0.172 (in-sample avg dev_std = 0.351)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.68
Model XAI F1 of binarized graphs for r=0.3 =  0.59393125
Model XAI WIoU of binarized graphs for r=0.3 =  0.95625375
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.344
NEC for r=0.3 class 0 = 0.472 +- 0.306 (in-sample avg dev_std = 0.228)
NEC for r=0.3 class 1 = 0.436 +- 0.306 (in-sample avg dev_std = 0.228)
NEC for r=0.3 class 2 = 0.408 +- 0.306 (in-sample avg dev_std = 0.228)
NEC for r=0.3 all KL = 0.346 +- 0.306 (in-sample avg dev_std = 0.228)
NEC for r=0.3 all L1 = 0.439 +- 0.171 (in-sample avg dev_std = 0.228)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.724
Model XAI F1 of binarized graphs for r=0.6 =  0.36283874999999993
Model XAI WIoU of binarized graphs for r=0.6 =  0.95625375
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.409
NEC for r=0.6 class 0 = 0.424 +- 0.282 (in-sample avg dev_std = 0.349)
NEC for r=0.6 class 1 = 0.396 +- 0.282 (in-sample avg dev_std = 0.349)
NEC for r=0.6 class 2 = 0.483 +- 0.282 (in-sample avg dev_std = 0.349)
NEC for r=0.6 all KL = 0.345 +- 0.282 (in-sample avg dev_std = 0.349)
NEC for r=0.6 all L1 = 0.435 +- 0.137 (in-sample avg dev_std = 0.349)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.733
Model XAI F1 of binarized graphs for r=0.9 =  0.27000875
Model XAI WIoU of binarized graphs for r=0.9 =  0.95625375
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.447
NEC for r=0.9 class 0 = 0.369 +- 0.215 (in-sample avg dev_std = 0.385)
NEC for r=0.9 class 1 = 0.357 +- 0.215 (in-sample avg dev_std = 0.385)
NEC for r=0.9 class 2 = 0.446 +- 0.215 (in-sample avg dev_std = 0.385)
NEC for r=0.9 all KL = 0.268 +- 0.215 (in-sample avg dev_std = 0.385)
NEC for r=0.9 all L1 = 0.391 +- 0.132 (in-sample avg dev_std = 0.385)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.736
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.95625375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.453
NEC for r=1.0 class 0 = 0.349 +- 0.196 (in-sample avg dev_std = 0.383)
NEC for r=1.0 class 1 = 0.344 +- 0.196 (in-sample avg dev_std = 0.383)
NEC for r=1.0 class 2 = 0.431 +- 0.196 (in-sample avg dev_std = 0.383)
NEC for r=1.0 all KL = 0.245 +- 0.196 (in-sample avg dev_std = 0.383)
NEC for r=1.0 all L1 = 0.375 +- 0.126 (in-sample avg dev_std = 0.383)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.744
Model XAI F1 of binarized graphs for r=0.3 =  0.61897125
Model XAI WIoU of binarized graphs for r=0.3 =  0.7514687499999999
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.429
NEC for r=0.3 class 0 = 0.582 +- 0.267 (in-sample avg dev_std = 0.282)
NEC for r=0.3 class 1 = 0.465 +- 0.267 (in-sample avg dev_std = 0.282)
NEC for r=0.3 class 2 = 0.485 +- 0.267 (in-sample avg dev_std = 0.282)
NEC for r=0.3 all KL = 0.427 +- 0.267 (in-sample avg dev_std = 0.282)
NEC for r=0.3 all L1 = 0.51 +- 0.162 (in-sample avg dev_std = 0.282)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.717
Model XAI F1 of binarized graphs for r=0.6 =  0.5169725
Model XAI WIoU of binarized graphs for r=0.6 =  0.8141849999999999
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.492
NEC for r=0.6 class 0 = 0.451 +- 0.308 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 1 = 0.308 +- 0.308 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 2 = 0.42 +- 0.308 (in-sample avg dev_std = 0.354)
NEC for r=0.6 all KL = 0.335 +- 0.308 (in-sample avg dev_std = 0.354)
NEC for r=0.6 all L1 = 0.392 +- 0.180 (in-sample avg dev_std = 0.354)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.634
Model XAI F1 of binarized graphs for r=0.9 =  0.42243749999999997
Model XAI WIoU of binarized graphs for r=0.9 =  0.8266850000000001
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.522
NEC for r=0.9 class 0 = 0.433 +- 0.333 (in-sample avg dev_std = 0.372)
NEC for r=0.9 class 1 = 0.317 +- 0.333 (in-sample avg dev_std = 0.372)
NEC for r=0.9 class 2 = 0.528 +- 0.333 (in-sample avg dev_std = 0.372)
NEC for r=0.9 all KL = 0.403 +- 0.333 (in-sample avg dev_std = 0.372)
NEC for r=0.9 all L1 = 0.425 +- 0.220 (in-sample avg dev_std = 0.372)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.63
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.8266850000000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.501
NEC for r=1.0 class 0 = 0.415 +- 0.314 (in-sample avg dev_std = 0.404)
NEC for r=1.0 class 1 = 0.314 +- 0.314 (in-sample avg dev_std = 0.404)
NEC for r=1.0 class 2 = 0.532 +- 0.314 (in-sample avg dev_std = 0.404)
NEC for r=1.0 all KL = 0.381 +- 0.314 (in-sample avg dev_std = 0.404)
NEC for r=1.0 all L1 = 0.419 +- 0.220 (in-sample avg dev_std = 0.404)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 11:18:43 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 04/22/2024 11:18:43 AM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/22/2024 11:18:43 AM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 11:18:43 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:18:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:18:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:18:44 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:18:44 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:18:44 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:18:44 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:18:44 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:18:44 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:18:44 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:18:44 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:18:44 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:18:44 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:18:44 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:18:44 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:18:44 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:18:44 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:18:44 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:18:44 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:18:44 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:18:44 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:18:44 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:18:44 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:18:44 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:18:44 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:18:44 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:18:44 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:18:44 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:18:44 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:18:44 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:18:44 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:18:44 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:18:44 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:18:44 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:18:44 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:18:44 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 102...
[0m[1;37mINFO[0m: [1mCheckpoint 102: 
-----------------------------------
Train ACCURACY: 0.3367
Train Loss: 1.0986
ID Validation ACCURACY: 0.3363
ID Validation Loss: 1.0987
ID Test ACCURACY: 0.3243
ID Test Loss: 1.0988
OOD Validation ACCURACY: 0.3260
OOD Validation Loss: 1.0989
OOD Test ACCURACY: 0.3420
OOD Test Loss: 1.0984

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 100...
[0m[1;37mINFO[0m: [1mCheckpoint 100: 
-----------------------------------
Train ACCURACY: 0.3342
Train Loss: 1.0986
ID Validation ACCURACY: 0.3297
ID Validation Loss: 1.0987
ID Test ACCURACY: 0.3463
ID Test Loss: 1.0985
OOD Validation ACCURACY: 0.3377
OOD Validation Loss: 1.0987
OOD Test ACCURACY: 0.3343
OOD Test Loss: 1.0985

[0m[1;37mINFO[0m: [1mChartInfo 0.3243 0.3420 0.3463 0.3343 0.3297 0.3377[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.392
WIoU for r=0.3 = 0.049
F1 for r=0.6 = 0.390
WIoU for r=0.6 = 0.052
F1 for r=0.9 = 0.425
WIoU for r=0.9 = 0.053
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.053
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.221
WIoU for r=0.3 = 0.051
F1 for r=0.6 = 0.164
WIoU for r=0.6 = 0.051
F1 for r=0.9 = 0.182
WIoU for r=0.9 = 0.050
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.050
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.480
WIoU for r=0.3 = 0.049
F1 for r=0.6 = 0.341
WIoU for r=0.6 = 0.055
F1 for r=0.9 = 0.375
WIoU for r=0.9 = 0.056
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.056


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.336
Model XAI F1 of binarized graphs for r=0.3 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=0.3 =  0.048735
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.336
SUFF++ for r=0.3 class 0 = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)
SUFF++ for r=0.3 class 1 = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)
SUFF++ for r=0.3 class 2 = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)
SUFF++ for r=0.3 all KL = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)
SUFF++ for r=0.3 all L1 = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.336
Model XAI F1 of binarized graphs for r=0.6 =  0.3897324999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.052309999999999995
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.336
SUFF++ for r=0.6 class 0 = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)
SUFF++ for r=0.6 class 1 = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)
SUFF++ for r=0.6 class 2 = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)
SUFF++ for r=0.6 all KL = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)
SUFF++ for r=0.6 all L1 = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.336
Model XAI F1 of binarized graphs for r=0.9 =  0.42482125000000004
Model XAI WIoU of binarized graphs for r=0.9 =  0.05264875
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.336
SUFF++ for r=0.9 class 0 = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)
SUFF++ for r=0.9 class 1 = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)
SUFF++ for r=0.9 class 2 = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)
SUFF++ for r=0.9 all KL = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)
SUFF++ for r=0.9 all L1 = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.326
Model XAI F1 of binarized graphs for r=0.3 =  0.22120499999999998
Model XAI WIoU of binarized graphs for r=0.3 =  0.05051
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.326
SUFF++ for r=0.3 class 0 = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)
SUFF++ for r=0.3 class 1 = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)
SUFF++ for r=0.3 class 2 = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)
SUFF++ for r=0.3 all KL = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)
SUFF++ for r=0.3 all L1 = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.326
Model XAI F1 of binarized graphs for r=0.6 =  0.1635225
Model XAI WIoU of binarized graphs for r=0.6 =  0.05064
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.326
SUFF++ for r=0.6 class 0 = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)
SUFF++ for r=0.6 class 1 = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)
SUFF++ for r=0.6 class 2 = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)
SUFF++ for r=0.6 all KL = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)
SUFF++ for r=0.6 all L1 = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.326
Model XAI F1 of binarized graphs for r=0.9 =  0.18247999999999998
Model XAI WIoU of binarized graphs for r=0.9 =  0.05040375000000001
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.326
SUFF++ for r=0.9 class 0 = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)
SUFF++ for r=0.9 class 1 = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)
SUFF++ for r=0.9 class 2 = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)
SUFF++ for r=0.9 all KL = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)
SUFF++ for r=0.9 all L1 = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.343
Model XAI F1 of binarized graphs for r=0.3 =  0.47992250000000003
Model XAI WIoU of binarized graphs for r=0.3 =  0.048870000000000004
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.343
SUFF++ for r=0.3 class 0 = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)
SUFF++ for r=0.3 class 1 = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)
SUFF++ for r=0.3 class 2 = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)
SUFF++ for r=0.3 all KL = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)
SUFF++ for r=0.3 all L1 = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.343
Model XAI F1 of binarized graphs for r=0.6 =  0.34120375
Model XAI WIoU of binarized graphs for r=0.6 =  0.055226250000000005
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.343
SUFF++ for r=0.6 class 0 = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)
SUFF++ for r=0.6 class 1 = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)
SUFF++ for r=0.6 class 2 = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)
SUFF++ for r=0.6 all KL = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)
SUFF++ for r=0.6 all L1 = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.343
Model XAI F1 of binarized graphs for r=0.9 =  0.3746025
Model XAI WIoU of binarized graphs for r=0.9 =  0.055953750000000003
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.343
SUFF++ for r=0.9 class 0 = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)
SUFF++ for r=0.9 class 1 = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)
SUFF++ for r=0.9 class 2 = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)
SUFF++ for r=0.9 all KL = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)
SUFF++ for r=0.9 all L1 = 1.0 +- 0.000 (in-sample avg dev_std = 0.000)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.336
Model XAI F1 of binarized graphs for r=0.3 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=0.3 =  0.048735
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.336
NEC for r=0.3 class 0 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=0.3 class 1 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=0.3 class 2 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=0.3 all KL = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=0.3 all L1 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.336
Model XAI F1 of binarized graphs for r=0.6 =  0.3897324999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.052309999999999995
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.336
NEC for r=0.6 class 0 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=0.6 class 1 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=0.6 class 2 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=0.6 all KL = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=0.6 all L1 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.336
Model XAI F1 of binarized graphs for r=0.9 =  0.42482125000000004
Model XAI WIoU of binarized graphs for r=0.9 =  0.05264875
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.336
NEC for r=0.9 class 0 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=0.9 class 1 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=0.9 class 2 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=0.9 all KL = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=0.9 all L1 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.336
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.052693750000000004
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.336
NEC for r=1.0 class 0 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=1.0 class 1 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=1.0 class 2 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=1.0 all KL = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=1.0 all L1 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.326
Model XAI F1 of binarized graphs for r=0.3 =  0.22120499999999998
Model XAI WIoU of binarized graphs for r=0.3 =  0.05051
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.326
NEC for r=0.3 class 0 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=0.3 class 1 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=0.3 class 2 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=0.3 all KL = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=0.3 all L1 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.326
Model XAI F1 of binarized graphs for r=0.6 =  0.1635225
Model XAI WIoU of binarized graphs for r=0.6 =  0.05064
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.326
NEC for r=0.6 class 0 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=0.6 class 1 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=0.6 class 2 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=0.6 all KL = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=0.6 all L1 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.326
Model XAI F1 of binarized graphs for r=0.9 =  0.18247999999999998
Model XAI WIoU of binarized graphs for r=0.9 =  0.05040375000000001
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.326
NEC for r=0.9 class 0 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=0.9 class 1 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=0.9 class 2 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=0.9 all KL = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=0.9 all L1 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.326
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.0504075
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.326
NEC for r=1.0 class 0 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=1.0 class 1 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=1.0 class 2 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=1.0 all KL = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=1.0 all L1 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.343
Model XAI F1 of binarized graphs for r=0.3 =  0.47992250000000003
Model XAI WIoU of binarized graphs for r=0.3 =  0.048870000000000004
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.343
NEC for r=0.3 class 0 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=0.3 class 1 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=0.3 class 2 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=0.3 all KL = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=0.3 all L1 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.343
Model XAI F1 of binarized graphs for r=0.6 =  0.34120375
Model XAI WIoU of binarized graphs for r=0.6 =  0.055226250000000005
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.343
NEC for r=0.6 class 0 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=0.6 class 1 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=0.6 class 2 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=0.6 all KL = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=0.6 all L1 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.343
Model XAI F1 of binarized graphs for r=0.9 =  0.3746025
Model XAI WIoU of binarized graphs for r=0.9 =  0.055953750000000003
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.343
NEC for r=0.9 class 0 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=0.9 class 1 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=0.9 class 2 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=0.9 all KL = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=0.9 all L1 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.343
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.055953750000000003
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.343
NEC for r=1.0 class 0 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=1.0 class 1 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=1.0 class 2 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=1.0 all KL = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)
NEC for r=1.0 all L1 = 0.0 +- 0.000 (in-sample avg dev_std = 0.000)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 11:22:29 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:22:29 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 128...
[0m[1;37mINFO[0m: [1mCheckpoint 128: 
-----------------------------------
Train ACCURACY: 0.6311
Train Loss: 0.6945
ID Validation ACCURACY: 0.6333
ID Validation Loss: 0.6755
ID Test ACCURACY: 0.6243
ID Test Loss: 0.7142
OOD Validation ACCURACY: 0.6210
OOD Validation Loss: 0.7191
OOD Test ACCURACY: 0.4067
OOD Test Loss: 6.9348

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 128...
[0m[1;37mINFO[0m: [1mCheckpoint 128: 
-----------------------------------
Train ACCURACY: 0.6311
Train Loss: 0.6945
ID Validation ACCURACY: 0.6333
ID Validation Loss: 0.6755
ID Test ACCURACY: 0.6243
ID Test Loss: 0.7142
OOD Validation ACCURACY: 0.6210
OOD Validation Loss: 0.7191
OOD Test ACCURACY: 0.4067
OOD Test Loss: 6.9348

[0m[1;37mINFO[0m: [1mChartInfo 0.6243 0.4067 0.6243 0.4067 0.6333 0.6210[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.512
WIoU for r=0.3 = 0.345
F1 for r=0.6 = 0.494
WIoU for r=0.6 = 0.352
F1 for r=0.9 = 0.449
WIoU for r=0.9 = 0.352
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.352
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.233
WIoU for r=0.3 = 0.271
F1 for r=0.6 = 0.189
WIoU for r=0.6 = 0.270
F1 for r=0.9 = 0.233
WIoU for r=0.9 = 0.270
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.270
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.061
WIoU for r=0.3 = 0.077
F1 for r=0.6 = 0.096
WIoU for r=0.6 = 0.086
F1 for r=0.9 = 0.296
WIoU for r=0.9 = 0.096
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.100


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.632
Model XAI F1 of binarized graphs for r=0.3 =  0.5119787499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.34512
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.481
SUFF++ for r=0.3 class 0 = 0.474 +- 0.329 (in-sample avg dev_std = 0.682)
SUFF++ for r=0.3 class 1 = 0.892 +- 0.329 (in-sample avg dev_std = 0.682)
SUFF++ for r=0.3 class 2 = 0.492 +- 0.329 (in-sample avg dev_std = 0.682)
SUFF++ for r=0.3 all KL = 0.551 +- 0.329 (in-sample avg dev_std = 0.682)
SUFF++ for r=0.3 all L1 = 0.62 +- 0.284 (in-sample avg dev_std = 0.682)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.631
Model XAI F1 of binarized graphs for r=0.6 =  0.49392374999999994
Model XAI WIoU of binarized graphs for r=0.6 =  0.35191625000000004
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.52
SUFF++ for r=0.6 class 0 = 0.569 +- 0.297 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.6 class 1 = 0.868 +- 0.297 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.6 class 2 = 0.593 +- 0.297 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.6 all KL = 0.638 +- 0.297 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.6 all L1 = 0.678 +- 0.263 (in-sample avg dev_std = 0.586)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.63
Model XAI F1 of binarized graphs for r=0.9 =  0.44891625000000007
Model XAI WIoU of binarized graphs for r=0.9 =  0.35191500000000003
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.597
SUFF++ for r=0.9 class 0 = 0.814 +- 0.191 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.9 class 1 = 0.9 +- 0.191 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.9 class 2 = 0.866 +- 0.191 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.9 all KL = 0.873 +- 0.191 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.9 all L1 = 0.86 +- 0.173 (in-sample avg dev_std = 0.367)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.611
Model XAI F1 of binarized graphs for r=0.3 =  0.2333325
Model XAI WIoU of binarized graphs for r=0.3 =  0.2710725
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.516
SUFF++ for r=0.3 class 0 = 0.568 +- 0.284 (in-sample avg dev_std = 0.668)
SUFF++ for r=0.3 class 1 = 0.912 +- 0.284 (in-sample avg dev_std = 0.668)
SUFF++ for r=0.3 class 2 = 0.606 +- 0.284 (in-sample avg dev_std = 0.668)
SUFF++ for r=0.3 all KL = 0.627 +- 0.284 (in-sample avg dev_std = 0.668)
SUFF++ for r=0.3 all L1 = 0.693 +- 0.246 (in-sample avg dev_std = 0.668)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.611
Model XAI F1 of binarized graphs for r=0.6 =  0.18949875
Model XAI WIoU of binarized graphs for r=0.6 =  0.26969375
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.511
SUFF++ for r=0.6 class 0 = 0.541 +- 0.264 (in-sample avg dev_std = 0.634)
SUFF++ for r=0.6 class 1 = 0.829 +- 0.264 (in-sample avg dev_std = 0.634)
SUFF++ for r=0.6 class 2 = 0.611 +- 0.264 (in-sample avg dev_std = 0.634)
SUFF++ for r=0.6 all KL = 0.632 +- 0.264 (in-sample avg dev_std = 0.634)
SUFF++ for r=0.6 all L1 = 0.659 +- 0.224 (in-sample avg dev_std = 0.634)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.61
Model XAI F1 of binarized graphs for r=0.9 =  0.23322375
Model XAI WIoU of binarized graphs for r=0.9 =  0.2697125
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.554
SUFF++ for r=0.9 class 0 = 0.72 +- 0.204 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.9 class 1 = 0.819 +- 0.204 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.9 class 2 = 0.795 +- 0.204 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.9 all KL = 0.812 +- 0.204 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.9 all L1 = 0.778 +- 0.184 (in-sample avg dev_std = 0.432)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.411
Model XAI F1 of binarized graphs for r=0.3 =  0.06060000000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.07689250000000002
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.367
SUFF++ for r=0.3 class 0 = 0.808 +- 0.298 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.3 class 1 = 0.951 +- 0.298 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.3 class 2 = 0.816 +- 0.298 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.3 all KL = 0.798 +- 0.298 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.3 all L1 = 0.86 +- 0.238 (in-sample avg dev_std = 0.330)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.411
Model XAI F1 of binarized graphs for r=0.6 =  0.09642875000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.08613624999999998
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.357
SUFF++ for r=0.6 class 0 = 0.839 +- 0.219 (in-sample avg dev_std = 0.286)
SUFF++ for r=0.6 class 1 = 0.964 +- 0.219 (in-sample avg dev_std = 0.286)
SUFF++ for r=0.6 class 2 = 0.873 +- 0.219 (in-sample avg dev_std = 0.286)
SUFF++ for r=0.6 all KL = 0.892 +- 0.219 (in-sample avg dev_std = 0.286)
SUFF++ for r=0.6 all L1 = 0.893 +- 0.225 (in-sample avg dev_std = 0.286)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.411
Model XAI F1 of binarized graphs for r=0.9 =  0.295515
Model XAI WIoU of binarized graphs for r=0.9 =  0.09583000000000003
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.344
SUFF++ for r=0.9 class 0 = 0.962 +- 0.178 (in-sample avg dev_std = 0.180)
SUFF++ for r=0.9 class 1 = 0.98 +- 0.178 (in-sample avg dev_std = 0.180)
SUFF++ for r=0.9 class 2 = 0.852 +- 0.178 (in-sample avg dev_std = 0.180)
SUFF++ for r=0.9 all KL = 0.94 +- 0.178 (in-sample avg dev_std = 0.180)
SUFF++ for r=0.9 all L1 = 0.931 +- 0.187 (in-sample avg dev_std = 0.180)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.632
Model XAI F1 of binarized graphs for r=0.3 =  0.5119787499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.34512
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.326
NEC for r=0.3 class 0 = 0.299 +- 0.372 (in-sample avg dev_std = 0.652)
NEC for r=0.3 class 1 = 0.699 +- 0.372 (in-sample avg dev_std = 0.652)
NEC for r=0.3 class 2 = 0.309 +- 0.372 (in-sample avg dev_std = 0.652)
NEC for r=0.3 all KL = 0.545 +- 0.372 (in-sample avg dev_std = 0.652)
NEC for r=0.3 all L1 = 0.437 +- 0.284 (in-sample avg dev_std = 0.652)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.631
Model XAI F1 of binarized graphs for r=0.6 =  0.49392374999999994
Model XAI WIoU of binarized graphs for r=0.6 =  0.35191625000000004
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.417
NEC for r=0.6 class 0 = 0.31 +- 0.333 (in-sample avg dev_std = 0.693)
NEC for r=0.6 class 1 = 0.564 +- 0.333 (in-sample avg dev_std = 0.693)
NEC for r=0.6 class 2 = 0.276 +- 0.333 (in-sample avg dev_std = 0.693)
NEC for r=0.6 all KL = 0.481 +- 0.333 (in-sample avg dev_std = 0.693)
NEC for r=0.6 all L1 = 0.384 +- 0.238 (in-sample avg dev_std = 0.693)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.63
Model XAI F1 of binarized graphs for r=0.9 =  0.44891625000000007
Model XAI WIoU of binarized graphs for r=0.9 =  0.35191500000000003
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.434
NEC for r=0.9 class 0 = 0.295 +- 0.293 (in-sample avg dev_std = 0.631)
NEC for r=0.9 class 1 = 0.503 +- 0.293 (in-sample avg dev_std = 0.631)
NEC for r=0.9 class 2 = 0.269 +- 0.293 (in-sample avg dev_std = 0.631)
NEC for r=0.9 all KL = 0.395 +- 0.293 (in-sample avg dev_std = 0.631)
NEC for r=0.9 all L1 = 0.356 +- 0.216 (in-sample avg dev_std = 0.631)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.63
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.35191500000000003
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.448
NEC for r=1.0 class 0 = 0.281 +- 0.276 (in-sample avg dev_std = 0.608)
NEC for r=1.0 class 1 = 0.475 +- 0.276 (in-sample avg dev_std = 0.608)
NEC for r=1.0 class 2 = 0.248 +- 0.276 (in-sample avg dev_std = 0.608)
NEC for r=1.0 all KL = 0.356 +- 0.276 (in-sample avg dev_std = 0.608)
NEC for r=1.0 all L1 = 0.336 +- 0.212 (in-sample avg dev_std = 0.608)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.611
Model XAI F1 of binarized graphs for r=0.3 =  0.2333325
Model XAI WIoU of binarized graphs for r=0.3 =  0.2710725
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.376
NEC for r=0.3 class 0 = 0.285 +- 0.361 (in-sample avg dev_std = 0.713)
NEC for r=0.3 class 1 = 0.627 +- 0.361 (in-sample avg dev_std = 0.713)
NEC for r=0.3 class 2 = 0.297 +- 0.361 (in-sample avg dev_std = 0.713)
NEC for r=0.3 all KL = 0.522 +- 0.361 (in-sample avg dev_std = 0.713)
NEC for r=0.3 all L1 = 0.4 +- 0.258 (in-sample avg dev_std = 0.713)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.611
Model XAI F1 of binarized graphs for r=0.6 =  0.18949875
Model XAI WIoU of binarized graphs for r=0.6 =  0.26969375
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.455
NEC for r=0.6 class 0 = 0.2 +- 0.315 (in-sample avg dev_std = 0.600)
NEC for r=0.6 class 1 = 0.497 +- 0.315 (in-sample avg dev_std = 0.600)
NEC for r=0.6 class 2 = 0.198 +- 0.315 (in-sample avg dev_std = 0.600)
NEC for r=0.6 all KL = 0.349 +- 0.315 (in-sample avg dev_std = 0.600)
NEC for r=0.6 all L1 = 0.296 +- 0.229 (in-sample avg dev_std = 0.600)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.61
Model XAI F1 of binarized graphs for r=0.9 =  0.23322375
Model XAI WIoU of binarized graphs for r=0.9 =  0.2697125
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.495
NEC for r=0.9 class 0 = 0.167 +- 0.238 (in-sample avg dev_std = 0.497)
NEC for r=0.9 class 1 = 0.432 +- 0.238 (in-sample avg dev_std = 0.497)
NEC for r=0.9 class 2 = 0.156 +- 0.238 (in-sample avg dev_std = 0.497)
NEC for r=0.9 all KL = 0.239 +- 0.238 (in-sample avg dev_std = 0.497)
NEC for r=0.9 all L1 = 0.25 +- 0.197 (in-sample avg dev_std = 0.497)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.61
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.26971749999999994
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.501
NEC for r=1.0 class 0 = 0.201 +- 0.216 (in-sample avg dev_std = 0.490)
NEC for r=1.0 class 1 = 0.408 +- 0.216 (in-sample avg dev_std = 0.490)
NEC for r=1.0 class 2 = 0.153 +- 0.216 (in-sample avg dev_std = 0.490)
NEC for r=1.0 all KL = 0.229 +- 0.216 (in-sample avg dev_std = 0.490)
NEC for r=1.0 all L1 = 0.252 +- 0.184 (in-sample avg dev_std = 0.490)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.411
Model XAI F1 of binarized graphs for r=0.3 =  0.06060000000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.07689250000000002
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.404
NEC for r=0.3 class 0 = 0.277 +- 0.406 (in-sample avg dev_std = 0.231)
NEC for r=0.3 class 1 = 0.181 +- 0.406 (in-sample avg dev_std = 0.231)
NEC for r=0.3 class 2 = 0.311 +- 0.406 (in-sample avg dev_std = 0.231)
NEC for r=0.3 all KL = 0.271 +- 0.406 (in-sample avg dev_std = 0.231)
NEC for r=0.3 all L1 = 0.256 +- 0.346 (in-sample avg dev_std = 0.231)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.411
Model XAI F1 of binarized graphs for r=0.6 =  0.09642875000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.08613624999999998
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.404
NEC for r=0.6 class 0 = 0.244 +- 0.414 (in-sample avg dev_std = 0.458)
NEC for r=0.6 class 1 = 0.215 +- 0.414 (in-sample avg dev_std = 0.458)
NEC for r=0.6 class 2 = 0.262 +- 0.414 (in-sample avg dev_std = 0.458)
NEC for r=0.6 all KL = 0.302 +- 0.414 (in-sample avg dev_std = 0.458)
NEC for r=0.6 all L1 = 0.24 +- 0.305 (in-sample avg dev_std = 0.458)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.411
Model XAI F1 of binarized graphs for r=0.9 =  0.295515
Model XAI WIoU of binarized graphs for r=0.9 =  0.09583000000000003
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.405
NEC for r=0.9 class 0 = 0.218 +- 0.368 (in-sample avg dev_std = 0.485)
NEC for r=0.9 class 1 = 0.128 +- 0.368 (in-sample avg dev_std = 0.485)
NEC for r=0.9 class 2 = 0.202 +- 0.368 (in-sample avg dev_std = 0.485)
NEC for r=0.9 all KL = 0.262 +- 0.368 (in-sample avg dev_std = 0.485)
NEC for r=0.9 all L1 = 0.182 +- 0.241 (in-sample avg dev_std = 0.485)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.411
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.0997875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.402
NEC for r=1.0 class 0 = 0.203 +- 0.368 (in-sample avg dev_std = 0.482)
NEC for r=1.0 class 1 = 0.125 +- 0.368 (in-sample avg dev_std = 0.482)
NEC for r=1.0 class 2 = 0.223 +- 0.368 (in-sample avg dev_std = 0.482)
NEC for r=1.0 all KL = 0.262 +- 0.368 (in-sample avg dev_std = 0.482)
NEC for r=1.0 all L1 = 0.183 +- 0.242 (in-sample avg dev_std = 0.482)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.914, 0.837, 0.872, 1.0], 'all_L1': [0.806, 0.724, 0.748, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.9, 0.711, 0.819, 1.0], 'all_L1': [0.792, 0.634, 0.759, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.805, 0.74, 0.864, 1.0], 'all_L1': [0.657, 0.649, 0.783, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [1.0, 1.0, 1.0, 1.0], 'all_L1': [1.0, 1.0, 1.0, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.551, 0.638, 0.873, 1.0], 'all_L1': [0.62, 0.678, 0.86, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.093, 0.177, 0.208, 0.248], 'all_L1': [0.21, 0.289, 0.324, 0.343]}), defaultdict(<class 'list'>, {'all_KL': [0.108, 0.262, 0.298, 0.352], 'all_L1': [0.239, 0.357, 0.377, 0.41]}), defaultdict(<class 'list'>, {'all_KL': [0.255, 0.313, 0.321, 0.328], 'all_L1': [0.403, 0.409, 0.405, 0.399]}), defaultdict(<class 'list'>, {'all_KL': [0.0, 0.0, 0.0, 0.0], 'all_L1': [0.0, 0.0, 0.0, 0.0]}), defaultdict(<class 'list'>, {'all_KL': [0.545, 0.481, 0.395, 0.356], 'all_L1': [0.437, 0.384, 0.356, 0.336]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.746, 0.815, 0.941, 1.0], 'all_L1': [0.676, 0.68, 0.825, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.665, 0.625, 0.843, 1.0], 'all_L1': [0.611, 0.582, 0.761, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.671, 0.749, 0.934, 1.0], 'all_L1': [0.575, 0.67, 0.873, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [1.0, 1.0, 1.0, 1.0], 'all_L1': [1.0, 1.0, 1.0, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.627, 0.632, 0.812, 1.0], 'all_L1': [0.693, 0.659, 0.778, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.261, 0.219, 0.171, 0.167], 'all_L1': [0.341, 0.352, 0.345, 0.346]}), defaultdict(<class 'list'>, {'all_KL': [0.333, 0.424, 0.306, 0.287], 'all_L1': [0.402, 0.469, 0.41, 0.404]}), defaultdict(<class 'list'>, {'all_KL': [0.346, 0.345, 0.268, 0.245], 'all_L1': [0.439, 0.435, 0.391, 0.375]}), defaultdict(<class 'list'>, {'all_KL': [0.0, 0.0, 0.0, 0.0], 'all_L1': [0.0, 0.0, 0.0, 0.0]}), defaultdict(<class 'list'>, {'all_KL': [0.522, 0.349, 0.239, 0.229], 'all_L1': [0.4, 0.296, 0.25, 0.252]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.876, 0.84, 0.944, 1.0], 'all_L1': [0.774, 0.726, 0.824, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.866, 0.713, 0.748, 1.0], 'all_L1': [0.763, 0.673, 0.752, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.741, 0.717, 0.697, 1.0], 'all_L1': [0.622, 0.644, 0.7, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [1.0, 1.0, 1.0, 1.0], 'all_L1': [1.0, 1.0, 1.0, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.798, 0.892, 0.94, 1.0], 'all_L1': [0.86, 0.893, 0.931, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.149, 0.193, 0.263, 0.236], 'all_L1': [0.266, 0.284, 0.332, 0.335]}), defaultdict(<class 'list'>, {'all_KL': [0.13, 0.287, 0.368, 0.395], 'all_L1': [0.243, 0.333, 0.393, 0.399]}), defaultdict(<class 'list'>, {'all_KL': [0.427, 0.335, 0.403, 0.381], 'all_L1': [0.51, 0.392, 0.425, 0.419]}), defaultdict(<class 'list'>, {'all_KL': [0.0, 0.0, 0.0, 0.0], 'all_L1': [0.0, 0.0, 0.0, 0.0]}), defaultdict(<class 'list'>, {'all_KL': [0.271, 0.302, 0.262, 0.262], 'all_L1': [0.256, 0.24, 0.182, 0.183]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.775 +- 0.134, 0.737 +- 0.135, 0.830 +- 0.094, 1.000 +- 0.000
suff++ class all_KL  =  0.834 +- 0.154, 0.785 +- 0.125, 0.886 +- 0.061, 1.000 +- 0.000
suff++_acc_int  =  0.399 +- 0.053, 0.477 +- 0.083, 0.590 +- 0.144
nec class all_L1  =  0.258 +- 0.156, 0.288 +- 0.149, 0.292 +- 0.149, 0.298 +- 0.152
nec class all_KL  =  0.200 +- 0.191, 0.247 +- 0.158, 0.244 +- 0.136, 0.257 +- 0.134
nec_acc_int  =  0.333 +- 0.033, 0.399 +- 0.035, 0.421 +- 0.048, 0.432 +- 0.050

Eval split val
suff++ class all_L1  =  0.711 +- 0.151, 0.718 +- 0.145, 0.847 +- 0.086, 1.000 +- 0.000
suff++ class all_KL  =  0.742 +- 0.135, 0.764 +- 0.138, 0.906 +- 0.069, 1.000 +- 0.000
suff++_acc_int  =  0.386 +- 0.069, 0.469 +- 0.079, 0.590 +- 0.144
nec class all_L1  =  0.316 +- 0.161, 0.310 +- 0.167, 0.279 +- 0.150, 0.275 +- 0.147
nec class all_KL  =  0.292 +- 0.170, 0.267 +- 0.149, 0.197 +- 0.108, 0.186 +- 0.100
nec_acc_int  =  0.343 +- 0.018, 0.394 +- 0.043, 0.431 +- 0.064, 0.432 +- 0.062

Eval split test
suff++ class all_L1  =  0.804 +- 0.124, 0.787 +- 0.137, 0.841 +- 0.111, 1.000 +- 0.000
suff++ class all_KL  =  0.856 +- 0.087, 0.832 +- 0.109, 0.866 +- 0.120, 1.000 +- 0.000
suff++_acc_int  =  0.400 +- 0.057, 0.483 +- 0.118, 0.501 +- 0.134
nec class all_L1  =  0.255 +- 0.161, 0.250 +- 0.135, 0.266 +- 0.157, 0.267 +- 0.157
nec class all_KL  =  0.195 +- 0.144, 0.223 +- 0.121, 0.259 +- 0.141, 0.255 +- 0.142
nec_acc_int  =  0.364 +- 0.050, 0.420 +- 0.051, 0.443 +- 0.065, 0.436 +- 0.057


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.516 +- 0.012, 0.512 +- 0.015, 0.561 +- 0.039, 0.649 +- 0.076
Faith. Armon (L1)= 		  =  0.343 +- 0.185, 0.372 +- 0.189, 0.399 +- 0.201, 0.433 +- 0.219
Faith. GMean (L1)= 	  =  0.376 +- 0.193, 0.392 +- 0.197, 0.429 +- 0.216, 0.487 +- 0.245
Faith. Aritm (KL)= 		  =  0.517 +- 0.019, 0.516 +- 0.025, 0.565 +- 0.046, 0.628 +- 0.067
Faith. Armon (KL)= 		  =  0.259 +- 0.190, 0.333 +- 0.186, 0.357 +- 0.191, 0.387 +- 0.199
Faith. GMean (KL)= 	  =  0.321 +- 0.186, 0.370 +- 0.193, 0.407 +- 0.210, 0.452 +- 0.229

Eval split val
Faith. Aritm (L1)= 		  =  0.514 +- 0.017, 0.514 +- 0.025, 0.563 +- 0.049, 0.638 +- 0.073
Faith. Armon (L1)= 		  =  0.389 +- 0.195, 0.384 +- 0.197, 0.388 +- 0.202, 0.408 +- 0.212
Faith. GMean (L1)= 	  =  0.401 +- 0.201, 0.399 +- 0.202, 0.423 +- 0.217, 0.468 +- 0.238
Faith. Aritm (KL)= 		  =  0.517 +- 0.029, 0.516 +- 0.020, 0.551 +- 0.036, 0.593 +- 0.050
Faith. Armon (KL)= 		  =  0.371 +- 0.195, 0.355 +- 0.185, 0.305 +- 0.162, 0.300 +- 0.158
Faith. GMean (KL)= 	  =  0.393 +- 0.201, 0.383 +- 0.194, 0.370 +- 0.189, 0.384 +- 0.196

Eval split test
Faith. Aritm (L1)= 		  =  0.529 +- 0.028, 0.518 +- 0.025, 0.554 +- 0.028, 0.634 +- 0.079
Faith. Armon (L1)= 		  =  0.344 +- 0.185, 0.344 +- 0.176, 0.365 +- 0.199, 0.394 +- 0.221
Faith. GMean (L1)= 	  =  0.383 +- 0.197, 0.379 +- 0.190, 0.405 +- 0.208, 0.457 +- 0.241
Faith. Aritm (KL)= 		  =  0.526 +- 0.032, 0.528 +- 0.036, 0.562 +- 0.038, 0.627 +- 0.071
Faith. Armon (KL)= 		  =  0.285 +- 0.182, 0.326 +- 0.171, 0.365 +- 0.187, 0.383 +- 0.205
Faith. GMean (KL)= 	  =  0.345 +- 0.190, 0.373 +- 0.190, 0.410 +- 0.205, 0.449 +- 0.231
Computed for split load_split = id



Completed in  0:19:07.341568  for LECIGIN GOODMotif2/basis



DONE LECI GOODMotif2/basis

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 11:27:10 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/22/2024 11:27:11 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:27:12 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 107...
[0m[1;37mINFO[0m: [1mCheckpoint 107: 
-----------------------------------
Train ACCURACY: 0.9294
Train Loss: 0.1523
ID Validation ACCURACY: 0.8678
ID Validation Loss: 0.3150
ID Test ACCURACY: 0.8640
ID Test Loss: 0.3338
OOD Validation ACCURACY: 0.8471
OOD Validation Loss: 0.3977
OOD Test ACCURACY: 0.7144
OOD Test Loss: 0.6785

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 110...
[0m[1;37mINFO[0m: [1mCheckpoint 110: 
-----------------------------------
Train ACCURACY: 0.9301
Train Loss: 0.1474
ID Validation ACCURACY: 0.8670
ID Validation Loss: 0.3230
ID Test ACCURACY: 0.8640
ID Test Loss: 0.3448
OOD Validation ACCURACY: 0.8671
OOD Validation Loss: 0.3561
OOD Test ACCURACY: 0.6753
OOD Test Loss: 0.6860

[0m[1;37mINFO[0m: [1mChartInfo 0.8640 0.7144 0.8640 0.6753 0.8670 0.8671[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 04/22/2024 11:27:13 AM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.778
SUFF++ for r=0.6 class 0.0 = 0.722 +- 0.283 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.6 class 1.0 = 0.745 +- 0.283 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.6 all KL = 0.633 +- 0.283 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.6 all L1 = 0.736 +- 0.208 (in-sample avg dev_std = 0.490)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.883
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.841
SUFF++ for r=0.9 class 0.0 = 0.863 +- 0.208 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 1.0 = 0.826 +- 0.208 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 all KL = 0.863 +- 0.208 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 all L1 = 0.842 +- 0.213 (in-sample avg dev_std = 0.261)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.858
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 795
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.736
SUFF++ for r=0.3 class 0.0 = 0.707 +- 0.283 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.3 class 1.0 = 0.669 +- 0.283 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.3 all KL = 0.576 +- 0.283 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.3 all L1 = 0.687 +- 0.176 (in-sample avg dev_std = 0.557)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.866
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.78
SUFF++ for r=0.6 class 0.0 = 0.731 +- 0.237 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.6 class 1.0 = 0.771 +- 0.237 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.6 all KL = 0.705 +- 0.237 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.6 all L1 = 0.752 +- 0.168 (in-sample avg dev_std = 0.425)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.859
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.849
SUFF++ for r=0.9 class 0.0 = 0.877 +- 0.108 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.9 class 1.0 = 0.922 +- 0.108 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.9 all KL = 0.937 +- 0.108 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.9 all L1 = 0.9 +- 0.116 (in-sample avg dev_std = 0.182)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.765
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.694
SUFF++ for r=0.3 class 0.0 = 0.649 +- 0.248 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.3 class 1.0 = 0.759 +- 0.248 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.3 all KL = 0.67 +- 0.248 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.3 all L1 = 0.706 +- 0.164 (in-sample avg dev_std = 0.476)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.75
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.726
SUFF++ for r=0.6 class 0.0 = 0.711 +- 0.168 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.6 class 1.0 = 0.832 +- 0.168 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.6 all KL = 0.816 +- 0.168 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.6 all L1 = 0.774 +- 0.147 (in-sample avg dev_std = 0.327)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.743
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.733
SUFF++ for r=0.9 class 0.0 = 0.84 +- 0.069 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.9 class 1.0 = 0.925 +- 0.069 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.9 all KL = 0.954 +- 0.069 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.9 all L1 = 0.884 +- 0.101 (in-sample avg dev_std = 0.147)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.85
NEC for r=0.6 class 0.0 = 0.154 +- 0.239 (in-sample avg dev_std = 0.229)
NEC for r=0.6 class 1.0 = 0.159 +- 0.239 (in-sample avg dev_std = 0.229)
NEC for r=0.6 all KL = 0.15 +- 0.239 (in-sample avg dev_std = 0.229)
NEC for r=0.6 all L1 = 0.157 +- 0.224 (in-sample avg dev_std = 0.229)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.888
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.857
NEC for r=0.9 class 0.0 = 0.134 +- 0.188 (in-sample avg dev_std = 0.224)
NEC for r=0.9 class 1.0 = 0.139 +- 0.188 (in-sample avg dev_std = 0.224)
NEC for r=0.9 all KL = 0.116 +- 0.188 (in-sample avg dev_std = 0.224)
NEC for r=0.9 all L1 = 0.137 +- 0.199 (in-sample avg dev_std = 0.224)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.888
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.857
NEC for r=1.0 class 0.0 = 0.134 +- 0.188 (in-sample avg dev_std = 0.224)
NEC for r=1.0 class 1.0 = 0.139 +- 0.188 (in-sample avg dev_std = 0.224)
NEC for r=1.0 all KL = 0.116 +- 0.188 (in-sample avg dev_std = 0.224)
NEC for r=1.0 all L1 = 0.137 +- 0.199 (in-sample avg dev_std = 0.224)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.859
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.836
NEC for r=0.3 class 0.0 = 0.131 +- 0.197 (in-sample avg dev_std = 0.188)
NEC for r=0.3 class 1.0 = 0.155 +- 0.197 (in-sample avg dev_std = 0.188)
NEC for r=0.3 all KL = 0.115 +- 0.197 (in-sample avg dev_std = 0.188)
NEC for r=0.3 all L1 = 0.144 +- 0.189 (in-sample avg dev_std = 0.188)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.866
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.857
NEC for r=0.6 class 0.0 = 0.153 +- 0.169 (in-sample avg dev_std = 0.210)
NEC for r=0.6 class 1.0 = 0.123 +- 0.169 (in-sample avg dev_std = 0.210)
NEC for r=0.6 all KL = 0.097 +- 0.169 (in-sample avg dev_std = 0.210)
NEC for r=0.6 all L1 = 0.137 +- 0.175 (in-sample avg dev_std = 0.210)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.859
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.845
NEC for r=0.9 class 0.0 = 0.163 +- 0.146 (in-sample avg dev_std = 0.203)
NEC for r=0.9 class 1.0 = 0.119 +- 0.146 (in-sample avg dev_std = 0.203)
NEC for r=0.9 all KL = 0.091 +- 0.146 (in-sample avg dev_std = 0.203)
NEC for r=0.9 all L1 = 0.14 +- 0.164 (in-sample avg dev_std = 0.203)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.86
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.841
NEC for r=1.0 class 0.0 = 0.163 +- 0.131 (in-sample avg dev_std = 0.194)
NEC for r=1.0 class 1.0 = 0.115 +- 0.131 (in-sample avg dev_std = 0.194)
NEC for r=1.0 all KL = 0.082 +- 0.131 (in-sample avg dev_std = 0.194)
NEC for r=1.0 all L1 = 0.138 +- 0.158 (in-sample avg dev_std = 0.194)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.765
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.782
NEC for r=0.3 class 0.0 = 0.206 +- 0.190 (in-sample avg dev_std = 0.190)
NEC for r=0.3 class 1.0 = 0.15 +- 0.190 (in-sample avg dev_std = 0.190)
NEC for r=0.3 all KL = 0.125 +- 0.190 (in-sample avg dev_std = 0.190)
NEC for r=0.3 all L1 = 0.177 +- 0.192 (in-sample avg dev_std = 0.190)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.75
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.772
NEC for r=0.6 class 0.0 = 0.205 +- 0.142 (in-sample avg dev_std = 0.164)
NEC for r=0.6 class 1.0 = 0.135 +- 0.142 (in-sample avg dev_std = 0.164)
NEC for r=0.6 all KL = 0.094 +- 0.142 (in-sample avg dev_std = 0.164)
NEC for r=0.6 all L1 = 0.169 +- 0.161 (in-sample avg dev_std = 0.164)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.743
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.757
NEC for r=0.9 class 0.0 = 0.189 +- 0.099 (in-sample avg dev_std = 0.149)
NEC for r=0.9 class 1.0 = 0.108 +- 0.099 (in-sample avg dev_std = 0.149)
NEC for r=0.9 all KL = 0.065 +- 0.099 (in-sample avg dev_std = 0.149)
NEC for r=0.9 all L1 = 0.147 +- 0.133 (in-sample avg dev_std = 0.149)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.733
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.749
NEC for r=1.0 class 0.0 = 0.184 +- 0.098 (in-sample avg dev_std = 0.143)
NEC for r=1.0 class 1.0 = 0.103 +- 0.098 (in-sample avg dev_std = 0.143)
NEC for r=1.0 all KL = 0.06 +- 0.098 (in-sample avg dev_std = 0.143)
NEC for r=1.0 all L1 = 0.142 +- 0.126 (in-sample avg dev_std = 0.143)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 11:31:00 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:31:01 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:31:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:02 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:31:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:02 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:31:02 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:31:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:02 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:31:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:31:02 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:31:02 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 103...
[0m[1;37mINFO[0m: [1mCheckpoint 103: 
-----------------------------------
Train ACCURACY: 0.9332
Train Loss: 0.1177
ID Validation ACCURACY: 0.8617
ID Validation Loss: 0.3626
ID Test ACCURACY: 0.8585
ID Test Loss: 0.3627
OOD Validation ACCURACY: 0.8724
OOD Validation Loss: 0.3851
OOD Test ACCURACY: 0.8150
OOD Test Loss: 0.6390

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 143...
[0m[1;37mINFO[0m: [1mCheckpoint 143: 
-----------------------------------
Train ACCURACY: 0.9340
Train Loss: 0.1135
ID Validation ACCURACY: 0.8542
ID Validation Loss: 0.3827
ID Test ACCURACY: 0.8570
ID Test Loss: 0.3788
OOD Validation ACCURACY: 0.8752
OOD Validation Loss: 0.4305
OOD Test ACCURACY: 0.8284
OOD Test Loss: 0.6868

[0m[1;37mINFO[0m: [1mChartInfo 0.8585 0.8150 0.8570 0.8284 0.8542 0.8752[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 04/22/2024 11:31:02 AM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.888
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.854
SUFF++ for r=0.6 class 0.0 = 0.865 +- 0.227 (in-sample avg dev_std = 0.335)
SUFF++ for r=0.6 class 1.0 = 0.911 +- 0.227 (in-sample avg dev_std = 0.335)
SUFF++ for r=0.6 all KL = 0.856 +- 0.227 (in-sample avg dev_std = 0.335)
SUFF++ for r=0.6 all L1 = 0.892 +- 0.162 (in-sample avg dev_std = 0.335)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.883
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.871
SUFF++ for r=0.9 class 0.0 = 0.929 +- 0.100 (in-sample avg dev_std = 0.121)
SUFF++ for r=0.9 class 1.0 = 0.945 +- 0.100 (in-sample avg dev_std = 0.121)
SUFF++ for r=0.9 all KL = 0.963 +- 0.100 (in-sample avg dev_std = 0.121)
SUFF++ for r=0.9 all L1 = 0.938 +- 0.128 (in-sample avg dev_std = 0.121)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.869
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 799
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.82
SUFF++ for r=0.3 class 0.0 = 0.839 +- 0.286 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 class 1.0 = 0.816 +- 0.286 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 all KL = 0.738 +- 0.286 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 all L1 = 0.827 +- 0.184 (in-sample avg dev_std = 0.470)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.869
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.857
SUFF++ for r=0.6 class 0.0 = 0.903 +- 0.146 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.6 class 1.0 = 0.897 +- 0.146 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.6 all KL = 0.906 +- 0.146 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.6 all L1 = 0.9 +- 0.141 (in-sample avg dev_std = 0.253)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.874
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.873
SUFF++ for r=0.9 class 0.0 = 0.961 +- 0.042 (in-sample avg dev_std = 0.090)
SUFF++ for r=0.9 class 1.0 = 0.96 +- 0.042 (in-sample avg dev_std = 0.090)
SUFF++ for r=0.9 all KL = 0.984 +- 0.042 (in-sample avg dev_std = 0.090)
SUFF++ for r=0.9 all L1 = 0.96 +- 0.069 (in-sample avg dev_std = 0.090)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.86
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.805
SUFF++ for r=0.3 class 0.0 = 0.788 +- 0.281 (in-sample avg dev_std = 0.447)
SUFF++ for r=0.3 class 1.0 = 0.862 +- 0.281 (in-sample avg dev_std = 0.447)
SUFF++ for r=0.3 all KL = 0.733 +- 0.281 (in-sample avg dev_std = 0.447)
SUFF++ for r=0.3 all L1 = 0.826 +- 0.185 (in-sample avg dev_std = 0.447)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.863
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.838
SUFF++ for r=0.6 class 0.0 = 0.887 +- 0.142 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.6 class 1.0 = 0.901 +- 0.142 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.6 all KL = 0.908 +- 0.142 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.6 all L1 = 0.894 +- 0.140 (in-sample avg dev_std = 0.220)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.854
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.854
SUFF++ for r=0.9 class 0.0 = 0.943 +- 0.092 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.9 class 1.0 = 0.944 +- 0.092 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.9 all KL = 0.971 +- 0.092 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.9 all L1 = 0.944 +- 0.092 (in-sample avg dev_std = 0.106)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.888
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.872
NEC for r=0.6 class 0.0 = 0.067 +- 0.127 (in-sample avg dev_std = 0.141)
NEC for r=0.6 class 1.0 = 0.05 +- 0.127 (in-sample avg dev_std = 0.141)
NEC for r=0.6 all KL = 0.043 +- 0.127 (in-sample avg dev_std = 0.141)
NEC for r=0.6 all L1 = 0.057 +- 0.127 (in-sample avg dev_std = 0.141)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.881
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.872
NEC for r=0.9 class 0.0 = 0.063 +- 0.090 (in-sample avg dev_std = 0.100)
NEC for r=0.9 class 1.0 = 0.045 +- 0.090 (in-sample avg dev_std = 0.100)
NEC for r=0.9 all KL = 0.031 +- 0.090 (in-sample avg dev_std = 0.100)
NEC for r=0.9 all L1 = 0.053 +- 0.114 (in-sample avg dev_std = 0.100)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.881
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.872
NEC for r=1.0 class 0.0 = 0.063 +- 0.090 (in-sample avg dev_std = 0.100)
NEC for r=1.0 class 1.0 = 0.045 +- 0.090 (in-sample avg dev_std = 0.100)
NEC for r=1.0 all KL = 0.031 +- 0.090 (in-sample avg dev_std = 0.100)
NEC for r=1.0 all L1 = 0.053 +- 0.114 (in-sample avg dev_std = 0.100)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.869
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.862
NEC for r=0.3 class 0.0 = 0.094 +- 0.182 (in-sample avg dev_std = 0.182)
NEC for r=0.3 class 1.0 = 0.078 +- 0.182 (in-sample avg dev_std = 0.182)
NEC for r=0.3 all KL = 0.074 +- 0.182 (in-sample avg dev_std = 0.182)
NEC for r=0.3 all L1 = 0.085 +- 0.171 (in-sample avg dev_std = 0.182)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.869
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.869
NEC for r=0.6 class 0.0 = 0.076 +- 0.139 (in-sample avg dev_std = 0.155)
NEC for r=0.6 class 1.0 = 0.073 +- 0.139 (in-sample avg dev_std = 0.155)
NEC for r=0.6 all KL = 0.052 +- 0.139 (in-sample avg dev_std = 0.155)
NEC for r=0.6 all L1 = 0.074 +- 0.146 (in-sample avg dev_std = 0.155)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.874
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.874
NEC for r=0.9 class 0.0 = 0.074 +- 0.098 (in-sample avg dev_std = 0.132)
NEC for r=0.9 class 1.0 = 0.065 +- 0.098 (in-sample avg dev_std = 0.132)
NEC for r=0.9 all KL = 0.038 +- 0.098 (in-sample avg dev_std = 0.132)
NEC for r=0.9 all L1 = 0.069 +- 0.120 (in-sample avg dev_std = 0.132)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.877
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.87
NEC for r=1.0 class 0.0 = 0.076 +- 0.086 (in-sample avg dev_std = 0.122)
NEC for r=1.0 class 1.0 = 0.063 +- 0.086 (in-sample avg dev_std = 0.122)
NEC for r=1.0 all KL = 0.034 +- 0.086 (in-sample avg dev_std = 0.122)
NEC for r=1.0 all L1 = 0.069 +- 0.114 (in-sample avg dev_std = 0.122)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.86
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.843
NEC for r=0.3 class 0.0 = 0.109 +- 0.201 (in-sample avg dev_std = 0.192)
NEC for r=0.3 class 1.0 = 0.079 +- 0.201 (in-sample avg dev_std = 0.192)
NEC for r=0.3 all KL = 0.091 +- 0.201 (in-sample avg dev_std = 0.192)
NEC for r=0.3 all L1 = 0.094 +- 0.175 (in-sample avg dev_std = 0.192)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.863
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.854
NEC for r=0.6 class 0.0 = 0.098 +- 0.123 (in-sample avg dev_std = 0.144)
NEC for r=0.6 class 1.0 = 0.08 +- 0.123 (in-sample avg dev_std = 0.144)
NEC for r=0.6 all KL = 0.058 +- 0.123 (in-sample avg dev_std = 0.144)
NEC for r=0.6 all L1 = 0.088 +- 0.145 (in-sample avg dev_std = 0.144)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.854
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.858
NEC for r=0.9 class 0.0 = 0.089 +- 0.115 (in-sample avg dev_std = 0.135)
NEC for r=0.9 class 1.0 = 0.087 +- 0.115 (in-sample avg dev_std = 0.135)
NEC for r=0.9 all KL = 0.051 +- 0.115 (in-sample avg dev_std = 0.135)
NEC for r=0.9 all L1 = 0.088 +- 0.126 (in-sample avg dev_std = 0.135)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.859
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.856
NEC for r=1.0 class 0.0 = 0.086 +- 0.114 (in-sample avg dev_std = 0.138)
NEC for r=1.0 class 1.0 = 0.09 +- 0.114 (in-sample avg dev_std = 0.138)
NEC for r=1.0 all KL = 0.051 +- 0.114 (in-sample avg dev_std = 0.138)
NEC for r=1.0 all L1 = 0.088 +- 0.124 (in-sample avg dev_std = 0.138)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 11:34:37 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:34:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:34:39 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:39 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:39 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:39 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:39 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:39 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:39 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:34:39 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:39 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:39 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:39 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:39 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:34:39 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:34:39 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 169...
[0m[1;37mINFO[0m: [1mCheckpoint 169: 
-----------------------------------
Train ACCURACY: 0.9406
Train Loss: 0.0987
ID Validation ACCURACY: 0.8679
ID Validation Loss: 0.3632
ID Test ACCURACY: 0.8612
ID Test Loss: 0.3815
OOD Validation ACCURACY: 0.8691
OOD Validation Loss: 0.4291
OOD Test ACCURACY: 0.7927
OOD Test Loss: 0.7098

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 187...
[0m[1;37mINFO[0m: [1mCheckpoint 187: 
-----------------------------------
Train ACCURACY: 0.9412
Train Loss: 0.0958
ID Validation ACCURACY: 0.8659
ID Validation Loss: 0.3707
ID Test ACCURACY: 0.8638
ID Test Loss: 0.3824
OOD Validation ACCURACY: 0.8746
OOD Validation Loss: 0.4475
OOD Test ACCURACY: 0.8061
OOD Test Loss: 0.8288

[0m[1;37mINFO[0m: [1mChartInfo 0.8612 0.7927 0.8638 0.8061 0.8659 0.8746[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 04/22/2024 11:34:39 AM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.87
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.848
SUFF++ for r=0.6 class 0.0 = 0.88 +- 0.229 (in-sample avg dev_std = 0.331)
SUFF++ for r=0.6 class 1.0 = 0.898 +- 0.229 (in-sample avg dev_std = 0.331)
SUFF++ for r=0.6 all KL = 0.856 +- 0.229 (in-sample avg dev_std = 0.331)
SUFF++ for r=0.6 all L1 = 0.89 +- 0.168 (in-sample avg dev_std = 0.331)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.867
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.871
SUFF++ for r=0.9 class 0.0 = 0.943 +- 0.101 (in-sample avg dev_std = 0.102)
SUFF++ for r=0.9 class 1.0 = 0.942 +- 0.101 (in-sample avg dev_std = 0.102)
SUFF++ for r=0.9 all KL = 0.963 +- 0.101 (in-sample avg dev_std = 0.102)
SUFF++ for r=0.9 all L1 = 0.943 +- 0.121 (in-sample avg dev_std = 0.102)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.861
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 796
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.817
SUFF++ for r=0.3 class 0.0 = 0.82 +- 0.294 (in-sample avg dev_std = 0.477)
SUFF++ for r=0.3 class 1.0 = 0.815 +- 0.294 (in-sample avg dev_std = 0.477)
SUFF++ for r=0.3 all KL = 0.72 +- 0.294 (in-sample avg dev_std = 0.477)
SUFF++ for r=0.3 all L1 = 0.817 +- 0.181 (in-sample avg dev_std = 0.477)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.871
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.855
SUFF++ for r=0.6 class 0.0 = 0.887 +- 0.179 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.6 class 1.0 = 0.915 +- 0.179 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.6 all KL = 0.893 +- 0.179 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.6 all L1 = 0.901 +- 0.141 (in-sample avg dev_std = 0.277)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.882
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.875
SUFF++ for r=0.9 class 0.0 = 0.935 +- 0.079 (in-sample avg dev_std = 0.143)
SUFF++ for r=0.9 class 1.0 = 0.962 +- 0.079 (in-sample avg dev_std = 0.143)
SUFF++ for r=0.9 all KL = 0.968 +- 0.079 (in-sample avg dev_std = 0.143)
SUFF++ for r=0.9 all L1 = 0.949 +- 0.095 (in-sample avg dev_std = 0.143)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.79
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.763
SUFF++ for r=0.3 class 0.0 = 0.791 +- 0.263 (in-sample avg dev_std = 0.418)
SUFF++ for r=0.3 class 1.0 = 0.833 +- 0.263 (in-sample avg dev_std = 0.418)
SUFF++ for r=0.3 all KL = 0.756 +- 0.263 (in-sample avg dev_std = 0.418)
SUFF++ for r=0.3 all L1 = 0.813 +- 0.176 (in-sample avg dev_std = 0.418)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.812
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.805
SUFF++ for r=0.6 class 0.0 = 0.827 +- 0.185 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.6 class 1.0 = 0.892 +- 0.185 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.6 all KL = 0.877 +- 0.185 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.6 all L1 = 0.861 +- 0.166 (in-sample avg dev_std = 0.259)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.819
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.808
SUFF++ for r=0.9 class 0.0 = 0.886 +- 0.103 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.9 class 1.0 = 0.944 +- 0.103 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.9 all KL = 0.953 +- 0.103 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.9 all L1 = 0.916 +- 0.131 (in-sample avg dev_std = 0.163)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.87
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.868
NEC for r=0.6 class 0.0 = 0.074 +- 0.153 (in-sample avg dev_std = 0.115)
NEC for r=0.6 class 1.0 = 0.062 +- 0.153 (in-sample avg dev_std = 0.115)
NEC for r=0.6 all KL = 0.057 +- 0.153 (in-sample avg dev_std = 0.115)
NEC for r=0.6 all L1 = 0.067 +- 0.152 (in-sample avg dev_std = 0.115)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.87
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.876
NEC for r=0.9 class 0.0 = 0.056 +- 0.082 (in-sample avg dev_std = 0.091)
NEC for r=0.9 class 1.0 = 0.047 +- 0.082 (in-sample avg dev_std = 0.091)
NEC for r=0.9 all KL = 0.029 +- 0.082 (in-sample avg dev_std = 0.091)
NEC for r=0.9 all L1 = 0.05 +- 0.108 (in-sample avg dev_std = 0.091)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.87
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.876
NEC for r=1.0 class 0.0 = 0.056 +- 0.082 (in-sample avg dev_std = 0.091)
NEC for r=1.0 class 1.0 = 0.047 +- 0.082 (in-sample avg dev_std = 0.091)
NEC for r=1.0 all KL = 0.029 +- 0.082 (in-sample avg dev_std = 0.091)
NEC for r=1.0 all L1 = 0.05 +- 0.108 (in-sample avg dev_std = 0.091)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.861
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.849
NEC for r=0.3 class 0.0 = 0.152 +- 0.209 (in-sample avg dev_std = 0.202)
NEC for r=0.3 class 1.0 = 0.071 +- 0.209 (in-sample avg dev_std = 0.202)
NEC for r=0.3 all KL = 0.103 +- 0.209 (in-sample avg dev_std = 0.202)
NEC for r=0.3 all L1 = 0.109 +- 0.183 (in-sample avg dev_std = 0.202)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.871
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.864
NEC for r=0.6 class 0.0 = 0.113 +- 0.161 (in-sample avg dev_std = 0.165)
NEC for r=0.6 class 1.0 = 0.056 +- 0.161 (in-sample avg dev_std = 0.165)
NEC for r=0.6 all KL = 0.068 +- 0.161 (in-sample avg dev_std = 0.165)
NEC for r=0.6 all L1 = 0.083 +- 0.145 (in-sample avg dev_std = 0.165)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.882
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.871
NEC for r=0.9 class 0.0 = 0.087 +- 0.106 (in-sample avg dev_std = 0.130)
NEC for r=0.9 class 1.0 = 0.047 +- 0.106 (in-sample avg dev_std = 0.130)
NEC for r=0.9 all KL = 0.042 +- 0.106 (in-sample avg dev_std = 0.130)
NEC for r=0.9 all L1 = 0.066 +- 0.117 (in-sample avg dev_std = 0.130)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.879
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.876
NEC for r=1.0 class 0.0 = 0.083 +- 0.096 (in-sample avg dev_std = 0.127)
NEC for r=1.0 class 1.0 = 0.048 +- 0.096 (in-sample avg dev_std = 0.127)
NEC for r=1.0 all KL = 0.039 +- 0.096 (in-sample avg dev_std = 0.127)
NEC for r=1.0 all L1 = 0.065 +- 0.109 (in-sample avg dev_std = 0.127)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.79
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.775
NEC for r=0.3 class 0.0 = 0.206 +- 0.231 (in-sample avg dev_std = 0.253)
NEC for r=0.3 class 1.0 = 0.109 +- 0.231 (in-sample avg dev_std = 0.253)
NEC for r=0.3 all KL = 0.138 +- 0.231 (in-sample avg dev_std = 0.253)
NEC for r=0.3 all L1 = 0.156 +- 0.212 (in-sample avg dev_std = 0.253)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.812
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.805
NEC for r=0.6 class 0.0 = 0.171 +- 0.169 (in-sample avg dev_std = 0.201)
NEC for r=0.6 class 1.0 = 0.092 +- 0.169 (in-sample avg dev_std = 0.201)
NEC for r=0.6 all KL = 0.091 +- 0.169 (in-sample avg dev_std = 0.201)
NEC for r=0.6 all L1 = 0.13 +- 0.178 (in-sample avg dev_std = 0.201)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.819
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.805
NEC for r=0.9 class 0.0 = 0.145 +- 0.129 (in-sample avg dev_std = 0.175)
NEC for r=0.9 class 1.0 = 0.076 +- 0.129 (in-sample avg dev_std = 0.175)
NEC for r=0.9 all KL = 0.066 +- 0.129 (in-sample avg dev_std = 0.175)
NEC for r=0.9 all L1 = 0.109 +- 0.154 (in-sample avg dev_std = 0.175)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.82
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.81
NEC for r=1.0 class 0.0 = 0.146 +- 0.122 (in-sample avg dev_std = 0.168)
NEC for r=1.0 class 1.0 = 0.075 +- 0.122 (in-sample avg dev_std = 0.168)
NEC for r=1.0 all KL = 0.064 +- 0.122 (in-sample avg dev_std = 0.168)
NEC for r=1.0 all L1 = 0.109 +- 0.152 (in-sample avg dev_std = 0.168)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 11:38:52 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:38:53 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 193...
[0m[1;37mINFO[0m: [1mCheckpoint 193: 
-----------------------------------
Train ACCURACY: 0.9389
Train Loss: 0.1117
ID Validation ACCURACY: 0.8670
ID Validation Loss: 0.3645
ID Test ACCURACY: 0.8651
ID Test Loss: 0.3686
OOD Validation ACCURACY: 0.8690
OOD Validation Loss: 0.4165
OOD Test ACCURACY: 0.7200
OOD Test Loss: 0.7180

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 198...
[0m[1;37mINFO[0m: [1mCheckpoint 198: 
-----------------------------------
Train ACCURACY: 0.9376
Train Loss: 0.1132
ID Validation ACCURACY: 0.8634
ID Validation Loss: 0.3805
ID Test ACCURACY: 0.8640
ID Test Loss: 0.3802
OOD Validation ACCURACY: 0.8736
OOD Validation Loss: 0.4245
OOD Test ACCURACY: 0.7564
OOD Test Loss: 0.6363

[0m[1;37mINFO[0m: [1mChartInfo 0.8651 0.7200 0.8640 0.7564 0.8634 0.8736[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 04/22/2024 11:38:54 AM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.891
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.85
SUFF++ for r=0.6 class 0.0 = 0.838 +- 0.242 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.6 class 1.0 = 0.849 +- 0.242 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.6 all KL = 0.78 +- 0.242 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.6 all L1 = 0.844 +- 0.179 (in-sample avg dev_std = 0.382)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.894
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.895
SUFF++ for r=0.9 class 0.0 = 0.907 +- 0.153 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.9 class 1.0 = 0.932 +- 0.153 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.9 all KL = 0.936 +- 0.153 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.9 all L1 = 0.921 +- 0.157 (in-sample avg dev_std = 0.155)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.87
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 797
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.788
SUFF++ for r=0.3 class 0.0 = 0.807 +- 0.292 (in-sample avg dev_std = 0.491)
SUFF++ for r=0.3 class 1.0 = 0.765 +- 0.292 (in-sample avg dev_std = 0.491)
SUFF++ for r=0.3 all KL = 0.636 +- 0.292 (in-sample avg dev_std = 0.491)
SUFF++ for r=0.3 all L1 = 0.785 +- 0.169 (in-sample avg dev_std = 0.491)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.863
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.828
SUFF++ for r=0.6 class 0.0 = 0.887 +- 0.205 (in-sample avg dev_std = 0.329)
SUFF++ for r=0.6 class 1.0 = 0.852 +- 0.205 (in-sample avg dev_std = 0.329)
SUFF++ for r=0.6 all KL = 0.834 +- 0.205 (in-sample avg dev_std = 0.329)
SUFF++ for r=0.6 all L1 = 0.869 +- 0.146 (in-sample avg dev_std = 0.329)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.861
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.856
SUFF++ for r=0.9 class 0.0 = 0.958 +- 0.062 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.9 class 1.0 = 0.944 +- 0.062 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.9 all KL = 0.973 +- 0.062 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.9 all L1 = 0.951 +- 0.075 (in-sample avg dev_std = 0.128)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.8
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.758
SUFF++ for r=0.3 class 0.0 = 0.815 +- 0.277 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.3 class 1.0 = 0.748 +- 0.277 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.3 all KL = 0.694 +- 0.277 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.3 all L1 = 0.781 +- 0.175 (in-sample avg dev_std = 0.438)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.791
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.764
SUFF++ for r=0.6 class 0.0 = 0.875 +- 0.176 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.6 class 1.0 = 0.775 +- 0.176 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.6 all KL = 0.849 +- 0.176 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.6 all L1 = 0.823 +- 0.144 (in-sample avg dev_std = 0.294)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.752
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.752
SUFF++ for r=0.9 class 0.0 = 0.928 +- 0.067 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.9 class 1.0 = 0.845 +- 0.067 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.9 all KL = 0.958 +- 0.067 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.9 all L1 = 0.885 +- 0.114 (in-sample avg dev_std = 0.139)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.891
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.903
NEC for r=0.6 class 0.0 = 0.092 +- 0.171 (in-sample avg dev_std = 0.131)
NEC for r=0.6 class 1.0 = 0.078 +- 0.171 (in-sample avg dev_std = 0.131)
NEC for r=0.6 all KL = 0.081 +- 0.171 (in-sample avg dev_std = 0.131)
NEC for r=0.6 all L1 = 0.084 +- 0.158 (in-sample avg dev_std = 0.131)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.891
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.891
NEC for r=0.9 class 0.0 = 0.073 +- 0.131 (in-sample avg dev_std = 0.119)
NEC for r=0.9 class 1.0 = 0.059 +- 0.131 (in-sample avg dev_std = 0.119)
NEC for r=0.9 all KL = 0.051 +- 0.131 (in-sample avg dev_std = 0.119)
NEC for r=0.9 all L1 = 0.065 +- 0.139 (in-sample avg dev_std = 0.119)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.891
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.891
NEC for r=1.0 class 0.0 = 0.073 +- 0.131 (in-sample avg dev_std = 0.119)
NEC for r=1.0 class 1.0 = 0.059 +- 0.131 (in-sample avg dev_std = 0.119)
NEC for r=1.0 all KL = 0.051 +- 0.131 (in-sample avg dev_std = 0.119)
NEC for r=1.0 all L1 = 0.065 +- 0.139 (in-sample avg dev_std = 0.119)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.869
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.854
NEC for r=0.3 class 0.0 = 0.119 +- 0.194 (in-sample avg dev_std = 0.157)
NEC for r=0.3 class 1.0 = 0.079 +- 0.194 (in-sample avg dev_std = 0.157)
NEC for r=0.3 all KL = 0.098 +- 0.194 (in-sample avg dev_std = 0.157)
NEC for r=0.3 all L1 = 0.098 +- 0.170 (in-sample avg dev_std = 0.157)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.863
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.858
NEC for r=0.6 class 0.0 = 0.08 +- 0.129 (in-sample avg dev_std = 0.136)
NEC for r=0.6 class 1.0 = 0.066 +- 0.129 (in-sample avg dev_std = 0.136)
NEC for r=0.6 all KL = 0.054 +- 0.129 (in-sample avg dev_std = 0.136)
NEC for r=0.6 all L1 = 0.072 +- 0.134 (in-sample avg dev_std = 0.136)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.861
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.858
NEC for r=0.9 class 0.0 = 0.069 +- 0.089 (in-sample avg dev_std = 0.128)
NEC for r=0.9 class 1.0 = 0.073 +- 0.089 (in-sample avg dev_std = 0.128)
NEC for r=0.9 all KL = 0.04 +- 0.089 (in-sample avg dev_std = 0.128)
NEC for r=0.9 all L1 = 0.071 +- 0.116 (in-sample avg dev_std = 0.128)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.859
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.855
NEC for r=1.0 class 0.0 = 0.069 +- 0.089 (in-sample avg dev_std = 0.125)
NEC for r=1.0 class 1.0 = 0.074 +- 0.089 (in-sample avg dev_std = 0.125)
NEC for r=1.0 all KL = 0.038 +- 0.089 (in-sample avg dev_std = 0.125)
NEC for r=1.0 all L1 = 0.072 +- 0.111 (in-sample avg dev_std = 0.125)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.8
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.793
NEC for r=0.3 class 0.0 = 0.209 +- 0.259 (in-sample avg dev_std = 0.251)
NEC for r=0.3 class 1.0 = 0.163 +- 0.259 (in-sample avg dev_std = 0.251)
NEC for r=0.3 all KL = 0.19 +- 0.259 (in-sample avg dev_std = 0.251)
NEC for r=0.3 all L1 = 0.185 +- 0.217 (in-sample avg dev_std = 0.251)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.791
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.8
NEC for r=0.6 class 0.0 = 0.163 +- 0.165 (in-sample avg dev_std = 0.195)
NEC for r=0.6 class 1.0 = 0.176 +- 0.165 (in-sample avg dev_std = 0.195)
NEC for r=0.6 all KL = 0.118 +- 0.165 (in-sample avg dev_std = 0.195)
NEC for r=0.6 all L1 = 0.169 +- 0.171 (in-sample avg dev_std = 0.195)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.752
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.785
NEC for r=0.9 class 0.0 = 0.125 +- 0.106 (in-sample avg dev_std = 0.160)
NEC for r=0.9 class 1.0 = 0.186 +- 0.106 (in-sample avg dev_std = 0.160)
NEC for r=0.9 all KL = 0.076 +- 0.106 (in-sample avg dev_std = 0.160)
NEC for r=0.9 all L1 = 0.156 +- 0.134 (in-sample avg dev_std = 0.160)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.733
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.77
NEC for r=1.0 class 0.0 = 0.119 +- 0.092 (in-sample avg dev_std = 0.145)
NEC for r=1.0 class 1.0 = 0.19 +- 0.092 (in-sample avg dev_std = 0.145)
NEC for r=1.0 all KL = 0.068 +- 0.092 (in-sample avg dev_std = 0.145)
NEC for r=1.0 all L1 = 0.156 +- 0.130 (in-sample avg dev_std = 0.145)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 11:42:12 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 198...
[0m[1;37mINFO[0m: [1mCheckpoint 198: 
-----------------------------------
Train ACCURACY: 0.9316
Train Loss: 0.1421
ID Validation ACCURACY: 0.8696
ID Validation Loss: 0.3301
ID Test ACCURACY: 0.8679
ID Test Loss: 0.3552
OOD Validation ACCURACY: 0.8675
OOD Validation Loss: 0.4206
OOD Test ACCURACY: 0.7977
OOD Test Loss: 0.6967

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 191...
[0m[1;37mINFO[0m: [1mCheckpoint 191: 
-----------------------------------
Train ACCURACY: 0.9303
Train Loss: 0.1436
ID Validation ACCURACY: 0.8674
ID Validation Loss: 0.3272
ID Test ACCURACY: 0.8666
ID Test Loss: 0.3524
OOD Validation ACCURACY: 0.8714
OOD Validation Loss: 0.3914
OOD Test ACCURACY: 0.8209
OOD Test Loss: 0.5308

[0m[1;37mINFO[0m: [1mChartInfo 0.8679 0.7977 0.8666 0.8209 0.8674 0.8714[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 04/22/2024 11:42:14 AM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.891
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.81
SUFF++ for r=0.6 class 0.0 = 0.794 +- 0.279 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 class 1.0 = 0.801 +- 0.279 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 all KL = 0.721 +- 0.279 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 all L1 = 0.798 +- 0.212 (in-sample avg dev_std = 0.429)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.917
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.874
SUFF++ for r=0.9 class 0.0 = 0.938 +- 0.148 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.9 class 1.0 = 0.888 +- 0.148 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.9 all KL = 0.931 +- 0.148 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.9 all L1 = 0.91 +- 0.170 (in-sample avg dev_std = 0.186)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.871
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 797
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.751
SUFF++ for r=0.3 class 0.0 = 0.689 +- 0.291 (in-sample avg dev_std = 0.637)
SUFF++ for r=0.3 class 1.0 = 0.716 +- 0.291 (in-sample avg dev_std = 0.637)
SUFF++ for r=0.3 all KL = 0.532 +- 0.291 (in-sample avg dev_std = 0.637)
SUFF++ for r=0.3 all L1 = 0.703 +- 0.188 (in-sample avg dev_std = 0.637)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.882
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.832
SUFF++ for r=0.6 class 0.0 = 0.817 +- 0.233 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.6 class 1.0 = 0.85 +- 0.233 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.6 all KL = 0.791 +- 0.233 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.6 all L1 = 0.834 +- 0.186 (in-sample avg dev_std = 0.399)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.882
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.875
SUFF++ for r=0.9 class 0.0 = 0.917 +- 0.113 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.9 class 1.0 = 0.936 +- 0.113 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.9 all KL = 0.947 +- 0.113 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.9 all L1 = 0.927 +- 0.119 (in-sample avg dev_std = 0.197)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.831
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.758
SUFF++ for r=0.3 class 0.0 = 0.707 +- 0.279 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.3 class 1.0 = 0.753 +- 0.279 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.3 all KL = 0.612 +- 0.279 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.3 all L1 = 0.731 +- 0.178 (in-sample avg dev_std = 0.542)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.83
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.799
SUFF++ for r=0.6 class 0.0 = 0.787 +- 0.213 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.6 class 1.0 = 0.849 +- 0.213 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.6 all KL = 0.798 +- 0.213 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.6 all L1 = 0.819 +- 0.154 (in-sample avg dev_std = 0.330)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.819
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.812
SUFF++ for r=0.9 class 0.0 = 0.877 +- 0.124 (in-sample avg dev_std = 0.177)
SUFF++ for r=0.9 class 1.0 = 0.924 +- 0.124 (in-sample avg dev_std = 0.177)
SUFF++ for r=0.9 all KL = 0.934 +- 0.124 (in-sample avg dev_std = 0.177)
SUFF++ for r=0.9 all L1 = 0.902 +- 0.120 (in-sample avg dev_std = 0.177)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.891
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.861
NEC for r=0.6 class 0.0 = 0.122 +- 0.223 (in-sample avg dev_std = 0.210)
NEC for r=0.6 class 1.0 = 0.121 +- 0.223 (in-sample avg dev_std = 0.210)
NEC for r=0.6 all KL = 0.114 +- 0.223 (in-sample avg dev_std = 0.210)
NEC for r=0.6 all L1 = 0.121 +- 0.206 (in-sample avg dev_std = 0.210)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.905
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.868
NEC for r=0.9 class 0.0 = 0.07 +- 0.181 (in-sample avg dev_std = 0.177)
NEC for r=0.9 class 1.0 = 0.115 +- 0.181 (in-sample avg dev_std = 0.177)
NEC for r=0.9 all KL = 0.083 +- 0.181 (in-sample avg dev_std = 0.177)
NEC for r=0.9 all L1 = 0.096 +- 0.188 (in-sample avg dev_std = 0.177)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.905
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.868
NEC for r=1.0 class 0.0 = 0.07 +- 0.181 (in-sample avg dev_std = 0.177)
NEC for r=1.0 class 1.0 = 0.115 +- 0.181 (in-sample avg dev_std = 0.177)
NEC for r=1.0 all KL = 0.083 +- 0.181 (in-sample avg dev_std = 0.177)
NEC for r=1.0 all L1 = 0.096 +- 0.188 (in-sample avg dev_std = 0.177)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.871
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.879
NEC for r=0.3 class 0.0 = 0.11 +- 0.186 (in-sample avg dev_std = 0.170)
NEC for r=0.3 class 1.0 = 0.091 +- 0.186 (in-sample avg dev_std = 0.170)
NEC for r=0.3 all KL = 0.087 +- 0.186 (in-sample avg dev_std = 0.170)
NEC for r=0.3 all L1 = 0.1 +- 0.173 (in-sample avg dev_std = 0.170)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.882
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.88
NEC for r=0.6 class 0.0 = 0.086 +- 0.155 (in-sample avg dev_std = 0.160)
NEC for r=0.6 class 1.0 = 0.074 +- 0.155 (in-sample avg dev_std = 0.160)
NEC for r=0.6 all KL = 0.063 +- 0.155 (in-sample avg dev_std = 0.160)
NEC for r=0.6 all L1 = 0.08 +- 0.147 (in-sample avg dev_std = 0.160)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.882
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.88
NEC for r=0.9 class 0.0 = 0.091 +- 0.132 (in-sample avg dev_std = 0.155)
NEC for r=0.9 class 1.0 = 0.075 +- 0.132 (in-sample avg dev_std = 0.155)
NEC for r=0.9 all KL = 0.057 +- 0.132 (in-sample avg dev_std = 0.155)
NEC for r=0.9 all L1 = 0.083 +- 0.140 (in-sample avg dev_std = 0.155)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.882
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.882
NEC for r=1.0 class 0.0 = 0.095 +- 0.125 (in-sample avg dev_std = 0.153)
NEC for r=1.0 class 1.0 = 0.075 +- 0.125 (in-sample avg dev_std = 0.153)
NEC for r=1.0 all KL = 0.054 +- 0.125 (in-sample avg dev_std = 0.153)
NEC for r=1.0 all L1 = 0.084 +- 0.138 (in-sample avg dev_std = 0.153)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.831
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.848
NEC for r=0.3 class 0.0 = 0.157 +- 0.229 (in-sample avg dev_std = 0.224)
NEC for r=0.3 class 1.0 = 0.12 +- 0.229 (in-sample avg dev_std = 0.224)
NEC for r=0.3 all KL = 0.126 +- 0.229 (in-sample avg dev_std = 0.224)
NEC for r=0.3 all L1 = 0.138 +- 0.192 (in-sample avg dev_std = 0.224)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.83
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.839
NEC for r=0.6 class 0.0 = 0.171 +- 0.199 (in-sample avg dev_std = 0.203)
NEC for r=0.6 class 1.0 = 0.105 +- 0.199 (in-sample avg dev_std = 0.203)
NEC for r=0.6 all KL = 0.11 +- 0.199 (in-sample avg dev_std = 0.203)
NEC for r=0.6 all L1 = 0.137 +- 0.171 (in-sample avg dev_std = 0.203)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.819
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.817
NEC for r=0.9 class 0.0 = 0.167 +- 0.167 (in-sample avg dev_std = 0.179)
NEC for r=0.9 class 1.0 = 0.089 +- 0.167 (in-sample avg dev_std = 0.179)
NEC for r=0.9 all KL = 0.086 +- 0.167 (in-sample avg dev_std = 0.179)
NEC for r=0.9 all L1 = 0.127 +- 0.149 (in-sample avg dev_std = 0.179)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.822
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.818
NEC for r=1.0 class 0.0 = 0.163 +- 0.160 (in-sample avg dev_std = 0.176)
NEC for r=1.0 class 1.0 = 0.09 +- 0.160 (in-sample avg dev_std = 0.176)
NEC for r=1.0 all KL = 0.085 +- 0.160 (in-sample avg dev_std = 0.176)
NEC for r=1.0 all L1 = 0.126 +- 0.145 (in-sample avg dev_std = 0.176)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.633, 0.863, 1.0], 'all_L1': [0.736, 0.842, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.856, 0.963, 1.0], 'all_L1': [0.892, 0.938, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.856, 0.963, 1.0], 'all_L1': [0.89, 0.943, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.78, 0.936, 1.0], 'all_L1': [0.844, 0.921, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.721, 0.931, 1.0], 'all_L1': [0.798, 0.91, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.15, 0.116, 0.116], 'all_L1': [0.157, 0.137, 0.137]}), defaultdict(<class 'list'>, {'all_KL': [0.043, 0.031, 0.031], 'all_L1': [0.057, 0.053, 0.053]}), defaultdict(<class 'list'>, {'all_KL': [0.057, 0.029, 0.029], 'all_L1': [0.067, 0.05, 0.05]}), defaultdict(<class 'list'>, {'all_KL': [0.081, 0.051, 0.051], 'all_L1': [0.084, 0.065, 0.065]}), defaultdict(<class 'list'>, {'all_KL': [0.114, 0.083, 0.083], 'all_L1': [0.121, 0.096, 0.096]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.576, 0.705, 0.937, 1.0], 'all_L1': [0.687, 0.752, 0.9, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.738, 0.906, 0.984, 1.0], 'all_L1': [0.827, 0.9, 0.96, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.72, 0.893, 0.968, 1.0], 'all_L1': [0.817, 0.901, 0.949, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.636, 0.834, 0.973, 1.0], 'all_L1': [0.785, 0.869, 0.951, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.532, 0.791, 0.947, 1.0], 'all_L1': [0.703, 0.834, 0.927, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.115, 0.097, 0.091, 0.082], 'all_L1': [0.144, 0.137, 0.14, 0.138]}), defaultdict(<class 'list'>, {'all_KL': [0.074, 0.052, 0.038, 0.034], 'all_L1': [0.085, 0.074, 0.069, 0.069]}), defaultdict(<class 'list'>, {'all_KL': [0.103, 0.068, 0.042, 0.039], 'all_L1': [0.109, 0.083, 0.066, 0.065]}), defaultdict(<class 'list'>, {'all_KL': [0.098, 0.054, 0.04, 0.038], 'all_L1': [0.098, 0.072, 0.071, 0.072]}), defaultdict(<class 'list'>, {'all_KL': [0.087, 0.063, 0.057, 0.054], 'all_L1': [0.1, 0.08, 0.083, 0.084]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.67, 0.816, 0.954, 1.0], 'all_L1': [0.706, 0.774, 0.884, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.733, 0.908, 0.971, 1.0], 'all_L1': [0.826, 0.894, 0.944, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.756, 0.877, 0.953, 1.0], 'all_L1': [0.813, 0.861, 0.916, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.694, 0.849, 0.958, 1.0], 'all_L1': [0.781, 0.823, 0.885, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.612, 0.798, 0.934, 1.0], 'all_L1': [0.731, 0.819, 0.902, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.125, 0.094, 0.065, 0.06], 'all_L1': [0.177, 0.169, 0.147, 0.142]}), defaultdict(<class 'list'>, {'all_KL': [0.091, 0.058, 0.051, 0.051], 'all_L1': [0.094, 0.088, 0.088, 0.088]}), defaultdict(<class 'list'>, {'all_KL': [0.138, 0.091, 0.066, 0.064], 'all_L1': [0.156, 0.13, 0.109, 0.109]}), defaultdict(<class 'list'>, {'all_KL': [0.19, 0.118, 0.076, 0.068], 'all_L1': [0.185, 0.169, 0.156, 0.156]}), defaultdict(<class 'list'>, {'all_KL': [0.126, 0.11, 0.086, 0.085], 'all_L1': [0.138, 0.137, 0.127, 0.126]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.832 +- 0.059, 0.911 +- 0.036, 1.000 +- 0.000
suff++ class all_KL  =  0.769 +- 0.085, 0.931 +- 0.037, 1.000 +- 0.000
suff++_acc_int  =  0.828 +- 0.030, 0.870 +- 0.017
nec class all_L1  =  0.097 +- 0.037, 0.080 +- 0.033, 0.080 +- 0.033
nec class all_KL  =  0.089 +- 0.039, 0.062 +- 0.033, 0.062 +- 0.033
nec_acc_int  =  0.871 +- 0.018, 0.873 +- 0.011, 0.873 +- 0.011

Eval split val
suff++ class all_L1  =  0.764 +- 0.058, 0.851 +- 0.055, 0.937 +- 0.022, 1.000 +- 0.000
suff++ class all_KL  =  0.640 +- 0.080, 0.826 +- 0.073, 0.962 +- 0.017, 1.000 +- 0.000
suff++_acc_int  =  0.782 +- 0.034, 0.830 +- 0.028, 0.866 +- 0.011
nec class all_L1  =  0.107 +- 0.020, 0.089 +- 0.024, 0.086 +- 0.028, 0.086 +- 0.027
nec class all_KL  =  0.095 +- 0.014, 0.067 +- 0.016, 0.054 +- 0.020, 0.049 +- 0.018
nec_acc_int  =  0.856 +- 0.014, 0.866 +- 0.008, 0.865 +- 0.012, 0.865 +- 0.015

Eval split test
suff++ class all_L1  =  0.771 +- 0.046, 0.834 +- 0.041, 0.906 +- 0.022, 1.000 +- 0.000
suff++ class all_KL  =  0.693 +- 0.050, 0.850 +- 0.040, 0.954 +- 0.012, 1.000 +- 0.000
suff++_acc_int  =  0.756 +- 0.036, 0.786 +- 0.038, 0.792 +- 0.044
nec class all_L1  =  0.150 +- 0.032, 0.139 +- 0.030, 0.125 +- 0.025, 0.124 +- 0.024
nec class all_KL  =  0.134 +- 0.032, 0.094 +- 0.021, 0.069 +- 0.012, 0.066 +- 0.011
nec_acc_int  =  0.808 +- 0.031, 0.814 +- 0.029, 0.804 +- 0.034, 0.801 +- 0.038


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.465 +- 0.011, 0.495 +- 0.004, 0.540 +- 0.016
Faith. Armon (L1)= 		  =  0.171 +- 0.056, 0.145 +- 0.053, 0.147 +- 0.055
Faith. GMean (L1)= 	  =  0.277 +- 0.042, 0.264 +- 0.047, 0.278 +- 0.055
Faith. Aritm (KL)= 		  =  0.429 +- 0.023, 0.497 +- 0.006, 0.531 +- 0.017
Faith. Armon (KL)= 		  =  0.155 +- 0.059, 0.114 +- 0.057, 0.115 +- 0.058
Faith. GMean (KL)= 	  =  0.252 +- 0.042, 0.231 +- 0.059, 0.240 +- 0.066

Eval split val
Faith. Aritm (L1)= 		  =  0.435 +- 0.024, 0.470 +- 0.018, 0.512 +- 0.005, 0.543 +- 0.013
Faith. Armon (L1)= 		  =  0.187 +- 0.028, 0.160 +- 0.037, 0.156 +- 0.044, 0.157 +- 0.044
Faith. GMean (L1)= 	  =  0.284 +- 0.019, 0.272 +- 0.026, 0.280 +- 0.039, 0.289 +- 0.043
Faith. Aritm (KL)= 		  =  0.368 +- 0.038, 0.446 +- 0.031, 0.508 +- 0.004, 0.525 +- 0.009
Faith. Armon (KL)= 		  =  0.165 +- 0.021, 0.123 +- 0.026, 0.101 +- 0.035, 0.094 +- 0.032
Faith. GMean (KL)= 	  =  0.246 +- 0.020, 0.232 +- 0.019, 0.223 +- 0.037, 0.219 +- 0.037

Eval split test
Faith. Aritm (L1)= 		  =  0.461 +- 0.021, 0.486 +- 0.010, 0.516 +- 0.003, 0.562 +- 0.012
Faith. Armon (L1)= 		  =  0.249 +- 0.046, 0.236 +- 0.044, 0.219 +- 0.038, 0.220 +- 0.038
Faith. GMean (L1)= 	  =  0.337 +- 0.035, 0.337 +- 0.032, 0.335 +- 0.030, 0.351 +- 0.035
Faith. Aritm (KL)= 		  =  0.414 +- 0.029, 0.472 +- 0.014, 0.511 +- 0.003, 0.533 +- 0.006
Faith. Armon (KL)= 		  =  0.223 +- 0.044, 0.169 +- 0.034, 0.128 +- 0.020, 0.123 +- 0.020
Faith. GMean (KL)= 	  =  0.302 +- 0.037, 0.280 +- 0.029, 0.255 +- 0.021, 0.255 +- 0.022
Computed for split load_split = id



Completed in  0:18:25.327634  for LECIvGIN GOODSST2/length



DONE LECI GOODSST2/length

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 11:46:00 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:01 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:03 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:03 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:04 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:05 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:46:07 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 125...
[0m[1;37mINFO[0m: [1mCheckpoint 125: 
-----------------------------------
Train ACCURACY: 0.9996
Train Loss: 0.0053
ID Validation ACCURACY: 0.6913
ID Validation Loss: 1.4984
ID Test ACCURACY: 0.6643
ID Test Loss: 1.5778
OOD Validation ACCURACY: 0.6000
OOD Validation Loss: 1.8812
OOD Test ACCURACY: 0.5923
OOD Test Loss: 2.1106

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 20...
[0m[1;37mINFO[0m: [1mCheckpoint 20: 
-----------------------------------
Train ACCURACY: 0.7691
Train Loss: 0.5510
ID Validation ACCURACY: 0.6625
ID Validation Loss: 0.8397
ID Test ACCURACY: 0.6588
ID Test Loss: 0.8709
OOD Validation ACCURACY: 0.6224
OOD Validation Loss: 0.9873
OOD Test ACCURACY: 0.5834
OOD Test Loss: 1.0991

[0m[1;37mINFO[0m: [1mChartInfo 0.6643 0.5923 0.6588 0.5834 0.6625 0.6224[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.679
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.628
SUFF++ for r=0.3 class 0 = 0.701 +- 0.304 (in-sample avg dev_std = 0.574)
SUFF++ for r=0.3 class 1 = 0.733 +- 0.304 (in-sample avg dev_std = 0.574)
SUFF++ for r=0.3 class 2 = 0.657 +- 0.304 (in-sample avg dev_std = 0.574)
SUFF++ for r=0.3 all KL = 0.587 +- 0.304 (in-sample avg dev_std = 0.574)
SUFF++ for r=0.3 all L1 = 0.704 +- 0.207 (in-sample avg dev_std = 0.574)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.682
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.674
SUFF++ for r=0.6 class 0 = 0.824 +- 0.246 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.6 class 1 = 0.834 +- 0.246 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.6 class 2 = 0.811 +- 0.246 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.6 all KL = 0.801 +- 0.246 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.6 all L1 = 0.825 +- 0.198 (in-sample avg dev_std = 0.375)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.689
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.683
SUFF++ for r=0.9 class 0 = 0.876 +- 0.192 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 class 1 = 0.882 +- 0.192 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 class 2 = 0.88 +- 0.192 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 all KL = 0.891 +- 0.192 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 all L1 = 0.88 +- 0.178 (in-sample avg dev_std = 0.277)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.613
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.601
SUFF++ for r=0.3 class 0 = 0.765 +- 0.301 (in-sample avg dev_std = 0.514)
SUFF++ for r=0.3 class 1 = 0.721 +- 0.301 (in-sample avg dev_std = 0.514)
SUFF++ for r=0.3 class 2 = 0.705 +- 0.301 (in-sample avg dev_std = 0.514)
SUFF++ for r=0.3 all KL = 0.636 +- 0.301 (in-sample avg dev_std = 0.514)
SUFF++ for r=0.3 all L1 = 0.729 +- 0.211 (in-sample avg dev_std = 0.514)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.62
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.621
SUFF++ for r=0.6 class 0 = 0.842 +- 0.223 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 class 1 = 0.838 +- 0.223 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 class 2 = 0.831 +- 0.223 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 all KL = 0.828 +- 0.223 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 all L1 = 0.838 +- 0.185 (in-sample avg dev_std = 0.346)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.62
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.63
SUFF++ for r=0.9 class 0 = 0.882 +- 0.194 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 class 1 = 0.875 +- 0.194 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 class 2 = 0.851 +- 0.194 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 all KL = 0.889 +- 0.194 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 all L1 = 0.872 +- 0.178 (in-sample avg dev_std = 0.255)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.571
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.547
SUFF++ for r=0.3 class 0 = 0.8 +- 0.300 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.3 class 1 = 0.724 +- 0.300 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.3 class 2 = 0.7 +- 0.300 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.3 all KL = 0.646 +- 0.300 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.3 all L1 = 0.738 +- 0.211 (in-sample avg dev_std = 0.516)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.58
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.575
SUFF++ for r=0.6 class 0 = 0.869 +- 0.228 (in-sample avg dev_std = 0.340)
SUFF++ for r=0.6 class 1 = 0.84 +- 0.228 (in-sample avg dev_std = 0.340)
SUFF++ for r=0.6 class 2 = 0.813 +- 0.228 (in-sample avg dev_std = 0.340)
SUFF++ for r=0.6 all KL = 0.832 +- 0.228 (in-sample avg dev_std = 0.340)
SUFF++ for r=0.6 all L1 = 0.841 +- 0.189 (in-sample avg dev_std = 0.340)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.582
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.579
SUFF++ for r=0.9 class 0 = 0.905 +- 0.173 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 class 1 = 0.871 +- 0.173 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 class 2 = 0.859 +- 0.173 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 all KL = 0.902 +- 0.173 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 all L1 = 0.877 +- 0.170 (in-sample avg dev_std = 0.240)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.679
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.659
NEC for r=0.3 class 0 = 0.209 +- 0.278 (in-sample avg dev_std = 0.332)
NEC for r=0.3 class 1 = 0.205 +- 0.278 (in-sample avg dev_std = 0.332)
NEC for r=0.3 class 2 = 0.189 +- 0.278 (in-sample avg dev_std = 0.332)
NEC for r=0.3 all KL = 0.213 +- 0.278 (in-sample avg dev_std = 0.332)
NEC for r=0.3 all L1 = 0.201 +- 0.224 (in-sample avg dev_std = 0.332)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.682
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.679
NEC for r=0.6 class 0 = 0.169 +- 0.249 (in-sample avg dev_std = 0.297)
NEC for r=0.6 class 1 = 0.168 +- 0.249 (in-sample avg dev_std = 0.297)
NEC for r=0.6 class 2 = 0.166 +- 0.249 (in-sample avg dev_std = 0.297)
NEC for r=0.6 all KL = 0.168 +- 0.249 (in-sample avg dev_std = 0.297)
NEC for r=0.6 all L1 = 0.168 +- 0.211 (in-sample avg dev_std = 0.297)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.69
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.681
NEC for r=0.9 class 0 = 0.147 +- 0.208 (in-sample avg dev_std = 0.253)
NEC for r=0.9 class 1 = 0.129 +- 0.208 (in-sample avg dev_std = 0.253)
NEC for r=0.9 class 2 = 0.139 +- 0.208 (in-sample avg dev_std = 0.253)
NEC for r=0.9 all KL = 0.122 +- 0.208 (in-sample avg dev_std = 0.253)
NEC for r=0.9 all L1 = 0.136 +- 0.188 (in-sample avg dev_std = 0.253)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.688
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.682
NEC for r=1.0 class 0 = 0.144 +- 0.192 (in-sample avg dev_std = 0.246)
NEC for r=1.0 class 1 = 0.131 +- 0.192 (in-sample avg dev_std = 0.246)
NEC for r=1.0 class 2 = 0.132 +- 0.192 (in-sample avg dev_std = 0.246)
NEC for r=1.0 all KL = 0.115 +- 0.192 (in-sample avg dev_std = 0.246)
NEC for r=1.0 all L1 = 0.134 +- 0.186 (in-sample avg dev_std = 0.246)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.613
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.606
NEC for r=0.3 class 0 = 0.21 +- 0.297 (in-sample avg dev_std = 0.357)
NEC for r=0.3 class 1 = 0.24 +- 0.297 (in-sample avg dev_std = 0.357)
NEC for r=0.3 class 2 = 0.245 +- 0.297 (in-sample avg dev_std = 0.357)
NEC for r=0.3 all KL = 0.263 +- 0.297 (in-sample avg dev_std = 0.357)
NEC for r=0.3 all L1 = 0.233 +- 0.236 (in-sample avg dev_std = 0.357)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.62
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.626
NEC for r=0.6 class 0 = 0.165 +- 0.232 (in-sample avg dev_std = 0.277)
NEC for r=0.6 class 1 = 0.162 +- 0.232 (in-sample avg dev_std = 0.277)
NEC for r=0.6 class 2 = 0.166 +- 0.232 (in-sample avg dev_std = 0.277)
NEC for r=0.6 all KL = 0.16 +- 0.232 (in-sample avg dev_std = 0.277)
NEC for r=0.6 all L1 = 0.164 +- 0.197 (in-sample avg dev_std = 0.277)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.62
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.631
NEC for r=0.9 class 0 = 0.166 +- 0.210 (in-sample avg dev_std = 0.259)
NEC for r=0.9 class 1 = 0.141 +- 0.210 (in-sample avg dev_std = 0.259)
NEC for r=0.9 class 2 = 0.156 +- 0.210 (in-sample avg dev_std = 0.259)
NEC for r=0.9 all KL = 0.138 +- 0.210 (in-sample avg dev_std = 0.259)
NEC for r=0.9 all L1 = 0.151 +- 0.188 (in-sample avg dev_std = 0.259)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.62
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.629
NEC for r=1.0 class 0 = 0.162 +- 0.204 (in-sample avg dev_std = 0.254)
NEC for r=1.0 class 1 = 0.139 +- 0.204 (in-sample avg dev_std = 0.254)
NEC for r=1.0 class 2 = 0.151 +- 0.204 (in-sample avg dev_std = 0.254)
NEC for r=1.0 all KL = 0.13 +- 0.204 (in-sample avg dev_std = 0.254)
NEC for r=1.0 all L1 = 0.147 +- 0.187 (in-sample avg dev_std = 0.254)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.571
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.56
NEC for r=0.3 class 0 = 0.158 +- 0.283 (in-sample avg dev_std = 0.337)
NEC for r=0.3 class 1 = 0.242 +- 0.283 (in-sample avg dev_std = 0.337)
NEC for r=0.3 class 2 = 0.207 +- 0.283 (in-sample avg dev_std = 0.337)
NEC for r=0.3 all KL = 0.231 +- 0.283 (in-sample avg dev_std = 0.337)
NEC for r=0.3 all L1 = 0.211 +- 0.228 (in-sample avg dev_std = 0.337)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.58
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.574
NEC for r=0.6 class 0 = 0.129 +- 0.222 (in-sample avg dev_std = 0.275)
NEC for r=0.6 class 1 = 0.177 +- 0.222 (in-sample avg dev_std = 0.275)
NEC for r=0.6 class 2 = 0.175 +- 0.222 (in-sample avg dev_std = 0.275)
NEC for r=0.6 all KL = 0.158 +- 0.222 (in-sample avg dev_std = 0.275)
NEC for r=0.6 all L1 = 0.164 +- 0.199 (in-sample avg dev_std = 0.275)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.582
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.58
NEC for r=0.9 class 0 = 0.119 +- 0.192 (in-sample avg dev_std = 0.238)
NEC for r=0.9 class 1 = 0.156 +- 0.192 (in-sample avg dev_std = 0.238)
NEC for r=0.9 class 2 = 0.16 +- 0.192 (in-sample avg dev_std = 0.238)
NEC for r=0.9 all KL = 0.123 +- 0.192 (in-sample avg dev_std = 0.238)
NEC for r=0.9 all L1 = 0.147 +- 0.189 (in-sample avg dev_std = 0.238)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.585
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.577
NEC for r=1.0 class 0 = 0.121 +- 0.187 (in-sample avg dev_std = 0.244)
NEC for r=1.0 class 1 = 0.153 +- 0.187 (in-sample avg dev_std = 0.244)
NEC for r=1.0 class 2 = 0.156 +- 0.187 (in-sample avg dev_std = 0.244)
NEC for r=1.0 all KL = 0.12 +- 0.187 (in-sample avg dev_std = 0.244)
NEC for r=1.0 all L1 = 0.145 +- 0.183 (in-sample avg dev_std = 0.244)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 11:51:37 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:37 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:40 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:40 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:41 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:43 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:51:45 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 178...
[0m[1;37mINFO[0m: [1mCheckpoint 178: 
-----------------------------------
Train ACCURACY: 0.9992
Train Loss: 0.0102
ID Validation ACCURACY: 0.6949
ID Validation Loss: 1.7809
ID Test ACCURACY: 0.6570
ID Test Loss: 1.8897
OOD Validation ACCURACY: 0.6095
OOD Validation Loss: 2.1368
OOD Test ACCURACY: 0.5587
OOD Test Loss: 2.3329

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 65...
[0m[1;37mINFO[0m: [1mCheckpoint 65: 
-----------------------------------
Train ACCURACY: 0.9780
Train Loss: 0.0634
ID Validation ACCURACY: 0.6841
ID Validation Loss: 1.6394
ID Test ACCURACY: 0.6697
ID Test Loss: 1.7223
OOD Validation ACCURACY: 0.6375
OOD Validation Loss: 2.2701
OOD Test ACCURACY: 0.5752
OOD Test Loss: 3.5318

[0m[1;37mINFO[0m: [1mChartInfo 0.6570 0.5587 0.6697 0.5752 0.6841 0.6375[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.675
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.608
SUFF++ for r=0.3 class 0 = 0.72 +- 0.313 (in-sample avg dev_std = 0.647)
SUFF++ for r=0.3 class 1 = 0.666 +- 0.313 (in-sample avg dev_std = 0.647)
SUFF++ for r=0.3 class 2 = 0.685 +- 0.313 (in-sample avg dev_std = 0.647)
SUFF++ for r=0.3 all KL = 0.497 +- 0.313 (in-sample avg dev_std = 0.647)
SUFF++ for r=0.3 all L1 = 0.684 +- 0.203 (in-sample avg dev_std = 0.647)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.682
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.655
SUFF++ for r=0.6 class 0 = 0.828 +- 0.315 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 class 1 = 0.805 +- 0.315 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 class 2 = 0.793 +- 0.315 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 all KL = 0.714 +- 0.315 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 all L1 = 0.807 +- 0.203 (in-sample avg dev_std = 0.483)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.691
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.676
SUFF++ for r=0.9 class 0 = 0.904 +- 0.220 (in-sample avg dev_std = 0.309)
SUFF++ for r=0.9 class 1 = 0.894 +- 0.220 (in-sample avg dev_std = 0.309)
SUFF++ for r=0.9 class 2 = 0.887 +- 0.220 (in-sample avg dev_std = 0.309)
SUFF++ for r=0.9 all KL = 0.883 +- 0.220 (in-sample avg dev_std = 0.309)
SUFF++ for r=0.9 all L1 = 0.894 +- 0.176 (in-sample avg dev_std = 0.309)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.606
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.572
SUFF++ for r=0.3 class 0 = 0.759 +- 0.324 (in-sample avg dev_std = 0.605)
SUFF++ for r=0.3 class 1 = 0.697 +- 0.324 (in-sample avg dev_std = 0.605)
SUFF++ for r=0.3 class 2 = 0.662 +- 0.324 (in-sample avg dev_std = 0.605)
SUFF++ for r=0.3 all KL = 0.546 +- 0.324 (in-sample avg dev_std = 0.605)
SUFF++ for r=0.3 all L1 = 0.705 +- 0.210 (in-sample avg dev_std = 0.605)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.613
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.605
SUFF++ for r=0.6 class 0 = 0.844 +- 0.298 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 class 1 = 0.806 +- 0.298 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 class 2 = 0.773 +- 0.298 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 all KL = 0.729 +- 0.298 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 all L1 = 0.808 +- 0.200 (in-sample avg dev_std = 0.468)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.618
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.614
SUFF++ for r=0.9 class 0 = 0.889 +- 0.254 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.9 class 1 = 0.863 +- 0.254 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.9 class 2 = 0.849 +- 0.254 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.9 all KL = 0.85 +- 0.254 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.9 all L1 = 0.867 +- 0.200 (in-sample avg dev_std = 0.339)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.543
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.504
SUFF++ for r=0.3 class 0 = 0.766 +- 0.317 (in-sample avg dev_std = 0.620)
SUFF++ for r=0.3 class 1 = 0.703 +- 0.317 (in-sample avg dev_std = 0.620)
SUFF++ for r=0.3 class 2 = 0.651 +- 0.317 (in-sample avg dev_std = 0.620)
SUFF++ for r=0.3 all KL = 0.544 +- 0.317 (in-sample avg dev_std = 0.620)
SUFF++ for r=0.3 all L1 = 0.707 +- 0.213 (in-sample avg dev_std = 0.620)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.549
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.529
SUFF++ for r=0.6 class 0 = 0.851 +- 0.309 (in-sample avg dev_std = 0.487)
SUFF++ for r=0.6 class 1 = 0.798 +- 0.309 (in-sample avg dev_std = 0.487)
SUFF++ for r=0.6 class 2 = 0.759 +- 0.309 (in-sample avg dev_std = 0.487)
SUFF++ for r=0.6 all KL = 0.715 +- 0.309 (in-sample avg dev_std = 0.487)
SUFF++ for r=0.6 all L1 = 0.802 +- 0.206 (in-sample avg dev_std = 0.487)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.553
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.551
SUFF++ for r=0.9 class 0 = 0.891 +- 0.246 (in-sample avg dev_std = 0.318)
SUFF++ for r=0.9 class 1 = 0.857 +- 0.246 (in-sample avg dev_std = 0.318)
SUFF++ for r=0.9 class 2 = 0.852 +- 0.246 (in-sample avg dev_std = 0.318)
SUFF++ for r=0.9 all KL = 0.854 +- 0.246 (in-sample avg dev_std = 0.318)
SUFF++ for r=0.9 all L1 = 0.864 +- 0.201 (in-sample avg dev_std = 0.318)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.675
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.64
NEC for r=0.3 class 0 = 0.153 +- 0.296 (in-sample avg dev_std = 0.345)
NEC for r=0.3 class 1 = 0.232 +- 0.296 (in-sample avg dev_std = 0.345)
NEC for r=0.3 class 2 = 0.151 +- 0.296 (in-sample avg dev_std = 0.345)
NEC for r=0.3 all KL = 0.212 +- 0.296 (in-sample avg dev_std = 0.345)
NEC for r=0.3 all L1 = 0.19 +- 0.234 (in-sample avg dev_std = 0.345)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.682
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.665
NEC for r=0.6 class 0 = 0.127 +- 0.270 (in-sample avg dev_std = 0.303)
NEC for r=0.6 class 1 = 0.165 +- 0.270 (in-sample avg dev_std = 0.303)
NEC for r=0.6 class 2 = 0.131 +- 0.270 (in-sample avg dev_std = 0.303)
NEC for r=0.6 all KL = 0.163 +- 0.270 (in-sample avg dev_std = 0.303)
NEC for r=0.6 all L1 = 0.146 +- 0.215 (in-sample avg dev_std = 0.303)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.692
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.677
NEC for r=0.9 class 0 = 0.103 +- 0.233 (in-sample avg dev_std = 0.287)
NEC for r=0.9 class 1 = 0.124 +- 0.233 (in-sample avg dev_std = 0.287)
NEC for r=0.9 class 2 = 0.113 +- 0.233 (in-sample avg dev_std = 0.287)
NEC for r=0.9 all KL = 0.125 +- 0.233 (in-sample avg dev_std = 0.287)
NEC for r=0.9 all L1 = 0.116 +- 0.191 (in-sample avg dev_std = 0.287)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.693
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.669
NEC for r=1.0 class 0 = 0.104 +- 0.237 (in-sample avg dev_std = 0.281)
NEC for r=1.0 class 1 = 0.126 +- 0.237 (in-sample avg dev_std = 0.281)
NEC for r=1.0 class 2 = 0.107 +- 0.237 (in-sample avg dev_std = 0.281)
NEC for r=1.0 all KL = 0.119 +- 0.237 (in-sample avg dev_std = 0.281)
NEC for r=1.0 all L1 = 0.115 +- 0.195 (in-sample avg dev_std = 0.281)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.606
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.59
NEC for r=0.3 class 0 = 0.178 +- 0.305 (in-sample avg dev_std = 0.370)
NEC for r=0.3 class 1 = 0.22 +- 0.305 (in-sample avg dev_std = 0.370)
NEC for r=0.3 class 2 = 0.199 +- 0.305 (in-sample avg dev_std = 0.370)
NEC for r=0.3 all KL = 0.251 +- 0.305 (in-sample avg dev_std = 0.370)
NEC for r=0.3 all L1 = 0.205 +- 0.231 (in-sample avg dev_std = 0.370)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.613
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.607
NEC for r=0.6 class 0 = 0.148 +- 0.275 (in-sample avg dev_std = 0.337)
NEC for r=0.6 class 1 = 0.162 +- 0.275 (in-sample avg dev_std = 0.337)
NEC for r=0.6 class 2 = 0.157 +- 0.275 (in-sample avg dev_std = 0.337)
NEC for r=0.6 all KL = 0.18 +- 0.275 (in-sample avg dev_std = 0.337)
NEC for r=0.6 all L1 = 0.157 +- 0.216 (in-sample avg dev_std = 0.337)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.618
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.61
NEC for r=0.9 class 0 = 0.129 +- 0.267 (in-sample avg dev_std = 0.308)
NEC for r=0.9 class 1 = 0.141 +- 0.267 (in-sample avg dev_std = 0.308)
NEC for r=0.9 class 2 = 0.161 +- 0.267 (in-sample avg dev_std = 0.308)
NEC for r=0.9 all KL = 0.158 +- 0.267 (in-sample avg dev_std = 0.308)
NEC for r=0.9 all L1 = 0.142 +- 0.215 (in-sample avg dev_std = 0.308)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.619
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.616
NEC for r=1.0 class 0 = 0.129 +- 0.243 (in-sample avg dev_std = 0.304)
NEC for r=1.0 class 1 = 0.126 +- 0.243 (in-sample avg dev_std = 0.304)
NEC for r=1.0 class 2 = 0.141 +- 0.243 (in-sample avg dev_std = 0.304)
NEC for r=1.0 all KL = 0.139 +- 0.243 (in-sample avg dev_std = 0.304)
NEC for r=1.0 all L1 = 0.13 +- 0.201 (in-sample avg dev_std = 0.304)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.543
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.54
NEC for r=0.3 class 0 = 0.146 +- 0.280 (in-sample avg dev_std = 0.312)
NEC for r=0.3 class 1 = 0.205 +- 0.280 (in-sample avg dev_std = 0.312)
NEC for r=0.3 class 2 = 0.172 +- 0.280 (in-sample avg dev_std = 0.312)
NEC for r=0.3 all KL = 0.207 +- 0.280 (in-sample avg dev_std = 0.312)
NEC for r=0.3 all L1 = 0.181 +- 0.222 (in-sample avg dev_std = 0.312)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.549
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.55
NEC for r=0.6 class 0 = 0.108 +- 0.261 (in-sample avg dev_std = 0.305)
NEC for r=0.6 class 1 = 0.163 +- 0.261 (in-sample avg dev_std = 0.305)
NEC for r=0.6 class 2 = 0.133 +- 0.261 (in-sample avg dev_std = 0.305)
NEC for r=0.6 all KL = 0.153 +- 0.261 (in-sample avg dev_std = 0.305)
NEC for r=0.6 all L1 = 0.141 +- 0.211 (in-sample avg dev_std = 0.305)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.553
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.554
NEC for r=0.9 class 0 = 0.108 +- 0.248 (in-sample avg dev_std = 0.291)
NEC for r=0.9 class 1 = 0.147 +- 0.248 (in-sample avg dev_std = 0.291)
NEC for r=0.9 class 2 = 0.139 +- 0.248 (in-sample avg dev_std = 0.291)
NEC for r=0.9 all KL = 0.138 +- 0.248 (in-sample avg dev_std = 0.291)
NEC for r=0.9 all L1 = 0.135 +- 0.208 (in-sample avg dev_std = 0.291)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.551
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.555
NEC for r=1.0 class 0 = 0.102 +- 0.239 (in-sample avg dev_std = 0.283)
NEC for r=1.0 class 1 = 0.146 +- 0.239 (in-sample avg dev_std = 0.283)
NEC for r=1.0 class 2 = 0.139 +- 0.239 (in-sample avg dev_std = 0.283)
NEC for r=1.0 all KL = 0.133 +- 0.239 (in-sample avg dev_std = 0.283)
NEC for r=1.0 all L1 = 0.133 +- 0.205 (in-sample avg dev_std = 0.283)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 11:57:00 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:00 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:02 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:03 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:03 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:05 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 11:57:07 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 19...
[0m[1;37mINFO[0m: [1mCheckpoint 19: 
-----------------------------------
Train ACCURACY: 0.7618
Train Loss: 0.5823
ID Validation ACCURACY: 0.6968
ID Validation Loss: 0.7715
ID Test ACCURACY: 0.6588
ID Test Loss: 0.8122
OOD Validation ACCURACY: 0.6190
OOD Validation Loss: 0.9178
OOD Test ACCURACY: 0.5724
OOD Test Loss: 1.0630

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 75...
[0m[1;37mINFO[0m: [1mCheckpoint 75: 
-----------------------------------
Train ACCURACY: 0.9927
Train Loss: 0.0184
ID Validation ACCURACY: 0.6841
ID Validation Loss: 1.7075
ID Test ACCURACY: 0.6606
ID Test Loss: 1.8076
OOD Validation ACCURACY: 0.6275
OOD Validation Loss: 2.2657
OOD Test ACCURACY: 0.5594
OOD Test Loss: 3.3090

[0m[1;37mINFO[0m: [1mChartInfo 0.6588 0.5724 0.6606 0.5594 0.6841 0.6275[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.622
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.574
SUFF++ for r=0.3 class 0 = 0.657 +- 0.120 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.3 class 1 = 0.707 +- 0.120 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.3 class 2 = 0.705 +- 0.120 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.3 all KL = 0.835 +- 0.120 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.3 all L1 = 0.694 +- 0.109 (in-sample avg dev_std = 0.316)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.673
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.629
SUFF++ for r=0.6 class 0 = 0.697 +- 0.121 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.6 class 1 = 0.748 +- 0.121 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.6 class 2 = 0.749 +- 0.121 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.6 all KL = 0.867 +- 0.121 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.6 all L1 = 0.736 +- 0.121 (in-sample avg dev_std = 0.271)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.686
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.674
SUFF++ for r=0.9 class 0 = 0.804 +- 0.090 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.9 class 1 = 0.852 +- 0.090 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.9 class 2 = 0.848 +- 0.090 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.9 all KL = 0.941 +- 0.090 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.9 all L1 = 0.839 +- 0.117 (in-sample avg dev_std = 0.176)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.569
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.545
SUFF++ for r=0.3 class 0 = 0.67 +- 0.117 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 class 1 = 0.699 +- 0.117 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 class 2 = 0.697 +- 0.117 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 all KL = 0.843 +- 0.117 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 all L1 = 0.691 +- 0.111 (in-sample avg dev_std = 0.279)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.592
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.579
SUFF++ for r=0.6 class 0 = 0.736 +- 0.089 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.6 class 1 = 0.766 +- 0.089 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.6 class 2 = 0.761 +- 0.089 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.6 all KL = 0.897 +- 0.089 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.6 all L1 = 0.757 +- 0.108 (in-sample avg dev_std = 0.233)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.611
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.598
SUFF++ for r=0.9 class 0 = 0.8 +- 0.071 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.9 class 1 = 0.824 +- 0.071 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.9 class 2 = 0.82 +- 0.071 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.9 all KL = 0.938 +- 0.071 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.9 all L1 = 0.817 +- 0.111 (in-sample avg dev_std = 0.157)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.54
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.519
SUFF++ for r=0.3 class 0 = 0.721 +- 0.101 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 class 1 = 0.719 +- 0.101 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 class 2 = 0.724 +- 0.101 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 all KL = 0.873 +- 0.101 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 all L1 = 0.72 +- 0.110 (in-sample avg dev_std = 0.252)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.548
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.547
SUFF++ for r=0.6 class 0 = 0.776 +- 0.083 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.6 class 1 = 0.765 +- 0.083 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.6 class 2 = 0.77 +- 0.083 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.6 all KL = 0.906 +- 0.083 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.6 all L1 = 0.769 +- 0.115 (in-sample avg dev_std = 0.216)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.565
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.548
SUFF++ for r=0.9 class 0 = 0.836 +- 0.064 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.9 class 1 = 0.822 +- 0.064 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.9 class 2 = 0.814 +- 0.064 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.9 all KL = 0.941 +- 0.064 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.9 all L1 = 0.823 +- 0.110 (in-sample avg dev_std = 0.156)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.622
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.617
NEC for r=0.3 class 0 = 0.255 +- 0.127 (in-sample avg dev_std = 0.207)
NEC for r=0.3 class 1 = 0.224 +- 0.127 (in-sample avg dev_std = 0.207)
NEC for r=0.3 class 2 = 0.232 +- 0.127 (in-sample avg dev_std = 0.207)
NEC for r=0.3 all KL = 0.101 +- 0.127 (in-sample avg dev_std = 0.207)
NEC for r=0.3 all L1 = 0.234 +- 0.143 (in-sample avg dev_std = 0.207)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.673
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.65
NEC for r=0.6 class 0 = 0.239 +- 0.101 (in-sample avg dev_std = 0.189)
NEC for r=0.6 class 1 = 0.203 +- 0.101 (in-sample avg dev_std = 0.189)
NEC for r=0.6 class 2 = 0.219 +- 0.101 (in-sample avg dev_std = 0.189)
NEC for r=0.6 all KL = 0.084 +- 0.101 (in-sample avg dev_std = 0.189)
NEC for r=0.6 all L1 = 0.216 +- 0.123 (in-sample avg dev_std = 0.189)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.688
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.664
NEC for r=0.9 class 0 = 0.218 +- 0.091 (in-sample avg dev_std = 0.168)
NEC for r=0.9 class 1 = 0.169 +- 0.091 (in-sample avg dev_std = 0.168)
NEC for r=0.9 class 2 = 0.192 +- 0.091 (in-sample avg dev_std = 0.168)
NEC for r=0.9 all KL = 0.069 +- 0.091 (in-sample avg dev_std = 0.168)
NEC for r=0.9 all L1 = 0.187 +- 0.123 (in-sample avg dev_std = 0.168)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.692
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.661
NEC for r=1.0 class 0 = 0.214 +- 0.094 (in-sample avg dev_std = 0.173)
NEC for r=1.0 class 1 = 0.173 +- 0.094 (in-sample avg dev_std = 0.173)
NEC for r=1.0 class 2 = 0.186 +- 0.094 (in-sample avg dev_std = 0.173)
NEC for r=1.0 all KL = 0.069 +- 0.094 (in-sample avg dev_std = 0.173)
NEC for r=1.0 all L1 = 0.187 +- 0.122 (in-sample avg dev_std = 0.173)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.569
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.573
NEC for r=0.3 class 0 = 0.283 +- 0.111 (in-sample avg dev_std = 0.209)
NEC for r=0.3 class 1 = 0.271 +- 0.111 (in-sample avg dev_std = 0.209)
NEC for r=0.3 class 2 = 0.276 +- 0.111 (in-sample avg dev_std = 0.209)
NEC for r=0.3 all KL = 0.117 +- 0.111 (in-sample avg dev_std = 0.209)
NEC for r=0.3 all L1 = 0.275 +- 0.121 (in-sample avg dev_std = 0.209)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.592
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.581
NEC for r=0.6 class 0 = 0.24 +- 0.092 (in-sample avg dev_std = 0.182)
NEC for r=0.6 class 1 = 0.214 +- 0.092 (in-sample avg dev_std = 0.182)
NEC for r=0.6 class 2 = 0.217 +- 0.092 (in-sample avg dev_std = 0.182)
NEC for r=0.6 all KL = 0.081 +- 0.092 (in-sample avg dev_std = 0.182)
NEC for r=0.6 all L1 = 0.221 +- 0.118 (in-sample avg dev_std = 0.182)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.611
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.605
NEC for r=0.9 class 0 = 0.205 +- 0.079 (in-sample avg dev_std = 0.161)
NEC for r=0.9 class 1 = 0.187 +- 0.079 (in-sample avg dev_std = 0.161)
NEC for r=0.9 class 2 = 0.187 +- 0.079 (in-sample avg dev_std = 0.161)
NEC for r=0.9 all KL = 0.066 +- 0.079 (in-sample avg dev_std = 0.161)
NEC for r=0.9 all L1 = 0.191 +- 0.116 (in-sample avg dev_std = 0.161)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.616
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.608
NEC for r=1.0 class 0 = 0.191 +- 0.073 (in-sample avg dev_std = 0.153)
NEC for r=1.0 class 1 = 0.176 +- 0.073 (in-sample avg dev_std = 0.153)
NEC for r=1.0 class 2 = 0.176 +- 0.073 (in-sample avg dev_std = 0.153)
NEC for r=1.0 all KL = 0.059 +- 0.073 (in-sample avg dev_std = 0.153)
NEC for r=1.0 all L1 = 0.18 +- 0.111 (in-sample avg dev_std = 0.153)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.54
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.536
NEC for r=0.3 class 0 = 0.267 +- 0.105 (in-sample avg dev_std = 0.200)
NEC for r=0.3 class 1 = 0.261 +- 0.105 (in-sample avg dev_std = 0.200)
NEC for r=0.3 class 2 = 0.268 +- 0.105 (in-sample avg dev_std = 0.200)
NEC for r=0.3 all KL = 0.108 +- 0.105 (in-sample avg dev_std = 0.200)
NEC for r=0.3 all L1 = 0.264 +- 0.126 (in-sample avg dev_std = 0.200)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.548
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.559
NEC for r=0.6 class 0 = 0.221 +- 0.087 (in-sample avg dev_std = 0.185)
NEC for r=0.6 class 1 = 0.221 +- 0.087 (in-sample avg dev_std = 0.185)
NEC for r=0.6 class 2 = 0.228 +- 0.087 (in-sample avg dev_std = 0.185)
NEC for r=0.6 all KL = 0.084 +- 0.087 (in-sample avg dev_std = 0.185)
NEC for r=0.6 all L1 = 0.222 +- 0.126 (in-sample avg dev_std = 0.185)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.565
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.565
NEC for r=0.9 class 0 = 0.175 +- 0.075 (in-sample avg dev_std = 0.164)
NEC for r=0.9 class 1 = 0.19 +- 0.075 (in-sample avg dev_std = 0.164)
NEC for r=0.9 class 2 = 0.195 +- 0.075 (in-sample avg dev_std = 0.164)
NEC for r=0.9 all KL = 0.065 +- 0.075 (in-sample avg dev_std = 0.164)
NEC for r=0.9 all L1 = 0.187 +- 0.118 (in-sample avg dev_std = 0.164)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.579
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.573
NEC for r=1.0 class 0 = 0.164 +- 0.066 (in-sample avg dev_std = 0.152)
NEC for r=1.0 class 1 = 0.183 +- 0.066 (in-sample avg dev_std = 0.152)
NEC for r=1.0 class 2 = 0.18 +- 0.066 (in-sample avg dev_std = 0.152)
NEC for r=1.0 all KL = 0.058 +- 0.066 (in-sample avg dev_std = 0.152)
NEC for r=1.0 all L1 = 0.177 +- 0.112 (in-sample avg dev_std = 0.152)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 12:02:03 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:03 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:06 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:06 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:07 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:08 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:11 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:02:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:11 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:02:11 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:02:11 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 101...
[0m[1;37mINFO[0m: [1mCheckpoint 101: 
-----------------------------------
Train ACCURACY: 0.9992
Train Loss: 0.0046
ID Validation ACCURACY: 0.7058
ID Validation Loss: 1.9005
ID Test ACCURACY: 0.6552
ID Test Loss: 2.3023
OOD Validation ACCURACY: 0.6403
OOD Validation Loss: 2.6631
OOD Test ACCURACY: 0.5738
OOD Test Loss: 3.3149

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 101...
[0m[1;37mINFO[0m: [1mCheckpoint 101: 
-----------------------------------
Train ACCURACY: 0.9992
Train Loss: 0.0046
ID Validation ACCURACY: 0.7058
ID Validation Loss: 1.9005
ID Test ACCURACY: 0.6552
ID Test Loss: 2.3023
OOD Validation ACCURACY: 0.6403
OOD Validation Loss: 2.6631
OOD Test ACCURACY: 0.5738
OOD Test Loss: 3.3149

[0m[1;37mINFO[0m: [1mChartInfo 0.6552 0.5738 0.6552 0.5738 0.7058 0.6403[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.692
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.648
SUFF++ for r=0.3 class 0 = 0.77 +- 0.317 (in-sample avg dev_std = 0.540)
SUFF++ for r=0.3 class 1 = 0.801 +- 0.317 (in-sample avg dev_std = 0.540)
SUFF++ for r=0.3 class 2 = 0.7 +- 0.317 (in-sample avg dev_std = 0.540)
SUFF++ for r=0.3 all KL = 0.64 +- 0.317 (in-sample avg dev_std = 0.540)
SUFF++ for r=0.3 all L1 = 0.765 +- 0.212 (in-sample avg dev_std = 0.540)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.697
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.682
SUFF++ for r=0.6 class 0 = 0.866 +- 0.275 (in-sample avg dev_std = 0.377)
SUFF++ for r=0.6 class 1 = 0.879 +- 0.275 (in-sample avg dev_std = 0.377)
SUFF++ for r=0.6 class 2 = 0.825 +- 0.275 (in-sample avg dev_std = 0.377)
SUFF++ for r=0.6 all KL = 0.819 +- 0.275 (in-sample avg dev_std = 0.377)
SUFF++ for r=0.6 all L1 = 0.861 +- 0.203 (in-sample avg dev_std = 0.377)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.7
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.695
SUFF++ for r=0.9 class 0 = 0.902 +- 0.199 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 class 1 = 0.924 +- 0.199 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 class 2 = 0.895 +- 0.199 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 all KL = 0.908 +- 0.199 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 all L1 = 0.911 +- 0.166 (in-sample avg dev_std = 0.255)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.641
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.612
SUFF++ for r=0.3 class 0 = 0.783 +- 0.346 (in-sample avg dev_std = 0.527)
SUFF++ for r=0.3 class 1 = 0.827 +- 0.346 (in-sample avg dev_std = 0.527)
SUFF++ for r=0.3 class 2 = 0.72 +- 0.346 (in-sample avg dev_std = 0.527)
SUFF++ for r=0.3 all KL = 0.652 +- 0.346 (in-sample avg dev_std = 0.527)
SUFF++ for r=0.3 all L1 = 0.793 +- 0.221 (in-sample avg dev_std = 0.527)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.645
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.635
SUFF++ for r=0.6 class 0 = 0.845 +- 0.295 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.6 class 1 = 0.884 +- 0.295 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.6 class 2 = 0.808 +- 0.295 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.6 all KL = 0.8 +- 0.295 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.6 all L1 = 0.858 +- 0.212 (in-sample avg dev_std = 0.398)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.644
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.64
SUFF++ for r=0.9 class 0 = 0.882 +- 0.233 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 1 = 0.91 +- 0.233 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 2 = 0.857 +- 0.233 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 all KL = 0.879 +- 0.233 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 all L1 = 0.891 +- 0.190 (in-sample avg dev_std = 0.285)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.569
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.536
SUFF++ for r=0.3 class 0 = 0.838 +- 0.347 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.3 class 1 = 0.786 +- 0.347 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.3 class 2 = 0.707 +- 0.347 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.3 all KL = 0.633 +- 0.347 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.3 all L1 = 0.78 +- 0.224 (in-sample avg dev_std = 0.550)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.558
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.548
SUFF++ for r=0.6 class 0 = 0.889 +- 0.308 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.6 class 1 = 0.848 +- 0.308 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.6 class 2 = 0.784 +- 0.308 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.6 all KL = 0.77 +- 0.308 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.6 all L1 = 0.843 +- 0.212 (in-sample avg dev_std = 0.426)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.565
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.553
SUFF++ for r=0.9 class 0 = 0.917 +- 0.223 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 class 1 = 0.892 +- 0.223 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 class 2 = 0.852 +- 0.223 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 all KL = 0.878 +- 0.223 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 all L1 = 0.889 +- 0.186 (in-sample avg dev_std = 0.279)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.692
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.674
NEC for r=0.3 class 0 = 0.197 +- 0.294 (in-sample avg dev_std = 0.320)
NEC for r=0.3 class 1 = 0.142 +- 0.294 (in-sample avg dev_std = 0.320)
NEC for r=0.3 class 2 = 0.174 +- 0.294 (in-sample avg dev_std = 0.320)
NEC for r=0.3 all KL = 0.195 +- 0.294 (in-sample avg dev_std = 0.320)
NEC for r=0.3 all L1 = 0.165 +- 0.222 (in-sample avg dev_std = 0.320)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.697
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.69
NEC for r=0.6 class 0 = 0.115 +- 0.250 (in-sample avg dev_std = 0.268)
NEC for r=0.6 class 1 = 0.104 +- 0.250 (in-sample avg dev_std = 0.268)
NEC for r=0.6 class 2 = 0.15 +- 0.250 (in-sample avg dev_std = 0.268)
NEC for r=0.6 all KL = 0.136 +- 0.250 (in-sample avg dev_std = 0.268)
NEC for r=0.6 all L1 = 0.119 +- 0.197 (in-sample avg dev_std = 0.268)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.701
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.688
NEC for r=0.9 class 0 = 0.11 +- 0.211 (in-sample avg dev_std = 0.243)
NEC for r=0.9 class 1 = 0.086 +- 0.211 (in-sample avg dev_std = 0.243)
NEC for r=0.9 class 2 = 0.124 +- 0.211 (in-sample avg dev_std = 0.243)
NEC for r=0.9 all KL = 0.106 +- 0.211 (in-sample avg dev_std = 0.243)
NEC for r=0.9 all L1 = 0.102 +- 0.171 (in-sample avg dev_std = 0.243)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.704
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.688
NEC for r=1.0 class 0 = 0.108 +- 0.206 (in-sample avg dev_std = 0.248)
NEC for r=1.0 class 1 = 0.089 +- 0.206 (in-sample avg dev_std = 0.248)
NEC for r=1.0 class 2 = 0.128 +- 0.206 (in-sample avg dev_std = 0.248)
NEC for r=1.0 all KL = 0.107 +- 0.206 (in-sample avg dev_std = 0.248)
NEC for r=1.0 all L1 = 0.104 +- 0.171 (in-sample avg dev_std = 0.248)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.641
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.634
NEC for r=0.3 class 0 = 0.164 +- 0.317 (in-sample avg dev_std = 0.353)
NEC for r=0.3 class 1 = 0.137 +- 0.317 (in-sample avg dev_std = 0.353)
NEC for r=0.3 class 2 = 0.186 +- 0.317 (in-sample avg dev_std = 0.353)
NEC for r=0.3 all KL = 0.214 +- 0.317 (in-sample avg dev_std = 0.353)
NEC for r=0.3 all L1 = 0.154 +- 0.227 (in-sample avg dev_std = 0.353)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.645
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.635
NEC for r=0.6 class 0 = 0.136 +- 0.282 (in-sample avg dev_std = 0.323)
NEC for r=0.6 class 1 = 0.108 +- 0.282 (in-sample avg dev_std = 0.323)
NEC for r=0.6 class 2 = 0.161 +- 0.282 (in-sample avg dev_std = 0.323)
NEC for r=0.6 all KL = 0.162 +- 0.282 (in-sample avg dev_std = 0.323)
NEC for r=0.6 all L1 = 0.126 +- 0.206 (in-sample avg dev_std = 0.323)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.644
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.638
NEC for r=0.9 class 0 = 0.135 +- 0.259 (in-sample avg dev_std = 0.287)
NEC for r=0.9 class 1 = 0.108 +- 0.259 (in-sample avg dev_std = 0.287)
NEC for r=0.9 class 2 = 0.152 +- 0.259 (in-sample avg dev_std = 0.287)
NEC for r=0.9 all KL = 0.141 +- 0.259 (in-sample avg dev_std = 0.287)
NEC for r=0.9 all L1 = 0.124 +- 0.206 (in-sample avg dev_std = 0.287)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.646
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.639
NEC for r=1.0 class 0 = 0.131 +- 0.243 (in-sample avg dev_std = 0.274)
NEC for r=1.0 class 1 = 0.105 +- 0.243 (in-sample avg dev_std = 0.274)
NEC for r=1.0 class 2 = 0.152 +- 0.243 (in-sample avg dev_std = 0.274)
NEC for r=1.0 all KL = 0.134 +- 0.243 (in-sample avg dev_std = 0.274)
NEC for r=1.0 all L1 = 0.122 +- 0.200 (in-sample avg dev_std = 0.274)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.569
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.56
NEC for r=0.3 class 0 = 0.123 +- 0.302 (in-sample avg dev_std = 0.353)
NEC for r=0.3 class 1 = 0.156 +- 0.302 (in-sample avg dev_std = 0.353)
NEC for r=0.3 class 2 = 0.193 +- 0.302 (in-sample avg dev_std = 0.353)
NEC for r=0.3 all KL = 0.208 +- 0.302 (in-sample avg dev_std = 0.353)
NEC for r=0.3 all L1 = 0.157 +- 0.222 (in-sample avg dev_std = 0.353)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.558
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.564
NEC for r=0.6 class 0 = 0.107 +- 0.272 (in-sample avg dev_std = 0.302)
NEC for r=0.6 class 1 = 0.127 +- 0.272 (in-sample avg dev_std = 0.302)
NEC for r=0.6 class 2 = 0.153 +- 0.272 (in-sample avg dev_std = 0.302)
NEC for r=0.6 all KL = 0.159 +- 0.272 (in-sample avg dev_std = 0.302)
NEC for r=0.6 all L1 = 0.128 +- 0.211 (in-sample avg dev_std = 0.302)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.565
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.564
NEC for r=0.9 class 0 = 0.104 +- 0.247 (in-sample avg dev_std = 0.279)
NEC for r=0.9 class 1 = 0.122 +- 0.247 (in-sample avg dev_std = 0.279)
NEC for r=0.9 class 2 = 0.15 +- 0.247 (in-sample avg dev_std = 0.279)
NEC for r=0.9 all KL = 0.139 +- 0.247 (in-sample avg dev_std = 0.279)
NEC for r=0.9 all L1 = 0.124 +- 0.199 (in-sample avg dev_std = 0.279)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.565
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.566
NEC for r=1.0 class 0 = 0.108 +- 0.239 (in-sample avg dev_std = 0.271)
NEC for r=1.0 class 1 = 0.12 +- 0.239 (in-sample avg dev_std = 0.271)
NEC for r=1.0 class 2 = 0.158 +- 0.239 (in-sample avg dev_std = 0.271)
NEC for r=1.0 all KL = 0.134 +- 0.239 (in-sample avg dev_std = 0.271)
NEC for r=1.0 all L1 = 0.126 +- 0.201 (in-sample avg dev_std = 0.271)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 12:07:06 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:06 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:09 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:09 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:10 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:12 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:13 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:13 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:13 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:07:14 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 146...
[0m[1;37mINFO[0m: [1mCheckpoint 146: 
-----------------------------------
Train ACCURACY: 0.9992
Train Loss: 0.0088
ID Validation ACCURACY: 0.6913
ID Validation Loss: 1.5860
ID Test ACCURACY: 0.6625
ID Test Loss: 1.7535
OOD Validation ACCURACY: 0.5994
OOD Validation Loss: 2.0521
OOD Test ACCURACY: 0.5504
OOD Test Loss: 2.4742

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 80...
[0m[1;37mINFO[0m: [1mCheckpoint 80: 
-----------------------------------
Train ACCURACY: 0.9915
Train Loss: 0.0302
ID Validation ACCURACY: 0.6805
ID Validation Loss: 1.9979
ID Test ACCURACY: 0.6534
ID Test Loss: 2.1197
OOD Validation ACCURACY: 0.6409
OOD Validation Loss: 2.5939
OOD Test ACCURACY: 0.5655
OOD Test Loss: 3.5479

[0m[1;37mINFO[0m: [1mChartInfo 0.6625 0.5504 0.6534 0.5655 0.6805 0.6409[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.679
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.612
SUFF++ for r=0.3 class 0 = 0.721 +- 0.300 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.3 class 1 = 0.689 +- 0.300 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.3 class 2 = 0.674 +- 0.300 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.3 all KL = 0.556 +- 0.300 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.3 all L1 = 0.693 +- 0.202 (in-sample avg dev_std = 0.586)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.686
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.665
SUFF++ for r=0.6 class 0 = 0.831 +- 0.254 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 class 1 = 0.822 +- 0.254 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 class 2 = 0.807 +- 0.254 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 all KL = 0.789 +- 0.254 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 all L1 = 0.82 +- 0.192 (in-sample avg dev_std = 0.392)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.686
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.679
SUFF++ for r=0.9 class 0 = 0.873 +- 0.203 (in-sample avg dev_std = 0.286)
SUFF++ for r=0.9 class 1 = 0.876 +- 0.203 (in-sample avg dev_std = 0.286)
SUFF++ for r=0.9 class 2 = 0.883 +- 0.203 (in-sample avg dev_std = 0.286)
SUFF++ for r=0.9 all KL = 0.883 +- 0.203 (in-sample avg dev_std = 0.286)
SUFF++ for r=0.9 all L1 = 0.877 +- 0.176 (in-sample avg dev_std = 0.286)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.59
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.565
SUFF++ for r=0.3 class 0 = 0.802 +- 0.302 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.3 class 1 = 0.663 +- 0.302 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.3 class 2 = 0.643 +- 0.302 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.3 all KL = 0.571 +- 0.302 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.3 all L1 = 0.694 +- 0.205 (in-sample avg dev_std = 0.568)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.608
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.598
SUFF++ for r=0.6 class 0 = 0.866 +- 0.263 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 class 1 = 0.794 +- 0.263 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 class 2 = 0.774 +- 0.263 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 all KL = 0.773 +- 0.263 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 all L1 = 0.808 +- 0.194 (in-sample avg dev_std = 0.417)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.604
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.601
SUFF++ for r=0.9 class 0 = 0.902 +- 0.209 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 1 = 0.858 +- 0.209 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 2 = 0.831 +- 0.209 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 all KL = 0.874 +- 0.209 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 all L1 = 0.863 +- 0.182 (in-sample avg dev_std = 0.276)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.535
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.511
SUFF++ for r=0.3 class 0 = 0.818 +- 0.312 (in-sample avg dev_std = 0.549)
SUFF++ for r=0.3 class 1 = 0.684 +- 0.312 (in-sample avg dev_std = 0.549)
SUFF++ for r=0.3 class 2 = 0.706 +- 0.312 (in-sample avg dev_std = 0.549)
SUFF++ for r=0.3 all KL = 0.608 +- 0.312 (in-sample avg dev_std = 0.549)
SUFF++ for r=0.3 all L1 = 0.724 +- 0.208 (in-sample avg dev_std = 0.549)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.543
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 799
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.535
SUFF++ for r=0.6 class 0 = 0.889 +- 0.257 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.6 class 1 = 0.806 +- 0.257 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.6 class 2 = 0.819 +- 0.257 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.6 all KL = 0.794 +- 0.257 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.6 all L1 = 0.831 +- 0.189 (in-sample avg dev_std = 0.387)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.55
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.542
SUFF++ for r=0.9 class 0 = 0.913 +- 0.208 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 class 1 = 0.851 +- 0.208 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 class 2 = 0.865 +- 0.208 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 all KL = 0.879 +- 0.208 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 all L1 = 0.871 +- 0.187 (in-sample avg dev_std = 0.277)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.679
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.657
NEC for r=0.3 class 0 = 0.194 +- 0.279 (in-sample avg dev_std = 0.338)
NEC for r=0.3 class 1 = 0.23 +- 0.279 (in-sample avg dev_std = 0.338)
NEC for r=0.3 class 2 = 0.179 +- 0.279 (in-sample avg dev_std = 0.338)
NEC for r=0.3 all KL = 0.225 +- 0.279 (in-sample avg dev_std = 0.338)
NEC for r=0.3 all L1 = 0.207 +- 0.220 (in-sample avg dev_std = 0.338)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.686
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.669
NEC for r=0.6 class 0 = 0.171 +- 0.234 (in-sample avg dev_std = 0.306)
NEC for r=0.6 class 1 = 0.168 +- 0.234 (in-sample avg dev_std = 0.306)
NEC for r=0.6 class 2 = 0.152 +- 0.234 (in-sample avg dev_std = 0.306)
NEC for r=0.6 all KL = 0.167 +- 0.234 (in-sample avg dev_std = 0.306)
NEC for r=0.6 all L1 = 0.164 +- 0.194 (in-sample avg dev_std = 0.306)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.688
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.674
NEC for r=0.9 class 0 = 0.145 +- 0.206 (in-sample avg dev_std = 0.268)
NEC for r=0.9 class 1 = 0.133 +- 0.206 (in-sample avg dev_std = 0.268)
NEC for r=0.9 class 2 = 0.137 +- 0.206 (in-sample avg dev_std = 0.268)
NEC for r=0.9 all KL = 0.128 +- 0.206 (in-sample avg dev_std = 0.268)
NEC for r=0.9 all L1 = 0.137 +- 0.181 (in-sample avg dev_std = 0.268)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.688
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.672
NEC for r=1.0 class 0 = 0.145 +- 0.214 (in-sample avg dev_std = 0.272)
NEC for r=1.0 class 1 = 0.136 +- 0.214 (in-sample avg dev_std = 0.272)
NEC for r=1.0 class 2 = 0.15 +- 0.214 (in-sample avg dev_std = 0.272)
NEC for r=1.0 all KL = 0.131 +- 0.214 (in-sample avg dev_std = 0.272)
NEC for r=1.0 all L1 = 0.142 +- 0.191 (in-sample avg dev_std = 0.272)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.59
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.585
NEC for r=0.3 class 0 = 0.145 +- 0.295 (in-sample avg dev_std = 0.358)
NEC for r=0.3 class 1 = 0.258 +- 0.295 (in-sample avg dev_std = 0.358)
NEC for r=0.3 class 2 = 0.257 +- 0.295 (in-sample avg dev_std = 0.358)
NEC for r=0.3 all KL = 0.252 +- 0.295 (in-sample avg dev_std = 0.358)
NEC for r=0.3 all L1 = 0.229 +- 0.227 (in-sample avg dev_std = 0.358)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.608
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.601
NEC for r=0.6 class 0 = 0.135 +- 0.254 (in-sample avg dev_std = 0.324)
NEC for r=0.6 class 1 = 0.197 +- 0.254 (in-sample avg dev_std = 0.324)
NEC for r=0.6 class 2 = 0.209 +- 0.254 (in-sample avg dev_std = 0.324)
NEC for r=0.6 all KL = 0.193 +- 0.254 (in-sample avg dev_std = 0.324)
NEC for r=0.6 all L1 = 0.184 +- 0.204 (in-sample avg dev_std = 0.324)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.604
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.603
NEC for r=0.9 class 0 = 0.117 +- 0.233 (in-sample avg dev_std = 0.300)
NEC for r=0.9 class 1 = 0.174 +- 0.233 (in-sample avg dev_std = 0.300)
NEC for r=0.9 class 2 = 0.189 +- 0.233 (in-sample avg dev_std = 0.300)
NEC for r=0.9 all KL = 0.159 +- 0.233 (in-sample avg dev_std = 0.300)
NEC for r=0.9 all L1 = 0.163 +- 0.194 (in-sample avg dev_std = 0.300)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.606
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.601
NEC for r=1.0 class 0 = 0.115 +- 0.226 (in-sample avg dev_std = 0.289)
NEC for r=1.0 class 1 = 0.163 +- 0.226 (in-sample avg dev_std = 0.289)
NEC for r=1.0 class 2 = 0.184 +- 0.226 (in-sample avg dev_std = 0.289)
NEC for r=1.0 all KL = 0.148 +- 0.226 (in-sample avg dev_std = 0.289)
NEC for r=1.0 all L1 = 0.156 +- 0.192 (in-sample avg dev_std = 0.289)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.535
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.527
NEC for r=0.3 class 0 = 0.147 +- 0.279 (in-sample avg dev_std = 0.334)
NEC for r=0.3 class 1 = 0.242 +- 0.279 (in-sample avg dev_std = 0.334)
NEC for r=0.3 class 2 = 0.222 +- 0.279 (in-sample avg dev_std = 0.334)
NEC for r=0.3 all KL = 0.237 +- 0.279 (in-sample avg dev_std = 0.334)
NEC for r=0.3 all L1 = 0.212 +- 0.216 (in-sample avg dev_std = 0.334)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.543
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.539
NEC for r=0.6 class 0 = 0.11 +- 0.248 (in-sample avg dev_std = 0.300)
NEC for r=0.6 class 1 = 0.186 +- 0.248 (in-sample avg dev_std = 0.300)
NEC for r=0.6 class 2 = 0.166 +- 0.248 (in-sample avg dev_std = 0.300)
NEC for r=0.6 all KL = 0.173 +- 0.248 (in-sample avg dev_std = 0.300)
NEC for r=0.6 all L1 = 0.161 +- 0.200 (in-sample avg dev_std = 0.300)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.55
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.544
NEC for r=0.9 class 0 = 0.1 +- 0.220 (in-sample avg dev_std = 0.274)
NEC for r=0.9 class 1 = 0.168 +- 0.220 (in-sample avg dev_std = 0.274)
NEC for r=0.9 class 2 = 0.152 +- 0.220 (in-sample avg dev_std = 0.274)
NEC for r=0.9 all KL = 0.141 +- 0.220 (in-sample avg dev_std = 0.274)
NEC for r=0.9 all L1 = 0.146 +- 0.193 (in-sample avg dev_std = 0.274)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.546
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.541
NEC for r=1.0 class 0 = 0.101 +- 0.213 (in-sample avg dev_std = 0.264)
NEC for r=1.0 class 1 = 0.162 +- 0.213 (in-sample avg dev_std = 0.264)
NEC for r=1.0 class 2 = 0.149 +- 0.213 (in-sample avg dev_std = 0.264)
NEC for r=1.0 all KL = 0.132 +- 0.213 (in-sample avg dev_std = 0.264)
NEC for r=1.0 all L1 = 0.143 +- 0.192 (in-sample avg dev_std = 0.264)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.587, 0.801, 0.891, 1.0], 'all_L1': [0.704, 0.825, 0.88, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.497, 0.714, 0.883, 1.0], 'all_L1': [0.684, 0.807, 0.894, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.835, 0.867, 0.941, 1.0], 'all_L1': [0.694, 0.736, 0.839, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.64, 0.819, 0.908, 1.0], 'all_L1': [0.765, 0.861, 0.911, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.556, 0.789, 0.883, 1.0], 'all_L1': [0.693, 0.82, 0.877, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.213, 0.168, 0.122, 0.115], 'all_L1': [0.201, 0.168, 0.136, 0.134]}), defaultdict(<class 'list'>, {'all_KL': [0.212, 0.163, 0.125, 0.119], 'all_L1': [0.19, 0.146, 0.116, 0.115]}), defaultdict(<class 'list'>, {'all_KL': [0.101, 0.084, 0.069, 0.069], 'all_L1': [0.234, 0.216, 0.187, 0.187]}), defaultdict(<class 'list'>, {'all_KL': [0.195, 0.136, 0.106, 0.107], 'all_L1': [0.165, 0.119, 0.102, 0.104]}), defaultdict(<class 'list'>, {'all_KL': [0.225, 0.167, 0.128, 0.131], 'all_L1': [0.207, 0.164, 0.137, 0.142]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.636, 0.828, 0.889, 1.0], 'all_L1': [0.729, 0.838, 0.872, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.546, 0.729, 0.85, 1.0], 'all_L1': [0.705, 0.808, 0.867, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.843, 0.897, 0.938, 1.0], 'all_L1': [0.691, 0.757, 0.817, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.652, 0.8, 0.879, 1.0], 'all_L1': [0.793, 0.858, 0.891, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.571, 0.773, 0.874, 1.0], 'all_L1': [0.694, 0.808, 0.863, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.263, 0.16, 0.138, 0.13], 'all_L1': [0.233, 0.164, 0.151, 0.147]}), defaultdict(<class 'list'>, {'all_KL': [0.251, 0.18, 0.158, 0.139], 'all_L1': [0.205, 0.157, 0.142, 0.13]}), defaultdict(<class 'list'>, {'all_KL': [0.117, 0.081, 0.066, 0.059], 'all_L1': [0.275, 0.221, 0.191, 0.18]}), defaultdict(<class 'list'>, {'all_KL': [0.214, 0.162, 0.141, 0.134], 'all_L1': [0.154, 0.126, 0.124, 0.122]}), defaultdict(<class 'list'>, {'all_KL': [0.252, 0.193, 0.159, 0.148], 'all_L1': [0.229, 0.184, 0.163, 0.156]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.646, 0.832, 0.902, 1.0], 'all_L1': [0.738, 0.841, 0.877, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.544, 0.715, 0.854, 1.0], 'all_L1': [0.707, 0.802, 0.864, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.873, 0.906, 0.941, 1.0], 'all_L1': [0.72, 0.769, 0.823, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.633, 0.77, 0.878, 1.0], 'all_L1': [0.78, 0.843, 0.889, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.608, 0.794, 0.879, 1.0], 'all_L1': [0.724, 0.831, 0.871, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.231, 0.158, 0.123, 0.12], 'all_L1': [0.211, 0.164, 0.147, 0.145]}), defaultdict(<class 'list'>, {'all_KL': [0.207, 0.153, 0.138, 0.133], 'all_L1': [0.181, 0.141, 0.135, 0.133]}), defaultdict(<class 'list'>, {'all_KL': [0.108, 0.084, 0.065, 0.058], 'all_L1': [0.264, 0.222, 0.187, 0.177]}), defaultdict(<class 'list'>, {'all_KL': [0.208, 0.159, 0.139, 0.134], 'all_L1': [0.157, 0.128, 0.124, 0.126]}), defaultdict(<class 'list'>, {'all_KL': [0.237, 0.173, 0.141, 0.132], 'all_L1': [0.212, 0.161, 0.146, 0.143]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.708 +- 0.029, 0.810 +- 0.041, 0.880 +- 0.024, 1.000 +- 0.000
suff++ class all_KL  =  0.623 +- 0.116, 0.798 +- 0.050, 0.901 +- 0.022, 1.000 +- 0.000
suff++_acc_int  =  0.614 +- 0.024, 0.661 +- 0.019, 0.681 +- 0.008
nec class all_L1  =  0.199 +- 0.022, 0.163 +- 0.032, 0.136 +- 0.029, 0.136 +- 0.029
nec class all_KL  =  0.189 +- 0.045, 0.144 +- 0.032, 0.110 +- 0.022, 0.108 +- 0.021
nec_acc_int  =  0.649 +- 0.019, 0.671 +- 0.013, 0.677 +- 0.008, 0.675 +- 0.010

Eval split val
suff++ class all_L1  =  0.722 +- 0.038, 0.814 +- 0.034, 0.862 +- 0.024, 1.000 +- 0.000
suff++ class all_KL  =  0.650 +- 0.104, 0.805 +- 0.056, 0.886 +- 0.029, 1.000 +- 0.000
suff++_acc_int  =  0.579 +- 0.024, 0.608 +- 0.019, 0.617 +- 0.016
nec class all_L1  =  0.219 +- 0.040, 0.170 +- 0.031, 0.154 +- 0.022, 0.147 +- 0.020
nec class all_KL  =  0.219 +- 0.054, 0.155 +- 0.039, 0.132 +- 0.034, 0.122 +- 0.032
nec_acc_int  =  0.597 +- 0.021, 0.610 +- 0.019, 0.618 +- 0.014, 0.619 +- 0.014

Eval split test
suff++ class all_L1  =  0.734 +- 0.025, 0.817 +- 0.028, 0.865 +- 0.022, 1.000 +- 0.000
suff++ class all_KL  =  0.661 +- 0.112, 0.803 +- 0.064, 0.891 +- 0.029, 1.000 +- 0.000
suff++_acc_int  =  0.523 +- 0.016, 0.547 +- 0.016, 0.555 +- 0.013
nec class all_L1  =  0.205 +- 0.036, 0.163 +- 0.032, 0.148 +- 0.021, 0.145 +- 0.018
nec class all_KL  =  0.198 +- 0.047, 0.145 +- 0.031, 0.121 +- 0.029, 0.115 +- 0.029
nec_acc_int  =  0.544 +- 0.013, 0.557 +- 0.012, 0.561 +- 0.012, 0.562 +- 0.013


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.454 +- 0.010, 0.486 +- 0.008, 0.508 +- 0.003, 0.568 +- 0.014
Faith. Armon (L1)= 		  =  0.310 +- 0.026, 0.269 +- 0.041, 0.233 +- 0.041, 0.239 +- 0.044
Faith. GMean (L1)= 	  =  0.375 +- 0.017, 0.360 +- 0.027, 0.343 +- 0.031, 0.367 +- 0.038
Faith. Aritm (KL)= 		  =  0.406 +- 0.037, 0.471 +- 0.016, 0.506 +- 0.001, 0.554 +- 0.011
Faith. Armon (KL)= 		  =  0.282 +- 0.052, 0.241 +- 0.047, 0.195 +- 0.035, 0.195 +- 0.035
Faith. GMean (KL)= 	  =  0.335 +- 0.025, 0.335 +- 0.035, 0.313 +- 0.030, 0.327 +- 0.034

Eval split val
Faith. Aritm (L1)= 		  =  0.471 +- 0.011, 0.492 +- 0.006, 0.508 +- 0.004, 0.574 +- 0.010
Faith. Armon (L1)= 		  =  0.333 +- 0.045, 0.280 +- 0.041, 0.261 +- 0.031, 0.256 +- 0.031
Faith. GMean (L1)= 	  =  0.395 +- 0.029, 0.370 +- 0.027, 0.363 +- 0.021, 0.382 +- 0.026
Faith. Aritm (KL)= 		  =  0.434 +- 0.029, 0.480 +- 0.014, 0.509 +- 0.006, 0.561 +- 0.016
Faith. Armon (KL)= 		  =  0.319 +- 0.059, 0.257 +- 0.056, 0.228 +- 0.054, 0.216 +- 0.053
Faith. GMean (KL)= 	  =  0.369 +- 0.031, 0.348 +- 0.041, 0.338 +- 0.045, 0.345 +- 0.052

Eval split test
Faith. Aritm (L1)= 		  =  0.469 +- 0.015, 0.490 +- 0.011, 0.506 +- 0.004, 0.572 +- 0.009
Faith. Armon (L1)= 		  =  0.318 +- 0.042, 0.270 +- 0.042, 0.252 +- 0.029, 0.253 +- 0.026
Faith. GMean (L1)= 	  =  0.386 +- 0.031, 0.363 +- 0.030, 0.356 +- 0.021, 0.380 +- 0.022
Faith. Aritm (KL)= 		  =  0.430 +- 0.037, 0.474 +- 0.023, 0.506 +- 0.006, 0.558 +- 0.015
Faith. Armon (KL)= 		  =  0.297 +- 0.055, 0.244 +- 0.046, 0.212 +- 0.046, 0.206 +- 0.049
Faith. GMean (KL)= 	  =  0.354 +- 0.029, 0.338 +- 0.034, 0.325 +- 0.039, 0.336 +- 0.048
Computed for split load_split = id



Completed in  0:25:57.841550  for LECIvGIN GOODTwitter/length



DONE LECI GOODTwitter/length

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 12:12:17 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:17 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:29 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:31 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:33 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:36 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:42 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:42 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:12:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:42 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:12:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:12:43 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 164...
[0m[1;37mINFO[0m: [1mCheckpoint 164: 
-----------------------------------
Train ACCURACY: 0.8111
Train Loss: 0.7638
ID Validation ACCURACY: 0.8277
ID Validation Loss: 0.7376
ID Test ACCURACY: 0.8170
ID Test Loss: 0.7535
OOD Validation ACCURACY: 0.5343
OOD Validation Loss: 0.9193
OOD Test ACCURACY: 0.4477
OOD Test Loss: 1.0321

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 192...
[0m[1;37mINFO[0m: [1mCheckpoint 192: 
-----------------------------------
Train ACCURACY: 0.6806
Train Loss: 0.8009
ID Validation ACCURACY: 0.6837
ID Validation Loss: 0.7816
ID Test ACCURACY: 0.6920
ID Test Loss: 0.7902
OOD Validation ACCURACY: 0.6747
OOD Validation Loss: 0.8524
OOD Test ACCURACY: 0.4377
OOD Test Loss: 3.6345

[0m[1;37mINFO[0m: [1mChartInfo 0.8170 0.4477 0.6920 0.4377 0.6837 0.6747[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.510
WIoU for r=0.3 = 0.627
F1 for r=0.6 = 0.461
WIoU for r=0.6 = 0.673
F1 for r=0.9 = 0.463
WIoU for r=0.9 = 0.678
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.678
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.348
WIoU for r=0.3 = 0.616
F1 for r=0.6 = 0.228
WIoU for r=0.6 = 0.616
F1 for r=0.9 = 0.199
WIoU for r=0.9 = 0.618
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.618
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.248
WIoU for r=0.3 = 0.587
F1 for r=0.6 = 0.142
WIoU for r=0.6 = 0.585
F1 for r=0.9 = 0.109
WIoU for r=0.9 = 0.585
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.585


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.636
Model XAI F1 of binarized graphs for r=0.3 =  0.50971875
Model XAI WIoU of binarized graphs for r=0.3 =  0.6270725
len(reference) = 797
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.462
SUFF++ for r=0.3 class 0 = 0.688 +- 0.209 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.3 class 1 = 0.64 +- 0.209 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.3 class 2 = 0.707 +- 0.209 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.3 all KL = 0.736 +- 0.209 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.3 all L1 = 0.679 +- 0.199 (in-sample avg dev_std = 0.451)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.71
Model XAI F1 of binarized graphs for r=0.6 =  0.46057875000000004
Model XAI WIoU of binarized graphs for r=0.6 =  0.6728037499999999
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.52
SUFF++ for r=0.6 class 0 = 0.557 +- 0.222 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.6 class 1 = 0.753 +- 0.222 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.6 class 2 = 0.659 +- 0.222 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.6 all KL = 0.735 +- 0.222 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.6 all L1 = 0.655 +- 0.207 (in-sample avg dev_std = 0.411)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.78
Model XAI F1 of binarized graphs for r=0.9 =  0.46310625
Model XAI WIoU of binarized graphs for r=0.9 =  0.6775887500000001
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.701
SUFF++ for r=0.9 class 0 = 0.723 +- 0.137 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 class 1 = 0.858 +- 0.137 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 class 2 = 0.683 +- 0.137 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 all KL = 0.871 +- 0.137 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 all L1 = 0.753 +- 0.173 (in-sample avg dev_std = 0.279)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.638
Model XAI F1 of binarized graphs for r=0.3 =  0.34846250000000006
Model XAI WIoU of binarized graphs for r=0.3 =  0.61582
len(reference) = 793
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.512
SUFF++ for r=0.3 class 0 = 0.664 +- 0.178 (in-sample avg dev_std = 0.418)
SUFF++ for r=0.3 class 1 = 0.593 +- 0.178 (in-sample avg dev_std = 0.418)
SUFF++ for r=0.3 class 2 = 0.63 +- 0.178 (in-sample avg dev_std = 0.418)
SUFF++ for r=0.3 all KL = 0.738 +- 0.178 (in-sample avg dev_std = 0.418)
SUFF++ for r=0.3 all L1 = 0.63 +- 0.174 (in-sample avg dev_std = 0.418)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.709
Model XAI F1 of binarized graphs for r=0.6 =  0.22785125
Model XAI WIoU of binarized graphs for r=0.6 =  0.615825
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.589
SUFF++ for r=0.6 class 0 = 0.621 +- 0.159 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.6 class 1 = 0.728 +- 0.159 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.6 class 2 = 0.604 +- 0.159 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.6 all KL = 0.802 +- 0.159 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.6 all L1 = 0.652 +- 0.157 (in-sample avg dev_std = 0.337)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.606
Model XAI F1 of binarized graphs for r=0.9 =  0.19947875
Model XAI WIoU of binarized graphs for r=0.9 =  0.6178087499999999
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.549
SUFF++ for r=0.9 class 0 = 0.733 +- 0.114 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.9 class 1 = 0.836 +- 0.114 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.9 class 2 = 0.742 +- 0.114 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.9 all KL = 0.917 +- 0.114 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.9 all L1 = 0.771 +- 0.133 (in-sample avg dev_std = 0.190)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.567
Model XAI F1 of binarized graphs for r=0.3 =  0.24797874999999997
Model XAI WIoU of binarized graphs for r=0.3 =  0.58656125
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.503
SUFF++ for r=0.3 class 0 = 0.619 +- 0.193 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.3 class 1 = 0.583 +- 0.193 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.3 class 2 = 0.488 +- 0.193 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.3 all KL = 0.701 +- 0.193 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.3 all L1 = 0.565 +- 0.197 (in-sample avg dev_std = 0.304)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.468
Model XAI F1 of binarized graphs for r=0.6 =  0.14207999999999998
Model XAI WIoU of binarized graphs for r=0.6 =  0.58465875
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.452
SUFF++ for r=0.6 class 0 = 0.619 +- 0.145 (in-sample avg dev_std = 0.356)
SUFF++ for r=0.6 class 1 = 0.668 +- 0.145 (in-sample avg dev_std = 0.356)
SUFF++ for r=0.6 class 2 = 0.585 +- 0.145 (in-sample avg dev_std = 0.356)
SUFF++ for r=0.6 all KL = 0.779 +- 0.145 (in-sample avg dev_std = 0.356)
SUFF++ for r=0.6 all L1 = 0.625 +- 0.166 (in-sample avg dev_std = 0.356)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.426
Model XAI F1 of binarized graphs for r=0.9 =  0.10910875
Model XAI WIoU of binarized graphs for r=0.9 =  0.58465375
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.42
SUFF++ for r=0.9 class 0 = 0.733 +- 0.113 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.9 class 1 = 0.83 +- 0.113 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.9 class 2 = 0.737 +- 0.113 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.9 all KL = 0.901 +- 0.113 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.9 all L1 = 0.768 +- 0.153 (in-sample avg dev_std = 0.269)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.636
Model XAI F1 of binarized graphs for r=0.3 =  0.50971875
Model XAI WIoU of binarized graphs for r=0.3 =  0.6270725
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.37
NEC for r=0.3 class 0 = 0.616 +- 0.304 (in-sample avg dev_std = 0.373)
NEC for r=0.3 class 1 = 0.187 +- 0.304 (in-sample avg dev_std = 0.373)
NEC for r=0.3 class 2 = 0.584 +- 0.304 (in-sample avg dev_std = 0.373)
NEC for r=0.3 all KL = 0.448 +- 0.304 (in-sample avg dev_std = 0.373)
NEC for r=0.3 all L1 = 0.466 +- 0.280 (in-sample avg dev_std = 0.373)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.71
Model XAI F1 of binarized graphs for r=0.6 =  0.46057875000000004
Model XAI WIoU of binarized graphs for r=0.6 =  0.6728037499999999
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.454
NEC for r=0.6 class 0 = 0.525 +- 0.291 (in-sample avg dev_std = 0.383)
NEC for r=0.6 class 1 = 0.164 +- 0.291 (in-sample avg dev_std = 0.383)
NEC for r=0.6 class 2 = 0.565 +- 0.291 (in-sample avg dev_std = 0.383)
NEC for r=0.6 all KL = 0.371 +- 0.291 (in-sample avg dev_std = 0.383)
NEC for r=0.6 all L1 = 0.422 +- 0.260 (in-sample avg dev_std = 0.383)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.781
Model XAI F1 of binarized graphs for r=0.9 =  0.46310625
Model XAI WIoU of binarized graphs for r=0.9 =  0.6775887500000001
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.508
NEC for r=0.9 class 0 = 0.447 +- 0.240 (in-sample avg dev_std = 0.328)
NEC for r=0.9 class 1 = 0.161 +- 0.240 (in-sample avg dev_std = 0.328)
NEC for r=0.9 class 2 = 0.479 +- 0.240 (in-sample avg dev_std = 0.328)
NEC for r=0.9 all KL = 0.264 +- 0.240 (in-sample avg dev_std = 0.328)
NEC for r=0.9 all L1 = 0.365 +- 0.235 (in-sample avg dev_std = 0.328)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.815
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.67781375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.519
NEC for r=1.0 class 0 = 0.436 +- 0.228 (in-sample avg dev_std = 0.309)
NEC for r=1.0 class 1 = 0.151 +- 0.228 (in-sample avg dev_std = 0.309)
NEC for r=1.0 class 2 = 0.458 +- 0.228 (in-sample avg dev_std = 0.309)
NEC for r=1.0 all KL = 0.239 +- 0.228 (in-sample avg dev_std = 0.309)
NEC for r=1.0 all L1 = 0.351 +- 0.230 (in-sample avg dev_std = 0.309)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.644
Model XAI F1 of binarized graphs for r=0.3 =  0.34846250000000006
Model XAI WIoU of binarized graphs for r=0.3 =  0.61582
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.407
NEC for r=0.3 class 0 = 0.568 +- 0.273 (in-sample avg dev_std = 0.280)
NEC for r=0.3 class 1 = 0.265 +- 0.273 (in-sample avg dev_std = 0.280)
NEC for r=0.3 class 2 = 0.58 +- 0.273 (in-sample avg dev_std = 0.280)
NEC for r=0.3 all KL = 0.373 +- 0.273 (in-sample avg dev_std = 0.280)
NEC for r=0.3 all L1 = 0.47 +- 0.237 (in-sample avg dev_std = 0.280)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.709
Model XAI F1 of binarized graphs for r=0.6 =  0.22785125
Model XAI WIoU of binarized graphs for r=0.6 =  0.615825
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.506
NEC for r=0.6 class 0 = 0.394 +- 0.213 (in-sample avg dev_std = 0.247)
NEC for r=0.6 class 1 = 0.177 +- 0.213 (in-sample avg dev_std = 0.247)
NEC for r=0.6 class 2 = 0.403 +- 0.213 (in-sample avg dev_std = 0.247)
NEC for r=0.6 all KL = 0.183 +- 0.213 (in-sample avg dev_std = 0.247)
NEC for r=0.6 all L1 = 0.324 +- 0.195 (in-sample avg dev_std = 0.247)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.605
Model XAI F1 of binarized graphs for r=0.9 =  0.19947875
Model XAI WIoU of binarized graphs for r=0.9 =  0.6178087499999999
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.498
NEC for r=0.9 class 0 = 0.312 +- 0.176 (in-sample avg dev_std = 0.209)
NEC for r=0.9 class 1 = 0.152 +- 0.176 (in-sample avg dev_std = 0.209)
NEC for r=0.9 class 2 = 0.315 +- 0.176 (in-sample avg dev_std = 0.209)
NEC for r=0.9 all KL = 0.122 +- 0.176 (in-sample avg dev_std = 0.209)
NEC for r=0.9 all L1 = 0.259 +- 0.181 (in-sample avg dev_std = 0.209)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.553
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.6182424999999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.479
NEC for r=1.0 class 0 = 0.288 +- 0.153 (in-sample avg dev_std = 0.196)
NEC for r=1.0 class 1 = 0.15 +- 0.153 (in-sample avg dev_std = 0.196)
NEC for r=1.0 class 2 = 0.292 +- 0.153 (in-sample avg dev_std = 0.196)
NEC for r=1.0 all KL = 0.105 +- 0.153 (in-sample avg dev_std = 0.196)
NEC for r=1.0 all L1 = 0.243 +- 0.174 (in-sample avg dev_std = 0.196)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.571
Model XAI F1 of binarized graphs for r=0.3 =  0.24797874999999997
Model XAI WIoU of binarized graphs for r=0.3 =  0.58656125
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.38
NEC for r=0.3 class 0 = 0.486 +- 0.278 (in-sample avg dev_std = 0.200)
NEC for r=0.3 class 1 = 0.347 +- 0.278 (in-sample avg dev_std = 0.200)
NEC for r=0.3 class 2 = 0.517 +- 0.278 (in-sample avg dev_std = 0.200)
NEC for r=0.3 all KL = 0.325 +- 0.278 (in-sample avg dev_std = 0.200)
NEC for r=0.3 all L1 = 0.448 +- 0.221 (in-sample avg dev_std = 0.200)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.471
Model XAI F1 of binarized graphs for r=0.6 =  0.14207999999999998
Model XAI WIoU of binarized graphs for r=0.6 =  0.58465875
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.411
NEC for r=0.6 class 0 = 0.32 +- 0.169 (in-sample avg dev_std = 0.184)
NEC for r=0.6 class 1 = 0.223 +- 0.169 (in-sample avg dev_std = 0.184)
NEC for r=0.6 class 2 = 0.353 +- 0.169 (in-sample avg dev_std = 0.184)
NEC for r=0.6 all KL = 0.142 +- 0.169 (in-sample avg dev_std = 0.184)
NEC for r=0.6 all L1 = 0.297 +- 0.192 (in-sample avg dev_std = 0.184)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.425
Model XAI F1 of binarized graphs for r=0.9 =  0.10910875
Model XAI WIoU of binarized graphs for r=0.9 =  0.58465375
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.4
NEC for r=0.9 class 0 = 0.256 +- 0.085 (in-sample avg dev_std = 0.161)
NEC for r=0.9 class 1 = 0.177 +- 0.085 (in-sample avg dev_std = 0.161)
NEC for r=0.9 class 2 = 0.273 +- 0.085 (in-sample avg dev_std = 0.161)
NEC for r=0.9 all KL = 0.077 +- 0.085 (in-sample avg dev_std = 0.161)
NEC for r=0.9 all L1 = 0.234 +- 0.149 (in-sample avg dev_std = 0.161)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.424
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.58465375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.388
NEC for r=1.0 class 0 = 0.238 +- 0.073 (in-sample avg dev_std = 0.150)
NEC for r=1.0 class 1 = 0.165 +- 0.073 (in-sample avg dev_std = 0.150)
NEC for r=1.0 class 2 = 0.249 +- 0.073 (in-sample avg dev_std = 0.150)
NEC for r=1.0 all KL = 0.064 +- 0.073 (in-sample avg dev_std = 0.150)
NEC for r=1.0 all L1 = 0.216 +- 0.138 (in-sample avg dev_std = 0.150)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 12:18:46 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/22/2024 12:18:46 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/22/2024 12:18:58 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:00 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:02 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:05 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:11 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:11 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:19:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:11 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:19:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:19:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:19:12 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 181...
[0m[1;37mINFO[0m: [1mCheckpoint 181: 
-----------------------------------
Train ACCURACY: 0.7951
Train Loss: 0.7744
ID Validation ACCURACY: 0.8013
ID Validation Loss: 0.7588
ID Test ACCURACY: 0.8053
ID Test Loss: 0.7591
OOD Validation ACCURACY: 0.6087
OOD Validation Loss: 0.9123
OOD Test ACCURACY: 0.3450
OOD Test Loss: 1.1474

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 168...
[0m[1;37mINFO[0m: [1mCheckpoint 168: 
-----------------------------------
Train ACCURACY: 0.6173
Train Loss: 0.9334
ID Validation ACCURACY: 0.6200
ID Validation Loss: 0.9227
ID Test ACCURACY: 0.6327
ID Test Loss: 0.9114
OOD Validation ACCURACY: 0.6463
OOD Validation Loss: 0.8722
OOD Test ACCURACY: 0.3960
OOD Test Loss: 1.0734

[0m[1;37mINFO[0m: [1mChartInfo 0.8053 0.3450 0.6327 0.3960 0.6200 0.6463[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.517
WIoU for r=0.3 = 0.708
F1 for r=0.6 = 0.444
WIoU for r=0.6 = 0.735
F1 for r=0.9 = 0.469
WIoU for r=0.9 = 0.738
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.738
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.372
WIoU for r=0.3 = 0.718
F1 for r=0.6 = 0.243
WIoU for r=0.6 = 0.710
F1 for r=0.9 = 0.207
WIoU for r=0.9 = 0.706
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.706
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.259
WIoU for r=0.3 = 0.560
F1 for r=0.6 = 0.157
WIoU for r=0.6 = 0.557
F1 for r=0.9 = 0.110
WIoU for r=0.9 = 0.555
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.554


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.586
Model XAI F1 of binarized graphs for r=0.3 =  0.5167225000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.7081425
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.437
SUFF++ for r=0.3 class 0 = 0.534 +- 0.296 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.3 class 1 = 0.663 +- 0.296 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.3 class 2 = 0.576 +- 0.296 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.3 all KL = 0.574 +- 0.296 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.3 all L1 = 0.59 +- 0.207 (in-sample avg dev_std = 0.567)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.629
Model XAI F1 of binarized graphs for r=0.6 =  0.44433374999999997
Model XAI WIoU of binarized graphs for r=0.6 =  0.7354587499999999
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.451
SUFF++ for r=0.6 class 0 = 0.457 +- 0.260 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 class 1 = 0.718 +- 0.260 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 class 2 = 0.597 +- 0.260 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 all KL = 0.646 +- 0.260 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 all L1 = 0.588 +- 0.209 (in-sample avg dev_std = 0.456)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.715
Model XAI F1 of binarized graphs for r=0.9 =  0.4686975
Model XAI WIoU of binarized graphs for r=0.9 =  0.737975
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.568
SUFF++ for r=0.9 class 0 = 0.596 +- 0.218 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.9 class 1 = 0.803 +- 0.218 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.9 class 2 = 0.645 +- 0.218 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.9 all KL = 0.783 +- 0.218 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.9 all L1 = 0.679 +- 0.220 (in-sample avg dev_std = 0.334)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.61
Model XAI F1 of binarized graphs for r=0.3 =  0.37196375000000004
Model XAI WIoU of binarized graphs for r=0.3 =  0.7184625
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.483
SUFF++ for r=0.3 class 0 = 0.482 +- 0.238 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 class 1 = 0.655 +- 0.238 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 class 2 = 0.502 +- 0.238 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 all KL = 0.617 +- 0.238 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 all L1 = 0.546 +- 0.174 (in-sample avg dev_std = 0.470)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.661
Model XAI F1 of binarized graphs for r=0.6 =  0.24302999999999997
Model XAI WIoU of binarized graphs for r=0.6 =  0.70982
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.543
SUFF++ for r=0.6 class 0 = 0.539 +- 0.189 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.6 class 1 = 0.765 +- 0.189 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.6 class 2 = 0.586 +- 0.189 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.6 all KL = 0.778 +- 0.189 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.6 all L1 = 0.63 +- 0.174 (in-sample avg dev_std = 0.327)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.654
Model XAI F1 of binarized graphs for r=0.9 =  0.20665875
Model XAI WIoU of binarized graphs for r=0.9 =  0.70609625
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.496
SUFF++ for r=0.9 class 0 = 0.629 +- 0.119 (in-sample avg dev_std = 0.206)
SUFF++ for r=0.9 class 1 = 0.808 +- 0.119 (in-sample avg dev_std = 0.206)
SUFF++ for r=0.9 class 2 = 0.743 +- 0.119 (in-sample avg dev_std = 0.206)
SUFF++ for r=0.9 all KL = 0.888 +- 0.119 (in-sample avg dev_std = 0.206)
SUFF++ for r=0.9 all L1 = 0.726 +- 0.148 (in-sample avg dev_std = 0.206)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.463
Model XAI F1 of binarized graphs for r=0.3 =  0.25948875
Model XAI WIoU of binarized graphs for r=0.3 =  0.5604012500000001
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.549
SUFF++ for r=0.3 class 0 = 0.556 +- 0.176 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.3 class 1 = 0.678 +- 0.176 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.3 class 2 = 0.513 +- 0.176 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.3 all KL = 0.735 +- 0.176 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.3 all L1 = 0.584 +- 0.160 (in-sample avg dev_std = 0.362)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.466
Model XAI F1 of binarized graphs for r=0.6 =  0.15715
Model XAI WIoU of binarized graphs for r=0.6 =  0.5570725
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.487
SUFF++ for r=0.6 class 0 = 0.694 +- 0.144 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.6 class 1 = 0.772 +- 0.144 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.6 class 2 = 0.646 +- 0.144 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.6 all KL = 0.855 +- 0.144 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.6 all L1 = 0.705 +- 0.157 (in-sample avg dev_std = 0.264)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.411
Model XAI F1 of binarized graphs for r=0.9 =  0.11041875000000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.55467625
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.405
SUFF++ for r=0.9 class 0 = 0.752 +- 0.120 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.9 class 1 = 0.799 +- 0.120 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.9 class 2 = 0.738 +- 0.120 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.9 all KL = 0.892 +- 0.120 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.9 all L1 = 0.763 +- 0.161 (in-sample avg dev_std = 0.262)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.585
Model XAI F1 of binarized graphs for r=0.3 =  0.5167225000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.7081425
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.374
NEC for r=0.3 class 0 = 0.575 +- 0.318 (in-sample avg dev_std = 0.385)
NEC for r=0.3 class 1 = 0.241 +- 0.318 (in-sample avg dev_std = 0.385)
NEC for r=0.3 class 2 = 0.602 +- 0.318 (in-sample avg dev_std = 0.385)
NEC for r=0.3 all KL = 0.494 +- 0.318 (in-sample avg dev_std = 0.385)
NEC for r=0.3 all L1 = 0.476 +- 0.271 (in-sample avg dev_std = 0.385)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.629
Model XAI F1 of binarized graphs for r=0.6 =  0.44433374999999997
Model XAI WIoU of binarized graphs for r=0.6 =  0.7354587499999999
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.448
NEC for r=0.6 class 0 = 0.47 +- 0.260 (in-sample avg dev_std = 0.381)
NEC for r=0.6 class 1 = 0.213 +- 0.260 (in-sample avg dev_std = 0.381)
NEC for r=0.6 class 2 = 0.544 +- 0.260 (in-sample avg dev_std = 0.381)
NEC for r=0.6 all KL = 0.351 +- 0.260 (in-sample avg dev_std = 0.381)
NEC for r=0.6 all L1 = 0.412 +- 0.236 (in-sample avg dev_std = 0.381)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.715
Model XAI F1 of binarized graphs for r=0.9 =  0.4686975
Model XAI WIoU of binarized graphs for r=0.9 =  0.737975
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.471
NEC for r=0.9 class 0 = 0.484 +- 0.240 (in-sample avg dev_std = 0.313)
NEC for r=0.9 class 1 = 0.207 +- 0.240 (in-sample avg dev_std = 0.313)
NEC for r=0.9 class 2 = 0.456 +- 0.240 (in-sample avg dev_std = 0.313)
NEC for r=0.9 all KL = 0.273 +- 0.240 (in-sample avg dev_std = 0.313)
NEC for r=0.9 all L1 = 0.385 +- 0.233 (in-sample avg dev_std = 0.313)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.756
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.7383325
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.472
NEC for r=1.0 class 0 = 0.474 +- 0.230 (in-sample avg dev_std = 0.295)
NEC for r=1.0 class 1 = 0.2 +- 0.230 (in-sample avg dev_std = 0.295)
NEC for r=1.0 class 2 = 0.443 +- 0.230 (in-sample avg dev_std = 0.295)
NEC for r=1.0 all KL = 0.258 +- 0.230 (in-sample avg dev_std = 0.295)
NEC for r=1.0 all L1 = 0.375 +- 0.232 (in-sample avg dev_std = 0.295)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.613
Model XAI F1 of binarized graphs for r=0.3 =  0.37196375000000004
Model XAI WIoU of binarized graphs for r=0.3 =  0.7184625
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.405
NEC for r=0.3 class 0 = 0.575 +- 0.274 (in-sample avg dev_std = 0.281)
NEC for r=0.3 class 1 = 0.272 +- 0.274 (in-sample avg dev_std = 0.281)
NEC for r=0.3 class 2 = 0.559 +- 0.274 (in-sample avg dev_std = 0.281)
NEC for r=0.3 all KL = 0.371 +- 0.274 (in-sample avg dev_std = 0.281)
NEC for r=0.3 all L1 = 0.468 +- 0.226 (in-sample avg dev_std = 0.281)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.66
Model XAI F1 of binarized graphs for r=0.6 =  0.24302999999999997
Model XAI WIoU of binarized graphs for r=0.6 =  0.70982
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.49
NEC for r=0.6 class 0 = 0.374 +- 0.168 (in-sample avg dev_std = 0.221)
NEC for r=0.6 class 1 = 0.187 +- 0.168 (in-sample avg dev_std = 0.221)
NEC for r=0.6 class 2 = 0.409 +- 0.168 (in-sample avg dev_std = 0.221)
NEC for r=0.6 all KL = 0.171 +- 0.168 (in-sample avg dev_std = 0.221)
NEC for r=0.6 all L1 = 0.322 +- 0.182 (in-sample avg dev_std = 0.221)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.654
Model XAI F1 of binarized graphs for r=0.9 =  0.20665875
Model XAI WIoU of binarized graphs for r=0.9 =  0.70609625
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.522
NEC for r=0.9 class 0 = 0.297 +- 0.136 (in-sample avg dev_std = 0.169)
NEC for r=0.9 class 1 = 0.147 +- 0.136 (in-sample avg dev_std = 0.169)
NEC for r=0.9 class 2 = 0.327 +- 0.136 (in-sample avg dev_std = 0.169)
NEC for r=0.9 all KL = 0.105 +- 0.136 (in-sample avg dev_std = 0.169)
NEC for r=0.9 all L1 = 0.256 +- 0.157 (in-sample avg dev_std = 0.169)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.646
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.70643
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.496
NEC for r=1.0 class 0 = 0.295 +- 0.119 (in-sample avg dev_std = 0.154)
NEC for r=1.0 class 1 = 0.141 +- 0.119 (in-sample avg dev_std = 0.154)
NEC for r=1.0 class 2 = 0.302 +- 0.119 (in-sample avg dev_std = 0.154)
NEC for r=1.0 all KL = 0.093 +- 0.119 (in-sample avg dev_std = 0.154)
NEC for r=1.0 all L1 = 0.246 +- 0.148 (in-sample avg dev_std = 0.154)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.46
Model XAI F1 of binarized graphs for r=0.3 =  0.25948875
Model XAI WIoU of binarized graphs for r=0.3 =  0.5604012500000001
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.396
NEC for r=0.3 class 0 = 0.386 +- 0.161 (in-sample avg dev_std = 0.197)
NEC for r=0.3 class 1 = 0.2 +- 0.161 (in-sample avg dev_std = 0.197)
NEC for r=0.3 class 2 = 0.338 +- 0.161 (in-sample avg dev_std = 0.197)
NEC for r=0.3 all KL = 0.165 +- 0.161 (in-sample avg dev_std = 0.197)
NEC for r=0.3 all L1 = 0.307 +- 0.188 (in-sample avg dev_std = 0.197)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.466
Model XAI F1 of binarized graphs for r=0.6 =  0.15715
Model XAI WIoU of binarized graphs for r=0.6 =  0.5570725
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.464
NEC for r=0.6 class 0 = 0.275 +- 0.143 (in-sample avg dev_std = 0.163)
NEC for r=0.6 class 1 = 0.164 +- 0.143 (in-sample avg dev_std = 0.163)
NEC for r=0.6 class 2 = 0.325 +- 0.143 (in-sample avg dev_std = 0.163)
NEC for r=0.6 all KL = 0.108 +- 0.143 (in-sample avg dev_std = 0.163)
NEC for r=0.6 all L1 = 0.253 +- 0.162 (in-sample avg dev_std = 0.163)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.414
Model XAI F1 of binarized graphs for r=0.9 =  0.11041875000000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.55467625
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.44
NEC for r=0.9 class 0 = 0.206 +- 0.091 (in-sample avg dev_std = 0.116)
NEC for r=0.9 class 1 = 0.13 +- 0.091 (in-sample avg dev_std = 0.116)
NEC for r=0.9 class 2 = 0.258 +- 0.091 (in-sample avg dev_std = 0.116)
NEC for r=0.9 all KL = 0.06 +- 0.091 (in-sample avg dev_std = 0.116)
NEC for r=0.9 all L1 = 0.196 +- 0.135 (in-sample avg dev_std = 0.116)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.387
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.554325
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.424
NEC for r=1.0 class 0 = 0.185 +- 0.075 (in-sample avg dev_std = 0.104)
NEC for r=1.0 class 1 = 0.12 +- 0.075 (in-sample avg dev_std = 0.104)
NEC for r=1.0 class 2 = 0.24 +- 0.075 (in-sample avg dev_std = 0.104)
NEC for r=1.0 all KL = 0.049 +- 0.075 (in-sample avg dev_std = 0.104)
NEC for r=1.0 all L1 = 0.18 +- 0.125 (in-sample avg dev_std = 0.104)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 12:25:07 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:07 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:19 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:21 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:23 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:26 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:25:33 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 64...
[0m[1;37mINFO[0m: [1mCheckpoint 64: 
-----------------------------------
Train ACCURACY: 0.6413
Train Loss: 1.1103
ID Validation ACCURACY: 0.6373
ID Validation Loss: 1.1235
ID Test ACCURACY: 0.6523
ID Test Loss: 1.0915
OOD Validation ACCURACY: 0.4457
OOD Validation Loss: 1.1439
OOD Test ACCURACY: 0.3797
OOD Test Loss: 1.2057

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 105...
[0m[1;37mINFO[0m: [1mCheckpoint 105: 
-----------------------------------
Train ACCURACY: 0.5954
Train Loss: 1.1959
ID Validation ACCURACY: 0.5933
ID Validation Loss: 1.1988
ID Test ACCURACY: 0.6077
ID Test Loss: 1.1697
OOD Validation ACCURACY: 0.5550
OOD Validation Loss: 1.1285
OOD Test ACCURACY: 0.4477
OOD Test Loss: 1.0980

[0m[1;37mINFO[0m: [1mChartInfo 0.6523 0.3797 0.6077 0.4477 0.5933 0.5550[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.502
WIoU for r=0.3 = 0.609
F1 for r=0.6 = 0.435
WIoU for r=0.6 = 0.621
F1 for r=0.9 = 0.443
WIoU for r=0.9 = 0.619
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.619
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.402
WIoU for r=0.3 = 0.613
F1 for r=0.6 = 0.265
WIoU for r=0.6 = 0.611
F1 for r=0.9 = 0.208
WIoU for r=0.9 = 0.610
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.610
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.254
WIoU for r=0.3 = 0.517
F1 for r=0.6 = 0.157
WIoU for r=0.6 = 0.517
F1 for r=0.9 = 0.116
WIoU for r=0.9 = 0.517
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.517


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.505
Model XAI F1 of binarized graphs for r=0.3 =  0.50168875
Model XAI WIoU of binarized graphs for r=0.3 =  0.6092775
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.395
SUFF++ for r=0.3 class 0 = 0.489 +- 0.265 (in-sample avg dev_std = 0.652)
SUFF++ for r=0.3 class 1 = 0.559 +- 0.265 (in-sample avg dev_std = 0.652)
SUFF++ for r=0.3 class 2 = 0.462 +- 0.265 (in-sample avg dev_std = 0.652)
SUFF++ for r=0.3 all KL = 0.46 +- 0.265 (in-sample avg dev_std = 0.652)
SUFF++ for r=0.3 all L1 = 0.503 +- 0.181 (in-sample avg dev_std = 0.652)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.621
Model XAI F1 of binarized graphs for r=0.6 =  0.43544999999999995
Model XAI WIoU of binarized graphs for r=0.6 =  0.6205875
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.435
SUFF++ for r=0.6 class 0 = 0.415 +- 0.306 (in-sample avg dev_std = 0.513)
SUFF++ for r=0.6 class 1 = 0.667 +- 0.306 (in-sample avg dev_std = 0.513)
SUFF++ for r=0.6 class 2 = 0.478 +- 0.306 (in-sample avg dev_std = 0.513)
SUFF++ for r=0.6 all KL = 0.534 +- 0.306 (in-sample avg dev_std = 0.513)
SUFF++ for r=0.6 all L1 = 0.518 +- 0.216 (in-sample avg dev_std = 0.513)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.57
Model XAI F1 of binarized graphs for r=0.9 =  0.44315375
Model XAI WIoU of binarized graphs for r=0.9 =  0.61855375
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.445
SUFF++ for r=0.9 class 0 = 0.552 +- 0.252 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.9 class 1 = 0.748 +- 0.252 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.9 class 2 = 0.566 +- 0.252 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.9 all KL = 0.701 +- 0.252 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.9 all L1 = 0.62 +- 0.220 (in-sample avg dev_std = 0.412)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.581
Model XAI F1 of binarized graphs for r=0.3 =  0.4021012500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.61319625
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.438
SUFF++ for r=0.3 class 0 = 0.487 +- 0.269 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.3 class 1 = 0.591 +- 0.269 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.3 class 2 = 0.471 +- 0.269 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.3 all KL = 0.565 +- 0.269 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.3 all L1 = 0.517 +- 0.176 (in-sample avg dev_std = 0.501)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.526
Model XAI F1 of binarized graphs for r=0.6 =  0.26483249999999997
Model XAI WIoU of binarized graphs for r=0.6 =  0.61059625
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.427
SUFF++ for r=0.6 class 0 = 0.548 +- 0.214 (in-sample avg dev_std = 0.349)
SUFF++ for r=0.6 class 1 = 0.685 +- 0.214 (in-sample avg dev_std = 0.349)
SUFF++ for r=0.6 class 2 = 0.561 +- 0.214 (in-sample avg dev_std = 0.349)
SUFF++ for r=0.6 all KL = 0.734 +- 0.214 (in-sample avg dev_std = 0.349)
SUFF++ for r=0.6 all L1 = 0.598 +- 0.173 (in-sample avg dev_std = 0.349)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.477
Model XAI F1 of binarized graphs for r=0.9 =  0.207805
Model XAI WIoU of binarized graphs for r=0.9 =  0.6102925
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.404
SUFF++ for r=0.9 class 0 = 0.678 +- 0.176 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.9 class 1 = 0.747 +- 0.176 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.9 class 2 = 0.641 +- 0.176 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.9 all KL = 0.837 +- 0.176 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.9 all L1 = 0.689 +- 0.158 (in-sample avg dev_std = 0.269)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.469
Model XAI F1 of binarized graphs for r=0.3 =  0.2536525
Model XAI WIoU of binarized graphs for r=0.3 =  0.51689
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.412
SUFF++ for r=0.3 class 0 = 0.562 +- 0.228 (in-sample avg dev_std = 0.345)
SUFF++ for r=0.3 class 1 = 0.717 +- 0.228 (in-sample avg dev_std = 0.345)
SUFF++ for r=0.3 class 2 = 0.598 +- 0.228 (in-sample avg dev_std = 0.345)
SUFF++ for r=0.3 all KL = 0.755 +- 0.228 (in-sample avg dev_std = 0.345)
SUFF++ for r=0.3 all L1 = 0.627 +- 0.189 (in-sample avg dev_std = 0.345)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.421
Model XAI F1 of binarized graphs for r=0.6 =  0.1574025
Model XAI WIoU of binarized graphs for r=0.6 =  0.51729625
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.417
SUFF++ for r=0.6 class 0 = 0.616 +- 0.176 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.6 class 1 = 0.773 +- 0.176 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.6 class 2 = 0.667 +- 0.176 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.6 all KL = 0.825 +- 0.176 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.6 all L1 = 0.686 +- 0.173 (in-sample avg dev_std = 0.276)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.382
Model XAI F1 of binarized graphs for r=0.9 =  0.11621625
Model XAI WIoU of binarized graphs for r=0.9 =  0.51714125
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.381
SUFF++ for r=0.9 class 0 = 0.795 +- 0.082 (in-sample avg dev_std = 0.173)
SUFF++ for r=0.9 class 1 = 0.858 +- 0.082 (in-sample avg dev_std = 0.173)
SUFF++ for r=0.9 class 2 = 0.808 +- 0.082 (in-sample avg dev_std = 0.173)
SUFF++ for r=0.9 all KL = 0.943 +- 0.082 (in-sample avg dev_std = 0.173)
SUFF++ for r=0.9 all L1 = 0.82 +- 0.122 (in-sample avg dev_std = 0.173)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.505
Model XAI F1 of binarized graphs for r=0.3 =  0.50168875
Model XAI WIoU of binarized graphs for r=0.3 =  0.6092775
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.394
NEC for r=0.3 class 0 = 0.675 +- 0.332 (in-sample avg dev_std = 0.433)
NEC for r=0.3 class 1 = 0.275 +- 0.332 (in-sample avg dev_std = 0.433)
NEC for r=0.3 class 2 = 0.585 +- 0.332 (in-sample avg dev_std = 0.433)
NEC for r=0.3 all KL = 0.54 +- 0.332 (in-sample avg dev_std = 0.433)
NEC for r=0.3 all L1 = 0.515 +- 0.269 (in-sample avg dev_std = 0.433)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.621
Model XAI F1 of binarized graphs for r=0.6 =  0.43544999999999995
Model XAI WIoU of binarized graphs for r=0.6 =  0.6205875
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.43
NEC for r=0.6 class 0 = 0.576 +- 0.314 (in-sample avg dev_std = 0.458)
NEC for r=0.6 class 1 = 0.274 +- 0.314 (in-sample avg dev_std = 0.458)
NEC for r=0.6 class 2 = 0.562 +- 0.314 (in-sample avg dev_std = 0.458)
NEC for r=0.6 all KL = 0.459 +- 0.314 (in-sample avg dev_std = 0.458)
NEC for r=0.6 all L1 = 0.473 +- 0.242 (in-sample avg dev_std = 0.458)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.57
Model XAI F1 of binarized graphs for r=0.9 =  0.44315375
Model XAI WIoU of binarized graphs for r=0.9 =  0.61855375
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.429
NEC for r=0.9 class 0 = 0.511 +- 0.291 (in-sample avg dev_std = 0.397)
NEC for r=0.9 class 1 = 0.247 +- 0.291 (in-sample avg dev_std = 0.397)
NEC for r=0.9 class 2 = 0.498 +- 0.291 (in-sample avg dev_std = 0.397)
NEC for r=0.9 all KL = 0.354 +- 0.291 (in-sample avg dev_std = 0.397)
NEC for r=0.9 all L1 = 0.421 +- 0.240 (in-sample avg dev_std = 0.397)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.587
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.61857
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.42
NEC for r=1.0 class 0 = 0.511 +- 0.278 (in-sample avg dev_std = 0.372)
NEC for r=1.0 class 1 = 0.229 +- 0.278 (in-sample avg dev_std = 0.372)
NEC for r=1.0 class 2 = 0.495 +- 0.278 (in-sample avg dev_std = 0.372)
NEC for r=1.0 all KL = 0.328 +- 0.278 (in-sample avg dev_std = 0.372)
NEC for r=1.0 all L1 = 0.414 +- 0.235 (in-sample avg dev_std = 0.372)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.582
Model XAI F1 of binarized graphs for r=0.3 =  0.4021012500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.61319625
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.378
NEC for r=0.3 class 0 = 0.652 +- 0.289 (in-sample avg dev_std = 0.345)
NEC for r=0.3 class 1 = 0.412 +- 0.289 (in-sample avg dev_std = 0.345)
NEC for r=0.3 class 2 = 0.618 +- 0.289 (in-sample avg dev_std = 0.345)
NEC for r=0.3 all KL = 0.515 +- 0.289 (in-sample avg dev_std = 0.345)
NEC for r=0.3 all L1 = 0.56 +- 0.210 (in-sample avg dev_std = 0.345)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.522
Model XAI F1 of binarized graphs for r=0.6 =  0.26483249999999997
Model XAI WIoU of binarized graphs for r=0.6 =  0.61059625
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.408
NEC for r=0.6 class 0 = 0.465 +- 0.245 (in-sample avg dev_std = 0.311)
NEC for r=0.6 class 1 = 0.308 +- 0.245 (in-sample avg dev_std = 0.311)
NEC for r=0.6 class 2 = 0.465 +- 0.245 (in-sample avg dev_std = 0.311)
NEC for r=0.6 all KL = 0.284 +- 0.245 (in-sample avg dev_std = 0.311)
NEC for r=0.6 all L1 = 0.412 +- 0.202 (in-sample avg dev_std = 0.311)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.481
Model XAI F1 of binarized graphs for r=0.9 =  0.207805
Model XAI WIoU of binarized graphs for r=0.9 =  0.6102925
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.414
NEC for r=0.9 class 0 = 0.352 +- 0.205 (in-sample avg dev_std = 0.250)
NEC for r=0.9 class 1 = 0.247 +- 0.205 (in-sample avg dev_std = 0.250)
NEC for r=0.9 class 2 = 0.361 +- 0.205 (in-sample avg dev_std = 0.250)
NEC for r=0.9 all KL = 0.183 +- 0.205 (in-sample avg dev_std = 0.250)
NEC for r=0.9 all L1 = 0.32 +- 0.189 (in-sample avg dev_std = 0.250)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.461
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.61024625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.391
NEC for r=1.0 class 0 = 0.342 +- 0.198 (in-sample avg dev_std = 0.248)
NEC for r=1.0 class 1 = 0.244 +- 0.198 (in-sample avg dev_std = 0.248)
NEC for r=1.0 class 2 = 0.355 +- 0.198 (in-sample avg dev_std = 0.248)
NEC for r=1.0 all KL = 0.173 +- 0.198 (in-sample avg dev_std = 0.248)
NEC for r=1.0 all L1 = 0.313 +- 0.175 (in-sample avg dev_std = 0.248)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.468
Model XAI F1 of binarized graphs for r=0.3 =  0.2536525
Model XAI WIoU of binarized graphs for r=0.3 =  0.51689
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.36
NEC for r=0.3 class 0 = 0.456 +- 0.215 (in-sample avg dev_std = 0.209)
NEC for r=0.3 class 1 = 0.304 +- 0.215 (in-sample avg dev_std = 0.209)
NEC for r=0.3 class 2 = 0.48 +- 0.215 (in-sample avg dev_std = 0.209)
NEC for r=0.3 all KL = 0.249 +- 0.215 (in-sample avg dev_std = 0.209)
NEC for r=0.3 all L1 = 0.412 +- 0.193 (in-sample avg dev_std = 0.209)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.42
Model XAI F1 of binarized graphs for r=0.6 =  0.1574025
Model XAI WIoU of binarized graphs for r=0.6 =  0.51729625
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.373
NEC for r=0.6 class 0 = 0.319 +- 0.136 (in-sample avg dev_std = 0.182)
NEC for r=0.6 class 1 = 0.233 +- 0.136 (in-sample avg dev_std = 0.182)
NEC for r=0.6 class 2 = 0.328 +- 0.136 (in-sample avg dev_std = 0.182)
NEC for r=0.6 all KL = 0.135 +- 0.136 (in-sample avg dev_std = 0.182)
NEC for r=0.6 all L1 = 0.293 +- 0.164 (in-sample avg dev_std = 0.182)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.382
Model XAI F1 of binarized graphs for r=0.9 =  0.11621625
Model XAI WIoU of binarized graphs for r=0.9 =  0.51714125
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.36
NEC for r=0.9 class 0 = 0.233 +- 0.084 (in-sample avg dev_std = 0.132)
NEC for r=0.9 class 1 = 0.149 +- 0.084 (in-sample avg dev_std = 0.132)
NEC for r=0.9 class 2 = 0.244 +- 0.084 (in-sample avg dev_std = 0.132)
NEC for r=0.9 all KL = 0.069 +- 0.084 (in-sample avg dev_std = 0.132)
NEC for r=0.9 all L1 = 0.208 +- 0.146 (in-sample avg dev_std = 0.132)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.377
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.5171224999999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.361
NEC for r=1.0 class 0 = 0.22 +- 0.066 (in-sample avg dev_std = 0.123)
NEC for r=1.0 class 1 = 0.133 +- 0.066 (in-sample avg dev_std = 0.123)
NEC for r=1.0 class 2 = 0.217 +- 0.066 (in-sample avg dev_std = 0.123)
NEC for r=1.0 all KL = 0.054 +- 0.066 (in-sample avg dev_std = 0.123)
NEC for r=1.0 all L1 = 0.189 +- 0.132 (in-sample avg dev_std = 0.123)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 12:31:59 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/22/2024 12:31:59 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:11 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:13 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:15 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:18 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:32:25 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 152...
[0m[1;37mINFO[0m: [1mCheckpoint 152: 
-----------------------------------
Train ACCURACY: 0.7652
Train Loss: 0.5935
ID Validation ACCURACY: 0.7850
ID Validation Loss: 0.5746
ID Test ACCURACY: 0.7727
ID Test Loss: 0.5913
OOD Validation ACCURACY: 0.4180
OOD Validation Loss: 0.9900
OOD Test ACCURACY: 0.3450
OOD Test Loss: 1.2377

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 56...
[0m[1;37mINFO[0m: [1mCheckpoint 56: 
-----------------------------------
Train ACCURACY: 0.6399
Train Loss: 1.0339
ID Validation ACCURACY: 0.6420
ID Validation Loss: 1.0280
ID Test ACCURACY: 0.6440
ID Test Loss: 1.0248
OOD Validation ACCURACY: 0.5023
OOD Validation Loss: 1.0169
OOD Test ACCURACY: 0.3983
OOD Test Loss: 1.1132

[0m[1;37mINFO[0m: [1mChartInfo 0.7727 0.3450 0.6440 0.3983 0.6420 0.5023[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.584
WIoU for r=0.3 = 0.634
F1 for r=0.6 = 0.534
WIoU for r=0.6 = 0.672
F1 for r=0.9 = 0.496
WIoU for r=0.9 = 0.675
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.675
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.412
WIoU for r=0.3 = 0.744
F1 for r=0.6 = 0.270
WIoU for r=0.6 = 0.743
F1 for r=0.9 = 0.215
WIoU for r=0.9 = 0.743
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.743
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.224
WIoU for r=0.3 = 0.507
F1 for r=0.6 = 0.129
WIoU for r=0.6 = 0.507
F1 for r=0.9 = 0.096
WIoU for r=0.9 = 0.507
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.507


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.683
Model XAI F1 of binarized graphs for r=0.3 =  0.58387625
Model XAI WIoU of binarized graphs for r=0.3 =  0.6337725000000001
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.532
SUFF++ for r=0.3 class 0 = 0.366 +- 0.319 (in-sample avg dev_std = 0.666)
SUFF++ for r=0.3 class 1 = 0.665 +- 0.319 (in-sample avg dev_std = 0.666)
SUFF++ for r=0.3 class 2 = 0.529 +- 0.319 (in-sample avg dev_std = 0.666)
SUFF++ for r=0.3 all KL = 0.43 +- 0.319 (in-sample avg dev_std = 0.666)
SUFF++ for r=0.3 all L1 = 0.518 +- 0.236 (in-sample avg dev_std = 0.666)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.855
Model XAI F1 of binarized graphs for r=0.6 =  0.53400625
Model XAI WIoU of binarized graphs for r=0.6 =  0.6724562499999999
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.635
SUFF++ for r=0.6 class 0 = 0.418 +- 0.313 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 class 1 = 0.799 +- 0.313 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 class 2 = 0.624 +- 0.313 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 all KL = 0.625 +- 0.313 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 all L1 = 0.61 +- 0.261 (in-sample avg dev_std = 0.483)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.824
Model XAI F1 of binarized graphs for r=0.9 =  0.49648
Model XAI WIoU of binarized graphs for r=0.9 =  0.6750737499999999
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.659
SUFF++ for r=0.9 class 0 = 0.568 +- 0.212 (in-sample avg dev_std = 0.318)
SUFF++ for r=0.9 class 1 = 0.894 +- 0.212 (in-sample avg dev_std = 0.318)
SUFF++ for r=0.9 class 2 = 0.782 +- 0.212 (in-sample avg dev_std = 0.318)
SUFF++ for r=0.9 all KL = 0.828 +- 0.212 (in-sample avg dev_std = 0.318)
SUFF++ for r=0.9 all L1 = 0.746 +- 0.222 (in-sample avg dev_std = 0.318)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.835
Model XAI F1 of binarized graphs for r=0.3 =  0.41213125000000006
Model XAI WIoU of binarized graphs for r=0.3 =  0.7441499999999999
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.603
SUFF++ for r=0.3 class 0 = 0.469 +- 0.237 (in-sample avg dev_std = 0.597)
SUFF++ for r=0.3 class 1 = 0.629 +- 0.237 (in-sample avg dev_std = 0.597)
SUFF++ for r=0.3 class 2 = 0.477 +- 0.237 (in-sample avg dev_std = 0.597)
SUFF++ for r=0.3 all KL = 0.549 +- 0.237 (in-sample avg dev_std = 0.597)
SUFF++ for r=0.3 all L1 = 0.526 +- 0.183 (in-sample avg dev_std = 0.597)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.609
Model XAI F1 of binarized graphs for r=0.6 =  0.26993875
Model XAI WIoU of binarized graphs for r=0.6 =  0.74334125
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.516
SUFF++ for r=0.6 class 0 = 0.56 +- 0.200 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.6 class 1 = 0.762 +- 0.200 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.6 class 2 = 0.564 +- 0.200 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.6 all KL = 0.728 +- 0.200 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.6 all L1 = 0.629 +- 0.185 (in-sample avg dev_std = 0.460)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.424
Model XAI F1 of binarized graphs for r=0.9 =  0.21494999999999997
Model XAI WIoU of binarized graphs for r=0.9 =  0.7431462500000001
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.414
SUFF++ for r=0.9 class 0 = 0.724 +- 0.100 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.9 class 1 = 0.91 +- 0.100 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.9 class 2 = 0.823 +- 0.100 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.9 all KL = 0.933 +- 0.100 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.9 all L1 = 0.818 +- 0.150 (in-sample avg dev_std = 0.162)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.556
Model XAI F1 of binarized graphs for r=0.3 =  0.22405124999999998
Model XAI WIoU of binarized graphs for r=0.3 =  0.5066975
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.442
SUFF++ for r=0.3 class 0 = 0.481 +- 0.251 (in-sample avg dev_std = 0.541)
SUFF++ for r=0.3 class 1 = 0.563 +- 0.251 (in-sample avg dev_std = 0.541)
SUFF++ for r=0.3 class 2 = 0.411 +- 0.251 (in-sample avg dev_std = 0.541)
SUFF++ for r=0.3 all KL = 0.542 +- 0.251 (in-sample avg dev_std = 0.541)
SUFF++ for r=0.3 all L1 = 0.487 +- 0.190 (in-sample avg dev_std = 0.541)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.421
Model XAI F1 of binarized graphs for r=0.6 =  0.12856625000000002
Model XAI WIoU of binarized graphs for r=0.6 =  0.5065437500000001
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.359
SUFF++ for r=0.6 class 0 = 0.608 +- 0.199 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.6 class 1 = 0.7 +- 0.199 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.6 class 2 = 0.594 +- 0.199 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.6 all KL = 0.743 +- 0.199 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.6 all L1 = 0.635 +- 0.175 (in-sample avg dev_std = 0.460)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.345
Model XAI F1 of binarized graphs for r=0.9 =  0.0961675
Model XAI WIoU of binarized graphs for r=0.9 =  0.506565
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.343
SUFF++ for r=0.9 class 0 = 0.792 +- 0.124 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.9 class 1 = 0.84 +- 0.124 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.9 class 2 = 0.8 +- 0.124 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.9 all KL = 0.912 +- 0.124 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.9 all L1 = 0.811 +- 0.138 (in-sample avg dev_std = 0.272)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.679
Model XAI F1 of binarized graphs for r=0.3 =  0.58387625
Model XAI WIoU of binarized graphs for r=0.3 =  0.6337725000000001
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.367
NEC for r=0.3 class 0 = 0.724 +- 0.404 (in-sample avg dev_std = 0.403)
NEC for r=0.3 class 1 = 0.18 +- 0.404 (in-sample avg dev_std = 0.403)
NEC for r=0.3 class 2 = 0.548 +- 0.404 (in-sample avg dev_std = 0.403)
NEC for r=0.3 all KL = 0.551 +- 0.404 (in-sample avg dev_std = 0.403)
NEC for r=0.3 all L1 = 0.489 +- 0.323 (in-sample avg dev_std = 0.403)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.856
Model XAI F1 of binarized graphs for r=0.6 =  0.53400625
Model XAI WIoU of binarized graphs for r=0.6 =  0.6724562499999999
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.459
NEC for r=0.6 class 0 = 0.61 +- 0.355 (in-sample avg dev_std = 0.456)
NEC for r=0.6 class 1 = 0.163 +- 0.355 (in-sample avg dev_std = 0.456)
NEC for r=0.6 class 2 = 0.582 +- 0.355 (in-sample avg dev_std = 0.456)
NEC for r=0.6 all KL = 0.457 +- 0.355 (in-sample avg dev_std = 0.456)
NEC for r=0.6 all L1 = 0.455 +- 0.298 (in-sample avg dev_std = 0.456)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.824
Model XAI F1 of binarized graphs for r=0.9 =  0.49648
Model XAI WIoU of binarized graphs for r=0.9 =  0.6750737499999999
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.463
NEC for r=0.9 class 0 = 0.541 +- 0.299 (in-sample avg dev_std = 0.386)
NEC for r=0.9 class 1 = 0.147 +- 0.299 (in-sample avg dev_std = 0.386)
NEC for r=0.9 class 2 = 0.522 +- 0.299 (in-sample avg dev_std = 0.386)
NEC for r=0.9 all KL = 0.346 +- 0.299 (in-sample avg dev_std = 0.386)
NEC for r=0.9 all L1 = 0.407 +- 0.277 (in-sample avg dev_std = 0.386)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.81
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.6750775
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.45
NEC for r=1.0 class 0 = 0.52 +- 0.286 (in-sample avg dev_std = 0.362)
NEC for r=1.0 class 1 = 0.137 +- 0.286 (in-sample avg dev_std = 0.362)
NEC for r=1.0 class 2 = 0.495 +- 0.286 (in-sample avg dev_std = 0.362)
NEC for r=1.0 all KL = 0.314 +- 0.286 (in-sample avg dev_std = 0.362)
NEC for r=1.0 all L1 = 0.388 +- 0.270 (in-sample avg dev_std = 0.362)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.837
Model XAI F1 of binarized graphs for r=0.3 =  0.41213125000000006
Model XAI WIoU of binarized graphs for r=0.3 =  0.7441499999999999
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.38
NEC for r=0.3 class 0 = 0.63 +- 0.349 (in-sample avg dev_std = 0.292)
NEC for r=0.3 class 1 = 0.188 +- 0.349 (in-sample avg dev_std = 0.292)
NEC for r=0.3 class 2 = 0.683 +- 0.349 (in-sample avg dev_std = 0.292)
NEC for r=0.3 all KL = 0.464 +- 0.349 (in-sample avg dev_std = 0.292)
NEC for r=0.3 all L1 = 0.498 +- 0.296 (in-sample avg dev_std = 0.292)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.611
Model XAI F1 of binarized graphs for r=0.6 =  0.26993875
Model XAI WIoU of binarized graphs for r=0.6 =  0.74334125
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.387
NEC for r=0.6 class 0 = 0.373 +- 0.244 (in-sample avg dev_std = 0.218)
NEC for r=0.6 class 1 = 0.112 +- 0.244 (in-sample avg dev_std = 0.218)
NEC for r=0.6 class 2 = 0.479 +- 0.244 (in-sample avg dev_std = 0.218)
NEC for r=0.6 all KL = 0.203 +- 0.244 (in-sample avg dev_std = 0.218)
NEC for r=0.6 all L1 = 0.32 +- 0.244 (in-sample avg dev_std = 0.218)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.424
Model XAI F1 of binarized graphs for r=0.9 =  0.21494999999999997
Model XAI WIoU of binarized graphs for r=0.9 =  0.7431462500000001
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.359
NEC for r=0.9 class 0 = 0.254 +- 0.159 (in-sample avg dev_std = 0.161)
NEC for r=0.9 class 1 = 0.08 +- 0.159 (in-sample avg dev_std = 0.161)
NEC for r=0.9 class 2 = 0.333 +- 0.159 (in-sample avg dev_std = 0.161)
NEC for r=0.9 all KL = 0.102 +- 0.159 (in-sample avg dev_std = 0.161)
NEC for r=0.9 all L1 = 0.221 +- 0.194 (in-sample avg dev_std = 0.161)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.405
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.74314875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.35
NEC for r=1.0 class 0 = 0.246 +- 0.129 (in-sample avg dev_std = 0.146)
NEC for r=1.0 class 1 = 0.08 +- 0.129 (in-sample avg dev_std = 0.146)
NEC for r=1.0 class 2 = 0.292 +- 0.129 (in-sample avg dev_std = 0.146)
NEC for r=1.0 all KL = 0.083 +- 0.129 (in-sample avg dev_std = 0.146)
NEC for r=1.0 all L1 = 0.205 +- 0.175 (in-sample avg dev_std = 0.146)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.555
Model XAI F1 of binarized graphs for r=0.3 =  0.22405124999999998
Model XAI WIoU of binarized graphs for r=0.3 =  0.5066975
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.316
NEC for r=0.3 class 0 = 0.489 +- 0.333 (in-sample avg dev_std = 0.150)
NEC for r=0.3 class 1 = 0.306 +- 0.333 (in-sample avg dev_std = 0.150)
NEC for r=0.3 class 2 = 0.519 +- 0.333 (in-sample avg dev_std = 0.150)
NEC for r=0.3 all KL = 0.33 +- 0.333 (in-sample avg dev_std = 0.150)
NEC for r=0.3 all L1 = 0.436 +- 0.268 (in-sample avg dev_std = 0.150)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.419
Model XAI F1 of binarized graphs for r=0.6 =  0.12856625000000002
Model XAI WIoU of binarized graphs for r=0.6 =  0.5065437500000001
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.318
NEC for r=0.6 class 0 = 0.274 +- 0.182 (in-sample avg dev_std = 0.164)
NEC for r=0.6 class 1 = 0.196 +- 0.182 (in-sample avg dev_std = 0.164)
NEC for r=0.6 class 2 = 0.28 +- 0.182 (in-sample avg dev_std = 0.164)
NEC for r=0.6 all KL = 0.116 +- 0.182 (in-sample avg dev_std = 0.164)
NEC for r=0.6 all L1 = 0.249 +- 0.200 (in-sample avg dev_std = 0.164)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.346
Model XAI F1 of binarized graphs for r=0.9 =  0.0961675
Model XAI WIoU of binarized graphs for r=0.9 =  0.506565
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.338
NEC for r=0.9 class 0 = 0.19 +- 0.086 (in-sample avg dev_std = 0.156)
NEC for r=0.9 class 1 = 0.119 +- 0.086 (in-sample avg dev_std = 0.156)
NEC for r=0.9 class 2 = 0.189 +- 0.086 (in-sample avg dev_std = 0.156)
NEC for r=0.9 all KL = 0.052 +- 0.086 (in-sample avg dev_std = 0.156)
NEC for r=0.9 all L1 = 0.165 +- 0.124 (in-sample avg dev_std = 0.156)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.345
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.5065612500000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.342
NEC for r=1.0 class 0 = 0.181 +- 0.069 (in-sample avg dev_std = 0.134)
NEC for r=1.0 class 1 = 0.096 +- 0.069 (in-sample avg dev_std = 0.134)
NEC for r=1.0 class 2 = 0.173 +- 0.069 (in-sample avg dev_std = 0.134)
NEC for r=1.0 all KL = 0.041 +- 0.069 (in-sample avg dev_std = 0.134)
NEC for r=1.0 all L1 = 0.149 +- 0.110 (in-sample avg dev_std = 0.134)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 12:39:50 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/22/2024 12:39:50 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:04 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:06 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:09 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:13 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:20 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:20 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:40:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:20 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:40:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:40:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:40:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:40:21 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 86...
[0m[1;37mINFO[0m: [1mCheckpoint 86: 
-----------------------------------
Train ACCURACY: 0.6953
Train Loss: 0.8904
ID Validation ACCURACY: 0.6970
ID Validation Loss: 0.8818
ID Test ACCURACY: 0.6917
ID Test Loss: 0.8977
OOD Validation ACCURACY: 0.5270
OOD Validation Loss: 0.9720
OOD Test ACCURACY: 0.4503
OOD Test Loss: 1.0411

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 53...
[0m[1;37mINFO[0m: [1mCheckpoint 53: 
-----------------------------------
Train ACCURACY: 0.6823
Train Loss: 0.9862
ID Validation ACCURACY: 0.6837
ID Validation Loss: 0.9798
ID Test ACCURACY: 0.6773
ID Test Loss: 0.9971
OOD Validation ACCURACY: 0.6483
OOD Validation Loss: 0.9393
OOD Test ACCURACY: 0.4930
OOD Test Loss: 1.0068

[0m[1;37mINFO[0m: [1mChartInfo 0.6917 0.4503 0.6773 0.4930 0.6837 0.6483[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.633
WIoU for r=0.3 = 0.742
F1 for r=0.6 = 0.536
WIoU for r=0.6 = 0.786
F1 for r=0.9 = 0.465
WIoU for r=0.9 = 0.788
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.788
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.456
WIoU for r=0.3 = 0.769
F1 for r=0.6 = 0.288
WIoU for r=0.6 = 0.765
F1 for r=0.9 = 0.221
WIoU for r=0.9 = 0.763
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.763
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.289
WIoU for r=0.3 = 0.652
F1 for r=0.6 = 0.168
WIoU for r=0.6 = 0.651
F1 for r=0.9 = 0.120
WIoU for r=0.9 = 0.651
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.651


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.717
Model XAI F1 of binarized graphs for r=0.3 =  0.6328162500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.7416375
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.555
SUFF++ for r=0.3 class 0 = 0.43 +- 0.311 (in-sample avg dev_std = 0.574)
SUFF++ for r=0.3 class 1 = 0.673 +- 0.311 (in-sample avg dev_std = 0.574)
SUFF++ for r=0.3 class 2 = 0.596 +- 0.311 (in-sample avg dev_std = 0.574)
SUFF++ for r=0.3 all KL = 0.531 +- 0.311 (in-sample avg dev_std = 0.574)
SUFF++ for r=0.3 all L1 = 0.565 +- 0.236 (in-sample avg dev_std = 0.574)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.717
Model XAI F1 of binarized graphs for r=0.6 =  0.5360524999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.78642375
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.616
SUFF++ for r=0.6 class 0 = 0.432 +- 0.296 (in-sample avg dev_std = 0.386)
SUFF++ for r=0.6 class 1 = 0.798 +- 0.296 (in-sample avg dev_std = 0.386)
SUFF++ for r=0.6 class 2 = 0.778 +- 0.296 (in-sample avg dev_std = 0.386)
SUFF++ for r=0.6 all KL = 0.698 +- 0.296 (in-sample avg dev_std = 0.386)
SUFF++ for r=0.6 all L1 = 0.667 +- 0.259 (in-sample avg dev_std = 0.386)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.704
Model XAI F1 of binarized graphs for r=0.9 =  0.46535375
Model XAI WIoU of binarized graphs for r=0.9 =  0.7883612499999999
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.645
SUFF++ for r=0.9 class 0 = 0.595 +- 0.167 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 1 = 0.879 +- 0.167 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 2 = 0.87 +- 0.167 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 all KL = 0.868 +- 0.167 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 all L1 = 0.779 +- 0.203 (in-sample avg dev_std = 0.263)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.671
Model XAI F1 of binarized graphs for r=0.3 =  0.4555325
Model XAI WIoU of binarized graphs for r=0.3 =  0.76873125
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.586
SUFF++ for r=0.3 class 0 = 0.465 +- 0.250 (in-sample avg dev_std = 0.492)
SUFF++ for r=0.3 class 1 = 0.624 +- 0.250 (in-sample avg dev_std = 0.492)
SUFF++ for r=0.3 class 2 = 0.771 +- 0.250 (in-sample avg dev_std = 0.492)
SUFF++ for r=0.3 all KL = 0.657 +- 0.250 (in-sample avg dev_std = 0.492)
SUFF++ for r=0.3 all L1 = 0.617 +- 0.215 (in-sample avg dev_std = 0.492)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.671
Model XAI F1 of binarized graphs for r=0.6 =  0.28803625
Model XAI WIoU of binarized graphs for r=0.6 =  0.7651887500000001
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.551
SUFF++ for r=0.6 class 0 = 0.586 +- 0.125 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.6 class 1 = 0.736 +- 0.125 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.6 class 2 = 0.736 +- 0.125 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.6 all KL = 0.826 +- 0.125 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.6 all L1 = 0.685 +- 0.147 (in-sample avg dev_std = 0.336)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.609
Model XAI F1 of binarized graphs for r=0.9 =  0.2209675
Model XAI WIoU of binarized graphs for r=0.9 =  0.7631600000000001
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.555
SUFF++ for r=0.9 class 0 = 0.7 +- 0.079 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.9 class 1 = 0.91 +- 0.079 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.9 class 2 = 0.86 +- 0.079 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.9 all KL = 0.944 +- 0.079 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.9 all L1 = 0.822 +- 0.141 (in-sample avg dev_std = 0.136)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.506
Model XAI F1 of binarized graphs for r=0.3 =  0.28875375
Model XAI WIoU of binarized graphs for r=0.3 =  0.6517937500000001
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.457
SUFF++ for r=0.3 class 0 = 0.555 +- 0.203 (in-sample avg dev_std = 0.465)
SUFF++ for r=0.3 class 1 = 0.602 +- 0.203 (in-sample avg dev_std = 0.465)
SUFF++ for r=0.3 class 2 = 0.534 +- 0.203 (in-sample avg dev_std = 0.465)
SUFF++ for r=0.3 all KL = 0.656 +- 0.203 (in-sample avg dev_std = 0.465)
SUFF++ for r=0.3 all L1 = 0.565 +- 0.167 (in-sample avg dev_std = 0.465)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.485
Model XAI F1 of binarized graphs for r=0.6 =  0.16803625
Model XAI WIoU of binarized graphs for r=0.6 =  0.6508862500000001
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.404
SUFF++ for r=0.6 class 0 = 0.645 +- 0.188 (in-sample avg dev_std = 0.361)
SUFF++ for r=0.6 class 1 = 0.707 +- 0.188 (in-sample avg dev_std = 0.361)
SUFF++ for r=0.6 class 2 = 0.607 +- 0.188 (in-sample avg dev_std = 0.361)
SUFF++ for r=0.6 all KL = 0.775 +- 0.188 (in-sample avg dev_std = 0.361)
SUFF++ for r=0.6 all L1 = 0.654 +- 0.190 (in-sample avg dev_std = 0.361)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.447
Model XAI F1 of binarized graphs for r=0.9 =  0.12036374999999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.65085
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.376
SUFF++ for r=0.9 class 0 = 0.766 +- 0.163 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.9 class 1 = 0.793 +- 0.163 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.9 class 2 = 0.76 +- 0.163 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.9 all KL = 0.879 +- 0.163 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.9 all L1 = 0.773 +- 0.185 (in-sample avg dev_std = 0.293)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.717
Model XAI F1 of binarized graphs for r=0.3 =  0.6328162500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.7416375
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.372
NEC for r=0.3 class 0 = 0.681 +- 0.388 (in-sample avg dev_std = 0.343)
NEC for r=0.3 class 1 = 0.152 +- 0.388 (in-sample avg dev_std = 0.343)
NEC for r=0.3 class 2 = 0.629 +- 0.388 (in-sample avg dev_std = 0.343)
NEC for r=0.3 all KL = 0.562 +- 0.388 (in-sample avg dev_std = 0.343)
NEC for r=0.3 all L1 = 0.492 +- 0.308 (in-sample avg dev_std = 0.343)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.717
Model XAI F1 of binarized graphs for r=0.6 =  0.5360524999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.78642375
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.44
NEC for r=0.6 class 0 = 0.588 +- 0.362 (in-sample avg dev_std = 0.435)
NEC for r=0.6 class 1 = 0.133 +- 0.362 (in-sample avg dev_std = 0.435)
NEC for r=0.6 class 2 = 0.613 +- 0.362 (in-sample avg dev_std = 0.435)
NEC for r=0.6 all KL = 0.477 +- 0.362 (in-sample avg dev_std = 0.435)
NEC for r=0.6 all L1 = 0.449 +- 0.293 (in-sample avg dev_std = 0.435)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.704
Model XAI F1 of binarized graphs for r=0.9 =  0.46535375
Model XAI WIoU of binarized graphs for r=0.9 =  0.7883612499999999
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.479
NEC for r=0.9 class 0 = 0.528 +- 0.315 (in-sample avg dev_std = 0.410)
NEC for r=0.9 class 1 = 0.108 +- 0.315 (in-sample avg dev_std = 0.410)
NEC for r=0.9 class 2 = 0.528 +- 0.315 (in-sample avg dev_std = 0.410)
NEC for r=0.9 all KL = 0.355 +- 0.315 (in-sample avg dev_std = 0.410)
NEC for r=0.9 all L1 = 0.392 +- 0.273 (in-sample avg dev_std = 0.410)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.696
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.78835375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.474
NEC for r=1.0 class 0 = 0.522 +- 0.311 (in-sample avg dev_std = 0.388)
NEC for r=1.0 class 1 = 0.108 +- 0.311 (in-sample avg dev_std = 0.388)
NEC for r=1.0 class 2 = 0.514 +- 0.311 (in-sample avg dev_std = 0.388)
NEC for r=1.0 all KL = 0.334 +- 0.311 (in-sample avg dev_std = 0.388)
NEC for r=1.0 all L1 = 0.385 +- 0.272 (in-sample avg dev_std = 0.388)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.673
Model XAI F1 of binarized graphs for r=0.3 =  0.4555325
Model XAI WIoU of binarized graphs for r=0.3 =  0.76873125
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.376
NEC for r=0.3 class 0 = 0.645 +- 0.349 (in-sample avg dev_std = 0.321)
NEC for r=0.3 class 1 = 0.21 +- 0.349 (in-sample avg dev_std = 0.321)
NEC for r=0.3 class 2 = 0.709 +- 0.349 (in-sample avg dev_std = 0.321)
NEC for r=0.3 all KL = 0.505 +- 0.349 (in-sample avg dev_std = 0.321)
NEC for r=0.3 all L1 = 0.52 +- 0.277 (in-sample avg dev_std = 0.321)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.674
Model XAI F1 of binarized graphs for r=0.6 =  0.28803625
Model XAI WIoU of binarized graphs for r=0.6 =  0.7651887500000001
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.412
NEC for r=0.6 class 0 = 0.425 +- 0.249 (in-sample avg dev_std = 0.255)
NEC for r=0.6 class 1 = 0.123 +- 0.249 (in-sample avg dev_std = 0.255)
NEC for r=0.6 class 2 = 0.52 +- 0.249 (in-sample avg dev_std = 0.255)
NEC for r=0.6 all KL = 0.229 +- 0.249 (in-sample avg dev_std = 0.255)
NEC for r=0.6 all L1 = 0.354 +- 0.235 (in-sample avg dev_std = 0.255)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.608
Model XAI F1 of binarized graphs for r=0.9 =  0.2209675
Model XAI WIoU of binarized graphs for r=0.9 =  0.7631600000000001
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.405
NEC for r=0.9 class 0 = 0.319 +- 0.170 (in-sample avg dev_std = 0.202)
NEC for r=0.9 class 1 = 0.087 +- 0.170 (in-sample avg dev_std = 0.202)
NEC for r=0.9 class 2 = 0.379 +- 0.170 (in-sample avg dev_std = 0.202)
NEC for r=0.9 all KL = 0.123 +- 0.170 (in-sample avg dev_std = 0.202)
NEC for r=0.9 all L1 = 0.26 +- 0.193 (in-sample avg dev_std = 0.202)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.562
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.7630837500000002
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.403
NEC for r=1.0 class 0 = 0.317 +- 0.148 (in-sample avg dev_std = 0.175)
NEC for r=1.0 class 1 = 0.081 +- 0.148 (in-sample avg dev_std = 0.175)
NEC for r=1.0 class 2 = 0.34 +- 0.148 (in-sample avg dev_std = 0.175)
NEC for r=1.0 all KL = 0.105 +- 0.148 (in-sample avg dev_std = 0.175)
NEC for r=1.0 all L1 = 0.245 +- 0.185 (in-sample avg dev_std = 0.175)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.509
Model XAI F1 of binarized graphs for r=0.3 =  0.28875375
Model XAI WIoU of binarized graphs for r=0.3 =  0.6517937500000001
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.35
NEC for r=0.3 class 0 = 0.461 +- 0.303 (in-sample avg dev_std = 0.208)
NEC for r=0.3 class 1 = 0.286 +- 0.303 (in-sample avg dev_std = 0.208)
NEC for r=0.3 class 2 = 0.542 +- 0.303 (in-sample avg dev_std = 0.208)
NEC for r=0.3 all KL = 0.326 +- 0.303 (in-sample avg dev_std = 0.208)
NEC for r=0.3 all L1 = 0.427 +- 0.252 (in-sample avg dev_std = 0.208)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.485
Model XAI F1 of binarized graphs for r=0.6 =  0.16803625
Model XAI WIoU of binarized graphs for r=0.6 =  0.6508862500000001
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.361
NEC for r=0.6 class 0 = 0.282 +- 0.188 (in-sample avg dev_std = 0.149)
NEC for r=0.6 class 1 = 0.163 +- 0.188 (in-sample avg dev_std = 0.149)
NEC for r=0.6 class 2 = 0.334 +- 0.188 (in-sample avg dev_std = 0.149)
NEC for r=0.6 all KL = 0.13 +- 0.188 (in-sample avg dev_std = 0.149)
NEC for r=0.6 all L1 = 0.258 +- 0.204 (in-sample avg dev_std = 0.149)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.447
Model XAI F1 of binarized graphs for r=0.9 =  0.12036374999999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.65085
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.352
NEC for r=0.9 class 0 = 0.212 +- 0.121 (in-sample avg dev_std = 0.101)
NEC for r=0.9 class 1 = 0.121 +- 0.121 (in-sample avg dev_std = 0.101)
NEC for r=0.9 class 2 = 0.254 +- 0.121 (in-sample avg dev_std = 0.101)
NEC for r=0.9 all KL = 0.073 +- 0.121 (in-sample avg dev_std = 0.101)
NEC for r=0.9 all L1 = 0.194 +- 0.173 (in-sample avg dev_std = 0.101)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.442
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.65085
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.346
NEC for r=1.0 class 0 = 0.199 +- 0.111 (in-sample avg dev_std = 0.088)
NEC for r=1.0 class 1 = 0.116 +- 0.111 (in-sample avg dev_std = 0.088)
NEC for r=1.0 class 2 = 0.245 +- 0.111 (in-sample avg dev_std = 0.088)
NEC for r=1.0 all KL = 0.065 +- 0.111 (in-sample avg dev_std = 0.088)
NEC for r=1.0 all L1 = 0.185 +- 0.168 (in-sample avg dev_std = 0.088)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.736, 0.735, 0.871, 1.0], 'all_L1': [0.679, 0.655, 0.753, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.574, 0.646, 0.783, 1.0], 'all_L1': [0.59, 0.588, 0.679, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.46, 0.534, 0.701, 1.0], 'all_L1': [0.503, 0.518, 0.62, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.43, 0.625, 0.828, 1.0], 'all_L1': [0.518, 0.61, 0.746, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.531, 0.698, 0.868, 1.0], 'all_L1': [0.565, 0.667, 0.779, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.448, 0.371, 0.264, 0.239], 'all_L1': [0.466, 0.422, 0.365, 0.351]}), defaultdict(<class 'list'>, {'all_KL': [0.494, 0.351, 0.273, 0.258], 'all_L1': [0.476, 0.412, 0.385, 0.375]}), defaultdict(<class 'list'>, {'all_KL': [0.54, 0.459, 0.354, 0.328], 'all_L1': [0.515, 0.473, 0.421, 0.414]}), defaultdict(<class 'list'>, {'all_KL': [0.551, 0.457, 0.346, 0.314], 'all_L1': [0.489, 0.455, 0.407, 0.388]}), defaultdict(<class 'list'>, {'all_KL': [0.562, 0.477, 0.355, 0.334], 'all_L1': [0.492, 0.449, 0.392, 0.385]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.738, 0.802, 0.917, 1.0], 'all_L1': [0.63, 0.652, 0.771, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.617, 0.778, 0.888, 1.0], 'all_L1': [0.546, 0.63, 0.726, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.565, 0.734, 0.837, 1.0], 'all_L1': [0.517, 0.598, 0.689, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.549, 0.728, 0.933, 1.0], 'all_L1': [0.526, 0.629, 0.818, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.657, 0.826, 0.944, 1.0], 'all_L1': [0.617, 0.685, 0.822, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.373, 0.183, 0.122, 0.105], 'all_L1': [0.47, 0.324, 0.259, 0.243]}), defaultdict(<class 'list'>, {'all_KL': [0.371, 0.171, 0.105, 0.093], 'all_L1': [0.468, 0.322, 0.256, 0.246]}), defaultdict(<class 'list'>, {'all_KL': [0.515, 0.284, 0.183, 0.173], 'all_L1': [0.56, 0.412, 0.32, 0.313]}), defaultdict(<class 'list'>, {'all_KL': [0.464, 0.203, 0.102, 0.083], 'all_L1': [0.498, 0.32, 0.221, 0.205]}), defaultdict(<class 'list'>, {'all_KL': [0.505, 0.229, 0.123, 0.105], 'all_L1': [0.52, 0.354, 0.26, 0.245]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.701, 0.779, 0.901, 1.0], 'all_L1': [0.565, 0.625, 0.768, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.735, 0.855, 0.892, 1.0], 'all_L1': [0.584, 0.705, 0.763, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.755, 0.825, 0.943, 1.0], 'all_L1': [0.627, 0.686, 0.82, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.542, 0.743, 0.912, 1.0], 'all_L1': [0.487, 0.635, 0.811, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.656, 0.775, 0.879, 1.0], 'all_L1': [0.565, 0.654, 0.773, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.325, 0.142, 0.077, 0.064], 'all_L1': [0.448, 0.297, 0.234, 0.216]}), defaultdict(<class 'list'>, {'all_KL': [0.165, 0.108, 0.06, 0.049], 'all_L1': [0.307, 0.253, 0.196, 0.18]}), defaultdict(<class 'list'>, {'all_KL': [0.249, 0.135, 0.069, 0.054], 'all_L1': [0.412, 0.293, 0.208, 0.189]}), defaultdict(<class 'list'>, {'all_KL': [0.33, 0.116, 0.052, 0.041], 'all_L1': [0.436, 0.249, 0.165, 0.149]}), defaultdict(<class 'list'>, {'all_KL': [0.326, 0.13, 0.073, 0.065], 'all_L1': [0.427, 0.258, 0.194, 0.185]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.571 +- 0.062, 0.608 +- 0.053, 0.715 +- 0.058, 1.000 +- 0.000
suff++ class all_KL  =  0.546 +- 0.108, 0.648 +- 0.069, 0.810 +- 0.063, 1.000 +- 0.000
suff++_acc_int  =  0.476 +- 0.059, 0.531 +- 0.082, 0.604 +- 0.090
nec class all_L1  =  0.488 +- 0.017, 0.442 +- 0.022, 0.394 +- 0.019, 0.383 +- 0.020
nec class all_KL  =  0.519 +- 0.042, 0.423 +- 0.051, 0.318 +- 0.041, 0.295 +- 0.039
nec_acc_int  =  0.375 +- 0.010, 0.446 +- 0.011, 0.470 +- 0.026, 0.467 +- 0.032

Eval split val
suff++ class all_L1  =  0.567 +- 0.047, 0.639 +- 0.029, 0.765 +- 0.052, 1.000 +- 0.000
suff++ class all_KL  =  0.625 +- 0.068, 0.774 +- 0.038, 0.904 +- 0.038, 1.000 +- 0.000
suff++_acc_int  =  0.524 +- 0.062, 0.525 +- 0.054, 0.484 +- 0.064
nec class all_L1  =  0.503 +- 0.034, 0.346 +- 0.035, 0.263 +- 0.032, 0.250 +- 0.035
nec class all_KL  =  0.446 +- 0.062, 0.214 +- 0.040, 0.127 +- 0.029, 0.112 +- 0.032
nec_acc_int  =  0.389 +- 0.014, 0.440 +- 0.048, 0.439 +- 0.061, 0.424 +- 0.055

Eval split test
suff++ class all_L1  =  0.566 +- 0.045, 0.661 +- 0.030, 0.787 +- 0.024, 1.000 +- 0.000
suff++ class all_KL  =  0.678 +- 0.076, 0.795 +- 0.040, 0.905 +- 0.022, 1.000 +- 0.000
suff++_acc_int  =  0.473 +- 0.048, 0.424 +- 0.044, 0.385 +- 0.026
nec class all_L1  =  0.406 +- 0.051, 0.270 +- 0.021, 0.199 +- 0.022, 0.184 +- 0.021
nec class all_KL  =  0.279 +- 0.065, 0.126 +- 0.012, 0.066 +- 0.009, 0.055 +- 0.009
nec_acc_int  =  0.360 +- 0.027, 0.385 +- 0.049, 0.378 +- 0.037, 0.373 +- 0.030


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.529 +- 0.024, 0.525 +- 0.024, 0.555 +- 0.025, 0.691 +- 0.010
Faith. Armon (L1)= 		  =  0.524 +- 0.017, 0.510 +- 0.019, 0.507 +- 0.015, 0.553 +- 0.021
Faith. GMean (L1)= 	  =  0.526 +- 0.021, 0.517 +- 0.021, 0.530 +- 0.018, 0.618 +- 0.016
Faith. Aritm (KL)= 		  =  0.533 +- 0.036, 0.535 +- 0.034, 0.564 +- 0.033, 0.647 +- 0.019
Faith. Armon (KL)= 		  =  0.523 +- 0.028, 0.507 +- 0.038, 0.454 +- 0.042, 0.454 +- 0.047
Faith. GMean (KL)= 	  =  0.528 +- 0.032, 0.521 +- 0.035, 0.506 +- 0.034, 0.542 +- 0.036

Eval split val
Faith. Aritm (L1)= 		  =  0.535 +- 0.023, 0.493 +- 0.017, 0.514 +- 0.017, 0.625 +- 0.017
Faith. Armon (L1)= 		  =  0.531 +- 0.022, 0.448 +- 0.025, 0.389 +- 0.029, 0.399 +- 0.044
Faith. GMean (L1)= 	  =  0.533 +- 0.022, 0.469 +- 0.021, 0.447 +- 0.017, 0.499 +- 0.034
Faith. Aritm (KL)= 		  =  0.535 +- 0.032, 0.494 +- 0.023, 0.515 +- 0.012, 0.556 +- 0.016
Faith. Armon (KL)= 		  =  0.514 +- 0.037, 0.333 +- 0.046, 0.221 +- 0.042, 0.200 +- 0.050
Faith. GMean (KL)= 	  =  0.525 +- 0.033, 0.405 +- 0.035, 0.336 +- 0.031, 0.331 +- 0.044

Eval split test
Faith. Aritm (L1)= 		  =  0.486 +- 0.028, 0.465 +- 0.017, 0.493 +- 0.013, 0.592 +- 0.011
Faith. Armon (L1)= 		  =  0.469 +- 0.036, 0.383 +- 0.020, 0.317 +- 0.028, 0.310 +- 0.031
Faith. GMean (L1)= 	  =  0.477 +- 0.032, 0.422 +- 0.017, 0.395 +- 0.021, 0.428 +- 0.025
Faith. Aritm (KL)= 		  =  0.478 +- 0.030, 0.461 +- 0.019, 0.486 +- 0.011, 0.527 +- 0.005
Faith. Armon (KL)= 		  =  0.387 +- 0.063, 0.217 +- 0.018, 0.123 +- 0.016, 0.103 +- 0.016
Faith. GMean (KL)= 	  =  0.429 +- 0.045, 0.316 +- 0.016, 0.244 +- 0.017, 0.233 +- 0.020
Computed for split load_split = id



Completed in  0:34:35.937694  for LECIvGIN GOODMotif/size



DONE LECI GOODMotif/size

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 12:47:18 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:18 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:21 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:25 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:28 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:47:31 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 57...
[0m[1;37mINFO[0m: [1mCheckpoint 57: 
-----------------------------------
Train ROC-AUC: 0.7730
Train Loss: 0.1348
ID Validation ROC-AUC: 0.7933
ID Validation Loss: 0.1467
ID Test ROC-AUC: 0.7708
ID Test Loss: 0.1303
OOD Validation ROC-AUC: 0.7037
OOD Validation Loss: 0.1264
OOD Test ROC-AUC: 0.6063
OOD Test Loss: 0.0994

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 63...
[0m[1;37mINFO[0m: [1mCheckpoint 63: 
-----------------------------------
Train ROC-AUC: 0.7758
Train Loss: 0.1299
ID Validation ROC-AUC: 0.7610
ID Validation Loss: 0.1417
ID Test ROC-AUC: 0.7672
ID Test Loss: 0.1230
OOD Validation ROC-AUC: 0.7334
OOD Validation Loss: 0.1156
OOD Test ROC-AUC: 0.6217
OOD Test Loss: 0.0941

[0m[1;37mINFO[0m: [1mChartInfo 0.7708 0.6063 0.7672 0.6217 0.7610 0.7334[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 04/22/2024 12:47:32 PM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 04/22/2024 12:47:34 PM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 04/22/2024 12:47:36 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.629
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.614
SUFF++ for r=0.3 class 0.0 = 0.955 +- 0.018 (in-sample avg dev_std = 0.060)
SUFF++ for r=0.3 class 1.0 = 0.939 +- 0.018 (in-sample avg dev_std = 0.060)
SUFF++ for r=0.3 all KL = 0.983 +- 0.018 (in-sample avg dev_std = 0.060)
SUFF++ for r=0.3 all L1 = 0.947 +- 0.043 (in-sample avg dev_std = 0.060)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.769
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.715
SUFF++ for r=0.6 class 0.0 = 0.961 +- 0.032 (in-sample avg dev_std = 0.071)
SUFF++ for r=0.6 class 1.0 = 0.924 +- 0.032 (in-sample avg dev_std = 0.071)
SUFF++ for r=0.6 all KL = 0.982 +- 0.032 (in-sample avg dev_std = 0.071)
SUFF++ for r=0.6 all L1 = 0.943 +- 0.061 (in-sample avg dev_std = 0.071)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.8
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.775
SUFF++ for r=0.9 class 0.0 = 0.973 +- 0.056 (in-sample avg dev_std = 0.094)
SUFF++ for r=0.9 class 1.0 = 0.906 +- 0.056 (in-sample avg dev_std = 0.094)
SUFF++ for r=0.9 all KL = 0.98 +- 0.056 (in-sample avg dev_std = 0.094)
SUFF++ for r=0.9 all L1 = 0.939 +- 0.094 (in-sample avg dev_std = 0.094)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.73
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.632
SUFF++ for r=0.3 class 0.0 = 0.961 +- 0.015 (in-sample avg dev_std = 0.055)
SUFF++ for r=0.3 class 1.0 = 0.934 +- 0.015 (in-sample avg dev_std = 0.055)
SUFF++ for r=0.3 all KL = 0.985 +- 0.015 (in-sample avg dev_std = 0.055)
SUFF++ for r=0.3 all L1 = 0.947 +- 0.040 (in-sample avg dev_std = 0.055)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.722
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.654
SUFF++ for r=0.6 class 0.0 = 0.957 +- 0.020 (in-sample avg dev_std = 0.056)
SUFF++ for r=0.6 class 1.0 = 0.925 +- 0.020 (in-sample avg dev_std = 0.056)
SUFF++ for r=0.6 all KL = 0.985 +- 0.020 (in-sample avg dev_std = 0.056)
SUFF++ for r=0.6 all L1 = 0.941 +- 0.050 (in-sample avg dev_std = 0.056)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.744
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.714
SUFF++ for r=0.9 class 0.0 = 0.959 +- 0.028 (in-sample avg dev_std = 0.069)
SUFF++ for r=0.9 class 1.0 = 0.924 +- 0.028 (in-sample avg dev_std = 0.069)
SUFF++ for r=0.9 all KL = 0.985 +- 0.028 (in-sample avg dev_std = 0.069)
SUFF++ for r=0.9 all L1 = 0.942 +- 0.068 (in-sample avg dev_std = 0.069)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.554
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.524
SUFF++ for r=0.3 class 0.0 = 0.957 +- 0.013 (in-sample avg dev_std = 0.042)
SUFF++ for r=0.3 class 1.0 = 0.957 +- 0.013 (in-sample avg dev_std = 0.042)
SUFF++ for r=0.3 all KL = 0.988 +- 0.013 (in-sample avg dev_std = 0.042)
SUFF++ for r=0.3 all L1 = 0.957 +- 0.034 (in-sample avg dev_std = 0.042)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.547
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.553
SUFF++ for r=0.6 class 0.0 = 0.96 +- 0.016 (in-sample avg dev_std = 0.047)
SUFF++ for r=0.6 class 1.0 = 0.959 +- 0.016 (in-sample avg dev_std = 0.047)
SUFF++ for r=0.6 all KL = 0.989 +- 0.016 (in-sample avg dev_std = 0.047)
SUFF++ for r=0.6 all L1 = 0.96 +- 0.036 (in-sample avg dev_std = 0.047)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.555
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.555
SUFF++ for r=0.9 class 0.0 = 0.974 +- 0.011 (in-sample avg dev_std = 0.030)
SUFF++ for r=0.9 class 1.0 = 0.964 +- 0.011 (in-sample avg dev_std = 0.030)
SUFF++ for r=0.9 all KL = 0.993 +- 0.011 (in-sample avg dev_std = 0.030)
SUFF++ for r=0.9 all L1 = 0.969 +- 0.033 (in-sample avg dev_std = 0.030)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.63
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.636
NEC for r=0.3 class 0.0 = 0.046 +- 0.022 (in-sample avg dev_std = 0.036)
NEC for r=0.3 class 1.0 = 0.051 +- 0.022 (in-sample avg dev_std = 0.036)
NEC for r=0.3 all KL = 0.015 +- 0.022 (in-sample avg dev_std = 0.036)
NEC for r=0.3 all L1 = 0.049 +- 0.045 (in-sample avg dev_std = 0.036)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.77
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.725
NEC for r=0.6 class 0.0 = 0.032 +- 0.036 (in-sample avg dev_std = 0.042)
NEC for r=0.6 class 1.0 = 0.071 +- 0.036 (in-sample avg dev_std = 0.042)
NEC for r=0.6 all KL = 0.015 +- 0.036 (in-sample avg dev_std = 0.042)
NEC for r=0.6 all L1 = 0.051 +- 0.068 (in-sample avg dev_std = 0.042)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.8
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.762
NEC for r=0.9 class 0.0 = 0.032 +- 0.042 (in-sample avg dev_std = 0.074)
NEC for r=0.9 class 1.0 = 0.096 +- 0.042 (in-sample avg dev_std = 0.074)
NEC for r=0.9 all KL = 0.019 +- 0.042 (in-sample avg dev_std = 0.074)
NEC for r=0.9 all L1 = 0.064 +- 0.089 (in-sample avg dev_std = 0.074)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.797
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.766
NEC for r=1.0 class 0.0 = 0.033 +- 0.050 (in-sample avg dev_std = 0.077)
NEC for r=1.0 class 1.0 = 0.106 +- 0.050 (in-sample avg dev_std = 0.077)
NEC for r=1.0 all KL = 0.022 +- 0.050 (in-sample avg dev_std = 0.077)
NEC for r=1.0 all L1 = 0.07 +- 0.099 (in-sample avg dev_std = 0.077)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.73
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.618
NEC for r=0.3 class 0.0 = 0.042 +- 0.021 (in-sample avg dev_std = 0.045)
NEC for r=0.3 class 1.0 = 0.061 +- 0.021 (in-sample avg dev_std = 0.045)
NEC for r=0.3 all KL = 0.016 +- 0.021 (in-sample avg dev_std = 0.045)
NEC for r=0.3 all L1 = 0.051 +- 0.043 (in-sample avg dev_std = 0.045)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.723
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.684
NEC for r=0.6 class 0.0 = 0.039 +- 0.014 (in-sample avg dev_std = 0.038)
NEC for r=0.6 class 1.0 = 0.059 +- 0.014 (in-sample avg dev_std = 0.038)
NEC for r=0.6 all KL = 0.011 +- 0.014 (in-sample avg dev_std = 0.038)
NEC for r=0.6 all L1 = 0.049 +- 0.043 (in-sample avg dev_std = 0.038)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.745
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.697
NEC for r=0.9 class 0.0 = 0.045 +- 0.025 (in-sample avg dev_std = 0.058)
NEC for r=0.9 class 1.0 = 0.076 +- 0.025 (in-sample avg dev_std = 0.058)
NEC for r=0.9 all KL = 0.015 +- 0.025 (in-sample avg dev_std = 0.058)
NEC for r=0.9 all L1 = 0.06 +- 0.067 (in-sample avg dev_std = 0.058)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.754
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.696
NEC for r=1.0 class 0.0 = 0.042 +- 0.034 (in-sample avg dev_std = 0.065)
NEC for r=1.0 class 1.0 = 0.085 +- 0.034 (in-sample avg dev_std = 0.065)
NEC for r=1.0 all KL = 0.016 +- 0.034 (in-sample avg dev_std = 0.065)
NEC for r=1.0 all L1 = 0.063 +- 0.077 (in-sample avg dev_std = 0.065)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.565
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.515
NEC for r=0.3 class 0.0 = 0.043 +- 0.017 (in-sample avg dev_std = 0.037)
NEC for r=0.3 class 1.0 = 0.048 +- 0.017 (in-sample avg dev_std = 0.037)
NEC for r=0.3 all KL = 0.014 +- 0.017 (in-sample avg dev_std = 0.037)
NEC for r=0.3 all L1 = 0.046 +- 0.038 (in-sample avg dev_std = 0.037)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.542
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.525
NEC for r=0.6 class 0.0 = 0.037 +- 0.011 (in-sample avg dev_std = 0.023)
NEC for r=0.6 class 1.0 = 0.035 +- 0.011 (in-sample avg dev_std = 0.023)
NEC for r=0.6 all KL = 0.008 +- 0.011 (in-sample avg dev_std = 0.023)
NEC for r=0.6 all L1 = 0.036 +- 0.033 (in-sample avg dev_std = 0.023)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.557
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.575
NEC for r=0.9 class 0.0 = 0.03 +- 0.012 (in-sample avg dev_std = 0.027)
NEC for r=0.9 class 1.0 = 0.041 +- 0.012 (in-sample avg dev_std = 0.027)
NEC for r=0.9 all KL = 0.008 +- 0.012 (in-sample avg dev_std = 0.027)
NEC for r=0.9 all L1 = 0.036 +- 0.034 (in-sample avg dev_std = 0.027)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.592
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.572
NEC for r=1.0 class 0.0 = 0.027 +- 0.013 (in-sample avg dev_std = 0.033)
NEC for r=1.0 class 1.0 = 0.044 +- 0.013 (in-sample avg dev_std = 0.033)
NEC for r=1.0 all KL = 0.009 +- 0.013 (in-sample avg dev_std = 0.033)
NEC for r=1.0 all L1 = 0.036 +- 0.037 (in-sample avg dev_std = 0.033)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 12:48:56 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 04/22/2024 12:48:56 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:00 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:04 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:07 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 69...
[0m[1;37mINFO[0m: [1mCheckpoint 69: 
-----------------------------------
Train ROC-AUC: 0.7579
Train Loss: 0.1325
ID Validation ROC-AUC: 0.7772
ID Validation Loss: 0.1410
ID Test ROC-AUC: 0.7435
ID Test Loss: 0.1284
OOD Validation ROC-AUC: 0.6853
OOD Validation Loss: 0.1253
OOD Test ROC-AUC: 0.6787
OOD Test Loss: 0.0952

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 67...
[0m[1;37mINFO[0m: [1mCheckpoint 67: 
-----------------------------------
Train ROC-AUC: 0.7790
Train Loss: 0.1329
ID Validation ROC-AUC: 0.7716
ID Validation Loss: 0.1464
ID Test ROC-AUC: 0.7662
ID Test Loss: 0.1259
OOD Validation ROC-AUC: 0.7458
OOD Validation Loss: 0.1209
OOD Test ROC-AUC: 0.5971
OOD Test Loss: 0.0998

[0m[1;37mINFO[0m: [1mChartInfo 0.7435 0.6787 0.7662 0.5971 0.7716 0.7458[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 04/22/2024 12:49:10 PM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 04/22/2024 12:49:12 PM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 04/22/2024 12:49:14 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.579
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 351
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.524
SUFF++ for r=0.3 class 0.0 = 0.947 +- 0.023 (in-sample avg dev_std = 0.047)
SUFF++ for r=0.3 class 1.0 = 0.932 +- 0.023 (in-sample avg dev_std = 0.047)
SUFF++ for r=0.3 all KL = 0.981 +- 0.023 (in-sample avg dev_std = 0.047)
SUFF++ for r=0.3 all L1 = 0.94 +- 0.059 (in-sample avg dev_std = 0.047)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.615
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.627
SUFF++ for r=0.6 class 0.0 = 0.951 +- 0.028 (in-sample avg dev_std = 0.072)
SUFF++ for r=0.6 class 1.0 = 0.918 +- 0.028 (in-sample avg dev_std = 0.072)
SUFF++ for r=0.6 all KL = 0.979 +- 0.028 (in-sample avg dev_std = 0.072)
SUFF++ for r=0.6 all L1 = 0.934 +- 0.058 (in-sample avg dev_std = 0.072)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.742
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.703
SUFF++ for r=0.9 class 0.0 = 0.959 +- 0.059 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.9 class 1.0 = 0.877 +- 0.059 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.9 all KL = 0.971 +- 0.059 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.9 all L1 = 0.918 +- 0.107 (in-sample avg dev_std = 0.105)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.646
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.527
SUFF++ for r=0.3 class 0.0 = 0.935 +- 0.028 (in-sample avg dev_std = 0.054)
SUFF++ for r=0.3 class 1.0 = 0.902 +- 0.028 (in-sample avg dev_std = 0.054)
SUFF++ for r=0.3 all KL = 0.973 +- 0.028 (in-sample avg dev_std = 0.054)
SUFF++ for r=0.3 all L1 = 0.918 +- 0.068 (in-sample avg dev_std = 0.054)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.576
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.596
SUFF++ for r=0.6 class 0.0 = 0.937 +- 0.018 (in-sample avg dev_std = 0.046)
SUFF++ for r=0.6 class 1.0 = 0.93 +- 0.018 (in-sample avg dev_std = 0.046)
SUFF++ for r=0.6 all KL = 0.982 +- 0.018 (in-sample avg dev_std = 0.046)
SUFF++ for r=0.6 all L1 = 0.934 +- 0.049 (in-sample avg dev_std = 0.046)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.574
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.586
SUFF++ for r=0.9 class 0.0 = 0.955 +- 0.038 (in-sample avg dev_std = 0.079)
SUFF++ for r=0.9 class 1.0 = 0.912 +- 0.038 (in-sample avg dev_std = 0.079)
SUFF++ for r=0.9 all KL = 0.979 +- 0.038 (in-sample avg dev_std = 0.079)
SUFF++ for r=0.9 all L1 = 0.934 +- 0.075 (in-sample avg dev_std = 0.079)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.537
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.494
SUFF++ for r=0.3 class 0.0 = 0.942 +- 0.019 (in-sample avg dev_std = 0.045)
SUFF++ for r=0.3 class 1.0 = 0.937 +- 0.019 (in-sample avg dev_std = 0.045)
SUFF++ for r=0.3 all KL = 0.982 +- 0.019 (in-sample avg dev_std = 0.045)
SUFF++ for r=0.3 all L1 = 0.94 +- 0.047 (in-sample avg dev_std = 0.045)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.481
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.503
SUFF++ for r=0.6 class 0.0 = 0.955 +- 0.012 (in-sample avg dev_std = 0.042)
SUFF++ for r=0.6 class 1.0 = 0.955 +- 0.012 (in-sample avg dev_std = 0.042)
SUFF++ for r=0.6 all KL = 0.988 +- 0.012 (in-sample avg dev_std = 0.042)
SUFF++ for r=0.6 all L1 = 0.955 +- 0.029 (in-sample avg dev_std = 0.042)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.473
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.482
SUFF++ for r=0.9 class 0.0 = 0.963 +- 0.012 (in-sample avg dev_std = 0.035)
SUFF++ for r=0.9 class 1.0 = 0.962 +- 0.012 (in-sample avg dev_std = 0.035)
SUFF++ for r=0.9 all KL = 0.991 +- 0.012 (in-sample avg dev_std = 0.035)
SUFF++ for r=0.9 all L1 = 0.962 +- 0.029 (in-sample avg dev_std = 0.035)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.581
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.533
NEC for r=0.3 class 0.0 = 0.058 +- 0.027 (in-sample avg dev_std = 0.042)
NEC for r=0.3 class 1.0 = 0.06 +- 0.027 (in-sample avg dev_std = 0.042)
NEC for r=0.3 all KL = 0.019 +- 0.027 (in-sample avg dev_std = 0.042)
NEC for r=0.3 all L1 = 0.059 +- 0.054 (in-sample avg dev_std = 0.042)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.618
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.633
NEC for r=0.6 class 0.0 = 0.047 +- 0.033 (in-sample avg dev_std = 0.055)
NEC for r=0.6 class 1.0 = 0.073 +- 0.033 (in-sample avg dev_std = 0.055)
NEC for r=0.6 all KL = 0.018 +- 0.033 (in-sample avg dev_std = 0.055)
NEC for r=0.6 all L1 = 0.06 +- 0.058 (in-sample avg dev_std = 0.055)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.743
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.725
NEC for r=0.9 class 0.0 = 0.04 +- 0.056 (in-sample avg dev_std = 0.094)
NEC for r=0.9 class 1.0 = 0.122 +- 0.056 (in-sample avg dev_std = 0.094)
NEC for r=0.9 all KL = 0.027 +- 0.056 (in-sample avg dev_std = 0.094)
NEC for r=0.9 all L1 = 0.081 +- 0.103 (in-sample avg dev_std = 0.094)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.752
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.725
NEC for r=1.0 class 0.0 = 0.04 +- 0.071 (in-sample avg dev_std = 0.116)
NEC for r=1.0 class 1.0 = 0.144 +- 0.071 (in-sample avg dev_std = 0.116)
NEC for r=1.0 all KL = 0.034 +- 0.071 (in-sample avg dev_std = 0.116)
NEC for r=1.0 all L1 = 0.092 +- 0.121 (in-sample avg dev_std = 0.116)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.646
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.592
NEC for r=0.3 class 0.0 = 0.061 +- 0.025 (in-sample avg dev_std = 0.045)
NEC for r=0.3 class 1.0 = 0.084 +- 0.025 (in-sample avg dev_std = 0.045)
NEC for r=0.3 all KL = 0.022 +- 0.025 (in-sample avg dev_std = 0.045)
NEC for r=0.3 all L1 = 0.072 +- 0.058 (in-sample avg dev_std = 0.045)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.574
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.603
NEC for r=0.6 class 0.0 = 0.058 +- 0.017 (in-sample avg dev_std = 0.037)
NEC for r=0.6 class 1.0 = 0.062 +- 0.017 (in-sample avg dev_std = 0.037)
NEC for r=0.6 all KL = 0.016 +- 0.017 (in-sample avg dev_std = 0.037)
NEC for r=0.6 all L1 = 0.06 +- 0.043 (in-sample avg dev_std = 0.037)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.574
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.628
NEC for r=0.9 class 0.0 = 0.051 +- 0.034 (in-sample avg dev_std = 0.061)
NEC for r=0.9 class 1.0 = 0.083 +- 0.034 (in-sample avg dev_std = 0.061)
NEC for r=0.9 all KL = 0.018 +- 0.034 (in-sample avg dev_std = 0.061)
NEC for r=0.9 all L1 = 0.067 +- 0.071 (in-sample avg dev_std = 0.061)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.604
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.645
NEC for r=1.0 class 0.0 = 0.049 +- 0.062 (in-sample avg dev_std = 0.096)
NEC for r=1.0 class 1.0 = 0.105 +- 0.062 (in-sample avg dev_std = 0.096)
NEC for r=1.0 all KL = 0.026 +- 0.062 (in-sample avg dev_std = 0.096)
NEC for r=1.0 all L1 = 0.077 +- 0.104 (in-sample avg dev_std = 0.096)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.542
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.464
NEC for r=0.3 class 0.0 = 0.059 +- 0.019 (in-sample avg dev_std = 0.043)
NEC for r=0.3 class 1.0 = 0.06 +- 0.019 (in-sample avg dev_std = 0.043)
NEC for r=0.3 all KL = 0.018 +- 0.019 (in-sample avg dev_std = 0.043)
NEC for r=0.3 all L1 = 0.059 +- 0.041 (in-sample avg dev_std = 0.043)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.5
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.51
NEC for r=0.6 class 0.0 = 0.04 +- 0.014 (in-sample avg dev_std = 0.033)
NEC for r=0.6 class 1.0 = 0.041 +- 0.014 (in-sample avg dev_std = 0.033)
NEC for r=0.6 all KL = 0.01 +- 0.014 (in-sample avg dev_std = 0.033)
NEC for r=0.6 all L1 = 0.041 +- 0.028 (in-sample avg dev_std = 0.033)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.473
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.541
NEC for r=0.9 class 0.0 = 0.039 +- 0.021 (in-sample avg dev_std = 0.035)
NEC for r=0.9 class 1.0 = 0.044 +- 0.021 (in-sample avg dev_std = 0.035)
NEC for r=0.9 all KL = 0.011 +- 0.021 (in-sample avg dev_std = 0.035)
NEC for r=0.9 all L1 = 0.041 +- 0.034 (in-sample avg dev_std = 0.035)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.519
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.535
NEC for r=1.0 class 0.0 = 0.035 +- 0.032 (in-sample avg dev_std = 0.044)
NEC for r=1.0 class 1.0 = 0.049 +- 0.032 (in-sample avg dev_std = 0.044)
NEC for r=1.0 all KL = 0.012 +- 0.032 (in-sample avg dev_std = 0.044)
NEC for r=1.0 all L1 = 0.042 +- 0.041 (in-sample avg dev_std = 0.044)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 12:50:33 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:33 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:37 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:40 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:43 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 69...
[0m[1;37mINFO[0m: [1mCheckpoint 69: 
-----------------------------------
Train ROC-AUC: 0.7491
Train Loss: 0.1359
ID Validation ROC-AUC: 0.7872
ID Validation Loss: 0.1437
ID Test ROC-AUC: 0.7145
ID Test Loss: 0.1301
OOD Validation ROC-AUC: 0.7184
OOD Validation Loss: 0.1199
OOD Test ROC-AUC: 0.5924
OOD Test Loss: 0.1030

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 71...
[0m[1;37mINFO[0m: [1mCheckpoint 71: 
-----------------------------------
Train ROC-AUC: 0.7819
Train Loss: 0.1312
ID Validation ROC-AUC: 0.7665
ID Validation Loss: 0.1461
ID Test ROC-AUC: 0.7460
ID Test Loss: 0.1338
OOD Validation ROC-AUC: 0.7333
OOD Validation Loss: 0.1238
OOD Test ROC-AUC: 0.6410
OOD Test Loss: 0.0964

[0m[1;37mINFO[0m: [1mChartInfo 0.7145 0.5924 0.7460 0.6410 0.7665 0.7333[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 04/22/2024 12:50:46 PM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 04/22/2024 12:50:48 PM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 04/22/2024 12:50:49 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.511
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.519
SUFF++ for r=0.3 class 0.0 = 0.944 +- 0.018 (in-sample avg dev_std = 0.051)
SUFF++ for r=0.3 class 1.0 = 0.936 +- 0.018 (in-sample avg dev_std = 0.051)
SUFF++ for r=0.3 all KL = 0.983 +- 0.018 (in-sample avg dev_std = 0.051)
SUFF++ for r=0.3 all L1 = 0.94 +- 0.043 (in-sample avg dev_std = 0.051)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.64
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.633
SUFF++ for r=0.6 class 0.0 = 0.944 +- 0.036 (in-sample avg dev_std = 0.076)
SUFF++ for r=0.6 class 1.0 = 0.912 +- 0.036 (in-sample avg dev_std = 0.076)
SUFF++ for r=0.6 all KL = 0.977 +- 0.036 (in-sample avg dev_std = 0.076)
SUFF++ for r=0.6 all L1 = 0.928 +- 0.058 (in-sample avg dev_std = 0.076)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.725
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.734
SUFF++ for r=0.9 class 0.0 = 0.963 +- 0.057 (in-sample avg dev_std = 0.083)
SUFF++ for r=0.9 class 1.0 = 0.898 +- 0.057 (in-sample avg dev_std = 0.083)
SUFF++ for r=0.9 all KL = 0.977 +- 0.057 (in-sample avg dev_std = 0.083)
SUFF++ for r=0.9 all L1 = 0.93 +- 0.086 (in-sample avg dev_std = 0.083)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.503
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.486
SUFF++ for r=0.3 class 0.0 = 0.944 +- 0.015 (in-sample avg dev_std = 0.046)
SUFF++ for r=0.3 class 1.0 = 0.94 +- 0.015 (in-sample avg dev_std = 0.046)
SUFF++ for r=0.3 all KL = 0.984 +- 0.015 (in-sample avg dev_std = 0.046)
SUFF++ for r=0.3 all L1 = 0.942 +- 0.035 (in-sample avg dev_std = 0.046)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.545
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.557
SUFF++ for r=0.6 class 0.0 = 0.946 +- 0.021 (in-sample avg dev_std = 0.059)
SUFF++ for r=0.6 class 1.0 = 0.932 +- 0.021 (in-sample avg dev_std = 0.059)
SUFF++ for r=0.6 all KL = 0.981 +- 0.021 (in-sample avg dev_std = 0.059)
SUFF++ for r=0.6 all L1 = 0.939 +- 0.039 (in-sample avg dev_std = 0.059)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.646
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.657
SUFF++ for r=0.9 class 0.0 = 0.957 +- 0.079 (in-sample avg dev_std = 0.076)
SUFF++ for r=0.9 class 1.0 = 0.88 +- 0.079 (in-sample avg dev_std = 0.076)
SUFF++ for r=0.9 all KL = 0.965 +- 0.079 (in-sample avg dev_std = 0.076)
SUFF++ for r=0.9 all L1 = 0.919 +- 0.118 (in-sample avg dev_std = 0.076)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.53
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.526
SUFF++ for r=0.3 class 0.0 = 0.939 +- 0.019 (in-sample avg dev_std = 0.052)
SUFF++ for r=0.3 class 1.0 = 0.932 +- 0.019 (in-sample avg dev_std = 0.052)
SUFF++ for r=0.3 all KL = 0.981 +- 0.019 (in-sample avg dev_std = 0.052)
SUFF++ for r=0.3 all L1 = 0.936 +- 0.040 (in-sample avg dev_std = 0.052)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.53
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.525
SUFF++ for r=0.6 class 0.0 = 0.955 +- 0.013 (in-sample avg dev_std = 0.048)
SUFF++ for r=0.6 class 1.0 = 0.943 +- 0.013 (in-sample avg dev_std = 0.048)
SUFF++ for r=0.6 all KL = 0.987 +- 0.013 (in-sample avg dev_std = 0.048)
SUFF++ for r=0.6 all L1 = 0.949 +- 0.030 (in-sample avg dev_std = 0.048)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.507
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.569
SUFF++ for r=0.9 class 0.0 = 0.967 +- 0.035 (in-sample avg dev_std = 0.043)
SUFF++ for r=0.9 class 1.0 = 0.95 +- 0.035 (in-sample avg dev_std = 0.043)
SUFF++ for r=0.9 all KL = 0.988 +- 0.035 (in-sample avg dev_std = 0.043)
SUFF++ for r=0.9 all L1 = 0.958 +- 0.043 (in-sample avg dev_std = 0.043)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.511
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.521
NEC for r=0.3 class 0.0 = 0.046 +- 0.015 (in-sample avg dev_std = 0.036)
NEC for r=0.3 class 1.0 = 0.055 +- 0.015 (in-sample avg dev_std = 0.036)
NEC for r=0.3 all KL = 0.012 +- 0.015 (in-sample avg dev_std = 0.036)
NEC for r=0.3 all L1 = 0.051 +- 0.039 (in-sample avg dev_std = 0.036)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.64
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.67
NEC for r=0.6 class 0.0 = 0.049 +- 0.019 (in-sample avg dev_std = 0.046)
NEC for r=0.6 class 1.0 = 0.068 +- 0.019 (in-sample avg dev_std = 0.046)
NEC for r=0.6 all KL = 0.014 +- 0.019 (in-sample avg dev_std = 0.046)
NEC for r=0.6 all L1 = 0.058 +- 0.048 (in-sample avg dev_std = 0.046)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.725
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.745
NEC for r=0.9 class 0.0 = 0.037 +- 0.043 (in-sample avg dev_std = 0.076)
NEC for r=0.9 class 1.0 = 0.096 +- 0.043 (in-sample avg dev_std = 0.076)
NEC for r=0.9 all KL = 0.019 +- 0.043 (in-sample avg dev_std = 0.076)
NEC for r=0.9 all L1 = 0.066 +- 0.076 (in-sample avg dev_std = 0.076)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.729
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.764
NEC for r=1.0 class 0.0 = 0.035 +- 0.048 (in-sample avg dev_std = 0.073)
NEC for r=1.0 class 1.0 = 0.101 +- 0.048 (in-sample avg dev_std = 0.073)
NEC for r=1.0 all KL = 0.02 +- 0.048 (in-sample avg dev_std = 0.073)
NEC for r=1.0 all L1 = 0.068 +- 0.085 (in-sample avg dev_std = 0.073)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.503
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.521
NEC for r=0.3 class 0.0 = 0.052 +- 0.012 (in-sample avg dev_std = 0.035)
NEC for r=0.3 class 1.0 = 0.05 +- 0.012 (in-sample avg dev_std = 0.035)
NEC for r=0.3 all KL = 0.012 +- 0.012 (in-sample avg dev_std = 0.035)
NEC for r=0.3 all L1 = 0.051 +- 0.031 (in-sample avg dev_std = 0.035)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.545
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.571
NEC for r=0.6 class 0.0 = 0.049 +- 0.022 (in-sample avg dev_std = 0.050)
NEC for r=0.6 class 1.0 = 0.065 +- 0.022 (in-sample avg dev_std = 0.050)
NEC for r=0.6 all KL = 0.017 +- 0.022 (in-sample avg dev_std = 0.050)
NEC for r=0.6 all L1 = 0.057 +- 0.038 (in-sample avg dev_std = 0.050)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.646
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.663
NEC for r=0.9 class 0.0 = 0.046 +- 0.041 (in-sample avg dev_std = 0.084)
NEC for r=0.9 class 1.0 = 0.089 +- 0.041 (in-sample avg dev_std = 0.084)
NEC for r=0.9 all KL = 0.023 +- 0.041 (in-sample avg dev_std = 0.084)
NEC for r=0.9 all L1 = 0.068 +- 0.070 (in-sample avg dev_std = 0.084)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.691
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.689
NEC for r=1.0 class 0.0 = 0.045 +- 0.052 (in-sample avg dev_std = 0.094)
NEC for r=1.0 class 1.0 = 0.101 +- 0.052 (in-sample avg dev_std = 0.094)
NEC for r=1.0 all KL = 0.025 +- 0.052 (in-sample avg dev_std = 0.094)
NEC for r=1.0 all L1 = 0.073 +- 0.086 (in-sample avg dev_std = 0.094)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.53
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.547
NEC for r=0.3 class 0.0 = 0.057 +- 0.026 (in-sample avg dev_std = 0.043)
NEC for r=0.3 class 1.0 = 0.056 +- 0.026 (in-sample avg dev_std = 0.043)
NEC for r=0.3 all KL = 0.016 +- 0.026 (in-sample avg dev_std = 0.043)
NEC for r=0.3 all L1 = 0.056 +- 0.045 (in-sample avg dev_std = 0.043)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.53
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.566
NEC for r=0.6 class 0.0 = 0.043 +- 0.013 (in-sample avg dev_std = 0.038)
NEC for r=0.6 class 1.0 = 0.056 +- 0.013 (in-sample avg dev_std = 0.038)
NEC for r=0.6 all KL = 0.011 +- 0.013 (in-sample avg dev_std = 0.038)
NEC for r=0.6 all L1 = 0.049 +- 0.033 (in-sample avg dev_std = 0.038)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.505
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.569
NEC for r=0.9 class 0.0 = 0.043 +- 0.017 (in-sample avg dev_std = 0.040)
NEC for r=0.9 class 1.0 = 0.056 +- 0.017 (in-sample avg dev_std = 0.040)
NEC for r=0.9 all KL = 0.013 +- 0.017 (in-sample avg dev_std = 0.040)
NEC for r=0.9 all L1 = 0.05 +- 0.039 (in-sample avg dev_std = 0.040)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.547
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.584
NEC for r=1.0 class 0.0 = 0.043 +- 0.022 (in-sample avg dev_std = 0.040)
NEC for r=1.0 class 1.0 = 0.056 +- 0.022 (in-sample avg dev_std = 0.040)
NEC for r=1.0 all KL = 0.012 +- 0.022 (in-sample avg dev_std = 0.040)
NEC for r=1.0 all L1 = 0.049 +- 0.044 (in-sample avg dev_std = 0.040)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 12:52:04 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:04 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:07 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:11 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:14 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:18 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:52:18 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:52:18 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 63...
[0m[1;37mINFO[0m: [1mCheckpoint 63: 
-----------------------------------
Train ROC-AUC: 0.7807
Train Loss: 0.1342
ID Validation ROC-AUC: 0.7683
ID Validation Loss: 0.1504
ID Test ROC-AUC: 0.7966
ID Test Loss: 0.1233
OOD Validation ROC-AUC: 0.7374
OOD Validation Loss: 0.1171
OOD Test ROC-AUC: 0.6114
OOD Test Loss: 0.0989

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 63...
[0m[1;37mINFO[0m: [1mCheckpoint 63: 
-----------------------------------
Train ROC-AUC: 0.7807
Train Loss: 0.1342
ID Validation ROC-AUC: 0.7683
ID Validation Loss: 0.1504
ID Test ROC-AUC: 0.7966
ID Test Loss: 0.1233
OOD Validation ROC-AUC: 0.7374
OOD Validation Loss: 0.1171
OOD Test ROC-AUC: 0.6114
OOD Test Loss: 0.0989

[0m[1;37mINFO[0m: [1mChartInfo 0.7966 0.6114 0.7966 0.6114 0.7683 0.7374[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 04/22/2024 12:52:18 PM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 04/22/2024 12:52:19 PM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 04/22/2024 12:52:21 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.58
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.585
SUFF++ for r=0.3 class 0.0 = 0.963 +- 0.015 (in-sample avg dev_std = 0.035)
SUFF++ for r=0.3 class 1.0 = 0.955 +- 0.015 (in-sample avg dev_std = 0.035)
SUFF++ for r=0.3 all KL = 0.989 +- 0.015 (in-sample avg dev_std = 0.035)
SUFF++ for r=0.3 all L1 = 0.959 +- 0.038 (in-sample avg dev_std = 0.035)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.675
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.654
SUFF++ for r=0.6 class 0.0 = 0.967 +- 0.042 (in-sample avg dev_std = 0.070)
SUFF++ for r=0.6 class 1.0 = 0.926 +- 0.042 (in-sample avg dev_std = 0.070)
SUFF++ for r=0.6 all KL = 0.982 +- 0.042 (in-sample avg dev_std = 0.070)
SUFF++ for r=0.6 all L1 = 0.946 +- 0.074 (in-sample avg dev_std = 0.070)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.752
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.692
SUFF++ for r=0.9 class 0.0 = 0.974 +- 0.062 (in-sample avg dev_std = 0.095)
SUFF++ for r=0.9 class 1.0 = 0.892 +- 0.062 (in-sample avg dev_std = 0.095)
SUFF++ for r=0.9 all KL = 0.975 +- 0.062 (in-sample avg dev_std = 0.095)
SUFF++ for r=0.9 all L1 = 0.933 +- 0.105 (in-sample avg dev_std = 0.095)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.654
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.593
SUFF++ for r=0.3 class 0.0 = 0.956 +- 0.013 (in-sample avg dev_std = 0.035)
SUFF++ for r=0.3 class 1.0 = 0.946 +- 0.013 (in-sample avg dev_std = 0.035)
SUFF++ for r=0.3 all KL = 0.987 +- 0.013 (in-sample avg dev_std = 0.035)
SUFF++ for r=0.3 all L1 = 0.951 +- 0.036 (in-sample avg dev_std = 0.035)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.678
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.644
SUFF++ for r=0.6 class 0.0 = 0.968 +- 0.016 (in-sample avg dev_std = 0.048)
SUFF++ for r=0.6 class 1.0 = 0.929 +- 0.016 (in-sample avg dev_std = 0.048)
SUFF++ for r=0.6 all KL = 0.987 +- 0.016 (in-sample avg dev_std = 0.048)
SUFF++ for r=0.6 all L1 = 0.948 +- 0.048 (in-sample avg dev_std = 0.048)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.735
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.695
SUFF++ for r=0.9 class 0.0 = 0.966 +- 0.037 (in-sample avg dev_std = 0.088)
SUFF++ for r=0.9 class 1.0 = 0.895 +- 0.037 (in-sample avg dev_std = 0.088)
SUFF++ for r=0.9 all KL = 0.98 +- 0.037 (in-sample avg dev_std = 0.088)
SUFF++ for r=0.9 all L1 = 0.931 +- 0.093 (in-sample avg dev_std = 0.088)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.647
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.526
SUFF++ for r=0.3 class 0.0 = 0.961 +- 0.013 (in-sample avg dev_std = 0.040)
SUFF++ for r=0.3 class 1.0 = 0.951 +- 0.013 (in-sample avg dev_std = 0.040)
SUFF++ for r=0.3 all KL = 0.987 +- 0.013 (in-sample avg dev_std = 0.040)
SUFF++ for r=0.3 all L1 = 0.956 +- 0.035 (in-sample avg dev_std = 0.040)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.547
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.54
SUFF++ for r=0.6 class 0.0 = 0.97 +- 0.009 (in-sample avg dev_std = 0.030)
SUFF++ for r=0.6 class 1.0 = 0.964 +- 0.009 (in-sample avg dev_std = 0.030)
SUFF++ for r=0.6 all KL = 0.992 +- 0.009 (in-sample avg dev_std = 0.030)
SUFF++ for r=0.6 all L1 = 0.967 +- 0.028 (in-sample avg dev_std = 0.030)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.648
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.577
SUFF++ for r=0.9 class 0.0 = 0.979 +- 0.022 (in-sample avg dev_std = 0.034)
SUFF++ for r=0.9 class 1.0 = 0.957 +- 0.022 (in-sample avg dev_std = 0.034)
SUFF++ for r=0.9 all KL = 0.993 +- 0.022 (in-sample avg dev_std = 0.034)
SUFF++ for r=0.9 all L1 = 0.968 +- 0.054 (in-sample avg dev_std = 0.034)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.576
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.544
NEC for r=0.3 class 0.0 = 0.046 +- 0.022 (in-sample avg dev_std = 0.037)
NEC for r=0.3 class 1.0 = 0.045 +- 0.022 (in-sample avg dev_std = 0.037)
NEC for r=0.3 all KL = 0.014 +- 0.022 (in-sample avg dev_std = 0.037)
NEC for r=0.3 all L1 = 0.045 +- 0.039 (in-sample avg dev_std = 0.037)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.675
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.669
NEC for r=0.6 class 0.0 = 0.033 +- 0.030 (in-sample avg dev_std = 0.051)
NEC for r=0.6 class 1.0 = 0.063 +- 0.030 (in-sample avg dev_std = 0.051)
NEC for r=0.6 all KL = 0.013 +- 0.030 (in-sample avg dev_std = 0.051)
NEC for r=0.6 all L1 = 0.048 +- 0.061 (in-sample avg dev_std = 0.051)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.752
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.727
NEC for r=0.9 class 0.0 = 0.027 +- 0.050 (in-sample avg dev_std = 0.083)
NEC for r=0.9 class 1.0 = 0.1 +- 0.050 (in-sample avg dev_std = 0.083)
NEC for r=0.9 all KL = 0.021 +- 0.050 (in-sample avg dev_std = 0.083)
NEC for r=0.9 all L1 = 0.064 +- 0.093 (in-sample avg dev_std = 0.083)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.77
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.734
NEC for r=1.0 class 0.0 = 0.028 +- 0.077 (in-sample avg dev_std = 0.097)
NEC for r=1.0 class 1.0 = 0.121 +- 0.077 (in-sample avg dev_std = 0.097)
NEC for r=1.0 all KL = 0.029 +- 0.077 (in-sample avg dev_std = 0.097)
NEC for r=1.0 all L1 = 0.074 +- 0.117 (in-sample avg dev_std = 0.097)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.654
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.569
NEC for r=0.3 class 0.0 = 0.053 +- 0.020 (in-sample avg dev_std = 0.040)
NEC for r=0.3 class 1.0 = 0.054 +- 0.020 (in-sample avg dev_std = 0.040)
NEC for r=0.3 all KL = 0.016 +- 0.020 (in-sample avg dev_std = 0.040)
NEC for r=0.3 all L1 = 0.053 +- 0.038 (in-sample avg dev_std = 0.040)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.677
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.647
NEC for r=0.6 class 0.0 = 0.037 +- 0.013 (in-sample avg dev_std = 0.036)
NEC for r=0.6 class 1.0 = 0.061 +- 0.013 (in-sample avg dev_std = 0.036)
NEC for r=0.6 all KL = 0.011 +- 0.013 (in-sample avg dev_std = 0.036)
NEC for r=0.6 all L1 = 0.049 +- 0.043 (in-sample avg dev_std = 0.036)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.734
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.695
NEC for r=0.9 class 0.0 = 0.039 +- 0.035 (in-sample avg dev_std = 0.072)
NEC for r=0.9 class 1.0 = 0.102 +- 0.035 (in-sample avg dev_std = 0.072)
NEC for r=0.9 all KL = 0.019 +- 0.035 (in-sample avg dev_std = 0.072)
NEC for r=0.9 all L1 = 0.071 +- 0.089 (in-sample avg dev_std = 0.072)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.733
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.707
NEC for r=1.0 class 0.0 = 0.042 +- 0.062 (in-sample avg dev_std = 0.091)
NEC for r=1.0 class 1.0 = 0.123 +- 0.062 (in-sample avg dev_std = 0.091)
NEC for r=1.0 all KL = 0.028 +- 0.062 (in-sample avg dev_std = 0.091)
NEC for r=1.0 all L1 = 0.082 +- 0.119 (in-sample avg dev_std = 0.091)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.645
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.578
NEC for r=0.3 class 0.0 = 0.05 +- 0.023 (in-sample avg dev_std = 0.045)
NEC for r=0.3 class 1.0 = 0.055 +- 0.023 (in-sample avg dev_std = 0.045)
NEC for r=0.3 all KL = 0.018 +- 0.023 (in-sample avg dev_std = 0.045)
NEC for r=0.3 all L1 = 0.052 +- 0.040 (in-sample avg dev_std = 0.045)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.553
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.559
NEC for r=0.6 class 0.0 = 0.03 +- 0.009 (in-sample avg dev_std = 0.029)
NEC for r=0.6 class 1.0 = 0.042 +- 0.009 (in-sample avg dev_std = 0.029)
NEC for r=0.6 all KL = 0.009 +- 0.009 (in-sample avg dev_std = 0.029)
NEC for r=0.6 all L1 = 0.036 +- 0.027 (in-sample avg dev_std = 0.029)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.65
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.605
NEC for r=0.9 class 0.0 = 0.024 +- 0.036 (in-sample avg dev_std = 0.039)
NEC for r=0.9 class 1.0 = 0.051 +- 0.036 (in-sample avg dev_std = 0.039)
NEC for r=0.9 all KL = 0.011 +- 0.036 (in-sample avg dev_std = 0.039)
NEC for r=0.9 all L1 = 0.038 +- 0.064 (in-sample avg dev_std = 0.039)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.661
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.597
NEC for r=1.0 class 0.0 = 0.025 +- 0.041 (in-sample avg dev_std = 0.054)
NEC for r=1.0 class 1.0 = 0.05 +- 0.041 (in-sample avg dev_std = 0.054)
NEC for r=1.0 all KL = 0.011 +- 0.041 (in-sample avg dev_std = 0.054)
NEC for r=1.0 all L1 = 0.037 +- 0.067 (in-sample avg dev_std = 0.054)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 12:53:39 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:39 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:43 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:47 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:51 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:53 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:53 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:53 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:53:53 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:53 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:53 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:53 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:53:53 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:53:53 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:53 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:53 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:53 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:53:53 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:53 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 62...
[0m[1;37mINFO[0m: [1mCheckpoint 62: 
-----------------------------------
Train ROC-AUC: 0.7811
Train Loss: 0.1351
ID Validation ROC-AUC: 0.7891
ID Validation Loss: 0.1440
ID Test ROC-AUC: 0.7577
ID Test Loss: 0.1311
OOD Validation ROC-AUC: 0.7371
OOD Validation Loss: 0.1253
OOD Test ROC-AUC: 0.6323
OOD Test Loss: 0.1028

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 54...
[0m[1;37mINFO[0m: [1mCheckpoint 54: 
-----------------------------------
Train ROC-AUC: 0.7742
Train Loss: 0.1327
ID Validation ROC-AUC: 0.7774
ID Validation Loss: 0.1435
ID Test ROC-AUC: 0.7765
ID Test Loss: 0.1226
OOD Validation ROC-AUC: 0.7567
OOD Validation Loss: 0.1183
OOD Test ROC-AUC: 0.6465
OOD Test Loss: 0.0974

[0m[1;37mINFO[0m: [1mChartInfo 0.7577 0.6323 0.7765 0.6465 0.7774 0.7567[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 04/22/2024 12:53:54 PM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 04/22/2024 12:53:56 PM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 04/22/2024 12:53:58 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.681
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.638
SUFF++ for r=0.3 class 0.0 = 0.964 +- 0.019 (in-sample avg dev_std = 0.043)
SUFF++ for r=0.3 class 1.0 = 0.939 +- 0.019 (in-sample avg dev_std = 0.043)
SUFF++ for r=0.3 all KL = 0.988 +- 0.019 (in-sample avg dev_std = 0.043)
SUFF++ for r=0.3 all L1 = 0.951 +- 0.048 (in-sample avg dev_std = 0.043)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.747
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.685
SUFF++ for r=0.6 class 0.0 = 0.968 +- 0.027 (in-sample avg dev_std = 0.058)
SUFF++ for r=0.6 class 1.0 = 0.923 +- 0.027 (in-sample avg dev_std = 0.058)
SUFF++ for r=0.6 all KL = 0.986 +- 0.027 (in-sample avg dev_std = 0.058)
SUFF++ for r=0.6 all L1 = 0.946 +- 0.064 (in-sample avg dev_std = 0.058)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.792
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.744
SUFF++ for r=0.9 class 0.0 = 0.975 +- 0.059 (in-sample avg dev_std = 0.103)
SUFF++ for r=0.9 class 1.0 = 0.903 +- 0.059 (in-sample avg dev_std = 0.103)
SUFF++ for r=0.9 all KL = 0.98 +- 0.059 (in-sample avg dev_std = 0.103)
SUFF++ for r=0.9 all L1 = 0.939 +- 0.093 (in-sample avg dev_std = 0.103)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.694
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.617
SUFF++ for r=0.3 class 0.0 = 0.956 +- 0.014 (in-sample avg dev_std = 0.042)
SUFF++ for r=0.3 class 1.0 = 0.937 +- 0.014 (in-sample avg dev_std = 0.042)
SUFF++ for r=0.3 all KL = 0.988 +- 0.014 (in-sample avg dev_std = 0.042)
SUFF++ for r=0.3 all L1 = 0.946 +- 0.043 (in-sample avg dev_std = 0.042)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.694
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.678
SUFF++ for r=0.6 class 0.0 = 0.964 +- 0.016 (in-sample avg dev_std = 0.051)
SUFF++ for r=0.6 class 1.0 = 0.934 +- 0.016 (in-sample avg dev_std = 0.051)
SUFF++ for r=0.6 all KL = 0.989 +- 0.016 (in-sample avg dev_std = 0.051)
SUFF++ for r=0.6 all L1 = 0.949 +- 0.044 (in-sample avg dev_std = 0.051)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.713
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.666
SUFF++ for r=0.9 class 0.0 = 0.967 +- 0.040 (in-sample avg dev_std = 0.081)
SUFF++ for r=0.9 class 1.0 = 0.901 +- 0.040 (in-sample avg dev_std = 0.081)
SUFF++ for r=0.9 all KL = 0.98 +- 0.040 (in-sample avg dev_std = 0.081)
SUFF++ for r=0.9 all L1 = 0.934 +- 0.086 (in-sample avg dev_std = 0.081)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.57
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.472
SUFF++ for r=0.3 class 0.0 = 0.956 +- 0.012 (in-sample avg dev_std = 0.039)
SUFF++ for r=0.3 class 1.0 = 0.953 +- 0.012 (in-sample avg dev_std = 0.039)
SUFF++ for r=0.3 all KL = 0.989 +- 0.012 (in-sample avg dev_std = 0.039)
SUFF++ for r=0.3 all L1 = 0.955 +- 0.037 (in-sample avg dev_std = 0.039)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.593
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.547
SUFF++ for r=0.6 class 0.0 = 0.966 +- 0.009 (in-sample avg dev_std = 0.033)
SUFF++ for r=0.6 class 1.0 = 0.956 +- 0.009 (in-sample avg dev_std = 0.033)
SUFF++ for r=0.6 all KL = 0.992 +- 0.009 (in-sample avg dev_std = 0.033)
SUFF++ for r=0.6 all L1 = 0.961 +- 0.029 (in-sample avg dev_std = 0.033)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.557
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.574
SUFF++ for r=0.9 class 0.0 = 0.973 +- 0.012 (in-sample avg dev_std = 0.036)
SUFF++ for r=0.9 class 1.0 = 0.963 +- 0.012 (in-sample avg dev_std = 0.036)
SUFF++ for r=0.9 all KL = 0.994 +- 0.012 (in-sample avg dev_std = 0.036)
SUFF++ for r=0.9 all L1 = 0.968 +- 0.037 (in-sample avg dev_std = 0.036)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.68
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.583
NEC for r=0.3 class 0.0 = 0.048 +- 0.027 (in-sample avg dev_std = 0.042)
NEC for r=0.3 class 1.0 = 0.071 +- 0.027 (in-sample avg dev_std = 0.042)
NEC for r=0.3 all KL = 0.018 +- 0.027 (in-sample avg dev_std = 0.042)
NEC for r=0.3 all L1 = 0.06 +- 0.056 (in-sample avg dev_std = 0.042)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.747
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.688
NEC for r=0.6 class 0.0 = 0.036 +- 0.020 (in-sample avg dev_std = 0.050)
NEC for r=0.6 class 1.0 = 0.077 +- 0.020 (in-sample avg dev_std = 0.050)
NEC for r=0.6 all KL = 0.014 +- 0.020 (in-sample avg dev_std = 0.050)
NEC for r=0.6 all L1 = 0.056 +- 0.056 (in-sample avg dev_std = 0.050)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.792
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.728
NEC for r=0.9 class 0.0 = 0.033 +- 0.041 (in-sample avg dev_std = 0.070)
NEC for r=0.9 class 1.0 = 0.095 +- 0.041 (in-sample avg dev_std = 0.070)
NEC for r=0.9 all KL = 0.018 +- 0.041 (in-sample avg dev_std = 0.070)
NEC for r=0.9 all L1 = 0.064 +- 0.082 (in-sample avg dev_std = 0.070)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.775
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.749
NEC for r=1.0 class 0.0 = 0.032 +- 0.062 (in-sample avg dev_std = 0.096)
NEC for r=1.0 class 1.0 = 0.112 +- 0.062 (in-sample avg dev_std = 0.096)
NEC for r=1.0 all KL = 0.024 +- 0.062 (in-sample avg dev_std = 0.096)
NEC for r=1.0 all L1 = 0.072 +- 0.101 (in-sample avg dev_std = 0.096)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.694
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.594
NEC for r=0.3 class 0.0 = 0.051 +- 0.016 (in-sample avg dev_std = 0.043)
NEC for r=0.3 class 1.0 = 0.078 +- 0.016 (in-sample avg dev_std = 0.043)
NEC for r=0.3 all KL = 0.016 +- 0.016 (in-sample avg dev_std = 0.043)
NEC for r=0.3 all L1 = 0.064 +- 0.047 (in-sample avg dev_std = 0.043)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.697
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.67
NEC for r=0.6 class 0.0 = 0.04 +- 0.017 (in-sample avg dev_std = 0.041)
NEC for r=0.6 class 1.0 = 0.069 +- 0.017 (in-sample avg dev_std = 0.041)
NEC for r=0.6 all KL = 0.012 +- 0.017 (in-sample avg dev_std = 0.041)
NEC for r=0.6 all L1 = 0.055 +- 0.048 (in-sample avg dev_std = 0.041)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.709
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.702
NEC for r=0.9 class 0.0 = 0.04 +- 0.024 (in-sample avg dev_std = 0.070)
NEC for r=0.9 class 1.0 = 0.09 +- 0.024 (in-sample avg dev_std = 0.070)
NEC for r=0.9 all KL = 0.016 +- 0.024 (in-sample avg dev_std = 0.070)
NEC for r=0.9 all L1 = 0.065 +- 0.069 (in-sample avg dev_std = 0.070)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.695
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.699
NEC for r=1.0 class 0.0 = 0.038 +- 0.033 (in-sample avg dev_std = 0.077)
NEC for r=1.0 class 1.0 = 0.1 +- 0.033 (in-sample avg dev_std = 0.077)
NEC for r=1.0 all KL = 0.018 +- 0.033 (in-sample avg dev_std = 0.077)
NEC for r=1.0 all L1 = 0.069 +- 0.082 (in-sample avg dev_std = 0.077)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.574
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.515
NEC for r=0.3 class 0.0 = 0.056 +- 0.026 (in-sample avg dev_std = 0.049)
NEC for r=0.3 class 1.0 = 0.065 +- 0.026 (in-sample avg dev_std = 0.049)
NEC for r=0.3 all KL = 0.02 +- 0.026 (in-sample avg dev_std = 0.049)
NEC for r=0.3 all L1 = 0.061 +- 0.045 (in-sample avg dev_std = 0.049)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.605
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.507
NEC for r=0.6 class 0.0 = 0.037 +- 0.008 (in-sample avg dev_std = 0.032)
NEC for r=0.6 class 1.0 = 0.044 +- 0.008 (in-sample avg dev_std = 0.032)
NEC for r=0.6 all KL = 0.008 +- 0.008 (in-sample avg dev_std = 0.032)
NEC for r=0.6 all L1 = 0.041 +- 0.026 (in-sample avg dev_std = 0.032)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.551
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.538
NEC for r=0.9 class 0.0 = 0.034 +- 0.012 (in-sample avg dev_std = 0.045)
NEC for r=0.9 class 1.0 = 0.046 +- 0.012 (in-sample avg dev_std = 0.045)
NEC for r=0.9 all KL = 0.009 +- 0.012 (in-sample avg dev_std = 0.045)
NEC for r=0.9 all L1 = 0.04 +- 0.037 (in-sample avg dev_std = 0.045)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.592
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.555
NEC for r=1.0 class 0.0 = 0.032 +- 0.018 (in-sample avg dev_std = 0.053)
NEC for r=1.0 class 1.0 = 0.054 +- 0.018 (in-sample avg dev_std = 0.053)
NEC for r=1.0 all KL = 0.01 +- 0.018 (in-sample avg dev_std = 0.053)
NEC for r=1.0 all L1 = 0.043 +- 0.045 (in-sample avg dev_std = 0.053)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.983, 0.982, 0.98, 1.0], 'all_L1': [0.947, 0.943, 0.939, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.981, 0.979, 0.971, 1.0], 'all_L1': [0.94, 0.934, 0.918, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.983, 0.977, 0.977, 1.0], 'all_L1': [0.94, 0.928, 0.93, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.989, 0.982, 0.975, 1.0], 'all_L1': [0.959, 0.946, 0.933, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.988, 0.986, 0.98, 1.0], 'all_L1': [0.951, 0.946, 0.939, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.015, 0.015, 0.019, 0.022], 'all_L1': [0.049, 0.051, 0.064, 0.07]}), defaultdict(<class 'list'>, {'all_KL': [0.019, 0.018, 0.027, 0.034], 'all_L1': [0.059, 0.06, 0.081, 0.092]}), defaultdict(<class 'list'>, {'all_KL': [0.012, 0.014, 0.019, 0.02], 'all_L1': [0.051, 0.058, 0.066, 0.068]}), defaultdict(<class 'list'>, {'all_KL': [0.014, 0.013, 0.021, 0.029], 'all_L1': [0.045, 0.048, 0.064, 0.074]}), defaultdict(<class 'list'>, {'all_KL': [0.018, 0.014, 0.018, 0.024], 'all_L1': [0.06, 0.056, 0.064, 0.072]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.985, 0.985, 0.985, 1.0], 'all_L1': [0.947, 0.941, 0.942, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.973, 0.982, 0.979, 1.0], 'all_L1': [0.918, 0.934, 0.934, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.984, 0.981, 0.965, 1.0], 'all_L1': [0.942, 0.939, 0.919, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.987, 0.987, 0.98, 1.0], 'all_L1': [0.951, 0.948, 0.931, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.988, 0.989, 0.98, 1.0], 'all_L1': [0.946, 0.949, 0.934, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.016, 0.011, 0.015, 0.016], 'all_L1': [0.051, 0.049, 0.06, 0.063]}), defaultdict(<class 'list'>, {'all_KL': [0.022, 0.016, 0.018, 0.026], 'all_L1': [0.072, 0.06, 0.067, 0.077]}), defaultdict(<class 'list'>, {'all_KL': [0.012, 0.017, 0.023, 0.025], 'all_L1': [0.051, 0.057, 0.068, 0.073]}), defaultdict(<class 'list'>, {'all_KL': [0.016, 0.011, 0.019, 0.028], 'all_L1': [0.053, 0.049, 0.071, 0.082]}), defaultdict(<class 'list'>, {'all_KL': [0.016, 0.012, 0.016, 0.018], 'all_L1': [0.064, 0.055, 0.065, 0.069]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.988, 0.989, 0.993, 1.0], 'all_L1': [0.957, 0.96, 0.969, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.982, 0.988, 0.991, 1.0], 'all_L1': [0.94, 0.955, 0.962, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.981, 0.987, 0.988, 1.0], 'all_L1': [0.936, 0.949, 0.958, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.987, 0.992, 0.993, 1.0], 'all_L1': [0.956, 0.967, 0.968, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.989, 0.992, 0.994, 1.0], 'all_L1': [0.955, 0.961, 0.968, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.014, 0.008, 0.008, 0.009], 'all_L1': [0.046, 0.036, 0.036, 0.036]}), defaultdict(<class 'list'>, {'all_KL': [0.018, 0.01, 0.011, 0.012], 'all_L1': [0.059, 0.041, 0.041, 0.042]}), defaultdict(<class 'list'>, {'all_KL': [0.016, 0.011, 0.013, 0.012], 'all_L1': [0.056, 0.049, 0.05, 0.049]}), defaultdict(<class 'list'>, {'all_KL': [0.018, 0.009, 0.011, 0.011], 'all_L1': [0.052, 0.036, 0.038, 0.037]}), defaultdict(<class 'list'>, {'all_KL': [0.02, 0.008, 0.009, 0.01], 'all_L1': [0.061, 0.041, 0.04, 0.043]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.947 +- 0.007, 0.939 +- 0.007, 0.932 +- 0.008, 1.000 +- 0.000
suff++ class all_KL  =  0.985 +- 0.003, 0.981 +- 0.003, 0.977 +- 0.003, 1.000 +- 0.000
suff++_acc_int  =  0.576 +- 0.047, 0.663 +- 0.033, 0.730 +- 0.030
nec class all_L1  =  0.053 +- 0.006, 0.055 +- 0.004, 0.068 +- 0.007, 0.075 +- 0.009
nec class all_KL  =  0.016 +- 0.003, 0.015 +- 0.002, 0.021 +- 0.003, 0.026 +- 0.005
nec_acc_int  =  0.563 +- 0.042, 0.677 +- 0.030, 0.738 +- 0.014, 0.748 +- 0.016

Eval split val
suff++ class all_L1  =  0.941 +- 0.012, 0.942 +- 0.006, 0.932 +- 0.007, 1.000 +- 0.000
suff++ class all_KL  =  0.983 +- 0.005, 0.985 +- 0.003, 0.978 +- 0.007, 1.000 +- 0.000
suff++_acc_int  =  0.571 +- 0.056, 0.626 +- 0.043, 0.664 +- 0.044
nec class all_L1  =  0.058 +- 0.008, 0.054 +- 0.004, 0.066 +- 0.004, 0.073 +- 0.007
nec class all_KL  =  0.016 +- 0.003, 0.013 +- 0.003, 0.018 +- 0.003, 0.023 +- 0.005
nec_acc_int  =  0.579 +- 0.033, 0.635 +- 0.042, 0.677 +- 0.028, 0.687 +- 0.022

Eval split test
suff++ class all_L1  =  0.949 +- 0.009, 0.958 +- 0.006, 0.965 +- 0.004, 1.000 +- 0.000
suff++ class all_KL  =  0.985 +- 0.003, 0.990 +- 0.002, 0.992 +- 0.002, 1.000 +- 0.000
suff++_acc_int  =  0.508 +- 0.022, 0.534 +- 0.018, 0.551 +- 0.035
nec class all_L1  =  0.055 +- 0.005, 0.041 +- 0.005, 0.041 +- 0.005, 0.041 +- 0.005
nec class all_KL  =  0.017 +- 0.002, 0.009 +- 0.001, 0.010 +- 0.002, 0.011 +- 0.001
nec_acc_int  =  0.524 +- 0.038, 0.533 +- 0.025, 0.566 +- 0.025, 0.569 +- 0.022


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.500 +- 0.003, 0.497 +- 0.003, 0.500 +- 0.001, 0.538 +- 0.004
Faith. Armon (L1)= 		  =  0.100 +- 0.010, 0.103 +- 0.008, 0.126 +- 0.011, 0.140 +- 0.015
Faith. GMean (L1)= 	  =  0.223 +- 0.012, 0.226 +- 0.009, 0.251 +- 0.011, 0.274 +- 0.015
Faith. Aritm (KL)= 		  =  0.500 +- 0.002, 0.498 +- 0.001, 0.499 +- 0.001, 0.513 +- 0.003
Faith. Armon (KL)= 		  =  0.031 +- 0.005, 0.029 +- 0.003, 0.041 +- 0.006, 0.050 +- 0.010
Faith. GMean (KL)= 	  =  0.124 +- 0.010, 0.120 +- 0.007, 0.142 +- 0.010, 0.160 +- 0.016

Eval split val
Faith. Aritm (L1)= 		  =  0.499 +- 0.004, 0.498 +- 0.002, 0.499 +- 0.003, 0.536 +- 0.003
Faith. Armon (L1)= 		  =  0.109 +- 0.015, 0.102 +- 0.008, 0.124 +- 0.006, 0.136 +- 0.011
Faith. GMean (L1)= 	  =  0.233 +- 0.015, 0.225 +- 0.009, 0.248 +- 0.006, 0.270 +- 0.012
Faith. Aritm (KL)= 		  =  0.500 +- 0.002, 0.499 +- 0.001, 0.498 +- 0.002, 0.511 +- 0.002
Faith. Armon (KL)= 		  =  0.032 +- 0.006, 0.026 +- 0.005, 0.036 +- 0.005, 0.044 +- 0.009
Faith. GMean (KL)= 	  =  0.126 +- 0.012, 0.114 +- 0.011, 0.133 +- 0.010, 0.149 +- 0.016

Eval split test
Faith. Aritm (L1)= 		  =  0.502 +- 0.004, 0.499 +- 0.001, 0.503 +- 0.001, 0.521 +- 0.002
Faith. Armon (L1)= 		  =  0.104 +- 0.010, 0.078 +- 0.009, 0.079 +- 0.009, 0.079 +- 0.009
Faith. GMean (L1)= 	  =  0.228 +- 0.011, 0.197 +- 0.011, 0.199 +- 0.011, 0.203 +- 0.011
Faith. Aritm (KL)= 		  =  0.501 +- 0.002, 0.499 +- 0.001, 0.501 +- 0.001, 0.505 +- 0.001
Faith. Armon (KL)= 		  =  0.034 +- 0.004, 0.018 +- 0.002, 0.021 +- 0.003, 0.021 +- 0.002
Faith. GMean (KL)= 	  =  0.130 +- 0.008, 0.095 +- 0.006, 0.101 +- 0.008, 0.104 +- 0.006
Computed for split load_split = id



Completed in  0:08:01.802339  for LECIvGIN GOODHIV/scaffold



DONE LECI GOODHIV/scaffold

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 12:55:47 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:48 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:48 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:48 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:48 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 12:55:49 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 194...
[0m[1;37mINFO[0m: [1mCheckpoint 194: 
-----------------------------------
Train ACCURACY: 0.4007
Train Loss: 1.6767
ID Validation ACCURACY: 0.3850
ID Validation Loss: 1.7263
ID Test ACCURACY: 0.3906
ID Test Loss: 1.7136
OOD Validation ACCURACY: 0.1660
OOD Validation Loss: 3.7653
OOD Test ACCURACY: 0.1411
OOD Test Loss: 4.2478

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 109...
[0m[1;37mINFO[0m: [1mCheckpoint 109: 
-----------------------------------
Train ACCURACY: 0.3419
Train Loss: 1.8242
ID Validation ACCURACY: 0.3471
ID Validation Loss: 1.8284
ID Test ACCURACY: 0.3459
ID Test Loss: 1.8206
OOD Validation ACCURACY: 0.2681
OOD Validation Loss: 2.0776
OOD Test ACCURACY: 0.1649
OOD Test Loss: 2.5724

[0m[1;37mINFO[0m: [1mChartInfo 0.3906 0.1411 0.3459 0.1649 0.3471 0.2681[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.126
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.13
SUFF++ for r=0.3 class 0 = 0.559 +- 0.134 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.3 class 1 = 0.639 +- 0.134 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.3 class 2 = 0.594 +- 0.134 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.3 class 3 = 0.612 +- 0.134 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.3 class 4 = 0.626 +- 0.134 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.3 class 5 = 0.629 +- 0.134 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.3 class 6 = 0.597 +- 0.134 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.3 class 7 = 0.629 +- 0.134 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.3 class 8 = 0.593 +- 0.134 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.3 class 9 = 0.62 +- 0.134 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.3 all KL = 0.727 +- 0.134 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.3 all L1 = 0.61 +- 0.098 (in-sample avg dev_std = 0.490)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.155
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.141
SUFF++ for r=0.6 class 0 = 0.823 +- 0.063 (in-sample avg dev_std = 0.094)
SUFF++ for r=0.6 class 1 = 0.739 +- 0.063 (in-sample avg dev_std = 0.094)
SUFF++ for r=0.6 class 2 = 0.793 +- 0.063 (in-sample avg dev_std = 0.094)
SUFF++ for r=0.6 class 3 = 0.8 +- 0.063 (in-sample avg dev_std = 0.094)
SUFF++ for r=0.6 class 4 = 0.793 +- 0.063 (in-sample avg dev_std = 0.094)
SUFF++ for r=0.6 class 5 = 0.814 +- 0.063 (in-sample avg dev_std = 0.094)
SUFF++ for r=0.6 class 6 = 0.778 +- 0.063 (in-sample avg dev_std = 0.094)
SUFF++ for r=0.6 class 7 = 0.789 +- 0.063 (in-sample avg dev_std = 0.094)
SUFF++ for r=0.6 class 8 = 0.786 +- 0.063 (in-sample avg dev_std = 0.094)
SUFF++ for r=0.6 class 9 = 0.773 +- 0.063 (in-sample avg dev_std = 0.094)
SUFF++ for r=0.6 all KL = 0.941 +- 0.063 (in-sample avg dev_std = 0.094)
SUFF++ for r=0.6 all L1 = 0.788 +- 0.093 (in-sample avg dev_std = 0.094)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.329
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.303
SUFF++ for r=0.9 class 0 = 0.908 +- 0.045 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.9 class 1 = 0.842 +- 0.045 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.9 class 2 = 0.897 +- 0.045 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.9 class 3 = 0.89 +- 0.045 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.9 class 4 = 0.871 +- 0.045 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.9 class 5 = 0.891 +- 0.045 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.9 class 6 = 0.871 +- 0.045 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.9 class 7 = 0.868 +- 0.045 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.9 class 8 = 0.882 +- 0.045 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.9 class 9 = 0.866 +- 0.045 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.9 all KL = 0.971 +- 0.045 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.9 all L1 = 0.878 +- 0.082 (in-sample avg dev_std = 0.111)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.105
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.121
SUFF++ for r=0.3 class 0 = 0.632 +- 0.097 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.3 class 1 = 0.625 +- 0.097 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.3 class 2 = 0.633 +- 0.097 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.3 class 3 = 0.649 +- 0.097 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.3 class 4 = 0.642 +- 0.097 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.3 class 5 = 0.642 +- 0.097 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.3 class 6 = 0.638 +- 0.097 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.3 class 7 = 0.632 +- 0.097 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.3 class 8 = 0.628 +- 0.097 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.3 class 9 = 0.644 +- 0.097 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.3 all KL = 0.771 +- 0.097 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.3 all L1 = 0.636 +- 0.071 (in-sample avg dev_std = 0.421)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.156
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.144
SUFF++ for r=0.6 class 0 = 0.824 +- 0.051 (in-sample avg dev_std = 0.071)
SUFF++ for r=0.6 class 1 = 0.776 +- 0.051 (in-sample avg dev_std = 0.071)
SUFF++ for r=0.6 class 2 = 0.811 +- 0.051 (in-sample avg dev_std = 0.071)
SUFF++ for r=0.6 class 3 = 0.797 +- 0.051 (in-sample avg dev_std = 0.071)
SUFF++ for r=0.6 class 4 = 0.796 +- 0.051 (in-sample avg dev_std = 0.071)
SUFF++ for r=0.6 class 5 = 0.8 +- 0.051 (in-sample avg dev_std = 0.071)
SUFF++ for r=0.6 class 6 = 0.801 +- 0.051 (in-sample avg dev_std = 0.071)
SUFF++ for r=0.6 class 7 = 0.795 +- 0.051 (in-sample avg dev_std = 0.071)
SUFF++ for r=0.6 class 8 = 0.802 +- 0.051 (in-sample avg dev_std = 0.071)
SUFF++ for r=0.6 class 9 = 0.786 +- 0.051 (in-sample avg dev_std = 0.071)
SUFF++ for r=0.6 all KL = 0.95 +- 0.051 (in-sample avg dev_std = 0.071)
SUFF++ for r=0.6 all L1 = 0.798 +- 0.082 (in-sample avg dev_std = 0.071)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.189
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.198
SUFF++ for r=0.9 class 0 = 0.878 +- 0.062 (in-sample avg dev_std = 0.130)
SUFF++ for r=0.9 class 1 = 0.923 +- 0.062 (in-sample avg dev_std = 0.130)
SUFF++ for r=0.9 class 2 = 0.881 +- 0.062 (in-sample avg dev_std = 0.130)
SUFF++ for r=0.9 class 3 = 0.871 +- 0.062 (in-sample avg dev_std = 0.130)
SUFF++ for r=0.9 class 4 = 0.869 +- 0.062 (in-sample avg dev_std = 0.130)
SUFF++ for r=0.9 class 5 = 0.873 +- 0.062 (in-sample avg dev_std = 0.130)
SUFF++ for r=0.9 class 6 = 0.856 +- 0.062 (in-sample avg dev_std = 0.130)
SUFF++ for r=0.9 class 7 = 0.859 +- 0.062 (in-sample avg dev_std = 0.130)
SUFF++ for r=0.9 class 8 = 0.87 +- 0.062 (in-sample avg dev_std = 0.130)
SUFF++ for r=0.9 class 9 = 0.834 +- 0.062 (in-sample avg dev_std = 0.130)
SUFF++ for r=0.9 all KL = 0.962 +- 0.062 (in-sample avg dev_std = 0.130)
SUFF++ for r=0.9 all L1 = 0.872 +- 0.097 (in-sample avg dev_std = 0.130)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.125
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.119
SUFF++ for r=0.3 class 0 = 0.613 +- 0.099 (in-sample avg dev_std = 0.440)
SUFF++ for r=0.3 class 1 = 0.658 +- 0.099 (in-sample avg dev_std = 0.440)
SUFF++ for r=0.3 class 2 = 0.619 +- 0.099 (in-sample avg dev_std = 0.440)
SUFF++ for r=0.3 class 3 = 0.614 +- 0.099 (in-sample avg dev_std = 0.440)
SUFF++ for r=0.3 class 4 = 0.63 +- 0.099 (in-sample avg dev_std = 0.440)
SUFF++ for r=0.3 class 5 = 0.608 +- 0.099 (in-sample avg dev_std = 0.440)
SUFF++ for r=0.3 class 6 = 0.631 +- 0.099 (in-sample avg dev_std = 0.440)
SUFF++ for r=0.3 class 7 = 0.644 +- 0.099 (in-sample avg dev_std = 0.440)
SUFF++ for r=0.3 class 8 = 0.627 +- 0.099 (in-sample avg dev_std = 0.440)
SUFF++ for r=0.3 class 9 = 0.641 +- 0.099 (in-sample avg dev_std = 0.440)
SUFF++ for r=0.3 all KL = 0.767 +- 0.099 (in-sample avg dev_std = 0.440)
SUFF++ for r=0.3 all L1 = 0.629 +- 0.072 (in-sample avg dev_std = 0.440)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.147
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.12
SUFF++ for r=0.6 class 0 = 0.836 +- 0.045 (in-sample avg dev_std = 0.068)
SUFF++ for r=0.6 class 1 = 0.799 +- 0.045 (in-sample avg dev_std = 0.068)
SUFF++ for r=0.6 class 2 = 0.816 +- 0.045 (in-sample avg dev_std = 0.068)
SUFF++ for r=0.6 class 3 = 0.825 +- 0.045 (in-sample avg dev_std = 0.068)
SUFF++ for r=0.6 class 4 = 0.826 +- 0.045 (in-sample avg dev_std = 0.068)
SUFF++ for r=0.6 class 5 = 0.805 +- 0.045 (in-sample avg dev_std = 0.068)
SUFF++ for r=0.6 class 6 = 0.822 +- 0.045 (in-sample avg dev_std = 0.068)
SUFF++ for r=0.6 class 7 = 0.801 +- 0.045 (in-sample avg dev_std = 0.068)
SUFF++ for r=0.6 class 8 = 0.805 +- 0.045 (in-sample avg dev_std = 0.068)
SUFF++ for r=0.6 class 9 = 0.808 +- 0.045 (in-sample avg dev_std = 0.068)
SUFF++ for r=0.6 all KL = 0.959 +- 0.045 (in-sample avg dev_std = 0.068)
SUFF++ for r=0.6 all L1 = 0.814 +- 0.077 (in-sample avg dev_std = 0.068)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.171
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.179
SUFF++ for r=0.9 class 0 = 0.881 +- 0.049 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.9 class 1 = 0.903 +- 0.049 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.9 class 2 = 0.881 +- 0.049 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.9 class 3 = 0.883 +- 0.049 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.9 class 4 = 0.847 +- 0.049 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.9 class 5 = 0.857 +- 0.049 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.9 class 6 = 0.85 +- 0.049 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.9 class 7 = 0.862 +- 0.049 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.9 class 8 = 0.859 +- 0.049 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.9 class 9 = 0.857 +- 0.049 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.9 all KL = 0.963 +- 0.049 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.9 all L1 = 0.869 +- 0.090 (in-sample avg dev_std = 0.128)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.126
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.119
NEC for r=0.3 class 0 = 0.113 +- 0.017 (in-sample avg dev_std = 0.060)
NEC for r=0.3 class 1 = 0.129 +- 0.017 (in-sample avg dev_std = 0.060)
NEC for r=0.3 class 2 = 0.122 +- 0.017 (in-sample avg dev_std = 0.060)
NEC for r=0.3 class 3 = 0.116 +- 0.017 (in-sample avg dev_std = 0.060)
NEC for r=0.3 class 4 = 0.114 +- 0.017 (in-sample avg dev_std = 0.060)
NEC for r=0.3 class 5 = 0.123 +- 0.017 (in-sample avg dev_std = 0.060)
NEC for r=0.3 class 6 = 0.118 +- 0.017 (in-sample avg dev_std = 0.060)
NEC for r=0.3 class 7 = 0.118 +- 0.017 (in-sample avg dev_std = 0.060)
NEC for r=0.3 class 8 = 0.11 +- 0.017 (in-sample avg dev_std = 0.060)
NEC for r=0.3 class 9 = 0.121 +- 0.017 (in-sample avg dev_std = 0.060)
NEC for r=0.3 all KL = 0.017 +- 0.017 (in-sample avg dev_std = 0.060)
NEC for r=0.3 all L1 = 0.118 +- 0.049 (in-sample avg dev_std = 0.060)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.155
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.135
NEC for r=0.6 class 0 = 0.142 +- 0.040 (in-sample avg dev_std = 0.110)
NEC for r=0.6 class 1 = 0.2 +- 0.040 (in-sample avg dev_std = 0.110)
NEC for r=0.6 class 2 = 0.166 +- 0.040 (in-sample avg dev_std = 0.110)
NEC for r=0.6 class 3 = 0.184 +- 0.040 (in-sample avg dev_std = 0.110)
NEC for r=0.6 class 4 = 0.175 +- 0.040 (in-sample avg dev_std = 0.110)
NEC for r=0.6 class 5 = 0.15 +- 0.040 (in-sample avg dev_std = 0.110)
NEC for r=0.6 class 6 = 0.174 +- 0.040 (in-sample avg dev_std = 0.110)
NEC for r=0.6 class 7 = 0.172 +- 0.040 (in-sample avg dev_std = 0.110)
NEC for r=0.6 class 8 = 0.172 +- 0.040 (in-sample avg dev_std = 0.110)
NEC for r=0.6 class 9 = 0.189 +- 0.040 (in-sample avg dev_std = 0.110)
NEC for r=0.6 all KL = 0.041 +- 0.040 (in-sample avg dev_std = 0.110)
NEC for r=0.6 all L1 = 0.173 +- 0.072 (in-sample avg dev_std = 0.110)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.329
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.269
NEC for r=0.9 class 0 = 0.21 +- 0.071 (in-sample avg dev_std = 0.143)
NEC for r=0.9 class 1 = 0.358 +- 0.071 (in-sample avg dev_std = 0.143)
NEC for r=0.9 class 2 = 0.244 +- 0.071 (in-sample avg dev_std = 0.143)
NEC for r=0.9 class 3 = 0.239 +- 0.071 (in-sample avg dev_std = 0.143)
NEC for r=0.9 class 4 = 0.268 +- 0.071 (in-sample avg dev_std = 0.143)
NEC for r=0.9 class 5 = 0.238 +- 0.071 (in-sample avg dev_std = 0.143)
NEC for r=0.9 class 6 = 0.272 +- 0.071 (in-sample avg dev_std = 0.143)
NEC for r=0.9 class 7 = 0.271 +- 0.071 (in-sample avg dev_std = 0.143)
NEC for r=0.9 class 8 = 0.235 +- 0.071 (in-sample avg dev_std = 0.143)
NEC for r=0.9 class 9 = 0.278 +- 0.071 (in-sample avg dev_std = 0.143)
NEC for r=0.9 all KL = 0.094 +- 0.071 (in-sample avg dev_std = 0.143)
NEC for r=0.9 all L1 = 0.263 +- 0.090 (in-sample avg dev_std = 0.143)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.382
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.338
NEC for r=1.0 class 0 = 0.227 +- 0.099 (in-sample avg dev_std = 0.155)
NEC for r=1.0 class 1 = 0.31 +- 0.099 (in-sample avg dev_std = 0.155)
NEC for r=1.0 class 2 = 0.269 +- 0.099 (in-sample avg dev_std = 0.155)
NEC for r=1.0 class 3 = 0.277 +- 0.099 (in-sample avg dev_std = 0.155)
NEC for r=1.0 class 4 = 0.311 +- 0.099 (in-sample avg dev_std = 0.155)
NEC for r=1.0 class 5 = 0.276 +- 0.099 (in-sample avg dev_std = 0.155)
NEC for r=1.0 class 6 = 0.299 +- 0.099 (in-sample avg dev_std = 0.155)
NEC for r=1.0 class 7 = 0.304 +- 0.099 (in-sample avg dev_std = 0.155)
NEC for r=1.0 class 8 = 0.284 +- 0.099 (in-sample avg dev_std = 0.155)
NEC for r=1.0 class 9 = 0.303 +- 0.099 (in-sample avg dev_std = 0.155)
NEC for r=1.0 all KL = 0.118 +- 0.099 (in-sample avg dev_std = 0.155)
NEC for r=1.0 all L1 = 0.286 +- 0.106 (in-sample avg dev_std = 0.155)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.105
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.106
NEC for r=0.3 class 0 = 0.121 +- 0.016 (in-sample avg dev_std = 0.058)
NEC for r=0.3 class 1 = 0.123 +- 0.016 (in-sample avg dev_std = 0.058)
NEC for r=0.3 class 2 = 0.118 +- 0.016 (in-sample avg dev_std = 0.058)
NEC for r=0.3 class 3 = 0.118 +- 0.016 (in-sample avg dev_std = 0.058)
NEC for r=0.3 class 4 = 0.118 +- 0.016 (in-sample avg dev_std = 0.058)
NEC for r=0.3 class 5 = 0.118 +- 0.016 (in-sample avg dev_std = 0.058)
NEC for r=0.3 class 6 = 0.121 +- 0.016 (in-sample avg dev_std = 0.058)
NEC for r=0.3 class 7 = 0.12 +- 0.016 (in-sample avg dev_std = 0.058)
NEC for r=0.3 class 8 = 0.116 +- 0.016 (in-sample avg dev_std = 0.058)
NEC for r=0.3 class 9 = 0.121 +- 0.016 (in-sample avg dev_std = 0.058)
NEC for r=0.3 all KL = 0.016 +- 0.016 (in-sample avg dev_std = 0.058)
NEC for r=0.3 all L1 = 0.119 +- 0.045 (in-sample avg dev_std = 0.058)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.156
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.137
NEC for r=0.6 class 0 = 0.151 +- 0.029 (in-sample avg dev_std = 0.090)
NEC for r=0.6 class 1 = 0.186 +- 0.029 (in-sample avg dev_std = 0.090)
NEC for r=0.6 class 2 = 0.159 +- 0.029 (in-sample avg dev_std = 0.090)
NEC for r=0.6 class 3 = 0.167 +- 0.029 (in-sample avg dev_std = 0.090)
NEC for r=0.6 class 4 = 0.169 +- 0.029 (in-sample avg dev_std = 0.090)
NEC for r=0.6 class 5 = 0.152 +- 0.029 (in-sample avg dev_std = 0.090)
NEC for r=0.6 class 6 = 0.172 +- 0.029 (in-sample avg dev_std = 0.090)
NEC for r=0.6 class 7 = 0.167 +- 0.029 (in-sample avg dev_std = 0.090)
NEC for r=0.6 class 8 = 0.162 +- 0.029 (in-sample avg dev_std = 0.090)
NEC for r=0.6 class 9 = 0.172 +- 0.029 (in-sample avg dev_std = 0.090)
NEC for r=0.6 all KL = 0.034 +- 0.029 (in-sample avg dev_std = 0.090)
NEC for r=0.6 all L1 = 0.166 +- 0.055 (in-sample avg dev_std = 0.090)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.189
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.207
NEC for r=0.9 class 0 = 0.232 +- 0.125 (in-sample avg dev_std = 0.158)
NEC for r=0.9 class 1 = 0.198 +- 0.125 (in-sample avg dev_std = 0.158)
NEC for r=0.9 class 2 = 0.251 +- 0.125 (in-sample avg dev_std = 0.158)
NEC for r=0.9 class 3 = 0.253 +- 0.125 (in-sample avg dev_std = 0.158)
NEC for r=0.9 class 4 = 0.309 +- 0.125 (in-sample avg dev_std = 0.158)
NEC for r=0.9 class 5 = 0.284 +- 0.125 (in-sample avg dev_std = 0.158)
NEC for r=0.9 class 6 = 0.295 +- 0.125 (in-sample avg dev_std = 0.158)
NEC for r=0.9 class 7 = 0.328 +- 0.125 (in-sample avg dev_std = 0.158)
NEC for r=0.9 class 8 = 0.286 +- 0.125 (in-sample avg dev_std = 0.158)
NEC for r=0.9 class 9 = 0.318 +- 0.125 (in-sample avg dev_std = 0.158)
NEC for r=0.9 all KL = 0.124 +- 0.125 (in-sample avg dev_std = 0.158)
NEC for r=0.9 all L1 = 0.275 +- 0.133 (in-sample avg dev_std = 0.158)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.162
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.189
NEC for r=1.0 class 0 = 0.332 +- 0.197 (in-sample avg dev_std = 0.208)
NEC for r=1.0 class 1 = 0.069 +- 0.197 (in-sample avg dev_std = 0.208)
NEC for r=1.0 class 2 = 0.358 +- 0.197 (in-sample avg dev_std = 0.208)
NEC for r=1.0 class 3 = 0.337 +- 0.197 (in-sample avg dev_std = 0.208)
NEC for r=1.0 class 4 = 0.343 +- 0.197 (in-sample avg dev_std = 0.208)
NEC for r=1.0 class 5 = 0.36 +- 0.197 (in-sample avg dev_std = 0.208)
NEC for r=1.0 class 6 = 0.318 +- 0.197 (in-sample avg dev_std = 0.208)
NEC for r=1.0 class 7 = 0.368 +- 0.197 (in-sample avg dev_std = 0.208)
NEC for r=1.0 class 8 = 0.34 +- 0.197 (in-sample avg dev_std = 0.208)
NEC for r=1.0 class 9 = 0.335 +- 0.197 (in-sample avg dev_std = 0.208)
NEC for r=1.0 all KL = 0.204 +- 0.197 (in-sample avg dev_std = 0.208)
NEC for r=1.0 all L1 = 0.312 +- 0.189 (in-sample avg dev_std = 0.208)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.125
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.12
NEC for r=0.3 class 0 = 0.106 +- 0.013 (in-sample avg dev_std = 0.055)
NEC for r=0.3 class 1 = 0.107 +- 0.013 (in-sample avg dev_std = 0.055)
NEC for r=0.3 class 2 = 0.109 +- 0.013 (in-sample avg dev_std = 0.055)
NEC for r=0.3 class 3 = 0.107 +- 0.013 (in-sample avg dev_std = 0.055)
NEC for r=0.3 class 4 = 0.109 +- 0.013 (in-sample avg dev_std = 0.055)
NEC for r=0.3 class 5 = 0.107 +- 0.013 (in-sample avg dev_std = 0.055)
NEC for r=0.3 class 6 = 0.114 +- 0.013 (in-sample avg dev_std = 0.055)
NEC for r=0.3 class 7 = 0.106 +- 0.013 (in-sample avg dev_std = 0.055)
NEC for r=0.3 class 8 = 0.11 +- 0.013 (in-sample avg dev_std = 0.055)
NEC for r=0.3 class 9 = 0.105 +- 0.013 (in-sample avg dev_std = 0.055)
NEC for r=0.3 all KL = 0.014 +- 0.013 (in-sample avg dev_std = 0.055)
NEC for r=0.3 all L1 = 0.108 +- 0.043 (in-sample avg dev_std = 0.055)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.147
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.132
NEC for r=0.6 class 0 = 0.128 +- 0.017 (in-sample avg dev_std = 0.074)
NEC for r=0.6 class 1 = 0.163 +- 0.017 (in-sample avg dev_std = 0.074)
NEC for r=0.6 class 2 = 0.132 +- 0.017 (in-sample avg dev_std = 0.074)
NEC for r=0.6 class 3 = 0.135 +- 0.017 (in-sample avg dev_std = 0.074)
NEC for r=0.6 class 4 = 0.139 +- 0.017 (in-sample avg dev_std = 0.074)
NEC for r=0.6 class 5 = 0.139 +- 0.017 (in-sample avg dev_std = 0.074)
NEC for r=0.6 class 6 = 0.145 +- 0.017 (in-sample avg dev_std = 0.074)
NEC for r=0.6 class 7 = 0.139 +- 0.017 (in-sample avg dev_std = 0.074)
NEC for r=0.6 class 8 = 0.14 +- 0.017 (in-sample avg dev_std = 0.074)
NEC for r=0.6 class 9 = 0.147 +- 0.017 (in-sample avg dev_std = 0.074)
NEC for r=0.6 all KL = 0.023 +- 0.017 (in-sample avg dev_std = 0.074)
NEC for r=0.6 all L1 = 0.141 +- 0.046 (in-sample avg dev_std = 0.074)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.171
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.192
NEC for r=0.9 class 0 = 0.249 +- 0.102 (in-sample avg dev_std = 0.151)
NEC for r=0.9 class 1 = 0.209 +- 0.102 (in-sample avg dev_std = 0.151)
NEC for r=0.9 class 2 = 0.266 +- 0.102 (in-sample avg dev_std = 0.151)
NEC for r=0.9 class 3 = 0.276 +- 0.102 (in-sample avg dev_std = 0.151)
NEC for r=0.9 class 4 = 0.31 +- 0.102 (in-sample avg dev_std = 0.151)
NEC for r=0.9 class 5 = 0.272 +- 0.102 (in-sample avg dev_std = 0.151)
NEC for r=0.9 class 6 = 0.303 +- 0.102 (in-sample avg dev_std = 0.151)
NEC for r=0.9 class 7 = 0.321 +- 0.102 (in-sample avg dev_std = 0.151)
NEC for r=0.9 class 8 = 0.303 +- 0.102 (in-sample avg dev_std = 0.151)
NEC for r=0.9 class 9 = 0.301 +- 0.102 (in-sample avg dev_std = 0.151)
NEC for r=0.9 all KL = 0.121 +- 0.102 (in-sample avg dev_std = 0.151)
NEC for r=0.9 all L1 = 0.28 +- 0.121 (in-sample avg dev_std = 0.151)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.142
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.162
NEC for r=1.0 class 0 = 0.36 +- 0.163 (in-sample avg dev_std = 0.188)
NEC for r=1.0 class 1 = 0.082 +- 0.163 (in-sample avg dev_std = 0.188)
NEC for r=1.0 class 2 = 0.343 +- 0.163 (in-sample avg dev_std = 0.188)
NEC for r=1.0 class 3 = 0.297 +- 0.163 (in-sample avg dev_std = 0.188)
NEC for r=1.0 class 4 = 0.312 +- 0.163 (in-sample avg dev_std = 0.188)
NEC for r=1.0 class 5 = 0.379 +- 0.163 (in-sample avg dev_std = 0.188)
NEC for r=1.0 class 6 = 0.341 +- 0.163 (in-sample avg dev_std = 0.188)
NEC for r=1.0 class 7 = 0.327 +- 0.163 (in-sample avg dev_std = 0.188)
NEC for r=1.0 class 8 = 0.352 +- 0.163 (in-sample avg dev_std = 0.188)
NEC for r=1.0 class 9 = 0.291 +- 0.163 (in-sample avg dev_std = 0.188)
NEC for r=1.0 all KL = 0.195 +- 0.163 (in-sample avg dev_std = 0.188)
NEC for r=1.0 all L1 = 0.305 +- 0.184 (in-sample avg dev_std = 0.188)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 13:14:44 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:14:45 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:14:46 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 193...
[0m[1;37mINFO[0m: [1mCheckpoint 193: 
-----------------------------------
Train ACCURACY: 0.3543
Train Loss: 1.8155
ID Validation ACCURACY: 0.3413
ID Validation Loss: 1.8408
ID Test ACCURACY: 0.3547
ID Test Loss: 1.8241
OOD Validation ACCURACY: 0.2271
OOD Validation Loss: 2.3057
OOD Test ACCURACY: 0.1493
OOD Test Loss: 2.5727

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 132...
[0m[1;37mINFO[0m: [1mCheckpoint 132: 
-----------------------------------
Train ACCURACY: 0.2912
Train Loss: 2.1421
ID Validation ACCURACY: 0.2874
ID Validation Loss: 2.1647
ID Test ACCURACY: 0.2943
ID Test Loss: 2.1323
OOD Validation ACCURACY: 0.2813
OOD Validation Loss: 2.0457
OOD Test ACCURACY: 0.1970
OOD Test Loss: 2.3276

[0m[1;37mINFO[0m: [1mChartInfo 0.3547 0.1493 0.2943 0.1970 0.2874 0.2813[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.115
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.12
SUFF++ for r=0.3 class 0 = 0.583 +- 0.130 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 class 1 = 0.646 +- 0.130 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 class 2 = 0.622 +- 0.130 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 class 3 = 0.62 +- 0.130 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 class 4 = 0.633 +- 0.130 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 class 5 = 0.642 +- 0.130 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 class 6 = 0.621 +- 0.130 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 class 7 = 0.635 +- 0.130 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 class 8 = 0.601 +- 0.130 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 class 9 = 0.617 +- 0.130 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 all KL = 0.74 +- 0.130 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 all L1 = 0.622 +- 0.094 (in-sample avg dev_std = 0.470)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.134
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.133
SUFF++ for r=0.6 class 0 = 0.817 +- 0.051 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.6 class 1 = 0.786 +- 0.051 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.6 class 2 = 0.817 +- 0.051 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.6 class 3 = 0.815 +- 0.051 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.6 class 4 = 0.804 +- 0.051 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.6 class 5 = 0.806 +- 0.051 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.6 class 6 = 0.817 +- 0.051 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.6 class 7 = 0.815 +- 0.051 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.6 class 8 = 0.812 +- 0.051 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.6 class 9 = 0.789 +- 0.051 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.6 all KL = 0.953 +- 0.051 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.6 all L1 = 0.808 +- 0.081 (in-sample avg dev_std = 0.089)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.281
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.257
SUFF++ for r=0.9 class 0 = 0.859 +- 0.057 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 class 1 = 0.83 +- 0.057 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 class 2 = 0.864 +- 0.057 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 class 3 = 0.878 +- 0.057 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 class 4 = 0.876 +- 0.057 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 class 5 = 0.852 +- 0.057 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 class 6 = 0.879 +- 0.057 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 class 7 = 0.851 +- 0.057 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 class 8 = 0.884 +- 0.057 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 class 9 = 0.872 +- 0.057 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 all KL = 0.965 +- 0.057 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 all L1 = 0.864 +- 0.095 (in-sample avg dev_std = 0.113)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.106
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.118
SUFF++ for r=0.3 class 0 = 0.597 +- 0.109 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 class 1 = 0.637 +- 0.109 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 class 2 = 0.618 +- 0.109 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 class 3 = 0.615 +- 0.109 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 class 4 = 0.616 +- 0.109 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 class 5 = 0.631 +- 0.109 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 class 6 = 0.615 +- 0.109 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 class 7 = 0.621 +- 0.109 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 class 8 = 0.608 +- 0.109 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 class 9 = 0.637 +- 0.109 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 all KL = 0.746 +- 0.109 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 all L1 = 0.62 +- 0.079 (in-sample avg dev_std = 0.462)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.151
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.134
SUFF++ for r=0.6 class 0 = 0.829 +- 0.048 (in-sample avg dev_std = 0.080)
SUFF++ for r=0.6 class 1 = 0.792 +- 0.048 (in-sample avg dev_std = 0.080)
SUFF++ for r=0.6 class 2 = 0.818 +- 0.048 (in-sample avg dev_std = 0.080)
SUFF++ for r=0.6 class 3 = 0.815 +- 0.048 (in-sample avg dev_std = 0.080)
SUFF++ for r=0.6 class 4 = 0.799 +- 0.048 (in-sample avg dev_std = 0.080)
SUFF++ for r=0.6 class 5 = 0.804 +- 0.048 (in-sample avg dev_std = 0.080)
SUFF++ for r=0.6 class 6 = 0.809 +- 0.048 (in-sample avg dev_std = 0.080)
SUFF++ for r=0.6 class 7 = 0.821 +- 0.048 (in-sample avg dev_std = 0.080)
SUFF++ for r=0.6 class 8 = 0.82 +- 0.048 (in-sample avg dev_std = 0.080)
SUFF++ for r=0.6 class 9 = 0.794 +- 0.048 (in-sample avg dev_std = 0.080)
SUFF++ for r=0.6 all KL = 0.955 +- 0.048 (in-sample avg dev_std = 0.080)
SUFF++ for r=0.6 all L1 = 0.81 +- 0.081 (in-sample avg dev_std = 0.080)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.22
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.229
SUFF++ for r=0.9 class 0 = 0.891 +- 0.030 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.9 class 1 = 0.869 +- 0.030 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.9 class 2 = 0.888 +- 0.030 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.9 class 3 = 0.89 +- 0.030 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.9 class 4 = 0.888 +- 0.030 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.9 class 5 = 0.901 +- 0.030 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.9 class 6 = 0.877 +- 0.030 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.9 class 7 = 0.877 +- 0.030 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.9 class 8 = 0.882 +- 0.030 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.9 class 9 = 0.872 +- 0.030 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.9 all KL = 0.976 +- 0.030 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.9 all L1 = 0.883 +- 0.072 (in-sample avg dev_std = 0.106)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.101
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.125
SUFF++ for r=0.3 class 0 = 0.688 +- 0.070 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.3 class 1 = 0.729 +- 0.070 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.3 class 2 = 0.7 +- 0.070 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.3 class 3 = 0.69 +- 0.070 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.3 class 4 = 0.697 +- 0.070 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.3 class 5 = 0.688 +- 0.070 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.3 class 6 = 0.692 +- 0.070 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.3 class 7 = 0.703 +- 0.070 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.3 class 8 = 0.688 +- 0.070 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.3 class 9 = 0.703 +- 0.070 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.3 all KL = 0.842 +- 0.070 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.3 all L1 = 0.698 +- 0.057 (in-sample avg dev_std = 0.339)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.164
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.151
SUFF++ for r=0.6 class 0 = 0.866 +- 0.038 (in-sample avg dev_std = 0.051)
SUFF++ for r=0.6 class 1 = 0.821 +- 0.038 (in-sample avg dev_std = 0.051)
SUFF++ for r=0.6 class 2 = 0.849 +- 0.038 (in-sample avg dev_std = 0.051)
SUFF++ for r=0.6 class 3 = 0.854 +- 0.038 (in-sample avg dev_std = 0.051)
SUFF++ for r=0.6 class 4 = 0.851 +- 0.038 (in-sample avg dev_std = 0.051)
SUFF++ for r=0.6 class 5 = 0.84 +- 0.038 (in-sample avg dev_std = 0.051)
SUFF++ for r=0.6 class 6 = 0.833 +- 0.038 (in-sample avg dev_std = 0.051)
SUFF++ for r=0.6 class 7 = 0.83 +- 0.038 (in-sample avg dev_std = 0.051)
SUFF++ for r=0.6 class 8 = 0.845 +- 0.038 (in-sample avg dev_std = 0.051)
SUFF++ for r=0.6 class 9 = 0.837 +- 0.038 (in-sample avg dev_std = 0.051)
SUFF++ for r=0.6 all KL = 0.97 +- 0.038 (in-sample avg dev_std = 0.051)
SUFF++ for r=0.6 all L1 = 0.843 +- 0.073 (in-sample avg dev_std = 0.051)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.172
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.179
SUFF++ for r=0.9 class 0 = 0.908 +- 0.046 (in-sample avg dev_std = 0.090)
SUFF++ for r=0.9 class 1 = 0.804 +- 0.046 (in-sample avg dev_std = 0.090)
SUFF++ for r=0.9 class 2 = 0.918 +- 0.046 (in-sample avg dev_std = 0.090)
SUFF++ for r=0.9 class 3 = 0.915 +- 0.046 (in-sample avg dev_std = 0.090)
SUFF++ for r=0.9 class 4 = 0.887 +- 0.046 (in-sample avg dev_std = 0.090)
SUFF++ for r=0.9 class 5 = 0.886 +- 0.046 (in-sample avg dev_std = 0.090)
SUFF++ for r=0.9 class 6 = 0.882 +- 0.046 (in-sample avg dev_std = 0.090)
SUFF++ for r=0.9 class 7 = 0.904 +- 0.046 (in-sample avg dev_std = 0.090)
SUFF++ for r=0.9 class 8 = 0.891 +- 0.046 (in-sample avg dev_std = 0.090)
SUFF++ for r=0.9 class 9 = 0.864 +- 0.046 (in-sample avg dev_std = 0.090)
SUFF++ for r=0.9 all KL = 0.976 +- 0.046 (in-sample avg dev_std = 0.090)
SUFF++ for r=0.9 all L1 = 0.885 +- 0.085 (in-sample avg dev_std = 0.090)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.115
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.116
NEC for r=0.3 class 0 = 0.108 +- 0.015 (in-sample avg dev_std = 0.052)
NEC for r=0.3 class 1 = 0.13 +- 0.015 (in-sample avg dev_std = 0.052)
NEC for r=0.3 class 2 = 0.117 +- 0.015 (in-sample avg dev_std = 0.052)
NEC for r=0.3 class 3 = 0.111 +- 0.015 (in-sample avg dev_std = 0.052)
NEC for r=0.3 class 4 = 0.115 +- 0.015 (in-sample avg dev_std = 0.052)
NEC for r=0.3 class 5 = 0.108 +- 0.015 (in-sample avg dev_std = 0.052)
NEC for r=0.3 class 6 = 0.11 +- 0.015 (in-sample avg dev_std = 0.052)
NEC for r=0.3 class 7 = 0.111 +- 0.015 (in-sample avg dev_std = 0.052)
NEC for r=0.3 class 8 = 0.103 +- 0.015 (in-sample avg dev_std = 0.052)
NEC for r=0.3 class 9 = 0.109 +- 0.015 (in-sample avg dev_std = 0.052)
NEC for r=0.3 all KL = 0.015 +- 0.015 (in-sample avg dev_std = 0.052)
NEC for r=0.3 all L1 = 0.112 +- 0.047 (in-sample avg dev_std = 0.052)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.134
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.129
NEC for r=0.6 class 0 = 0.151 +- 0.044 (in-sample avg dev_std = 0.085)
NEC for r=0.6 class 1 = 0.171 +- 0.044 (in-sample avg dev_std = 0.085)
NEC for r=0.6 class 2 = 0.157 +- 0.044 (in-sample avg dev_std = 0.085)
NEC for r=0.6 class 3 = 0.16 +- 0.044 (in-sample avg dev_std = 0.085)
NEC for r=0.6 class 4 = 0.161 +- 0.044 (in-sample avg dev_std = 0.085)
NEC for r=0.6 class 5 = 0.151 +- 0.044 (in-sample avg dev_std = 0.085)
NEC for r=0.6 class 6 = 0.143 +- 0.044 (in-sample avg dev_std = 0.085)
NEC for r=0.6 class 7 = 0.149 +- 0.044 (in-sample avg dev_std = 0.085)
NEC for r=0.6 class 8 = 0.141 +- 0.044 (in-sample avg dev_std = 0.085)
NEC for r=0.6 class 9 = 0.164 +- 0.044 (in-sample avg dev_std = 0.085)
NEC for r=0.6 all KL = 0.033 +- 0.044 (in-sample avg dev_std = 0.085)
NEC for r=0.6 all L1 = 0.155 +- 0.075 (in-sample avg dev_std = 0.085)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.281
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.227
NEC for r=0.9 class 0 = 0.221 +- 0.081 (in-sample avg dev_std = 0.126)
NEC for r=0.9 class 1 = 0.306 +- 0.081 (in-sample avg dev_std = 0.126)
NEC for r=0.9 class 2 = 0.261 +- 0.081 (in-sample avg dev_std = 0.126)
NEC for r=0.9 class 3 = 0.259 +- 0.081 (in-sample avg dev_std = 0.126)
NEC for r=0.9 class 4 = 0.265 +- 0.081 (in-sample avg dev_std = 0.126)
NEC for r=0.9 class 5 = 0.266 +- 0.081 (in-sample avg dev_std = 0.126)
NEC for r=0.9 class 6 = 0.255 +- 0.081 (in-sample avg dev_std = 0.126)
NEC for r=0.9 class 7 = 0.264 +- 0.081 (in-sample avg dev_std = 0.126)
NEC for r=0.9 class 8 = 0.245 +- 0.081 (in-sample avg dev_std = 0.126)
NEC for r=0.9 class 9 = 0.26 +- 0.081 (in-sample avg dev_std = 0.126)
NEC for r=0.9 all KL = 0.091 +- 0.081 (in-sample avg dev_std = 0.126)
NEC for r=0.9 all L1 = 0.261 +- 0.095 (in-sample avg dev_std = 0.126)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.343
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.303
NEC for r=1.0 class 0 = 0.244 +- 0.105 (in-sample avg dev_std = 0.132)
NEC for r=1.0 class 1 = 0.323 +- 0.105 (in-sample avg dev_std = 0.132)
NEC for r=1.0 class 2 = 0.286 +- 0.105 (in-sample avg dev_std = 0.132)
NEC for r=1.0 class 3 = 0.272 +- 0.105 (in-sample avg dev_std = 0.132)
NEC for r=1.0 class 4 = 0.312 +- 0.105 (in-sample avg dev_std = 0.132)
NEC for r=1.0 class 5 = 0.296 +- 0.105 (in-sample avg dev_std = 0.132)
NEC for r=1.0 class 6 = 0.277 +- 0.105 (in-sample avg dev_std = 0.132)
NEC for r=1.0 class 7 = 0.302 +- 0.105 (in-sample avg dev_std = 0.132)
NEC for r=1.0 class 8 = 0.267 +- 0.105 (in-sample avg dev_std = 0.132)
NEC for r=1.0 class 9 = 0.274 +- 0.105 (in-sample avg dev_std = 0.132)
NEC for r=1.0 all KL = 0.113 +- 0.105 (in-sample avg dev_std = 0.132)
NEC for r=1.0 all L1 = 0.286 +- 0.112 (in-sample avg dev_std = 0.132)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.106
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.114
NEC for r=0.3 class 0 = 0.112 +- 0.012 (in-sample avg dev_std = 0.051)
NEC for r=0.3 class 1 = 0.114 +- 0.012 (in-sample avg dev_std = 0.051)
NEC for r=0.3 class 2 = 0.11 +- 0.012 (in-sample avg dev_std = 0.051)
NEC for r=0.3 class 3 = 0.104 +- 0.012 (in-sample avg dev_std = 0.051)
NEC for r=0.3 class 4 = 0.104 +- 0.012 (in-sample avg dev_std = 0.051)
NEC for r=0.3 class 5 = 0.106 +- 0.012 (in-sample avg dev_std = 0.051)
NEC for r=0.3 class 6 = 0.104 +- 0.012 (in-sample avg dev_std = 0.051)
NEC for r=0.3 class 7 = 0.105 +- 0.012 (in-sample avg dev_std = 0.051)
NEC for r=0.3 class 8 = 0.099 +- 0.012 (in-sample avg dev_std = 0.051)
NEC for r=0.3 class 9 = 0.11 +- 0.012 (in-sample avg dev_std = 0.051)
NEC for r=0.3 all KL = 0.013 +- 0.012 (in-sample avg dev_std = 0.051)
NEC for r=0.3 all L1 = 0.107 +- 0.041 (in-sample avg dev_std = 0.051)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.151
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.134
NEC for r=0.6 class 0 = 0.133 +- 0.023 (in-sample avg dev_std = 0.082)
NEC for r=0.6 class 1 = 0.153 +- 0.023 (in-sample avg dev_std = 0.082)
NEC for r=0.6 class 2 = 0.142 +- 0.023 (in-sample avg dev_std = 0.082)
NEC for r=0.6 class 3 = 0.14 +- 0.023 (in-sample avg dev_std = 0.082)
NEC for r=0.6 class 4 = 0.146 +- 0.023 (in-sample avg dev_std = 0.082)
NEC for r=0.6 class 5 = 0.139 +- 0.023 (in-sample avg dev_std = 0.082)
NEC for r=0.6 class 6 = 0.148 +- 0.023 (in-sample avg dev_std = 0.082)
NEC for r=0.6 class 7 = 0.148 +- 0.023 (in-sample avg dev_std = 0.082)
NEC for r=0.6 class 8 = 0.137 +- 0.023 (in-sample avg dev_std = 0.082)
NEC for r=0.6 class 9 = 0.169 +- 0.023 (in-sample avg dev_std = 0.082)
NEC for r=0.6 all KL = 0.026 +- 0.023 (in-sample avg dev_std = 0.082)
NEC for r=0.6 all L1 = 0.146 +- 0.054 (in-sample avg dev_std = 0.082)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.22
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.223
NEC for r=0.9 class 0 = 0.232 +- 0.042 (in-sample avg dev_std = 0.118)
NEC for r=0.9 class 1 = 0.271 +- 0.042 (in-sample avg dev_std = 0.118)
NEC for r=0.9 class 2 = 0.249 +- 0.042 (in-sample avg dev_std = 0.118)
NEC for r=0.9 class 3 = 0.249 +- 0.042 (in-sample avg dev_std = 0.118)
NEC for r=0.9 class 4 = 0.253 +- 0.042 (in-sample avg dev_std = 0.118)
NEC for r=0.9 class 5 = 0.244 +- 0.042 (in-sample avg dev_std = 0.118)
NEC for r=0.9 class 6 = 0.254 +- 0.042 (in-sample avg dev_std = 0.118)
NEC for r=0.9 class 7 = 0.247 +- 0.042 (in-sample avg dev_std = 0.118)
NEC for r=0.9 class 8 = 0.251 +- 0.042 (in-sample avg dev_std = 0.118)
NEC for r=0.9 class 9 = 0.257 +- 0.042 (in-sample avg dev_std = 0.118)
NEC for r=0.9 all KL = 0.074 +- 0.042 (in-sample avg dev_std = 0.118)
NEC for r=0.9 all L1 = 0.251 +- 0.070 (in-sample avg dev_std = 0.118)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.22
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.237
NEC for r=1.0 class 0 = 0.26 +- 0.060 (in-sample avg dev_std = 0.131)
NEC for r=1.0 class 1 = 0.261 +- 0.060 (in-sample avg dev_std = 0.131)
NEC for r=1.0 class 2 = 0.274 +- 0.060 (in-sample avg dev_std = 0.131)
NEC for r=1.0 class 3 = 0.292 +- 0.060 (in-sample avg dev_std = 0.131)
NEC for r=1.0 class 4 = 0.306 +- 0.060 (in-sample avg dev_std = 0.131)
NEC for r=1.0 class 5 = 0.292 +- 0.060 (in-sample avg dev_std = 0.131)
NEC for r=1.0 class 6 = 0.286 +- 0.060 (in-sample avg dev_std = 0.131)
NEC for r=1.0 class 7 = 0.299 +- 0.060 (in-sample avg dev_std = 0.131)
NEC for r=1.0 class 8 = 0.296 +- 0.060 (in-sample avg dev_std = 0.131)
NEC for r=1.0 class 9 = 0.302 +- 0.060 (in-sample avg dev_std = 0.131)
NEC for r=1.0 all KL = 0.101 +- 0.060 (in-sample avg dev_std = 0.131)
NEC for r=1.0 all L1 = 0.287 +- 0.087 (in-sample avg dev_std = 0.131)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.101
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.111
NEC for r=0.3 class 0 = 0.076 +- 0.008 (in-sample avg dev_std = 0.038)
NEC for r=0.3 class 1 = 0.092 +- 0.008 (in-sample avg dev_std = 0.038)
NEC for r=0.3 class 2 = 0.082 +- 0.008 (in-sample avg dev_std = 0.038)
NEC for r=0.3 class 3 = 0.078 +- 0.008 (in-sample avg dev_std = 0.038)
NEC for r=0.3 class 4 = 0.084 +- 0.008 (in-sample avg dev_std = 0.038)
NEC for r=0.3 class 5 = 0.082 +- 0.008 (in-sample avg dev_std = 0.038)
NEC for r=0.3 class 6 = 0.084 +- 0.008 (in-sample avg dev_std = 0.038)
NEC for r=0.3 class 7 = 0.082 +- 0.008 (in-sample avg dev_std = 0.038)
NEC for r=0.3 class 8 = 0.083 +- 0.008 (in-sample avg dev_std = 0.038)
NEC for r=0.3 class 9 = 0.081 +- 0.008 (in-sample avg dev_std = 0.038)
NEC for r=0.3 all KL = 0.008 +- 0.008 (in-sample avg dev_std = 0.038)
NEC for r=0.3 all L1 = 0.083 +- 0.034 (in-sample avg dev_std = 0.038)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.164
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.144
NEC for r=0.6 class 0 = 0.114 +- 0.030 (in-sample avg dev_std = 0.065)
NEC for r=0.6 class 1 = 0.178 +- 0.030 (in-sample avg dev_std = 0.065)
NEC for r=0.6 class 2 = 0.125 +- 0.030 (in-sample avg dev_std = 0.065)
NEC for r=0.6 class 3 = 0.126 +- 0.030 (in-sample avg dev_std = 0.065)
NEC for r=0.6 class 4 = 0.132 +- 0.030 (in-sample avg dev_std = 0.065)
NEC for r=0.6 class 5 = 0.12 +- 0.030 (in-sample avg dev_std = 0.065)
NEC for r=0.6 class 6 = 0.146 +- 0.030 (in-sample avg dev_std = 0.065)
NEC for r=0.6 class 7 = 0.12 +- 0.030 (in-sample avg dev_std = 0.065)
NEC for r=0.6 class 8 = 0.123 +- 0.030 (in-sample avg dev_std = 0.065)
NEC for r=0.6 class 9 = 0.139 +- 0.030 (in-sample avg dev_std = 0.065)
NEC for r=0.6 all KL = 0.022 +- 0.030 (in-sample avg dev_std = 0.065)
NEC for r=0.6 all L1 = 0.133 +- 0.056 (in-sample avg dev_std = 0.065)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.172
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.184
NEC for r=0.9 class 0 = 0.187 +- 0.077 (in-sample avg dev_std = 0.093)
NEC for r=0.9 class 1 = 0.311 +- 0.077 (in-sample avg dev_std = 0.093)
NEC for r=0.9 class 2 = 0.207 +- 0.077 (in-sample avg dev_std = 0.093)
NEC for r=0.9 class 3 = 0.213 +- 0.077 (in-sample avg dev_std = 0.093)
NEC for r=0.9 class 4 = 0.235 +- 0.077 (in-sample avg dev_std = 0.093)
NEC for r=0.9 class 5 = 0.21 +- 0.077 (in-sample avg dev_std = 0.093)
NEC for r=0.9 class 6 = 0.229 +- 0.077 (in-sample avg dev_std = 0.093)
NEC for r=0.9 class 7 = 0.222 +- 0.077 (in-sample avg dev_std = 0.093)
NEC for r=0.9 class 8 = 0.221 +- 0.077 (in-sample avg dev_std = 0.093)
NEC for r=0.9 class 9 = 0.239 +- 0.077 (in-sample avg dev_std = 0.093)
NEC for r=0.9 all KL = 0.065 +- 0.077 (in-sample avg dev_std = 0.093)
NEC for r=0.9 all L1 = 0.228 +- 0.088 (in-sample avg dev_std = 0.093)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.155
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.182
NEC for r=1.0 class 0 = 0.232 +- 0.075 (in-sample avg dev_std = 0.111)
NEC for r=1.0 class 1 = 0.269 +- 0.075 (in-sample avg dev_std = 0.111)
NEC for r=1.0 class 2 = 0.253 +- 0.075 (in-sample avg dev_std = 0.111)
NEC for r=1.0 class 3 = 0.236 +- 0.075 (in-sample avg dev_std = 0.111)
NEC for r=1.0 class 4 = 0.264 +- 0.075 (in-sample avg dev_std = 0.111)
NEC for r=1.0 class 5 = 0.266 +- 0.075 (in-sample avg dev_std = 0.111)
NEC for r=1.0 class 6 = 0.27 +- 0.075 (in-sample avg dev_std = 0.111)
NEC for r=1.0 class 7 = 0.28 +- 0.075 (in-sample avg dev_std = 0.111)
NEC for r=1.0 class 8 = 0.271 +- 0.075 (in-sample avg dev_std = 0.111)
NEC for r=1.0 class 9 = 0.285 +- 0.075 (in-sample avg dev_std = 0.111)
NEC for r=1.0 all KL = 0.085 +- 0.075 (in-sample avg dev_std = 0.111)
NEC for r=1.0 all L1 = 0.263 +- 0.084 (in-sample avg dev_std = 0.111)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 13:33:06 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:07 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:07 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:07 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:33:08 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 197...
[0m[1;37mINFO[0m: [1mCheckpoint 197: 
-----------------------------------
Train ACCURACY: 0.4221
Train Loss: 1.6271
ID Validation ACCURACY: 0.3881
ID Validation Loss: 1.7272
ID Test ACCURACY: 0.3984
ID Test Loss: 1.6998
OOD Validation ACCURACY: 0.1159
OOD Validation Loss: 12.8596
OOD Test ACCURACY: 0.0987
OOD Test Loss: 12.4099

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 68...
[0m[1;37mINFO[0m: [1mCheckpoint 68: 
-----------------------------------
Train ACCURACY: 0.3066
Train Loss: 1.9207
ID Validation ACCURACY: 0.3050
ID Validation Loss: 1.9271
ID Test ACCURACY: 0.3113
ID Test Loss: 1.9162
OOD Validation ACCURACY: 0.2930
OOD Validation Loss: 1.9442
OOD Test ACCURACY: 0.1717
OOD Test Loss: 4.0057

[0m[1;37mINFO[0m: [1mChartInfo 0.3984 0.0987 0.3113 0.1717 0.3050 0.2930[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.108
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.107
SUFF++ for r=0.3 class 0 = 0.548 +- 0.124 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.3 class 1 = 0.624 +- 0.124 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.3 class 2 = 0.583 +- 0.124 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.3 class 3 = 0.589 +- 0.124 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.3 class 4 = 0.638 +- 0.124 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.3 class 5 = 0.618 +- 0.124 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.3 class 6 = 0.591 +- 0.124 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.3 class 7 = 0.609 +- 0.124 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.3 class 8 = 0.573 +- 0.124 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.3 class 9 = 0.609 +- 0.124 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.3 all KL = 0.716 +- 0.124 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.3 all L1 = 0.598 +- 0.093 (in-sample avg dev_std = 0.507)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.138
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.122
SUFF++ for r=0.6 class 0 = 0.823 +- 0.068 (in-sample avg dev_std = 0.101)
SUFF++ for r=0.6 class 1 = 0.722 +- 0.068 (in-sample avg dev_std = 0.101)
SUFF++ for r=0.6 class 2 = 0.802 +- 0.068 (in-sample avg dev_std = 0.101)
SUFF++ for r=0.6 class 3 = 0.796 +- 0.068 (in-sample avg dev_std = 0.101)
SUFF++ for r=0.6 class 4 = 0.8 +- 0.068 (in-sample avg dev_std = 0.101)
SUFF++ for r=0.6 class 5 = 0.802 +- 0.068 (in-sample avg dev_std = 0.101)
SUFF++ for r=0.6 class 6 = 0.79 +- 0.068 (in-sample avg dev_std = 0.101)
SUFF++ for r=0.6 class 7 = 0.782 +- 0.068 (in-sample avg dev_std = 0.101)
SUFF++ for r=0.6 class 8 = 0.784 +- 0.068 (in-sample avg dev_std = 0.101)
SUFF++ for r=0.6 class 9 = 0.782 +- 0.068 (in-sample avg dev_std = 0.101)
SUFF++ for r=0.6 all KL = 0.94 +- 0.068 (in-sample avg dev_std = 0.101)
SUFF++ for r=0.6 all L1 = 0.787 +- 0.095 (in-sample avg dev_std = 0.101)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.326
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.298
SUFF++ for r=0.9 class 0 = 0.908 +- 0.058 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.9 class 1 = 0.82 +- 0.058 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.9 class 2 = 0.886 +- 0.058 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.9 class 3 = 0.88 +- 0.058 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.9 class 4 = 0.864 +- 0.058 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.9 class 5 = 0.883 +- 0.058 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.9 class 6 = 0.855 +- 0.058 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.9 class 7 = 0.846 +- 0.058 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.9 class 8 = 0.867 +- 0.058 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.9 class 9 = 0.862 +- 0.058 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.9 all KL = 0.964 +- 0.058 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.9 all L1 = 0.866 +- 0.093 (in-sample avg dev_std = 0.132)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.106
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.121
SUFF++ for r=0.3 class 0 = 0.579 +- 0.146 (in-sample avg dev_std = 0.551)
SUFF++ for r=0.3 class 1 = 0.532 +- 0.146 (in-sample avg dev_std = 0.551)
SUFF++ for r=0.3 class 2 = 0.58 +- 0.146 (in-sample avg dev_std = 0.551)
SUFF++ for r=0.3 class 3 = 0.576 +- 0.146 (in-sample avg dev_std = 0.551)
SUFF++ for r=0.3 class 4 = 0.582 +- 0.146 (in-sample avg dev_std = 0.551)
SUFF++ for r=0.3 class 5 = 0.594 +- 0.146 (in-sample avg dev_std = 0.551)
SUFF++ for r=0.3 class 6 = 0.561 +- 0.146 (in-sample avg dev_std = 0.551)
SUFF++ for r=0.3 class 7 = 0.548 +- 0.146 (in-sample avg dev_std = 0.551)
SUFF++ for r=0.3 class 8 = 0.557 +- 0.146 (in-sample avg dev_std = 0.551)
SUFF++ for r=0.3 class 9 = 0.56 +- 0.146 (in-sample avg dev_std = 0.551)
SUFF++ for r=0.3 all KL = 0.664 +- 0.146 (in-sample avg dev_std = 0.551)
SUFF++ for r=0.3 all L1 = 0.566 +- 0.088 (in-sample avg dev_std = 0.551)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.159
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.146
SUFF++ for r=0.6 class 0 = 0.796 +- 0.119 (in-sample avg dev_std = 0.095)
SUFF++ for r=0.6 class 1 = 0.674 +- 0.119 (in-sample avg dev_std = 0.095)
SUFF++ for r=0.6 class 2 = 0.768 +- 0.119 (in-sample avg dev_std = 0.095)
SUFF++ for r=0.6 class 3 = 0.763 +- 0.119 (in-sample avg dev_std = 0.095)
SUFF++ for r=0.6 class 4 = 0.737 +- 0.119 (in-sample avg dev_std = 0.095)
SUFF++ for r=0.6 class 5 = 0.759 +- 0.119 (in-sample avg dev_std = 0.095)
SUFF++ for r=0.6 class 6 = 0.759 +- 0.119 (in-sample avg dev_std = 0.095)
SUFF++ for r=0.6 class 7 = 0.756 +- 0.119 (in-sample avg dev_std = 0.095)
SUFF++ for r=0.6 class 8 = 0.772 +- 0.119 (in-sample avg dev_std = 0.095)
SUFF++ for r=0.6 class 9 = 0.747 +- 0.119 (in-sample avg dev_std = 0.095)
SUFF++ for r=0.6 all KL = 0.91 +- 0.119 (in-sample avg dev_std = 0.095)
SUFF++ for r=0.6 all L1 = 0.752 +- 0.131 (in-sample avg dev_std = 0.095)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.121
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.123
SUFF++ for r=0.9 class 0 = 0.863 +- 0.089 (in-sample avg dev_std = 0.134)
SUFF++ for r=0.9 class 1 = 0.989 +- 0.089 (in-sample avg dev_std = 0.134)
SUFF++ for r=0.9 class 2 = 0.903 +- 0.089 (in-sample avg dev_std = 0.134)
SUFF++ for r=0.9 class 3 = 0.893 +- 0.089 (in-sample avg dev_std = 0.134)
SUFF++ for r=0.9 class 4 = 0.916 +- 0.089 (in-sample avg dev_std = 0.134)
SUFF++ for r=0.9 class 5 = 0.91 +- 0.089 (in-sample avg dev_std = 0.134)
SUFF++ for r=0.9 class 6 = 0.923 +- 0.089 (in-sample avg dev_std = 0.134)
SUFF++ for r=0.9 class 7 = 0.928 +- 0.089 (in-sample avg dev_std = 0.134)
SUFF++ for r=0.9 class 8 = 0.899 +- 0.089 (in-sample avg dev_std = 0.134)
SUFF++ for r=0.9 class 9 = 0.925 +- 0.089 (in-sample avg dev_std = 0.134)
SUFF++ for r=0.9 all KL = 0.956 +- 0.089 (in-sample avg dev_std = 0.134)
SUFF++ for r=0.9 all L1 = 0.916 +- 0.116 (in-sample avg dev_std = 0.134)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.155
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.167
SUFF++ for r=0.3 class 0 = 0.63 +- 0.138 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.3 class 1 = 0.64 +- 0.138 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.3 class 2 = 0.656 +- 0.138 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.3 class 3 = 0.612 +- 0.138 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.3 class 4 = 0.645 +- 0.138 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.3 class 5 = 0.638 +- 0.138 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.3 class 6 = 0.648 +- 0.138 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.3 class 7 = 0.653 +- 0.138 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.3 class 8 = 0.645 +- 0.138 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.3 class 9 = 0.666 +- 0.138 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.3 all KL = 0.788 +- 0.138 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.3 all L1 = 0.643 +- 0.096 (in-sample avg dev_std = 0.350)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.19
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.192
SUFF++ for r=0.6 class 0 = 0.715 +- 0.320 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.6 class 1 = 0.506 +- 0.320 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.6 class 2 = 0.663 +- 0.320 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.6 class 3 = 0.659 +- 0.320 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.6 class 4 = 0.606 +- 0.320 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.6 class 5 = 0.684 +- 0.320 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.6 class 6 = 0.592 +- 0.320 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.6 class 7 = 0.625 +- 0.320 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.6 class 8 = 0.628 +- 0.320 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.6 class 9 = 0.589 +- 0.320 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.6 all KL = 0.71 +- 0.320 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.6 all L1 = 0.625 +- 0.207 (in-sample avg dev_std = 0.238)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.134
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.156
SUFF++ for r=0.9 class 0 = 0.751 +- 0.401 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.9 class 1 = 0.628 +- 0.401 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.9 class 2 = 0.674 +- 0.401 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.9 class 3 = 0.737 +- 0.401 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.9 class 4 = 0.607 +- 0.401 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.9 class 5 = 0.721 +- 0.401 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.9 class 6 = 0.617 +- 0.401 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.9 class 7 = 0.615 +- 0.401 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.9 class 8 = 0.712 +- 0.401 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.9 class 9 = 0.623 +- 0.401 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.9 all KL = 0.636 +- 0.401 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.9 all L1 = 0.668 +- 0.263 (in-sample avg dev_std = 0.332)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.108
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.108
NEC for r=0.3 class 0 = 0.115 +- 0.017 (in-sample avg dev_std = 0.062)
NEC for r=0.3 class 1 = 0.131 +- 0.017 (in-sample avg dev_std = 0.062)
NEC for r=0.3 class 2 = 0.126 +- 0.017 (in-sample avg dev_std = 0.062)
NEC for r=0.3 class 3 = 0.121 +- 0.017 (in-sample avg dev_std = 0.062)
NEC for r=0.3 class 4 = 0.118 +- 0.017 (in-sample avg dev_std = 0.062)
NEC for r=0.3 class 5 = 0.122 +- 0.017 (in-sample avg dev_std = 0.062)
NEC for r=0.3 class 6 = 0.122 +- 0.017 (in-sample avg dev_std = 0.062)
NEC for r=0.3 class 7 = 0.124 +- 0.017 (in-sample avg dev_std = 0.062)
NEC for r=0.3 class 8 = 0.113 +- 0.017 (in-sample avg dev_std = 0.062)
NEC for r=0.3 class 9 = 0.13 +- 0.017 (in-sample avg dev_std = 0.062)
NEC for r=0.3 all KL = 0.018 +- 0.017 (in-sample avg dev_std = 0.062)
NEC for r=0.3 all L1 = 0.122 +- 0.048 (in-sample avg dev_std = 0.062)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.138
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.124
NEC for r=0.6 class 0 = 0.138 +- 0.036 (in-sample avg dev_std = 0.115)
NEC for r=0.6 class 1 = 0.213 +- 0.036 (in-sample avg dev_std = 0.115)
NEC for r=0.6 class 2 = 0.162 +- 0.036 (in-sample avg dev_std = 0.115)
NEC for r=0.6 class 3 = 0.172 +- 0.036 (in-sample avg dev_std = 0.115)
NEC for r=0.6 class 4 = 0.163 +- 0.036 (in-sample avg dev_std = 0.115)
NEC for r=0.6 class 5 = 0.152 +- 0.036 (in-sample avg dev_std = 0.115)
NEC for r=0.6 class 6 = 0.161 +- 0.036 (in-sample avg dev_std = 0.115)
NEC for r=0.6 class 7 = 0.174 +- 0.036 (in-sample avg dev_std = 0.115)
NEC for r=0.6 class 8 = 0.169 +- 0.036 (in-sample avg dev_std = 0.115)
NEC for r=0.6 class 9 = 0.174 +- 0.036 (in-sample avg dev_std = 0.115)
NEC for r=0.6 all KL = 0.038 +- 0.036 (in-sample avg dev_std = 0.115)
NEC for r=0.6 all L1 = 0.169 +- 0.066 (in-sample avg dev_std = 0.115)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.326
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.268
NEC for r=0.9 class 0 = 0.214 +- 0.092 (in-sample avg dev_std = 0.162)
NEC for r=0.9 class 1 = 0.384 +- 0.092 (in-sample avg dev_std = 0.162)
NEC for r=0.9 class 2 = 0.266 +- 0.092 (in-sample avg dev_std = 0.162)
NEC for r=0.9 class 3 = 0.264 +- 0.092 (in-sample avg dev_std = 0.162)
NEC for r=0.9 class 4 = 0.285 +- 0.092 (in-sample avg dev_std = 0.162)
NEC for r=0.9 class 5 = 0.267 +- 0.092 (in-sample avg dev_std = 0.162)
NEC for r=0.9 class 6 = 0.274 +- 0.092 (in-sample avg dev_std = 0.162)
NEC for r=0.9 class 7 = 0.3 +- 0.092 (in-sample avg dev_std = 0.162)
NEC for r=0.9 class 8 = 0.256 +- 0.092 (in-sample avg dev_std = 0.162)
NEC for r=0.9 class 9 = 0.287 +- 0.092 (in-sample avg dev_std = 0.162)
NEC for r=0.9 all KL = 0.114 +- 0.092 (in-sample avg dev_std = 0.162)
NEC for r=0.9 all L1 = 0.281 +- 0.099 (in-sample avg dev_std = 0.162)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.389
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.347
NEC for r=1.0 class 0 = 0.248 +- 0.116 (in-sample avg dev_std = 0.173)
NEC for r=1.0 class 1 = 0.299 +- 0.116 (in-sample avg dev_std = 0.173)
NEC for r=1.0 class 2 = 0.299 +- 0.116 (in-sample avg dev_std = 0.173)
NEC for r=1.0 class 3 = 0.299 +- 0.116 (in-sample avg dev_std = 0.173)
NEC for r=1.0 class 4 = 0.305 +- 0.116 (in-sample avg dev_std = 0.173)
NEC for r=1.0 class 5 = 0.296 +- 0.116 (in-sample avg dev_std = 0.173)
NEC for r=1.0 class 6 = 0.288 +- 0.116 (in-sample avg dev_std = 0.173)
NEC for r=1.0 class 7 = 0.32 +- 0.116 (in-sample avg dev_std = 0.173)
NEC for r=1.0 class 8 = 0.278 +- 0.116 (in-sample avg dev_std = 0.173)
NEC for r=1.0 class 9 = 0.306 +- 0.116 (in-sample avg dev_std = 0.173)
NEC for r=1.0 all KL = 0.133 +- 0.116 (in-sample avg dev_std = 0.173)
NEC for r=1.0 all L1 = 0.294 +- 0.113 (in-sample avg dev_std = 0.173)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.106
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.108
NEC for r=0.3 class 0 = 0.128 +- 0.021 (in-sample avg dev_std = 0.067)
NEC for r=0.3 class 1 = 0.141 +- 0.021 (in-sample avg dev_std = 0.067)
NEC for r=0.3 class 2 = 0.126 +- 0.021 (in-sample avg dev_std = 0.067)
NEC for r=0.3 class 3 = 0.132 +- 0.021 (in-sample avg dev_std = 0.067)
NEC for r=0.3 class 4 = 0.124 +- 0.021 (in-sample avg dev_std = 0.067)
NEC for r=0.3 class 5 = 0.134 +- 0.021 (in-sample avg dev_std = 0.067)
NEC for r=0.3 class 6 = 0.135 +- 0.021 (in-sample avg dev_std = 0.067)
NEC for r=0.3 class 7 = 0.124 +- 0.021 (in-sample avg dev_std = 0.067)
NEC for r=0.3 class 8 = 0.122 +- 0.021 (in-sample avg dev_std = 0.067)
NEC for r=0.3 class 9 = 0.129 +- 0.021 (in-sample avg dev_std = 0.067)
NEC for r=0.3 all KL = 0.02 +- 0.021 (in-sample avg dev_std = 0.067)
NEC for r=0.3 all L1 = 0.129 +- 0.049 (in-sample avg dev_std = 0.067)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.159
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.143
NEC for r=0.6 class 0 = 0.17 +- 0.089 (in-sample avg dev_std = 0.132)
NEC for r=0.6 class 1 = 0.282 +- 0.089 (in-sample avg dev_std = 0.132)
NEC for r=0.6 class 2 = 0.192 +- 0.089 (in-sample avg dev_std = 0.132)
NEC for r=0.6 class 3 = 0.173 +- 0.089 (in-sample avg dev_std = 0.132)
NEC for r=0.6 class 4 = 0.217 +- 0.089 (in-sample avg dev_std = 0.132)
NEC for r=0.6 class 5 = 0.2 +- 0.089 (in-sample avg dev_std = 0.132)
NEC for r=0.6 class 6 = 0.212 +- 0.089 (in-sample avg dev_std = 0.132)
NEC for r=0.6 class 7 = 0.197 +- 0.089 (in-sample avg dev_std = 0.132)
NEC for r=0.6 class 8 = 0.18 +- 0.089 (in-sample avg dev_std = 0.132)
NEC for r=0.6 class 9 = 0.21 +- 0.089 (in-sample avg dev_std = 0.132)
NEC for r=0.6 all KL = 0.063 +- 0.089 (in-sample avg dev_std = 0.132)
NEC for r=0.6 all L1 = 0.205 +- 0.100 (in-sample avg dev_std = 0.132)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.121
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.13
NEC for r=0.9 class 0 = 0.328 +- 0.170 (in-sample avg dev_std = 0.192)
NEC for r=0.9 class 1 = 0.03 +- 0.170 (in-sample avg dev_std = 0.192)
NEC for r=0.9 class 2 = 0.244 +- 0.170 (in-sample avg dev_std = 0.192)
NEC for r=0.9 class 3 = 0.269 +- 0.170 (in-sample avg dev_std = 0.192)
NEC for r=0.9 class 4 = 0.23 +- 0.170 (in-sample avg dev_std = 0.192)
NEC for r=0.9 class 5 = 0.233 +- 0.170 (in-sample avg dev_std = 0.192)
NEC for r=0.9 class 6 = 0.221 +- 0.170 (in-sample avg dev_std = 0.192)
NEC for r=0.9 class 7 = 0.17 +- 0.170 (in-sample avg dev_std = 0.192)
NEC for r=0.9 class 8 = 0.269 +- 0.170 (in-sample avg dev_std = 0.192)
NEC for r=0.9 class 9 = 0.167 +- 0.170 (in-sample avg dev_std = 0.192)
NEC for r=0.9 all KL = 0.169 +- 0.170 (in-sample avg dev_std = 0.192)
NEC for r=0.9 all L1 = 0.212 +- 0.199 (in-sample avg dev_std = 0.192)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.116
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.123
NEC for r=1.0 class 0 = 0.25 +- 0.199 (in-sample avg dev_std = 0.172)
NEC for r=1.0 class 1 = 0.021 +- 0.199 (in-sample avg dev_std = 0.172)
NEC for r=1.0 class 2 = 0.196 +- 0.199 (in-sample avg dev_std = 0.172)
NEC for r=1.0 class 3 = 0.176 +- 0.199 (in-sample avg dev_std = 0.172)
NEC for r=1.0 class 4 = 0.094 +- 0.199 (in-sample avg dev_std = 0.172)
NEC for r=1.0 class 5 = 0.201 +- 0.199 (in-sample avg dev_std = 0.172)
NEC for r=1.0 class 6 = 0.15 +- 0.199 (in-sample avg dev_std = 0.172)
NEC for r=1.0 class 7 = 0.098 +- 0.199 (in-sample avg dev_std = 0.172)
NEC for r=1.0 class 8 = 0.185 +- 0.199 (in-sample avg dev_std = 0.172)
NEC for r=1.0 class 9 = 0.085 +- 0.199 (in-sample avg dev_std = 0.172)
NEC for r=1.0 all KL = 0.14 +- 0.199 (in-sample avg dev_std = 0.172)
NEC for r=1.0 all L1 = 0.142 +- 0.203 (in-sample avg dev_std = 0.172)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.155
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.134
NEC for r=0.3 class 0 = 0.171 +- 0.142 (in-sample avg dev_std = 0.066)
NEC for r=0.3 class 1 = 0.33 +- 0.142 (in-sample avg dev_std = 0.066)
NEC for r=0.3 class 2 = 0.193 +- 0.142 (in-sample avg dev_std = 0.066)
NEC for r=0.3 class 3 = 0.22 +- 0.142 (in-sample avg dev_std = 0.066)
NEC for r=0.3 class 4 = 0.267 +- 0.142 (in-sample avg dev_std = 0.066)
NEC for r=0.3 class 5 = 0.189 +- 0.142 (in-sample avg dev_std = 0.066)
NEC for r=0.3 class 6 = 0.259 +- 0.142 (in-sample avg dev_std = 0.066)
NEC for r=0.3 class 7 = 0.238 +- 0.142 (in-sample avg dev_std = 0.066)
NEC for r=0.3 class 8 = 0.221 +- 0.142 (in-sample avg dev_std = 0.066)
NEC for r=0.3 class 9 = 0.289 +- 0.142 (in-sample avg dev_std = 0.066)
NEC for r=0.3 all KL = 0.101 +- 0.142 (in-sample avg dev_std = 0.066)
NEC for r=0.3 all L1 = 0.239 +- 0.163 (in-sample avg dev_std = 0.066)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.19
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.189
NEC for r=0.6 class 0 = 0.266 +- 0.361 (in-sample avg dev_std = 0.109)
NEC for r=0.6 class 1 = 0.522 +- 0.361 (in-sample avg dev_std = 0.109)
NEC for r=0.6 class 2 = 0.33 +- 0.361 (in-sample avg dev_std = 0.109)
NEC for r=0.6 class 3 = 0.33 +- 0.361 (in-sample avg dev_std = 0.109)
NEC for r=0.6 class 4 = 0.44 +- 0.361 (in-sample avg dev_std = 0.109)
NEC for r=0.6 class 5 = 0.293 +- 0.361 (in-sample avg dev_std = 0.109)
NEC for r=0.6 class 6 = 0.429 +- 0.361 (in-sample avg dev_std = 0.109)
NEC for r=0.6 class 7 = 0.397 +- 0.361 (in-sample avg dev_std = 0.109)
NEC for r=0.6 class 8 = 0.36 +- 0.361 (in-sample avg dev_std = 0.109)
NEC for r=0.6 class 9 = 0.462 +- 0.361 (in-sample avg dev_std = 0.109)
NEC for r=0.6 all KL = 0.313 +- 0.361 (in-sample avg dev_std = 0.109)
NEC for r=0.6 all L1 = 0.384 +- 0.260 (in-sample avg dev_std = 0.109)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.134
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.179
NEC for r=0.9 class 0 = 0.384 +- 0.397 (in-sample avg dev_std = 0.161)
NEC for r=0.9 class 1 = 0.421 +- 0.397 (in-sample avg dev_std = 0.161)
NEC for r=0.9 class 2 = 0.471 +- 0.397 (in-sample avg dev_std = 0.161)
NEC for r=0.9 class 3 = 0.409 +- 0.397 (in-sample avg dev_std = 0.161)
NEC for r=0.9 class 4 = 0.544 +- 0.397 (in-sample avg dev_std = 0.161)
NEC for r=0.9 class 5 = 0.438 +- 0.397 (in-sample avg dev_std = 0.161)
NEC for r=0.9 class 6 = 0.526 +- 0.397 (in-sample avg dev_std = 0.161)
NEC for r=0.9 class 7 = 0.53 +- 0.397 (in-sample avg dev_std = 0.161)
NEC for r=0.9 class 8 = 0.457 +- 0.397 (in-sample avg dev_std = 0.161)
NEC for r=0.9 class 9 = 0.534 +- 0.397 (in-sample avg dev_std = 0.161)
NEC for r=0.9 all KL = 0.46 +- 0.397 (in-sample avg dev_std = 0.161)
NEC for r=0.9 all L1 = 0.471 +- 0.260 (in-sample avg dev_std = 0.161)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.101
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.154
NEC for r=1.0 class 0 = 0.437 +- 0.381 (in-sample avg dev_std = 0.170)
NEC for r=1.0 class 1 = 0.392 +- 0.381 (in-sample avg dev_std = 0.170)
NEC for r=1.0 class 2 = 0.518 +- 0.381 (in-sample avg dev_std = 0.170)
NEC for r=1.0 class 3 = 0.436 +- 0.381 (in-sample avg dev_std = 0.170)
NEC for r=1.0 class 4 = 0.533 +- 0.381 (in-sample avg dev_std = 0.170)
NEC for r=1.0 class 5 = 0.469 +- 0.381 (in-sample avg dev_std = 0.170)
NEC for r=1.0 class 6 = 0.522 +- 0.381 (in-sample avg dev_std = 0.170)
NEC for r=1.0 class 7 = 0.556 +- 0.381 (in-sample avg dev_std = 0.170)
NEC for r=1.0 class 8 = 0.458 +- 0.381 (in-sample avg dev_std = 0.170)
NEC for r=1.0 class 9 = 0.498 +- 0.381 (in-sample avg dev_std = 0.170)
NEC for r=1.0 all KL = 0.484 +- 0.381 (in-sample avg dev_std = 0.170)
NEC for r=1.0 all L1 = 0.481 +- 0.258 (in-sample avg dev_std = 0.170)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 13:52:01 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 01:52:02 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 01:52:03 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 187...
[0m[1;37mINFO[0m: [1mCheckpoint 187: 
-----------------------------------
Train ACCURACY: 0.4022
Train Loss: 1.6862
ID Validation ACCURACY: 0.3846
ID Validation Loss: 1.7268
ID Test ACCURACY: 0.3937
ID Test Loss: 1.7097
OOD Validation ACCURACY: 0.1211
OOD Validation Loss: 7.6338
OOD Test ACCURACY: 0.1210
OOD Test Loss: 7.0955

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 108...
[0m[1;37mINFO[0m: [1mCheckpoint 108: 
-----------------------------------
Train ACCURACY: 0.3179
Train Loss: 1.8973
ID Validation ACCURACY: 0.3136
ID Validation Loss: 1.9053
ID Test ACCURACY: 0.3183
ID Test Loss: 1.8974
OOD Validation ACCURACY: 0.2959
OOD Validation Loss: 1.9613
OOD Test ACCURACY: 0.2541
OOD Test Loss: 2.1020

[0m[1;37mINFO[0m: [1mChartInfo 0.3937 0.1210 0.3183 0.2541 0.3136 0.2959[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.106
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.121
SUFF++ for r=0.3 class 0 = 0.609 +- 0.125 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.3 class 1 = 0.696 +- 0.125 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.3 class 2 = 0.637 +- 0.125 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.3 class 3 = 0.651 +- 0.125 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.3 class 4 = 0.677 +- 0.125 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.3 class 5 = 0.669 +- 0.125 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.3 class 6 = 0.643 +- 0.125 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.3 class 7 = 0.675 +- 0.125 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.3 class 8 = 0.618 +- 0.125 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.3 class 9 = 0.657 +- 0.125 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.3 all KL = 0.774 +- 0.125 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.3 all L1 = 0.654 +- 0.094 (in-sample avg dev_std = 0.425)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.149
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.123
SUFF++ for r=0.6 class 0 = 0.834 +- 0.048 (in-sample avg dev_std = 0.078)
SUFF++ for r=0.6 class 1 = 0.774 +- 0.048 (in-sample avg dev_std = 0.078)
SUFF++ for r=0.6 class 2 = 0.814 +- 0.048 (in-sample avg dev_std = 0.078)
SUFF++ for r=0.6 class 3 = 0.815 +- 0.048 (in-sample avg dev_std = 0.078)
SUFF++ for r=0.6 class 4 = 0.818 +- 0.048 (in-sample avg dev_std = 0.078)
SUFF++ for r=0.6 class 5 = 0.823 +- 0.048 (in-sample avg dev_std = 0.078)
SUFF++ for r=0.6 class 6 = 0.814 +- 0.048 (in-sample avg dev_std = 0.078)
SUFF++ for r=0.6 class 7 = 0.817 +- 0.048 (in-sample avg dev_std = 0.078)
SUFF++ for r=0.6 class 8 = 0.799 +- 0.048 (in-sample avg dev_std = 0.078)
SUFF++ for r=0.6 class 9 = 0.786 +- 0.048 (in-sample avg dev_std = 0.078)
SUFF++ for r=0.6 all KL = 0.952 +- 0.048 (in-sample avg dev_std = 0.078)
SUFF++ for r=0.6 all L1 = 0.809 +- 0.081 (in-sample avg dev_std = 0.078)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.327
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.302
SUFF++ for r=0.9 class 0 = 0.897 +- 0.035 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.9 class 1 = 0.828 +- 0.035 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.9 class 2 = 0.898 +- 0.035 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.9 class 3 = 0.896 +- 0.035 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.9 class 4 = 0.893 +- 0.035 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.9 class 5 = 0.892 +- 0.035 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.9 class 6 = 0.885 +- 0.035 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.9 class 7 = 0.877 +- 0.035 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.9 class 8 = 0.885 +- 0.035 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.9 class 9 = 0.882 +- 0.035 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.9 all KL = 0.975 +- 0.035 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.9 all L1 = 0.883 +- 0.074 (in-sample avg dev_std = 0.105)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.096
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.114
SUFF++ for r=0.3 class 0 = 0.605 +- 0.116 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.3 class 1 = 0.559 +- 0.116 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.3 class 2 = 0.602 +- 0.116 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.3 class 3 = 0.597 +- 0.116 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.3 class 4 = 0.603 +- 0.116 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.3 class 5 = 0.607 +- 0.116 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.3 class 6 = 0.595 +- 0.116 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.3 class 7 = 0.584 +- 0.116 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.3 class 8 = 0.592 +- 0.116 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.3 class 9 = 0.601 +- 0.116 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.3 all KL = 0.708 +- 0.116 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.3 all L1 = 0.594 +- 0.077 (in-sample avg dev_std = 0.501)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.141
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.127
SUFF++ for r=0.6 class 0 = 0.829 +- 0.054 (in-sample avg dev_std = 0.070)
SUFF++ for r=0.6 class 1 = 0.744 +- 0.054 (in-sample avg dev_std = 0.070)
SUFF++ for r=0.6 class 2 = 0.811 +- 0.054 (in-sample avg dev_std = 0.070)
SUFF++ for r=0.6 class 3 = 0.803 +- 0.054 (in-sample avg dev_std = 0.070)
SUFF++ for r=0.6 class 4 = 0.794 +- 0.054 (in-sample avg dev_std = 0.070)
SUFF++ for r=0.6 class 5 = 0.796 +- 0.054 (in-sample avg dev_std = 0.070)
SUFF++ for r=0.6 class 6 = 0.795 +- 0.054 (in-sample avg dev_std = 0.070)
SUFF++ for r=0.6 class 7 = 0.796 +- 0.054 (in-sample avg dev_std = 0.070)
SUFF++ for r=0.6 class 8 = 0.816 +- 0.054 (in-sample avg dev_std = 0.070)
SUFF++ for r=0.6 class 9 = 0.798 +- 0.054 (in-sample avg dev_std = 0.070)
SUFF++ for r=0.6 all KL = 0.95 +- 0.054 (in-sample avg dev_std = 0.070)
SUFF++ for r=0.6 all L1 = 0.797 +- 0.090 (in-sample avg dev_std = 0.070)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.141
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.148
SUFF++ for r=0.9 class 0 = 0.864 +- 0.072 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.9 class 1 = 0.955 +- 0.072 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.9 class 2 = 0.862 +- 0.072 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.9 class 3 = 0.855 +- 0.072 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.9 class 4 = 0.875 +- 0.072 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.9 class 5 = 0.895 +- 0.072 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.9 class 6 = 0.861 +- 0.072 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.9 class 7 = 0.874 +- 0.072 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.9 class 8 = 0.864 +- 0.072 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.9 class 9 = 0.881 +- 0.072 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.9 all KL = 0.957 +- 0.072 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.9 all L1 = 0.88 +- 0.102 (in-sample avg dev_std = 0.135)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.125
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.132
SUFF++ for r=0.3 class 0 = 0.704 +- 0.087 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.3 class 1 = 0.696 +- 0.087 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.3 class 2 = 0.713 +- 0.087 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.3 class 3 = 0.705 +- 0.087 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.3 class 4 = 0.706 +- 0.087 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.3 class 5 = 0.699 +- 0.087 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.3 class 6 = 0.702 +- 0.087 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.3 class 7 = 0.704 +- 0.087 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.3 class 8 = 0.704 +- 0.087 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.3 class 9 = 0.719 +- 0.087 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.3 all KL = 0.845 +- 0.087 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.3 all L1 = 0.705 +- 0.071 (in-sample avg dev_std = 0.328)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.14
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.121
SUFF++ for r=0.6 class 0 = 0.844 +- 0.045 (in-sample avg dev_std = 0.054)
SUFF++ for r=0.6 class 1 = 0.785 +- 0.045 (in-sample avg dev_std = 0.054)
SUFF++ for r=0.6 class 2 = 0.824 +- 0.045 (in-sample avg dev_std = 0.054)
SUFF++ for r=0.6 class 3 = 0.828 +- 0.045 (in-sample avg dev_std = 0.054)
SUFF++ for r=0.6 class 4 = 0.819 +- 0.045 (in-sample avg dev_std = 0.054)
SUFF++ for r=0.6 class 5 = 0.82 +- 0.045 (in-sample avg dev_std = 0.054)
SUFF++ for r=0.6 class 6 = 0.807 +- 0.045 (in-sample avg dev_std = 0.054)
SUFF++ for r=0.6 class 7 = 0.798 +- 0.045 (in-sample avg dev_std = 0.054)
SUFF++ for r=0.6 class 8 = 0.798 +- 0.045 (in-sample avg dev_std = 0.054)
SUFF++ for r=0.6 class 9 = 0.813 +- 0.045 (in-sample avg dev_std = 0.054)
SUFF++ for r=0.6 all KL = 0.957 +- 0.045 (in-sample avg dev_std = 0.054)
SUFF++ for r=0.6 all L1 = 0.813 +- 0.083 (in-sample avg dev_std = 0.054)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.139
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.153
SUFF++ for r=0.9 class 0 = 0.846 +- 0.071 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.9 class 1 = 0.92 +- 0.071 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.9 class 2 = 0.845 +- 0.071 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.9 class 3 = 0.865 +- 0.071 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.9 class 4 = 0.842 +- 0.071 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.9 class 5 = 0.845 +- 0.071 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.9 class 6 = 0.85 +- 0.071 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.9 class 7 = 0.837 +- 0.071 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.9 class 8 = 0.845 +- 0.071 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.9 class 9 = 0.844 +- 0.071 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.9 all KL = 0.946 +- 0.071 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.9 all L1 = 0.855 +- 0.108 (in-sample avg dev_std = 0.145)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.106
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.113
NEC for r=0.3 class 0 = 0.107 +- 0.011 (in-sample avg dev_std = 0.051)
NEC for r=0.3 class 1 = 0.109 +- 0.011 (in-sample avg dev_std = 0.051)
NEC for r=0.3 class 2 = 0.112 +- 0.011 (in-sample avg dev_std = 0.051)
NEC for r=0.3 class 3 = 0.107 +- 0.011 (in-sample avg dev_std = 0.051)
NEC for r=0.3 class 4 = 0.104 +- 0.011 (in-sample avg dev_std = 0.051)
NEC for r=0.3 class 5 = 0.108 +- 0.011 (in-sample avg dev_std = 0.051)
NEC for r=0.3 class 6 = 0.108 +- 0.011 (in-sample avg dev_std = 0.051)
NEC for r=0.3 class 7 = 0.107 +- 0.011 (in-sample avg dev_std = 0.051)
NEC for r=0.3 class 8 = 0.099 +- 0.011 (in-sample avg dev_std = 0.051)
NEC for r=0.3 class 9 = 0.112 +- 0.011 (in-sample avg dev_std = 0.051)
NEC for r=0.3 all KL = 0.014 +- 0.011 (in-sample avg dev_std = 0.051)
NEC for r=0.3 all L1 = 0.107 +- 0.038 (in-sample avg dev_std = 0.051)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.149
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.128
NEC for r=0.6 class 0 = 0.142 +- 0.027 (in-sample avg dev_std = 0.089)
NEC for r=0.6 class 1 = 0.168 +- 0.027 (in-sample avg dev_std = 0.089)
NEC for r=0.6 class 2 = 0.151 +- 0.027 (in-sample avg dev_std = 0.089)
NEC for r=0.6 class 3 = 0.162 +- 0.027 (in-sample avg dev_std = 0.089)
NEC for r=0.6 class 4 = 0.157 +- 0.027 (in-sample avg dev_std = 0.089)
NEC for r=0.6 class 5 = 0.137 +- 0.027 (in-sample avg dev_std = 0.089)
NEC for r=0.6 class 6 = 0.152 +- 0.027 (in-sample avg dev_std = 0.089)
NEC for r=0.6 class 7 = 0.148 +- 0.027 (in-sample avg dev_std = 0.089)
NEC for r=0.6 class 8 = 0.146 +- 0.027 (in-sample avg dev_std = 0.089)
NEC for r=0.6 class 9 = 0.167 +- 0.027 (in-sample avg dev_std = 0.089)
NEC for r=0.6 all KL = 0.031 +- 0.027 (in-sample avg dev_std = 0.089)
NEC for r=0.6 all L1 = 0.153 +- 0.057 (in-sample avg dev_std = 0.089)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.327
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.271
NEC for r=0.9 class 0 = 0.214 +- 0.059 (in-sample avg dev_std = 0.132)
NEC for r=0.9 class 1 = 0.345 +- 0.059 (in-sample avg dev_std = 0.132)
NEC for r=0.9 class 2 = 0.224 +- 0.059 (in-sample avg dev_std = 0.132)
NEC for r=0.9 class 3 = 0.236 +- 0.059 (in-sample avg dev_std = 0.132)
NEC for r=0.9 class 4 = 0.236 +- 0.059 (in-sample avg dev_std = 0.132)
NEC for r=0.9 class 5 = 0.23 +- 0.059 (in-sample avg dev_std = 0.132)
NEC for r=0.9 class 6 = 0.232 +- 0.059 (in-sample avg dev_std = 0.132)
NEC for r=0.9 class 7 = 0.246 +- 0.059 (in-sample avg dev_std = 0.132)
NEC for r=0.9 class 8 = 0.231 +- 0.059 (in-sample avg dev_std = 0.132)
NEC for r=0.9 class 9 = 0.245 +- 0.059 (in-sample avg dev_std = 0.132)
NEC for r=0.9 all KL = 0.077 +- 0.059 (in-sample avg dev_std = 0.132)
NEC for r=0.9 all L1 = 0.245 +- 0.075 (in-sample avg dev_std = 0.132)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.4
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.343
NEC for r=1.0 class 0 = 0.234 +- 0.078 (in-sample avg dev_std = 0.142)
NEC for r=1.0 class 1 = 0.327 +- 0.078 (in-sample avg dev_std = 0.142)
NEC for r=1.0 class 2 = 0.258 +- 0.078 (in-sample avg dev_std = 0.142)
NEC for r=1.0 class 3 = 0.253 +- 0.078 (in-sample avg dev_std = 0.142)
NEC for r=1.0 class 4 = 0.276 +- 0.078 (in-sample avg dev_std = 0.142)
NEC for r=1.0 class 5 = 0.257 +- 0.078 (in-sample avg dev_std = 0.142)
NEC for r=1.0 class 6 = 0.261 +- 0.078 (in-sample avg dev_std = 0.142)
NEC for r=1.0 class 7 = 0.286 +- 0.078 (in-sample avg dev_std = 0.142)
NEC for r=1.0 class 8 = 0.258 +- 0.078 (in-sample avg dev_std = 0.142)
NEC for r=1.0 class 9 = 0.272 +- 0.078 (in-sample avg dev_std = 0.142)
NEC for r=1.0 all KL = 0.098 +- 0.078 (in-sample avg dev_std = 0.142)
NEC for r=1.0 all L1 = 0.269 +- 0.090 (in-sample avg dev_std = 0.142)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.096
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.1
NEC for r=0.3 class 0 = 0.112 +- 0.011 (in-sample avg dev_std = 0.057)
NEC for r=0.3 class 1 = 0.109 +- 0.011 (in-sample avg dev_std = 0.057)
NEC for r=0.3 class 2 = 0.112 +- 0.011 (in-sample avg dev_std = 0.057)
NEC for r=0.3 class 3 = 0.118 +- 0.011 (in-sample avg dev_std = 0.057)
NEC for r=0.3 class 4 = 0.121 +- 0.011 (in-sample avg dev_std = 0.057)
NEC for r=0.3 class 5 = 0.113 +- 0.011 (in-sample avg dev_std = 0.057)
NEC for r=0.3 class 6 = 0.117 +- 0.011 (in-sample avg dev_std = 0.057)
NEC for r=0.3 class 7 = 0.112 +- 0.011 (in-sample avg dev_std = 0.057)
NEC for r=0.3 class 8 = 0.111 +- 0.011 (in-sample avg dev_std = 0.057)
NEC for r=0.3 class 9 = 0.11 +- 0.011 (in-sample avg dev_std = 0.057)
NEC for r=0.3 all KL = 0.014 +- 0.011 (in-sample avg dev_std = 0.057)
NEC for r=0.3 all L1 = 0.113 +- 0.039 (in-sample avg dev_std = 0.057)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.141
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.13
NEC for r=0.6 class 0 = 0.132 +- 0.028 (in-sample avg dev_std = 0.086)
NEC for r=0.6 class 1 = 0.189 +- 0.028 (in-sample avg dev_std = 0.086)
NEC for r=0.6 class 2 = 0.153 +- 0.028 (in-sample avg dev_std = 0.086)
NEC for r=0.6 class 3 = 0.144 +- 0.028 (in-sample avg dev_std = 0.086)
NEC for r=0.6 class 4 = 0.158 +- 0.028 (in-sample avg dev_std = 0.086)
NEC for r=0.6 class 5 = 0.145 +- 0.028 (in-sample avg dev_std = 0.086)
NEC for r=0.6 class 6 = 0.158 +- 0.028 (in-sample avg dev_std = 0.086)
NEC for r=0.6 class 7 = 0.156 +- 0.028 (in-sample avg dev_std = 0.086)
NEC for r=0.6 class 8 = 0.148 +- 0.028 (in-sample avg dev_std = 0.086)
NEC for r=0.6 class 9 = 0.165 +- 0.028 (in-sample avg dev_std = 0.086)
NEC for r=0.6 all KL = 0.029 +- 0.028 (in-sample avg dev_std = 0.086)
NEC for r=0.6 all L1 = 0.156 +- 0.059 (in-sample avg dev_std = 0.086)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.141
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.16
NEC for r=0.9 class 0 = 0.301 +- 0.128 (in-sample avg dev_std = 0.170)
NEC for r=0.9 class 1 = 0.117 +- 0.128 (in-sample avg dev_std = 0.170)
NEC for r=0.9 class 2 = 0.332 +- 0.128 (in-sample avg dev_std = 0.170)
NEC for r=0.9 class 3 = 0.336 +- 0.128 (in-sample avg dev_std = 0.170)
NEC for r=0.9 class 4 = 0.311 +- 0.128 (in-sample avg dev_std = 0.170)
NEC for r=0.9 class 5 = 0.316 +- 0.128 (in-sample avg dev_std = 0.170)
NEC for r=0.9 class 6 = 0.328 +- 0.128 (in-sample avg dev_std = 0.170)
NEC for r=0.9 class 7 = 0.319 +- 0.128 (in-sample avg dev_std = 0.170)
NEC for r=0.9 class 8 = 0.339 +- 0.128 (in-sample avg dev_std = 0.170)
NEC for r=0.9 class 9 = 0.277 +- 0.128 (in-sample avg dev_std = 0.170)
NEC for r=0.9 all KL = 0.161 +- 0.128 (in-sample avg dev_std = 0.170)
NEC for r=0.9 all L1 = 0.295 +- 0.159 (in-sample avg dev_std = 0.170)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.119
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.135
NEC for r=1.0 class 0 = 0.354 +- 0.143 (in-sample avg dev_std = 0.159)
NEC for r=1.0 class 1 = 0.038 +- 0.143 (in-sample avg dev_std = 0.159)
NEC for r=1.0 class 2 = 0.286 +- 0.143 (in-sample avg dev_std = 0.159)
NEC for r=1.0 class 3 = 0.329 +- 0.143 (in-sample avg dev_std = 0.159)
NEC for r=1.0 class 4 = 0.24 +- 0.143 (in-sample avg dev_std = 0.159)
NEC for r=1.0 class 5 = 0.261 +- 0.143 (in-sample avg dev_std = 0.159)
NEC for r=1.0 class 6 = 0.268 +- 0.143 (in-sample avg dev_std = 0.159)
NEC for r=1.0 class 7 = 0.215 +- 0.143 (in-sample avg dev_std = 0.159)
NEC for r=1.0 class 8 = 0.306 +- 0.143 (in-sample avg dev_std = 0.159)
NEC for r=1.0 class 9 = 0.194 +- 0.143 (in-sample avg dev_std = 0.159)
NEC for r=1.0 all KL = 0.171 +- 0.143 (in-sample avg dev_std = 0.159)
NEC for r=1.0 all L1 = 0.245 +- 0.188 (in-sample avg dev_std = 0.159)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.125
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.12
NEC for r=0.3 class 0 = 0.104 +- 0.012 (in-sample avg dev_std = 0.052)
NEC for r=0.3 class 1 = 0.113 +- 0.012 (in-sample avg dev_std = 0.052)
NEC for r=0.3 class 2 = 0.102 +- 0.012 (in-sample avg dev_std = 0.052)
NEC for r=0.3 class 3 = 0.106 +- 0.012 (in-sample avg dev_std = 0.052)
NEC for r=0.3 class 4 = 0.108 +- 0.012 (in-sample avg dev_std = 0.052)
NEC for r=0.3 class 5 = 0.097 +- 0.012 (in-sample avg dev_std = 0.052)
NEC for r=0.3 class 6 = 0.106 +- 0.012 (in-sample avg dev_std = 0.052)
NEC for r=0.3 class 7 = 0.1 +- 0.012 (in-sample avg dev_std = 0.052)
NEC for r=0.3 class 8 = 0.105 +- 0.012 (in-sample avg dev_std = 0.052)
NEC for r=0.3 class 9 = 0.101 +- 0.012 (in-sample avg dev_std = 0.052)
NEC for r=0.3 all KL = 0.013 +- 0.012 (in-sample avg dev_std = 0.052)
NEC for r=0.3 all L1 = 0.104 +- 0.040 (in-sample avg dev_std = 0.052)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.14
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.135
NEC for r=0.6 class 0 = 0.132 +- 0.020 (in-sample avg dev_std = 0.075)
NEC for r=0.6 class 1 = 0.164 +- 0.020 (in-sample avg dev_std = 0.075)
NEC for r=0.6 class 2 = 0.14 +- 0.020 (in-sample avg dev_std = 0.075)
NEC for r=0.6 class 3 = 0.141 +- 0.020 (in-sample avg dev_std = 0.075)
NEC for r=0.6 class 4 = 0.153 +- 0.020 (in-sample avg dev_std = 0.075)
NEC for r=0.6 class 5 = 0.141 +- 0.020 (in-sample avg dev_std = 0.075)
NEC for r=0.6 class 6 = 0.153 +- 0.020 (in-sample avg dev_std = 0.075)
NEC for r=0.6 class 7 = 0.146 +- 0.020 (in-sample avg dev_std = 0.075)
NEC for r=0.6 class 8 = 0.149 +- 0.020 (in-sample avg dev_std = 0.075)
NEC for r=0.6 class 9 = 0.156 +- 0.020 (in-sample avg dev_std = 0.075)
NEC for r=0.6 all KL = 0.027 +- 0.020 (in-sample avg dev_std = 0.075)
NEC for r=0.6 all L1 = 0.148 +- 0.047 (in-sample avg dev_std = 0.075)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.139
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.166
NEC for r=0.9 class 0 = 0.305 +- 0.116 (in-sample avg dev_std = 0.172)
NEC for r=0.9 class 1 = 0.162 +- 0.116 (in-sample avg dev_std = 0.172)
NEC for r=0.9 class 2 = 0.315 +- 0.116 (in-sample avg dev_std = 0.172)
NEC for r=0.9 class 3 = 0.319 +- 0.116 (in-sample avg dev_std = 0.172)
NEC for r=0.9 class 4 = 0.31 +- 0.116 (in-sample avg dev_std = 0.172)
NEC for r=0.9 class 5 = 0.306 +- 0.116 (in-sample avg dev_std = 0.172)
NEC for r=0.9 class 6 = 0.311 +- 0.116 (in-sample avg dev_std = 0.172)
NEC for r=0.9 class 7 = 0.327 +- 0.116 (in-sample avg dev_std = 0.172)
NEC for r=0.9 class 8 = 0.325 +- 0.116 (in-sample avg dev_std = 0.172)
NEC for r=0.9 class 9 = 0.309 +- 0.116 (in-sample avg dev_std = 0.172)
NEC for r=0.9 all KL = 0.155 +- 0.116 (in-sample avg dev_std = 0.172)
NEC for r=0.9 all L1 = 0.297 +- 0.141 (in-sample avg dev_std = 0.172)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.124
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.135
NEC for r=1.0 class 0 = 0.366 +- 0.178 (in-sample avg dev_std = 0.198)
NEC for r=1.0 class 1 = 0.045 +- 0.178 (in-sample avg dev_std = 0.198)
NEC for r=1.0 class 2 = 0.348 +- 0.178 (in-sample avg dev_std = 0.198)
NEC for r=1.0 class 3 = 0.301 +- 0.178 (in-sample avg dev_std = 0.198)
NEC for r=1.0 class 4 = 0.267 +- 0.178 (in-sample avg dev_std = 0.198)
NEC for r=1.0 class 5 = 0.363 +- 0.178 (in-sample avg dev_std = 0.198)
NEC for r=1.0 class 6 = 0.326 +- 0.178 (in-sample avg dev_std = 0.198)
NEC for r=1.0 class 7 = 0.286 +- 0.178 (in-sample avg dev_std = 0.198)
NEC for r=1.0 class 8 = 0.293 +- 0.178 (in-sample avg dev_std = 0.198)
NEC for r=1.0 class 9 = 0.246 +- 0.178 (in-sample avg dev_std = 0.198)
NEC for r=1.0 all KL = 0.222 +- 0.178 (in-sample avg dev_std = 0.198)
NEC for r=1.0 all L1 = 0.281 +- 0.199 (in-sample avg dev_std = 0.198)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 14:10:44 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:45 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:45 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:10:46 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 199...
[0m[1;37mINFO[0m: [1mCheckpoint 199: 
-----------------------------------
Train ACCURACY: 0.3825
Train Loss: 1.7472
ID Validation ACCURACY: 0.3644
ID Validation Loss: 1.7852
ID Test ACCURACY: 0.3786
ID Test Loss: 1.7707
OOD Validation ACCURACY: 0.1313
OOD Validation Loss: 4.2171
OOD Test ACCURACY: 0.1213
OOD Test Loss: 4.5535

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 69...
[0m[1;37mINFO[0m: [1mCheckpoint 69: 
-----------------------------------
Train ACCURACY: 0.3014
Train Loss: 1.9495
ID Validation ACCURACY: 0.2964
ID Validation Loss: 1.9606
ID Test ACCURACY: 0.2970
ID Test Loss: 1.9524
OOD Validation ACCURACY: 0.3054
OOD Validation Loss: 1.9541
OOD Test ACCURACY: 0.2194
OOD Test Loss: 2.1680

[0m[1;37mINFO[0m: [1mChartInfo 0.3786 0.1213 0.2970 0.2194 0.2964 0.3054[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.125
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.114
SUFF++ for r=0.3 class 0 = 0.53 +- 0.163 (in-sample avg dev_std = 0.546)
SUFF++ for r=0.3 class 1 = 0.626 +- 0.163 (in-sample avg dev_std = 0.546)
SUFF++ for r=0.3 class 2 = 0.567 +- 0.163 (in-sample avg dev_std = 0.546)
SUFF++ for r=0.3 class 3 = 0.572 +- 0.163 (in-sample avg dev_std = 0.546)
SUFF++ for r=0.3 class 4 = 0.61 +- 0.163 (in-sample avg dev_std = 0.546)
SUFF++ for r=0.3 class 5 = 0.617 +- 0.163 (in-sample avg dev_std = 0.546)
SUFF++ for r=0.3 class 6 = 0.571 +- 0.163 (in-sample avg dev_std = 0.546)
SUFF++ for r=0.3 class 7 = 0.599 +- 0.163 (in-sample avg dev_std = 0.546)
SUFF++ for r=0.3 class 8 = 0.549 +- 0.163 (in-sample avg dev_std = 0.546)
SUFF++ for r=0.3 class 9 = 0.587 +- 0.163 (in-sample avg dev_std = 0.546)
SUFF++ for r=0.3 all KL = 0.679 +- 0.163 (in-sample avg dev_std = 0.546)
SUFF++ for r=0.3 all L1 = 0.583 +- 0.112 (in-sample avg dev_std = 0.546)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.119
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.116
SUFF++ for r=0.6 class 0 = 0.813 +- 0.060 (in-sample avg dev_std = 0.100)
SUFF++ for r=0.6 class 1 = 0.774 +- 0.060 (in-sample avg dev_std = 0.100)
SUFF++ for r=0.6 class 2 = 0.793 +- 0.060 (in-sample avg dev_std = 0.100)
SUFF++ for r=0.6 class 3 = 0.807 +- 0.060 (in-sample avg dev_std = 0.100)
SUFF++ for r=0.6 class 4 = 0.801 +- 0.060 (in-sample avg dev_std = 0.100)
SUFF++ for r=0.6 class 5 = 0.81 +- 0.060 (in-sample avg dev_std = 0.100)
SUFF++ for r=0.6 class 6 = 0.807 +- 0.060 (in-sample avg dev_std = 0.100)
SUFF++ for r=0.6 class 7 = 0.8 +- 0.060 (in-sample avg dev_std = 0.100)
SUFF++ for r=0.6 class 8 = 0.79 +- 0.060 (in-sample avg dev_std = 0.100)
SUFF++ for r=0.6 class 9 = 0.769 +- 0.060 (in-sample avg dev_std = 0.100)
SUFF++ for r=0.6 all KL = 0.947 +- 0.060 (in-sample avg dev_std = 0.100)
SUFF++ for r=0.6 all L1 = 0.796 +- 0.095 (in-sample avg dev_std = 0.100)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.279
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.256
SUFF++ for r=0.9 class 0 = 0.902 +- 0.034 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.9 class 1 = 0.84 +- 0.034 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.9 class 2 = 0.897 +- 0.034 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.9 class 3 = 0.893 +- 0.034 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.9 class 4 = 0.888 +- 0.034 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.9 class 5 = 0.893 +- 0.034 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.9 class 6 = 0.873 +- 0.034 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.9 class 7 = 0.888 +- 0.034 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.9 class 8 = 0.885 +- 0.034 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.9 class 9 = 0.878 +- 0.034 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.9 all KL = 0.976 +- 0.034 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.9 all L1 = 0.883 +- 0.074 (in-sample avg dev_std = 0.106)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.104
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.115
SUFF++ for r=0.3 class 0 = 0.616 +- 0.094 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.3 class 1 = 0.608 +- 0.094 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.3 class 2 = 0.613 +- 0.094 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.3 class 3 = 0.599 +- 0.094 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.3 class 4 = 0.627 +- 0.094 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.3 class 5 = 0.622 +- 0.094 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.3 class 6 = 0.62 +- 0.094 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.3 class 7 = 0.598 +- 0.094 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.3 class 8 = 0.604 +- 0.094 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.3 class 9 = 0.619 +- 0.094 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.3 all KL = 0.751 +- 0.094 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.3 all L1 = 0.612 +- 0.072 (in-sample avg dev_std = 0.451)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.12
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.115
SUFF++ for r=0.6 class 0 = 0.834 +- 0.035 (in-sample avg dev_std = 0.066)
SUFF++ for r=0.6 class 1 = 0.791 +- 0.035 (in-sample avg dev_std = 0.066)
SUFF++ for r=0.6 class 2 = 0.814 +- 0.035 (in-sample avg dev_std = 0.066)
SUFF++ for r=0.6 class 3 = 0.812 +- 0.035 (in-sample avg dev_std = 0.066)
SUFF++ for r=0.6 class 4 = 0.824 +- 0.035 (in-sample avg dev_std = 0.066)
SUFF++ for r=0.6 class 5 = 0.82 +- 0.035 (in-sample avg dev_std = 0.066)
SUFF++ for r=0.6 class 6 = 0.816 +- 0.035 (in-sample avg dev_std = 0.066)
SUFF++ for r=0.6 class 7 = 0.822 +- 0.035 (in-sample avg dev_std = 0.066)
SUFF++ for r=0.6 class 8 = 0.823 +- 0.035 (in-sample avg dev_std = 0.066)
SUFF++ for r=0.6 class 9 = 0.817 +- 0.035 (in-sample avg dev_std = 0.066)
SUFF++ for r=0.6 all KL = 0.961 +- 0.035 (in-sample avg dev_std = 0.066)
SUFF++ for r=0.6 all L1 = 0.817 +- 0.069 (in-sample avg dev_std = 0.066)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.144
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.149
SUFF++ for r=0.9 class 0 = 0.884 +- 0.039 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.9 class 1 = 0.927 +- 0.039 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.9 class 2 = 0.876 +- 0.039 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.9 class 3 = 0.879 +- 0.039 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.9 class 4 = 0.878 +- 0.039 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.9 class 5 = 0.898 +- 0.039 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.9 class 6 = 0.871 +- 0.039 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.9 class 7 = 0.87 +- 0.039 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.9 class 8 = 0.882 +- 0.039 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.9 class 9 = 0.845 +- 0.039 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.9 all KL = 0.973 +- 0.039 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.9 all L1 = 0.881 +- 0.091 (in-sample avg dev_std = 0.124)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.106
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.122
SUFF++ for r=0.3 class 0 = 0.689 +- 0.121 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 class 1 = 0.68 +- 0.121 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 class 2 = 0.696 +- 0.121 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 class 3 = 0.674 +- 0.121 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 class 4 = 0.701 +- 0.121 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 class 5 = 0.665 +- 0.121 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 class 6 = 0.679 +- 0.121 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 class 7 = 0.684 +- 0.121 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 class 8 = 0.677 +- 0.121 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 class 9 = 0.691 +- 0.121 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 all KL = 0.815 +- 0.121 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 all L1 = 0.684 +- 0.085 (in-sample avg dev_std = 0.372)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.176
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.147
SUFF++ for r=0.6 class 0 = 0.83 +- 0.057 (in-sample avg dev_std = 0.063)
SUFF++ for r=0.6 class 1 = 0.782 +- 0.057 (in-sample avg dev_std = 0.063)
SUFF++ for r=0.6 class 2 = 0.812 +- 0.057 (in-sample avg dev_std = 0.063)
SUFF++ for r=0.6 class 3 = 0.833 +- 0.057 (in-sample avg dev_std = 0.063)
SUFF++ for r=0.6 class 4 = 0.822 +- 0.057 (in-sample avg dev_std = 0.063)
SUFF++ for r=0.6 class 5 = 0.814 +- 0.057 (in-sample avg dev_std = 0.063)
SUFF++ for r=0.6 class 6 = 0.811 +- 0.057 (in-sample avg dev_std = 0.063)
SUFF++ for r=0.6 class 7 = 0.806 +- 0.057 (in-sample avg dev_std = 0.063)
SUFF++ for r=0.6 class 8 = 0.801 +- 0.057 (in-sample avg dev_std = 0.063)
SUFF++ for r=0.6 class 9 = 0.805 +- 0.057 (in-sample avg dev_std = 0.063)
SUFF++ for r=0.6 all KL = 0.953 +- 0.057 (in-sample avg dev_std = 0.063)
SUFF++ for r=0.6 all L1 = 0.811 +- 0.089 (in-sample avg dev_std = 0.063)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.134
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.147
SUFF++ for r=0.9 class 0 = 0.838 +- 0.055 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.9 class 1 = 0.926 +- 0.055 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.9 class 2 = 0.87 +- 0.055 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.9 class 3 = 0.864 +- 0.055 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.9 class 4 = 0.848 +- 0.055 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.9 class 5 = 0.829 +- 0.055 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.9 class 6 = 0.865 +- 0.055 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.9 class 7 = 0.863 +- 0.055 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.9 class 8 = 0.855 +- 0.055 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.9 class 9 = 0.849 +- 0.055 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.9 all KL = 0.958 +- 0.055 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.9 all L1 = 0.862 +- 0.102 (in-sample avg dev_std = 0.139)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.125
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.12
NEC for r=0.3 class 0 = 0.126 +- 0.023 (in-sample avg dev_std = 0.064)
NEC for r=0.3 class 1 = 0.145 +- 0.023 (in-sample avg dev_std = 0.064)
NEC for r=0.3 class 2 = 0.134 +- 0.023 (in-sample avg dev_std = 0.064)
NEC for r=0.3 class 3 = 0.127 +- 0.023 (in-sample avg dev_std = 0.064)
NEC for r=0.3 class 4 = 0.122 +- 0.023 (in-sample avg dev_std = 0.064)
NEC for r=0.3 class 5 = 0.131 +- 0.023 (in-sample avg dev_std = 0.064)
NEC for r=0.3 class 6 = 0.13 +- 0.023 (in-sample avg dev_std = 0.064)
NEC for r=0.3 class 7 = 0.121 +- 0.023 (in-sample avg dev_std = 0.064)
NEC for r=0.3 class 8 = 0.118 +- 0.023 (in-sample avg dev_std = 0.064)
NEC for r=0.3 class 9 = 0.125 +- 0.023 (in-sample avg dev_std = 0.064)
NEC for r=0.3 all KL = 0.02 +- 0.023 (in-sample avg dev_std = 0.064)
NEC for r=0.3 all L1 = 0.128 +- 0.051 (in-sample avg dev_std = 0.064)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.119
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.118
NEC for r=0.6 class 0 = 0.125 +- 0.024 (in-sample avg dev_std = 0.093)
NEC for r=0.6 class 1 = 0.155 +- 0.024 (in-sample avg dev_std = 0.093)
NEC for r=0.6 class 2 = 0.145 +- 0.024 (in-sample avg dev_std = 0.093)
NEC for r=0.6 class 3 = 0.152 +- 0.024 (in-sample avg dev_std = 0.093)
NEC for r=0.6 class 4 = 0.134 +- 0.024 (in-sample avg dev_std = 0.093)
NEC for r=0.6 class 5 = 0.138 +- 0.024 (in-sample avg dev_std = 0.093)
NEC for r=0.6 class 6 = 0.137 +- 0.024 (in-sample avg dev_std = 0.093)
NEC for r=0.6 class 7 = 0.144 +- 0.024 (in-sample avg dev_std = 0.093)
NEC for r=0.6 class 8 = 0.144 +- 0.024 (in-sample avg dev_std = 0.093)
NEC for r=0.6 class 9 = 0.153 +- 0.024 (in-sample avg dev_std = 0.093)
NEC for r=0.6 all KL = 0.025 +- 0.024 (in-sample avg dev_std = 0.093)
NEC for r=0.6 all L1 = 0.143 +- 0.058 (in-sample avg dev_std = 0.093)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.279
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.226
NEC for r=0.9 class 0 = 0.2 +- 0.050 (in-sample avg dev_std = 0.126)
NEC for r=0.9 class 1 = 0.297 +- 0.050 (in-sample avg dev_std = 0.126)
NEC for r=0.9 class 2 = 0.227 +- 0.050 (in-sample avg dev_std = 0.126)
NEC for r=0.9 class 3 = 0.228 +- 0.050 (in-sample avg dev_std = 0.126)
NEC for r=0.9 class 4 = 0.236 +- 0.050 (in-sample avg dev_std = 0.126)
NEC for r=0.9 class 5 = 0.231 +- 0.050 (in-sample avg dev_std = 0.126)
NEC for r=0.9 class 6 = 0.251 +- 0.050 (in-sample avg dev_std = 0.126)
NEC for r=0.9 class 7 = 0.224 +- 0.050 (in-sample avg dev_std = 0.126)
NEC for r=0.9 class 8 = 0.227 +- 0.050 (in-sample avg dev_std = 0.126)
NEC for r=0.9 class 9 = 0.245 +- 0.050 (in-sample avg dev_std = 0.126)
NEC for r=0.9 all KL = 0.071 +- 0.050 (in-sample avg dev_std = 0.126)
NEC for r=0.9 all L1 = 0.237 +- 0.076 (in-sample avg dev_std = 0.126)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.37
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.311
NEC for r=1.0 class 0 = 0.214 +- 0.063 (in-sample avg dev_std = 0.131)
NEC for r=1.0 class 1 = 0.307 +- 0.063 (in-sample avg dev_std = 0.131)
NEC for r=1.0 class 2 = 0.248 +- 0.063 (in-sample avg dev_std = 0.131)
NEC for r=1.0 class 3 = 0.249 +- 0.063 (in-sample avg dev_std = 0.131)
NEC for r=1.0 class 4 = 0.286 +- 0.063 (in-sample avg dev_std = 0.131)
NEC for r=1.0 class 5 = 0.246 +- 0.063 (in-sample avg dev_std = 0.131)
NEC for r=1.0 class 6 = 0.264 +- 0.063 (in-sample avg dev_std = 0.131)
NEC for r=1.0 class 7 = 0.281 +- 0.063 (in-sample avg dev_std = 0.131)
NEC for r=1.0 class 8 = 0.261 +- 0.063 (in-sample avg dev_std = 0.131)
NEC for r=1.0 class 9 = 0.267 +- 0.063 (in-sample avg dev_std = 0.131)
NEC for r=1.0 all KL = 0.088 +- 0.063 (in-sample avg dev_std = 0.131)
NEC for r=1.0 all L1 = 0.263 +- 0.087 (in-sample avg dev_std = 0.131)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.104
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.11
NEC for r=0.3 class 0 = 0.13 +- 0.014 (in-sample avg dev_std = 0.066)
NEC for r=0.3 class 1 = 0.129 +- 0.014 (in-sample avg dev_std = 0.066)
NEC for r=0.3 class 2 = 0.135 +- 0.014 (in-sample avg dev_std = 0.066)
NEC for r=0.3 class 3 = 0.134 +- 0.014 (in-sample avg dev_std = 0.066)
NEC for r=0.3 class 4 = 0.129 +- 0.014 (in-sample avg dev_std = 0.066)
NEC for r=0.3 class 5 = 0.134 +- 0.014 (in-sample avg dev_std = 0.066)
NEC for r=0.3 class 6 = 0.128 +- 0.014 (in-sample avg dev_std = 0.066)
NEC for r=0.3 class 7 = 0.124 +- 0.014 (in-sample avg dev_std = 0.066)
NEC for r=0.3 class 8 = 0.129 +- 0.014 (in-sample avg dev_std = 0.066)
NEC for r=0.3 class 9 = 0.132 +- 0.014 (in-sample avg dev_std = 0.066)
NEC for r=0.3 all KL = 0.019 +- 0.014 (in-sample avg dev_std = 0.066)
NEC for r=0.3 all L1 = 0.13 +- 0.043 (in-sample avg dev_std = 0.066)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.12
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.117
NEC for r=0.6 class 0 = 0.13 +- 0.014 (in-sample avg dev_std = 0.073)
NEC for r=0.6 class 1 = 0.138 +- 0.014 (in-sample avg dev_std = 0.073)
NEC for r=0.6 class 2 = 0.135 +- 0.014 (in-sample avg dev_std = 0.073)
NEC for r=0.6 class 3 = 0.132 +- 0.014 (in-sample avg dev_std = 0.073)
NEC for r=0.6 class 4 = 0.129 +- 0.014 (in-sample avg dev_std = 0.073)
NEC for r=0.6 class 5 = 0.122 +- 0.014 (in-sample avg dev_std = 0.073)
NEC for r=0.6 class 6 = 0.138 +- 0.014 (in-sample avg dev_std = 0.073)
NEC for r=0.6 class 7 = 0.129 +- 0.014 (in-sample avg dev_std = 0.073)
NEC for r=0.6 class 8 = 0.122 +- 0.014 (in-sample avg dev_std = 0.073)
NEC for r=0.6 class 9 = 0.132 +- 0.014 (in-sample avg dev_std = 0.073)
NEC for r=0.6 all KL = 0.02 +- 0.014 (in-sample avg dev_std = 0.073)
NEC for r=0.6 all L1 = 0.131 +- 0.041 (in-sample avg dev_std = 0.073)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.144
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.163
NEC for r=0.9 class 0 = 0.212 +- 0.069 (in-sample avg dev_std = 0.132)
NEC for r=0.9 class 1 = 0.146 +- 0.069 (in-sample avg dev_std = 0.132)
NEC for r=0.9 class 2 = 0.242 +- 0.069 (in-sample avg dev_std = 0.132)
NEC for r=0.9 class 3 = 0.236 +- 0.069 (in-sample avg dev_std = 0.132)
NEC for r=0.9 class 4 = 0.241 +- 0.069 (in-sample avg dev_std = 0.132)
NEC for r=0.9 class 5 = 0.223 +- 0.069 (in-sample avg dev_std = 0.132)
NEC for r=0.9 class 6 = 0.249 +- 0.069 (in-sample avg dev_std = 0.132)
NEC for r=0.9 class 7 = 0.264 +- 0.069 (in-sample avg dev_std = 0.132)
NEC for r=0.9 class 8 = 0.241 +- 0.069 (in-sample avg dev_std = 0.132)
NEC for r=0.9 class 9 = 0.263 +- 0.069 (in-sample avg dev_std = 0.132)
NEC for r=0.9 all KL = 0.072 +- 0.069 (in-sample avg dev_std = 0.132)
NEC for r=0.9 all L1 = 0.231 +- 0.121 (in-sample avg dev_std = 0.132)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.129
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.144
NEC for r=1.0 class 0 = 0.265 +- 0.099 (in-sample avg dev_std = 0.156)
NEC for r=1.0 class 1 = 0.09 +- 0.099 (in-sample avg dev_std = 0.156)
NEC for r=1.0 class 2 = 0.275 +- 0.099 (in-sample avg dev_std = 0.156)
NEC for r=1.0 class 3 = 0.282 +- 0.099 (in-sample avg dev_std = 0.156)
NEC for r=1.0 class 4 = 0.25 +- 0.099 (in-sample avg dev_std = 0.156)
NEC for r=1.0 class 5 = 0.261 +- 0.099 (in-sample avg dev_std = 0.156)
NEC for r=1.0 class 6 = 0.242 +- 0.099 (in-sample avg dev_std = 0.156)
NEC for r=1.0 class 7 = 0.217 +- 0.099 (in-sample avg dev_std = 0.156)
NEC for r=1.0 class 8 = 0.289 +- 0.099 (in-sample avg dev_std = 0.156)
NEC for r=1.0 class 9 = 0.237 +- 0.099 (in-sample avg dev_std = 0.156)
NEC for r=1.0 all KL = 0.095 +- 0.099 (in-sample avg dev_std = 0.156)
NEC for r=1.0 all L1 = 0.238 +- 0.152 (in-sample avg dev_std = 0.156)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.106
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.106
NEC for r=0.3 class 0 = 0.096 +- 0.011 (in-sample avg dev_std = 0.052)
NEC for r=0.3 class 1 = 0.115 +- 0.011 (in-sample avg dev_std = 0.052)
NEC for r=0.3 class 2 = 0.102 +- 0.011 (in-sample avg dev_std = 0.052)
NEC for r=0.3 class 3 = 0.101 +- 0.011 (in-sample avg dev_std = 0.052)
NEC for r=0.3 class 4 = 0.108 +- 0.011 (in-sample avg dev_std = 0.052)
NEC for r=0.3 class 5 = 0.098 +- 0.011 (in-sample avg dev_std = 0.052)
NEC for r=0.3 class 6 = 0.108 +- 0.011 (in-sample avg dev_std = 0.052)
NEC for r=0.3 class 7 = 0.1 +- 0.011 (in-sample avg dev_std = 0.052)
NEC for r=0.3 class 8 = 0.11 +- 0.011 (in-sample avg dev_std = 0.052)
NEC for r=0.3 class 9 = 0.102 +- 0.011 (in-sample avg dev_std = 0.052)
NEC for r=0.3 all KL = 0.013 +- 0.011 (in-sample avg dev_std = 0.052)
NEC for r=0.3 all L1 = 0.104 +- 0.039 (in-sample avg dev_std = 0.052)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.176
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.155
NEC for r=0.6 class 0 = 0.149 +- 0.026 (in-sample avg dev_std = 0.082)
NEC for r=0.6 class 1 = 0.183 +- 0.026 (in-sample avg dev_std = 0.082)
NEC for r=0.6 class 2 = 0.151 +- 0.026 (in-sample avg dev_std = 0.082)
NEC for r=0.6 class 3 = 0.141 +- 0.026 (in-sample avg dev_std = 0.082)
NEC for r=0.6 class 4 = 0.149 +- 0.026 (in-sample avg dev_std = 0.082)
NEC for r=0.6 class 5 = 0.148 +- 0.026 (in-sample avg dev_std = 0.082)
NEC for r=0.6 class 6 = 0.154 +- 0.026 (in-sample avg dev_std = 0.082)
NEC for r=0.6 class 7 = 0.149 +- 0.026 (in-sample avg dev_std = 0.082)
NEC for r=0.6 class 8 = 0.153 +- 0.026 (in-sample avg dev_std = 0.082)
NEC for r=0.6 class 9 = 0.159 +- 0.026 (in-sample avg dev_std = 0.082)
NEC for r=0.6 all KL = 0.03 +- 0.026 (in-sample avg dev_std = 0.082)
NEC for r=0.6 all L1 = 0.154 +- 0.051 (in-sample avg dev_std = 0.082)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.134
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.172
NEC for r=0.9 class 0 = 0.322 +- 0.097 (in-sample avg dev_std = 0.157)
NEC for r=0.9 class 1 = 0.157 +- 0.097 (in-sample avg dev_std = 0.157)
NEC for r=0.9 class 2 = 0.306 +- 0.097 (in-sample avg dev_std = 0.157)
NEC for r=0.9 class 3 = 0.315 +- 0.097 (in-sample avg dev_std = 0.157)
NEC for r=0.9 class 4 = 0.309 +- 0.097 (in-sample avg dev_std = 0.157)
NEC for r=0.9 class 5 = 0.306 +- 0.097 (in-sample avg dev_std = 0.157)
NEC for r=0.9 class 6 = 0.31 +- 0.097 (in-sample avg dev_std = 0.157)
NEC for r=0.9 class 7 = 0.328 +- 0.097 (in-sample avg dev_std = 0.157)
NEC for r=0.9 class 8 = 0.32 +- 0.097 (in-sample avg dev_std = 0.157)
NEC for r=0.9 class 9 = 0.303 +- 0.097 (in-sample avg dev_std = 0.157)
NEC for r=0.9 all KL = 0.135 +- 0.097 (in-sample avg dev_std = 0.157)
NEC for r=0.9 all L1 = 0.296 +- 0.136 (in-sample avg dev_std = 0.157)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.119
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.132
NEC for r=1.0 class 0 = 0.351 +- 0.127 (in-sample avg dev_std = 0.162)
NEC for r=1.0 class 1 = 0.072 +- 0.127 (in-sample avg dev_std = 0.162)
NEC for r=1.0 class 2 = 0.319 +- 0.127 (in-sample avg dev_std = 0.162)
NEC for r=1.0 class 3 = 0.294 +- 0.127 (in-sample avg dev_std = 0.162)
NEC for r=1.0 class 4 = 0.238 +- 0.127 (in-sample avg dev_std = 0.162)
NEC for r=1.0 class 5 = 0.318 +- 0.127 (in-sample avg dev_std = 0.162)
NEC for r=1.0 class 6 = 0.287 +- 0.127 (in-sample avg dev_std = 0.162)
NEC for r=1.0 class 7 = 0.247 +- 0.127 (in-sample avg dev_std = 0.162)
NEC for r=1.0 class 8 = 0.29 +- 0.127 (in-sample avg dev_std = 0.162)
NEC for r=1.0 class 9 = 0.236 +- 0.127 (in-sample avg dev_std = 0.162)
NEC for r=1.0 all KL = 0.15 +- 0.127 (in-sample avg dev_std = 0.162)
NEC for r=1.0 all L1 = 0.263 +- 0.173 (in-sample avg dev_std = 0.162)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.727, 0.941, 0.971, 1.0], 'all_L1': [0.61, 0.788, 0.878, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.74, 0.953, 0.965, 1.0], 'all_L1': [0.622, 0.808, 0.864, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.716, 0.94, 0.964, 1.0], 'all_L1': [0.598, 0.787, 0.866, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.774, 0.952, 0.975, 1.0], 'all_L1': [0.654, 0.809, 0.883, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.679, 0.947, 0.976, 1.0], 'all_L1': [0.583, 0.796, 0.883, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.017, 0.041, 0.094, 0.118], 'all_L1': [0.118, 0.173, 0.263, 0.286]}), defaultdict(<class 'list'>, {'all_KL': [0.015, 0.033, 0.091, 0.113], 'all_L1': [0.112, 0.155, 0.261, 0.286]}), defaultdict(<class 'list'>, {'all_KL': [0.018, 0.038, 0.114, 0.133], 'all_L1': [0.122, 0.169, 0.281, 0.294]}), defaultdict(<class 'list'>, {'all_KL': [0.014, 0.031, 0.077, 0.098], 'all_L1': [0.107, 0.153, 0.245, 0.269]}), defaultdict(<class 'list'>, {'all_KL': [0.02, 0.025, 0.071, 0.088], 'all_L1': [0.128, 0.143, 0.237, 0.263]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.771, 0.95, 0.962, 1.0], 'all_L1': [0.636, 0.798, 0.872, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.746, 0.955, 0.976, 1.0], 'all_L1': [0.62, 0.81, 0.883, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.664, 0.91, 0.956, 1.0], 'all_L1': [0.566, 0.752, 0.916, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.708, 0.95, 0.957, 1.0], 'all_L1': [0.594, 0.797, 0.88, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.751, 0.961, 0.973, 1.0], 'all_L1': [0.612, 0.817, 0.881, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.016, 0.034, 0.124, 0.204], 'all_L1': [0.119, 0.166, 0.275, 0.312]}), defaultdict(<class 'list'>, {'all_KL': [0.013, 0.026, 0.074, 0.101], 'all_L1': [0.107, 0.146, 0.251, 0.287]}), defaultdict(<class 'list'>, {'all_KL': [0.02, 0.063, 0.169, 0.14], 'all_L1': [0.129, 0.205, 0.212, 0.142]}), defaultdict(<class 'list'>, {'all_KL': [0.014, 0.029, 0.161, 0.171], 'all_L1': [0.113, 0.156, 0.295, 0.245]}), defaultdict(<class 'list'>, {'all_KL': [0.019, 0.02, 0.072, 0.095], 'all_L1': [0.13, 0.131, 0.231, 0.238]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.767, 0.959, 0.963, 1.0], 'all_L1': [0.629, 0.814, 0.869, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.842, 0.97, 0.976, 1.0], 'all_L1': [0.698, 0.843, 0.885, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.788, 0.71, 0.636, 1.0], 'all_L1': [0.643, 0.625, 0.668, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.845, 0.957, 0.946, 1.0], 'all_L1': [0.705, 0.813, 0.855, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.815, 0.953, 0.958, 1.0], 'all_L1': [0.684, 0.811, 0.862, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.014, 0.023, 0.121, 0.195], 'all_L1': [0.108, 0.141, 0.28, 0.305]}), defaultdict(<class 'list'>, {'all_KL': [0.008, 0.022, 0.065, 0.085], 'all_L1': [0.083, 0.133, 0.228, 0.263]}), defaultdict(<class 'list'>, {'all_KL': [0.101, 0.313, 0.46, 0.484], 'all_L1': [0.239, 0.384, 0.471, 0.481]}), defaultdict(<class 'list'>, {'all_KL': [0.013, 0.027, 0.155, 0.222], 'all_L1': [0.104, 0.148, 0.297, 0.281]}), defaultdict(<class 'list'>, {'all_KL': [0.013, 0.03, 0.135, 0.15], 'all_L1': [0.104, 0.154, 0.296, 0.263]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.613 +- 0.024, 0.798 +- 0.009, 0.875 +- 0.008, 1.000 +- 0.000
suff++ class all_KL  =  0.727 +- 0.031, 0.947 +- 0.005, 0.970 +- 0.005, 1.000 +- 0.000
suff++_acc_int  =  0.118 +- 0.008, 0.127 +- 0.009, 0.283 +- 0.022
nec class all_L1  =  0.117 +- 0.007, 0.159 +- 0.011, 0.257 +- 0.015, 0.280 +- 0.012
nec class all_KL  =  0.017 +- 0.002, 0.034 +- 0.006, 0.089 +- 0.015, 0.110 +- 0.016
nec_acc_int  =  0.115 +- 0.005, 0.127 +- 0.005, 0.252 +- 0.021, 0.328 +- 0.018

Eval split val
suff++ class all_L1  =  0.606 +- 0.024, 0.795 +- 0.023, 0.886 +- 0.015, 1.000 +- 0.000
suff++ class all_KL  =  0.728 +- 0.038, 0.945 +- 0.018, 0.965 +- 0.008, 1.000 +- 0.000
suff++_acc_int  =  0.117 +- 0.003, 0.133 +- 0.011, 0.169 +- 0.038
nec class all_L1  =  0.120 +- 0.009, 0.161 +- 0.025, 0.253 +- 0.030, 0.245 +- 0.058
nec class all_KL  =  0.016 +- 0.003, 0.034 +- 0.015, 0.120 +- 0.041, 0.142 +- 0.041
nec_acc_int  =  0.107 +- 0.005, 0.132 +- 0.009, 0.177 +- 0.034, 0.166 +- 0.042

Eval split test
suff++ class all_L1  =  0.672 +- 0.030, 0.781 +- 0.079, 0.828 +- 0.081, 1.000 +- 0.000
suff++ class all_KL  =  0.811 +- 0.030, 0.910 +- 0.100, 0.896 +- 0.130, 1.000 +- 0.000
suff++_acc_int  =  0.133 +- 0.018, 0.146 +- 0.026, 0.163 +- 0.013
nec class all_L1  =  0.128 +- 0.056, 0.192 +- 0.096, 0.314 +- 0.082, 0.319 +- 0.083
nec class all_KL  =  0.030 +- 0.036, 0.083 +- 0.115, 0.187 +- 0.140, 0.227 +- 0.137
nec_acc_int  =  0.118 +- 0.010, 0.151 +- 0.020, 0.179 +- 0.009, 0.153 +- 0.018


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.365 +- 0.008, 0.478 +- 0.004, 0.566 +- 0.005, 0.640 +- 0.006
Faith. Armon (L1)= 		  =  0.197 +- 0.009, 0.264 +- 0.015, 0.397 +- 0.018, 0.437 +- 0.014
Faith. GMean (L1)= 	  =  0.268 +- 0.003, 0.355 +- 0.011, 0.474 +- 0.012, 0.529 +- 0.011
Faith. Aritm (KL)= 		  =  0.372 +- 0.014, 0.490 +- 0.002, 0.530 +- 0.005, 0.555 +- 0.008
Faith. Armon (KL)= 		  =  0.033 +- 0.004, 0.065 +- 0.010, 0.163 +- 0.025, 0.198 +- 0.025
Faith. GMean (KL)= 	  =  0.110 +- 0.005, 0.178 +- 0.015, 0.293 +- 0.024, 0.331 +- 0.024

Eval split val
Faith. Aritm (L1)= 		  =  0.363 +- 0.011, 0.478 +- 0.003, 0.570 +- 0.011, 0.622 +- 0.029
Faith. Armon (L1)= 		  =  0.199 +- 0.012, 0.266 +- 0.032, 0.392 +- 0.035, 0.390 +- 0.078
Faith. GMean (L1)= 	  =  0.269 +- 0.009, 0.356 +- 0.022, 0.472 +- 0.025, 0.491 +- 0.063
Faith. Aritm (KL)= 		  =  0.372 +- 0.018, 0.490 +- 0.002, 0.542 +- 0.017, 0.571 +- 0.021
Faith. Armon (KL)= 		  =  0.032 +- 0.005, 0.066 +- 0.027, 0.211 +- 0.065, 0.247 +- 0.063
Faith. GMean (KL)= 	  =  0.109 +- 0.008, 0.176 +- 0.034, 0.335 +- 0.059, 0.373 +- 0.055

Eval split test
Faith. Aritm (L1)= 		  =  0.400 +- 0.024, 0.487 +- 0.010, 0.571 +- 0.008, 0.659 +- 0.041
Faith. Armon (L1)= 		  =  0.209 +- 0.071, 0.291 +- 0.093, 0.444 +- 0.061, 0.478 +- 0.088
Faith. GMean (L1)= 	  =  0.286 +- 0.054, 0.373 +- 0.059, 0.502 +- 0.036, 0.560 +- 0.068
Faith. Aritm (KL)= 		  =  0.421 +- 0.018, 0.496 +- 0.008, 0.541 +- 0.011, 0.614 +- 0.068
Faith. Armon (KL)= 		  =  0.055 +- 0.062, 0.127 +- 0.154, 0.275 +- 0.138, 0.352 +- 0.166
Faith. GMean (KL)= 	  =  0.135 +- 0.074, 0.219 +- 0.126, 0.375 +- 0.094, 0.457 +- 0.134
Computed for split load_split = id



Completed in  1:33:55.915776  for LECIvGIN GOODCMNIST/color



DONE LECI GOODCMNIST/color

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 14:30:10 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 04/22/2024 02:30:11 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/22/2024 02:30:43 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/22/2024 02:30:54 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:04 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:21 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:36 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:36 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:36 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:31:37 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 167...
[0m[1;37mINFO[0m: [1mCheckpoint 167: 
-----------------------------------
Train ROC-AUC: 0.9091
Train Loss: 0.2352
ID Validation ROC-AUC: 0.8920
ID Validation Loss: 0.2570
ID Test ROC-AUC: 0.8910
ID Test Loss: 0.2625
OOD Validation ROC-AUC: 0.6727
OOD Validation Loss: 0.3773
OOD Test ROC-AUC: 0.7128
OOD Test Loss: 0.5339

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 121...
[0m[1;37mINFO[0m: [1mCheckpoint 121: 
-----------------------------------
Train ROC-AUC: 0.8897
Train Loss: 0.2516
ID Validation ROC-AUC: 0.8802
ID Validation Loss: 0.2620
ID Test ROC-AUC: 0.8798
ID Test Loss: 0.2669
OOD Validation ROC-AUC: 0.7041
OOD Validation Loss: 0.3079
OOD Test ROC-AUC: 0.7269
OOD Test Loss: 0.4742

[0m[1;37mINFO[0m: [1mChartInfo 0.8910 0.7128 0.8798 0.7269 0.8802 0.7041[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 04/22/2024 02:31:38 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 04/22/2024 02:31:43 PM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 04/22/2024 02:31:47 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.699
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.59
SUFF++ for r=0.3 class 0.0 = 0.842 +- 0.076 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.3 class 1.0 = 0.795 +- 0.076 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.3 all KL = 0.942 +- 0.076 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.3 all L1 = 0.801 +- 0.098 (in-sample avg dev_std = 0.176)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.818
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.756
SUFF++ for r=0.6 class 0.0 = 0.807 +- 0.090 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.6 class 1.0 = 0.79 +- 0.090 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.6 all KL = 0.907 +- 0.090 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.6 all L1 = 0.792 +- 0.095 (in-sample avg dev_std = 0.213)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.851
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.823
SUFF++ for r=0.9 class 0.0 = 0.858 +- 0.104 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.9 class 1.0 = 0.867 +- 0.104 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.9 all KL = 0.928 +- 0.104 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.9 all L1 = 0.866 +- 0.111 (in-sample avg dev_std = 0.160)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.567
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.551
SUFF++ for r=0.3 class 0.0 = 0.847 +- 0.063 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.3 class 1.0 = 0.821 +- 0.063 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.3 all KL = 0.956 +- 0.063 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.3 all L1 = 0.823 +- 0.088 (in-sample avg dev_std = 0.164)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.653
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.608
SUFF++ for r=0.6 class 0.0 = 0.804 +- 0.093 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.6 class 1.0 = 0.78 +- 0.093 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.6 all KL = 0.915 +- 0.093 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.6 all L1 = 0.782 +- 0.097 (in-sample avg dev_std = 0.214)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.674
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.635
SUFF++ for r=0.9 class 0.0 = 0.834 +- 0.099 (in-sample avg dev_std = 0.178)
SUFF++ for r=0.9 class 1.0 = 0.828 +- 0.099 (in-sample avg dev_std = 0.178)
SUFF++ for r=0.9 all KL = 0.925 +- 0.099 (in-sample avg dev_std = 0.178)
SUFF++ for r=0.9 all L1 = 0.829 +- 0.113 (in-sample avg dev_std = 0.178)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.596
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.52
SUFF++ for r=0.3 class 0.0 = 0.845 +- 0.071 (in-sample avg dev_std = 0.167)
SUFF++ for r=0.3 class 1.0 = 0.818 +- 0.071 (in-sample avg dev_std = 0.167)
SUFF++ for r=0.3 all KL = 0.952 +- 0.071 (in-sample avg dev_std = 0.167)
SUFF++ for r=0.3 all L1 = 0.823 +- 0.095 (in-sample avg dev_std = 0.167)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.717
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.641
SUFF++ for r=0.6 class 0.0 = 0.812 +- 0.089 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.6 class 1.0 = 0.787 +- 0.089 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.6 all KL = 0.918 +- 0.089 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.6 all L1 = 0.791 +- 0.093 (in-sample avg dev_std = 0.210)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.734
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.691
SUFF++ for r=0.9 class 0.0 = 0.841 +- 0.093 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.9 class 1.0 = 0.85 +- 0.093 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.9 all KL = 0.935 +- 0.093 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.9 all L1 = 0.848 +- 0.109 (in-sample avg dev_std = 0.164)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.699
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.659
NEC for r=0.3 class 0.0 = 0.125 +- 0.070 (in-sample avg dev_std = 0.124)
NEC for r=0.3 class 1.0 = 0.169 +- 0.070 (in-sample avg dev_std = 0.124)
NEC for r=0.3 all KL = 0.04 +- 0.070 (in-sample avg dev_std = 0.124)
NEC for r=0.3 all L1 = 0.164 +- 0.103 (in-sample avg dev_std = 0.124)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.818
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.768
NEC for r=0.6 class 0.0 = 0.161 +- 0.099 (in-sample avg dev_std = 0.161)
NEC for r=0.6 class 1.0 = 0.188 +- 0.099 (in-sample avg dev_std = 0.161)
NEC for r=0.6 all KL = 0.077 +- 0.099 (in-sample avg dev_std = 0.161)
NEC for r=0.6 all L1 = 0.185 +- 0.109 (in-sample avg dev_std = 0.161)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.851
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.815
NEC for r=0.9 class 0.0 = 0.153 +- 0.115 (in-sample avg dev_std = 0.162)
NEC for r=0.9 class 1.0 = 0.148 +- 0.115 (in-sample avg dev_std = 0.162)
NEC for r=0.9 all KL = 0.086 +- 0.115 (in-sample avg dev_std = 0.162)
NEC for r=0.9 all L1 = 0.149 +- 0.114 (in-sample avg dev_std = 0.162)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.858
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.826
NEC for r=1.0 class 0.0 = 0.158 +- 0.105 (in-sample avg dev_std = 0.153)
NEC for r=1.0 class 1.0 = 0.134 +- 0.105 (in-sample avg dev_std = 0.153)
NEC for r=1.0 all KL = 0.08 +- 0.105 (in-sample avg dev_std = 0.153)
NEC for r=1.0 all L1 = 0.136 +- 0.110 (in-sample avg dev_std = 0.153)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.567
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.568
NEC for r=0.3 class 0.0 = 0.139 +- 0.057 (in-sample avg dev_std = 0.106)
NEC for r=0.3 class 1.0 = 0.142 +- 0.057 (in-sample avg dev_std = 0.106)
NEC for r=0.3 all KL = 0.029 +- 0.057 (in-sample avg dev_std = 0.106)
NEC for r=0.3 all L1 = 0.142 +- 0.091 (in-sample avg dev_std = 0.106)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.653
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.606
NEC for r=0.6 class 0.0 = 0.161 +- 0.096 (in-sample avg dev_std = 0.151)
NEC for r=0.6 class 1.0 = 0.178 +- 0.096 (in-sample avg dev_std = 0.151)
NEC for r=0.6 all KL = 0.062 +- 0.096 (in-sample avg dev_std = 0.151)
NEC for r=0.6 all L1 = 0.177 +- 0.108 (in-sample avg dev_std = 0.151)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.674
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.633
NEC for r=0.9 class 0.0 = 0.158 +- 0.108 (in-sample avg dev_std = 0.169)
NEC for r=0.9 class 1.0 = 0.177 +- 0.108 (in-sample avg dev_std = 0.169)
NEC for r=0.9 all KL = 0.084 +- 0.108 (in-sample avg dev_std = 0.169)
NEC for r=0.9 all L1 = 0.176 +- 0.114 (in-sample avg dev_std = 0.169)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.664
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.628
NEC for r=1.0 class 0.0 = 0.148 +- 0.110 (in-sample avg dev_std = 0.167)
NEC for r=1.0 class 1.0 = 0.17 +- 0.110 (in-sample avg dev_std = 0.167)
NEC for r=1.0 all KL = 0.083 +- 0.110 (in-sample avg dev_std = 0.167)
NEC for r=1.0 all L1 = 0.168 +- 0.114 (in-sample avg dev_std = 0.167)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.596
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.586
NEC for r=0.3 class 0.0 = 0.128 +- 0.055 (in-sample avg dev_std = 0.117)
NEC for r=0.3 class 1.0 = 0.149 +- 0.055 (in-sample avg dev_std = 0.117)
NEC for r=0.3 all KL = 0.032 +- 0.055 (in-sample avg dev_std = 0.117)
NEC for r=0.3 all L1 = 0.146 +- 0.095 (in-sample avg dev_std = 0.117)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.717
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.662
NEC for r=0.6 class 0.0 = 0.152 +- 0.091 (in-sample avg dev_std = 0.147)
NEC for r=0.6 class 1.0 = 0.175 +- 0.091 (in-sample avg dev_std = 0.147)
NEC for r=0.6 all KL = 0.06 +- 0.091 (in-sample avg dev_std = 0.147)
NEC for r=0.6 all L1 = 0.171 +- 0.109 (in-sample avg dev_std = 0.147)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.734
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.69
NEC for r=0.9 class 0.0 = 0.155 +- 0.107 (in-sample avg dev_std = 0.162)
NEC for r=0.9 class 1.0 = 0.165 +- 0.107 (in-sample avg dev_std = 0.162)
NEC for r=0.9 all KL = 0.075 +- 0.107 (in-sample avg dev_std = 0.162)
NEC for r=0.9 all L1 = 0.163 +- 0.112 (in-sample avg dev_std = 0.162)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.728
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.694
NEC for r=1.0 class 0.0 = 0.156 +- 0.105 (in-sample avg dev_std = 0.164)
NEC for r=1.0 class 1.0 = 0.155 +- 0.105 (in-sample avg dev_std = 0.164)
NEC for r=1.0 all KL = 0.075 +- 0.105 (in-sample avg dev_std = 0.164)
NEC for r=1.0 all L1 = 0.155 +- 0.110 (in-sample avg dev_std = 0.164)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 14:36:07 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 04/22/2024 02:36:08 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/22/2024 02:36:39 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/22/2024 02:36:49 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:00 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:16 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 141...
[0m[1;37mINFO[0m: [1mCheckpoint 141: 
-----------------------------------
Train ROC-AUC: 0.8974
Train Loss: 0.2422
ID Validation ROC-AUC: 0.8865
ID Validation Loss: 0.2546
ID Test ROC-AUC: 0.8878
ID Test Loss: 0.2573
OOD Validation ROC-AUC: 0.6676
OOD Validation Loss: 0.3702
OOD Test ROC-AUC: 0.7155
OOD Test Loss: 0.4981

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 26...
[0m[1;37mINFO[0m: [1mCheckpoint 26: 
-----------------------------------
Train ROC-AUC: 0.8491
Train Loss: 0.2843
ID Validation ROC-AUC: 0.8430
ID Validation Loss: 0.2893
ID Test ROC-AUC: 0.8441
ID Test Loss: 0.2919
OOD Validation ROC-AUC: 0.6893
OOD Validation Loss: 0.2873
OOD Test ROC-AUC: 0.7023
OOD Test Loss: 0.4629

[0m[1;37mINFO[0m: [1mChartInfo 0.8878 0.7155 0.8441 0.7023 0.8430 0.6893[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 04/22/2024 02:37:32 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 04/22/2024 02:37:36 PM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 04/22/2024 02:37:41 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.812
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.725
SUFF++ for r=0.3 class 0.0 = 0.774 +- 0.053 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.3 class 1.0 = 0.826 +- 0.053 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.3 all KL = 0.945 +- 0.053 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.3 all L1 = 0.82 +- 0.085 (in-sample avg dev_std = 0.183)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.856
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.801
SUFF++ for r=0.6 class 0.0 = 0.785 +- 0.045 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.6 class 1.0 = 0.877 +- 0.045 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.6 all KL = 0.953 +- 0.045 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.6 all L1 = 0.866 +- 0.096 (in-sample avg dev_std = 0.144)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.876
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.87
SUFF++ for r=0.9 class 0.0 = 0.874 +- 0.043 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.9 class 1.0 = 0.941 +- 0.043 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.9 all KL = 0.979 +- 0.043 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.9 all L1 = 0.933 +- 0.076 (in-sample avg dev_std = 0.089)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.644
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.576
SUFF++ for r=0.3 class 0.0 = 0.807 +- 0.040 (in-sample avg dev_std = 0.180)
SUFF++ for r=0.3 class 1.0 = 0.817 +- 0.040 (in-sample avg dev_std = 0.180)
SUFF++ for r=0.3 all KL = 0.949 +- 0.040 (in-sample avg dev_std = 0.180)
SUFF++ for r=0.3 all L1 = 0.816 +- 0.074 (in-sample avg dev_std = 0.180)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.651
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.632
SUFF++ for r=0.6 class 0.0 = 0.818 +- 0.046 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.6 class 1.0 = 0.848 +- 0.046 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.6 all KL = 0.951 +- 0.046 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.6 all L1 = 0.846 +- 0.092 (in-sample avg dev_std = 0.156)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.675
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.648
SUFF++ for r=0.9 class 0.0 = 0.895 +- 0.037 (in-sample avg dev_std = 0.090)
SUFF++ for r=0.9 class 1.0 = 0.921 +- 0.037 (in-sample avg dev_std = 0.090)
SUFF++ for r=0.9 all KL = 0.978 +- 0.037 (in-sample avg dev_std = 0.090)
SUFF++ for r=0.9 all L1 = 0.919 +- 0.075 (in-sample avg dev_std = 0.090)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.712
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.617
SUFF++ for r=0.3 class 0.0 = 0.783 +- 0.052 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.3 class 1.0 = 0.812 +- 0.052 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.3 all KL = 0.944 +- 0.052 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.3 all L1 = 0.808 +- 0.080 (in-sample avg dev_std = 0.187)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.734
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.677
SUFF++ for r=0.6 class 0.0 = 0.791 +- 0.047 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.6 class 1.0 = 0.852 +- 0.047 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.6 all KL = 0.949 +- 0.047 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.6 all L1 = 0.842 +- 0.096 (in-sample avg dev_std = 0.158)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.739
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.714
SUFF++ for r=0.9 class 0.0 = 0.869 +- 0.047 (in-sample avg dev_std = 0.109)
SUFF++ for r=0.9 class 1.0 = 0.917 +- 0.047 (in-sample avg dev_std = 0.109)
SUFF++ for r=0.9 all KL = 0.973 +- 0.047 (in-sample avg dev_std = 0.109)
SUFF++ for r=0.9 all L1 = 0.909 +- 0.084 (in-sample avg dev_std = 0.109)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.812
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.766
NEC for r=0.3 class 0.0 = 0.159 +- 0.044 (in-sample avg dev_std = 0.114)
NEC for r=0.3 class 1.0 = 0.134 +- 0.044 (in-sample avg dev_std = 0.114)
NEC for r=0.3 all KL = 0.031 +- 0.044 (in-sample avg dev_std = 0.114)
NEC for r=0.3 all L1 = 0.137 +- 0.084 (in-sample avg dev_std = 0.114)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.856
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.824
NEC for r=0.6 class 0.0 = 0.151 +- 0.058 (in-sample avg dev_std = 0.118)
NEC for r=0.6 class 1.0 = 0.116 +- 0.058 (in-sample avg dev_std = 0.118)
NEC for r=0.6 all KL = 0.041 +- 0.058 (in-sample avg dev_std = 0.118)
NEC for r=0.6 all L1 = 0.12 +- 0.087 (in-sample avg dev_std = 0.118)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.876
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.86
NEC for r=0.9 class 0.0 = 0.165 +- 0.053 (in-sample avg dev_std = 0.110)
NEC for r=0.9 class 1.0 = 0.085 +- 0.053 (in-sample avg dev_std = 0.110)
NEC for r=0.9 all KL = 0.037 +- 0.053 (in-sample avg dev_std = 0.110)
NEC for r=0.9 all L1 = 0.094 +- 0.091 (in-sample avg dev_std = 0.110)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.88
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.869
NEC for r=1.0 class 0.0 = 0.152 +- 0.050 (in-sample avg dev_std = 0.106)
NEC for r=1.0 class 1.0 = 0.074 +- 0.050 (in-sample avg dev_std = 0.106)
NEC for r=1.0 all KL = 0.033 +- 0.050 (in-sample avg dev_std = 0.106)
NEC for r=1.0 all L1 = 0.083 +- 0.087 (in-sample avg dev_std = 0.106)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.644
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.579
NEC for r=0.3 class 0.0 = 0.157 +- 0.037 (in-sample avg dev_std = 0.122)
NEC for r=0.3 class 1.0 = 0.146 +- 0.037 (in-sample avg dev_std = 0.122)
NEC for r=0.3 all KL = 0.032 +- 0.037 (in-sample avg dev_std = 0.122)
NEC for r=0.3 all L1 = 0.147 +- 0.079 (in-sample avg dev_std = 0.122)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.648
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.619
NEC for r=0.6 class 0.0 = 0.165 +- 0.052 (in-sample avg dev_std = 0.132)
NEC for r=0.6 class 1.0 = 0.143 +- 0.052 (in-sample avg dev_std = 0.132)
NEC for r=0.6 all KL = 0.043 +- 0.052 (in-sample avg dev_std = 0.132)
NEC for r=0.6 all L1 = 0.145 +- 0.084 (in-sample avg dev_std = 0.132)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.675
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.645
NEC for r=0.9 class 0.0 = 0.131 +- 0.057 (in-sample avg dev_std = 0.128)
NEC for r=0.9 class 1.0 = 0.12 +- 0.057 (in-sample avg dev_std = 0.128)
NEC for r=0.9 all KL = 0.042 +- 0.057 (in-sample avg dev_std = 0.128)
NEC for r=0.9 all L1 = 0.121 +- 0.088 (in-sample avg dev_std = 0.128)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.678
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.647
NEC for r=1.0 class 0.0 = 0.132 +- 0.054 (in-sample avg dev_std = 0.121)
NEC for r=1.0 class 1.0 = 0.108 +- 0.054 (in-sample avg dev_std = 0.121)
NEC for r=1.0 all KL = 0.038 +- 0.054 (in-sample avg dev_std = 0.121)
NEC for r=1.0 all L1 = 0.11 +- 0.088 (in-sample avg dev_std = 0.121)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.712
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.694
NEC for r=0.3 class 0.0 = 0.158 +- 0.040 (in-sample avg dev_std = 0.121)
NEC for r=0.3 class 1.0 = 0.15 +- 0.040 (in-sample avg dev_std = 0.121)
NEC for r=0.3 all KL = 0.033 +- 0.040 (in-sample avg dev_std = 0.121)
NEC for r=0.3 all L1 = 0.151 +- 0.085 (in-sample avg dev_std = 0.121)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.734
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.7
NEC for r=0.6 class 0.0 = 0.172 +- 0.053 (in-sample avg dev_std = 0.129)
NEC for r=0.6 class 1.0 = 0.135 +- 0.053 (in-sample avg dev_std = 0.129)
NEC for r=0.6 all KL = 0.042 +- 0.053 (in-sample avg dev_std = 0.129)
NEC for r=0.6 all L1 = 0.141 +- 0.089 (in-sample avg dev_std = 0.129)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.739
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.713
NEC for r=0.9 class 0.0 = 0.161 +- 0.058 (in-sample avg dev_std = 0.124)
NEC for r=0.9 class 1.0 = 0.111 +- 0.058 (in-sample avg dev_std = 0.124)
NEC for r=0.9 all KL = 0.04 +- 0.058 (in-sample avg dev_std = 0.124)
NEC for r=0.9 all L1 = 0.119 +- 0.093 (in-sample avg dev_std = 0.124)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.739
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.717
NEC for r=1.0 class 0.0 = 0.148 +- 0.056 (in-sample avg dev_std = 0.123)
NEC for r=1.0 class 1.0 = 0.106 +- 0.056 (in-sample avg dev_std = 0.123)
NEC for r=1.0 all KL = 0.039 +- 0.056 (in-sample avg dev_std = 0.123)
NEC for r=1.0 all L1 = 0.113 +- 0.092 (in-sample avg dev_std = 0.123)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 14:41:47 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 04/22/2024 02:41:47 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/22/2024 02:42:18 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/22/2024 02:42:28 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/22/2024 02:42:39 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/22/2024 02:42:54 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 181...
[0m[1;37mINFO[0m: [1mCheckpoint 181: 
-----------------------------------
Train ROC-AUC: 0.9079
Train Loss: 0.2316
ID Validation ROC-AUC: 0.8940
ID Validation Loss: 0.2484
ID Test ROC-AUC: 0.8917
ID Test Loss: 0.2549
OOD Validation ROC-AUC: 0.6890
OOD Validation Loss: 0.3310
OOD Test ROC-AUC: 0.7252
OOD Test Loss: 0.4885

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 95...
[0m[1;37mINFO[0m: [1mCheckpoint 95: 
-----------------------------------
Train ROC-AUC: 0.8927
Train Loss: 0.2449
ID Validation ROC-AUC: 0.8798
ID Validation Loss: 0.2585
ID Test ROC-AUC: 0.8839
ID Test Loss: 0.2579
OOD Validation ROC-AUC: 0.7030
OOD Validation Loss: 0.3211
OOD Test ROC-AUC: 0.7129
OOD Test Loss: 0.4836

[0m[1;37mINFO[0m: [1mChartInfo 0.8917 0.7252 0.8839 0.7129 0.8798 0.7030[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 04/22/2024 02:43:10 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 04/22/2024 02:43:15 PM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 04/22/2024 02:43:19 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.809
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.704
SUFF++ for r=0.3 class 0.0 = 0.767 +- 0.056 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.3 class 1.0 = 0.812 +- 0.056 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.3 all KL = 0.934 +- 0.056 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.3 all L1 = 0.807 +- 0.080 (in-sample avg dev_std = 0.195)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.861
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.777
SUFF++ for r=0.6 class 0.0 = 0.794 +- 0.056 (in-sample avg dev_std = 0.154)
SUFF++ for r=0.6 class 1.0 = 0.871 +- 0.056 (in-sample avg dev_std = 0.154)
SUFF++ for r=0.6 all KL = 0.943 +- 0.056 (in-sample avg dev_std = 0.154)
SUFF++ for r=0.6 all L1 = 0.862 +- 0.094 (in-sample avg dev_std = 0.154)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.878
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.845
SUFF++ for r=0.9 class 0.0 = 0.862 +- 0.052 (in-sample avg dev_std = 0.094)
SUFF++ for r=0.9 class 1.0 = 0.936 +- 0.052 (in-sample avg dev_std = 0.094)
SUFF++ for r=0.9 all KL = 0.973 +- 0.052 (in-sample avg dev_std = 0.094)
SUFF++ for r=0.9 all L1 = 0.928 +- 0.081 (in-sample avg dev_std = 0.094)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.641
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.57
SUFF++ for r=0.3 class 0.0 = 0.785 +- 0.058 (in-sample avg dev_std = 0.200)
SUFF++ for r=0.3 class 1.0 = 0.797 +- 0.058 (in-sample avg dev_std = 0.200)
SUFF++ for r=0.3 all KL = 0.931 +- 0.058 (in-sample avg dev_std = 0.200)
SUFF++ for r=0.3 all L1 = 0.796 +- 0.082 (in-sample avg dev_std = 0.200)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.671
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.622
SUFF++ for r=0.6 class 0.0 = 0.809 +- 0.056 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.6 class 1.0 = 0.843 +- 0.056 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.6 all KL = 0.939 +- 0.056 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.6 all L1 = 0.84 +- 0.091 (in-sample avg dev_std = 0.168)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.681
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.644
SUFF++ for r=0.9 class 0.0 = 0.881 +- 0.043 (in-sample avg dev_std = 0.100)
SUFF++ for r=0.9 class 1.0 = 0.913 +- 0.043 (in-sample avg dev_std = 0.100)
SUFF++ for r=0.9 all KL = 0.971 +- 0.043 (in-sample avg dev_std = 0.100)
SUFF++ for r=0.9 all L1 = 0.91 +- 0.082 (in-sample avg dev_std = 0.100)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.695
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.616
SUFF++ for r=0.3 class 0.0 = 0.783 +- 0.054 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.3 class 1.0 = 0.797 +- 0.054 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.3 all KL = 0.931 +- 0.054 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.3 all L1 = 0.795 +- 0.077 (in-sample avg dev_std = 0.205)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.727
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.675
SUFF++ for r=0.6 class 0.0 = 0.812 +- 0.060 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 class 1.0 = 0.849 +- 0.060 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 all KL = 0.937 +- 0.060 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 all L1 = 0.843 +- 0.089 (in-sample avg dev_std = 0.174)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.738
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.716
SUFF++ for r=0.9 class 0.0 = 0.888 +- 0.043 (in-sample avg dev_std = 0.101)
SUFF++ for r=0.9 class 1.0 = 0.917 +- 0.043 (in-sample avg dev_std = 0.101)
SUFF++ for r=0.9 all KL = 0.972 +- 0.043 (in-sample avg dev_std = 0.101)
SUFF++ for r=0.9 all L1 = 0.912 +- 0.079 (in-sample avg dev_std = 0.101)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.809
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.802
NEC for r=0.3 class 0.0 = 0.137 +- 0.060 (in-sample avg dev_std = 0.119)
NEC for r=0.3 class 1.0 = 0.145 +- 0.060 (in-sample avg dev_std = 0.119)
NEC for r=0.3 all KL = 0.041 +- 0.060 (in-sample avg dev_std = 0.119)
NEC for r=0.3 all L1 = 0.144 +- 0.092 (in-sample avg dev_std = 0.119)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.861
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.836
NEC for r=0.6 class 0.0 = 0.144 +- 0.049 (in-sample avg dev_std = 0.109)
NEC for r=0.6 class 1.0 = 0.101 +- 0.049 (in-sample avg dev_std = 0.109)
NEC for r=0.6 all KL = 0.036 +- 0.049 (in-sample avg dev_std = 0.109)
NEC for r=0.6 all L1 = 0.106 +- 0.079 (in-sample avg dev_std = 0.109)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.878
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.853
NEC for r=0.9 class 0.0 = 0.151 +- 0.049 (in-sample avg dev_std = 0.095)
NEC for r=0.9 class 1.0 = 0.074 +- 0.049 (in-sample avg dev_std = 0.095)
NEC for r=0.9 all KL = 0.032 +- 0.049 (in-sample avg dev_std = 0.095)
NEC for r=0.9 all L1 = 0.083 +- 0.081 (in-sample avg dev_std = 0.095)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.878
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.858
NEC for r=1.0 class 0.0 = 0.143 +- 0.046 (in-sample avg dev_std = 0.090)
NEC for r=1.0 class 1.0 = 0.066 +- 0.046 (in-sample avg dev_std = 0.090)
NEC for r=1.0 all KL = 0.029 +- 0.046 (in-sample avg dev_std = 0.090)
NEC for r=1.0 all L1 = 0.075 +- 0.076 (in-sample avg dev_std = 0.090)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.641
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.628
NEC for r=0.3 class 0.0 = 0.139 +- 0.050 (in-sample avg dev_std = 0.123)
NEC for r=0.3 class 1.0 = 0.14 +- 0.050 (in-sample avg dev_std = 0.123)
NEC for r=0.3 all KL = 0.036 +- 0.050 (in-sample avg dev_std = 0.123)
NEC for r=0.3 all L1 = 0.14 +- 0.085 (in-sample avg dev_std = 0.123)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.671
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.647
NEC for r=0.6 class 0.0 = 0.134 +- 0.046 (in-sample avg dev_std = 0.114)
NEC for r=0.6 class 1.0 = 0.115 +- 0.046 (in-sample avg dev_std = 0.114)
NEC for r=0.6 all KL = 0.035 +- 0.046 (in-sample avg dev_std = 0.114)
NEC for r=0.6 all L1 = 0.117 +- 0.077 (in-sample avg dev_std = 0.114)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.681
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.659
NEC for r=0.9 class 0.0 = 0.115 +- 0.046 (in-sample avg dev_std = 0.103)
NEC for r=0.9 class 1.0 = 0.099 +- 0.046 (in-sample avg dev_std = 0.103)
NEC for r=0.9 all KL = 0.033 +- 0.046 (in-sample avg dev_std = 0.103)
NEC for r=0.9 all L1 = 0.1 +- 0.075 (in-sample avg dev_std = 0.103)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.682
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.655
NEC for r=1.0 class 0.0 = 0.112 +- 0.041 (in-sample avg dev_std = 0.098)
NEC for r=1.0 class 1.0 = 0.094 +- 0.041 (in-sample avg dev_std = 0.098)
NEC for r=1.0 all KL = 0.032 +- 0.041 (in-sample avg dev_std = 0.098)
NEC for r=1.0 all L1 = 0.095 +- 0.073 (in-sample avg dev_std = 0.098)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.695
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.683
NEC for r=0.3 class 0.0 = 0.14 +- 0.058 (in-sample avg dev_std = 0.123)
NEC for r=0.3 class 1.0 = 0.149 +- 0.058 (in-sample avg dev_std = 0.123)
NEC for r=0.3 all KL = 0.041 +- 0.058 (in-sample avg dev_std = 0.123)
NEC for r=0.3 all L1 = 0.148 +- 0.089 (in-sample avg dev_std = 0.123)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.727
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.707
NEC for r=0.6 class 0.0 = 0.138 +- 0.058 (in-sample avg dev_std = 0.114)
NEC for r=0.6 class 1.0 = 0.114 +- 0.058 (in-sample avg dev_std = 0.114)
NEC for r=0.6 all KL = 0.038 +- 0.058 (in-sample avg dev_std = 0.114)
NEC for r=0.6 all L1 = 0.118 +- 0.083 (in-sample avg dev_std = 0.114)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.738
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.713
NEC for r=0.9 class 0.0 = 0.132 +- 0.056 (in-sample avg dev_std = 0.104)
NEC for r=0.9 class 1.0 = 0.096 +- 0.056 (in-sample avg dev_std = 0.104)
NEC for r=0.9 all KL = 0.035 +- 0.056 (in-sample avg dev_std = 0.104)
NEC for r=0.9 all L1 = 0.102 +- 0.083 (in-sample avg dev_std = 0.104)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.734
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.71
NEC for r=1.0 class 0.0 = 0.133 +- 0.054 (in-sample avg dev_std = 0.103)
NEC for r=1.0 class 1.0 = 0.09 +- 0.054 (in-sample avg dev_std = 0.103)
NEC for r=1.0 all KL = 0.034 +- 0.054 (in-sample avg dev_std = 0.103)
NEC for r=1.0 all L1 = 0.098 +- 0.083 (in-sample avg dev_std = 0.103)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 14:47:37 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 04/22/2024 02:47:38 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/22/2024 02:48:09 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/22/2024 02:48:19 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/22/2024 02:48:30 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/22/2024 02:48:46 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 177...
[0m[1;37mINFO[0m: [1mCheckpoint 177: 
-----------------------------------
Train ROC-AUC: 0.9126
Train Loss: 0.2231
ID Validation ROC-AUC: 0.8957
ID Validation Loss: 0.2419
ID Test ROC-AUC: 0.8939
ID Test Loss: 0.2480
OOD Validation ROC-AUC: 0.6829
OOD Validation Loss: 0.3545
OOD Test ROC-AUC: 0.7115
OOD Test Loss: 0.4996

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 86...
[0m[1;37mINFO[0m: [1mCheckpoint 86: 
-----------------------------------
Train ROC-AUC: 0.8847
Train Loss: 0.2578
ID Validation ROC-AUC: 0.8749
ID Validation Loss: 0.2670
ID Test ROC-AUC: 0.8766
ID Test Loss: 0.2698
OOD Validation ROC-AUC: 0.7046
OOD Validation Loss: 0.3072
OOD Test ROC-AUC: 0.7276
OOD Test Loss: 0.4696

[0m[1;37mINFO[0m: [1mChartInfo 0.8939 0.7115 0.8766 0.7276 0.8749 0.7046[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 04/22/2024 02:49:01 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 04/22/2024 02:49:06 PM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 04/22/2024 02:49:10 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.751
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.641
SUFF++ for r=0.3 class 0.0 = 0.83 +- 0.054 (in-sample avg dev_std = 0.167)
SUFF++ for r=0.3 class 1.0 = 0.82 +- 0.054 (in-sample avg dev_std = 0.167)
SUFF++ for r=0.3 all KL = 0.956 +- 0.054 (in-sample avg dev_std = 0.167)
SUFF++ for r=0.3 all L1 = 0.821 +- 0.074 (in-sample avg dev_std = 0.167)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.876
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.769
SUFF++ for r=0.6 class 0.0 = 0.802 +- 0.077 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.6 class 1.0 = 0.82 +- 0.077 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.6 all KL = 0.926 +- 0.077 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.6 all L1 = 0.818 +- 0.089 (in-sample avg dev_std = 0.187)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.898
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.854
SUFF++ for r=0.9 class 0.0 = 0.851 +- 0.102 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.9 class 1.0 = 0.885 +- 0.102 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.9 all KL = 0.934 +- 0.102 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.9 all L1 = 0.881 +- 0.105 (in-sample avg dev_std = 0.156)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.584
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.528
SUFF++ for r=0.3 class 0.0 = 0.837 +- 0.052 (in-sample avg dev_std = 0.153)
SUFF++ for r=0.3 class 1.0 = 0.831 +- 0.052 (in-sample avg dev_std = 0.153)
SUFF++ for r=0.3 all KL = 0.964 +- 0.052 (in-sample avg dev_std = 0.153)
SUFF++ for r=0.3 all L1 = 0.831 +- 0.067 (in-sample avg dev_std = 0.153)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.645
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.613
SUFF++ for r=0.6 class 0.0 = 0.813 +- 0.073 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.6 class 1.0 = 0.804 +- 0.073 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.6 all KL = 0.931 +- 0.073 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.6 all L1 = 0.805 +- 0.084 (in-sample avg dev_std = 0.188)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.686
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.662
SUFF++ for r=0.9 class 0.0 = 0.853 +- 0.089 (in-sample avg dev_std = 0.153)
SUFF++ for r=0.9 class 1.0 = 0.856 +- 0.089 (in-sample avg dev_std = 0.153)
SUFF++ for r=0.9 all KL = 0.939 +- 0.089 (in-sample avg dev_std = 0.153)
SUFF++ for r=0.9 all L1 = 0.856 +- 0.101 (in-sample avg dev_std = 0.153)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.628
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.562
SUFF++ for r=0.3 class 0.0 = 0.834 +- 0.049 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.3 class 1.0 = 0.822 +- 0.049 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.3 all KL = 0.959 +- 0.049 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.3 all L1 = 0.824 +- 0.076 (in-sample avg dev_std = 0.164)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.695
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.645
SUFF++ for r=0.6 class 0.0 = 0.802 +- 0.071 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.6 class 1.0 = 0.805 +- 0.071 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.6 all KL = 0.93 +- 0.071 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.6 all L1 = 0.805 +- 0.081 (in-sample avg dev_std = 0.198)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.708
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.66
SUFF++ for r=0.9 class 0.0 = 0.863 +- 0.095 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.9 class 1.0 = 0.857 +- 0.095 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.9 all KL = 0.938 +- 0.095 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.9 all L1 = 0.858 +- 0.102 (in-sample avg dev_std = 0.162)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.751
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.723
NEC for r=0.3 class 0.0 = 0.102 +- 0.048 (in-sample avg dev_std = 0.104)
NEC for r=0.3 class 1.0 = 0.132 +- 0.048 (in-sample avg dev_std = 0.104)
NEC for r=0.3 all KL = 0.024 +- 0.048 (in-sample avg dev_std = 0.104)
NEC for r=0.3 all L1 = 0.128 +- 0.082 (in-sample avg dev_std = 0.104)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.876
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.809
NEC for r=0.6 class 0.0 = 0.125 +- 0.083 (in-sample avg dev_std = 0.137)
NEC for r=0.6 class 1.0 = 0.153 +- 0.083 (in-sample avg dev_std = 0.137)
NEC for r=0.6 all KL = 0.055 +- 0.083 (in-sample avg dev_std = 0.137)
NEC for r=0.6 all L1 = 0.15 +- 0.095 (in-sample avg dev_std = 0.137)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.898
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.847
NEC for r=0.9 class 0.0 = 0.157 +- 0.104 (in-sample avg dev_std = 0.155)
NEC for r=0.9 class 1.0 = 0.13 +- 0.104 (in-sample avg dev_std = 0.155)
NEC for r=0.9 all KL = 0.076 +- 0.104 (in-sample avg dev_std = 0.155)
NEC for r=0.9 all L1 = 0.134 +- 0.110 (in-sample avg dev_std = 0.155)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.897
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.849
NEC for r=1.0 class 0.0 = 0.163 +- 0.108 (in-sample avg dev_std = 0.158)
NEC for r=1.0 class 1.0 = 0.122 +- 0.108 (in-sample avg dev_std = 0.158)
NEC for r=1.0 all KL = 0.077 +- 0.108 (in-sample avg dev_std = 0.158)
NEC for r=1.0 all L1 = 0.127 +- 0.111 (in-sample avg dev_std = 0.158)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.584
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.56
NEC for r=0.3 class 0.0 = 0.119 +- 0.041 (in-sample avg dev_std = 0.100)
NEC for r=0.3 class 1.0 = 0.12 +- 0.041 (in-sample avg dev_std = 0.100)
NEC for r=0.3 all KL = 0.02 +- 0.041 (in-sample avg dev_std = 0.100)
NEC for r=0.3 all L1 = 0.12 +- 0.074 (in-sample avg dev_std = 0.100)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.645
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.596
NEC for r=0.6 class 0.0 = 0.149 +- 0.074 (in-sample avg dev_std = 0.132)
NEC for r=0.6 class 1.0 = 0.155 +- 0.074 (in-sample avg dev_std = 0.132)
NEC for r=0.6 all KL = 0.046 +- 0.074 (in-sample avg dev_std = 0.132)
NEC for r=0.6 all L1 = 0.154 +- 0.092 (in-sample avg dev_std = 0.132)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.686
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.629
NEC for r=0.9 class 0.0 = 0.157 +- 0.098 (in-sample avg dev_std = 0.161)
NEC for r=0.9 class 1.0 = 0.163 +- 0.098 (in-sample avg dev_std = 0.161)
NEC for r=0.9 all KL = 0.074 +- 0.098 (in-sample avg dev_std = 0.161)
NEC for r=0.9 all L1 = 0.163 +- 0.110 (in-sample avg dev_std = 0.161)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.698
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.64
NEC for r=1.0 class 0.0 = 0.15 +- 0.102 (in-sample avg dev_std = 0.164)
NEC for r=1.0 class 1.0 = 0.16 +- 0.102 (in-sample avg dev_std = 0.164)
NEC for r=1.0 all KL = 0.076 +- 0.102 (in-sample avg dev_std = 0.164)
NEC for r=1.0 all L1 = 0.159 +- 0.112 (in-sample avg dev_std = 0.164)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.627
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.599
NEC for r=0.3 class 0.0 = 0.11 +- 0.043 (in-sample avg dev_std = 0.105)
NEC for r=0.3 class 1.0 = 0.127 +- 0.043 (in-sample avg dev_std = 0.105)
NEC for r=0.3 all KL = 0.023 +- 0.043 (in-sample avg dev_std = 0.105)
NEC for r=0.3 all L1 = 0.125 +- 0.085 (in-sample avg dev_std = 0.105)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.695
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.651
NEC for r=0.6 class 0.0 = 0.144 +- 0.072 (in-sample avg dev_std = 0.134)
NEC for r=0.6 class 1.0 = 0.156 +- 0.072 (in-sample avg dev_std = 0.134)
NEC for r=0.6 all KL = 0.047 +- 0.072 (in-sample avg dev_std = 0.134)
NEC for r=0.6 all L1 = 0.154 +- 0.093 (in-sample avg dev_std = 0.134)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.708
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.681
NEC for r=0.9 class 0.0 = 0.161 +- 0.103 (in-sample avg dev_std = 0.156)
NEC for r=0.9 class 1.0 = 0.152 +- 0.103 (in-sample avg dev_std = 0.156)
NEC for r=0.9 all KL = 0.07 +- 0.103 (in-sample avg dev_std = 0.156)
NEC for r=0.9 all L1 = 0.154 +- 0.108 (in-sample avg dev_std = 0.156)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.717
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.682
NEC for r=1.0 class 0.0 = 0.163 +- 0.106 (in-sample avg dev_std = 0.156)
NEC for r=1.0 class 1.0 = 0.151 +- 0.106 (in-sample avg dev_std = 0.156)
NEC for r=1.0 all KL = 0.073 +- 0.106 (in-sample avg dev_std = 0.156)
NEC for r=1.0 all L1 = 0.153 +- 0.111 (in-sample avg dev_std = 0.156)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr 22 14:53:29 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 04/22/2024 02:53:29 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:02 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:12 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:23 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:39 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/22/2024 02:54:55 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 181...
[0m[1;37mINFO[0m: [1mCheckpoint 181: 
-----------------------------------
Train ROC-AUC: 0.9018
Train Loss: 0.2434
ID Validation ROC-AUC: 0.8875
ID Validation Loss: 0.2625
ID Test ROC-AUC: 0.8881
ID Test Loss: 0.2644
OOD Validation ROC-AUC: 0.6639
OOD Validation Loss: 0.3521
OOD Test ROC-AUC: 0.7191
OOD Test Loss: 0.5124

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 95...
[0m[1;37mINFO[0m: [1mCheckpoint 95: 
-----------------------------------
Train ROC-AUC: 0.8807
Train Loss: 0.2710
ID Validation ROC-AUC: 0.8756
ID Validation Loss: 0.2766
ID Test ROC-AUC: 0.8772
ID Test Loss: 0.2783
OOD Validation ROC-AUC: 0.7031
OOD Validation Loss: 0.2933
OOD Test ROC-AUC: 0.7222
OOD Test Loss: 0.4761

[0m[1;37mINFO[0m: [1mChartInfo 0.8881 0.7191 0.8772 0.7222 0.8756 0.7031[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 04/22/2024 02:54:56 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 04/22/2024 02:55:00 PM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 04/22/2024 02:55:04 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.798
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.634
SUFF++ for r=0.3 class 0.0 = 0.781 +- 0.083 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.3 class 1.0 = 0.765 +- 0.083 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.3 all KL = 0.908 +- 0.083 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.3 all L1 = 0.767 +- 0.078 (in-sample avg dev_std = 0.236)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.849
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.695
SUFF++ for r=0.6 class 0.0 = 0.766 +- 0.101 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.6 class 1.0 = 0.794 +- 0.101 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.6 all KL = 0.89 +- 0.101 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.6 all L1 = 0.791 +- 0.089 (in-sample avg dev_std = 0.218)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.864
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.806
SUFF++ for r=0.9 class 0.0 = 0.833 +- 0.093 (in-sample avg dev_std = 0.146)
SUFF++ for r=0.9 class 1.0 = 0.873 +- 0.093 (in-sample avg dev_std = 0.146)
SUFF++ for r=0.9 all KL = 0.931 +- 0.093 (in-sample avg dev_std = 0.146)
SUFF++ for r=0.9 all L1 = 0.868 +- 0.095 (in-sample avg dev_std = 0.146)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.624
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.543
SUFF++ for r=0.3 class 0.0 = 0.78 +- 0.074 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.3 class 1.0 = 0.777 +- 0.074 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.3 all KL = 0.922 +- 0.074 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.3 all L1 = 0.777 +- 0.077 (in-sample avg dev_std = 0.227)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.636
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 799
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.566
SUFF++ for r=0.6 class 0.0 = 0.781 +- 0.083 (in-sample avg dev_std = 0.209)
SUFF++ for r=0.6 class 1.0 = 0.786 +- 0.083 (in-sample avg dev_std = 0.209)
SUFF++ for r=0.6 all KL = 0.909 +- 0.083 (in-sample avg dev_std = 0.209)
SUFF++ for r=0.6 all L1 = 0.785 +- 0.086 (in-sample avg dev_std = 0.209)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.683
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.623
SUFF++ for r=0.9 class 0.0 = 0.868 +- 0.073 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.9 class 1.0 = 0.859 +- 0.073 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.9 all KL = 0.945 +- 0.073 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.9 all L1 = 0.86 +- 0.089 (in-sample avg dev_std = 0.145)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.686
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.576
SUFF++ for r=0.3 class 0.0 = 0.772 +- 0.070 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.3 class 1.0 = 0.769 +- 0.070 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.3 all KL = 0.917 +- 0.070 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.3 all L1 = 0.77 +- 0.077 (in-sample avg dev_std = 0.239)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.706
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.614
SUFF++ for r=0.6 class 0.0 = 0.778 +- 0.089 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.6 class 1.0 = 0.787 +- 0.089 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.6 all KL = 0.903 +- 0.089 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.6 all L1 = 0.786 +- 0.085 (in-sample avg dev_std = 0.220)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.719
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.673
SUFF++ for r=0.9 class 0.0 = 0.853 +- 0.073 (in-sample avg dev_std = 0.138)
SUFF++ for r=0.9 class 1.0 = 0.866 +- 0.073 (in-sample avg dev_std = 0.138)
SUFF++ for r=0.9 all KL = 0.946 +- 0.073 (in-sample avg dev_std = 0.138)
SUFF++ for r=0.9 all L1 = 0.864 +- 0.090 (in-sample avg dev_std = 0.138)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.798
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.775
NEC for r=0.3 class 0.0 = 0.1 +- 0.037 (in-sample avg dev_std = 0.099)
NEC for r=0.3 class 1.0 = 0.107 +- 0.037 (in-sample avg dev_std = 0.099)
NEC for r=0.3 all KL = 0.021 +- 0.037 (in-sample avg dev_std = 0.099)
NEC for r=0.3 all L1 = 0.106 +- 0.078 (in-sample avg dev_std = 0.099)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.849
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.812
NEC for r=0.6 class 0.0 = 0.106 +- 0.049 (in-sample avg dev_std = 0.114)
NEC for r=0.6 class 1.0 = 0.113 +- 0.049 (in-sample avg dev_std = 0.114)
NEC for r=0.6 all KL = 0.036 +- 0.049 (in-sample avg dev_std = 0.114)
NEC for r=0.6 all L1 = 0.112 +- 0.074 (in-sample avg dev_std = 0.114)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.864
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.835
NEC for r=0.9 class 0.0 = 0.143 +- 0.077 (in-sample avg dev_std = 0.122)
NEC for r=0.9 class 1.0 = 0.113 +- 0.077 (in-sample avg dev_std = 0.122)
NEC for r=0.9 all KL = 0.055 +- 0.077 (in-sample avg dev_std = 0.122)
NEC for r=0.9 all L1 = 0.116 +- 0.084 (in-sample avg dev_std = 0.122)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.873
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.845
NEC for r=1.0 class 0.0 = 0.151 +- 0.085 (in-sample avg dev_std = 0.124)
NEC for r=1.0 class 1.0 = 0.111 +- 0.085 (in-sample avg dev_std = 0.124)
NEC for r=1.0 all KL = 0.059 +- 0.085 (in-sample avg dev_std = 0.124)
NEC for r=1.0 all L1 = 0.116 +- 0.089 (in-sample avg dev_std = 0.124)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.624
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.591
NEC for r=0.3 class 0.0 = 0.113 +- 0.034 (in-sample avg dev_std = 0.092)
NEC for r=0.3 class 1.0 = 0.109 +- 0.034 (in-sample avg dev_std = 0.092)
NEC for r=0.3 all KL = 0.02 +- 0.034 (in-sample avg dev_std = 0.092)
NEC for r=0.3 all L1 = 0.11 +- 0.082 (in-sample avg dev_std = 0.092)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.636
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.608
NEC for r=0.6 class 0.0 = 0.113 +- 0.045 (in-sample avg dev_std = 0.115)
NEC for r=0.6 class 1.0 = 0.121 +- 0.045 (in-sample avg dev_std = 0.115)
NEC for r=0.6 all KL = 0.031 +- 0.045 (in-sample avg dev_std = 0.115)
NEC for r=0.6 all L1 = 0.12 +- 0.078 (in-sample avg dev_std = 0.115)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.683
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.63
NEC for r=0.9 class 0.0 = 0.119 +- 0.053 (in-sample avg dev_std = 0.120)
NEC for r=0.9 class 1.0 = 0.131 +- 0.053 (in-sample avg dev_std = 0.120)
NEC for r=0.9 all KL = 0.044 +- 0.053 (in-sample avg dev_std = 0.120)
NEC for r=0.9 all L1 = 0.13 +- 0.078 (in-sample avg dev_std = 0.120)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.682
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.641
NEC for r=1.0 class 0.0 = 0.121 +- 0.066 (in-sample avg dev_std = 0.125)
NEC for r=1.0 class 1.0 = 0.136 +- 0.066 (in-sample avg dev_std = 0.125)
NEC for r=1.0 all KL = 0.051 +- 0.066 (in-sample avg dev_std = 0.125)
NEC for r=1.0 all L1 = 0.135 +- 0.088 (in-sample avg dev_std = 0.125)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.686
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.66
NEC for r=0.3 class 0.0 = 0.103 +- 0.037 (in-sample avg dev_std = 0.089)
NEC for r=0.3 class 1.0 = 0.11 +- 0.037 (in-sample avg dev_std = 0.089)
NEC for r=0.3 all KL = 0.02 +- 0.037 (in-sample avg dev_std = 0.089)
NEC for r=0.3 all L1 = 0.109 +- 0.079 (in-sample avg dev_std = 0.089)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.706
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.678
NEC for r=0.6 class 0.0 = 0.114 +- 0.052 (in-sample avg dev_std = 0.108)
NEC for r=0.6 class 1.0 = 0.122 +- 0.052 (in-sample avg dev_std = 0.108)
NEC for r=0.6 all KL = 0.033 +- 0.052 (in-sample avg dev_std = 0.108)
NEC for r=0.6 all L1 = 0.12 +- 0.080 (in-sample avg dev_std = 0.108)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.719
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.7
NEC for r=0.9 class 0.0 = 0.131 +- 0.060 (in-sample avg dev_std = 0.125)
NEC for r=0.9 class 1.0 = 0.125 +- 0.060 (in-sample avg dev_std = 0.125)
NEC for r=0.9 all KL = 0.046 +- 0.060 (in-sample avg dev_std = 0.125)
NEC for r=0.9 all L1 = 0.126 +- 0.082 (in-sample avg dev_std = 0.125)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.721
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.704
NEC for r=1.0 class 0.0 = 0.139 +- 0.067 (in-sample avg dev_std = 0.120)
NEC for r=1.0 class 1.0 = 0.127 +- 0.067 (in-sample avg dev_std = 0.120)
NEC for r=1.0 all KL = 0.049 +- 0.067 (in-sample avg dev_std = 0.120)
NEC for r=1.0 all L1 = 0.129 +- 0.082 (in-sample avg dev_std = 0.120)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.942, 0.907, 0.928, 1.0], 'all_L1': [0.801, 0.792, 0.866, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.945, 0.953, 0.979, 1.0], 'all_L1': [0.82, 0.866, 0.933, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.934, 0.943, 0.973, 1.0], 'all_L1': [0.807, 0.862, 0.928, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.956, 0.926, 0.934, 1.0], 'all_L1': [0.821, 0.818, 0.881, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.908, 0.89, 0.931, 1.0], 'all_L1': [0.767, 0.791, 0.868, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.04, 0.077, 0.086, 0.08], 'all_L1': [0.164, 0.185, 0.149, 0.136]}), defaultdict(<class 'list'>, {'all_KL': [0.031, 0.041, 0.037, 0.033], 'all_L1': [0.137, 0.12, 0.094, 0.083]}), defaultdict(<class 'list'>, {'all_KL': [0.041, 0.036, 0.032, 0.029], 'all_L1': [0.144, 0.106, 0.083, 0.075]}), defaultdict(<class 'list'>, {'all_KL': [0.024, 0.055, 0.076, 0.077], 'all_L1': [0.128, 0.15, 0.134, 0.127]}), defaultdict(<class 'list'>, {'all_KL': [0.021, 0.036, 0.055, 0.059], 'all_L1': [0.106, 0.112, 0.116, 0.116]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.956, 0.915, 0.925, 1.0], 'all_L1': [0.823, 0.782, 0.829, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.949, 0.951, 0.978, 1.0], 'all_L1': [0.816, 0.846, 0.919, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.931, 0.939, 0.971, 1.0], 'all_L1': [0.796, 0.84, 0.91, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.964, 0.931, 0.939, 1.0], 'all_L1': [0.831, 0.805, 0.856, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.922, 0.909, 0.945, 1.0], 'all_L1': [0.777, 0.785, 0.86, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.029, 0.062, 0.084, 0.083], 'all_L1': [0.142, 0.177, 0.176, 0.168]}), defaultdict(<class 'list'>, {'all_KL': [0.032, 0.043, 0.042, 0.038], 'all_L1': [0.147, 0.145, 0.121, 0.11]}), defaultdict(<class 'list'>, {'all_KL': [0.036, 0.035, 0.033, 0.032], 'all_L1': [0.14, 0.117, 0.1, 0.095]}), defaultdict(<class 'list'>, {'all_KL': [0.02, 0.046, 0.074, 0.076], 'all_L1': [0.12, 0.154, 0.163, 0.159]}), defaultdict(<class 'list'>, {'all_KL': [0.02, 0.031, 0.044, 0.051], 'all_L1': [0.11, 0.12, 0.13, 0.135]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.952, 0.918, 0.935, 1.0], 'all_L1': [0.823, 0.791, 0.848, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.944, 0.949, 0.973, 1.0], 'all_L1': [0.808, 0.842, 0.909, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.931, 0.937, 0.972, 1.0], 'all_L1': [0.795, 0.843, 0.912, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.959, 0.93, 0.938, 1.0], 'all_L1': [0.824, 0.805, 0.858, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.917, 0.903, 0.946, 1.0], 'all_L1': [0.77, 0.786, 0.864, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.032, 0.06, 0.075, 0.075], 'all_L1': [0.146, 0.171, 0.163, 0.155]}), defaultdict(<class 'list'>, {'all_KL': [0.033, 0.042, 0.04, 0.039], 'all_L1': [0.151, 0.141, 0.119, 0.113]}), defaultdict(<class 'list'>, {'all_KL': [0.041, 0.038, 0.035, 0.034], 'all_L1': [0.148, 0.118, 0.102, 0.098]}), defaultdict(<class 'list'>, {'all_KL': [0.023, 0.047, 0.07, 0.073], 'all_L1': [0.125, 0.154, 0.154, 0.153]}), defaultdict(<class 'list'>, {'all_KL': [0.02, 0.033, 0.046, 0.049], 'all_L1': [0.109, 0.12, 0.126, 0.129]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.803 +- 0.020, 0.826 +- 0.033, 0.895 +- 0.029, 1.000 +- 0.000
suff++ class all_KL  =  0.937 +- 0.016, 0.924 +- 0.023, 0.949 +- 0.022, 1.000 +- 0.000
suff++_acc_int  =  0.659 +- 0.049, 0.760 +- 0.035, 0.840 +- 0.023
nec class all_L1  =  0.136 +- 0.019, 0.135 +- 0.029, 0.115 +- 0.024, 0.107 +- 0.024
nec class all_KL  =  0.031 +- 0.008, 0.049 +- 0.016, 0.057 +- 0.021, 0.056 +- 0.021
nec_acc_int  =  0.745 +- 0.050, 0.810 +- 0.023, 0.842 +- 0.016, 0.849 +- 0.014

Eval split val
suff++ class all_L1  =  0.809 +- 0.020, 0.812 +- 0.027, 0.875 +- 0.034, 1.000 +- 0.000
suff++ class all_KL  =  0.944 +- 0.016, 0.929 +- 0.015, 0.952 +- 0.020, 1.000 +- 0.000
suff++_acc_int  =  0.554 +- 0.018, 0.608 +- 0.023, 0.643 +- 0.013
nec class all_L1  =  0.132 +- 0.014, 0.143 +- 0.022, 0.138 +- 0.028, 0.133 +- 0.028
nec class all_KL  =  0.027 +- 0.006, 0.043 +- 0.011, 0.055 +- 0.020, 0.056 +- 0.020
nec_acc_int  =  0.585 +- 0.024, 0.615 +- 0.018, 0.639 +- 0.012, 0.642 +- 0.009

Eval split test
suff++ class all_L1  =  0.804 +- 0.020, 0.813 +- 0.025, 0.878 +- 0.027, 1.000 +- 0.000
suff++ class all_KL  =  0.941 +- 0.015, 0.927 +- 0.016, 0.953 +- 0.016, 1.000 +- 0.000
suff++_acc_int  =  0.578 +- 0.036, 0.650 +- 0.023, 0.691 +- 0.022
nec class all_L1  =  0.136 +- 0.016, 0.141 +- 0.020, 0.133 +- 0.023, 0.130 +- 0.022
nec class all_KL  =  0.030 +- 0.008, 0.044 +- 0.009, 0.053 +- 0.016, 0.054 +- 0.017
nec_acc_int  =  0.644 +- 0.044, 0.680 +- 0.021, 0.699 +- 0.013, 0.701 +- 0.012


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.470 +- 0.017, 0.480 +- 0.015, 0.505 +- 0.007, 0.554 +- 0.012
Faith. Armon (L1)= 		  =  0.232 +- 0.028, 0.230 +- 0.042, 0.203 +- 0.038, 0.193 +- 0.040
Faith. GMean (L1)= 	  =  0.330 +- 0.025, 0.331 +- 0.032, 0.319 +- 0.030, 0.326 +- 0.038
Faith. Aritm (KL)= 		  =  0.484 +- 0.010, 0.486 +- 0.012, 0.503 +- 0.005, 0.528 +- 0.011
Faith. Armon (KL)= 		  =  0.061 +- 0.015, 0.093 +- 0.028, 0.107 +- 0.037, 0.105 +- 0.038
Faith. GMean (KL)= 	  =  0.170 +- 0.023, 0.210 +- 0.032, 0.228 +- 0.041, 0.231 +- 0.047

Eval split val
Faith. Aritm (L1)= 		  =  0.470 +- 0.014, 0.477 +- 0.014, 0.506 +- 0.008, 0.567 +- 0.014
Faith. Armon (L1)= 		  =  0.226 +- 0.022, 0.242 +- 0.032, 0.237 +- 0.040, 0.234 +- 0.044
Faith. GMean (L1)= 	  =  0.326 +- 0.020, 0.339 +- 0.025, 0.345 +- 0.029, 0.363 +- 0.039
Faith. Aritm (KL)= 		  =  0.486 +- 0.008, 0.486 +- 0.009, 0.503 +- 0.005, 0.528 +- 0.010
Faith. Armon (KL)= 		  =  0.053 +- 0.012, 0.083 +- 0.019, 0.104 +- 0.035, 0.105 +- 0.036
Faith. GMean (KL)= 	  =  0.160 +- 0.019, 0.199 +- 0.024, 0.226 +- 0.039, 0.233 +- 0.043

Eval split test
Faith. Aritm (L1)= 		  =  0.470 +- 0.016, 0.477 +- 0.013, 0.506 +- 0.006, 0.565 +- 0.011
Faith. Armon (L1)= 		  =  0.232 +- 0.024, 0.239 +- 0.029, 0.230 +- 0.033, 0.229 +- 0.035
Faith. GMean (L1)= 	  =  0.330 +- 0.022, 0.337 +- 0.023, 0.340 +- 0.025, 0.359 +- 0.031
Faith. Aritm (KL)= 		  =  0.485 +- 0.009, 0.486 +- 0.009, 0.503 +- 0.004, 0.527 +- 0.009
Faith. Armon (KL)= 		  =  0.058 +- 0.014, 0.084 +- 0.017, 0.100 +- 0.029, 0.102 +- 0.031
Faith. GMean (KL)= 	  =  0.166 +- 0.021, 0.201 +- 0.021, 0.222 +- 0.032, 0.229 +- 0.037
Computed for split load_split = id



Completed in  0:29:36.687218  for LECIvGIN LBAPcore/assay



DONE LECI LBAPcore/assay
DONE all :)
