Time to compute metrics for random explanations!
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 14:16:08 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:16:08 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 106...
[0m[1;37mINFO[0m: [1mCheckpoint 106: 
-----------------------------------
Train ACCURACY: 0.9077
Train Loss: 0.4320
ID Validation ACCURACY: 0.9117
ID Validation Loss: 0.4033
ID Test ACCURACY: 0.9047
ID Test Loss: 0.4417
OOD Validation ACCURACY: 0.9277
OOD Validation Loss: 0.3670
OOD Test ACCURACY: 0.9023
OOD Test Loss: 0.4492

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 130...
[0m[1;37mINFO[0m: [1mCheckpoint 130: 
-----------------------------------
Train ACCURACY: 0.8641
Train Loss: 0.4637
ID Validation ACCURACY: 0.8727
ID Validation Loss: 0.4477
ID Test ACCURACY: 0.8610
ID Test Loss: 0.4772
OOD Validation ACCURACY: 0.9313
OOD Validation Loss: 0.3851
OOD Test ACCURACY: 0.7927
OOD Test Loss: 0.6936

[0m[1;37mINFO[0m: [1mChartInfo 0.9047 0.9023 0.8610 0.7927 0.8727 0.9313[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.223
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.278
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.306
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.308
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.173
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.224
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.245
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.250


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.594
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.22328
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.4
SUFF++ for r=0.3 class 0 = 0.358 +- 0.206 (in-sample avg dev_std = 0.670)
SUFF++ for r=0.3 class 1 = 0.426 +- 0.206 (in-sample avg dev_std = 0.670)
SUFF++ for r=0.3 class 2 = 0.431 +- 0.206 (in-sample avg dev_std = 0.670)
SUFF++ for r=0.3 all KL = 0.214 +- 0.206 (in-sample avg dev_std = 0.670)
SUFF++ for r=0.3 all L1 = 0.405 +- 0.118 (in-sample avg dev_std = 0.670)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.892
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.27763
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.455
SUFF++ for r=0.6 class 0 = 0.352 +- 0.223 (in-sample avg dev_std = 0.638)
SUFF++ for r=0.6 class 1 = 0.407 +- 0.223 (in-sample avg dev_std = 0.638)
SUFF++ for r=0.6 class 2 = 0.405 +- 0.223 (in-sample avg dev_std = 0.638)
SUFF++ for r=0.6 all KL = 0.228 +- 0.223 (in-sample avg dev_std = 0.638)
SUFF++ for r=0.6 all L1 = 0.388 +- 0.129 (in-sample avg dev_std = 0.638)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.923
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.30646500000000004
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.677
SUFF++ for r=0.9 class 0 = 0.651 +- 0.355 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.9 class 1 = 0.637 +- 0.355 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.9 class 2 = 0.618 +- 0.355 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.9 all KL = 0.582 +- 0.355 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.9 all L1 = 0.635 +- 0.255 (in-sample avg dev_std = 0.430)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.676
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.17275875
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.414
SUFF++ for r=0.3 class 0 = 0.339 +- 0.152 (in-sample avg dev_std = 0.746)
SUFF++ for r=0.3 class 1 = 0.365 +- 0.152 (in-sample avg dev_std = 0.746)
SUFF++ for r=0.3 class 2 = 0.412 +- 0.152 (in-sample avg dev_std = 0.746)
SUFF++ for r=0.3 all KL = 0.134 +- 0.152 (in-sample avg dev_std = 0.746)
SUFF++ for r=0.3 all L1 = 0.372 +- 0.112 (in-sample avg dev_std = 0.746)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.841
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.22398249999999997
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.469
SUFF++ for r=0.6 class 0 = 0.41 +- 0.217 (in-sample avg dev_std = 0.695)
SUFF++ for r=0.6 class 1 = 0.364 +- 0.217 (in-sample avg dev_std = 0.695)
SUFF++ for r=0.6 class 2 = 0.434 +- 0.217 (in-sample avg dev_std = 0.695)
SUFF++ for r=0.6 all KL = 0.226 +- 0.217 (in-sample avg dev_std = 0.695)
SUFF++ for r=0.6 all L1 = 0.402 +- 0.156 (in-sample avg dev_std = 0.695)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.9
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.24513875
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.663
SUFF++ for r=0.9 class 0 = 0.634 +- 0.310 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.9 class 1 = 0.598 +- 0.310 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.9 class 2 = 0.612 +- 0.310 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.9 all KL = 0.596 +- 0.310 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.9 all L1 = 0.614 +- 0.225 (in-sample avg dev_std = 0.419)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.594
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.22328
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.438
NEC for r=0.3 class 0 = 0.532 +- 0.274 (in-sample avg dev_std = 0.590)
NEC for r=0.3 class 1 = 0.456 +- 0.274 (in-sample avg dev_std = 0.590)
NEC for r=0.3 class 2 = 0.546 +- 0.274 (in-sample avg dev_std = 0.590)
NEC for r=0.3 all KL = 0.686 +- 0.274 (in-sample avg dev_std = 0.590)
NEC for r=0.3 all L1 = 0.511 +- 0.191 (in-sample avg dev_std = 0.590)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.894
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.27763
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.54
NEC for r=0.6 class 0 = 0.564 +- 0.274 (in-sample avg dev_std = 0.635)
NEC for r=0.6 class 1 = 0.534 +- 0.274 (in-sample avg dev_std = 0.635)
NEC for r=0.6 class 2 = 0.507 +- 0.274 (in-sample avg dev_std = 0.635)
NEC for r=0.6 all KL = 0.692 +- 0.274 (in-sample avg dev_std = 0.635)
NEC for r=0.6 all L1 = 0.535 +- 0.173 (in-sample avg dev_std = 0.635)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.923
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.30646500000000004
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.531
NEC for r=0.9 class 0 = 0.506 +- 0.277 (in-sample avg dev_std = 0.628)
NEC for r=0.9 class 1 = 0.556 +- 0.277 (in-sample avg dev_std = 0.628)
NEC for r=0.9 class 2 = 0.555 +- 0.277 (in-sample avg dev_std = 0.628)
NEC for r=0.9 all KL = 0.66 +- 0.277 (in-sample avg dev_std = 0.628)
NEC for r=0.9 all L1 = 0.539 +- 0.162 (in-sample avg dev_std = 0.628)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.92
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.30825875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.537
NEC for r=1.0 class 0 = 0.505 +- 0.281 (in-sample avg dev_std = 0.619)
NEC for r=1.0 class 1 = 0.554 +- 0.281 (in-sample avg dev_std = 0.619)
NEC for r=1.0 class 2 = 0.556 +- 0.281 (in-sample avg dev_std = 0.619)
NEC for r=1.0 all KL = 0.652 +- 0.281 (in-sample avg dev_std = 0.619)
NEC for r=1.0 all L1 = 0.538 +- 0.164 (in-sample avg dev_std = 0.619)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.676
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.17275875
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.5
NEC for r=0.3 class 0 = 0.509 +- 0.259 (in-sample avg dev_std = 0.693)
NEC for r=0.3 class 1 = 0.528 +- 0.259 (in-sample avg dev_std = 0.693)
NEC for r=0.3 class 2 = 0.536 +- 0.259 (in-sample avg dev_std = 0.693)
NEC for r=0.3 all KL = 0.742 +- 0.259 (in-sample avg dev_std = 0.693)
NEC for r=0.3 all L1 = 0.525 +- 0.187 (in-sample avg dev_std = 0.693)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.841
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.22398249999999997
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.574
NEC for r=0.6 class 0 = 0.459 +- 0.311 (in-sample avg dev_std = 0.682)
NEC for r=0.6 class 1 = 0.542 +- 0.311 (in-sample avg dev_std = 0.682)
NEC for r=0.6 class 2 = 0.453 +- 0.311 (in-sample avg dev_std = 0.682)
NEC for r=0.6 all KL = 0.633 +- 0.311 (in-sample avg dev_std = 0.682)
NEC for r=0.6 all L1 = 0.485 +- 0.221 (in-sample avg dev_std = 0.682)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.9
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.24513875
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.647
NEC for r=0.9 class 0 = 0.41 +- 0.289 (in-sample avg dev_std = 0.582)
NEC for r=0.9 class 1 = 0.492 +- 0.289 (in-sample avg dev_std = 0.582)
NEC for r=0.9 class 2 = 0.368 +- 0.289 (in-sample avg dev_std = 0.582)
NEC for r=0.9 all KL = 0.5 +- 0.289 (in-sample avg dev_std = 0.582)
NEC for r=0.9 all L1 = 0.424 +- 0.177 (in-sample avg dev_std = 0.582)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.9
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.2497325
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.646
NEC for r=1.0 class 0 = 0.411 +- 0.304 (in-sample avg dev_std = 0.607)
NEC for r=1.0 class 1 = 0.512 +- 0.304 (in-sample avg dev_std = 0.607)
NEC for r=1.0 class 2 = 0.349 +- 0.304 (in-sample avg dev_std = 0.607)
NEC for r=1.0 all KL = 0.503 +- 0.304 (in-sample avg dev_std = 0.607)
NEC for r=1.0 all L1 = 0.425 +- 0.187 (in-sample avg dev_std = 0.607)
model_dirname= repr_LECIGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 14:18:53 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:53 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 188...
[0m[1;37mINFO[0m: [1mCheckpoint 188: 
-----------------------------------
Train ACCURACY: 0.9162
Train Loss: 0.4093
ID Validation ACCURACY: 0.9230
ID Validation Loss: 0.3818
ID Test ACCURACY: 0.9110
ID Test Loss: 0.4274
OOD Validation ACCURACY: 0.9130
OOD Validation Loss: 0.4851
OOD Test ACCURACY: 0.8380
OOD Test Loss: 0.4985

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 119...
[0m[1;37mINFO[0m: [1mCheckpoint 119: 
-----------------------------------
Train ACCURACY: 0.8970
Train Loss: 0.4289
ID Validation ACCURACY: 0.9023
ID Validation Loss: 0.4071
ID Test ACCURACY: 0.8917
ID Test Loss: 0.4442
OOD Validation ACCURACY: 0.9293
OOD Validation Loss: 0.4515
OOD Test ACCURACY: 0.8837
OOD Test Loss: 0.4862

[0m[1;37mINFO[0m: [1mChartInfo 0.9110 0.8380 0.8917 0.8837 0.9023 0.9293[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.228
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.283
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.308
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.309
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.202
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.244
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.255
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.256


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.644
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.22788624999999998
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.378
SUFF++ for r=0.3 class 0 = 0.365 +- 0.278 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.3 class 1 = 0.547 +- 0.278 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.3 class 2 = 0.433 +- 0.278 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.3 all KL = 0.344 +- 0.278 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.3 all L1 = 0.449 +- 0.195 (in-sample avg dev_std = 0.568)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.896
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.2825625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.458
SUFF++ for r=0.6 class 0 = 0.346 +- 0.275 (in-sample avg dev_std = 0.589)
SUFF++ for r=0.6 class 1 = 0.513 +- 0.275 (in-sample avg dev_std = 0.589)
SUFF++ for r=0.6 class 2 = 0.355 +- 0.275 (in-sample avg dev_std = 0.589)
SUFF++ for r=0.6 all KL = 0.299 +- 0.275 (in-sample avg dev_std = 0.589)
SUFF++ for r=0.6 all L1 = 0.405 +- 0.156 (in-sample avg dev_std = 0.589)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.931
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.3080375
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.698
SUFF++ for r=0.9 class 0 = 0.628 +- 0.324 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.9 class 1 = 0.668 +- 0.324 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.9 class 2 = 0.632 +- 0.324 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.9 all KL = 0.649 +- 0.324 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.9 all L1 = 0.643 +- 0.241 (in-sample avg dev_std = 0.390)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.68
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.20202375
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.435
SUFF++ for r=0.3 class 0 = 0.31 +- 0.295 (in-sample avg dev_std = 0.601)
SUFF++ for r=0.3 class 1 = 0.613 +- 0.295 (in-sample avg dev_std = 0.601)
SUFF++ for r=0.3 class 2 = 0.467 +- 0.295 (in-sample avg dev_std = 0.601)
SUFF++ for r=0.3 all KL = 0.377 +- 0.295 (in-sample avg dev_std = 0.601)
SUFF++ for r=0.3 all L1 = 0.466 +- 0.202 (in-sample avg dev_std = 0.601)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.836
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.24403000000000002
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.487
SUFF++ for r=0.6 class 0 = 0.421 +- 0.312 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.6 class 1 = 0.56 +- 0.312 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.6 class 2 = 0.379 +- 0.312 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.6 all KL = 0.398 +- 0.312 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.6 all L1 = 0.454 +- 0.169 (in-sample avg dev_std = 0.580)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.842
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.25481000000000004
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.562
SUFF++ for r=0.9 class 0 = 0.591 +- 0.315 (in-sample avg dev_std = 0.373)
SUFF++ for r=0.9 class 1 = 0.593 +- 0.315 (in-sample avg dev_std = 0.373)
SUFF++ for r=0.9 class 2 = 0.526 +- 0.315 (in-sample avg dev_std = 0.373)
SUFF++ for r=0.9 all KL = 0.584 +- 0.315 (in-sample avg dev_std = 0.373)
SUFF++ for r=0.9 all L1 = 0.57 +- 0.233 (in-sample avg dev_std = 0.373)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.644
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.22788624999999998
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.438
NEC for r=0.3 class 0 = 0.555 +- 0.304 (in-sample avg dev_std = 0.530)
NEC for r=0.3 class 1 = 0.412 +- 0.304 (in-sample avg dev_std = 0.530)
NEC for r=0.3 class 2 = 0.499 +- 0.304 (in-sample avg dev_std = 0.530)
NEC for r=0.3 all KL = 0.591 +- 0.304 (in-sample avg dev_std = 0.530)
NEC for r=0.3 all L1 = 0.489 +- 0.229 (in-sample avg dev_std = 0.530)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.902
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.2825625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.54
NEC for r=0.6 class 0 = 0.582 +- 0.300 (in-sample avg dev_std = 0.600)
NEC for r=0.6 class 1 = 0.496 +- 0.300 (in-sample avg dev_std = 0.600)
NEC for r=0.6 class 2 = 0.508 +- 0.300 (in-sample avg dev_std = 0.600)
NEC for r=0.6 all KL = 0.637 +- 0.300 (in-sample avg dev_std = 0.600)
NEC for r=0.6 all L1 = 0.528 +- 0.182 (in-sample avg dev_std = 0.600)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.931
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.3080375
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.537
NEC for r=0.9 class 0 = 0.532 +- 0.291 (in-sample avg dev_std = 0.572)
NEC for r=0.9 class 1 = 0.505 +- 0.291 (in-sample avg dev_std = 0.572)
NEC for r=0.9 class 2 = 0.533 +- 0.291 (in-sample avg dev_std = 0.572)
NEC for r=0.9 all KL = 0.574 +- 0.291 (in-sample avg dev_std = 0.572)
NEC for r=0.9 all L1 = 0.523 +- 0.162 (in-sample avg dev_std = 0.572)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.934
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.30861875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.537
NEC for r=1.0 class 0 = 0.534 +- 0.291 (in-sample avg dev_std = 0.566)
NEC for r=1.0 class 1 = 0.525 +- 0.291 (in-sample avg dev_std = 0.566)
NEC for r=1.0 class 2 = 0.522 +- 0.291 (in-sample avg dev_std = 0.566)
NEC for r=1.0 all KL = 0.576 +- 0.291 (in-sample avg dev_std = 0.566)
NEC for r=1.0 all L1 = 0.527 +- 0.162 (in-sample avg dev_std = 0.566)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.68
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.20202375
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.546
NEC for r=0.3 class 0 = 0.587 +- 0.324 (in-sample avg dev_std = 0.554)
NEC for r=0.3 class 1 = 0.322 +- 0.324 (in-sample avg dev_std = 0.554)
NEC for r=0.3 class 2 = 0.453 +- 0.324 (in-sample avg dev_std = 0.554)
NEC for r=0.3 all KL = 0.524 +- 0.324 (in-sample avg dev_std = 0.554)
NEC for r=0.3 all L1 = 0.452 +- 0.233 (in-sample avg dev_std = 0.554)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.836
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.24403000000000002
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.566
NEC for r=0.6 class 0 = 0.5 +- 0.330 (in-sample avg dev_std = 0.611)
NEC for r=0.6 class 1 = 0.4 +- 0.330 (in-sample avg dev_std = 0.611)
NEC for r=0.6 class 2 = 0.515 +- 0.330 (in-sample avg dev_std = 0.611)
NEC for r=0.6 all KL = 0.519 +- 0.330 (in-sample avg dev_std = 0.611)
NEC for r=0.6 all L1 = 0.471 +- 0.184 (in-sample avg dev_std = 0.611)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.842
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.25481000000000004
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.611
NEC for r=0.9 class 0 = 0.445 +- 0.317 (in-sample avg dev_std = 0.593)
NEC for r=0.9 class 1 = 0.414 +- 0.317 (in-sample avg dev_std = 0.593)
NEC for r=0.9 class 2 = 0.428 +- 0.317 (in-sample avg dev_std = 0.593)
NEC for r=0.9 all KL = 0.47 +- 0.317 (in-sample avg dev_std = 0.593)
NEC for r=0.9 all L1 = 0.428 +- 0.171 (in-sample avg dev_std = 0.593)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.846
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.25552375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.586
NEC for r=1.0 class 0 = 0.455 +- 0.317 (in-sample avg dev_std = 0.594)
NEC for r=1.0 class 1 = 0.43 +- 0.317 (in-sample avg dev_std = 0.594)
NEC for r=1.0 class 2 = 0.46 +- 0.317 (in-sample avg dev_std = 0.594)
NEC for r=1.0 all KL = 0.493 +- 0.317 (in-sample avg dev_std = 0.594)
NEC for r=1.0 all L1 = 0.448 +- 0.164 (in-sample avg dev_std = 0.594)
model_dirname= repr_LECIGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 14:21:32 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:32 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 171...
[0m[1;37mINFO[0m: [1mCheckpoint 171: 
-----------------------------------
Train ACCURACY: 0.9011
Train Loss: 0.4339
ID Validation ACCURACY: 0.9127
ID Validation Loss: 0.4039
ID Test ACCURACY: 0.9043
ID Test Loss: 0.4420
OOD Validation ACCURACY: 0.9230
OOD Validation Loss: 0.4746
OOD Test ACCURACY: 0.8267
OOD Test Loss: 0.4981

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 143...
[0m[1;37mINFO[0m: [1mCheckpoint 143: 
-----------------------------------
Train ACCURACY: 0.8969
Train Loss: 0.4316
ID Validation ACCURACY: 0.9050
ID Validation Loss: 0.4049
ID Test ACCURACY: 0.8977
ID Test Loss: 0.4367
OOD Validation ACCURACY: 0.9297
OOD Validation Loss: 0.4768
OOD Test ACCURACY: 0.8177
OOD Test Loss: 0.5880

[0m[1;37mINFO[0m: [1mChartInfo 0.9043 0.8267 0.8977 0.8177 0.9050 0.9297[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.232
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.285
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.315
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.316
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.211
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.238
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.253
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.253


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.678
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.231735
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.383
SUFF++ for r=0.3 class 0 = 0.336 +- 0.279 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 class 1 = 0.557 +- 0.279 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 class 2 = 0.44 +- 0.279 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 all KL = 0.347 +- 0.279 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 all L1 = 0.445 +- 0.192 (in-sample avg dev_std = 0.563)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.882
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.28526
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.467
SUFF++ for r=0.6 class 0 = 0.334 +- 0.268 (in-sample avg dev_std = 0.601)
SUFF++ for r=0.6 class 1 = 0.534 +- 0.268 (in-sample avg dev_std = 0.601)
SUFF++ for r=0.6 class 2 = 0.356 +- 0.268 (in-sample avg dev_std = 0.601)
SUFF++ for r=0.6 all KL = 0.306 +- 0.268 (in-sample avg dev_std = 0.601)
SUFF++ for r=0.6 all L1 = 0.408 +- 0.164 (in-sample avg dev_std = 0.601)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.915
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.3151625
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.719
SUFF++ for r=0.9 class 0 = 0.6 +- 0.320 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.9 class 1 = 0.664 +- 0.320 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.9 class 2 = 0.669 +- 0.320 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.9 all KL = 0.648 +- 0.320 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.9 all L1 = 0.644 +- 0.237 (in-sample avg dev_std = 0.398)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.582
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.21104124999999996
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.425
SUFF++ for r=0.3 class 0 = 0.357 +- 0.277 (in-sample avg dev_std = 0.628)
SUFF++ for r=0.3 class 1 = 0.588 +- 0.277 (in-sample avg dev_std = 0.628)
SUFF++ for r=0.3 class 2 = 0.473 +- 0.277 (in-sample avg dev_std = 0.628)
SUFF++ for r=0.3 all KL = 0.372 +- 0.277 (in-sample avg dev_std = 0.628)
SUFF++ for r=0.3 all L1 = 0.475 +- 0.178 (in-sample avg dev_std = 0.628)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.812
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.23755375
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.499
SUFF++ for r=0.6 class 0 = 0.402 +- 0.281 (in-sample avg dev_std = 0.610)
SUFF++ for r=0.6 class 1 = 0.538 +- 0.281 (in-sample avg dev_std = 0.610)
SUFF++ for r=0.6 class 2 = 0.385 +- 0.281 (in-sample avg dev_std = 0.610)
SUFF++ for r=0.6 all KL = 0.377 +- 0.281 (in-sample avg dev_std = 0.610)
SUFF++ for r=0.6 all L1 = 0.443 +- 0.153 (in-sample avg dev_std = 0.610)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.816
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.2525125
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.705
SUFF++ for r=0.9 class 0 = 0.626 +- 0.289 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.9 class 1 = 0.664 +- 0.289 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.9 class 2 = 0.677 +- 0.289 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.9 all KL = 0.681 +- 0.289 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.9 all L1 = 0.656 +- 0.210 (in-sample avg dev_std = 0.409)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.678
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.231735
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.433
NEC for r=0.3 class 0 = 0.616 +- 0.293 (in-sample avg dev_std = 0.545)
NEC for r=0.3 class 1 = 0.416 +- 0.293 (in-sample avg dev_std = 0.545)
NEC for r=0.3 class 2 = 0.487 +- 0.293 (in-sample avg dev_std = 0.545)
NEC for r=0.3 all KL = 0.605 +- 0.293 (in-sample avg dev_std = 0.545)
NEC for r=0.3 all L1 = 0.506 +- 0.214 (in-sample avg dev_std = 0.545)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.28526
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.546
NEC for r=0.6 class 0 = 0.601 +- 0.289 (in-sample avg dev_std = 0.615)
NEC for r=0.6 class 1 = 0.483 +- 0.289 (in-sample avg dev_std = 0.615)
NEC for r=0.6 class 2 = 0.537 +- 0.289 (in-sample avg dev_std = 0.615)
NEC for r=0.6 all KL = 0.637 +- 0.289 (in-sample avg dev_std = 0.615)
NEC for r=0.6 all L1 = 0.54 +- 0.177 (in-sample avg dev_std = 0.615)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.915
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.3151625
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.565
NEC for r=0.9 class 0 = 0.546 +- 0.292 (in-sample avg dev_std = 0.586)
NEC for r=0.9 class 1 = 0.485 +- 0.292 (in-sample avg dev_std = 0.586)
NEC for r=0.9 class 2 = 0.521 +- 0.292 (in-sample avg dev_std = 0.586)
NEC for r=0.9 all KL = 0.569 +- 0.292 (in-sample avg dev_std = 0.586)
NEC for r=0.9 all L1 = 0.517 +- 0.163 (in-sample avg dev_std = 0.586)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.92
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.31573875000000007
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.557
NEC for r=1.0 class 0 = 0.534 +- 0.289 (in-sample avg dev_std = 0.577)
NEC for r=1.0 class 1 = 0.5 +- 0.289 (in-sample avg dev_std = 0.577)
NEC for r=1.0 class 2 = 0.512 +- 0.289 (in-sample avg dev_std = 0.577)
NEC for r=1.0 all KL = 0.561 +- 0.289 (in-sample avg dev_std = 0.577)
NEC for r=1.0 all L1 = 0.516 +- 0.163 (in-sample avg dev_std = 0.577)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.582
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.21104124999999996
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.532
NEC for r=0.3 class 0 = 0.584 +- 0.290 (in-sample avg dev_std = 0.501)
NEC for r=0.3 class 1 = 0.318 +- 0.290 (in-sample avg dev_std = 0.501)
NEC for r=0.3 class 2 = 0.34 +- 0.290 (in-sample avg dev_std = 0.501)
NEC for r=0.3 all KL = 0.475 +- 0.290 (in-sample avg dev_std = 0.501)
NEC for r=0.3 all L1 = 0.411 +- 0.221 (in-sample avg dev_std = 0.501)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.812
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.23755375
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.604
NEC for r=0.6 class 0 = 0.521 +- 0.317 (in-sample avg dev_std = 0.608)
NEC for r=0.6 class 1 = 0.417 +- 0.317 (in-sample avg dev_std = 0.608)
NEC for r=0.6 class 2 = 0.464 +- 0.317 (in-sample avg dev_std = 0.608)
NEC for r=0.6 all KL = 0.518 +- 0.317 (in-sample avg dev_std = 0.608)
NEC for r=0.6 all L1 = 0.467 +- 0.191 (in-sample avg dev_std = 0.608)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.816
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.2525125
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.615
NEC for r=0.9 class 0 = 0.487 +- 0.299 (in-sample avg dev_std = 0.581)
NEC for r=0.9 class 1 = 0.428 +- 0.299 (in-sample avg dev_std = 0.581)
NEC for r=0.9 class 2 = 0.432 +- 0.299 (in-sample avg dev_std = 0.581)
NEC for r=0.9 all KL = 0.467 +- 0.299 (in-sample avg dev_std = 0.581)
NEC for r=0.9 all L1 = 0.449 +- 0.170 (in-sample avg dev_std = 0.581)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.825
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.25323
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.613
NEC for r=1.0 class 0 = 0.484 +- 0.292 (in-sample avg dev_std = 0.598)
NEC for r=1.0 class 1 = 0.423 +- 0.292 (in-sample avg dev_std = 0.598)
NEC for r=1.0 class 2 = 0.432 +- 0.292 (in-sample avg dev_std = 0.598)
NEC for r=1.0 all KL = 0.47 +- 0.292 (in-sample avg dev_std = 0.598)
NEC for r=1.0 all L1 = 0.446 +- 0.165 (in-sample avg dev_std = 0.598)
model_dirname= repr_LECIGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 14:24:28 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:28 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 134...
[0m[1;37mINFO[0m: [1mCheckpoint 134: 
-----------------------------------
Train ACCURACY: 0.8988
Train Loss: 0.4539
ID Validation ACCURACY: 0.9030
ID Validation Loss: 0.4374
ID Test ACCURACY: 0.8997
ID Test Loss: 0.4667
OOD Validation ACCURACY: 0.9270
OOD Validation Loss: 0.4777
OOD Test ACCURACY: 0.8460
OOD Test Loss: 0.5987

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 137...
[0m[1;37mINFO[0m: [1mCheckpoint 137: 
-----------------------------------
Train ACCURACY: 0.8639
Train Loss: 0.4728
ID Validation ACCURACY: 0.8680
ID Validation Loss: 0.4616
ID Test ACCURACY: 0.8647
ID Test Loss: 0.4806
OOD Validation ACCURACY: 0.9313
OOD Validation Loss: 0.4486
OOD Test ACCURACY: 0.7277
OOD Test Loss: 0.7415

[0m[1;37mINFO[0m: [1mChartInfo 0.8997 0.8460 0.8647 0.7277 0.8680 0.9313[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.192
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.268
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.307
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.307
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.169
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.229
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.247
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.254


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.63
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.19161500000000004
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.37
SUFF++ for r=0.3 class 0 = 0.401 +- 0.256 (in-sample avg dev_std = 0.598)
SUFF++ for r=0.3 class 1 = 0.523 +- 0.256 (in-sample avg dev_std = 0.598)
SUFF++ for r=0.3 class 2 = 0.378 +- 0.256 (in-sample avg dev_std = 0.598)
SUFF++ for r=0.3 all KL = 0.32 +- 0.256 (in-sample avg dev_std = 0.598)
SUFF++ for r=0.3 all L1 = 0.434 +- 0.161 (in-sample avg dev_std = 0.598)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.894
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.2678025
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.451
SUFF++ for r=0.6 class 0 = 0.375 +- 0.259 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.6 class 1 = 0.449 +- 0.259 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.6 class 2 = 0.334 +- 0.259 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.6 all KL = 0.308 +- 0.259 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.6 all L1 = 0.387 +- 0.137 (in-sample avg dev_std = 0.554)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.911
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.30668500000000004
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.66
SUFF++ for r=0.9 class 0 = 0.627 +- 0.324 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.9 class 1 = 0.654 +- 0.324 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.9 class 2 = 0.546 +- 0.324 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.9 all KL = 0.621 +- 0.324 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.9 all L1 = 0.609 +- 0.227 (in-sample avg dev_std = 0.388)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.465
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.16940000000000002
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.402
SUFF++ for r=0.3 class 0 = 0.434 +- 0.227 (in-sample avg dev_std = 0.641)
SUFF++ for r=0.3 class 1 = 0.442 +- 0.227 (in-sample avg dev_std = 0.641)
SUFF++ for r=0.3 class 2 = 0.454 +- 0.227 (in-sample avg dev_std = 0.641)
SUFF++ for r=0.3 all KL = 0.309 +- 0.227 (in-sample avg dev_std = 0.641)
SUFF++ for r=0.3 all L1 = 0.443 +- 0.156 (in-sample avg dev_std = 0.641)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.749
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.22867375000000004
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.471
SUFF++ for r=0.6 class 0 = 0.447 +- 0.239 (in-sample avg dev_std = 0.631)
SUFF++ for r=0.6 class 1 = 0.396 +- 0.239 (in-sample avg dev_std = 0.631)
SUFF++ for r=0.6 class 2 = 0.381 +- 0.239 (in-sample avg dev_std = 0.631)
SUFF++ for r=0.6 all KL = 0.3 +- 0.239 (in-sample avg dev_std = 0.631)
SUFF++ for r=0.6 all L1 = 0.408 +- 0.134 (in-sample avg dev_std = 0.631)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.855
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.24740750000000003
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.607
SUFF++ for r=0.9 class 0 = 0.675 +- 0.287 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.9 class 1 = 0.509 +- 0.287 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.9 class 2 = 0.547 +- 0.287 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.9 all KL = 0.586 +- 0.287 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.9 all L1 = 0.575 +- 0.213 (in-sample avg dev_std = 0.388)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.63
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.19161500000000004
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.428
NEC for r=0.3 class 0 = 0.514 +- 0.295 (in-sample avg dev_std = 0.545)
NEC for r=0.3 class 1 = 0.402 +- 0.295 (in-sample avg dev_std = 0.545)
NEC for r=0.3 class 2 = 0.557 +- 0.295 (in-sample avg dev_std = 0.545)
NEC for r=0.3 all KL = 0.582 +- 0.295 (in-sample avg dev_std = 0.545)
NEC for r=0.3 all L1 = 0.49 +- 0.204 (in-sample avg dev_std = 0.545)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.895
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.2678025
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.509
NEC for r=0.6 class 0 = 0.585 +- 0.286 (in-sample avg dev_std = 0.573)
NEC for r=0.6 class 1 = 0.512 +- 0.286 (in-sample avg dev_std = 0.573)
NEC for r=0.6 class 2 = 0.586 +- 0.286 (in-sample avg dev_std = 0.573)
NEC for r=0.6 all KL = 0.631 +- 0.286 (in-sample avg dev_std = 0.573)
NEC for r=0.6 all L1 = 0.561 +- 0.161 (in-sample avg dev_std = 0.573)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.911
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.30668500000000004
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.522
NEC for r=0.9 class 0 = 0.521 +- 0.284 (in-sample avg dev_std = 0.527)
NEC for r=0.9 class 1 = 0.516 +- 0.284 (in-sample avg dev_std = 0.527)
NEC for r=0.9 class 2 = 0.561 +- 0.284 (in-sample avg dev_std = 0.527)
NEC for r=0.9 all KL = 0.556 +- 0.284 (in-sample avg dev_std = 0.527)
NEC for r=0.9 all L1 = 0.533 +- 0.148 (in-sample avg dev_std = 0.527)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.913
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.30730375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.529
NEC for r=1.0 class 0 = 0.517 +- 0.288 (in-sample avg dev_std = 0.522)
NEC for r=1.0 class 1 = 0.519 +- 0.288 (in-sample avg dev_std = 0.522)
NEC for r=1.0 class 2 = 0.549 +- 0.288 (in-sample avg dev_std = 0.522)
NEC for r=1.0 all KL = 0.542 +- 0.288 (in-sample avg dev_std = 0.522)
NEC for r=1.0 all L1 = 0.528 +- 0.152 (in-sample avg dev_std = 0.522)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.468
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.16940000000000002
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.478
NEC for r=0.3 class 0 = 0.496 +- 0.282 (in-sample avg dev_std = 0.603)
NEC for r=0.3 class 1 = 0.51 +- 0.282 (in-sample avg dev_std = 0.603)
NEC for r=0.3 class 2 = 0.435 +- 0.282 (in-sample avg dev_std = 0.603)
NEC for r=0.3 all KL = 0.594 +- 0.282 (in-sample avg dev_std = 0.603)
NEC for r=0.3 all L1 = 0.48 +- 0.206 (in-sample avg dev_std = 0.603)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.749
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.22867375000000004
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.577
NEC for r=0.6 class 0 = 0.523 +- 0.263 (in-sample avg dev_std = 0.607)
NEC for r=0.6 class 1 = 0.56 +- 0.263 (in-sample avg dev_std = 0.607)
NEC for r=0.6 class 2 = 0.498 +- 0.263 (in-sample avg dev_std = 0.607)
NEC for r=0.6 all KL = 0.617 +- 0.263 (in-sample avg dev_std = 0.607)
NEC for r=0.6 all L1 = 0.527 +- 0.166 (in-sample avg dev_std = 0.607)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.855
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.24740750000000003
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.606
NEC for r=0.9 class 0 = 0.404 +- 0.264 (in-sample avg dev_std = 0.542)
NEC for r=0.9 class 1 = 0.503 +- 0.264 (in-sample avg dev_std = 0.542)
NEC for r=0.9 class 2 = 0.463 +- 0.264 (in-sample avg dev_std = 0.542)
NEC for r=0.9 all KL = 0.488 +- 0.264 (in-sample avg dev_std = 0.542)
NEC for r=0.9 all L1 = 0.457 +- 0.139 (in-sample avg dev_std = 0.542)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.858
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.253545
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.603
NEC for r=1.0 class 0 = 0.384 +- 0.250 (in-sample avg dev_std = 0.534)
NEC for r=1.0 class 1 = 0.5 +- 0.250 (in-sample avg dev_std = 0.534)
NEC for r=1.0 class 2 = 0.471 +- 0.250 (in-sample avg dev_std = 0.534)
NEC for r=1.0 all KL = 0.469 +- 0.250 (in-sample avg dev_std = 0.534)
NEC for r=1.0 all L1 = 0.453 +- 0.142 (in-sample avg dev_std = 0.534)
model_dirname= repr_LECIGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 14:27:11 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:11 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 150...
[0m[1;37mINFO[0m: [1mCheckpoint 150: 
-----------------------------------
Train ACCURACY: 0.9096
Train Loss: 0.4091
ID Validation ACCURACY: 0.9127
ID Validation Loss: 0.3875
ID Test ACCURACY: 0.9030
ID Test Loss: 0.4331
OOD Validation ACCURACY: 0.9240
OOD Validation Loss: 0.4585
OOD Test ACCURACY: 0.8997
OOD Test Loss: 0.4258

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 109...
[0m[1;37mINFO[0m: [1mCheckpoint 109: 
-----------------------------------
Train ACCURACY: 0.8893
Train Loss: 0.4702
ID Validation ACCURACY: 0.8970
ID Validation Loss: 0.4634
ID Test ACCURACY: 0.8937
ID Test Loss: 0.4939
OOD Validation ACCURACY: 0.9293
OOD Validation Loss: 0.4938
OOD Test ACCURACY: 0.8903
OOD Test Loss: 0.4810

[0m[1;37mINFO[0m: [1mChartInfo 0.9030 0.8997 0.8937 0.8903 0.8970 0.9293[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.218
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.282
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.311
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.312
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.201
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.241
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.255
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.256


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.507
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.21836
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.357
SUFF++ for r=0.3 class 0 = 0.372 +- 0.254 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.3 class 1 = 0.449 +- 0.254 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.3 class 2 = 0.479 +- 0.254 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.3 all KL = 0.348 +- 0.254 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.3 all L1 = 0.433 +- 0.157 (in-sample avg dev_std = 0.557)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.886
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.28174625000000003
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.446
SUFF++ for r=0.6 class 0 = 0.34 +- 0.262 (in-sample avg dev_std = 0.571)
SUFF++ for r=0.6 class 1 = 0.479 +- 0.262 (in-sample avg dev_std = 0.571)
SUFF++ for r=0.6 class 2 = 0.415 +- 0.262 (in-sample avg dev_std = 0.571)
SUFF++ for r=0.6 all KL = 0.331 +- 0.262 (in-sample avg dev_std = 0.571)
SUFF++ for r=0.6 all L1 = 0.411 +- 0.156 (in-sample avg dev_std = 0.571)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.918
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.31108375
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.698
SUFF++ for r=0.9 class 0 = 0.579 +- 0.303 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.9 class 1 = 0.682 +- 0.303 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.9 class 2 = 0.632 +- 0.303 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.9 all KL = 0.652 +- 0.303 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.9 all L1 = 0.631 +- 0.230 (in-sample avg dev_std = 0.387)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.539
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.20082875
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.394
SUFF++ for r=0.3 class 0 = 0.32 +- 0.214 (in-sample avg dev_std = 0.579)
SUFF++ for r=0.3 class 1 = 0.394 +- 0.214 (in-sample avg dev_std = 0.579)
SUFF++ for r=0.3 class 2 = 0.443 +- 0.214 (in-sample avg dev_std = 0.579)
SUFF++ for r=0.3 all KL = 0.261 +- 0.214 (in-sample avg dev_std = 0.579)
SUFF++ for r=0.3 all L1 = 0.387 +- 0.166 (in-sample avg dev_std = 0.579)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.875
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.24135125000000002
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.483
SUFF++ for r=0.6 class 0 = 0.385 +- 0.238 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.6 class 1 = 0.474 +- 0.238 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.6 class 2 = 0.462 +- 0.238 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.6 all KL = 0.379 +- 0.238 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.6 all L1 = 0.442 +- 0.141 (in-sample avg dev_std = 0.580)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.906
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.25478249999999997
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.712
SUFF++ for r=0.9 class 0 = 0.6 +- 0.263 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.9 class 1 = 0.66 +- 0.263 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.9 class 2 = 0.657 +- 0.263 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.9 all KL = 0.685 +- 0.263 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.9 all L1 = 0.64 +- 0.193 (in-sample avg dev_std = 0.383)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.505
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.21836
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.393
NEC for r=0.3 class 0 = 0.547 +- 0.291 (in-sample avg dev_std = 0.537)
NEC for r=0.3 class 1 = 0.46 +- 0.291 (in-sample avg dev_std = 0.537)
NEC for r=0.3 class 2 = 0.495 +- 0.291 (in-sample avg dev_std = 0.537)
NEC for r=0.3 all KL = 0.581 +- 0.291 (in-sample avg dev_std = 0.537)
NEC for r=0.3 all L1 = 0.501 +- 0.199 (in-sample avg dev_std = 0.537)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.886
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.28174625000000003
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.512
NEC for r=0.6 class 0 = 0.581 +- 0.293 (in-sample avg dev_std = 0.574)
NEC for r=0.6 class 1 = 0.529 +- 0.293 (in-sample avg dev_std = 0.574)
NEC for r=0.6 class 2 = 0.515 +- 0.293 (in-sample avg dev_std = 0.574)
NEC for r=0.6 all KL = 0.612 +- 0.293 (in-sample avg dev_std = 0.574)
NEC for r=0.6 all L1 = 0.542 +- 0.180 (in-sample avg dev_std = 0.574)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.918
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.31108375
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.547
NEC for r=0.9 class 0 = 0.542 +- 0.281 (in-sample avg dev_std = 0.559)
NEC for r=0.9 class 1 = 0.494 +- 0.281 (in-sample avg dev_std = 0.559)
NEC for r=0.9 class 2 = 0.519 +- 0.281 (in-sample avg dev_std = 0.559)
NEC for r=0.9 all KL = 0.548 +- 0.281 (in-sample avg dev_std = 0.559)
NEC for r=0.9 all L1 = 0.518 +- 0.162 (in-sample avg dev_std = 0.559)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.921
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.312455
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.551
NEC for r=1.0 class 0 = 0.529 +- 0.287 (in-sample avg dev_std = 0.534)
NEC for r=1.0 class 1 = 0.481 +- 0.287 (in-sample avg dev_std = 0.534)
NEC for r=1.0 class 2 = 0.524 +- 0.287 (in-sample avg dev_std = 0.534)
NEC for r=1.0 all KL = 0.527 +- 0.287 (in-sample avg dev_std = 0.534)
NEC for r=1.0 all L1 = 0.511 +- 0.172 (in-sample avg dev_std = 0.534)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.539
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.20082875
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.461
NEC for r=0.3 class 0 = 0.626 +- 0.299 (in-sample avg dev_std = 0.545)
NEC for r=0.3 class 1 = 0.54 +- 0.299 (in-sample avg dev_std = 0.545)
NEC for r=0.3 class 2 = 0.471 +- 0.299 (in-sample avg dev_std = 0.545)
NEC for r=0.3 all KL = 0.644 +- 0.299 (in-sample avg dev_std = 0.545)
NEC for r=0.3 all L1 = 0.545 +- 0.227 (in-sample avg dev_std = 0.545)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.875
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.24135125000000002
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.55
NEC for r=0.6 class 0 = 0.54 +- 0.274 (in-sample avg dev_std = 0.574)
NEC for r=0.6 class 1 = 0.502 +- 0.274 (in-sample avg dev_std = 0.574)
NEC for r=0.6 class 2 = 0.389 +- 0.274 (in-sample avg dev_std = 0.574)
NEC for r=0.6 all KL = 0.519 +- 0.274 (in-sample avg dev_std = 0.574)
NEC for r=0.6 all L1 = 0.477 +- 0.180 (in-sample avg dev_std = 0.574)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.906
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.25478249999999997
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.595
NEC for r=0.9 class 0 = 0.488 +- 0.272 (in-sample avg dev_std = 0.552)
NEC for r=0.9 class 1 = 0.452 +- 0.272 (in-sample avg dev_std = 0.552)
NEC for r=0.9 class 2 = 0.422 +- 0.272 (in-sample avg dev_std = 0.552)
NEC for r=0.9 all KL = 0.452 +- 0.272 (in-sample avg dev_std = 0.552)
NEC for r=0.9 all L1 = 0.454 +- 0.155 (in-sample avg dev_std = 0.552)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.904
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.2555175
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.601
NEC for r=1.0 class 0 = 0.474 +- 0.268 (in-sample avg dev_std = 0.543)
NEC for r=1.0 class 1 = 0.451 +- 0.268 (in-sample avg dev_std = 0.543)
NEC for r=1.0 class 2 = 0.414 +- 0.268 (in-sample avg dev_std = 0.543)
NEC for r=1.0 all KL = 0.439 +- 0.268 (in-sample avg dev_std = 0.543)
NEC for r=1.0 all L1 = 0.446 +- 0.148 (in-sample avg dev_std = 0.543)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.214, 0.228, 0.582, 1.0], 'all_L1': [0.405, 0.388, 0.635, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.344, 0.299, 0.649, 1.0], 'all_L1': [0.449, 0.405, 0.643, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.347, 0.306, 0.648, 1.0], 'all_L1': [0.445, 0.408, 0.644, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.32, 0.308, 0.621, 1.0], 'all_L1': [0.434, 0.387, 0.609, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.348, 0.331, 0.652, 1.0], 'all_L1': [0.433, 0.411, 0.631, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.686, 0.692, 0.66, 0.652], 'all_L1': [0.511, 0.535, 0.539, 0.538]}), defaultdict(<class 'list'>, {'all_KL': [0.591, 0.637, 0.574, 0.576], 'all_L1': [0.489, 0.528, 0.523, 0.527]}), defaultdict(<class 'list'>, {'all_KL': [0.605, 0.637, 0.569, 0.561], 'all_L1': [0.506, 0.54, 0.517, 0.516]}), defaultdict(<class 'list'>, {'all_KL': [0.582, 0.631, 0.556, 0.542], 'all_L1': [0.49, 0.561, 0.533, 0.528]}), defaultdict(<class 'list'>, {'all_KL': [0.581, 0.612, 0.548, 0.527], 'all_L1': [0.501, 0.542, 0.518, 0.511]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.134, 0.226, 0.596, 1.0], 'all_L1': [0.372, 0.402, 0.614, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.377, 0.398, 0.584, 1.0], 'all_L1': [0.466, 0.454, 0.57, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.372, 0.377, 0.681, 1.0], 'all_L1': [0.475, 0.443, 0.656, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.309, 0.3, 0.586, 1.0], 'all_L1': [0.443, 0.408, 0.575, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.261, 0.379, 0.685, 1.0], 'all_L1': [0.387, 0.442, 0.64, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.742, 0.633, 0.5, 0.503], 'all_L1': [0.525, 0.485, 0.424, 0.425]}), defaultdict(<class 'list'>, {'all_KL': [0.524, 0.519, 0.47, 0.493], 'all_L1': [0.452, 0.471, 0.428, 0.448]}), defaultdict(<class 'list'>, {'all_KL': [0.475, 0.518, 0.467, 0.47], 'all_L1': [0.411, 0.467, 0.449, 0.446]}), defaultdict(<class 'list'>, {'all_KL': [0.594, 0.617, 0.488, 0.469], 'all_L1': [0.48, 0.527, 0.457, 0.453]}), defaultdict(<class 'list'>, {'all_KL': [0.644, 0.519, 0.452, 0.439], 'all_L1': [0.545, 0.477, 0.454, 0.446]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.433 +- 0.015, 0.400 +- 0.010, 0.632 +- 0.013, 1.000 +- 0.000
suff++ class all_KL  =  0.315 +- 0.051, 0.294 +- 0.035, 0.630 +- 0.027, 1.000 +- 0.000
suff++_acc_int  =  0.377 +- 0.014, 0.456 +- 0.007, 0.691 +- 0.020
nec class all_L1  =  0.499 +- 0.009, 0.541 +- 0.011, 0.526 +- 0.009, 0.524 +- 0.010
nec class all_KL  =  0.609 +- 0.039, 0.642 +- 0.027, 0.581 +- 0.040, 0.572 +- 0.043
nec_acc_int  =  0.426 +- 0.017, 0.529 +- 0.015, 0.540 +- 0.015, 0.542 +- 0.010

Eval split test
suff++ class all_L1  =  0.429 +- 0.042, 0.430 +- 0.021, 0.611 +- 0.034, 1.000 +- 0.000
suff++ class all_KL  =  0.291 +- 0.089, 0.336 +- 0.064, 0.626 +- 0.046, 1.000 +- 0.000
suff++_acc_int  =  0.414 +- 0.015, 0.482 +- 0.011, 0.650 +- 0.058
nec class all_L1  =  0.483 +- 0.048, 0.485 +- 0.022, 0.442 +- 0.014, 0.444 +- 0.010
nec class all_KL  =  0.596 +- 0.093, 0.561 +- 0.052, 0.475 +- 0.017, 0.475 +- 0.022
nec_acc_int  =  0.504 +- 0.032, 0.574 +- 0.018, 0.615 +- 0.017, 0.610 +- 0.020


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.466 +- 0.006, 0.470 +- 0.006, 0.579 +- 0.006, 0.762 +- 0.005
Faith. Armon (L1)= 		  =  0.464 +- 0.007, 0.460 +- 0.006, 0.574 +- 0.005, 0.688 +- 0.008
Faith. GMean (L1)= 	  =  0.465 +- 0.007, 0.465 +- 0.006, 0.577 +- 0.006, 0.724 +- 0.007
Faith. Aritm (KL)= 		  =  0.462 +- 0.010, 0.468 +- 0.004, 0.606 +- 0.011, 0.786 +- 0.022
Faith. Armon (KL)= 		  =  0.410 +- 0.043, 0.401 +- 0.030, 0.603 +- 0.011, 0.726 +- 0.034
Faith. GMean (KL)= 	  =  0.435 +- 0.027, 0.433 +- 0.019, 0.605 +- 0.011, 0.756 +- 0.028

Eval split test
Faith. Aritm (L1)= 		  =  0.456 +- 0.009, 0.458 +- 0.008, 0.527 +- 0.020, 0.722 +- 0.005
Faith. Armon (L1)= 		  =  0.450 +- 0.010, 0.455 +- 0.008, 0.513 +- 0.017, 0.615 +- 0.009
Faith. GMean (L1)= 	  =  0.453 +- 0.009, 0.456 +- 0.008, 0.520 +- 0.018, 0.666 +- 0.007
Faith. Aritm (KL)= 		  =  0.443 +- 0.011, 0.449 +- 0.011, 0.551 +- 0.018, 0.737 +- 0.011
Faith. Armon (KL)= 		  =  0.372 +- 0.076, 0.412 +- 0.043, 0.539 +- 0.011, 0.644 +- 0.021
Faith. GMean (KL)= 	  =  0.404 +- 0.046, 0.430 +- 0.027, 0.545 +- 0.014, 0.689 +- 0.016
Computed for split load_split = id



Completed in  0:13:48.697783  for LECIGIN GOODMotif2/basis



DONE LECI GOODMotif2/basis
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 14:30:08 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:09 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:09 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:09 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:30:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:09 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:30:09 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:30:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:09 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:30:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:09 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:30:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:09 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:30:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:30:10 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 171...
[0m[1;37mINFO[0m: [1mCheckpoint 171: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0751
ID Validation ACCURACY: 0.8762
ID Validation Loss: 0.4772
ID Test ACCURACY: 0.8732
ID Test Loss: 0.5405
OOD Validation ACCURACY: 0.8785
OOD Validation Loss: 0.6693
OOD Test ACCURACY: 0.8286
OOD Test Loss: 1.1668

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 155...
[0m[1;37mINFO[0m: [1mCheckpoint 155: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0752
ID Validation ACCURACY: 0.8738
ID Validation Loss: 0.4331
ID Test ACCURACY: 0.8747
ID Test Loss: 0.4825
OOD Validation ACCURACY: 0.8831
OOD Validation Loss: 0.5611
OOD Test ACCURACY: 0.8341
OOD Test Loss: 0.9574

[0m[1;37mINFO[0m: [1mChartInfo 0.8732 0.8286 0.8747 0.8341 0.8738 0.8831[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/28/2024 02:30:13 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.87
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.853
SUFF++ for r=0.6 class 0.0 = 0.883 +- 0.280 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.6 class 1.0 = 0.929 +- 0.280 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.6 all KL = 0.858 +- 0.280 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.6 all L1 = 0.91 +- 0.168 (in-sample avg dev_std = 0.277)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.856
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.871
SUFF++ for r=0.9 class 0.0 = 0.936 +- 0.185 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 class 1.0 = 0.945 +- 0.185 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 all KL = 0.941 +- 0.185 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 all L1 = 0.941 +- 0.160 (in-sample avg dev_std = 0.152)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.762
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.732
SUFF++ for r=0.3 class 0.0 = 0.836 +- 0.273 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.3 class 1.0 = 0.913 +- 0.273 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.3 all KL = 0.813 +- 0.273 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.3 all L1 = 0.876 +- 0.178 (in-sample avg dev_std = 0.338)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.811
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.797
SUFF++ for r=0.6 class 0.0 = 0.87 +- 0.220 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.6 class 1.0 = 0.926 +- 0.220 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.6 all KL = 0.876 +- 0.220 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.6 all L1 = 0.899 +- 0.174 (in-sample avg dev_std = 0.242)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.834
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.832
SUFF++ for r=0.9 class 0.0 = 0.938 +- 0.135 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.9 class 1.0 = 0.965 +- 0.135 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.9 all KL = 0.953 +- 0.135 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.9 all L1 = 0.952 +- 0.111 (in-sample avg dev_std = 0.172)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.87
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.869
NEC for r=0.6 class 0.0 = 0.085 +- 0.163 (in-sample avg dev_std = 0.141)
NEC for r=0.6 class 1.0 = 0.047 +- 0.163 (in-sample avg dev_std = 0.141)
NEC for r=0.6 all KL = 0.06 +- 0.163 (in-sample avg dev_std = 0.141)
NEC for r=0.6 all L1 = 0.063 +- 0.145 (in-sample avg dev_std = 0.141)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.867
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.868
NEC for r=0.9 class 0.0 = 0.051 +- 0.174 (in-sample avg dev_std = 0.117)
NEC for r=0.9 class 1.0 = 0.045 +- 0.174 (in-sample avg dev_std = 0.117)
NEC for r=0.9 all KL = 0.048 +- 0.174 (in-sample avg dev_std = 0.117)
NEC for r=0.9 all L1 = 0.047 +- 0.150 (in-sample avg dev_std = 0.117)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.884
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.871
NEC for r=1.0 class 0.0 = 0.029 +- 0.131 (in-sample avg dev_std = 0.108)
NEC for r=1.0 class 1.0 = 0.03 +- 0.131 (in-sample avg dev_std = 0.108)
NEC for r=1.0 all KL = 0.026 +- 0.131 (in-sample avg dev_std = 0.108)
NEC for r=1.0 all L1 = 0.029 +- 0.113 (in-sample avg dev_std = 0.108)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.762
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.753
NEC for r=0.3 class 0.0 = 0.128 +- 0.210 (in-sample avg dev_std = 0.181)
NEC for r=0.3 class 1.0 = 0.061 +- 0.210 (in-sample avg dev_std = 0.181)
NEC for r=0.3 all KL = 0.09 +- 0.210 (in-sample avg dev_std = 0.181)
NEC for r=0.3 all L1 = 0.093 +- 0.185 (in-sample avg dev_std = 0.181)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.811
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.8
NEC for r=0.6 class 0.0 = 0.095 +- 0.152 (in-sample avg dev_std = 0.138)
NEC for r=0.6 class 1.0 = 0.051 +- 0.152 (in-sample avg dev_std = 0.138)
NEC for r=0.6 all KL = 0.056 +- 0.152 (in-sample avg dev_std = 0.138)
NEC for r=0.6 all L1 = 0.072 +- 0.161 (in-sample avg dev_std = 0.138)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.834
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.836
NEC for r=0.9 class 0.0 = 0.056 +- 0.103 (in-sample avg dev_std = 0.118)
NEC for r=0.9 class 1.0 = 0.035 +- 0.103 (in-sample avg dev_std = 0.118)
NEC for r=0.9 all KL = 0.032 +- 0.103 (in-sample avg dev_std = 0.118)
NEC for r=0.9 all L1 = 0.045 +- 0.114 (in-sample avg dev_std = 0.118)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.836
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.833
NEC for r=1.0 class 0.0 = 0.043 +- 0.080 (in-sample avg dev_std = 0.097)
NEC for r=1.0 class 1.0 = 0.022 +- 0.080 (in-sample avg dev_std = 0.097)
NEC for r=1.0 all KL = 0.02 +- 0.080 (in-sample avg dev_std = 0.097)
NEC for r=1.0 all L1 = 0.032 +- 0.092 (in-sample avg dev_std = 0.097)
model_dirname= repr_LECIvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 14:32:26 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:32:27 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 199...
[0m[1;37mINFO[0m: [1mCheckpoint 199: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0750
ID Validation ACCURACY: 0.8810
ID Validation Loss: 0.5004
ID Test ACCURACY: 0.8753
ID Test Loss: 0.5729
OOD Validation ACCURACY: 0.8835
OOD Validation Loss: 0.6764
OOD Test ACCURACY: 0.8298
OOD Test Loss: 1.2856

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 198...
[0m[1;37mINFO[0m: [1mCheckpoint 198: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0751
ID Validation ACCURACY: 0.8795
ID Validation Loss: 0.4785
ID Test ACCURACY: 0.8753
ID Test Loss: 0.5475
OOD Validation ACCURACY: 0.8846
OOD Validation Loss: 0.6262
OOD Test ACCURACY: 0.8300
OOD Test Loss: 1.0355

[0m[1;37mINFO[0m: [1mChartInfo 0.8753 0.8298 0.8753 0.8300 0.8795 0.8846[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/28/2024 02:32:29 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.867
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.868
SUFF++ for r=0.6 class 0.0 = 0.927 +- 0.196 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.6 class 1.0 = 0.948 +- 0.196 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.6 all KL = 0.922 +- 0.196 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.6 all L1 = 0.939 +- 0.130 (in-sample avg dev_std = 0.201)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.883
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.88
SUFF++ for r=0.9 class 0.0 = 0.94 +- 0.147 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.9 class 1.0 = 0.989 +- 0.147 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.9 all KL = 0.967 +- 0.147 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.9 all L1 = 0.967 +- 0.118 (in-sample avg dev_std = 0.111)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.769
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.74
SUFF++ for r=0.3 class 0.0 = 0.873 +- 0.202 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.3 class 1.0 = 0.931 +- 0.202 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.3 all KL = 0.884 +- 0.202 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.3 all L1 = 0.903 +- 0.149 (in-sample avg dev_std = 0.281)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.799
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.785
SUFF++ for r=0.6 class 0.0 = 0.892 +- 0.161 (in-sample avg dev_std = 0.206)
SUFF++ for r=0.6 class 1.0 = 0.95 +- 0.161 (in-sample avg dev_std = 0.206)
SUFF++ for r=0.6 all KL = 0.922 +- 0.161 (in-sample avg dev_std = 0.206)
SUFF++ for r=0.6 all L1 = 0.922 +- 0.147 (in-sample avg dev_std = 0.206)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.839
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.833
SUFF++ for r=0.9 class 0.0 = 0.958 +- 0.103 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.9 class 1.0 = 0.964 +- 0.103 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.9 all KL = 0.967 +- 0.103 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.9 all L1 = 0.961 +- 0.101 (in-sample avg dev_std = 0.159)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.867
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.873
NEC for r=0.6 class 0.0 = 0.065 +- 0.122 (in-sample avg dev_std = 0.114)
NEC for r=0.6 class 1.0 = 0.039 +- 0.122 (in-sample avg dev_std = 0.114)
NEC for r=0.6 all KL = 0.041 +- 0.122 (in-sample avg dev_std = 0.114)
NEC for r=0.6 all L1 = 0.05 +- 0.123 (in-sample avg dev_std = 0.114)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.884
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.875
NEC for r=0.9 class 0.0 = 0.051 +- 0.148 (in-sample avg dev_std = 0.087)
NEC for r=0.9 class 1.0 = 0.019 +- 0.148 (in-sample avg dev_std = 0.087)
NEC for r=0.9 all KL = 0.033 +- 0.148 (in-sample avg dev_std = 0.087)
NEC for r=0.9 all L1 = 0.032 +- 0.118 (in-sample avg dev_std = 0.087)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.881
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.873
NEC for r=1.0 class 0.0 = 0.041 +- 0.135 (in-sample avg dev_std = 0.073)
NEC for r=1.0 class 1.0 = 0.017 +- 0.135 (in-sample avg dev_std = 0.073)
NEC for r=1.0 all KL = 0.026 +- 0.135 (in-sample avg dev_std = 0.073)
NEC for r=1.0 all L1 = 0.027 +- 0.110 (in-sample avg dev_std = 0.073)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.769
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.764
NEC for r=0.3 class 0.0 = 0.088 +- 0.125 (in-sample avg dev_std = 0.140)
NEC for r=0.3 class 1.0 = 0.041 +- 0.125 (in-sample avg dev_std = 0.140)
NEC for r=0.3 all KL = 0.042 +- 0.125 (in-sample avg dev_std = 0.140)
NEC for r=0.3 all L1 = 0.064 +- 0.134 (in-sample avg dev_std = 0.140)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.799
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.792
NEC for r=0.6 class 0.0 = 0.08 +- 0.109 (in-sample avg dev_std = 0.126)
NEC for r=0.6 class 1.0 = 0.034 +- 0.109 (in-sample avg dev_std = 0.126)
NEC for r=0.6 all KL = 0.035 +- 0.109 (in-sample avg dev_std = 0.126)
NEC for r=0.6 all L1 = 0.056 +- 0.130 (in-sample avg dev_std = 0.126)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.839
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.838
NEC for r=0.9 class 0.0 = 0.052 +- 0.109 (in-sample avg dev_std = 0.120)
NEC for r=0.9 class 1.0 = 0.039 +- 0.109 (in-sample avg dev_std = 0.120)
NEC for r=0.9 all KL = 0.032 +- 0.109 (in-sample avg dev_std = 0.120)
NEC for r=0.9 all L1 = 0.045 +- 0.119 (in-sample avg dev_std = 0.120)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.839
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.838
NEC for r=1.0 class 0.0 = 0.05 +- 0.093 (in-sample avg dev_std = 0.105)
NEC for r=1.0 class 1.0 = 0.031 +- 0.093 (in-sample avg dev_std = 0.105)
NEC for r=1.0 all KL = 0.027 +- 0.093 (in-sample avg dev_std = 0.105)
NEC for r=1.0 all L1 = 0.04 +- 0.110 (in-sample avg dev_std = 0.105)
model_dirname= repr_LECIvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 14:34:47 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:34:48 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 159...
[0m[1;37mINFO[0m: [1mCheckpoint 159: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0752
ID Validation ACCURACY: 0.8796
ID Validation Loss: 0.4389
ID Test ACCURACY: 0.8757
ID Test Loss: 0.4942
OOD Validation ACCURACY: 0.8781
OOD Validation Loss: 0.5616
OOD Test ACCURACY: 0.8223
OOD Test Loss: 0.8763

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 97...
[0m[1;37mINFO[0m: [1mCheckpoint 97: 
-----------------------------------
Train ACCURACY: 0.9488
Train Loss: 0.0772
ID Validation ACCURACY: 0.8764
ID Validation Loss: 0.3801
ID Test ACCURACY: 0.8732
ID Test Loss: 0.4337
OOD Validation ACCURACY: 0.8807
OOD Validation Loss: 0.4866
OOD Test ACCURACY: 0.8229
OOD Test Loss: 0.8869

[0m[1;37mINFO[0m: [1mChartInfo 0.8757 0.8223 0.8732 0.8229 0.8764 0.8807[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/28/2024 02:34:50 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.865
SUFF++ for r=0.6 class 0.0 = 0.924 +- 0.211 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.6 class 1.0 = 0.947 +- 0.211 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.6 all KL = 0.913 +- 0.211 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.6 all L1 = 0.938 +- 0.132 (in-sample avg dev_std = 0.228)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.867
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.866
SUFF++ for r=0.9 class 0.0 = 0.942 +- 0.106 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.9 class 1.0 = 0.969 +- 0.106 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.9 all KL = 0.971 +- 0.106 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.9 all L1 = 0.957 +- 0.114 (in-sample avg dev_std = 0.111)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.759
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.741
SUFF++ for r=0.3 class 0.0 = 0.876 +- 0.169 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.3 class 1.0 = 0.939 +- 0.169 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.3 all KL = 0.907 +- 0.169 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.3 all L1 = 0.909 +- 0.141 (in-sample avg dev_std = 0.243)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.798
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.78
SUFF++ for r=0.6 class 0.0 = 0.894 +- 0.152 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.6 class 1.0 = 0.945 +- 0.152 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.6 all KL = 0.928 +- 0.152 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.6 all L1 = 0.92 +- 0.142 (in-sample avg dev_std = 0.192)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.832
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.832
SUFF++ for r=0.9 class 0.0 = 0.949 +- 0.074 (in-sample avg dev_std = 0.134)
SUFF++ for r=0.9 class 1.0 = 0.967 +- 0.074 (in-sample avg dev_std = 0.134)
SUFF++ for r=0.9 all KL = 0.973 +- 0.074 (in-sample avg dev_std = 0.134)
SUFF++ for r=0.9 all L1 = 0.958 +- 0.090 (in-sample avg dev_std = 0.134)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.873
NEC for r=0.6 class 0.0 = 0.061 +- 0.125 (in-sample avg dev_std = 0.124)
NEC for r=0.6 class 1.0 = 0.035 +- 0.125 (in-sample avg dev_std = 0.124)
NEC for r=0.6 all KL = 0.04 +- 0.125 (in-sample avg dev_std = 0.124)
NEC for r=0.6 all L1 = 0.046 +- 0.112 (in-sample avg dev_std = 0.124)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.874
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.864
NEC for r=0.9 class 0.0 = 0.062 +- 0.144 (in-sample avg dev_std = 0.127)
NEC for r=0.9 class 1.0 = 0.035 +- 0.144 (in-sample avg dev_std = 0.127)
NEC for r=0.9 all KL = 0.036 +- 0.144 (in-sample avg dev_std = 0.127)
NEC for r=0.9 all L1 = 0.047 +- 0.134 (in-sample avg dev_std = 0.127)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.877
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.864
NEC for r=1.0 class 0.0 = 0.058 +- 0.133 (in-sample avg dev_std = 0.115)
NEC for r=1.0 class 1.0 = 0.028 +- 0.133 (in-sample avg dev_std = 0.115)
NEC for r=1.0 all KL = 0.029 +- 0.133 (in-sample avg dev_std = 0.115)
NEC for r=1.0 all L1 = 0.04 +- 0.124 (in-sample avg dev_std = 0.115)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.759
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.759
NEC for r=0.3 class 0.0 = 0.101 +- 0.127 (in-sample avg dev_std = 0.134)
NEC for r=0.3 class 1.0 = 0.05 +- 0.127 (in-sample avg dev_std = 0.134)
NEC for r=0.3 all KL = 0.047 +- 0.127 (in-sample avg dev_std = 0.134)
NEC for r=0.3 all L1 = 0.075 +- 0.138 (in-sample avg dev_std = 0.134)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.798
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.787
NEC for r=0.6 class 0.0 = 0.082 +- 0.108 (in-sample avg dev_std = 0.118)
NEC for r=0.6 class 1.0 = 0.044 +- 0.108 (in-sample avg dev_std = 0.118)
NEC for r=0.6 all KL = 0.036 +- 0.108 (in-sample avg dev_std = 0.118)
NEC for r=0.6 all L1 = 0.062 +- 0.128 (in-sample avg dev_std = 0.118)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.832
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.829
NEC for r=0.9 class 0.0 = 0.064 +- 0.088 (in-sample avg dev_std = 0.107)
NEC for r=0.9 class 1.0 = 0.039 +- 0.088 (in-sample avg dev_std = 0.107)
NEC for r=0.9 all KL = 0.029 +- 0.088 (in-sample avg dev_std = 0.107)
NEC for r=0.9 all L1 = 0.051 +- 0.111 (in-sample avg dev_std = 0.107)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.831
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.829
NEC for r=1.0 class 0.0 = 0.057 +- 0.077 (in-sample avg dev_std = 0.093)
NEC for r=1.0 class 1.0 = 0.035 +- 0.077 (in-sample avg dev_std = 0.093)
NEC for r=1.0 all KL = 0.024 +- 0.077 (in-sample avg dev_std = 0.093)
NEC for r=1.0 all L1 = 0.046 +- 0.103 (in-sample avg dev_std = 0.093)
model_dirname= repr_LECIvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 14:37:07 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:37:08 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 142...
[0m[1;37mINFO[0m: [1mCheckpoint 142: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0758
ID Validation ACCURACY: 0.8795
ID Validation Loss: 0.3939
ID Test ACCURACY: 0.8734
ID Test Loss: 0.4467
OOD Validation ACCURACY: 0.8811
OOD Validation Loss: 0.5654
OOD Test ACCURACY: 0.8098
OOD Test Loss: 1.1500

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 193...
[0m[1;37mINFO[0m: [1mCheckpoint 193: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0751
ID Validation ACCURACY: 0.8776
ID Validation Loss: 0.4561
ID Test ACCURACY: 0.8779
ID Test Loss: 0.5161
OOD Validation ACCURACY: 0.8846
OOD Validation Loss: 0.6825
OOD Test ACCURACY: 0.8120
OOD Test Loss: 1.3717

[0m[1;37mINFO[0m: [1mChartInfo 0.8734 0.8098 0.8779 0.8120 0.8776 0.8846[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/28/2024 02:37:09 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.87
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.85
SUFF++ for r=0.6 class 0.0 = 0.918 +- 0.177 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.6 class 1.0 = 0.943 +- 0.177 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.6 all KL = 0.927 +- 0.177 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.6 all L1 = 0.933 +- 0.126 (in-sample avg dev_std = 0.213)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.878
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.872
SUFF++ for r=0.9 class 0.0 = 0.94 +- 0.110 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.9 class 1.0 = 0.964 +- 0.110 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.9 all KL = 0.968 +- 0.110 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.9 all L1 = 0.953 +- 0.122 (in-sample avg dev_std = 0.111)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.755
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.732
SUFF++ for r=0.3 class 0.0 = 0.868 +- 0.172 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 class 1.0 = 0.935 +- 0.172 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 all KL = 0.901 +- 0.172 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 all L1 = 0.903 +- 0.137 (in-sample avg dev_std = 0.252)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.788
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.768
SUFF++ for r=0.6 class 0.0 = 0.867 +- 0.155 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.6 class 1.0 = 0.954 +- 0.155 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.6 all KL = 0.923 +- 0.155 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.6 all L1 = 0.912 +- 0.149 (in-sample avg dev_std = 0.193)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.822
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.82
SUFF++ for r=0.9 class 0.0 = 0.942 +- 0.068 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.9 class 1.0 = 0.976 +- 0.068 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.9 all KL = 0.975 +- 0.068 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.9 all L1 = 0.96 +- 0.085 (in-sample avg dev_std = 0.124)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.87
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.86
NEC for r=0.6 class 0.0 = 0.071 +- 0.124 (in-sample avg dev_std = 0.118)
NEC for r=0.6 class 1.0 = 0.048 +- 0.124 (in-sample avg dev_std = 0.118)
NEC for r=0.6 all KL = 0.043 +- 0.124 (in-sample avg dev_std = 0.118)
NEC for r=0.6 all L1 = 0.057 +- 0.119 (in-sample avg dev_std = 0.118)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.877
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.866
NEC for r=0.9 class 0.0 = 0.06 +- 0.141 (in-sample avg dev_std = 0.092)
NEC for r=0.9 class 1.0 = 0.032 +- 0.141 (in-sample avg dev_std = 0.092)
NEC for r=0.9 all KL = 0.035 +- 0.141 (in-sample avg dev_std = 0.092)
NEC for r=0.9 all L1 = 0.044 +- 0.132 (in-sample avg dev_std = 0.092)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.884
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.866
NEC for r=1.0 class 0.0 = 0.055 +- 0.133 (in-sample avg dev_std = 0.074)
NEC for r=1.0 class 1.0 = 0.025 +- 0.133 (in-sample avg dev_std = 0.074)
NEC for r=1.0 all KL = 0.028 +- 0.133 (in-sample avg dev_std = 0.074)
NEC for r=1.0 all L1 = 0.038 +- 0.125 (in-sample avg dev_std = 0.074)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.755
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.757
NEC for r=0.3 class 0.0 = 0.091 +- 0.097 (in-sample avg dev_std = 0.117)
NEC for r=0.3 class 1.0 = 0.044 +- 0.097 (in-sample avg dev_std = 0.117)
NEC for r=0.3 all KL = 0.035 +- 0.097 (in-sample avg dev_std = 0.117)
NEC for r=0.3 all L1 = 0.067 +- 0.120 (in-sample avg dev_std = 0.117)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.788
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.78
NEC for r=0.6 class 0.0 = 0.082 +- 0.088 (in-sample avg dev_std = 0.113)
NEC for r=0.6 class 1.0 = 0.039 +- 0.088 (in-sample avg dev_std = 0.113)
NEC for r=0.6 all KL = 0.031 +- 0.088 (in-sample avg dev_std = 0.113)
NEC for r=0.6 all L1 = 0.06 +- 0.122 (in-sample avg dev_std = 0.113)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.822
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.819
NEC for r=0.9 class 0.0 = 0.067 +- 0.071 (in-sample avg dev_std = 0.086)
NEC for r=0.9 class 1.0 = 0.029 +- 0.071 (in-sample avg dev_std = 0.086)
NEC for r=0.9 all KL = 0.023 +- 0.071 (in-sample avg dev_std = 0.086)
NEC for r=0.9 all L1 = 0.048 +- 0.102 (in-sample avg dev_std = 0.086)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.822
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.824
NEC for r=1.0 class 0.0 = 0.063 +- 0.069 (in-sample avg dev_std = 0.093)
NEC for r=1.0 class 1.0 = 0.028 +- 0.069 (in-sample avg dev_std = 0.093)
NEC for r=1.0 all KL = 0.021 +- 0.069 (in-sample avg dev_std = 0.093)
NEC for r=1.0 all L1 = 0.045 +- 0.102 (in-sample avg dev_std = 0.093)
model_dirname= repr_LECIvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 14:39:30 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:39:31 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:39:32 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 192...
[0m[1;37mINFO[0m: [1mCheckpoint 192: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0750
ID Validation ACCURACY: 0.8781
ID Validation Loss: 0.5140
ID Test ACCURACY: 0.8742
ID Test Loss: 0.5848
OOD Validation ACCURACY: 0.8821
OOD Validation Loss: 0.6982
OOD Test ACCURACY: 0.8264
OOD Test Loss: 1.2184

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 191...
[0m[1;37mINFO[0m: [1mCheckpoint 191: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0750
ID Validation ACCURACY: 0.8755
ID Validation Loss: 0.4966
ID Test ACCURACY: 0.8761
ID Test Loss: 0.5645
OOD Validation ACCURACY: 0.8860
OOD Validation Loss: 0.6638
OOD Test ACCURACY: 0.8338
OOD Test Loss: 1.0510

[0m[1;37mINFO[0m: [1mChartInfo 0.8742 0.8264 0.8761 0.8338 0.8755 0.8860[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/28/2024 02:39:33 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.874
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.861
SUFF++ for r=0.6 class 0.0 = 0.918 +- 0.200 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.6 class 1.0 = 0.96 +- 0.200 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.6 all KL = 0.923 +- 0.200 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.6 all L1 = 0.943 +- 0.133 (in-sample avg dev_std = 0.219)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.872
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.872
SUFF++ for r=0.9 class 0.0 = 0.94 +- 0.136 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 class 1.0 = 0.966 +- 0.136 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 all KL = 0.963 +- 0.136 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 all L1 = 0.954 +- 0.135 (in-sample avg dev_std = 0.107)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.754
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.742
SUFF++ for r=0.3 class 0.0 = 0.881 +- 0.206 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.3 class 1.0 = 0.942 +- 0.206 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.3 all KL = 0.888 +- 0.206 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.3 all L1 = 0.913 +- 0.141 (in-sample avg dev_std = 0.269)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.809
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.794
SUFF++ for r=0.6 class 0.0 = 0.892 +- 0.166 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.6 class 1.0 = 0.95 +- 0.166 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.6 all KL = 0.922 +- 0.166 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.6 all L1 = 0.922 +- 0.145 (in-sample avg dev_std = 0.204)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.836
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.832
SUFF++ for r=0.9 class 0.0 = 0.947 +- 0.105 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 class 1.0 = 0.973 +- 0.105 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 all KL = 0.966 +- 0.105 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 all L1 = 0.961 +- 0.095 (in-sample avg dev_std = 0.152)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.874
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.872
NEC for r=0.6 class 0.0 = 0.077 +- 0.146 (in-sample avg dev_std = 0.106)
NEC for r=0.6 class 1.0 = 0.024 +- 0.146 (in-sample avg dev_std = 0.106)
NEC for r=0.6 all KL = 0.044 +- 0.146 (in-sample avg dev_std = 0.106)
NEC for r=0.6 all L1 = 0.046 +- 0.125 (in-sample avg dev_std = 0.106)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.877
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.871
NEC for r=0.9 class 0.0 = 0.047 +- 0.133 (in-sample avg dev_std = 0.098)
NEC for r=0.9 class 1.0 = 0.033 +- 0.133 (in-sample avg dev_std = 0.098)
NEC for r=0.9 all KL = 0.031 +- 0.133 (in-sample avg dev_std = 0.098)
NEC for r=0.9 all L1 = 0.039 +- 0.130 (in-sample avg dev_std = 0.098)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.881
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.871
NEC for r=1.0 class 0.0 = 0.037 +- 0.128 (in-sample avg dev_std = 0.097)
NEC for r=1.0 class 1.0 = 0.032 +- 0.128 (in-sample avg dev_std = 0.097)
NEC for r=1.0 all KL = 0.026 +- 0.128 (in-sample avg dev_std = 0.097)
NEC for r=1.0 all L1 = 0.034 +- 0.120 (in-sample avg dev_std = 0.097)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.754
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.76
NEC for r=0.3 class 0.0 = 0.092 +- 0.132 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 1.0 = 0.036 +- 0.132 (in-sample avg dev_std = 0.142)
NEC for r=0.3 all KL = 0.044 +- 0.132 (in-sample avg dev_std = 0.142)
NEC for r=0.3 all L1 = 0.063 +- 0.134 (in-sample avg dev_std = 0.142)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.809
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.8
NEC for r=0.6 class 0.0 = 0.076 +- 0.119 (in-sample avg dev_std = 0.128)
NEC for r=0.6 class 1.0 = 0.041 +- 0.119 (in-sample avg dev_std = 0.128)
NEC for r=0.6 all KL = 0.039 +- 0.119 (in-sample avg dev_std = 0.128)
NEC for r=0.6 all L1 = 0.058 +- 0.129 (in-sample avg dev_std = 0.128)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.836
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.829
NEC for r=0.9 class 0.0 = 0.064 +- 0.096 (in-sample avg dev_std = 0.114)
NEC for r=0.9 class 1.0 = 0.029 +- 0.096 (in-sample avg dev_std = 0.114)
NEC for r=0.9 all KL = 0.029 +- 0.096 (in-sample avg dev_std = 0.114)
NEC for r=0.9 all L1 = 0.046 +- 0.116 (in-sample avg dev_std = 0.114)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.832
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.838
NEC for r=1.0 class 0.0 = 0.059 +- 0.102 (in-sample avg dev_std = 0.110)
NEC for r=1.0 class 1.0 = 0.03 +- 0.102 (in-sample avg dev_std = 0.110)
NEC for r=1.0 all KL = 0.028 +- 0.102 (in-sample avg dev_std = 0.110)
NEC for r=1.0 all L1 = 0.044 +- 0.116 (in-sample avg dev_std = 0.110)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.858, 0.941, 1.0], 'all_L1': [0.91, 0.941, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.922, 0.967, 1.0], 'all_L1': [0.939, 0.967, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.913, 0.971, 1.0], 'all_L1': [0.938, 0.957, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.927, 0.968, 1.0], 'all_L1': [0.933, 0.953, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.923, 0.963, 1.0], 'all_L1': [0.943, 0.954, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.06, 0.048, 0.026], 'all_L1': [0.063, 0.047, 0.029]}), defaultdict(<class 'list'>, {'all_KL': [0.041, 0.033, 0.026], 'all_L1': [0.05, 0.032, 0.027]}), defaultdict(<class 'list'>, {'all_KL': [0.04, 0.036, 0.029], 'all_L1': [0.046, 0.047, 0.04]}), defaultdict(<class 'list'>, {'all_KL': [0.043, 0.035, 0.028], 'all_L1': [0.057, 0.044, 0.038]}), defaultdict(<class 'list'>, {'all_KL': [0.044, 0.031, 0.026], 'all_L1': [0.046, 0.039, 0.034]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.813, 0.876, 0.953, 1.0], 'all_L1': [0.876, 0.899, 0.952, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.884, 0.922, 0.967, 1.0], 'all_L1': [0.903, 0.922, 0.961, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.907, 0.928, 0.973, 1.0], 'all_L1': [0.909, 0.92, 0.958, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.901, 0.923, 0.975, 1.0], 'all_L1': [0.903, 0.912, 0.96, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.888, 0.922, 0.966, 1.0], 'all_L1': [0.913, 0.922, 0.961, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.09, 0.056, 0.032, 0.02], 'all_L1': [0.093, 0.072, 0.045, 0.032]}), defaultdict(<class 'list'>, {'all_KL': [0.042, 0.035, 0.032, 0.027], 'all_L1': [0.064, 0.056, 0.045, 0.04]}), defaultdict(<class 'list'>, {'all_KL': [0.047, 0.036, 0.029, 0.024], 'all_L1': [0.075, 0.062, 0.051, 0.046]}), defaultdict(<class 'list'>, {'all_KL': [0.035, 0.031, 0.023, 0.021], 'all_L1': [0.067, 0.06, 0.048, 0.045]}), defaultdict(<class 'list'>, {'all_KL': [0.044, 0.039, 0.029, 0.028], 'all_L1': [0.063, 0.058, 0.046, 0.044]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.933 +- 0.012, 0.954 +- 0.008, 1.000 +- 0.000
suff++ class all_KL  =  0.909 +- 0.026, 0.962 +- 0.011, 1.000 +- 0.000
suff++_acc_int  =  0.859 +- 0.007, 0.872 +- 0.004
nec class all_L1  =  0.052 +- 0.007, 0.042 +- 0.006, 0.034 +- 0.005
nec class all_KL  =  0.046 +- 0.007, 0.037 +- 0.006, 0.027 +- 0.001
nec_acc_int  =  0.870 +- 0.005, 0.869 +- 0.004, 0.869 +- 0.003

Eval split test
suff++ class all_L1  =  0.901 +- 0.013, 0.915 +- 0.009, 0.958 +- 0.003, 1.000 +- 0.000
suff++ class all_KL  =  0.879 +- 0.034, 0.914 +- 0.019, 0.967 +- 0.008, 1.000 +- 0.000
suff++_acc_int  =  0.737 +- 0.004, 0.785 +- 0.010, 0.830 +- 0.005
nec class all_L1  =  0.072 +- 0.011, 0.062 +- 0.006, 0.047 +- 0.002, 0.041 +- 0.005
nec class all_KL  =  0.052 +- 0.020, 0.039 +- 0.009, 0.029 +- 0.003, 0.024 +- 0.003
nec_acc_int  =  0.759 +- 0.004, 0.792 +- 0.008, 0.830 +- 0.007, 0.832 +- 0.006


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.493 +- 0.003, 0.498 +- 0.003, 0.517 +- 0.003
Faith. Armon (L1)= 		  =  0.099 +- 0.012, 0.080 +- 0.011, 0.065 +- 0.009
Faith. GMean (L1)= 	  =  0.221 +- 0.013, 0.199 +- 0.013, 0.183 +- 0.014
Faith. Aritm (KL)= 		  =  0.477 +- 0.009, 0.499 +- 0.003, 0.514 +- 0.001
Faith. Armon (KL)= 		  =  0.087 +- 0.013, 0.070 +- 0.011, 0.053 +- 0.002
Faith. GMean (KL)= 	  =  0.203 +- 0.013, 0.187 +- 0.014, 0.164 +- 0.004

Eval split test
Faith. Aritm (L1)= 		  =  0.487 +- 0.003, 0.488 +- 0.002, 0.503 +- 0.002, 0.521 +- 0.003
Faith. Armon (L1)= 		  =  0.134 +- 0.019, 0.115 +- 0.010, 0.090 +- 0.004, 0.079 +- 0.009
Faith. GMean (L1)= 	  =  0.255 +- 0.017, 0.237 +- 0.009, 0.212 +- 0.005, 0.203 +- 0.013
Faith. Aritm (KL)= 		  =  0.465 +- 0.008, 0.477 +- 0.006, 0.498 +- 0.003, 0.512 +- 0.002
Faith. Armon (KL)= 		  =  0.097 +- 0.034, 0.075 +- 0.016, 0.056 +- 0.006, 0.047 +- 0.006
Faith. GMean (KL)= 	  =  0.209 +- 0.032, 0.189 +- 0.018, 0.167 +- 0.009, 0.155 +- 0.010
Computed for split load_split = id



Completed in  0:11:49.216018  for LECIvGIN GOODSST2/length



DONE LECI GOODSST2/length
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 14:42:11 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/28/2024 02:42:11 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/28/2024 02:42:47 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/28/2024 02:42:58 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:08 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:24 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 154...
[0m[1;37mINFO[0m: [1mCheckpoint 154: 
-----------------------------------
Train ROC-AUC: 0.9727
Train Loss: 0.1378
ID Validation ROC-AUC: 0.9248
ID Validation Loss: 0.2674
ID Test ROC-AUC: 0.9280
ID Test Loss: 0.2650
OOD Validation ROC-AUC: 0.6550
OOD Validation Loss: 0.4948
OOD Test ROC-AUC: 0.7073
OOD Test Loss: 0.6679

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 56...
[0m[1;37mINFO[0m: [1mCheckpoint 56: 
-----------------------------------
Train ROC-AUC: 0.9313
Train Loss: 0.2369
ID Validation ROC-AUC: 0.9115
ID Validation Loss: 0.2655
ID Test ROC-AUC: 0.9145
ID Test Loss: 0.2678
OOD Validation ROC-AUC: 0.7016
OOD Validation Loss: 0.3203
OOD Test ROC-AUC: 0.7225
OOD Test Loss: 0.5195

[0m[1;37mINFO[0m: [1mChartInfo 0.9280 0.7073 0.9145 0.7225 0.9115 0.7016[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/28/2024 02:43:41 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/28/2024 02:43:46 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.738
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.652
SUFF++ for r=0.3 class 0.0 = 0.585 +- 0.206 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.3 class 1.0 = 0.7 +- 0.206 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.3 all KL = 0.713 +- 0.206 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.3 all L1 = 0.687 +- 0.181 (in-sample avg dev_std = 0.411)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.85
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.769
SUFF++ for r=0.6 class 0.0 = 0.611 +- 0.194 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.6 class 1.0 = 0.858 +- 0.194 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.6 all KL = 0.85 +- 0.194 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.6 all L1 = 0.829 +- 0.204 (in-sample avg dev_std = 0.265)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.909
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.873
SUFF++ for r=0.9 class 0.0 = 0.706 +- 0.138 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.9 class 1.0 = 0.927 +- 0.138 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.9 all KL = 0.932 +- 0.138 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.9 all L1 = 0.901 +- 0.162 (in-sample avg dev_std = 0.190)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.637
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.587
SUFF++ for r=0.3 class 0.0 = 0.568 +- 0.210 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.3 class 1.0 = 0.628 +- 0.210 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.3 all KL = 0.68 +- 0.210 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.3 all L1 = 0.618 +- 0.172 (in-sample avg dev_std = 0.446)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.658
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.615
SUFF++ for r=0.6 class 0.0 = 0.658 +- 0.217 (in-sample avg dev_std = 0.335)
SUFF++ for r=0.6 class 1.0 = 0.766 +- 0.217 (in-sample avg dev_std = 0.335)
SUFF++ for r=0.6 all KL = 0.787 +- 0.217 (in-sample avg dev_std = 0.335)
SUFF++ for r=0.6 all L1 = 0.748 +- 0.218 (in-sample avg dev_std = 0.335)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.696
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.667
SUFF++ for r=0.9 class 0.0 = 0.745 +- 0.169 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.9 class 1.0 = 0.846 +- 0.169 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.9 all KL = 0.886 +- 0.169 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.9 all L1 = 0.829 +- 0.201 (in-sample avg dev_std = 0.229)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.738
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.714
NEC for r=0.3 class 0.0 = 0.323 +- 0.215 (in-sample avg dev_std = 0.343)
NEC for r=0.3 class 1.0 = 0.249 +- 0.215 (in-sample avg dev_std = 0.343)
NEC for r=0.3 all KL = 0.209 +- 0.215 (in-sample avg dev_std = 0.343)
NEC for r=0.3 all L1 = 0.258 +- 0.182 (in-sample avg dev_std = 0.343)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.85
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.825
NEC for r=0.6 class 0.0 = 0.319 +- 0.180 (in-sample avg dev_std = 0.248)
NEC for r=0.6 class 1.0 = 0.128 +- 0.180 (in-sample avg dev_std = 0.248)
NEC for r=0.6 all KL = 0.123 +- 0.180 (in-sample avg dev_std = 0.248)
NEC for r=0.6 all L1 = 0.15 +- 0.178 (in-sample avg dev_std = 0.248)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.909
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.866
NEC for r=0.9 class 0.0 = 0.305 +- 0.144 (in-sample avg dev_std = 0.211)
NEC for r=0.9 class 1.0 = 0.08 +- 0.144 (in-sample avg dev_std = 0.211)
NEC for r=0.9 all KL = 0.077 +- 0.144 (in-sample avg dev_std = 0.211)
NEC for r=0.9 all L1 = 0.106 +- 0.165 (in-sample avg dev_std = 0.211)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.92
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.866
NEC for r=1.0 class 0.0 = 0.331 +- 0.152 (in-sample avg dev_std = 0.227)
NEC for r=1.0 class 1.0 = 0.076 +- 0.152 (in-sample avg dev_std = 0.227)
NEC for r=1.0 all KL = 0.078 +- 0.152 (in-sample avg dev_std = 0.227)
NEC for r=1.0 all L1 = 0.106 +- 0.165 (in-sample avg dev_std = 0.227)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.637
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.622
NEC for r=0.3 class 0.0 = 0.31 +- 0.212 (in-sample avg dev_std = 0.344)
NEC for r=0.3 class 1.0 = 0.297 +- 0.212 (in-sample avg dev_std = 0.344)
NEC for r=0.3 all KL = 0.212 +- 0.212 (in-sample avg dev_std = 0.344)
NEC for r=0.3 all L1 = 0.3 +- 0.186 (in-sample avg dev_std = 0.344)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.658
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.664
NEC for r=0.6 class 0.0 = 0.285 +- 0.184 (in-sample avg dev_std = 0.292)
NEC for r=0.6 class 1.0 = 0.198 +- 0.184 (in-sample avg dev_std = 0.292)
NEC for r=0.6 all KL = 0.16 +- 0.184 (in-sample avg dev_std = 0.292)
NEC for r=0.6 all L1 = 0.213 +- 0.186 (in-sample avg dev_std = 0.292)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.696
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.684
NEC for r=0.9 class 0.0 = 0.246 +- 0.165 (in-sample avg dev_std = 0.255)
NEC for r=0.9 class 1.0 = 0.16 +- 0.165 (in-sample avg dev_std = 0.255)
NEC for r=0.9 all KL = 0.121 +- 0.165 (in-sample avg dev_std = 0.255)
NEC for r=0.9 all L1 = 0.174 +- 0.186 (in-sample avg dev_std = 0.255)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.707
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.697
NEC for r=1.0 class 0.0 = 0.262 +- 0.178 (in-sample avg dev_std = 0.281)
NEC for r=1.0 class 1.0 = 0.17 +- 0.178 (in-sample avg dev_std = 0.281)
NEC for r=1.0 all KL = 0.13 +- 0.178 (in-sample avg dev_std = 0.281)
NEC for r=1.0 all L1 = 0.185 +- 0.197 (in-sample avg dev_std = 0.281)
model_dirname= repr_LECIvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 14:47:18 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/28/2024 02:47:18 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/28/2024 02:47:49 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:00 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:10 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:26 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:48:42 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 145...
[0m[1;37mINFO[0m: [1mCheckpoint 145: 
-----------------------------------
Train ROC-AUC: 0.9651
Train Loss: 0.1565
ID Validation ROC-AUC: 0.9232
ID Validation Loss: 0.2486
ID Test ROC-AUC: 0.9247
ID Test Loss: 0.2522
OOD Validation ROC-AUC: 0.6738
OOD Validation Loss: 0.4349
OOD Test ROC-AUC: 0.7050
OOD Test Loss: 0.6209

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 30...
[0m[1;37mINFO[0m: [1mCheckpoint 30: 
-----------------------------------
Train ROC-AUC: 0.9095
Train Loss: 0.2555
ID Validation ROC-AUC: 0.8966
ID Validation Loss: 0.2709
ID Test ROC-AUC: 0.8993
ID Test Loss: 0.2732
OOD Validation ROC-AUC: 0.6989
OOD Validation Loss: 0.3054
OOD Test ROC-AUC: 0.7302
OOD Test Loss: 0.4911

[0m[1;37mINFO[0m: [1mChartInfo 0.9247 0.7050 0.8993 0.7302 0.8966 0.6989[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/28/2024 02:48:43 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/28/2024 02:48:47 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.565
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.584
SUFF++ for r=0.3 class 0.0 = 0.634 +- 0.155 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.3 class 1.0 = 0.604 +- 0.155 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.3 all KL = 0.749 +- 0.155 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.3 all L1 = 0.607 +- 0.120 (in-sample avg dev_std = 0.433)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.795
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.731
SUFF++ for r=0.6 class 0.0 = 0.583 +- 0.197 (in-sample avg dev_std = 0.395)
SUFF++ for r=0.6 class 1.0 = 0.702 +- 0.197 (in-sample avg dev_std = 0.395)
SUFF++ for r=0.6 all KL = 0.743 +- 0.197 (in-sample avg dev_std = 0.395)
SUFF++ for r=0.6 all L1 = 0.688 +- 0.202 (in-sample avg dev_std = 0.395)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.906
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.864
SUFF++ for r=0.9 class 0.0 = 0.709 +- 0.158 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 class 1.0 = 0.885 +- 0.158 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 all KL = 0.905 +- 0.158 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 all L1 = 0.865 +- 0.177 (in-sample avg dev_std = 0.235)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.488
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.541
SUFF++ for r=0.3 class 0.0 = 0.641 +- 0.145 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 class 1.0 = 0.631 +- 0.145 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 all KL = 0.777 +- 0.145 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 all L1 = 0.633 +- 0.117 (in-sample avg dev_std = 0.415)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.61
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.612
SUFF++ for r=0.6 class 0.0 = 0.588 +- 0.189 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.6 class 1.0 = 0.623 +- 0.189 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.6 all KL = 0.692 +- 0.189 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.6 all L1 = 0.617 +- 0.178 (in-sample avg dev_std = 0.459)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.668
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.663
SUFF++ for r=0.9 class 0.0 = 0.743 +- 0.186 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.9 class 1.0 = 0.795 +- 0.186 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.9 all KL = 0.849 +- 0.186 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.9 all L1 = 0.786 +- 0.205 (in-sample avg dev_std = 0.289)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.565
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.558
NEC for r=0.3 class 0.0 = 0.28 +- 0.142 (in-sample avg dev_std = 0.280)
NEC for r=0.3 class 1.0 = 0.287 +- 0.142 (in-sample avg dev_std = 0.280)
NEC for r=0.3 all KL = 0.137 +- 0.142 (in-sample avg dev_std = 0.280)
NEC for r=0.3 all L1 = 0.286 +- 0.143 (in-sample avg dev_std = 0.280)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.795
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.769
NEC for r=0.6 class 0.0 = 0.28 +- 0.226 (in-sample avg dev_std = 0.342)
NEC for r=0.6 class 1.0 = 0.278 +- 0.226 (in-sample avg dev_std = 0.342)
NEC for r=0.6 all KL = 0.222 +- 0.226 (in-sample avg dev_std = 0.342)
NEC for r=0.6 all L1 = 0.279 +- 0.188 (in-sample avg dev_std = 0.342)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.906
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.861
NEC for r=0.9 class 0.0 = 0.27 +- 0.180 (in-sample avg dev_std = 0.260)
NEC for r=0.9 class 1.0 = 0.132 +- 0.180 (in-sample avg dev_std = 0.260)
NEC for r=0.9 all KL = 0.123 +- 0.180 (in-sample avg dev_std = 0.260)
NEC for r=0.9 all L1 = 0.148 +- 0.173 (in-sample avg dev_std = 0.260)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.908
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.873
NEC for r=1.0 class 0.0 = 0.239 +- 0.163 (in-sample avg dev_std = 0.237)
NEC for r=1.0 class 1.0 = 0.099 +- 0.163 (in-sample avg dev_std = 0.237)
NEC for r=1.0 all KL = 0.092 +- 0.163 (in-sample avg dev_std = 0.237)
NEC for r=1.0 all L1 = 0.116 +- 0.158 (in-sample avg dev_std = 0.237)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.488
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.507
NEC for r=0.3 class 0.0 = 0.266 +- 0.139 (in-sample avg dev_std = 0.264)
NEC for r=0.3 class 1.0 = 0.28 +- 0.139 (in-sample avg dev_std = 0.264)
NEC for r=0.3 all KL = 0.13 +- 0.139 (in-sample avg dev_std = 0.264)
NEC for r=0.3 all L1 = 0.277 +- 0.147 (in-sample avg dev_std = 0.264)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.61
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.623
NEC for r=0.6 class 0.0 = 0.322 +- 0.215 (in-sample avg dev_std = 0.340)
NEC for r=0.6 class 1.0 = 0.306 +- 0.215 (in-sample avg dev_std = 0.340)
NEC for r=0.6 all KL = 0.22 +- 0.215 (in-sample avg dev_std = 0.340)
NEC for r=0.6 all L1 = 0.308 +- 0.184 (in-sample avg dev_std = 0.340)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.668
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.673
NEC for r=0.9 class 0.0 = 0.26 +- 0.192 (in-sample avg dev_std = 0.310)
NEC for r=0.9 class 1.0 = 0.214 +- 0.192 (in-sample avg dev_std = 0.310)
NEC for r=0.9 all KL = 0.168 +- 0.192 (in-sample avg dev_std = 0.310)
NEC for r=0.9 all L1 = 0.222 +- 0.188 (in-sample avg dev_std = 0.310)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.696
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.684
NEC for r=1.0 class 0.0 = 0.229 +- 0.171 (in-sample avg dev_std = 0.298)
NEC for r=1.0 class 1.0 = 0.176 +- 0.171 (in-sample avg dev_std = 0.298)
NEC for r=1.0 all KL = 0.134 +- 0.171 (in-sample avg dev_std = 0.298)
NEC for r=1.0 all L1 = 0.185 +- 0.175 (in-sample avg dev_std = 0.298)
model_dirname= repr_LECIvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 14:52:21 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/28/2024 02:52:21 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/28/2024 02:52:52 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:02 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:13 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:29 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:45 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:53:46 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 119...
[0m[1;37mINFO[0m: [1mCheckpoint 119: 
-----------------------------------
Train ROC-AUC: 0.9599
Train Loss: 0.1725
ID Validation ROC-AUC: 0.9219
ID Validation Loss: 0.2486
ID Test ROC-AUC: 0.9238
ID Test Loss: 0.2502
OOD Validation ROC-AUC: 0.6637
OOD Validation Loss: 0.3933
OOD Test ROC-AUC: 0.7126
OOD Test Loss: 0.5743

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 24...
[0m[1;37mINFO[0m: [1mCheckpoint 24: 
-----------------------------------
Train ROC-AUC: 0.9060
Train Loss: 0.2554
ID Validation ROC-AUC: 0.8940
ID Validation Loss: 0.2686
ID Test ROC-AUC: 0.8978
ID Test Loss: 0.2703
OOD Validation ROC-AUC: 0.6978
OOD Validation Loss: 0.2989
OOD Test ROC-AUC: 0.7280
OOD Test Loss: 0.4799

[0m[1;37mINFO[0m: [1mChartInfo 0.9238 0.7126 0.8978 0.7280 0.8940 0.6978[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/28/2024 02:53:46 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/28/2024 02:53:50 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.699
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.644
SUFF++ for r=0.3 class 0.0 = 0.611 +- 0.155 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.3 class 1.0 = 0.668 +- 0.155 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.3 all KL = 0.778 +- 0.155 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.3 all L1 = 0.661 +- 0.151 (in-sample avg dev_std = 0.366)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.818
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.764
SUFF++ for r=0.6 class 0.0 = 0.647 +- 0.143 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.6 class 1.0 = 0.848 +- 0.143 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.6 all KL = 0.873 +- 0.143 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.6 all L1 = 0.824 +- 0.179 (in-sample avg dev_std = 0.232)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.897
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.872
SUFF++ for r=0.9 class 0.0 = 0.756 +- 0.089 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.9 class 1.0 = 0.941 +- 0.089 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.9 all KL = 0.958 +- 0.089 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.9 all L1 = 0.92 +- 0.136 (in-sample avg dev_std = 0.132)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.578
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.591
SUFF++ for r=0.3 class 0.0 = 0.634 +- 0.155 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.3 class 1.0 = 0.638 +- 0.155 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.3 all KL = 0.76 +- 0.155 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.3 all L1 = 0.637 +- 0.138 (in-sample avg dev_std = 0.390)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.668
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.647
SUFF++ for r=0.6 class 0.0 = 0.658 +- 0.153 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.6 class 1.0 = 0.764 +- 0.153 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.6 all KL = 0.826 +- 0.153 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.6 all L1 = 0.746 +- 0.190 (in-sample avg dev_std = 0.294)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.718
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.696
SUFF++ for r=0.9 class 0.0 = 0.75 +- 0.122 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.9 class 1.0 = 0.87 +- 0.122 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.9 all KL = 0.918 +- 0.122 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.9 all L1 = 0.85 +- 0.169 (in-sample avg dev_std = 0.188)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.699
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.684
NEC for r=0.3 class 0.0 = 0.249 +- 0.145 (in-sample avg dev_std = 0.280)
NEC for r=0.3 class 1.0 = 0.268 +- 0.145 (in-sample avg dev_std = 0.280)
NEC for r=0.3 all KL = 0.144 +- 0.145 (in-sample avg dev_std = 0.280)
NEC for r=0.3 all L1 = 0.266 +- 0.140 (in-sample avg dev_std = 0.280)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.818
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.806
NEC for r=0.6 class 0.0 = 0.271 +- 0.144 (in-sample avg dev_std = 0.218)
NEC for r=0.6 class 1.0 = 0.147 +- 0.144 (in-sample avg dev_std = 0.218)
NEC for r=0.6 all KL = 0.112 +- 0.144 (in-sample avg dev_std = 0.218)
NEC for r=0.6 all L1 = 0.162 +- 0.154 (in-sample avg dev_std = 0.218)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.897
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.868
NEC for r=0.9 class 0.0 = 0.244 +- 0.105 (in-sample avg dev_std = 0.158)
NEC for r=0.9 class 1.0 = 0.067 +- 0.105 (in-sample avg dev_std = 0.158)
NEC for r=0.9 all KL = 0.055 +- 0.105 (in-sample avg dev_std = 0.158)
NEC for r=0.9 all L1 = 0.088 +- 0.133 (in-sample avg dev_std = 0.158)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.914
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.881
NEC for r=1.0 class 0.0 = 0.224 +- 0.090 (in-sample avg dev_std = 0.144)
NEC for r=1.0 class 1.0 = 0.051 +- 0.090 (in-sample avg dev_std = 0.144)
NEC for r=1.0 all KL = 0.04 +- 0.090 (in-sample avg dev_std = 0.144)
NEC for r=1.0 all L1 = 0.071 +- 0.123 (in-sample avg dev_std = 0.144)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.578
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.583
NEC for r=0.3 class 0.0 = 0.254 +- 0.150 (in-sample avg dev_std = 0.269)
NEC for r=0.3 class 1.0 = 0.268 +- 0.150 (in-sample avg dev_std = 0.269)
NEC for r=0.3 all KL = 0.14 +- 0.150 (in-sample avg dev_std = 0.269)
NEC for r=0.3 all L1 = 0.266 +- 0.149 (in-sample avg dev_std = 0.269)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.668
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.653
NEC for r=0.6 class 0.0 = 0.279 +- 0.149 (in-sample avg dev_std = 0.258)
NEC for r=0.6 class 1.0 = 0.207 +- 0.149 (in-sample avg dev_std = 0.258)
NEC for r=0.6 all KL = 0.138 +- 0.149 (in-sample avg dev_std = 0.258)
NEC for r=0.6 all L1 = 0.219 +- 0.158 (in-sample avg dev_std = 0.258)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.718
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.698
NEC for r=0.9 class 0.0 = 0.222 +- 0.126 (in-sample avg dev_std = 0.200)
NEC for r=0.9 class 1.0 = 0.137 +- 0.126 (in-sample avg dev_std = 0.200)
NEC for r=0.9 all KL = 0.087 +- 0.126 (in-sample avg dev_std = 0.200)
NEC for r=0.9 all L1 = 0.151 +- 0.157 (in-sample avg dev_std = 0.200)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.731
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.7
NEC for r=1.0 class 0.0 = 0.219 +- 0.115 (in-sample avg dev_std = 0.185)
NEC for r=1.0 class 1.0 = 0.118 +- 0.115 (in-sample avg dev_std = 0.185)
NEC for r=1.0 all KL = 0.071 +- 0.115 (in-sample avg dev_std = 0.185)
NEC for r=1.0 all L1 = 0.134 +- 0.156 (in-sample avg dev_std = 0.185)
model_dirname= repr_LECIvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 14:57:20 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/28/2024 02:57:20 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/28/2024 02:57:53 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:06 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:17 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:33 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:48 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:58:49 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:49 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:49 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:49 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:58:49 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 136...
[0m[1;37mINFO[0m: [1mCheckpoint 136: 
-----------------------------------
Train ROC-AUC: 0.9683
Train Loss: 0.1544
ID Validation ROC-AUC: 0.9248
ID Validation Loss: 0.2444
ID Test ROC-AUC: 0.9244
ID Test Loss: 0.2478
OOD Validation ROC-AUC: 0.6793
OOD Validation Loss: 0.3957
OOD Test ROC-AUC: 0.7158
OOD Test Loss: 0.5602

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 92...
[0m[1;37mINFO[0m: [1mCheckpoint 92: 
-----------------------------------
Train ROC-AUC: 0.9510
Train Loss: 0.1952
ID Validation ROC-AUC: 0.9178
ID Validation Loss: 0.2653
ID Test ROC-AUC: 0.9200
ID Test Loss: 0.2655
OOD Validation ROC-AUC: 0.6963
OOD Validation Loss: 0.3695
OOD Test ROC-AUC: 0.7235
OOD Test Loss: 0.5689

[0m[1;37mINFO[0m: [1mChartInfo 0.9244 0.7158 0.9200 0.7235 0.9178 0.6963[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/28/2024 02:58:49 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/28/2024 02:58:53 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.726
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.642
SUFF++ for r=0.3 class 0.0 = 0.648 +- 0.119 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.3 class 1.0 = 0.732 +- 0.119 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.3 all KL = 0.842 +- 0.119 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.3 all L1 = 0.722 +- 0.129 (in-sample avg dev_std = 0.294)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.849
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.768
SUFF++ for r=0.6 class 0.0 = 0.634 +- 0.143 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.6 class 1.0 = 0.855 +- 0.143 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.6 all KL = 0.875 +- 0.143 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.6 all L1 = 0.829 +- 0.176 (in-sample avg dev_std = 0.244)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.915
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.889
SUFF++ for r=0.9 class 0.0 = 0.712 +- 0.113 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.9 class 1.0 = 0.912 +- 0.113 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.9 all KL = 0.937 +- 0.113 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.9 all L1 = 0.889 +- 0.154 (in-sample avg dev_std = 0.170)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.615
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.597
SUFF++ for r=0.3 class 0.0 = 0.673 +- 0.113 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.3 class 1.0 = 0.695 +- 0.113 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.3 all KL = 0.836 +- 0.113 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.3 all L1 = 0.691 +- 0.117 (in-sample avg dev_std = 0.319)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.665
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.628
SUFF++ for r=0.6 class 0.0 = 0.67 +- 0.146 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.6 class 1.0 = 0.76 +- 0.146 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.6 all KL = 0.831 +- 0.146 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.6 all L1 = 0.745 +- 0.181 (in-sample avg dev_std = 0.297)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.707
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.674
SUFF++ for r=0.9 class 0.0 = 0.729 +- 0.142 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 class 1.0 = 0.825 +- 0.142 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 all KL = 0.891 +- 0.142 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 all L1 = 0.809 +- 0.174 (in-sample avg dev_std = 0.235)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.726
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.743
NEC for r=0.3 class 0.0 = 0.247 +- 0.115 (in-sample avg dev_std = 0.224)
NEC for r=0.3 class 1.0 = 0.213 +- 0.115 (in-sample avg dev_std = 0.224)
NEC for r=0.3 all KL = 0.099 +- 0.115 (in-sample avg dev_std = 0.224)
NEC for r=0.3 all L1 = 0.217 +- 0.123 (in-sample avg dev_std = 0.224)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.849
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.848
NEC for r=0.6 class 0.0 = 0.283 +- 0.141 (in-sample avg dev_std = 0.215)
NEC for r=0.6 class 1.0 = 0.138 +- 0.141 (in-sample avg dev_std = 0.215)
NEC for r=0.6 all KL = 0.111 +- 0.141 (in-sample avg dev_std = 0.215)
NEC for r=0.6 all L1 = 0.155 +- 0.148 (in-sample avg dev_std = 0.215)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.915
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.88
NEC for r=0.9 class 0.0 = 0.296 +- 0.116 (in-sample avg dev_std = 0.201)
NEC for r=0.9 class 1.0 = 0.094 +- 0.116 (in-sample avg dev_std = 0.201)
NEC for r=0.9 all KL = 0.074 +- 0.116 (in-sample avg dev_std = 0.201)
NEC for r=0.9 all L1 = 0.118 +- 0.148 (in-sample avg dev_std = 0.201)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.916
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.869
NEC for r=1.0 class 0.0 = 0.278 +- 0.124 (in-sample avg dev_std = 0.201)
NEC for r=1.0 class 1.0 = 0.082 +- 0.124 (in-sample avg dev_std = 0.201)
NEC for r=1.0 all KL = 0.068 +- 0.124 (in-sample avg dev_std = 0.201)
NEC for r=1.0 all L1 = 0.105 +- 0.148 (in-sample avg dev_std = 0.201)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.615
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.618
NEC for r=0.3 class 0.0 = 0.249 +- 0.107 (in-sample avg dev_std = 0.233)
NEC for r=0.3 class 1.0 = 0.234 +- 0.107 (in-sample avg dev_std = 0.233)
NEC for r=0.3 all KL = 0.098 +- 0.107 (in-sample avg dev_std = 0.233)
NEC for r=0.3 all L1 = 0.237 +- 0.124 (in-sample avg dev_std = 0.233)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.665
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.67
NEC for r=0.6 class 0.0 = 0.275 +- 0.144 (in-sample avg dev_std = 0.259)
NEC for r=0.6 class 1.0 = 0.211 +- 0.144 (in-sample avg dev_std = 0.259)
NEC for r=0.6 all KL = 0.136 +- 0.144 (in-sample avg dev_std = 0.259)
NEC for r=0.6 all L1 = 0.222 +- 0.153 (in-sample avg dev_std = 0.259)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.707
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.69
NEC for r=0.9 class 0.0 = 0.248 +- 0.141 (in-sample avg dev_std = 0.254)
NEC for r=0.9 class 1.0 = 0.181 +- 0.141 (in-sample avg dev_std = 0.254)
NEC for r=0.9 all KL = 0.115 +- 0.141 (in-sample avg dev_std = 0.254)
NEC for r=0.9 all L1 = 0.192 +- 0.163 (in-sample avg dev_std = 0.254)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.724
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.702
NEC for r=1.0 class 0.0 = 0.269 +- 0.147 (in-sample avg dev_std = 0.257)
NEC for r=1.0 class 1.0 = 0.166 +- 0.147 (in-sample avg dev_std = 0.257)
NEC for r=1.0 all KL = 0.109 +- 0.147 (in-sample avg dev_std = 0.257)
NEC for r=1.0 all L1 = 0.183 +- 0.170 (in-sample avg dev_std = 0.257)
model_dirname= repr_LECIvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 15:02:20 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/28/2024 03:02:20 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/28/2024 03:02:52 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:02 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:12 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:28 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:46 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:46 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:46 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:03:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:46 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:03:46 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:03:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:46 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:03:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:46 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 166...
[0m[1;37mINFO[0m: [1mCheckpoint 166: 
-----------------------------------
Train ROC-AUC: 0.9712
Train Loss: 0.1682
ID Validation ROC-AUC: 0.9235
ID Validation Loss: 0.3171
ID Test ROC-AUC: 0.9267
ID Test Loss: 0.3191
OOD Validation ROC-AUC: 0.6651
OOD Validation Loss: 0.5310
OOD Test ROC-AUC: 0.7146
OOD Test Loss: 0.7641

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 26...
[0m[1;37mINFO[0m: [1mCheckpoint 26: 
-----------------------------------
Train ROC-AUC: 0.9105
Train Loss: 0.2495
ID Validation ROC-AUC: 0.8984
ID Validation Loss: 0.2622
ID Test ROC-AUC: 0.9001
ID Test Loss: 0.2660
OOD Validation ROC-AUC: 0.7015
OOD Validation Loss: 0.2936
OOD Test ROC-AUC: 0.7252
OOD Test Loss: 0.4753

[0m[1;37mINFO[0m: [1mChartInfo 0.9267 0.7146 0.9001 0.7252 0.8984 0.7015[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/28/2024 03:03:47 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/28/2024 03:03:55 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.6
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.573
SUFF++ for r=0.3 class 0.0 = 0.586 +- 0.205 (in-sample avg dev_std = 0.522)
SUFF++ for r=0.3 class 1.0 = 0.56 +- 0.205 (in-sample avg dev_std = 0.522)
SUFF++ for r=0.3 all KL = 0.643 +- 0.205 (in-sample avg dev_std = 0.522)
SUFF++ for r=0.3 all L1 = 0.563 +- 0.116 (in-sample avg dev_std = 0.522)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.795
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.709
SUFF++ for r=0.6 class 0.0 = 0.567 +- 0.221 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.6 class 1.0 = 0.716 +- 0.221 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.6 all KL = 0.735 +- 0.221 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.6 all L1 = 0.699 +- 0.202 (in-sample avg dev_std = 0.409)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.873
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.826
SUFF++ for r=0.9 class 0.0 = 0.731 +- 0.170 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.9 class 1.0 = 0.888 +- 0.170 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.9 all KL = 0.901 +- 0.170 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.9 all L1 = 0.87 +- 0.176 (in-sample avg dev_std = 0.229)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.56
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.556
SUFF++ for r=0.3 class 0.0 = 0.588 +- 0.196 (in-sample avg dev_std = 0.493)
SUFF++ for r=0.3 class 1.0 = 0.577 +- 0.196 (in-sample avg dev_std = 0.493)
SUFF++ for r=0.3 all KL = 0.659 +- 0.196 (in-sample avg dev_std = 0.493)
SUFF++ for r=0.3 all L1 = 0.579 +- 0.118 (in-sample avg dev_std = 0.493)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.634
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.599
SUFF++ for r=0.6 class 0.0 = 0.607 +- 0.215 (in-sample avg dev_std = 0.454)
SUFF++ for r=0.6 class 1.0 = 0.646 +- 0.215 (in-sample avg dev_std = 0.454)
SUFF++ for r=0.6 all KL = 0.693 +- 0.215 (in-sample avg dev_std = 0.454)
SUFF++ for r=0.6 all L1 = 0.64 +- 0.182 (in-sample avg dev_std = 0.454)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.674
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.649
SUFF++ for r=0.9 class 0.0 = 0.746 +- 0.196 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.9 class 1.0 = 0.82 +- 0.196 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.9 all KL = 0.856 +- 0.196 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.9 all L1 = 0.808 +- 0.200 (in-sample avg dev_std = 0.272)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.6
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.582
NEC for r=0.3 class 0.0 = 0.287 +- 0.185 (in-sample avg dev_std = 0.350)
NEC for r=0.3 class 1.0 = 0.325 +- 0.185 (in-sample avg dev_std = 0.350)
NEC for r=0.3 all KL = 0.208 +- 0.185 (in-sample avg dev_std = 0.350)
NEC for r=0.3 all L1 = 0.321 +- 0.161 (in-sample avg dev_std = 0.350)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.795
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.758
NEC for r=0.6 class 0.0 = 0.333 +- 0.202 (in-sample avg dev_std = 0.361)
NEC for r=0.6 class 1.0 = 0.257 +- 0.202 (in-sample avg dev_std = 0.361)
NEC for r=0.6 all KL = 0.214 +- 0.202 (in-sample avg dev_std = 0.361)
NEC for r=0.6 all L1 = 0.266 +- 0.185 (in-sample avg dev_std = 0.361)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.873
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.829
NEC for r=0.9 class 0.0 = 0.289 +- 0.187 (in-sample avg dev_std = 0.275)
NEC for r=0.9 class 1.0 = 0.133 +- 0.187 (in-sample avg dev_std = 0.275)
NEC for r=0.9 all KL = 0.129 +- 0.187 (in-sample avg dev_std = 0.275)
NEC for r=0.9 all L1 = 0.151 +- 0.178 (in-sample avg dev_std = 0.275)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.89
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.833
NEC for r=1.0 class 0.0 = 0.266 +- 0.170 (in-sample avg dev_std = 0.245)
NEC for r=1.0 class 1.0 = 0.102 +- 0.170 (in-sample avg dev_std = 0.245)
NEC for r=1.0 all KL = 0.102 +- 0.170 (in-sample avg dev_std = 0.245)
NEC for r=1.0 all L1 = 0.121 +- 0.168 (in-sample avg dev_std = 0.245)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.56
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.533
NEC for r=0.3 class 0.0 = 0.319 +- 0.191 (in-sample avg dev_std = 0.349)
NEC for r=0.3 class 1.0 = 0.32 +- 0.191 (in-sample avg dev_std = 0.349)
NEC for r=0.3 all KL = 0.213 +- 0.191 (in-sample avg dev_std = 0.349)
NEC for r=0.3 all L1 = 0.32 +- 0.163 (in-sample avg dev_std = 0.349)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.634
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.612
NEC for r=0.6 class 0.0 = 0.326 +- 0.201 (in-sample avg dev_std = 0.374)
NEC for r=0.6 class 1.0 = 0.31 +- 0.201 (in-sample avg dev_std = 0.374)
NEC for r=0.6 all KL = 0.239 +- 0.201 (in-sample avg dev_std = 0.374)
NEC for r=0.6 all L1 = 0.313 +- 0.177 (in-sample avg dev_std = 0.374)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.674
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.644
NEC for r=0.9 class 0.0 = 0.276 +- 0.198 (in-sample avg dev_std = 0.317)
NEC for r=0.9 class 1.0 = 0.197 +- 0.198 (in-sample avg dev_std = 0.317)
NEC for r=0.9 all KL = 0.171 +- 0.198 (in-sample avg dev_std = 0.317)
NEC for r=0.9 all L1 = 0.21 +- 0.190 (in-sample avg dev_std = 0.317)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.699
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.667
NEC for r=1.0 class 0.0 = 0.238 +- 0.184 (in-sample avg dev_std = 0.287)
NEC for r=1.0 class 1.0 = 0.159 +- 0.184 (in-sample avg dev_std = 0.287)
NEC for r=1.0 all KL = 0.135 +- 0.184 (in-sample avg dev_std = 0.287)
NEC for r=1.0 all L1 = 0.172 +- 0.182 (in-sample avg dev_std = 0.287)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.713, 0.85, 0.932, 1.0], 'all_L1': [0.687, 0.829, 0.901, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.749, 0.743, 0.905, 1.0], 'all_L1': [0.607, 0.688, 0.865, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.778, 0.873, 0.958, 1.0], 'all_L1': [0.661, 0.824, 0.92, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.842, 0.875, 0.937, 1.0], 'all_L1': [0.722, 0.829, 0.889, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.643, 0.735, 0.901, 1.0], 'all_L1': [0.563, 0.699, 0.87, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.209, 0.123, 0.077, 0.078], 'all_L1': [0.258, 0.15, 0.106, 0.106]}), defaultdict(<class 'list'>, {'all_KL': [0.137, 0.222, 0.123, 0.092], 'all_L1': [0.286, 0.279, 0.148, 0.116]}), defaultdict(<class 'list'>, {'all_KL': [0.144, 0.112, 0.055, 0.04], 'all_L1': [0.266, 0.162, 0.088, 0.071]}), defaultdict(<class 'list'>, {'all_KL': [0.099, 0.111, 0.074, 0.068], 'all_L1': [0.217, 0.155, 0.118, 0.105]}), defaultdict(<class 'list'>, {'all_KL': [0.208, 0.214, 0.129, 0.102], 'all_L1': [0.321, 0.266, 0.151, 0.121]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.68, 0.787, 0.886, 1.0], 'all_L1': [0.618, 0.748, 0.829, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.777, 0.692, 0.849, 1.0], 'all_L1': [0.633, 0.617, 0.786, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.76, 0.826, 0.918, 1.0], 'all_L1': [0.637, 0.746, 0.85, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.836, 0.831, 0.891, 1.0], 'all_L1': [0.691, 0.745, 0.809, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.659, 0.693, 0.856, 1.0], 'all_L1': [0.579, 0.64, 0.808, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.212, 0.16, 0.121, 0.13], 'all_L1': [0.3, 0.213, 0.174, 0.185]}), defaultdict(<class 'list'>, {'all_KL': [0.13, 0.22, 0.168, 0.134], 'all_L1': [0.277, 0.308, 0.222, 0.185]}), defaultdict(<class 'list'>, {'all_KL': [0.14, 0.138, 0.087, 0.071], 'all_L1': [0.266, 0.219, 0.151, 0.134]}), defaultdict(<class 'list'>, {'all_KL': [0.098, 0.136, 0.115, 0.109], 'all_L1': [0.237, 0.222, 0.192, 0.183]}), defaultdict(<class 'list'>, {'all_KL': [0.213, 0.239, 0.171, 0.135], 'all_L1': [0.32, 0.313, 0.21, 0.172]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.648 +- 0.057, 0.774 +- 0.066, 0.889 +- 0.020, 1.000 +- 0.000
suff++ class all_KL  =  0.745 +- 0.066, 0.815 +- 0.063, 0.927 +- 0.021, 1.000 +- 0.000
suff++_acc_int  =  0.619 +- 0.033, 0.748 +- 0.024, 0.865 +- 0.021
nec class all_L1  =  0.270 +- 0.034, 0.202 +- 0.058, 0.122 +- 0.024, 0.104 +- 0.017
nec class all_KL  =  0.159 +- 0.043, 0.156 +- 0.051, 0.092 +- 0.029, 0.076 +- 0.021
nec_acc_int  =  0.656 +- 0.073, 0.801 +- 0.034, 0.861 +- 0.017, 0.864 +- 0.017

Eval split test
suff++ class all_L1  =  0.632 +- 0.036, 0.699 +- 0.058, 0.816 +- 0.022, 1.000 +- 0.000
suff++ class all_KL  =  0.742 +- 0.065, 0.766 +- 0.062, 0.880 +- 0.025, 1.000 +- 0.000
suff++_acc_int  =  0.574 +- 0.022, 0.620 +- 0.016, 0.670 +- 0.015
nec class all_L1  =  0.280 +- 0.028, 0.255 +- 0.045, 0.190 +- 0.025, 0.172 +- 0.020
nec class all_KL  =  0.159 +- 0.046, 0.179 +- 0.043, 0.132 +- 0.032, 0.116 +- 0.024
nec_acc_int  =  0.573 +- 0.046, 0.644 +- 0.023, 0.678 +- 0.019, 0.690 +- 0.013


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.459 +- 0.012, 0.488 +- 0.004, 0.506 +- 0.003, 0.552 +- 0.009
Faith. Armon (L1)= 		  =  0.377 +- 0.025, 0.314 +- 0.064, 0.214 +- 0.037, 0.188 +- 0.029
Faith. GMean (L1)= 	  =  0.416 +- 0.010, 0.389 +- 0.037, 0.328 +- 0.029, 0.321 +- 0.029
Faith. Aritm (KL)= 		  =  0.452 +- 0.016, 0.486 +- 0.007, 0.509 +- 0.004, 0.538 +- 0.011
Faith. Armon (KL)= 		  =  0.258 +- 0.055, 0.257 +- 0.066, 0.165 +- 0.048, 0.141 +- 0.037
Faith. GMean (KL)= 	  =  0.339 +- 0.034, 0.350 +- 0.042, 0.287 +- 0.043, 0.273 +- 0.041

Eval split test
Faith. Aritm (L1)= 		  =  0.456 +- 0.005, 0.477 +- 0.008, 0.503 +- 0.003, 0.586 +- 0.010
Faith. Armon (L1)= 		  =  0.386 +- 0.021, 0.369 +- 0.039, 0.307 +- 0.032, 0.293 +- 0.029
Faith. GMean (L1)= 	  =  0.419 +- 0.010, 0.419 +- 0.019, 0.392 +- 0.022, 0.414 +- 0.025
Faith. Aritm (KL)= 		  =  0.451 +- 0.010, 0.472 +- 0.010, 0.506 +- 0.004, 0.558 +- 0.012
Faith. Armon (KL)= 		  =  0.256 +- 0.058, 0.285 +- 0.050, 0.228 +- 0.048, 0.207 +- 0.040
Faith. GMean (KL)= 	  =  0.337 +- 0.036, 0.365 +- 0.029, 0.338 +- 0.038, 0.338 +- 0.038
Computed for split load_split = id



Completed in  0:25:09.535191  for LECIvGIN LBAPcore/assay



DONE LECI LBAPcore/assay
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 15:07:33 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:34 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:34 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:34 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:34 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:34 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:34 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:34 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:34 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:07:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 03:07:35 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 181...
[0m[1;37mINFO[0m: [1mCheckpoint 181: 
-----------------------------------
Train ACCURACY: 0.9982
Train Loss: 0.0116
ID Validation ACCURACY: 0.9041
ID Validation Loss: 0.3838
ID Test ACCURACY: 0.9016
ID Test Loss: 0.4021
OOD Validation ACCURACY: 0.8686
OOD Validation Loss: 0.5562
OOD Test ACCURACY: 0.5691
OOD Test Loss: 5.0866

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 143...
[0m[1;37mINFO[0m: [1mCheckpoint 143: 
-----------------------------------
Train ACCURACY: 0.9945
Train Loss: 0.0234
ID Validation ACCURACY: 0.9013
ID Validation Loss: 0.3604
ID Test ACCURACY: 0.9033
ID Test Loss: 0.3697
OOD Validation ACCURACY: 0.8911
OOD Validation Loss: 0.4327
OOD Test ACCURACY: 0.7119
OOD Test Loss: 1.6593

[0m[1;37mINFO[0m: [1mChartInfo 0.9016 0.5691 0.9033 0.7119 0.9013 0.8911[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.099
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.099
SUFF++ for r=0.3 class 0 = 0.513 +- 0.120 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.3 class 1 = 0.488 +- 0.120 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.3 class 2 = 0.502 +- 0.120 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.3 class 3 = 0.487 +- 0.120 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.3 class 4 = 0.503 +- 0.120 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.3 class 5 = 0.505 +- 0.120 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.3 class 6 = 0.497 +- 0.120 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.3 class 7 = 0.49 +- 0.120 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.3 class 8 = 0.501 +- 0.120 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.3 class 9 = 0.487 +- 0.120 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.3 all KL = 0.624 +- 0.120 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.3 all L1 = 0.497 +- 0.071 (in-sample avg dev_std = 0.391)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.203
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.17
SUFF++ for r=0.6 class 0 = 0.34 +- 0.204 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 class 1 = 0.438 +- 0.204 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 class 2 = 0.391 +- 0.204 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 class 3 = 0.34 +- 0.204 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 class 4 = 0.41 +- 0.204 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 class 5 = 0.375 +- 0.204 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 class 6 = 0.377 +- 0.204 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 class 7 = 0.379 +- 0.204 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 class 8 = 0.369 +- 0.204 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 class 9 = 0.369 +- 0.204 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 all KL = 0.303 +- 0.204 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 all L1 = 0.379 +- 0.135 (in-sample avg dev_std = 0.402)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.809
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.753
SUFF++ for r=0.9 class 0 = 0.923 +- 0.244 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 1 = 0.956 +- 0.244 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 2 = 0.757 +- 0.244 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 3 = 0.712 +- 0.244 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 4 = 0.851 +- 0.244 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 5 = 0.731 +- 0.244 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 6 = 0.788 +- 0.244 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 7 = 0.827 +- 0.244 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 8 = 0.813 +- 0.244 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 9 = 0.748 +- 0.244 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 all KL = 0.822 +- 0.244 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 all L1 = 0.813 +- 0.213 (in-sample avg dev_std = 0.263)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.11
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.104
SUFF++ for r=0.3 class 0 = 0.538 +- 0.104 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 1 = 0.521 +- 0.104 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 2 = 0.538 +- 0.104 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 3 = 0.522 +- 0.104 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 4 = 0.53 +- 0.104 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 5 = 0.527 +- 0.104 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 6 = 0.536 +- 0.104 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 7 = 0.519 +- 0.104 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 8 = 0.542 +- 0.104 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 9 = 0.54 +- 0.104 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 all KL = 0.69 +- 0.104 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 all L1 = 0.531 +- 0.075 (in-sample avg dev_std = 0.342)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.174
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.155
SUFF++ for r=0.6 class 0 = 0.465 +- 0.215 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 class 1 = 0.439 +- 0.215 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 class 2 = 0.447 +- 0.215 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 class 3 = 0.417 +- 0.215 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 class 4 = 0.445 +- 0.215 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 class 5 = 0.42 +- 0.215 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 class 6 = 0.442 +- 0.215 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 class 7 = 0.429 +- 0.215 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 class 8 = 0.393 +- 0.215 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 class 9 = 0.401 +- 0.215 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 all KL = 0.381 +- 0.215 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 all L1 = 0.43 +- 0.137 (in-sample avg dev_std = 0.415)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.595
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.56
SUFF++ for r=0.9 class 0 = 0.78 +- 0.279 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.9 class 1 = 0.934 +- 0.279 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.9 class 2 = 0.703 +- 0.279 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.9 class 3 = 0.7 +- 0.279 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.9 class 4 = 0.741 +- 0.279 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.9 class 5 = 0.647 +- 0.279 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.9 class 6 = 0.751 +- 0.279 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.9 class 7 = 0.826 +- 0.279 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.9 class 8 = 0.66 +- 0.279 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.9 class 9 = 0.68 +- 0.279 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.9 all KL = 0.752 +- 0.279 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.9 all L1 = 0.745 +- 0.239 (in-sample avg dev_std = 0.337)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.099
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.099
NEC for r=0.3 class 0 = 0.366 +- 0.091 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 1 = 0.345 +- 0.091 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 2 = 0.353 +- 0.091 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 3 = 0.381 +- 0.091 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 4 = 0.361 +- 0.091 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 5 = 0.349 +- 0.091 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 6 = 0.388 +- 0.091 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 7 = 0.373 +- 0.091 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 8 = 0.359 +- 0.091 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 9 = 0.367 +- 0.091 (in-sample avg dev_std = 0.158)
NEC for r=0.3 all KL = 0.167 +- 0.091 (in-sample avg dev_std = 0.158)
NEC for r=0.3 all L1 = 0.364 +- 0.090 (in-sample avg dev_std = 0.158)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.203
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.157
NEC for r=0.6 class 0 = 0.571 +- 0.233 (in-sample avg dev_std = 0.319)
NEC for r=0.6 class 1 = 0.507 +- 0.233 (in-sample avg dev_std = 0.319)
NEC for r=0.6 class 2 = 0.448 +- 0.233 (in-sample avg dev_std = 0.319)
NEC for r=0.6 class 3 = 0.526 +- 0.233 (in-sample avg dev_std = 0.319)
NEC for r=0.6 class 4 = 0.488 +- 0.233 (in-sample avg dev_std = 0.319)
NEC for r=0.6 class 5 = 0.459 +- 0.233 (in-sample avg dev_std = 0.319)
NEC for r=0.6 class 6 = 0.518 +- 0.233 (in-sample avg dev_std = 0.319)
NEC for r=0.6 class 7 = 0.51 +- 0.233 (in-sample avg dev_std = 0.319)
NEC for r=0.6 class 8 = 0.543 +- 0.233 (in-sample avg dev_std = 0.319)
NEC for r=0.6 class 9 = 0.541 +- 0.233 (in-sample avg dev_std = 0.319)
NEC for r=0.6 all KL = 0.476 +- 0.233 (in-sample avg dev_std = 0.319)
NEC for r=0.6 all L1 = 0.512 +- 0.172 (in-sample avg dev_std = 0.319)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.809
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.608
NEC for r=0.9 class 0 = 0.319 +- 0.331 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 1 = 0.146 +- 0.331 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 2 = 0.385 +- 0.331 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 3 = 0.597 +- 0.331 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 4 = 0.285 +- 0.331 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 5 = 0.506 +- 0.331 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 6 = 0.492 +- 0.331 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 7 = 0.407 +- 0.331 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 8 = 0.392 +- 0.331 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 9 = 0.538 +- 0.331 (in-sample avg dev_std = 0.456)
NEC for r=0.9 all KL = 0.573 +- 0.331 (in-sample avg dev_std = 0.456)
NEC for r=0.9 all L1 = 0.403 +- 0.268 (in-sample avg dev_std = 0.456)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.955
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.835
NEC for r=1.0 class 0 = 0.097 +- 0.369 (in-sample avg dev_std = 0.406)
NEC for r=1.0 class 1 = 0.024 +- 0.369 (in-sample avg dev_std = 0.406)
NEC for r=1.0 class 2 = 0.27 +- 0.369 (in-sample avg dev_std = 0.406)
NEC for r=1.0 class 3 = 0.381 +- 0.369 (in-sample avg dev_std = 0.406)
NEC for r=1.0 class 4 = 0.168 +- 0.369 (in-sample avg dev_std = 0.406)
NEC for r=1.0 class 5 = 0.343 +- 0.369 (in-sample avg dev_std = 0.406)
NEC for r=1.0 class 6 = 0.319 +- 0.369 (in-sample avg dev_std = 0.406)
NEC for r=1.0 class 7 = 0.15 +- 0.369 (in-sample avg dev_std = 0.406)
NEC for r=1.0 class 8 = 0.202 +- 0.369 (in-sample avg dev_std = 0.406)
NEC for r=1.0 class 9 = 0.387 +- 0.369 (in-sample avg dev_std = 0.406)
NEC for r=1.0 all KL = 0.399 +- 0.369 (in-sample avg dev_std = 0.406)
NEC for r=1.0 all L1 = 0.23 +- 0.257 (in-sample avg dev_std = 0.406)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.11
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.106
NEC for r=0.3 class 0 = 0.375 +- 0.086 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 1 = 0.357 +- 0.086 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 2 = 0.375 +- 0.086 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 3 = 0.383 +- 0.086 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 4 = 0.366 +- 0.086 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 5 = 0.359 +- 0.086 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 6 = 0.372 +- 0.086 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 7 = 0.383 +- 0.086 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 8 = 0.369 +- 0.086 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 9 = 0.359 +- 0.086 (in-sample avg dev_std = 0.158)
NEC for r=0.3 all KL = 0.168 +- 0.086 (in-sample avg dev_std = 0.158)
NEC for r=0.3 all L1 = 0.37 +- 0.090 (in-sample avg dev_std = 0.158)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.174
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.143
NEC for r=0.6 class 0 = 0.346 +- 0.235 (in-sample avg dev_std = 0.326)
NEC for r=0.6 class 1 = 0.49 +- 0.235 (in-sample avg dev_std = 0.326)
NEC for r=0.6 class 2 = 0.389 +- 0.235 (in-sample avg dev_std = 0.326)
NEC for r=0.6 class 3 = 0.431 +- 0.235 (in-sample avg dev_std = 0.326)
NEC for r=0.6 class 4 = 0.455 +- 0.235 (in-sample avg dev_std = 0.326)
NEC for r=0.6 class 5 = 0.433 +- 0.235 (in-sample avg dev_std = 0.326)
NEC for r=0.6 class 6 = 0.443 +- 0.235 (in-sample avg dev_std = 0.326)
NEC for r=0.6 class 7 = 0.431 +- 0.235 (in-sample avg dev_std = 0.326)
NEC for r=0.6 class 8 = 0.506 +- 0.235 (in-sample avg dev_std = 0.326)
NEC for r=0.6 class 9 = 0.529 +- 0.235 (in-sample avg dev_std = 0.326)
NEC for r=0.6 all KL = 0.398 +- 0.235 (in-sample avg dev_std = 0.326)
NEC for r=0.6 all L1 = 0.445 +- 0.192 (in-sample avg dev_std = 0.326)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.595
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.448
NEC for r=0.9 class 0 = 0.626 +- 0.348 (in-sample avg dev_std = 0.428)
NEC for r=0.9 class 1 = 0.115 +- 0.348 (in-sample avg dev_std = 0.428)
NEC for r=0.9 class 2 = 0.494 +- 0.348 (in-sample avg dev_std = 0.428)
NEC for r=0.9 class 3 = 0.591 +- 0.348 (in-sample avg dev_std = 0.428)
NEC for r=0.9 class 4 = 0.446 +- 0.348 (in-sample avg dev_std = 0.428)
NEC for r=0.9 class 5 = 0.629 +- 0.348 (in-sample avg dev_std = 0.428)
NEC for r=0.9 class 6 = 0.579 +- 0.348 (in-sample avg dev_std = 0.428)
NEC for r=0.9 class 7 = 0.307 +- 0.348 (in-sample avg dev_std = 0.428)
NEC for r=0.9 class 8 = 0.64 +- 0.348 (in-sample avg dev_std = 0.428)
NEC for r=0.9 class 9 = 0.568 +- 0.348 (in-sample avg dev_std = 0.428)
NEC for r=0.9 all KL = 0.631 +- 0.348 (in-sample avg dev_std = 0.428)
NEC for r=0.9 all L1 = 0.494 +- 0.285 (in-sample avg dev_std = 0.428)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.571
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.585
NEC for r=1.0 class 0 = 0.359 +- 0.391 (in-sample avg dev_std = 0.425)
NEC for r=1.0 class 1 = 0.049 +- 0.391 (in-sample avg dev_std = 0.425)
NEC for r=1.0 class 2 = 0.524 +- 0.391 (in-sample avg dev_std = 0.425)
NEC for r=1.0 class 3 = 0.488 +- 0.391 (in-sample avg dev_std = 0.425)
NEC for r=1.0 class 4 = 0.58 +- 0.391 (in-sample avg dev_std = 0.425)
NEC for r=1.0 class 5 = 0.518 +- 0.391 (in-sample avg dev_std = 0.425)
NEC for r=1.0 class 6 = 0.471 +- 0.391 (in-sample avg dev_std = 0.425)
NEC for r=1.0 class 7 = 0.304 +- 0.391 (in-sample avg dev_std = 0.425)
NEC for r=1.0 class 8 = 0.624 +- 0.391 (in-sample avg dev_std = 0.425)
NEC for r=1.0 class 9 = 0.531 +- 0.391 (in-sample avg dev_std = 0.425)
NEC for r=1.0 all KL = 0.598 +- 0.391 (in-sample avg dev_std = 0.425)
NEC for r=1.0 all L1 = 0.439 +- 0.313 (in-sample avg dev_std = 0.425)
model_dirname= repr_LECIvGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 15:20:18 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 03:20:19 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 153...
[0m[1;37mINFO[0m: [1mCheckpoint 153: 
-----------------------------------
Train ACCURACY: 0.9895
Train Loss: 0.0368
ID Validation ACCURACY: 0.8991
ID Validation Loss: 0.3644
ID Test ACCURACY: 0.8936
ID Test Loss: 0.3839
OOD Validation ACCURACY: 0.8770
OOD Validation Loss: 0.4499
OOD Test ACCURACY: 0.4940
OOD Test Loss: 2.9614

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 161...
[0m[1;37mINFO[0m: [1mCheckpoint 161: 
-----------------------------------
Train ACCURACY: 0.9911
Train Loss: 0.0328
ID Validation ACCURACY: 0.8986
ID Validation Loss: 0.3696
ID Test ACCURACY: 0.8951
ID Test Loss: 0.3805
OOD Validation ACCURACY: 0.8856
OOD Validation Loss: 0.4241
OOD Test ACCURACY: 0.5491
OOD Test Loss: 2.5001

[0m[1;37mINFO[0m: [1mChartInfo 0.8936 0.4940 0.8951 0.5491 0.8986 0.8856[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.096
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.093
SUFF++ for r=0.3 class 0 = 0.601 +- 0.103 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.3 class 1 = 0.597 +- 0.103 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.3 class 2 = 0.581 +- 0.103 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.3 class 3 = 0.584 +- 0.103 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.3 class 4 = 0.578 +- 0.103 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.3 class 5 = 0.587 +- 0.103 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.3 class 6 = 0.579 +- 0.103 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.3 class 7 = 0.582 +- 0.103 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.3 class 8 = 0.606 +- 0.103 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.3 class 9 = 0.585 +- 0.103 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.3 all KL = 0.771 +- 0.103 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.3 all L1 = 0.588 +- 0.098 (in-sample avg dev_std = 0.326)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.169
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.105
SUFF++ for r=0.6 class 0 = 0.38 +- 0.226 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 class 1 = 0.429 +- 0.226 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 class 2 = 0.401 +- 0.226 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 class 3 = 0.37 +- 0.226 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 class 4 = 0.401 +- 0.226 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 class 5 = 0.398 +- 0.226 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 class 6 = 0.429 +- 0.226 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 class 7 = 0.384 +- 0.226 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 class 8 = 0.417 +- 0.226 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 class 9 = 0.409 +- 0.226 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 all KL = 0.378 +- 0.226 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 all L1 = 0.402 +- 0.151 (in-sample avg dev_std = 0.346)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.805
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.752
SUFF++ for r=0.9 class 0 = 0.915 +- 0.237 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 1 = 0.925 +- 0.237 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 2 = 0.768 +- 0.237 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 3 = 0.711 +- 0.237 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 4 = 0.808 +- 0.237 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 5 = 0.708 +- 0.237 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 6 = 0.775 +- 0.237 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 7 = 0.828 +- 0.237 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 8 = 0.795 +- 0.237 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 9 = 0.759 +- 0.237 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 all KL = 0.818 +- 0.237 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 all L1 = 0.802 +- 0.206 (in-sample avg dev_std = 0.285)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.095
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.096
SUFF++ for r=0.3 class 0 = 0.633 +- 0.090 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.3 class 1 = 0.636 +- 0.090 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.3 class 2 = 0.614 +- 0.090 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.3 class 3 = 0.612 +- 0.090 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.3 class 4 = 0.626 +- 0.090 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.3 class 5 = 0.623 +- 0.090 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.3 class 6 = 0.642 +- 0.090 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.3 class 7 = 0.628 +- 0.090 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.3 class 8 = 0.643 +- 0.090 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.3 class 9 = 0.637 +- 0.090 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.3 all KL = 0.812 +- 0.090 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.3 all L1 = 0.63 +- 0.098 (in-sample avg dev_std = 0.293)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.131
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.112
SUFF++ for r=0.6 class 0 = 0.571 +- 0.244 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.6 class 1 = 0.477 +- 0.244 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.6 class 2 = 0.58 +- 0.244 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.6 class 3 = 0.54 +- 0.244 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.6 class 4 = 0.583 +- 0.244 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.6 class 5 = 0.549 +- 0.244 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.6 class 6 = 0.628 +- 0.244 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.6 class 7 = 0.506 +- 0.244 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.6 class 8 = 0.496 +- 0.244 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.6 class 9 = 0.512 +- 0.244 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.6 all KL = 0.552 +- 0.244 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.6 all L1 = 0.543 +- 0.192 (in-sample avg dev_std = 0.298)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.426
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.398
SUFF++ for r=0.9 class 0 = 0.763 +- 0.211 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 class 1 = 0.876 +- 0.211 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 class 2 = 0.831 +- 0.211 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 class 3 = 0.713 +- 0.211 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 class 4 = 0.812 +- 0.211 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 class 5 = 0.717 +- 0.211 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 class 6 = 0.71 +- 0.211 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 class 7 = 0.763 +- 0.211 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 class 8 = 0.709 +- 0.211 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 class 9 = 0.745 +- 0.211 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 all KL = 0.818 +- 0.211 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 all L1 = 0.766 +- 0.202 (in-sample avg dev_std = 0.281)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.096
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.091
NEC for r=0.3 class 0 = 0.296 +- 0.097 (in-sample avg dev_std = 0.137)
NEC for r=0.3 class 1 = 0.293 +- 0.097 (in-sample avg dev_std = 0.137)
NEC for r=0.3 class 2 = 0.317 +- 0.097 (in-sample avg dev_std = 0.137)
NEC for r=0.3 class 3 = 0.309 +- 0.097 (in-sample avg dev_std = 0.137)
NEC for r=0.3 class 4 = 0.315 +- 0.097 (in-sample avg dev_std = 0.137)
NEC for r=0.3 class 5 = 0.296 +- 0.097 (in-sample avg dev_std = 0.137)
NEC for r=0.3 class 6 = 0.319 +- 0.097 (in-sample avg dev_std = 0.137)
NEC for r=0.3 class 7 = 0.31 +- 0.097 (in-sample avg dev_std = 0.137)
NEC for r=0.3 class 8 = 0.281 +- 0.097 (in-sample avg dev_std = 0.137)
NEC for r=0.3 class 9 = 0.305 +- 0.097 (in-sample avg dev_std = 0.137)
NEC for r=0.3 all KL = 0.133 +- 0.097 (in-sample avg dev_std = 0.137)
NEC for r=0.3 all L1 = 0.304 +- 0.097 (in-sample avg dev_std = 0.137)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.169
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.122
NEC for r=0.6 class 0 = 0.541 +- 0.231 (in-sample avg dev_std = 0.300)
NEC for r=0.6 class 1 = 0.469 +- 0.231 (in-sample avg dev_std = 0.300)
NEC for r=0.6 class 2 = 0.508 +- 0.231 (in-sample avg dev_std = 0.300)
NEC for r=0.6 class 3 = 0.555 +- 0.231 (in-sample avg dev_std = 0.300)
NEC for r=0.6 class 4 = 0.513 +- 0.231 (in-sample avg dev_std = 0.300)
NEC for r=0.6 class 5 = 0.535 +- 0.231 (in-sample avg dev_std = 0.300)
NEC for r=0.6 class 6 = 0.481 +- 0.231 (in-sample avg dev_std = 0.300)
NEC for r=0.6 class 7 = 0.528 +- 0.231 (in-sample avg dev_std = 0.300)
NEC for r=0.6 class 8 = 0.495 +- 0.231 (in-sample avg dev_std = 0.300)
NEC for r=0.6 class 9 = 0.521 +- 0.231 (in-sample avg dev_std = 0.300)
NEC for r=0.6 all KL = 0.458 +- 0.231 (in-sample avg dev_std = 0.300)
NEC for r=0.6 all L1 = 0.514 +- 0.165 (in-sample avg dev_std = 0.300)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.805
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.611
NEC for r=0.9 class 0 = 0.367 +- 0.312 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 1 = 0.194 +- 0.312 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 2 = 0.319 +- 0.312 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 3 = 0.584 +- 0.312 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 4 = 0.346 +- 0.312 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 5 = 0.566 +- 0.312 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 6 = 0.449 +- 0.312 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 7 = 0.43 +- 0.312 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 8 = 0.443 +- 0.312 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 9 = 0.453 +- 0.312 (in-sample avg dev_std = 0.432)
NEC for r=0.9 all KL = 0.54 +- 0.312 (in-sample avg dev_std = 0.432)
NEC for r=0.9 all L1 = 0.411 +- 0.254 (in-sample avg dev_std = 0.432)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.955
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.838
NEC for r=1.0 class 0 = 0.119 +- 0.338 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 1 = 0.02 +- 0.338 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 2 = 0.21 +- 0.338 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 3 = 0.338 +- 0.338 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 4 = 0.169 +- 0.338 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 5 = 0.401 +- 0.338 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 6 = 0.336 +- 0.338 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 7 = 0.21 +- 0.338 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 8 = 0.238 +- 0.338 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 9 = 0.341 +- 0.338 (in-sample avg dev_std = 0.385)
NEC for r=1.0 all KL = 0.364 +- 0.338 (in-sample avg dev_std = 0.385)
NEC for r=1.0 all L1 = 0.233 +- 0.247 (in-sample avg dev_std = 0.385)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.095
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.099
NEC for r=0.3 class 0 = 0.288 +- 0.078 (in-sample avg dev_std = 0.117)
NEC for r=0.3 class 1 = 0.246 +- 0.078 (in-sample avg dev_std = 0.117)
NEC for r=0.3 class 2 = 0.289 +- 0.078 (in-sample avg dev_std = 0.117)
NEC for r=0.3 class 3 = 0.287 +- 0.078 (in-sample avg dev_std = 0.117)
NEC for r=0.3 class 4 = 0.279 +- 0.078 (in-sample avg dev_std = 0.117)
NEC for r=0.3 class 5 = 0.269 +- 0.078 (in-sample avg dev_std = 0.117)
NEC for r=0.3 class 6 = 0.271 +- 0.078 (in-sample avg dev_std = 0.117)
NEC for r=0.3 class 7 = 0.271 +- 0.078 (in-sample avg dev_std = 0.117)
NEC for r=0.3 class 8 = 0.259 +- 0.078 (in-sample avg dev_std = 0.117)
NEC for r=0.3 class 9 = 0.278 +- 0.078 (in-sample avg dev_std = 0.117)
NEC for r=0.3 all KL = 0.109 +- 0.078 (in-sample avg dev_std = 0.117)
NEC for r=0.3 all L1 = 0.274 +- 0.096 (in-sample avg dev_std = 0.117)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.131
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.12
NEC for r=0.6 class 0 = 0.385 +- 0.192 (in-sample avg dev_std = 0.268)
NEC for r=0.6 class 1 = 0.382 +- 0.192 (in-sample avg dev_std = 0.268)
NEC for r=0.6 class 2 = 0.344 +- 0.192 (in-sample avg dev_std = 0.268)
NEC for r=0.6 class 3 = 0.371 +- 0.192 (in-sample avg dev_std = 0.268)
NEC for r=0.6 class 4 = 0.344 +- 0.192 (in-sample avg dev_std = 0.268)
NEC for r=0.6 class 5 = 0.381 +- 0.192 (in-sample avg dev_std = 0.268)
NEC for r=0.6 class 6 = 0.332 +- 0.192 (in-sample avg dev_std = 0.268)
NEC for r=0.6 class 7 = 0.408 +- 0.192 (in-sample avg dev_std = 0.268)
NEC for r=0.6 class 8 = 0.405 +- 0.192 (in-sample avg dev_std = 0.268)
NEC for r=0.6 class 9 = 0.421 +- 0.192 (in-sample avg dev_std = 0.268)
NEC for r=0.6 all KL = 0.312 +- 0.192 (in-sample avg dev_std = 0.268)
NEC for r=0.6 all L1 = 0.377 +- 0.181 (in-sample avg dev_std = 0.268)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.426
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.274
NEC for r=0.9 class 0 = 0.388 +- 0.320 (in-sample avg dev_std = 0.346)
NEC for r=0.9 class 1 = 0.292 +- 0.320 (in-sample avg dev_std = 0.346)
NEC for r=0.9 class 2 = 0.27 +- 0.320 (in-sample avg dev_std = 0.346)
NEC for r=0.9 class 3 = 0.454 +- 0.320 (in-sample avg dev_std = 0.346)
NEC for r=0.9 class 4 = 0.356 +- 0.320 (in-sample avg dev_std = 0.346)
NEC for r=0.9 class 5 = 0.489 +- 0.320 (in-sample avg dev_std = 0.346)
NEC for r=0.9 class 6 = 0.474 +- 0.320 (in-sample avg dev_std = 0.346)
NEC for r=0.9 class 7 = 0.436 +- 0.320 (in-sample avg dev_std = 0.346)
NEC for r=0.9 class 8 = 0.489 +- 0.320 (in-sample avg dev_std = 0.346)
NEC for r=0.9 class 9 = 0.454 +- 0.320 (in-sample avg dev_std = 0.346)
NEC for r=0.9 all KL = 0.436 +- 0.320 (in-sample avg dev_std = 0.346)
NEC for r=0.9 all L1 = 0.407 +- 0.273 (in-sample avg dev_std = 0.346)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.5
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.378
NEC for r=1.0 class 0 = 0.402 +- 0.332 (in-sample avg dev_std = 0.378)
NEC for r=1.0 class 1 = 0.186 +- 0.332 (in-sample avg dev_std = 0.378)
NEC for r=1.0 class 2 = 0.183 +- 0.332 (in-sample avg dev_std = 0.378)
NEC for r=1.0 class 3 = 0.466 +- 0.332 (in-sample avg dev_std = 0.378)
NEC for r=1.0 class 4 = 0.352 +- 0.332 (in-sample avg dev_std = 0.378)
NEC for r=1.0 class 5 = 0.453 +- 0.332 (in-sample avg dev_std = 0.378)
NEC for r=1.0 class 6 = 0.519 +- 0.332 (in-sample avg dev_std = 0.378)
NEC for r=1.0 class 7 = 0.389 +- 0.332 (in-sample avg dev_std = 0.378)
NEC for r=1.0 class 8 = 0.507 +- 0.332 (in-sample avg dev_std = 0.378)
NEC for r=1.0 class 9 = 0.52 +- 0.332 (in-sample avg dev_std = 0.378)
NEC for r=1.0 all KL = 0.451 +- 0.332 (in-sample avg dev_std = 0.378)
NEC for r=1.0 all L1 = 0.392 +- 0.274 (in-sample avg dev_std = 0.378)
model_dirname= repr_LECIvGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 15:32:50 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:50 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 03:32:51 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 189...
[0m[1;37mINFO[0m: [1mCheckpoint 189: 
-----------------------------------
Train ACCURACY: 0.9977
Train Loss: 0.0122
ID Validation ACCURACY: 0.9020
ID Validation Loss: 0.4048
ID Test ACCURACY: 0.8964
ID Test Loss: 0.4180
OOD Validation ACCURACY: 0.8684
OOD Validation Loss: 0.5222
OOD Test ACCURACY: 0.3916
OOD Test Loss: 6.8162

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 97...
[0m[1;37mINFO[0m: [1mCheckpoint 97: 
-----------------------------------
Train ACCURACY: 0.9677
Train Loss: 0.0990
ID Validation ACCURACY: 0.8980
ID Validation Loss: 0.3369
ID Test ACCURACY: 0.8956
ID Test Loss: 0.3387
OOD Validation ACCURACY: 0.8854
OOD Validation Loss: 0.3793
OOD Test ACCURACY: 0.7431
OOD Test Loss: 1.0135

[0m[1;37mINFO[0m: [1mChartInfo 0.8964 0.3916 0.8956 0.7431 0.8980 0.8854[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.087
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.1
SUFF++ for r=0.3 class 0 = 0.489 +- 0.174 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.3 class 1 = 0.46 +- 0.174 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.3 class 2 = 0.472 +- 0.174 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.3 class 3 = 0.448 +- 0.174 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.3 class 4 = 0.459 +- 0.174 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.3 class 5 = 0.464 +- 0.174 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.3 class 6 = 0.47 +- 0.174 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.3 class 7 = 0.449 +- 0.174 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.3 class 8 = 0.463 +- 0.174 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.3 class 9 = 0.45 +- 0.174 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.3 all KL = 0.537 +- 0.174 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.3 all L1 = 0.462 +- 0.105 (in-sample avg dev_std = 0.452)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.216
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.152
SUFF++ for r=0.6 class 0 = 0.312 +- 0.216 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 class 1 = 0.335 +- 0.216 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 class 2 = 0.352 +- 0.216 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 class 3 = 0.355 +- 0.216 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 class 4 = 0.391 +- 0.216 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 class 5 = 0.336 +- 0.216 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 class 6 = 0.378 +- 0.216 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 class 7 = 0.335 +- 0.216 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 class 8 = 0.415 +- 0.216 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 class 9 = 0.381 +- 0.216 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 all KL = 0.273 +- 0.216 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 all L1 = 0.358 +- 0.140 (in-sample avg dev_std = 0.456)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.816
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.757
SUFF++ for r=0.9 class 0 = 0.939 +- 0.255 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 class 1 = 0.956 +- 0.255 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 class 2 = 0.764 +- 0.255 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 class 3 = 0.729 +- 0.255 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 class 4 = 0.817 +- 0.255 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 class 5 = 0.683 +- 0.255 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 class 6 = 0.8 +- 0.255 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 class 7 = 0.812 +- 0.255 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 class 8 = 0.852 +- 0.255 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 class 9 = 0.778 +- 0.255 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 all KL = 0.815 +- 0.255 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 all L1 = 0.816 +- 0.215 (in-sample avg dev_std = 0.281)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.119
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.115
SUFF++ for r=0.3 class 0 = 0.492 +- 0.173 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 class 1 = 0.421 +- 0.173 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 class 2 = 0.484 +- 0.173 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 class 3 = 0.474 +- 0.173 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 class 4 = 0.468 +- 0.173 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 class 5 = 0.465 +- 0.173 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 class 6 = 0.446 +- 0.173 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 class 7 = 0.468 +- 0.173 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 class 8 = 0.444 +- 0.173 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 class 9 = 0.425 +- 0.173 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 all KL = 0.485 +- 0.173 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 all L1 = 0.459 +- 0.109 (in-sample avg dev_std = 0.462)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.186
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.174
SUFF++ for r=0.6 class 0 = 0.432 +- 0.249 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 class 1 = 0.452 +- 0.249 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 class 2 = 0.418 +- 0.249 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 class 3 = 0.439 +- 0.249 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 class 4 = 0.415 +- 0.249 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 class 5 = 0.432 +- 0.249 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 class 6 = 0.401 +- 0.249 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 class 7 = 0.427 +- 0.249 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 class 8 = 0.397 +- 0.249 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 class 9 = 0.372 +- 0.249 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 all KL = 0.364 +- 0.249 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 all L1 = 0.419 +- 0.176 (in-sample avg dev_std = 0.443)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.381
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.347
SUFF++ for r=0.9 class 0 = 0.701 +- 0.272 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.9 class 1 = 0.805 +- 0.272 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.9 class 2 = 0.751 +- 0.272 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.9 class 3 = 0.622 +- 0.272 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.9 class 4 = 0.696 +- 0.272 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.9 class 5 = 0.732 +- 0.272 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.9 class 6 = 0.679 +- 0.272 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.9 class 7 = 0.718 +- 0.272 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.9 class 8 = 0.651 +- 0.272 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.9 class 9 = 0.674 +- 0.272 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.9 all KL = 0.72 +- 0.272 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.9 all L1 = 0.704 +- 0.223 (in-sample avg dev_std = 0.385)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.087
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.105
NEC for r=0.3 class 0 = 0.41 +- 0.149 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 1 = 0.421 +- 0.149 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 2 = 0.406 +- 0.149 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 3 = 0.427 +- 0.149 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 4 = 0.404 +- 0.149 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 5 = 0.384 +- 0.149 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 6 = 0.41 +- 0.149 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 7 = 0.402 +- 0.149 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 8 = 0.415 +- 0.149 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 9 = 0.429 +- 0.149 (in-sample avg dev_std = 0.232)
NEC for r=0.3 all KL = 0.26 +- 0.149 (in-sample avg dev_std = 0.232)
NEC for r=0.3 all L1 = 0.411 +- 0.122 (in-sample avg dev_std = 0.232)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.216
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.177
NEC for r=0.6 class 0 = 0.592 +- 0.228 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 1 = 0.472 +- 0.228 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 2 = 0.536 +- 0.228 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 3 = 0.512 +- 0.228 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 4 = 0.461 +- 0.228 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 5 = 0.539 +- 0.228 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 6 = 0.532 +- 0.228 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 7 = 0.538 +- 0.228 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 8 = 0.493 +- 0.228 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 9 = 0.523 +- 0.228 (in-sample avg dev_std = 0.351)
NEC for r=0.6 all KL = 0.523 +- 0.228 (in-sample avg dev_std = 0.351)
NEC for r=0.6 all L1 = 0.519 +- 0.168 (in-sample avg dev_std = 0.351)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.816
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.639
NEC for r=0.9 class 0 = 0.287 +- 0.339 (in-sample avg dev_std = 0.452)
NEC for r=0.9 class 1 = 0.117 +- 0.339 (in-sample avg dev_std = 0.452)
NEC for r=0.9 class 2 = 0.396 +- 0.339 (in-sample avg dev_std = 0.452)
NEC for r=0.9 class 3 = 0.488 +- 0.339 (in-sample avg dev_std = 0.452)
NEC for r=0.9 class 4 = 0.404 +- 0.339 (in-sample avg dev_std = 0.452)
NEC for r=0.9 class 5 = 0.588 +- 0.339 (in-sample avg dev_std = 0.452)
NEC for r=0.9 class 6 = 0.46 +- 0.339 (in-sample avg dev_std = 0.452)
NEC for r=0.9 class 7 = 0.379 +- 0.339 (in-sample avg dev_std = 0.452)
NEC for r=0.9 class 8 = 0.322 +- 0.339 (in-sample avg dev_std = 0.452)
NEC for r=0.9 class 9 = 0.418 +- 0.339 (in-sample avg dev_std = 0.452)
NEC for r=0.9 all KL = 0.536 +- 0.339 (in-sample avg dev_std = 0.452)
NEC for r=0.9 all L1 = 0.38 +- 0.271 (in-sample avg dev_std = 0.452)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.952
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.849
NEC for r=1.0 class 0 = 0.074 +- 0.365 (in-sample avg dev_std = 0.411)
NEC for r=1.0 class 1 = 0.018 +- 0.365 (in-sample avg dev_std = 0.411)
NEC for r=1.0 class 2 = 0.258 +- 0.365 (in-sample avg dev_std = 0.411)
NEC for r=1.0 class 3 = 0.275 +- 0.365 (in-sample avg dev_std = 0.411)
NEC for r=1.0 class 4 = 0.204 +- 0.365 (in-sample avg dev_std = 0.411)
NEC for r=1.0 class 5 = 0.38 +- 0.365 (in-sample avg dev_std = 0.411)
NEC for r=1.0 class 6 = 0.281 +- 0.365 (in-sample avg dev_std = 0.411)
NEC for r=1.0 class 7 = 0.2 +- 0.365 (in-sample avg dev_std = 0.411)
NEC for r=1.0 class 8 = 0.161 +- 0.365 (in-sample avg dev_std = 0.411)
NEC for r=1.0 class 9 = 0.276 +- 0.365 (in-sample avg dev_std = 0.411)
NEC for r=1.0 all KL = 0.375 +- 0.365 (in-sample avg dev_std = 0.411)
NEC for r=1.0 all L1 = 0.208 +- 0.240 (in-sample avg dev_std = 0.411)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.119
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.123
NEC for r=0.3 class 0 = 0.37 +- 0.148 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 1 = 0.409 +- 0.148 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 2 = 0.381 +- 0.148 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 3 = 0.4 +- 0.148 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 4 = 0.408 +- 0.148 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 5 = 0.392 +- 0.148 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 6 = 0.412 +- 0.148 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 7 = 0.367 +- 0.148 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 8 = 0.415 +- 0.148 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 9 = 0.437 +- 0.148 (in-sample avg dev_std = 0.220)
NEC for r=0.3 all KL = 0.248 +- 0.148 (in-sample avg dev_std = 0.220)
NEC for r=0.3 all L1 = 0.399 +- 0.124 (in-sample avg dev_std = 0.220)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.186
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.178
NEC for r=0.6 class 0 = 0.508 +- 0.242 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 1 = 0.429 +- 0.242 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 2 = 0.483 +- 0.242 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 3 = 0.513 +- 0.242 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 4 = 0.469 +- 0.242 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 5 = 0.491 +- 0.242 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 6 = 0.478 +- 0.242 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 7 = 0.498 +- 0.242 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 8 = 0.462 +- 0.242 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 9 = 0.504 +- 0.242 (in-sample avg dev_std = 0.359)
NEC for r=0.6 all KL = 0.468 +- 0.242 (in-sample avg dev_std = 0.359)
NEC for r=0.6 all L1 = 0.483 +- 0.179 (in-sample avg dev_std = 0.359)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.381
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.277
NEC for r=0.9 class 0 = 0.526 +- 0.312 (in-sample avg dev_std = 0.431)
NEC for r=0.9 class 1 = 0.384 +- 0.312 (in-sample avg dev_std = 0.431)
NEC for r=0.9 class 2 = 0.382 +- 0.312 (in-sample avg dev_std = 0.431)
NEC for r=0.9 class 3 = 0.515 +- 0.312 (in-sample avg dev_std = 0.431)
NEC for r=0.9 class 4 = 0.44 +- 0.312 (in-sample avg dev_std = 0.431)
NEC for r=0.9 class 5 = 0.498 +- 0.312 (in-sample avg dev_std = 0.431)
NEC for r=0.9 class 6 = 0.555 +- 0.312 (in-sample avg dev_std = 0.431)
NEC for r=0.9 class 7 = 0.485 +- 0.312 (in-sample avg dev_std = 0.431)
NEC for r=0.9 class 8 = 0.535 +- 0.312 (in-sample avg dev_std = 0.431)
NEC for r=0.9 class 9 = 0.569 +- 0.312 (in-sample avg dev_std = 0.431)
NEC for r=0.9 all KL = 0.581 +- 0.312 (in-sample avg dev_std = 0.431)
NEC for r=0.9 all L1 = 0.487 +- 0.253 (in-sample avg dev_std = 0.431)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.394
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.341
NEC for r=1.0 class 0 = 0.614 +- 0.345 (in-sample avg dev_std = 0.418)
NEC for r=1.0 class 1 = 0.279 +- 0.345 (in-sample avg dev_std = 0.418)
NEC for r=1.0 class 2 = 0.336 +- 0.345 (in-sample avg dev_std = 0.418)
NEC for r=1.0 class 3 = 0.476 +- 0.345 (in-sample avg dev_std = 0.418)
NEC for r=1.0 class 4 = 0.544 +- 0.345 (in-sample avg dev_std = 0.418)
NEC for r=1.0 class 5 = 0.474 +- 0.345 (in-sample avg dev_std = 0.418)
NEC for r=1.0 class 6 = 0.589 +- 0.345 (in-sample avg dev_std = 0.418)
NEC for r=1.0 class 7 = 0.425 +- 0.345 (in-sample avg dev_std = 0.418)
NEC for r=1.0 class 8 = 0.538 +- 0.345 (in-sample avg dev_std = 0.418)
NEC for r=1.0 class 9 = 0.573 +- 0.345 (in-sample avg dev_std = 0.418)
NEC for r=1.0 all KL = 0.593 +- 0.345 (in-sample avg dev_std = 0.418)
NEC for r=1.0 all L1 = 0.481 +- 0.286 (in-sample avg dev_std = 0.418)
model_dirname= repr_LECIvGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 15:45:28 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:45:29 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 03:45:30 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 181...
[0m[1;37mINFO[0m: [1mCheckpoint 181: 
-----------------------------------
Train ACCURACY: 0.9970
Train Loss: 0.0158
ID Validation ACCURACY: 0.9020
ID Validation Loss: 0.3897
ID Test ACCURACY: 0.8953
ID Test Loss: 0.4044
OOD Validation ACCURACY: 0.8734
OOD Validation Loss: 0.5272
OOD Test ACCURACY: 0.6619
OOD Test Loss: 1.9791

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 118...
[0m[1;37mINFO[0m: [1mCheckpoint 118: 
-----------------------------------
Train ACCURACY: 0.9799
Train Loss: 0.0665
ID Validation ACCURACY: 0.8979
ID Validation Loss: 0.3461
ID Test ACCURACY: 0.8966
ID Test Loss: 0.3492
OOD Validation ACCURACY: 0.8897
OOD Validation Loss: 0.3708
OOD Test ACCURACY: 0.7326
OOD Test Loss: 1.0225

[0m[1;37mINFO[0m: [1mChartInfo 0.8953 0.6619 0.8966 0.7326 0.8979 0.8897[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.095
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.093
SUFF++ for r=0.3 class 0 = 0.655 +- 0.106 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.3 class 1 = 0.655 +- 0.106 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.3 class 2 = 0.636 +- 0.106 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.3 class 3 = 0.617 +- 0.106 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.3 class 4 = 0.618 +- 0.106 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.3 class 5 = 0.647 +- 0.106 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.3 class 6 = 0.622 +- 0.106 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.3 class 7 = 0.631 +- 0.106 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.3 class 8 = 0.641 +- 0.106 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.3 class 9 = 0.63 +- 0.106 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.3 all KL = 0.814 +- 0.106 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.3 all L1 = 0.635 +- 0.099 (in-sample avg dev_std = 0.238)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.192
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.14
SUFF++ for r=0.6 class 0 = 0.337 +- 0.234 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.6 class 1 = 0.384 +- 0.234 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.6 class 2 = 0.361 +- 0.234 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.6 class 3 = 0.374 +- 0.234 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.6 class 4 = 0.426 +- 0.234 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.6 class 5 = 0.392 +- 0.234 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.6 class 6 = 0.419 +- 0.234 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.6 class 7 = 0.355 +- 0.234 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.6 class 8 = 0.411 +- 0.234 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.6 class 9 = 0.36 +- 0.234 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.6 all KL = 0.306 +- 0.234 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.6 all L1 = 0.381 +- 0.148 (in-sample avg dev_std = 0.398)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.817
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.759
SUFF++ for r=0.9 class 0 = 0.964 +- 0.257 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 class 1 = 0.976 +- 0.257 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 class 2 = 0.761 +- 0.257 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 class 3 = 0.765 +- 0.257 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 class 4 = 0.848 +- 0.257 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 class 5 = 0.716 +- 0.257 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 class 6 = 0.764 +- 0.257 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 class 7 = 0.801 +- 0.257 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 class 8 = 0.858 +- 0.257 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 class 9 = 0.698 +- 0.257 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 all KL = 0.819 +- 0.257 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 all L1 = 0.819 +- 0.216 (in-sample avg dev_std = 0.279)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.108
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.106
SUFF++ for r=0.3 class 0 = 0.621 +- 0.120 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 class 1 = 0.605 +- 0.120 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 class 2 = 0.625 +- 0.120 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 class 3 = 0.621 +- 0.120 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 class 4 = 0.625 +- 0.120 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 class 5 = 0.605 +- 0.120 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 class 6 = 0.608 +- 0.120 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 class 7 = 0.605 +- 0.120 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 class 8 = 0.617 +- 0.120 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 class 9 = 0.626 +- 0.120 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 all KL = 0.797 +- 0.120 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 all L1 = 0.616 +- 0.101 (in-sample avg dev_std = 0.252)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.154
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.136
SUFF++ for r=0.6 class 0 = 0.363 +- 0.228 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 class 1 = 0.435 +- 0.228 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 class 2 = 0.381 +- 0.228 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 class 3 = 0.379 +- 0.228 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 class 4 = 0.42 +- 0.228 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 class 5 = 0.399 +- 0.228 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 class 6 = 0.427 +- 0.228 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 class 7 = 0.381 +- 0.228 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 class 8 = 0.377 +- 0.228 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 class 9 = 0.44 +- 0.228 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 all KL = 0.39 +- 0.228 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 all L1 = 0.4 +- 0.145 (in-sample avg dev_std = 0.348)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.626
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.567
SUFF++ for r=0.9 class 0 = 0.754 +- 0.248 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 1 = 0.951 +- 0.248 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 2 = 0.693 +- 0.248 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 3 = 0.692 +- 0.248 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 4 = 0.725 +- 0.248 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 5 = 0.66 +- 0.248 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 6 = 0.752 +- 0.248 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 7 = 0.815 +- 0.248 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 8 = 0.714 +- 0.248 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 9 = 0.669 +- 0.248 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 all KL = 0.771 +- 0.248 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 all L1 = 0.746 +- 0.222 (in-sample avg dev_std = 0.303)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.095
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.095
NEC for r=0.3 class 0 = 0.279 +- 0.104 (in-sample avg dev_std = 0.144)
NEC for r=0.3 class 1 = 0.312 +- 0.104 (in-sample avg dev_std = 0.144)
NEC for r=0.3 class 2 = 0.303 +- 0.104 (in-sample avg dev_std = 0.144)
NEC for r=0.3 class 3 = 0.308 +- 0.104 (in-sample avg dev_std = 0.144)
NEC for r=0.3 class 4 = 0.303 +- 0.104 (in-sample avg dev_std = 0.144)
NEC for r=0.3 class 5 = 0.281 +- 0.104 (in-sample avg dev_std = 0.144)
NEC for r=0.3 class 6 = 0.319 +- 0.104 (in-sample avg dev_std = 0.144)
NEC for r=0.3 class 7 = 0.305 +- 0.104 (in-sample avg dev_std = 0.144)
NEC for r=0.3 class 8 = 0.304 +- 0.104 (in-sample avg dev_std = 0.144)
NEC for r=0.3 class 9 = 0.303 +- 0.104 (in-sample avg dev_std = 0.144)
NEC for r=0.3 all KL = 0.139 +- 0.104 (in-sample avg dev_std = 0.144)
NEC for r=0.3 all L1 = 0.302 +- 0.086 (in-sample avg dev_std = 0.144)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.192
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.138
NEC for r=0.6 class 0 = 0.553 +- 0.227 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 1 = 0.537 +- 0.227 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 2 = 0.522 +- 0.227 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 3 = 0.518 +- 0.227 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 4 = 0.48 +- 0.227 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 5 = 0.496 +- 0.227 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 6 = 0.492 +- 0.227 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 7 = 0.537 +- 0.227 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 8 = 0.493 +- 0.227 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 9 = 0.527 +- 0.227 (in-sample avg dev_std = 0.360)
NEC for r=0.6 all KL = 0.495 +- 0.227 (in-sample avg dev_std = 0.360)
NEC for r=0.6 all L1 = 0.517 +- 0.163 (in-sample avg dev_std = 0.360)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.817
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.608
NEC for r=0.9 class 0 = 0.293 +- 0.337 (in-sample avg dev_std = 0.472)
NEC for r=0.9 class 1 = 0.163 +- 0.337 (in-sample avg dev_std = 0.472)
NEC for r=0.9 class 2 = 0.539 +- 0.337 (in-sample avg dev_std = 0.472)
NEC for r=0.9 class 3 = 0.515 +- 0.337 (in-sample avg dev_std = 0.472)
NEC for r=0.9 class 4 = 0.301 +- 0.337 (in-sample avg dev_std = 0.472)
NEC for r=0.9 class 5 = 0.552 +- 0.337 (in-sample avg dev_std = 0.472)
NEC for r=0.9 class 6 = 0.445 +- 0.337 (in-sample avg dev_std = 0.472)
NEC for r=0.9 class 7 = 0.448 +- 0.337 (in-sample avg dev_std = 0.472)
NEC for r=0.9 class 8 = 0.333 +- 0.337 (in-sample avg dev_std = 0.472)
NEC for r=0.9 class 9 = 0.532 +- 0.337 (in-sample avg dev_std = 0.472)
NEC for r=0.9 all KL = 0.591 +- 0.337 (in-sample avg dev_std = 0.472)
NEC for r=0.9 all L1 = 0.408 +- 0.270 (in-sample avg dev_std = 0.472)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.951
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.823
NEC for r=1.0 class 0 = 0.088 +- 0.369 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 1 = 0.008 +- 0.369 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 2 = 0.332 +- 0.369 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 3 = 0.269 +- 0.369 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 4 = 0.168 +- 0.369 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 5 = 0.366 +- 0.369 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 6 = 0.327 +- 0.369 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 7 = 0.209 +- 0.369 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 8 = 0.179 +- 0.369 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 9 = 0.449 +- 0.369 (in-sample avg dev_std = 0.414)
NEC for r=1.0 all KL = 0.4 +- 0.369 (in-sample avg dev_std = 0.414)
NEC for r=1.0 all L1 = 0.234 +- 0.253 (in-sample avg dev_std = 0.414)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.108
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.1
NEC for r=0.3 class 0 = 0.307 +- 0.118 (in-sample avg dev_std = 0.149)
NEC for r=0.3 class 1 = 0.315 +- 0.118 (in-sample avg dev_std = 0.149)
NEC for r=0.3 class 2 = 0.298 +- 0.118 (in-sample avg dev_std = 0.149)
NEC for r=0.3 class 3 = 0.307 +- 0.118 (in-sample avg dev_std = 0.149)
NEC for r=0.3 class 4 = 0.344 +- 0.118 (in-sample avg dev_std = 0.149)
NEC for r=0.3 class 5 = 0.308 +- 0.118 (in-sample avg dev_std = 0.149)
NEC for r=0.3 class 6 = 0.326 +- 0.118 (in-sample avg dev_std = 0.149)
NEC for r=0.3 class 7 = 0.314 +- 0.118 (in-sample avg dev_std = 0.149)
NEC for r=0.3 class 8 = 0.327 +- 0.118 (in-sample avg dev_std = 0.149)
NEC for r=0.3 class 9 = 0.322 +- 0.118 (in-sample avg dev_std = 0.149)
NEC for r=0.3 all KL = 0.149 +- 0.118 (in-sample avg dev_std = 0.149)
NEC for r=0.3 all L1 = 0.316 +- 0.101 (in-sample avg dev_std = 0.149)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.154
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.129
NEC for r=0.6 class 0 = 0.549 +- 0.217 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 1 = 0.506 +- 0.217 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 2 = 0.544 +- 0.217 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 3 = 0.524 +- 0.217 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 4 = 0.532 +- 0.217 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 5 = 0.542 +- 0.217 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 6 = 0.536 +- 0.217 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 7 = 0.557 +- 0.217 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 8 = 0.572 +- 0.217 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 9 = 0.518 +- 0.217 (in-sample avg dev_std = 0.353)
NEC for r=0.6 all KL = 0.509 +- 0.217 (in-sample avg dev_std = 0.353)
NEC for r=0.6 all L1 = 0.538 +- 0.144 (in-sample avg dev_std = 0.353)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.626
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.424
NEC for r=0.9 class 0 = 0.639 +- 0.311 (in-sample avg dev_std = 0.437)
NEC for r=0.9 class 1 = 0.186 +- 0.311 (in-sample avg dev_std = 0.437)
NEC for r=0.9 class 2 = 0.48 +- 0.311 (in-sample avg dev_std = 0.437)
NEC for r=0.9 class 3 = 0.614 +- 0.311 (in-sample avg dev_std = 0.437)
NEC for r=0.9 class 4 = 0.412 +- 0.311 (in-sample avg dev_std = 0.437)
NEC for r=0.9 class 5 = 0.587 +- 0.311 (in-sample avg dev_std = 0.437)
NEC for r=0.9 class 6 = 0.458 +- 0.311 (in-sample avg dev_std = 0.437)
NEC for r=0.9 class 7 = 0.463 +- 0.311 (in-sample avg dev_std = 0.437)
NEC for r=0.9 class 8 = 0.567 +- 0.311 (in-sample avg dev_std = 0.437)
NEC for r=0.9 class 9 = 0.621 +- 0.311 (in-sample avg dev_std = 0.437)
NEC for r=0.9 all KL = 0.625 +- 0.311 (in-sample avg dev_std = 0.437)
NEC for r=0.9 all L1 = 0.499 +- 0.256 (in-sample avg dev_std = 0.437)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.678
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.585
NEC for r=1.0 class 0 = 0.521 +- 0.355 (in-sample avg dev_std = 0.444)
NEC for r=1.0 class 1 = 0.038 +- 0.355 (in-sample avg dev_std = 0.444)
NEC for r=1.0 class 2 = 0.379 +- 0.355 (in-sample avg dev_std = 0.444)
NEC for r=1.0 class 3 = 0.472 +- 0.355 (in-sample avg dev_std = 0.444)
NEC for r=1.0 class 4 = 0.405 +- 0.355 (in-sample avg dev_std = 0.444)
NEC for r=1.0 class 5 = 0.507 +- 0.355 (in-sample avg dev_std = 0.444)
NEC for r=1.0 class 6 = 0.426 +- 0.355 (in-sample avg dev_std = 0.444)
NEC for r=1.0 class 7 = 0.337 +- 0.355 (in-sample avg dev_std = 0.444)
NEC for r=1.0 class 8 = 0.551 +- 0.355 (in-sample avg dev_std = 0.444)
NEC for r=1.0 class 9 = 0.585 +- 0.355 (in-sample avg dev_std = 0.444)
NEC for r=1.0 all KL = 0.564 +- 0.355 (in-sample avg dev_std = 0.444)
NEC for r=1.0 all L1 = 0.417 +- 0.285 (in-sample avg dev_std = 0.444)
model_dirname= repr_LECIvGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 15:58:01 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:02 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:02 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:02 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:02 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 03:58:03 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 158...
[0m[1;37mINFO[0m: [1mCheckpoint 158: 
-----------------------------------
Train ACCURACY: 0.9950
Train Loss: 0.0231
ID Validation ACCURACY: 0.9024
ID Validation Loss: 0.3659
ID Test ACCURACY: 0.8969
ID Test Loss: 0.3748
OOD Validation ACCURACY: 0.8824
OOD Validation Loss: 0.4311
OOD Test ACCURACY: 0.7293
OOD Test Loss: 1.2294

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 136...
[0m[1;37mINFO[0m: [1mCheckpoint 136: 
-----------------------------------
Train ACCURACY: 0.9895
Train Loss: 0.0364
ID Validation ACCURACY: 0.8990
ID Validation Loss: 0.3635
ID Test ACCURACY: 0.9014
ID Test Loss: 0.3583
OOD Validation ACCURACY: 0.8921
OOD Validation Loss: 0.4134
OOD Test ACCURACY: 0.7336
OOD Test Loss: 1.4819

[0m[1;37mINFO[0m: [1mChartInfo 0.8969 0.7293 0.9014 0.7336 0.8990 0.8921[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.105
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.088
SUFF++ for r=0.3 class 0 = 0.544 +- 0.128 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.3 class 1 = 0.563 +- 0.128 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.3 class 2 = 0.548 +- 0.128 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.3 class 3 = 0.53 +- 0.128 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.3 class 4 = 0.547 +- 0.128 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.3 class 5 = 0.565 +- 0.128 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.3 class 6 = 0.538 +- 0.128 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.3 class 7 = 0.547 +- 0.128 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.3 class 8 = 0.557 +- 0.128 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.3 class 9 = 0.539 +- 0.128 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.3 all KL = 0.666 +- 0.128 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.3 all L1 = 0.548 +- 0.094 (in-sample avg dev_std = 0.360)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.18
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.136
SUFF++ for r=0.6 class 0 = 0.36 +- 0.226 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 class 1 = 0.427 +- 0.226 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 class 2 = 0.436 +- 0.226 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 class 3 = 0.409 +- 0.226 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 class 4 = 0.394 +- 0.226 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 class 5 = 0.392 +- 0.226 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 class 6 = 0.404 +- 0.226 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 class 7 = 0.398 +- 0.226 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 class 8 = 0.404 +- 0.226 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 class 9 = 0.39 +- 0.226 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 all KL = 0.404 +- 0.226 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 all L1 = 0.402 +- 0.148 (in-sample avg dev_std = 0.353)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.821
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.771
SUFF++ for r=0.9 class 0 = 0.958 +- 0.241 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 1 = 0.906 +- 0.241 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 2 = 0.77 +- 0.241 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 3 = 0.733 +- 0.241 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 4 = 0.825 +- 0.241 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 5 = 0.699 +- 0.241 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 6 = 0.79 +- 0.241 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 7 = 0.809 +- 0.241 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 8 = 0.84 +- 0.241 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 9 = 0.751 +- 0.241 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 all KL = 0.82 +- 0.241 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 all L1 = 0.811 +- 0.206 (in-sample avg dev_std = 0.276)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.09
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.098
SUFF++ for r=0.3 class 0 = 0.525 +- 0.146 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.3 class 1 = 0.512 +- 0.146 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.3 class 2 = 0.531 +- 0.146 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.3 class 3 = 0.521 +- 0.146 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.3 class 4 = 0.51 +- 0.146 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.3 class 5 = 0.505 +- 0.146 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.3 class 6 = 0.529 +- 0.146 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.3 class 7 = 0.524 +- 0.146 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.3 class 8 = 0.527 +- 0.146 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.3 class 9 = 0.516 +- 0.146 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.3 all KL = 0.628 +- 0.146 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.3 all L1 = 0.52 +- 0.098 (in-sample avg dev_std = 0.411)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.174
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.129
SUFF++ for r=0.6 class 0 = 0.44 +- 0.235 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.6 class 1 = 0.383 +- 0.235 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.6 class 2 = 0.419 +- 0.235 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.6 class 3 = 0.449 +- 0.235 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.6 class 4 = 0.409 +- 0.235 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.6 class 5 = 0.401 +- 0.235 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.6 class 6 = 0.429 +- 0.235 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.6 class 7 = 0.43 +- 0.235 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.6 class 8 = 0.415 +- 0.235 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.6 class 9 = 0.385 +- 0.235 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.6 all KL = 0.391 +- 0.235 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.6 all L1 = 0.416 +- 0.154 (in-sample avg dev_std = 0.394)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.632
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.559
SUFF++ for r=0.9 class 0 = 0.689 +- 0.259 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 class 1 = 0.777 +- 0.259 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 class 2 = 0.688 +- 0.259 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 class 3 = 0.655 +- 0.259 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 class 4 = 0.754 +- 0.259 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 class 5 = 0.642 +- 0.259 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 class 6 = 0.79 +- 0.259 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 class 7 = 0.737 +- 0.259 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 class 8 = 0.648 +- 0.259 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 class 9 = 0.68 +- 0.259 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 all KL = 0.728 +- 0.259 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 all L1 = 0.707 +- 0.221 (in-sample avg dev_std = 0.346)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.105
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.09
NEC for r=0.3 class 0 = 0.321 +- 0.078 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 1 = 0.322 +- 0.078 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 2 = 0.322 +- 0.078 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 3 = 0.351 +- 0.078 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 4 = 0.332 +- 0.078 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 5 = 0.312 +- 0.078 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 6 = 0.337 +- 0.078 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 7 = 0.322 +- 0.078 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 8 = 0.326 +- 0.078 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 9 = 0.341 +- 0.078 (in-sample avg dev_std = 0.145)
NEC for r=0.3 all KL = 0.143 +- 0.078 (in-sample avg dev_std = 0.145)
NEC for r=0.3 all L1 = 0.329 +- 0.080 (in-sample avg dev_std = 0.145)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.18
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.147
NEC for r=0.6 class 0 = 0.536 +- 0.192 (in-sample avg dev_std = 0.322)
NEC for r=0.6 class 1 = 0.509 +- 0.192 (in-sample avg dev_std = 0.322)
NEC for r=0.6 class 2 = 0.481 +- 0.192 (in-sample avg dev_std = 0.322)
NEC for r=0.6 class 3 = 0.528 +- 0.192 (in-sample avg dev_std = 0.322)
NEC for r=0.6 class 4 = 0.517 +- 0.192 (in-sample avg dev_std = 0.322)
NEC for r=0.6 class 5 = 0.509 +- 0.192 (in-sample avg dev_std = 0.322)
NEC for r=0.6 class 6 = 0.514 +- 0.192 (in-sample avg dev_std = 0.322)
NEC for r=0.6 class 7 = 0.535 +- 0.192 (in-sample avg dev_std = 0.322)
NEC for r=0.6 class 8 = 0.503 +- 0.192 (in-sample avg dev_std = 0.322)
NEC for r=0.6 class 9 = 0.51 +- 0.192 (in-sample avg dev_std = 0.322)
NEC for r=0.6 all KL = 0.441 +- 0.192 (in-sample avg dev_std = 0.322)
NEC for r=0.6 all L1 = 0.514 +- 0.134 (in-sample avg dev_std = 0.322)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.821
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.626
NEC for r=0.9 class 0 = 0.263 +- 0.314 (in-sample avg dev_std = 0.440)
NEC for r=0.9 class 1 = 0.255 +- 0.314 (in-sample avg dev_std = 0.440)
NEC for r=0.9 class 2 = 0.442 +- 0.314 (in-sample avg dev_std = 0.440)
NEC for r=0.9 class 3 = 0.546 +- 0.314 (in-sample avg dev_std = 0.440)
NEC for r=0.9 class 4 = 0.319 +- 0.314 (in-sample avg dev_std = 0.440)
NEC for r=0.9 class 5 = 0.58 +- 0.314 (in-sample avg dev_std = 0.440)
NEC for r=0.9 class 6 = 0.487 +- 0.314 (in-sample avg dev_std = 0.440)
NEC for r=0.9 class 7 = 0.381 +- 0.314 (in-sample avg dev_std = 0.440)
NEC for r=0.9 class 8 = 0.332 +- 0.314 (in-sample avg dev_std = 0.440)
NEC for r=0.9 class 9 = 0.507 +- 0.314 (in-sample avg dev_std = 0.440)
NEC for r=0.9 all KL = 0.557 +- 0.314 (in-sample avg dev_std = 0.440)
NEC for r=0.9 all L1 = 0.407 +- 0.258 (in-sample avg dev_std = 0.440)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.96
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.843
NEC for r=1.0 class 0 = 0.108 +- 0.348 (in-sample avg dev_std = 0.398)
NEC for r=1.0 class 1 = 0.047 +- 0.348 (in-sample avg dev_std = 0.398)
NEC for r=1.0 class 2 = 0.233 +- 0.348 (in-sample avg dev_std = 0.398)
NEC for r=1.0 class 3 = 0.297 +- 0.348 (in-sample avg dev_std = 0.398)
NEC for r=1.0 class 4 = 0.171 +- 0.348 (in-sample avg dev_std = 0.398)
NEC for r=1.0 class 5 = 0.39 +- 0.348 (in-sample avg dev_std = 0.398)
NEC for r=1.0 class 6 = 0.274 +- 0.348 (in-sample avg dev_std = 0.398)
NEC for r=1.0 class 7 = 0.205 +- 0.348 (in-sample avg dev_std = 0.398)
NEC for r=1.0 class 8 = 0.201 +- 0.348 (in-sample avg dev_std = 0.398)
NEC for r=1.0 class 9 = 0.35 +- 0.348 (in-sample avg dev_std = 0.398)
NEC for r=1.0 all KL = 0.37 +- 0.348 (in-sample avg dev_std = 0.398)
NEC for r=1.0 all L1 = 0.223 +- 0.241 (in-sample avg dev_std = 0.398)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.09
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.101
NEC for r=0.3 class 0 = 0.348 +- 0.085 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 1 = 0.344 +- 0.085 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 2 = 0.325 +- 0.085 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 3 = 0.338 +- 0.085 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 4 = 0.344 +- 0.085 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 5 = 0.342 +- 0.085 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 6 = 0.342 +- 0.085 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 7 = 0.336 +- 0.085 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 8 = 0.331 +- 0.085 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 9 = 0.347 +- 0.085 (in-sample avg dev_std = 0.142)
NEC for r=0.3 all KL = 0.151 +- 0.085 (in-sample avg dev_std = 0.142)
NEC for r=0.3 all L1 = 0.339 +- 0.088 (in-sample avg dev_std = 0.142)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.174
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.142
NEC for r=0.6 class 0 = 0.408 +- 0.204 (in-sample avg dev_std = 0.331)
NEC for r=0.6 class 1 = 0.52 +- 0.204 (in-sample avg dev_std = 0.331)
NEC for r=0.6 class 2 = 0.471 +- 0.204 (in-sample avg dev_std = 0.331)
NEC for r=0.6 class 3 = 0.474 +- 0.204 (in-sample avg dev_std = 0.331)
NEC for r=0.6 class 4 = 0.514 +- 0.204 (in-sample avg dev_std = 0.331)
NEC for r=0.6 class 5 = 0.484 +- 0.204 (in-sample avg dev_std = 0.331)
NEC for r=0.6 class 6 = 0.494 +- 0.204 (in-sample avg dev_std = 0.331)
NEC for r=0.6 class 7 = 0.512 +- 0.204 (in-sample avg dev_std = 0.331)
NEC for r=0.6 class 8 = 0.495 +- 0.204 (in-sample avg dev_std = 0.331)
NEC for r=0.6 class 9 = 0.539 +- 0.204 (in-sample avg dev_std = 0.331)
NEC for r=0.6 all KL = 0.435 +- 0.204 (in-sample avg dev_std = 0.331)
NEC for r=0.6 all L1 = 0.491 +- 0.153 (in-sample avg dev_std = 0.331)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.632
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.396
NEC for r=0.9 class 0 = 0.631 +- 0.297 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 1 = 0.465 +- 0.297 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 2 = 0.477 +- 0.297 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 3 = 0.631 +- 0.297 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 4 = 0.381 +- 0.297 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 5 = 0.645 +- 0.297 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 6 = 0.456 +- 0.297 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 7 = 0.546 +- 0.297 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 8 = 0.606 +- 0.297 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 9 = 0.566 +- 0.297 (in-sample avg dev_std = 0.426)
NEC for r=0.9 all KL = 0.656 +- 0.297 (in-sample avg dev_std = 0.426)
NEC for r=0.9 all L1 = 0.539 +- 0.244 (in-sample avg dev_std = 0.426)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.759
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.612
NEC for r=1.0 class 0 = 0.639 +- 0.343 (in-sample avg dev_std = 0.439)
NEC for r=1.0 class 1 = 0.173 +- 0.343 (in-sample avg dev_std = 0.439)
NEC for r=1.0 class 2 = 0.424 +- 0.343 (in-sample avg dev_std = 0.439)
NEC for r=1.0 class 3 = 0.49 +- 0.343 (in-sample avg dev_std = 0.439)
NEC for r=1.0 class 4 = 0.4 +- 0.343 (in-sample avg dev_std = 0.439)
NEC for r=1.0 class 5 = 0.494 +- 0.343 (in-sample avg dev_std = 0.439)
NEC for r=1.0 class 6 = 0.324 +- 0.343 (in-sample avg dev_std = 0.439)
NEC for r=1.0 class 7 = 0.34 +- 0.343 (in-sample avg dev_std = 0.439)
NEC for r=1.0 class 8 = 0.606 +- 0.343 (in-sample avg dev_std = 0.439)
NEC for r=1.0 class 9 = 0.49 +- 0.343 (in-sample avg dev_std = 0.439)
NEC for r=1.0 all KL = 0.575 +- 0.343 (in-sample avg dev_std = 0.439)
NEC for r=1.0 all L1 = 0.435 +- 0.275 (in-sample avg dev_std = 0.439)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.624, 0.303, 0.822, 1.0], 'all_L1': [0.497, 0.379, 0.813, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.771, 0.378, 0.818, 1.0], 'all_L1': [0.588, 0.402, 0.802, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.537, 0.273, 0.815, 1.0], 'all_L1': [0.462, 0.358, 0.816, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.814, 0.306, 0.819, 1.0], 'all_L1': [0.635, 0.381, 0.819, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.666, 0.404, 0.82, 1.0], 'all_L1': [0.548, 0.402, 0.811, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.167, 0.476, 0.573, 0.399], 'all_L1': [0.364, 0.512, 0.403, 0.23]}), defaultdict(<class 'list'>, {'all_KL': [0.133, 0.458, 0.54, 0.364], 'all_L1': [0.304, 0.514, 0.411, 0.233]}), defaultdict(<class 'list'>, {'all_KL': [0.26, 0.523, 0.536, 0.375], 'all_L1': [0.411, 0.519, 0.38, 0.208]}), defaultdict(<class 'list'>, {'all_KL': [0.139, 0.495, 0.591, 0.4], 'all_L1': [0.302, 0.517, 0.408, 0.234]}), defaultdict(<class 'list'>, {'all_KL': [0.143, 0.441, 0.557, 0.37], 'all_L1': [0.329, 0.514, 0.407, 0.223]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.69, 0.381, 0.752, 1.0], 'all_L1': [0.531, 0.43, 0.745, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.812, 0.552, 0.818, 1.0], 'all_L1': [0.63, 0.543, 0.766, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.485, 0.364, 0.72, 1.0], 'all_L1': [0.459, 0.419, 0.704, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.797, 0.39, 0.771, 1.0], 'all_L1': [0.616, 0.4, 0.746, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.628, 0.391, 0.728, 1.0], 'all_L1': [0.52, 0.416, 0.707, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.168, 0.398, 0.631, 0.598], 'all_L1': [0.37, 0.445, 0.494, 0.439]}), defaultdict(<class 'list'>, {'all_KL': [0.109, 0.312, 0.436, 0.451], 'all_L1': [0.274, 0.377, 0.407, 0.392]}), defaultdict(<class 'list'>, {'all_KL': [0.248, 0.468, 0.581, 0.593], 'all_L1': [0.399, 0.483, 0.487, 0.481]}), defaultdict(<class 'list'>, {'all_KL': [0.149, 0.509, 0.625, 0.564], 'all_L1': [0.316, 0.538, 0.499, 0.417]}), defaultdict(<class 'list'>, {'all_KL': [0.151, 0.435, 0.656, 0.575], 'all_L1': [0.339, 0.491, 0.539, 0.435]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.546 +- 0.062, 0.384 +- 0.016, 0.812 +- 0.006, 1.000 +- 0.000
suff++ class all_KL  =  0.682 +- 0.100, 0.333 +- 0.050, 0.819 +- 0.002, 1.000 +- 0.000
suff++_acc_int  =  0.094 +- 0.004, 0.140 +- 0.021, 0.759 +- 0.007
nec class all_L1  =  0.342 +- 0.041, 0.515 +- 0.002, 0.402 +- 0.011, 0.226 +- 0.010
nec class all_KL  =  0.168 +- 0.047, 0.479 +- 0.029, 0.559 +- 0.021, 0.382 +- 0.015
nec_acc_int  =  0.096 +- 0.006, 0.148 +- 0.018, 0.618 +- 0.012, 0.838 +- 0.009

Eval split test
suff++ class all_L1  =  0.551 +- 0.064, 0.442 +- 0.052, 0.734 +- 0.024, 1.000 +- 0.000
suff++ class all_KL  =  0.682 +- 0.120, 0.416 +- 0.069, 0.758 +- 0.035, 1.000 +- 0.000
suff++_acc_int  =  0.104 +- 0.007, 0.141 +- 0.021, 0.486 +- 0.094
nec class all_L1  =  0.340 +- 0.043, 0.467 +- 0.054, 0.485 +- 0.043, 0.433 +- 0.029
nec class all_KL  =  0.165 +- 0.046, 0.424 +- 0.067, 0.586 +- 0.079, 0.556 +- 0.054
nec_acc_int  =  0.106 +- 0.009, 0.142 +- 0.020, 0.364 +- 0.074, 0.500 +- 0.116


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.444 +- 0.013, 0.450 +- 0.008, 0.607 +- 0.005, 0.613 +- 0.005
Faith. Armon (L1)= 		  =  0.415 +- 0.012, 0.440 +- 0.010, 0.538 +- 0.010, 0.368 +- 0.013
Faith. GMean (L1)= 	  =  0.429 +- 0.006, 0.445 +- 0.009, 0.571 +- 0.007, 0.475 +- 0.010
Faith. Aritm (KL)= 		  =  0.425 +- 0.033, 0.406 +- 0.013, 0.689 +- 0.011, 0.691 +- 0.008
Faith. Armon (KL)= 		  =  0.263 +- 0.045, 0.389 +- 0.025, 0.664 +- 0.015, 0.552 +- 0.016
Faith. GMean (KL)= 	  =  0.332 +- 0.022, 0.397 +- 0.019, 0.677 +- 0.013, 0.618 +- 0.012

Eval split test
Faith. Aritm (L1)= 		  =  0.445 +- 0.014, 0.454 +- 0.010, 0.609 +- 0.015, 0.716 +- 0.015
Faith. Armon (L1)= 		  =  0.415 +- 0.018, 0.448 +- 0.007, 0.582 +- 0.028, 0.604 +- 0.028
Faith. GMean (L1)= 	  =  0.430 +- 0.011, 0.451 +- 0.008, 0.596 +- 0.021, 0.658 +- 0.022
Faith. Aritm (KL)= 		  =  0.424 +- 0.041, 0.420 +- 0.020, 0.672 +- 0.028, 0.778 +- 0.027
Faith. Armon (KL)= 		  =  0.257 +- 0.044, 0.410 +- 0.018, 0.656 +- 0.047, 0.713 +- 0.047
Faith. GMean (KL)= 	  =  0.327 +- 0.021, 0.415 +- 0.018, 0.664 +- 0.037, 0.745 +- 0.038
Computed for split load_split = id



Completed in  1:03:11.771294  for LECIvGIN GOODCMNIST/color



DONE LECI GOODCMNIST/color
DONE all :)
