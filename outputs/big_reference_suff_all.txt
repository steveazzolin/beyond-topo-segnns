
[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Mar 20 13:54:10 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:10 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:22 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:24 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:26 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:28 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 01:54:30 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 132...
[0m[1;37mINFO[0m: [1mCheckpoint 132: 
-----------------------------------
Train ACCURACY: 0.9035
Train Loss: 0.4128
ID Validation ACCURACY: 0.9023
ID Validation Loss: 0.4270
ID Test ACCURACY: 0.8953
ID Test Loss: 0.4215
OOD Validation ACCURACY: 0.8670
OOD Validation Loss: 0.4795
OOD Test ACCURACY: 0.6793
OOD Test Loss: 0.8040

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 124...
[0m[1;37mINFO[0m: [1mCheckpoint 124: 
-----------------------------------
Train ACCURACY: 0.8663
Train Loss: 0.4837
ID Validation ACCURACY: 0.8677
ID Validation Loss: 0.4913
ID Test ACCURACY: 0.8707
ID Test Loss: 0.4812
OOD Validation ACCURACY: 0.9310
OOD Validation Loss: 0.4154
OOD Test ACCURACY: 0.7697
OOD Test Loss: 0.6769

[0m[1;37mINFO[0m: [1mChartInfo 0.8953 0.6793 0.8707 0.7697 0.8677 0.9310[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.706
WIoU for r=0.3 = 0.658
F1 for r=0.6 = 0.602
WIoU for r=0.6 = 0.745
F1 for r=0.9 = 0.476
WIoU for r=0.9 = 0.758
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.758
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.824
WIoU for r=0.3 = 0.888
F1 for r=0.6 = 0.723
WIoU for r=0.6 = 1.000
F1 for r=0.9 = 0.598
WIoU for r=0.9 = 1.000
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 1.000
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.398
WIoU for r=0.3 = 0.264
F1 for r=0.6 = 0.551
WIoU for r=0.6 = 0.400
F1 for r=0.9 = 0.592
WIoU for r=0.9 = 0.448
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.447
Size bank for r=0.3 -> 1500
Size bank for r=0.6 -> 1500
Size bank for r=0.9 -> 766


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.651
Model XAI F1 of binarized graphs for r=0.3 =  0.7064349999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.6576099999999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.369
NEC for r=0.3 class 0 = 0.568 +- 0.299 (in-sample avg dev_std = 0.496)
NEC for r=0.3 class 1 = 0.505 +- 0.299 (in-sample avg dev_std = 0.496)
NEC for r=0.3 class 2 = 0.615 +- 0.299 (in-sample avg dev_std = 0.496)
NEC for r=0.3 all KL = 0.611 +- 0.299 (in-sample avg dev_std = 0.496)
NEC for r=0.3 all L1 = 0.563 +- 0.177 (in-sample avg dev_std = 0.496)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.845
Model XAI F1 of binarized graphs for r=0.6 =  0.60239375
Model XAI WIoU of binarized graphs for r=0.6 =  0.74490875
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.485
NEC for r=0.6 class 0 = 0.522 +- 0.305 (in-sample avg dev_std = 0.522)
NEC for r=0.6 class 1 = 0.465 +- 0.305 (in-sample avg dev_std = 0.522)
NEC for r=0.6 class 2 = 0.618 +- 0.305 (in-sample avg dev_std = 0.522)
NEC for r=0.6 all KL = 0.568 +- 0.305 (in-sample avg dev_std = 0.522)
NEC for r=0.6 all L1 = 0.536 +- 0.185 (in-sample avg dev_std = 0.522)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.904
Model XAI F1 of binarized graphs for r=0.9 =  0.47577375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.7579224999999999
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.562
NEC for r=0.9 class 0 = 0.466 +- 0.295 (in-sample avg dev_std = 0.570)
NEC for r=0.9 class 1 = 0.456 +- 0.295 (in-sample avg dev_std = 0.570)
NEC for r=0.9 class 2 = 0.576 +- 0.295 (in-sample avg dev_std = 0.570)
NEC for r=0.9 all KL = 0.526 +- 0.295 (in-sample avg dev_std = 0.570)
NEC for r=0.9 all L1 = 0.501 +- 0.169 (in-sample avg dev_std = 0.570)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.905
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.75789125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.56
NEC for r=1.0 class 0 = 0.47 +- 0.296 (in-sample avg dev_std = 0.565)
NEC for r=1.0 class 1 = 0.459 +- 0.296 (in-sample avg dev_std = 0.565)
NEC for r=1.0 class 2 = 0.562 +- 0.296 (in-sample avg dev_std = 0.565)
NEC for r=1.0 all KL = 0.521 +- 0.296 (in-sample avg dev_std = 0.565)
NEC for r=1.0 all L1 = 0.498 +- 0.167 (in-sample avg dev_std = 0.565)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.62
Model XAI F1 of binarized graphs for r=0.3 =  0.8242675000000002
Model XAI WIoU of binarized graphs for r=0.3 =  0.8881399999999999
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.382
NEC for r=0.3 class 0 = 0.561 +- 0.309 (in-sample avg dev_std = 0.653)
NEC for r=0.3 class 1 = 0.469 +- 0.309 (in-sample avg dev_std = 0.653)
NEC for r=0.3 class 2 = 0.569 +- 0.309 (in-sample avg dev_std = 0.653)
NEC for r=0.3 all KL = 0.67 +- 0.309 (in-sample avg dev_std = 0.653)
NEC for r=0.3 all L1 = 0.533 +- 0.212 (in-sample avg dev_std = 0.653)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.871
Model XAI F1 of binarized graphs for r=0.6 =  0.72317875
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.625
NEC for r=0.6 class 0 = 0.347 +- 0.299 (in-sample avg dev_std = 0.609)
NEC for r=0.6 class 1 = 0.324 +- 0.299 (in-sample avg dev_std = 0.609)
NEC for r=0.6 class 2 = 0.465 +- 0.299 (in-sample avg dev_std = 0.609)
NEC for r=0.6 all KL = 0.455 +- 0.299 (in-sample avg dev_std = 0.609)
NEC for r=0.6 all L1 = 0.378 +- 0.168 (in-sample avg dev_std = 0.609)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.871
Model XAI F1 of binarized graphs for r=0.9 =  0.597645
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.682
NEC for r=0.9 class 0 = 0.292 +- 0.250 (in-sample avg dev_std = 0.558)
NEC for r=0.9 class 1 = 0.268 +- 0.250 (in-sample avg dev_std = 0.558)
NEC for r=0.9 class 2 = 0.373 +- 0.250 (in-sample avg dev_std = 0.558)
NEC for r=0.9 all KL = 0.33 +- 0.250 (in-sample avg dev_std = 0.558)
NEC for r=0.9 all L1 = 0.311 +- 0.148 (in-sample avg dev_std = 0.558)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.871
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  1.0
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.683
NEC for r=1.0 class 0 = 0.264 +- 0.250 (in-sample avg dev_std = 0.546)
NEC for r=1.0 class 1 = 0.261 +- 0.250 (in-sample avg dev_std = 0.546)
NEC for r=1.0 class 2 = 0.39 +- 0.250 (in-sample avg dev_std = 0.546)
NEC for r=1.0 all KL = 0.319 +- 0.250 (in-sample avg dev_std = 0.546)
NEC for r=1.0 all L1 = 0.305 +- 0.156 (in-sample avg dev_std = 0.546)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.319
Model XAI F1 of binarized graphs for r=0.3 =  0.39848749999999994
Model XAI WIoU of binarized graphs for r=0.3 =  0.2644925
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.35
NEC for r=0.3 class 0 = 0.251 +- 0.176 (in-sample avg dev_std = 0.321)
NEC for r=0.3 class 1 = 0.319 +- 0.176 (in-sample avg dev_std = 0.321)
NEC for r=0.3 class 2 = 0.298 +- 0.176 (in-sample avg dev_std = 0.321)
NEC for r=0.3 all KL = 0.166 +- 0.176 (in-sample avg dev_std = 0.321)
NEC for r=0.3 all L1 = 0.289 +- 0.152 (in-sample avg dev_std = 0.321)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.494
Model XAI F1 of binarized graphs for r=0.6 =  0.55061625
Model XAI WIoU of binarized graphs for r=0.6 =  0.39973375000000005
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.478
NEC for r=0.6 class 0 = 0.441 +- 0.277 (in-sample avg dev_std = 0.517)
NEC for r=0.6 class 1 = 0.424 +- 0.277 (in-sample avg dev_std = 0.517)
NEC for r=0.6 class 2 = 0.502 +- 0.277 (in-sample avg dev_std = 0.517)
NEC for r=0.6 all KL = 0.416 +- 0.277 (in-sample avg dev_std = 0.517)
NEC for r=0.6 all L1 = 0.456 +- 0.170 (in-sample avg dev_std = 0.517)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.689
Model XAI F1 of binarized graphs for r=0.9 =  0.59211875
Model XAI WIoU of binarized graphs for r=0.9 =  0.44840374999999993
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.608
NEC for r=0.9 class 0 = 0.456 +- 0.249 (in-sample avg dev_std = 0.517)
NEC for r=0.9 class 1 = 0.223 +- 0.249 (in-sample avg dev_std = 0.517)
NEC for r=0.9 class 2 = 0.554 +- 0.249 (in-sample avg dev_std = 0.517)
NEC for r=0.9 all KL = 0.436 +- 0.249 (in-sample avg dev_std = 0.517)
NEC for r=0.9 all L1 = 0.414 +- 0.199 (in-sample avg dev_std = 0.517)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.691
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.446735
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.631
NEC for r=1.0 class 0 = 0.441 +- 0.227 (in-sample avg dev_std = 0.488)
NEC for r=1.0 class 1 = 0.213 +- 0.227 (in-sample avg dev_std = 0.488)
NEC for r=1.0 class 2 = 0.514 +- 0.227 (in-sample avg dev_std = 0.488)
NEC for r=1.0 all KL = 0.391 +- 0.227 (in-sample avg dev_std = 0.488)
NEC for r=1.0 all L1 = 0.392 +- 0.187 (in-sample avg dev_std = 0.488)


Evaluating SUFF for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7119
torch.Size([7119, 3])
7119

Model Accuracy of binarized graphs for r=0.3 =  0.655
Model XAI F1 of binarized graphs for r=0.3 =  0.7064349999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.6576099999999999
len(reference) = 791
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.472
SUFF for r=0.3 class 0 = 0.466 +- 0.292 (in-sample avg dev_std = 0.554)
SUFF for r=0.3 class 1 = 0.583 +- 0.292 (in-sample avg dev_std = 0.554)
SUFF for r=0.3 class 2 = 0.475 +- 0.292 (in-sample avg dev_std = 0.554)
SUFF for r=0.3 all KL = 0.453 +- 0.292 (in-sample avg dev_std = 0.554)
SUFF for r=0.3 all L1 = 0.508 +- 0.170 (in-sample avg dev_std = 0.554)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.845
Model XAI F1 of binarized graphs for r=0.6 =  0.60239375
Model XAI WIoU of binarized graphs for r=0.6 =  0.74490875
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.711
SUFF for r=0.6 class 0 = 0.615 +- 0.265 (in-sample avg dev_std = 0.449)
SUFF for r=0.6 class 1 = 0.644 +- 0.265 (in-sample avg dev_std = 0.449)
SUFF for r=0.6 class 2 = 0.639 +- 0.265 (in-sample avg dev_std = 0.449)
SUFF for r=0.6 all KL = 0.629 +- 0.265 (in-sample avg dev_std = 0.449)
SUFF for r=0.6 all L1 = 0.633 +- 0.188 (in-sample avg dev_std = 0.449)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.904
Model XAI F1 of binarized graphs for r=0.9 =  0.47577375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.7579224999999999
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.872
SUFF for r=0.9 class 0 = 0.823 +- 0.171 (in-sample avg dev_std = 0.194)
SUFF for r=0.9 class 1 = 0.78 +- 0.171 (in-sample avg dev_std = 0.194)
SUFF for r=0.9 class 2 = 0.822 +- 0.171 (in-sample avg dev_std = 0.194)
SUFF for r=0.9 all KL = 0.869 +- 0.171 (in-sample avg dev_std = 0.194)
SUFF for r=0.9 all L1 = 0.808 +- 0.168 (in-sample avg dev_std = 0.194)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.62
Model XAI F1 of binarized graphs for r=0.3 =  0.8242675000000002
Model XAI WIoU of binarized graphs for r=0.3 =  0.8881399999999999
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.487
SUFF for r=0.3 class 0 = 0.474 +- 0.332 (in-sample avg dev_std = 0.611)
SUFF for r=0.3 class 1 = 0.696 +- 0.332 (in-sample avg dev_std = 0.611)
SUFF for r=0.3 class 2 = 0.469 +- 0.332 (in-sample avg dev_std = 0.611)
SUFF for r=0.3 all KL = 0.411 +- 0.332 (in-sample avg dev_std = 0.611)
SUFF for r=0.3 all L1 = 0.545 +- 0.212 (in-sample avg dev_std = 0.611)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.871
Model XAI F1 of binarized graphs for r=0.6 =  0.72317875
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.827
SUFF for r=0.6 class 0 = 0.749 +- 0.276 (in-sample avg dev_std = 0.458)
SUFF for r=0.6 class 1 = 0.743 +- 0.276 (in-sample avg dev_std = 0.458)
SUFF for r=0.6 class 2 = 0.73 +- 0.276 (in-sample avg dev_std = 0.458)
SUFF for r=0.6 all KL = 0.715 +- 0.276 (in-sample avg dev_std = 0.458)
SUFF for r=0.6 all L1 = 0.741 +- 0.184 (in-sample avg dev_std = 0.458)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.871
Model XAI F1 of binarized graphs for r=0.9 =  0.597645
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.885
SUFF for r=0.9 class 0 = 0.935 +- 0.103 (in-sample avg dev_std = 0.127)
SUFF for r=0.9 class 1 = 0.923 +- 0.103 (in-sample avg dev_std = 0.127)
SUFF for r=0.9 class 2 = 0.91 +- 0.103 (in-sample avg dev_std = 0.127)
SUFF for r=0.9 all KL = 0.966 +- 0.103 (in-sample avg dev_std = 0.127)
SUFF for r=0.9 all L1 = 0.923 +- 0.118 (in-sample avg dev_std = 0.127)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
6696
torch.Size([6696, 3])
6696

Model Accuracy of binarized graphs for r=0.3 =  0.327
Model XAI F1 of binarized graphs for r=0.3 =  0.39848749999999994
Model XAI WIoU of binarized graphs for r=0.3 =  0.2644925
len(reference) = 744
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.32
SUFF for r=0.3 class 0 = 0.543 +- 0.171 (in-sample avg dev_std = 0.428)
SUFF for r=0.3 class 1 = 0.544 +- 0.171 (in-sample avg dev_std = 0.428)
SUFF for r=0.3 class 2 = 0.54 +- 0.171 (in-sample avg dev_std = 0.428)
SUFF for r=0.3 all KL = 0.668 +- 0.171 (in-sample avg dev_std = 0.428)
SUFF for r=0.3 all L1 = 0.542 +- 0.116 (in-sample avg dev_std = 0.428)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.494
Model XAI F1 of binarized graphs for r=0.6 =  0.55061625
Model XAI WIoU of binarized graphs for r=0.6 =  0.39973375000000005
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.438
SUFF for r=0.6 class 0 = 0.577 +- 0.251 (in-sample avg dev_std = 0.447)
SUFF for r=0.6 class 1 = 0.599 +- 0.251 (in-sample avg dev_std = 0.447)
SUFF for r=0.6 class 2 = 0.525 +- 0.251 (in-sample avg dev_std = 0.447)
SUFF for r=0.6 all KL = 0.631 +- 0.251 (in-sample avg dev_std = 0.447)
SUFF for r=0.6 all L1 = 0.566 +- 0.176 (in-sample avg dev_std = 0.447)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.689
Model XAI F1 of binarized graphs for r=0.9 =  0.59211875
Model XAI WIoU of binarized graphs for r=0.9 =  0.44840374999999993
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.703
SUFF for r=0.9 class 0 = 0.695 +- 0.151 (in-sample avg dev_std = 0.212)
SUFF for r=0.9 class 1 = 0.964 +- 0.151 (in-sample avg dev_std = 0.212)
SUFF for r=0.9 class 2 = 0.732 +- 0.151 (in-sample avg dev_std = 0.212)
SUFF for r=0.9 all KL = 0.877 +- 0.151 (in-sample avg dev_std = 0.212)
SUFF for r=0.9 all L1 = 0.794 +- 0.192 (in-sample avg dev_std = 0.212)


ratio=1.0



Zero intervened samples, skipping weight=1.0

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Mar 20 13:57:57 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/20/2024 01:57:57 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:09 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:12 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:13 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:15 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 01:58:17 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 133...
[0m[1;37mINFO[0m: [1mCheckpoint 133: 
-----------------------------------
Train ACCURACY: 0.8972
Train Loss: 0.4272
ID Validation ACCURACY: 0.8990
ID Validation Loss: 0.4477
ID Test ACCURACY: 0.9030
ID Test Loss: 0.4154
OOD Validation ACCURACY: 0.9210
OOD Validation Loss: 0.3677
OOD Test ACCURACY: 0.6950
OOD Test Loss: 0.7662

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 132...
[0m[1;37mINFO[0m: [1mCheckpoint 132: 
-----------------------------------
Train ACCURACY: 0.8812
Train Loss: 0.4545
ID Validation ACCURACY: 0.8767
ID Validation Loss: 0.4837
ID Test ACCURACY: 0.8840
ID Test Loss: 0.4477
OOD Validation ACCURACY: 0.9280
OOD Validation Loss: 0.3667
OOD Test ACCURACY: 0.6257
OOD Test Loss: 1.1210

[0m[1;37mINFO[0m: [1mChartInfo 0.9030 0.6950 0.8840 0.6257 0.8767 0.9280[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.686
WIoU for r=0.3 = 0.633
F1 for r=0.6 = 0.608
WIoU for r=0.6 = 0.744
F1 for r=0.9 = 0.475
WIoU for r=0.9 = 0.747
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.747
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.869
WIoU for r=0.3 = 0.874
F1 for r=0.6 = 0.770
WIoU for r=0.6 = 1.000
F1 for r=0.9 = 0.598
WIoU for r=0.9 = 1.000
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 1.000
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.415
WIoU for r=0.3 = 0.282
F1 for r=0.6 = 0.573
WIoU for r=0.6 = 0.431
F1 for r=0.9 = 0.588
WIoU for r=0.9 = 0.473
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.467
Size bank for r=0.3 -> 1500
Size bank for r=0.6 -> 1500
Size bank for r=0.9 -> 1148


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.604
Model XAI F1 of binarized graphs for r=0.3 =  0.68556875
Model XAI WIoU of binarized graphs for r=0.3 =  0.63299125
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.369
NEC for r=0.3 class 0 = 0.585 +- 0.283 (in-sample avg dev_std = 0.483)
NEC for r=0.3 class 1 = 0.484 +- 0.283 (in-sample avg dev_std = 0.483)
NEC for r=0.3 class 2 = 0.618 +- 0.283 (in-sample avg dev_std = 0.483)
NEC for r=0.3 all KL = 0.599 +- 0.283 (in-sample avg dev_std = 0.483)
NEC for r=0.3 all L1 = 0.563 +- 0.162 (in-sample avg dev_std = 0.483)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.846
Model XAI F1 of binarized graphs for r=0.6 =  0.6081150000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.74435625
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.454
NEC for r=0.6 class 0 = 0.567 +- 0.299 (in-sample avg dev_std = 0.487)
NEC for r=0.6 class 1 = 0.452 +- 0.299 (in-sample avg dev_std = 0.487)
NEC for r=0.6 class 2 = 0.631 +- 0.299 (in-sample avg dev_std = 0.487)
NEC for r=0.6 all KL = 0.555 +- 0.299 (in-sample avg dev_std = 0.487)
NEC for r=0.6 all L1 = 0.551 +- 0.176 (in-sample avg dev_std = 0.487)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.899
Model XAI F1 of binarized graphs for r=0.9 =  0.47541875
Model XAI WIoU of binarized graphs for r=0.9 =  0.7473650000000001
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.526
NEC for r=0.9 class 0 = 0.506 +- 0.306 (in-sample avg dev_std = 0.515)
NEC for r=0.9 class 1 = 0.429 +- 0.306 (in-sample avg dev_std = 0.515)
NEC for r=0.9 class 2 = 0.593 +- 0.306 (in-sample avg dev_std = 0.515)
NEC for r=0.9 all KL = 0.509 +- 0.306 (in-sample avg dev_std = 0.515)
NEC for r=0.9 all L1 = 0.51 +- 0.176 (in-sample avg dev_std = 0.515)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.899
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.747375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.557
NEC for r=1.0 class 0 = 0.491 +- 0.305 (in-sample avg dev_std = 0.508)
NEC for r=1.0 class 1 = 0.403 +- 0.305 (in-sample avg dev_std = 0.508)
NEC for r=1.0 class 2 = 0.571 +- 0.305 (in-sample avg dev_std = 0.508)
NEC for r=1.0 all KL = 0.483 +- 0.305 (in-sample avg dev_std = 0.508)
NEC for r=1.0 all L1 = 0.489 +- 0.178 (in-sample avg dev_std = 0.508)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.605
Model XAI F1 of binarized graphs for r=0.3 =  0.86858875
Model XAI WIoU of binarized graphs for r=0.3 =  0.873595
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.241
NEC for r=0.3 class 0 = 0.559 +- 0.287 (in-sample avg dev_std = 0.468)
NEC for r=0.3 class 1 = 0.532 +- 0.287 (in-sample avg dev_std = 0.468)
NEC for r=0.3 class 2 = 0.562 +- 0.287 (in-sample avg dev_std = 0.468)
NEC for r=0.3 all KL = 0.642 +- 0.287 (in-sample avg dev_std = 0.468)
NEC for r=0.3 all L1 = 0.551 +- 0.208 (in-sample avg dev_std = 0.468)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.926
Model XAI F1 of binarized graphs for r=0.6 =  0.77017625
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.576
NEC for r=0.6 class 0 = 0.511 +- 0.336 (in-sample avg dev_std = 0.623)
NEC for r=0.6 class 1 = 0.273 +- 0.336 (in-sample avg dev_std = 0.623)
NEC for r=0.6 class 2 = 0.538 +- 0.336 (in-sample avg dev_std = 0.623)
NEC for r=0.6 all KL = 0.534 +- 0.336 (in-sample avg dev_std = 0.623)
NEC for r=0.6 all L1 = 0.442 +- 0.195 (in-sample avg dev_std = 0.623)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.926
Model XAI F1 of binarized graphs for r=0.9 =  0.5983625
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.655
NEC for r=0.9 class 0 = 0.39 +- 0.267 (in-sample avg dev_std = 0.575)
NEC for r=0.9 class 1 = 0.219 +- 0.267 (in-sample avg dev_std = 0.575)
NEC for r=0.9 class 2 = 0.433 +- 0.267 (in-sample avg dev_std = 0.575)
NEC for r=0.9 all KL = 0.363 +- 0.267 (in-sample avg dev_std = 0.575)
NEC for r=0.9 all L1 = 0.348 +- 0.174 (in-sample avg dev_std = 0.575)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.926
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  1.0
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.67
NEC for r=1.0 class 0 = 0.382 +- 0.264 (in-sample avg dev_std = 0.574)
NEC for r=1.0 class 1 = 0.211 +- 0.264 (in-sample avg dev_std = 0.574)
NEC for r=1.0 class 2 = 0.424 +- 0.264 (in-sample avg dev_std = 0.574)
NEC for r=1.0 all KL = 0.353 +- 0.264 (in-sample avg dev_std = 0.574)
NEC for r=1.0 all L1 = 0.34 +- 0.170 (in-sample avg dev_std = 0.574)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.343
Model XAI F1 of binarized graphs for r=0.3 =  0.41494749999999997
Model XAI WIoU of binarized graphs for r=0.3 =  0.28239
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.377
NEC for r=0.3 class 0 = 0.311 +- 0.311 (in-sample avg dev_std = 0.385)
NEC for r=0.3 class 1 = 0.416 +- 0.311 (in-sample avg dev_std = 0.385)
NEC for r=0.3 class 2 = 0.345 +- 0.311 (in-sample avg dev_std = 0.385)
NEC for r=0.3 all KL = 0.369 +- 0.311 (in-sample avg dev_std = 0.385)
NEC for r=0.3 all L1 = 0.357 +- 0.206 (in-sample avg dev_std = 0.385)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.506
Model XAI F1 of binarized graphs for r=0.6 =  0.5729099999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.43138750000000003
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.488
NEC for r=0.6 class 0 = 0.494 +- 0.309 (in-sample avg dev_std = 0.528)
NEC for r=0.6 class 1 = 0.339 +- 0.309 (in-sample avg dev_std = 0.528)
NEC for r=0.6 class 2 = 0.598 +- 0.309 (in-sample avg dev_std = 0.528)
NEC for r=0.6 all KL = 0.471 +- 0.309 (in-sample avg dev_std = 0.528)
NEC for r=0.6 all L1 = 0.48 +- 0.215 (in-sample avg dev_std = 0.528)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.748
Model XAI F1 of binarized graphs for r=0.9 =  0.5884075
Model XAI WIoU of binarized graphs for r=0.9 =  0.47348
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.603
NEC for r=0.9 class 0 = 0.438 +- 0.262 (in-sample avg dev_std = 0.478)
NEC for r=0.9 class 1 = 0.147 +- 0.262 (in-sample avg dev_std = 0.478)
NEC for r=0.9 class 2 = 0.535 +- 0.262 (in-sample avg dev_std = 0.478)
NEC for r=0.9 all KL = 0.342 +- 0.262 (in-sample avg dev_std = 0.478)
NEC for r=0.9 all L1 = 0.377 +- 0.220 (in-sample avg dev_std = 0.478)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.706
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.46704375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.593
NEC for r=1.0 class 0 = 0.397 +- 0.241 (in-sample avg dev_std = 0.449)
NEC for r=1.0 class 1 = 0.144 +- 0.241 (in-sample avg dev_std = 0.449)
NEC for r=1.0 class 2 = 0.519 +- 0.241 (in-sample avg dev_std = 0.449)
NEC for r=1.0 all KL = 0.305 +- 0.241 (in-sample avg dev_std = 0.449)
NEC for r=1.0 all L1 = 0.357 +- 0.209 (in-sample avg dev_std = 0.449)


Evaluating SUFF for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7119
torch.Size([7119, 3])
7119

Model Accuracy of binarized graphs for r=0.3 =  0.611
Model XAI F1 of binarized graphs for r=0.3 =  0.68556875
Model XAI WIoU of binarized graphs for r=0.3 =  0.63299125
len(reference) = 791
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.457
SUFF for r=0.3 class 0 = 0.487 +- 0.280 (in-sample avg dev_std = 0.533)
SUFF for r=0.3 class 1 = 0.542 +- 0.280 (in-sample avg dev_std = 0.533)
SUFF for r=0.3 class 2 = 0.428 +- 0.280 (in-sample avg dev_std = 0.533)
SUFF for r=0.3 all KL = 0.445 +- 0.280 (in-sample avg dev_std = 0.533)
SUFF for r=0.3 all L1 = 0.485 +- 0.163 (in-sample avg dev_std = 0.533)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.846
Model XAI F1 of binarized graphs for r=0.6 =  0.6081150000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.74435625
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.744
SUFF for r=0.6 class 0 = 0.642 +- 0.220 (in-sample avg dev_std = 0.375)
SUFF for r=0.6 class 1 = 0.693 +- 0.220 (in-sample avg dev_std = 0.375)
SUFF for r=0.6 class 2 = 0.66 +- 0.220 (in-sample avg dev_std = 0.375)
SUFF for r=0.6 all KL = 0.705 +- 0.220 (in-sample avg dev_std = 0.375)
SUFF for r=0.6 all L1 = 0.665 +- 0.179 (in-sample avg dev_std = 0.375)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.899
Model XAI F1 of binarized graphs for r=0.9 =  0.47541875
Model XAI WIoU of binarized graphs for r=0.9 =  0.7473650000000001
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.844
SUFF for r=0.9 class 0 = 0.791 +- 0.157 (in-sample avg dev_std = 0.191)
SUFF for r=0.9 class 1 = 0.78 +- 0.157 (in-sample avg dev_std = 0.191)
SUFF for r=0.9 class 2 = 0.818 +- 0.157 (in-sample avg dev_std = 0.191)
SUFF for r=0.9 all KL = 0.881 +- 0.157 (in-sample avg dev_std = 0.191)
SUFF for r=0.9 all L1 = 0.796 +- 0.160 (in-sample avg dev_std = 0.191)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.605
Model XAI F1 of binarized graphs for r=0.3 =  0.86858875
Model XAI WIoU of binarized graphs for r=0.3 =  0.873595
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.503
SUFF for r=0.3 class 0 = 0.501 +- 0.315 (in-sample avg dev_std = 0.596)
SUFF for r=0.3 class 1 = 0.7 +- 0.315 (in-sample avg dev_std = 0.596)
SUFF for r=0.3 class 2 = 0.421 +- 0.315 (in-sample avg dev_std = 0.596)
SUFF for r=0.3 all KL = 0.428 +- 0.315 (in-sample avg dev_std = 0.596)
SUFF for r=0.3 all L1 = 0.54 +- 0.202 (in-sample avg dev_std = 0.596)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.926
Model XAI F1 of binarized graphs for r=0.6 =  0.77017625
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.91
SUFF for r=0.6 class 0 = 0.841 +- 0.194 (in-sample avg dev_std = 0.263)
SUFF for r=0.6 class 1 = 0.781 +- 0.194 (in-sample avg dev_std = 0.263)
SUFF for r=0.6 class 2 = 0.89 +- 0.194 (in-sample avg dev_std = 0.263)
SUFF for r=0.6 all KL = 0.855 +- 0.194 (in-sample avg dev_std = 0.263)
SUFF for r=0.6 all L1 = 0.838 +- 0.133 (in-sample avg dev_std = 0.263)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.926
Model XAI F1 of binarized graphs for r=0.9 =  0.5983625
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.931
SUFF for r=0.9 class 0 = 0.935 +- 0.053 (in-sample avg dev_std = 0.075)
SUFF for r=0.9 class 1 = 0.844 +- 0.053 (in-sample avg dev_std = 0.075)
SUFF for r=0.9 class 2 = 0.935 +- 0.053 (in-sample avg dev_std = 0.075)
SUFF for r=0.9 all KL = 0.974 +- 0.053 (in-sample avg dev_std = 0.075)
SUFF for r=0.9 all L1 = 0.905 +- 0.092 (in-sample avg dev_std = 0.075)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
6921
torch.Size([6921, 3])
6921

Model Accuracy of binarized graphs for r=0.3 =  0.349
Model XAI F1 of binarized graphs for r=0.3 =  0.41494749999999997
Model XAI WIoU of binarized graphs for r=0.3 =  0.28239
len(reference) = 769
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.349
SUFF for r=0.3 class 0 = 0.373 +- 0.266 (in-sample avg dev_std = 0.507)
SUFF for r=0.3 class 1 = 0.371 +- 0.266 (in-sample avg dev_std = 0.507)
SUFF for r=0.3 class 2 = 0.376 +- 0.266 (in-sample avg dev_std = 0.507)
SUFF for r=0.3 all KL = 0.269 +- 0.266 (in-sample avg dev_std = 0.507)
SUFF for r=0.3 all L1 = 0.373 +- 0.122 (in-sample avg dev_std = 0.507)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.506
Model XAI F1 of binarized graphs for r=0.6 =  0.5729099999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.43138750000000003
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.492
SUFF for r=0.6 class 0 = 0.625 +- 0.259 (in-sample avg dev_std = 0.310)
SUFF for r=0.6 class 1 = 0.725 +- 0.259 (in-sample avg dev_std = 0.310)
SUFF for r=0.6 class 2 = 0.669 +- 0.259 (in-sample avg dev_std = 0.310)
SUFF for r=0.6 all KL = 0.738 +- 0.259 (in-sample avg dev_std = 0.310)
SUFF for r=0.6 all L1 = 0.672 +- 0.227 (in-sample avg dev_std = 0.310)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.748
Model XAI F1 of binarized graphs for r=0.9 =  0.5884075
Model XAI WIoU of binarized graphs for r=0.9 =  0.47348
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.723
SUFF for r=0.9 class 0 = 0.81 +- 0.084 (in-sample avg dev_std = 0.166)
SUFF for r=0.9 class 1 = 0.95 +- 0.084 (in-sample avg dev_std = 0.166)
SUFF for r=0.9 class 2 = 0.81 +- 0.084 (in-sample avg dev_std = 0.166)
SUFF for r=0.9 all KL = 0.934 +- 0.084 (in-sample avg dev_std = 0.166)
SUFF for r=0.9 all L1 = 0.855 +- 0.131 (in-sample avg dev_std = 0.166)


ratio=1.0



Zero intervened samples, skipping weight=1.0

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Mar 20 14:01:45 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/20/2024 02:01:45 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:01 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:03 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:05 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:08 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:02:11 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 124...
[0m[1;37mINFO[0m: [1mCheckpoint 124: 
-----------------------------------
Train ACCURACY: 0.8979
Train Loss: 0.4207
ID Validation ACCURACY: 0.8973
ID Validation Loss: 0.4417
ID Test ACCURACY: 0.8983
ID Test Loss: 0.4343
OOD Validation ACCURACY: 0.8787
OOD Validation Loss: 0.4566
OOD Test ACCURACY: 0.7470
OOD Test Loss: 0.7194

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 109...
[0m[1;37mINFO[0m: [1mCheckpoint 109: 
-----------------------------------
Train ACCURACY: 0.8898
Train Loss: 0.4455
ID Validation ACCURACY: 0.8893
ID Validation Loss: 0.4661
ID Test ACCURACY: 0.8897
ID Test Loss: 0.4398
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.3359
OOD Test ACCURACY: 0.7320
OOD Test Loss: 0.7218

[0m[1;37mINFO[0m: [1mChartInfo 0.8983 0.7470 0.8897 0.7320 0.8893 0.9317[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.724
WIoU for r=0.3 = 0.707
F1 for r=0.6 = 0.620
WIoU for r=0.6 = 0.784
F1 for r=0.9 = 0.476
WIoU for r=0.9 = 0.784
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.784
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.817
WIoU for r=0.3 = 0.880
F1 for r=0.6 = 0.690
WIoU for r=0.6 = 1.000
F1 for r=0.9 = 0.563
WIoU for r=0.9 = 1.000
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 1.000
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.505
WIoU for r=0.3 = 0.413
F1 for r=0.6 = 0.677
WIoU for r=0.6 = 0.587
F1 for r=0.9 = 0.592
WIoU for r=0.9 = 0.612
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.612
Size bank for r=0.3 -> 1500
Size bank for r=0.6 -> 1500
Size bank for r=0.9 -> 1422


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.655
Model XAI F1 of binarized graphs for r=0.3 =  0.7239125
Model XAI WIoU of binarized graphs for r=0.3 =  0.7069249999999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.402
NEC for r=0.3 class 0 = 0.599 +- 0.272 (in-sample avg dev_std = 0.461)
NEC for r=0.3 class 1 = 0.547 +- 0.272 (in-sample avg dev_std = 0.461)
NEC for r=0.3 class 2 = 0.629 +- 0.272 (in-sample avg dev_std = 0.461)
NEC for r=0.3 all KL = 0.662 +- 0.272 (in-sample avg dev_std = 0.461)
NEC for r=0.3 all L1 = 0.592 +- 0.148 (in-sample avg dev_std = 0.461)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.856
Model XAI F1 of binarized graphs for r=0.6 =  0.61969
Model XAI WIoU of binarized graphs for r=0.6 =  0.7843725
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.48
NEC for r=0.6 class 0 = 0.561 +- 0.295 (in-sample avg dev_std = 0.474)
NEC for r=0.6 class 1 = 0.524 +- 0.295 (in-sample avg dev_std = 0.474)
NEC for r=0.6 class 2 = 0.604 +- 0.295 (in-sample avg dev_std = 0.474)
NEC for r=0.6 all KL = 0.614 +- 0.295 (in-sample avg dev_std = 0.474)
NEC for r=0.6 all L1 = 0.563 +- 0.164 (in-sample avg dev_std = 0.474)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.896
Model XAI F1 of binarized graphs for r=0.9 =  0.4756975
Model XAI WIoU of binarized graphs for r=0.9 =  0.7844737500000001
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.538
NEC for r=0.9 class 0 = 0.545 +- 0.292 (in-sample avg dev_std = 0.537)
NEC for r=0.9 class 1 = 0.491 +- 0.292 (in-sample avg dev_std = 0.537)
NEC for r=0.9 class 2 = 0.531 +- 0.292 (in-sample avg dev_std = 0.537)
NEC for r=0.9 all KL = 0.557 +- 0.292 (in-sample avg dev_std = 0.537)
NEC for r=0.9 all L1 = 0.522 +- 0.165 (in-sample avg dev_std = 0.537)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.896
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.78447125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.533
NEC for r=1.0 class 0 = 0.537 +- 0.288 (in-sample avg dev_std = 0.548)
NEC for r=1.0 class 1 = 0.491 +- 0.288 (in-sample avg dev_std = 0.548)
NEC for r=1.0 class 2 = 0.529 +- 0.288 (in-sample avg dev_std = 0.548)
NEC for r=1.0 all KL = 0.556 +- 0.288 (in-sample avg dev_std = 0.548)
NEC for r=1.0 all L1 = 0.519 +- 0.161 (in-sample avg dev_std = 0.548)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.585
Model XAI F1 of binarized graphs for r=0.3 =  0.8170425
Model XAI WIoU of binarized graphs for r=0.3 =  0.88028
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.155
NEC for r=0.3 class 0 = 0.589 +- 0.263 (in-sample avg dev_std = 0.441)
NEC for r=0.3 class 1 = 0.646 +- 0.263 (in-sample avg dev_std = 0.441)
NEC for r=0.3 class 2 = 0.536 +- 0.263 (in-sample avg dev_std = 0.441)
NEC for r=0.3 all KL = 0.725 +- 0.263 (in-sample avg dev_std = 0.441)
NEC for r=0.3 all L1 = 0.59 +- 0.177 (in-sample avg dev_std = 0.441)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  0.6904699999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.9999849999999999
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.53
NEC for r=0.6 class 0 = 0.489 +- 0.291 (in-sample avg dev_std = 0.642)
NEC for r=0.6 class 1 = 0.388 +- 0.291 (in-sample avg dev_std = 0.642)
NEC for r=0.6 class 2 = 0.431 +- 0.291 (in-sample avg dev_std = 0.642)
NEC for r=0.6 all KL = 0.556 +- 0.291 (in-sample avg dev_std = 0.642)
NEC for r=0.6 all L1 = 0.436 +- 0.176 (in-sample avg dev_std = 0.642)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.881
Model XAI F1 of binarized graphs for r=0.9 =  0.56300125
Model XAI WIoU of binarized graphs for r=0.9 =  0.9999549999999999
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.601
NEC for r=0.9 class 0 = 0.402 +- 0.244 (in-sample avg dev_std = 0.599)
NEC for r=0.9 class 1 = 0.358 +- 0.244 (in-sample avg dev_std = 0.599)
NEC for r=0.9 class 2 = 0.357 +- 0.244 (in-sample avg dev_std = 0.599)
NEC for r=0.9 all KL = 0.415 +- 0.244 (in-sample avg dev_std = 0.599)
NEC for r=0.9 all L1 = 0.372 +- 0.162 (in-sample avg dev_std = 0.599)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.881
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  0.9999549999999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.61
NEC for r=1.0 class 0 = 0.401 +- 0.243 (in-sample avg dev_std = 0.605)
NEC for r=1.0 class 1 = 0.336 +- 0.243 (in-sample avg dev_std = 0.605)
NEC for r=1.0 class 2 = 0.356 +- 0.243 (in-sample avg dev_std = 0.605)
NEC for r=1.0 all KL = 0.41 +- 0.243 (in-sample avg dev_std = 0.605)
NEC for r=1.0 all L1 = 0.364 +- 0.157 (in-sample avg dev_std = 0.605)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.322
Model XAI F1 of binarized graphs for r=0.3 =  0.50527125
Model XAI WIoU of binarized graphs for r=0.3 =  0.41275999999999996
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.36
NEC for r=0.3 class 0 = 0.503 +- 0.276 (in-sample avg dev_std = 0.388)
NEC for r=0.3 class 1 = 0.586 +- 0.276 (in-sample avg dev_std = 0.388)
NEC for r=0.3 class 2 = 0.505 +- 0.276 (in-sample avg dev_std = 0.388)
NEC for r=0.3 all KL = 0.475 +- 0.276 (in-sample avg dev_std = 0.388)
NEC for r=0.3 all L1 = 0.53 +- 0.178 (in-sample avg dev_std = 0.388)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.649
Model XAI F1 of binarized graphs for r=0.6 =  0.67744
Model XAI WIoU of binarized graphs for r=0.6 =  0.5872175
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.522
NEC for r=0.6 class 0 = 0.481 +- 0.307 (in-sample avg dev_std = 0.592)
NEC for r=0.6 class 1 = 0.375 +- 0.307 (in-sample avg dev_std = 0.592)
NEC for r=0.6 class 2 = 0.613 +- 0.307 (in-sample avg dev_std = 0.592)
NEC for r=0.6 all KL = 0.554 +- 0.307 (in-sample avg dev_std = 0.592)
NEC for r=0.6 all L1 = 0.492 +- 0.188 (in-sample avg dev_std = 0.592)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.759
Model XAI F1 of binarized graphs for r=0.9 =  0.592455
Model XAI WIoU of binarized graphs for r=0.9 =  0.6116812500000001
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.612
NEC for r=0.9 class 0 = 0.44 +- 0.244 (in-sample avg dev_std = 0.551)
NEC for r=0.9 class 1 = 0.332 +- 0.244 (in-sample avg dev_std = 0.551)
NEC for r=0.9 class 2 = 0.499 +- 0.244 (in-sample avg dev_std = 0.551)
NEC for r=0.9 all KL = 0.438 +- 0.244 (in-sample avg dev_std = 0.551)
NEC for r=0.9 all L1 = 0.425 +- 0.154 (in-sample avg dev_std = 0.551)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.759
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.61195375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.635
NEC for r=1.0 class 0 = 0.438 +- 0.237 (in-sample avg dev_std = 0.549)
NEC for r=1.0 class 1 = 0.313 +- 0.237 (in-sample avg dev_std = 0.549)
NEC for r=1.0 class 2 = 0.472 +- 0.237 (in-sample avg dev_std = 0.549)
NEC for r=1.0 all KL = 0.419 +- 0.237 (in-sample avg dev_std = 0.549)
NEC for r=1.0 all L1 = 0.409 +- 0.152 (in-sample avg dev_std = 0.549)


Evaluating SUFF for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7191
torch.Size([7191, 3])
7191

Model Accuracy of binarized graphs for r=0.3 =  0.657
Model XAI F1 of binarized graphs for r=0.3 =  0.7239125
Model XAI WIoU of binarized graphs for r=0.3 =  0.7069249999999999
len(reference) = 799
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.455
SUFF for r=0.3 class 0 = 0.473 +- 0.296 (in-sample avg dev_std = 0.546)
SUFF for r=0.3 class 1 = 0.603 +- 0.296 (in-sample avg dev_std = 0.546)
SUFF for r=0.3 class 2 = 0.414 +- 0.296 (in-sample avg dev_std = 0.546)
SUFF for r=0.3 all KL = 0.424 +- 0.296 (in-sample avg dev_std = 0.546)
SUFF for r=0.3 all L1 = 0.496 +- 0.190 (in-sample avg dev_std = 0.546)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.855
Model XAI F1 of binarized graphs for r=0.6 =  0.61969
Model XAI WIoU of binarized graphs for r=0.6 =  0.7843725
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.676
SUFF for r=0.6 class 0 = 0.527 +- 0.305 (in-sample avg dev_std = 0.416)
SUFF for r=0.6 class 1 = 0.774 +- 0.305 (in-sample avg dev_std = 0.416)
SUFF for r=0.6 class 2 = 0.593 +- 0.305 (in-sample avg dev_std = 0.416)
SUFF for r=0.6 all KL = 0.608 +- 0.305 (in-sample avg dev_std = 0.416)
SUFF for r=0.6 all L1 = 0.633 +- 0.232 (in-sample avg dev_std = 0.416)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.896
Model XAI F1 of binarized graphs for r=0.9 =  0.4756975
Model XAI WIoU of binarized graphs for r=0.9 =  0.7844737500000001
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.818
SUFF for r=0.9 class 0 = 0.725 +- 0.208 (in-sample avg dev_std = 0.162)
SUFF for r=0.9 class 1 = 0.817 +- 0.208 (in-sample avg dev_std = 0.162)
SUFF for r=0.9 class 2 = 0.863 +- 0.208 (in-sample avg dev_std = 0.162)
SUFF for r=0.9 all KL = 0.87 +- 0.208 (in-sample avg dev_std = 0.162)
SUFF for r=0.9 all L1 = 0.804 +- 0.204 (in-sample avg dev_std = 0.162)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.585
Model XAI F1 of binarized graphs for r=0.3 =  0.8170425
Model XAI WIoU of binarized graphs for r=0.3 =  0.88028
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.501
SUFF for r=0.3 class 0 = 0.516 +- 0.328 (in-sample avg dev_std = 0.551)
SUFF for r=0.3 class 1 = 0.761 +- 0.328 (in-sample avg dev_std = 0.551)
SUFF for r=0.3 class 2 = 0.449 +- 0.328 (in-sample avg dev_std = 0.551)
SUFF for r=0.3 all KL = 0.456 +- 0.328 (in-sample avg dev_std = 0.551)
SUFF for r=0.3 all L1 = 0.574 +- 0.217 (in-sample avg dev_std = 0.551)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  0.6904699999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.9999849999999999
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.867
SUFF for r=0.6 class 0 = 0.755 +- 0.248 (in-sample avg dev_std = 0.360)
SUFF for r=0.6 class 1 = 0.839 +- 0.248 (in-sample avg dev_std = 0.360)
SUFF for r=0.6 class 2 = 0.813 +- 0.248 (in-sample avg dev_std = 0.360)
SUFF for r=0.6 all KL = 0.787 +- 0.248 (in-sample avg dev_std = 0.360)
SUFF for r=0.6 all L1 = 0.802 +- 0.184 (in-sample avg dev_std = 0.360)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.881
Model XAI F1 of binarized graphs for r=0.9 =  0.56300125
Model XAI WIoU of binarized graphs for r=0.9 =  0.9999549999999999
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.893
SUFF for r=0.9 class 0 = 0.74 +- 0.193 (in-sample avg dev_std = 0.206)
SUFF for r=0.9 class 1 = 0.91 +- 0.193 (in-sample avg dev_std = 0.206)
SUFF for r=0.9 class 2 = 0.887 +- 0.193 (in-sample avg dev_std = 0.206)
SUFF for r=0.9 all KL = 0.889 +- 0.193 (in-sample avg dev_std = 0.206)
SUFF for r=0.9 all L1 = 0.845 +- 0.190 (in-sample avg dev_std = 0.206)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
7128
torch.Size([7128, 3])
7128

Model Accuracy of binarized graphs for r=0.3 =  0.323
Model XAI F1 of binarized graphs for r=0.3 =  0.50527125
Model XAI WIoU of binarized graphs for r=0.3 =  0.41275999999999996
len(reference) = 792
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.361
SUFF for r=0.3 class 0 = 0.533 +- 0.254 (in-sample avg dev_std = 0.409)
SUFF for r=0.3 class 1 = 0.503 +- 0.254 (in-sample avg dev_std = 0.409)
SUFF for r=0.3 class 2 = 0.501 +- 0.254 (in-sample avg dev_std = 0.409)
SUFF for r=0.3 all KL = 0.587 +- 0.254 (in-sample avg dev_std = 0.409)
SUFF for r=0.3 all L1 = 0.512 +- 0.165 (in-sample avg dev_std = 0.409)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.649
Model XAI F1 of binarized graphs for r=0.6 =  0.67744
Model XAI WIoU of binarized graphs for r=0.6 =  0.5872175
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.606
SUFF for r=0.6 class 0 = 0.594 +- 0.260 (in-sample avg dev_std = 0.391)
SUFF for r=0.6 class 1 = 0.866 +- 0.260 (in-sample avg dev_std = 0.391)
SUFF for r=0.6 class 2 = 0.697 +- 0.260 (in-sample avg dev_std = 0.391)
SUFF for r=0.6 all KL = 0.723 +- 0.260 (in-sample avg dev_std = 0.391)
SUFF for r=0.6 all L1 = 0.716 +- 0.207 (in-sample avg dev_std = 0.391)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.759
Model XAI F1 of binarized graphs for r=0.9 =  0.592455
Model XAI WIoU of binarized graphs for r=0.9 =  0.6116812500000001
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.712
SUFF for r=0.9 class 0 = 0.707 +- 0.125 (in-sample avg dev_std = 0.184)
SUFF for r=0.9 class 1 = 0.943 +- 0.125 (in-sample avg dev_std = 0.184)
SUFF for r=0.9 class 2 = 0.83 +- 0.125 (in-sample avg dev_std = 0.184)
SUFF for r=0.9 all KL = 0.906 +- 0.125 (in-sample avg dev_std = 0.184)
SUFF for r=0.9 all L1 = 0.825 +- 0.170 (in-sample avg dev_std = 0.184)


ratio=1.0



Zero intervened samples, skipping weight=1.0

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Mar 20 14:06:09 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:09 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:22 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:24 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:26 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:28 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:06:30 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 112...
[0m[1;37mINFO[0m: [1mCheckpoint 112: 
-----------------------------------
Train ACCURACY: 0.9111
Train Loss: 0.4118
ID Validation ACCURACY: 0.9100
ID Validation Loss: 0.4282
ID Test ACCURACY: 0.9093
ID Test Loss: 0.4292
OOD Validation ACCURACY: 0.8720
OOD Validation Loss: 0.4700
OOD Test ACCURACY: 0.6660
OOD Test Loss: 0.8918

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 146...
[0m[1;37mINFO[0m: [1mCheckpoint 146: 
-----------------------------------
Train ACCURACY: 0.8854
Train Loss: 0.4498
ID Validation ACCURACY: 0.8820
ID Validation Loss: 0.4694
ID Test ACCURACY: 0.8770
ID Test Loss: 0.4720
OOD Validation ACCURACY: 0.9293
OOD Validation Loss: 0.3373
OOD Test ACCURACY: 0.5787
OOD Test Loss: 1.0425

[0m[1;37mINFO[0m: [1mChartInfo 0.9093 0.6660 0.8770 0.5787 0.8820 0.9293[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.733
WIoU for r=0.3 = 0.726
F1 for r=0.6 = 0.611
WIoU for r=0.6 = 0.824
F1 for r=0.9 = 0.476
WIoU for r=0.9 = 0.817
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.817
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.829
WIoU for r=0.3 = 0.884
F1 for r=0.6 = 0.694
WIoU for r=0.6 = 0.981
F1 for r=0.9 = 0.549
WIoU for r=0.9 = 0.981
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 0.981
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.516
WIoU for r=0.3 = 0.414
F1 for r=0.6 = 0.652
WIoU for r=0.6 = 0.552
F1 for r=0.9 = 0.579
WIoU for r=0.9 = 0.515
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.509
Size bank for r=0.3 -> 1500
Size bank for r=0.6 -> 1500
Size bank for r=0.9 -> 1201


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.71
Model XAI F1 of binarized graphs for r=0.3 =  0.73309
Model XAI WIoU of binarized graphs for r=0.3 =  0.7262937500000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.388
NEC for r=0.3 class 0 = 0.6 +- 0.286 (in-sample avg dev_std = 0.492)
NEC for r=0.3 class 1 = 0.533 +- 0.286 (in-sample avg dev_std = 0.492)
NEC for r=0.3 class 2 = 0.643 +- 0.286 (in-sample avg dev_std = 0.492)
NEC for r=0.3 all KL = 0.683 +- 0.286 (in-sample avg dev_std = 0.492)
NEC for r=0.3 all L1 = 0.592 +- 0.151 (in-sample avg dev_std = 0.492)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.865
Model XAI F1 of binarized graphs for r=0.6 =  0.6113262500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.8242512500000001
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.472
NEC for r=0.6 class 0 = 0.536 +- 0.303 (in-sample avg dev_std = 0.507)
NEC for r=0.6 class 1 = 0.487 +- 0.303 (in-sample avg dev_std = 0.507)
NEC for r=0.6 class 2 = 0.633 +- 0.303 (in-sample avg dev_std = 0.507)
NEC for r=0.6 all KL = 0.58 +- 0.303 (in-sample avg dev_std = 0.507)
NEC for r=0.6 all L1 = 0.553 +- 0.165 (in-sample avg dev_std = 0.507)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.905
Model XAI F1 of binarized graphs for r=0.9 =  0.475505
Model XAI WIoU of binarized graphs for r=0.9 =  0.8168412500000001
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.561
NEC for r=0.9 class 0 = 0.488 +- 0.305 (in-sample avg dev_std = 0.541)
NEC for r=0.9 class 1 = 0.439 +- 0.305 (in-sample avg dev_std = 0.541)
NEC for r=0.9 class 2 = 0.565 +- 0.305 (in-sample avg dev_std = 0.541)
NEC for r=0.9 all KL = 0.516 +- 0.305 (in-sample avg dev_std = 0.541)
NEC for r=0.9 all L1 = 0.498 +- 0.175 (in-sample avg dev_std = 0.541)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.905
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.81683125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.565
NEC for r=1.0 class 0 = 0.486 +- 0.302 (in-sample avg dev_std = 0.537)
NEC for r=1.0 class 1 = 0.438 +- 0.302 (in-sample avg dev_std = 0.537)
NEC for r=1.0 class 2 = 0.557 +- 0.302 (in-sample avg dev_std = 0.537)
NEC for r=1.0 all KL = 0.51 +- 0.302 (in-sample avg dev_std = 0.537)
NEC for r=1.0 all L1 = 0.494 +- 0.173 (in-sample avg dev_std = 0.537)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.64
Model XAI F1 of binarized graphs for r=0.3 =  0.8285925000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.883925
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.357
NEC for r=0.3 class 0 = 0.613 +- 0.257 (in-sample avg dev_std = 0.438)
NEC for r=0.3 class 1 = 0.581 +- 0.257 (in-sample avg dev_std = 0.438)
NEC for r=0.3 class 2 = 0.632 +- 0.257 (in-sample avg dev_std = 0.438)
NEC for r=0.3 all KL = 0.743 +- 0.257 (in-sample avg dev_std = 0.438)
NEC for r=0.3 all L1 = 0.609 +- 0.153 (in-sample avg dev_std = 0.438)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.876
Model XAI F1 of binarized graphs for r=0.6 =  0.6938037499999998
Model XAI WIoU of binarized graphs for r=0.6 =  0.9806912499999999
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.611
NEC for r=0.6 class 0 = 0.497 +- 0.312 (in-sample avg dev_std = 0.599)
NEC for r=0.6 class 1 = 0.373 +- 0.312 (in-sample avg dev_std = 0.599)
NEC for r=0.6 class 2 = 0.481 +- 0.312 (in-sample avg dev_std = 0.599)
NEC for r=0.6 all KL = 0.556 +- 0.312 (in-sample avg dev_std = 0.599)
NEC for r=0.6 all L1 = 0.451 +- 0.170 (in-sample avg dev_std = 0.599)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.876
Model XAI F1 of binarized graphs for r=0.9 =  0.5493487499999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.9806912499999999
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.666
NEC for r=0.9 class 0 = 0.414 +- 0.271 (in-sample avg dev_std = 0.576)
NEC for r=0.9 class 1 = 0.31 +- 0.271 (in-sample avg dev_std = 0.576)
NEC for r=0.9 class 2 = 0.405 +- 0.271 (in-sample avg dev_std = 0.576)
NEC for r=0.9 all KL = 0.415 +- 0.271 (in-sample avg dev_std = 0.576)
NEC for r=0.9 all L1 = 0.377 +- 0.158 (in-sample avg dev_std = 0.576)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.876
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  0.9806912499999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.666
NEC for r=1.0 class 0 = 0.382 +- 0.271 (in-sample avg dev_std = 0.573)
NEC for r=1.0 class 1 = 0.297 +- 0.271 (in-sample avg dev_std = 0.573)
NEC for r=1.0 class 2 = 0.394 +- 0.271 (in-sample avg dev_std = 0.573)
NEC for r=1.0 all KL = 0.398 +- 0.271 (in-sample avg dev_std = 0.573)
NEC for r=1.0 all L1 = 0.358 +- 0.160 (in-sample avg dev_std = 0.573)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.311
Model XAI F1 of binarized graphs for r=0.3 =  0.5158937499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.41417375
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.372
NEC for r=0.3 class 0 = 0.48 +- 0.288 (in-sample avg dev_std = 0.497)
NEC for r=0.3 class 1 = 0.535 +- 0.288 (in-sample avg dev_std = 0.497)
NEC for r=0.3 class 2 = 0.535 +- 0.288 (in-sample avg dev_std = 0.497)
NEC for r=0.3 all KL = 0.548 +- 0.288 (in-sample avg dev_std = 0.497)
NEC for r=0.3 all L1 = 0.516 +- 0.173 (in-sample avg dev_std = 0.497)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.632
Model XAI F1 of binarized graphs for r=0.6 =  0.6516525
Model XAI WIoU of binarized graphs for r=0.6 =  0.55193625
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.493
NEC for r=0.6 class 0 = 0.435 +- 0.320 (in-sample avg dev_std = 0.548)
NEC for r=0.6 class 1 = 0.341 +- 0.320 (in-sample avg dev_std = 0.548)
NEC for r=0.6 class 2 = 0.619 +- 0.320 (in-sample avg dev_std = 0.548)
NEC for r=0.6 all KL = 0.515 +- 0.320 (in-sample avg dev_std = 0.548)
NEC for r=0.6 all L1 = 0.467 +- 0.221 (in-sample avg dev_std = 0.548)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.685
Model XAI F1 of binarized graphs for r=0.9 =  0.57940875
Model XAI WIoU of binarized graphs for r=0.9 =  0.51532875
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.579
NEC for r=0.9 class 0 = 0.436 +- 0.257 (in-sample avg dev_std = 0.506)
NEC for r=0.9 class 1 = 0.221 +- 0.257 (in-sample avg dev_std = 0.506)
NEC for r=0.9 class 2 = 0.495 +- 0.257 (in-sample avg dev_std = 0.506)
NEC for r=0.9 all KL = 0.387 +- 0.257 (in-sample avg dev_std = 0.506)
NEC for r=0.9 all L1 = 0.387 +- 0.197 (in-sample avg dev_std = 0.506)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.674
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.50932125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.574
NEC for r=1.0 class 0 = 0.438 +- 0.254 (in-sample avg dev_std = 0.507)
NEC for r=1.0 class 1 = 0.204 +- 0.254 (in-sample avg dev_std = 0.507)
NEC for r=1.0 class 2 = 0.498 +- 0.254 (in-sample avg dev_std = 0.507)
NEC for r=1.0 all KL = 0.379 +- 0.254 (in-sample avg dev_std = 0.507)
NEC for r=1.0 all L1 = 0.383 +- 0.198 (in-sample avg dev_std = 0.507)


Evaluating SUFF for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7146
torch.Size([7146, 3])
7146

Model Accuracy of binarized graphs for r=0.3 =  0.715
Model XAI F1 of binarized graphs for r=0.3 =  0.73309
Model XAI WIoU of binarized graphs for r=0.3 =  0.7262937500000001
len(reference) = 794
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.496
SUFF for r=0.3 class 0 = 0.543 +- 0.297 (in-sample avg dev_std = 0.583)
SUFF for r=0.3 class 1 = 0.578 +- 0.297 (in-sample avg dev_std = 0.583)
SUFF for r=0.3 class 2 = 0.429 +- 0.297 (in-sample avg dev_std = 0.583)
SUFF for r=0.3 all KL = 0.421 +- 0.297 (in-sample avg dev_std = 0.583)
SUFF for r=0.3 all L1 = 0.516 +- 0.175 (in-sample avg dev_std = 0.583)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.865
Model XAI F1 of binarized graphs for r=0.6 =  0.6113262500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.8242512500000001
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.776
SUFF for r=0.6 class 0 = 0.681 +- 0.238 (in-sample avg dev_std = 0.377)
SUFF for r=0.6 class 1 = 0.72 +- 0.238 (in-sample avg dev_std = 0.377)
SUFF for r=0.6 class 2 = 0.719 +- 0.238 (in-sample avg dev_std = 0.377)
SUFF for r=0.6 all KL = 0.728 +- 0.238 (in-sample avg dev_std = 0.377)
SUFF for r=0.6 all L1 = 0.707 +- 0.180 (in-sample avg dev_std = 0.377)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.905
Model XAI F1 of binarized graphs for r=0.9 =  0.475505
Model XAI WIoU of binarized graphs for r=0.9 =  0.8168412500000001
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.857
SUFF for r=0.9 class 0 = 0.781 +- 0.201 (in-sample avg dev_std = 0.239)
SUFF for r=0.9 class 1 = 0.808 +- 0.201 (in-sample avg dev_std = 0.239)
SUFF for r=0.9 class 2 = 0.871 +- 0.201 (in-sample avg dev_std = 0.239)
SUFF for r=0.9 all KL = 0.881 +- 0.201 (in-sample avg dev_std = 0.239)
SUFF for r=0.9 all L1 = 0.821 +- 0.168 (in-sample avg dev_std = 0.239)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.64
Model XAI F1 of binarized graphs for r=0.3 =  0.8285925000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.883925
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.52
SUFF for r=0.3 class 0 = 0.482 +- 0.327 (in-sample avg dev_std = 0.618)
SUFF for r=0.3 class 1 = 0.728 +- 0.327 (in-sample avg dev_std = 0.618)
SUFF for r=0.3 class 2 = 0.411 +- 0.327 (in-sample avg dev_std = 0.618)
SUFF for r=0.3 all KL = 0.393 +- 0.327 (in-sample avg dev_std = 0.618)
SUFF for r=0.3 all L1 = 0.539 +- 0.210 (in-sample avg dev_std = 0.618)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.876
Model XAI F1 of binarized graphs for r=0.6 =  0.6938037499999998
Model XAI WIoU of binarized graphs for r=0.6 =  0.9806912499999999
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.827
SUFF for r=0.6 class 0 = 0.625 +- 0.337 (in-sample avg dev_std = 0.443)
SUFF for r=0.6 class 1 = 0.808 +- 0.337 (in-sample avg dev_std = 0.443)
SUFF for r=0.6 class 2 = 0.826 +- 0.337 (in-sample avg dev_std = 0.443)
SUFF for r=0.6 all KL = 0.704 +- 0.337 (in-sample avg dev_std = 0.443)
SUFF for r=0.6 all L1 = 0.752 +- 0.214 (in-sample avg dev_std = 0.443)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.876
Model XAI F1 of binarized graphs for r=0.9 =  0.5493487499999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.9806912499999999
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.815
SUFF for r=0.9 class 0 = 0.631 +- 0.318 (in-sample avg dev_std = 0.320)
SUFF for r=0.9 class 1 = 0.879 +- 0.318 (in-sample avg dev_std = 0.320)
SUFF for r=0.9 class 2 = 0.907 +- 0.318 (in-sample avg dev_std = 0.320)
SUFF for r=0.9 all KL = 0.803 +- 0.318 (in-sample avg dev_std = 0.320)
SUFF for r=0.9 all L1 = 0.805 +- 0.231 (in-sample avg dev_std = 0.320)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
7065
torch.Size([7065, 3])
7065

Model Accuracy of binarized graphs for r=0.3 =  0.313
Model XAI F1 of binarized graphs for r=0.3 =  0.5158937499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.41417375
len(reference) = 785
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.345
SUFF for r=0.3 class 0 = 0.451 +- 0.264 (in-sample avg dev_std = 0.531)
SUFF for r=0.3 class 1 = 0.467 +- 0.264 (in-sample avg dev_std = 0.531)
SUFF for r=0.3 class 2 = 0.495 +- 0.264 (in-sample avg dev_std = 0.531)
SUFF for r=0.3 all KL = 0.435 +- 0.264 (in-sample avg dev_std = 0.531)
SUFF for r=0.3 all L1 = 0.471 +- 0.137 (in-sample avg dev_std = 0.531)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.632
Model XAI F1 of binarized graphs for r=0.6 =  0.6516525
Model XAI WIoU of binarized graphs for r=0.6 =  0.55193625
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.59
SUFF for r=0.6 class 0 = 0.555 +- 0.244 (in-sample avg dev_std = 0.409)
SUFF for r=0.6 class 1 = 0.782 +- 0.244 (in-sample avg dev_std = 0.409)
SUFF for r=0.6 class 2 = 0.718 +- 0.244 (in-sample avg dev_std = 0.409)
SUFF for r=0.6 all KL = 0.689 +- 0.244 (in-sample avg dev_std = 0.409)
SUFF for r=0.6 all L1 = 0.683 +- 0.211 (in-sample avg dev_std = 0.409)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.685
Model XAI F1 of binarized graphs for r=0.9 =  0.57940875
Model XAI WIoU of binarized graphs for r=0.9 =  0.51532875
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.64
SUFF for r=0.9 class 0 = 0.705 +- 0.157 (in-sample avg dev_std = 0.195)
SUFF for r=0.9 class 1 = 0.943 +- 0.157 (in-sample avg dev_std = 0.195)
SUFF for r=0.9 class 2 = 0.765 +- 0.157 (in-sample avg dev_std = 0.195)
SUFF for r=0.9 all KL = 0.878 +- 0.157 (in-sample avg dev_std = 0.195)
SUFF for r=0.9 all L1 = 0.802 +- 0.177 (in-sample avg dev_std = 0.195)


ratio=1.0



Zero intervened samples, skipping weight=1.0

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Mar 20 14:10:14 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:14 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:26 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:28 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:30 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:32 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:10:34 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 137...
[0m[1;37mINFO[0m: [1mCheckpoint 137: 
-----------------------------------
Train ACCURACY: 0.9082
Train Loss: 0.4161
ID Validation ACCURACY: 0.9060
ID Validation Loss: 0.4276
ID Test ACCURACY: 0.9077
ID Test Loss: 0.4175
OOD Validation ACCURACY: 0.9313
OOD Validation Loss: 0.3282
OOD Test ACCURACY: 0.8457
OOD Test Loss: 0.4898

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 115...
[0m[1;37mINFO[0m: [1mCheckpoint 115: 
-----------------------------------
Train ACCURACY: 0.8790
Train Loss: 0.4656
ID Validation ACCURACY: 0.8803
ID Validation Loss: 0.4735
ID Test ACCURACY: 0.8743
ID Test Loss: 0.4768
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.3354
OOD Test ACCURACY: 0.8413
OOD Test Loss: 0.5178

[0m[1;37mINFO[0m: [1mChartInfo 0.9077 0.8457 0.8743 0.8413 0.8803 0.9317[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.728
WIoU for r=0.3 = 0.704
F1 for r=0.6 = 0.614
WIoU for r=0.6 = 0.800
F1 for r=0.9 = 0.476
WIoU for r=0.9 = 0.797
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.797
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.869
WIoU for r=0.3 = 0.783
F1 for r=0.6 = 0.798
WIoU for r=0.6 = 1.000
F1 for r=0.9 = 0.618
WIoU for r=0.9 = 1.000
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 1.000
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.540
WIoU for r=0.3 = 0.420
F1 for r=0.6 = 0.646
WIoU for r=0.6 = 0.510
F1 for r=0.9 = 0.592
WIoU for r=0.9 = 0.496
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.495
Size bank for r=0.3 -> 1500
Size bank for r=0.6 -> 1500
Size bank for r=0.9 -> 1004


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.65
Model XAI F1 of binarized graphs for r=0.3 =  0.7277025
Model XAI WIoU of binarized graphs for r=0.3 =  0.70377375
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.335
NEC for r=0.3 class 0 = 0.613 +- 0.291 (in-sample avg dev_std = 0.475)
NEC for r=0.3 class 1 = 0.581 +- 0.291 (in-sample avg dev_std = 0.475)
NEC for r=0.3 class 2 = 0.634 +- 0.291 (in-sample avg dev_std = 0.475)
NEC for r=0.3 all KL = 0.672 +- 0.291 (in-sample avg dev_std = 0.475)
NEC for r=0.3 all L1 = 0.609 +- 0.161 (in-sample avg dev_std = 0.475)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.846
Model XAI F1 of binarized graphs for r=0.6 =  0.6144775
Model XAI WIoU of binarized graphs for r=0.6 =  0.80013
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.456
NEC for r=0.6 class 0 = 0.544 +- 0.291 (in-sample avg dev_std = 0.498)
NEC for r=0.6 class 1 = 0.57 +- 0.291 (in-sample avg dev_std = 0.498)
NEC for r=0.6 class 2 = 0.61 +- 0.291 (in-sample avg dev_std = 0.498)
NEC for r=0.6 all KL = 0.625 +- 0.291 (in-sample avg dev_std = 0.498)
NEC for r=0.6 all L1 = 0.575 +- 0.163 (in-sample avg dev_std = 0.498)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.905
Model XAI F1 of binarized graphs for r=0.9 =  0.4757187500000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.79734375
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.535
NEC for r=0.9 class 0 = 0.489 +- 0.287 (in-sample avg dev_std = 0.533)
NEC for r=0.9 class 1 = 0.513 +- 0.287 (in-sample avg dev_std = 0.533)
NEC for r=0.9 class 2 = 0.563 +- 0.287 (in-sample avg dev_std = 0.533)
NEC for r=0.9 all KL = 0.551 +- 0.287 (in-sample avg dev_std = 0.533)
NEC for r=0.9 all L1 = 0.523 +- 0.163 (in-sample avg dev_std = 0.533)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.906
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.7967962499999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.54
NEC for r=1.0 class 0 = 0.481 +- 0.281 (in-sample avg dev_std = 0.533)
NEC for r=1.0 class 1 = 0.508 +- 0.281 (in-sample avg dev_std = 0.533)
NEC for r=1.0 class 2 = 0.547 +- 0.281 (in-sample avg dev_std = 0.533)
NEC for r=1.0 all KL = 0.539 +- 0.281 (in-sample avg dev_std = 0.533)
NEC for r=1.0 all L1 = 0.513 +- 0.160 (in-sample avg dev_std = 0.533)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.466
Model XAI F1 of binarized graphs for r=0.3 =  0.86858875
Model XAI WIoU of binarized graphs for r=0.3 =  0.7829925
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.215
NEC for r=0.3 class 0 = 0.572 +- 0.290 (in-sample avg dev_std = 0.430)
NEC for r=0.3 class 1 = 0.618 +- 0.290 (in-sample avg dev_std = 0.430)
NEC for r=0.3 class 2 = 0.627 +- 0.290 (in-sample avg dev_std = 0.430)
NEC for r=0.3 all KL = 0.62 +- 0.290 (in-sample avg dev_std = 0.430)
NEC for r=0.3 all L1 = 0.605 +- 0.150 (in-sample avg dev_std = 0.430)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.934
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  0.9999750000000001
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.513
NEC for r=0.6 class 0 = 0.522 +- 0.239 (in-sample avg dev_std = 0.651)
NEC for r=0.6 class 1 = 0.543 +- 0.239 (in-sample avg dev_std = 0.651)
NEC for r=0.6 class 2 = 0.559 +- 0.239 (in-sample avg dev_std = 0.651)
NEC for r=0.6 all KL = 0.717 +- 0.239 (in-sample avg dev_std = 0.651)
NEC for r=0.6 all L1 = 0.541 +- 0.153 (in-sample avg dev_std = 0.651)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.934
Model XAI F1 of binarized graphs for r=0.9 =  0.61811125
Model XAI WIoU of binarized graphs for r=0.9 =  0.9999750000000001
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.653
NEC for r=0.9 class 0 = 0.38 +- 0.237 (in-sample avg dev_std = 0.624)
NEC for r=0.9 class 1 = 0.398 +- 0.237 (in-sample avg dev_std = 0.624)
NEC for r=0.9 class 2 = 0.434 +- 0.237 (in-sample avg dev_std = 0.624)
NEC for r=0.9 all KL = 0.461 +- 0.237 (in-sample avg dev_std = 0.624)
NEC for r=0.9 all L1 = 0.404 +- 0.150 (in-sample avg dev_std = 0.624)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.934
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  0.9999750000000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.654
NEC for r=1.0 class 0 = 0.379 +- 0.226 (in-sample avg dev_std = 0.625)
NEC for r=1.0 class 1 = 0.403 +- 0.226 (in-sample avg dev_std = 0.625)
NEC for r=1.0 class 2 = 0.431 +- 0.226 (in-sample avg dev_std = 0.625)
NEC for r=1.0 all KL = 0.457 +- 0.226 (in-sample avg dev_std = 0.625)
NEC for r=1.0 all L1 = 0.405 +- 0.143 (in-sample avg dev_std = 0.625)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.321
Model XAI F1 of binarized graphs for r=0.3 =  0.53952625
Model XAI WIoU of binarized graphs for r=0.3 =  0.41968249999999996
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.343
NEC for r=0.3 class 0 = 0.488 +- 0.246 (in-sample avg dev_std = 0.462)
NEC for r=0.3 class 1 = 0.517 +- 0.246 (in-sample avg dev_std = 0.462)
NEC for r=0.3 class 2 = 0.474 +- 0.246 (in-sample avg dev_std = 0.462)
NEC for r=0.3 all KL = 0.409 +- 0.246 (in-sample avg dev_std = 0.462)
NEC for r=0.3 all L1 = 0.492 +- 0.185 (in-sample avg dev_std = 0.462)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.739
Model XAI F1 of binarized graphs for r=0.6 =  0.6458625000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.50951875
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.528
NEC for r=0.6 class 0 = 0.535 +- 0.279 (in-sample avg dev_std = 0.590)
NEC for r=0.6 class 1 = 0.499 +- 0.279 (in-sample avg dev_std = 0.590)
NEC for r=0.6 class 2 = 0.623 +- 0.279 (in-sample avg dev_std = 0.590)
NEC for r=0.6 all KL = 0.599 +- 0.279 (in-sample avg dev_std = 0.590)
NEC for r=0.6 all L1 = 0.553 +- 0.145 (in-sample avg dev_std = 0.590)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.87
Model XAI F1 of binarized graphs for r=0.9 =  0.59204375
Model XAI WIoU of binarized graphs for r=0.9 =  0.49600875
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.625
NEC for r=0.9 class 0 = 0.448 +- 0.243 (in-sample avg dev_std = 0.566)
NEC for r=0.9 class 1 = 0.42 +- 0.243 (in-sample avg dev_std = 0.566)
NEC for r=0.9 class 2 = 0.523 +- 0.243 (in-sample avg dev_std = 0.566)
NEC for r=0.9 all KL = 0.496 +- 0.243 (in-sample avg dev_std = 0.566)
NEC for r=0.9 all L1 = 0.464 +- 0.148 (in-sample avg dev_std = 0.566)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.864
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.49549374999999996
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.642
NEC for r=1.0 class 0 = 0.445 +- 0.235 (in-sample avg dev_std = 0.569)
NEC for r=1.0 class 1 = 0.407 +- 0.235 (in-sample avg dev_std = 0.569)
NEC for r=1.0 class 2 = 0.504 +- 0.235 (in-sample avg dev_std = 0.569)
NEC for r=1.0 all KL = 0.482 +- 0.235 (in-sample avg dev_std = 0.569)
NEC for r=1.0 all L1 = 0.453 +- 0.142 (in-sample avg dev_std = 0.569)


Evaluating SUFF for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7164
torch.Size([7164, 3])
7164

Model Accuracy of binarized graphs for r=0.3 =  0.652
Model XAI F1 of binarized graphs for r=0.3 =  0.7277025
Model XAI WIoU of binarized graphs for r=0.3 =  0.70377375
len(reference) = 796
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.414
SUFF for r=0.3 class 0 = 0.45 +- 0.274 (in-sample avg dev_std = 0.565)
SUFF for r=0.3 class 1 = 0.504 +- 0.274 (in-sample avg dev_std = 0.565)
SUFF for r=0.3 class 2 = 0.36 +- 0.274 (in-sample avg dev_std = 0.565)
SUFF for r=0.3 all KL = 0.365 +- 0.274 (in-sample avg dev_std = 0.565)
SUFF for r=0.3 all L1 = 0.437 +- 0.150 (in-sample avg dev_std = 0.565)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.846
Model XAI F1 of binarized graphs for r=0.6 =  0.6144775
Model XAI WIoU of binarized graphs for r=0.6 =  0.80013
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.719
SUFF for r=0.6 class 0 = 0.564 +- 0.280 (in-sample avg dev_std = 0.401)
SUFF for r=0.6 class 1 = 0.735 +- 0.280 (in-sample avg dev_std = 0.401)
SUFF for r=0.6 class 2 = 0.666 +- 0.280 (in-sample avg dev_std = 0.401)
SUFF for r=0.6 all KL = 0.655 +- 0.280 (in-sample avg dev_std = 0.401)
SUFF for r=0.6 all L1 = 0.657 +- 0.225 (in-sample avg dev_std = 0.401)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.905
Model XAI F1 of binarized graphs for r=0.9 =  0.4757187500000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.79734375
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.855
SUFF for r=0.9 class 0 = 0.801 +- 0.188 (in-sample avg dev_std = 0.212)
SUFF for r=0.9 class 1 = 0.764 +- 0.188 (in-sample avg dev_std = 0.212)
SUFF for r=0.9 class 2 = 0.857 +- 0.188 (in-sample avg dev_std = 0.212)
SUFF for r=0.9 all KL = 0.875 +- 0.188 (in-sample avg dev_std = 0.212)
SUFF for r=0.9 all L1 = 0.808 +- 0.178 (in-sample avg dev_std = 0.212)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.466
Model XAI F1 of binarized graphs for r=0.3 =  0.86858875
Model XAI WIoU of binarized graphs for r=0.3 =  0.7829925
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.416
SUFF for r=0.3 class 0 = 0.481 +- 0.265 (in-sample avg dev_std = 0.535)
SUFF for r=0.3 class 1 = 0.551 +- 0.265 (in-sample avg dev_std = 0.535)
SUFF for r=0.3 class 2 = 0.39 +- 0.265 (in-sample avg dev_std = 0.535)
SUFF for r=0.3 all KL = 0.439 +- 0.265 (in-sample avg dev_std = 0.535)
SUFF for r=0.3 all L1 = 0.474 +- 0.147 (in-sample avg dev_std = 0.535)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.934
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  0.9999750000000001
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.851
SUFF for r=0.6 class 0 = 0.702 +- 0.320 (in-sample avg dev_std = 0.450)
SUFF for r=0.6 class 1 = 0.884 +- 0.320 (in-sample avg dev_std = 0.450)
SUFF for r=0.6 class 2 = 0.861 +- 0.320 (in-sample avg dev_std = 0.450)
SUFF for r=0.6 all KL = 0.739 +- 0.320 (in-sample avg dev_std = 0.450)
SUFF for r=0.6 all L1 = 0.815 +- 0.191 (in-sample avg dev_std = 0.450)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.934
Model XAI F1 of binarized graphs for r=0.9 =  0.61811125
Model XAI WIoU of binarized graphs for r=0.9 =  0.9999750000000001
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.935
SUFF for r=0.9 class 0 = 0.961 +- 0.026 (in-sample avg dev_std = 0.026)
SUFF for r=0.9 class 1 = 0.955 +- 0.026 (in-sample avg dev_std = 0.026)
SUFF for r=0.9 class 2 = 0.981 +- 0.026 (in-sample avg dev_std = 0.026)
SUFF for r=0.9 all KL = 0.994 +- 0.026 (in-sample avg dev_std = 0.026)
SUFF for r=0.9 all L1 = 0.965 +- 0.039 (in-sample avg dev_std = 0.026)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
7083
torch.Size([7083, 3])
7083

Model Accuracy of binarized graphs for r=0.3 =  0.324
Model XAI F1 of binarized graphs for r=0.3 =  0.53952625
Model XAI WIoU of binarized graphs for r=0.3 =  0.41968249999999996
len(reference) = 787
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.389
SUFF for r=0.3 class 0 = 0.496 +- 0.194 (in-sample avg dev_std = 0.510)
SUFF for r=0.3 class 1 = 0.536 +- 0.194 (in-sample avg dev_std = 0.510)
SUFF for r=0.3 class 2 = 0.484 +- 0.194 (in-sample avg dev_std = 0.510)
SUFF for r=0.3 all KL = 0.593 +- 0.194 (in-sample avg dev_std = 0.510)
SUFF for r=0.3 all L1 = 0.505 +- 0.129 (in-sample avg dev_std = 0.510)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.738
Model XAI F1 of binarized graphs for r=0.6 =  0.6458625000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.50951875
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.629
SUFF for r=0.6 class 0 = 0.59 +- 0.228 (in-sample avg dev_std = 0.370)
SUFF for r=0.6 class 1 = 0.784 +- 0.228 (in-sample avg dev_std = 0.370)
SUFF for r=0.6 class 2 = 0.729 +- 0.228 (in-sample avg dev_std = 0.370)
SUFF for r=0.6 all KL = 0.74 +- 0.228 (in-sample avg dev_std = 0.370)
SUFF for r=0.6 all L1 = 0.7 +- 0.195 (in-sample avg dev_std = 0.370)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.87
Model XAI F1 of binarized graphs for r=0.9 =  0.59204375
Model XAI WIoU of binarized graphs for r=0.9 =  0.49600875
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.754
SUFF for r=0.9 class 0 = 0.712 +- 0.180 (in-sample avg dev_std = 0.248)
SUFF for r=0.9 class 1 = 0.9 +- 0.180 (in-sample avg dev_std = 0.248)
SUFF for r=0.9 class 2 = 0.736 +- 0.180 (in-sample avg dev_std = 0.248)
SUFF for r=0.9 all KL = 0.852 +- 0.180 (in-sample avg dev_std = 0.248)
SUFF for r=0.9 all L1 = 0.781 +- 0.192 (in-sample avg dev_std = 0.248)


ratio=1.0



Zero intervened samples, skipping weight=1.0


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
nec = [defaultdict(<class 'list'>, {'all_KL': [0.611, 0.568, 0.526, 0.521], 'all_L1': [0.563, 0.536, 0.501, 0.498]}), defaultdict(<class 'list'>, {'all_KL': [0.599, 0.555, 0.509, 0.483], 'all_L1': [0.563, 0.551, 0.51, 0.489]}), defaultdict(<class 'list'>, {'all_KL': [0.662, 0.614, 0.557, 0.556], 'all_L1': [0.592, 0.563, 0.522, 0.519]}), defaultdict(<class 'list'>, {'all_KL': [0.683, 0.58, 0.516, 0.51], 'all_L1': [0.592, 0.553, 0.498, 0.494]}), defaultdict(<class 'list'>, {'all_KL': [0.672, 0.625, 0.551, 0.539], 'all_L1': [0.609, 0.575, 0.523, 0.513]})]
suff = [defaultdict(<class 'list'>, {'all_KL': [0.453, 0.629, 0.869, 1.0], 'all_L1': [0.508, 0.633, 0.808, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.445, 0.705, 0.881, 1.0], 'all_L1': [0.485, 0.665, 0.796, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.424, 0.608, 0.87, 1.0], 'all_L1': [0.496, 0.633, 0.804, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.421, 0.728, 0.881, 1.0], 'all_L1': [0.516, 0.707, 0.821, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.365, 0.655, 0.875, 1.0], 'all_L1': [0.437, 0.657, 0.808, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]

Eval split val
nec = [defaultdict(<class 'list'>, {'all_KL': [0.67, 0.455, 0.33, 0.319], 'all_L1': [0.533, 0.378, 0.311, 0.305]}), defaultdict(<class 'list'>, {'all_KL': [0.642, 0.534, 0.363, 0.353], 'all_L1': [0.551, 0.442, 0.348, 0.34]}), defaultdict(<class 'list'>, {'all_KL': [0.725, 0.556, 0.415, 0.41], 'all_L1': [0.59, 0.436, 0.372, 0.364]}), defaultdict(<class 'list'>, {'all_KL': [0.743, 0.556, 0.415, 0.398], 'all_L1': [0.609, 0.451, 0.377, 0.358]}), defaultdict(<class 'list'>, {'all_KL': [0.62, 0.717, 0.461, 0.457], 'all_L1': [0.605, 0.541, 0.404, 0.405]})]
suff = [defaultdict(<class 'list'>, {'all_KL': [0.411, 0.715, 0.966, 1.0], 'all_L1': [0.545, 0.741, 0.923, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.428, 0.855, 0.974, 1.0], 'all_L1': [0.54, 0.838, 0.905, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.456, 0.787, 0.889, 1.0], 'all_L1': [0.574, 0.802, 0.845, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.393, 0.704, 0.803, 1.0], 'all_L1': [0.539, 0.752, 0.805, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.439, 0.739, 0.994, 1.0], 'all_L1': [0.474, 0.815, 0.965, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]

Eval split test
nec = [defaultdict(<class 'list'>, {'all_KL': [0.166, 0.416, 0.436, 0.391], 'all_L1': [0.289, 0.456, 0.414, 0.392]}), defaultdict(<class 'list'>, {'all_KL': [0.369, 0.471, 0.342, 0.305], 'all_L1': [0.357, 0.48, 0.377, 0.357]}), defaultdict(<class 'list'>, {'all_KL': [0.475, 0.554, 0.438, 0.419], 'all_L1': [0.53, 0.492, 0.425, 0.409]}), defaultdict(<class 'list'>, {'all_KL': [0.548, 0.515, 0.387, 0.379], 'all_L1': [0.516, 0.467, 0.387, 0.383]}), defaultdict(<class 'list'>, {'all_KL': [0.409, 0.599, 0.496, 0.482], 'all_L1': [0.492, 0.553, 0.464, 0.453]})]
suff = [defaultdict(<class 'list'>, {'all_KL': [0.668, 0.631, 0.877, 1.0], 'all_L1': [0.542, 0.566, 0.794, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.269, 0.738, 0.934, 1.0], 'all_L1': [0.373, 0.672, 0.855, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.587, 0.723, 0.906, 1.0], 'all_L1': [0.512, 0.716, 0.825, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.435, 0.689, 0.878, 1.0], 'all_L1': [0.471, 0.683, 0.802, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.593, 0.74, 0.852, 1.0], 'all_L1': [0.505, 0.7, 0.781, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
nec class all_KL  =  0.645 +- 0.034, 0.588 +- 0.027, 0.532 +- 0.019, 0.522 +- 0.025
nec class all_L1  =  0.584 +- 0.018, 0.556 +- 0.013, 0.511 +- 0.010, 0.503 +- 0.011
nec_acc_int  =  0.373 +- 0.023, 0.469 +- 0.013, 0.544 +- 0.015, 0.551 +- 0.012
suff class all_KL  =  0.422 +- 0.031, 0.665 +- 0.045, 0.875 +- 0.005, 1.000 +- 0.000
suff class all_L1  =  0.488 +- 0.028, 0.659 +- 0.027, 0.807 +- 0.008, 1.000 +- 0.000
suff class 0  =  1.000 +- 0.000
suff class 1  =  1.000 +- 0.000
suff class 2  =  1.000 +- 0.000
suff_acc_int  =  0.459 +- 0.027, 0.725 +- 0.033, 0.849 +- 0.018

Eval split val
nec class all_KL  =  0.680 +- 0.047, 0.564 +- 0.085, 0.397 +- 0.046, 0.387 +- 0.048
nec class all_L1  =  0.578 +- 0.030, 0.450 +- 0.052, 0.362 +- 0.031, 0.354 +- 0.033
nec_acc_int  =  0.270 +- 0.086, 0.571 +- 0.044, 0.652 +- 0.027, 0.657 +- 0.025
suff class all_KL  =  0.425 +- 0.022, 0.760 +- 0.055, 0.925 +- 0.071, 1.000 +- 0.000
suff class all_L1  =  0.534 +- 0.033, 0.790 +- 0.037, 0.889 +- 0.057, 1.000 +- 0.000
suff class 0  =  1.000 +- 0.000
suff class 1  =  1.000 +- 0.000
suff class 2  =  1.000 +- 0.000
suff_acc_int  =  0.485 +- 0.036, 0.856 +- 0.031, 0.892 +- 0.043

Eval split test
nec class all_KL  =  0.393 +- 0.129, 0.511 +- 0.064, 0.420 +- 0.052, 0.395 +- 0.057
nec class all_L1  =  0.437 +- 0.096, 0.490 +- 0.034, 0.413 +- 0.031, 0.399 +- 0.032
nec_acc_int  =  0.360 +- 0.013, 0.502 +- 0.020, 0.605 +- 0.015, 0.615 +- 0.027
suff class all_KL  =  0.510 +- 0.142, 0.704 +- 0.041, 0.889 +- 0.028, 1.000 +- 0.000
suff class all_L1  =  0.481 +- 0.058, 0.667 +- 0.053, 0.811 +- 0.026, 1.000 +- 0.000
suff class 0  =  1.000 +- 0.000
suff class 1  =  1.000 +- 0.000
suff class 2  =  1.000 +- 0.000
suff_acc_int  =  0.353 +- 0.023, 0.551 +- 0.074, 0.706 +- 0.037


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
torch.Size([5, 4]) torch.Size([5, 4])
torch.Size([5, 4])
Faith. Aritm= 		  =  0.536 +- 0.012, 0.607 +- 0.015, 0.659 +- 0.005, 0.751 +- 0.006
Faith. Armon= 		  =  0.531 +- 0.015, 0.603 +- 0.014, 0.626 +- 0.007, 0.669 +- 0.010
Faith. GMean = 	  =  0.534 +- 0.013, 0.605 +- 0.015, 0.642 +- 0.006, 0.709 +- 0.008

Eval split val
torch.Size([5, 4]) torch.Size([5, 4])
torch.Size([5, 4])
Faith. Aritm= 		  =  0.556 +- 0.018, 0.620 +- 0.039, 0.626 +- 0.032, 0.677 +- 0.016
Faith. Armon= 		  =  0.554 +- 0.020, 0.572 +- 0.048, 0.514 +- 0.033, 0.522 +- 0.036
Faith. GMean = 	  =  0.555 +- 0.019, 0.595 +- 0.043, 0.567 +- 0.030, 0.595 +- 0.027

Eval split test
torch.Size([5, 4]) torch.Size([5, 4])
torch.Size([5, 4])
Faith. Aritm= 		  =  0.459 +- 0.059, 0.578 +- 0.039, 0.612 +- 0.012, 0.699 +- 0.016
Faith. Armon= 		  =  0.451 +- 0.066, 0.564 +- 0.037, 0.547 +- 0.023, 0.569 +- 0.032
Faith. GMean = 	  =  0.455 +- 0.062, 0.571 +- 0.038, 0.578 +- 0.016, 0.631 +- 0.025
Computed for split load_split = id



Completed in  0:19:54.134953  for LECIGIN GOODMotif/basis



DONE LECI GOODMotif/basis

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Mar 20 14:14:17 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/20/2024 02:14:17 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/20/2024 02:14:29 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/20/2024 02:14:31 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/20/2024 02:14:33 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/20/2024 02:14:35 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/20/2024 02:14:37 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/20/2024 02:14:37 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/20/2024 02:14:37 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/20/2024 02:14:37 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/20/2024 02:14:37 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:14:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:14:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:14:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:14:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:14:37 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/20/2024 02:14:37 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:14:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:14:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:14:37 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/20/2024 02:14:37 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 32...
[0m[1;37mINFO[0m: [1mCheckpoint 32: 
-----------------------------------
Train ACCURACY: 0.8933
Train Loss: 0.4689
ID Validation ACCURACY: 0.8867
ID Validation Loss: 0.4937
ID Test ACCURACY: 0.9010
ID Test Loss: 0.4439
OOD Validation ACCURACY: 0.6550
OOD Validation Loss: 1.5131
OOD Test ACCURACY: 0.3787
OOD Test Loss: 2.5757

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 3...
[0m[1;37mINFO[0m: [1mCheckpoint 3: 
-----------------------------------
Train ACCURACY: 0.5774
Train Loss: 1.3209
ID Validation ACCURACY: 0.5740
ID Validation Loss: 1.3483
ID Test ACCURACY: 0.5860
ID Test Loss: 1.2983
OOD Validation ACCURACY: 0.9227
OOD Validation Loss: 0.4906
OOD Test ACCURACY: 0.3487
OOD Test Loss: 9.0129

[0m[1;37mINFO[0m: [1mChartInfo 0.9010 0.3787 0.5860 0.3487 0.5740 0.9227[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.6 = 0.551
WIoU for r=0.6 = 0.675
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.6 = 0.795
WIoU for r=0.6 = 0.996
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.6 = 0.446
WIoU for r=0.6 = 0.351
Size bank for r=0.6 -> 1500


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.887
Model XAI F1 of binarized graphs for r=0.6 =  0.55145875
Model XAI WIoU of binarized graphs for r=0.6 =  0.67477125
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.442
NEC for r=0.6 class 0 = 0.595 +- 0.254 (in-sample avg dev_std = 0.634)
NEC for r=0.6 class 1 = 0.552 +- 0.254 (in-sample avg dev_std = 0.634)
NEC for r=0.6 class 2 = 0.653 +- 0.254 (in-sample avg dev_std = 0.634)
NEC for r=0.6 all KL = 0.671 +- 0.254 (in-sample avg dev_std = 0.634)
NEC for r=0.6 all L1 = 0.601 +- 0.154 (in-sample avg dev_std = 0.634)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.654
Model XAI F1 of binarized graphs for r=0.6 =  0.7952750000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.9961325
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.409
NEC for r=0.6 class 0 = 0.375 +- 0.326 (in-sample avg dev_std = 0.562)
NEC for r=0.6 class 1 = 0.269 +- 0.326 (in-sample avg dev_std = 0.562)
NEC for r=0.6 class 2 = 0.541 +- 0.326 (in-sample avg dev_std = 0.562)
NEC for r=0.6 all KL = 0.464 +- 0.326 (in-sample avg dev_std = 0.562)
NEC for r=0.6 all L1 = 0.396 +- 0.219 (in-sample avg dev_std = 0.562)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.377
Model XAI F1 of binarized graphs for r=0.6 =  0.44623874999999996
Model XAI WIoU of binarized graphs for r=0.6 =  0.35069249999999996
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.422
NEC for r=0.6 class 0 = 0.311 +- 0.280 (in-sample avg dev_std = 0.429)
NEC for r=0.6 class 1 = 0.143 +- 0.280 (in-sample avg dev_std = 0.429)
NEC for r=0.6 class 2 = 0.355 +- 0.280 (in-sample avg dev_std = 0.429)
NEC for r=0.6 all KL = 0.32 +- 0.280 (in-sample avg dev_std = 0.429)
NEC for r=0.6 all L1 = 0.272 +- 0.216 (in-sample avg dev_std = 0.429)


Evaluating SUFF for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.887
Model XAI F1 of binarized graphs for r=0.6 =  0.55145875
Model XAI WIoU of binarized graphs for r=0.6 =  0.67477125
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.579
SUFF for r=0.6 class 0 = 0.37 +- 0.293 (in-sample avg dev_std = 0.514)
SUFF for r=0.6 class 1 = 0.505 +- 0.293 (in-sample avg dev_std = 0.514)
SUFF for r=0.6 class 2 = 0.588 +- 0.293 (in-sample avg dev_std = 0.514)
SUFF for r=0.6 all KL = 0.436 +- 0.293 (in-sample avg dev_std = 0.514)
SUFF for r=0.6 all L1 = 0.49 +- 0.220 (in-sample avg dev_std = 0.514)



--------------------------------------------------


#D#Computing SUFF over val across ratios (random_expl=False)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.654
Model XAI F1 of binarized graphs for r=0.6 =  0.7952750000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.9961325
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.606
SUFF for r=0.6 class 0 = 0.533 +- 0.293 (in-sample avg dev_std = 0.620)
SUFF for r=0.6 class 1 = 0.337 +- 0.293 (in-sample avg dev_std = 0.620)
SUFF for r=0.6 class 2 = 0.452 +- 0.293 (in-sample avg dev_std = 0.620)
SUFF for r=0.6 all KL = 0.239 +- 0.293 (in-sample avg dev_std = 0.620)
SUFF for r=0.6 all L1 = 0.441 +- 0.222 (in-sample avg dev_std = 0.620)



--------------------------------------------------


#D#Computing SUFF over test across ratios (random_expl=False)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.377
Model XAI F1 of binarized graphs for r=0.6 =  0.44623874999999996
Model XAI WIoU of binarized graphs for r=0.6 =  0.35069249999999996
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.392
SUFF for r=0.6 class 0 = 0.675 +- 0.284 (in-sample avg dev_std = 0.593)
SUFF for r=0.6 class 1 = 0.746 +- 0.284 (in-sample avg dev_std = 0.593)
SUFF for r=0.6 class 2 = 0.601 +- 0.284 (in-sample avg dev_std = 0.593)
SUFF for r=0.6 all KL = 0.515 +- 0.284 (in-sample avg dev_std = 0.593)
SUFF for r=0.6 all L1 = 0.672 +- 0.200 (in-sample avg dev_std = 0.593)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Mar 20 14:15:49 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/20/2024 02:15:49 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/20/2024 02:16:01 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/20/2024 02:16:03 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/20/2024 02:16:05 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/20/2024 02:16:07 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/20/2024 02:16:09 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/20/2024 02:16:09 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/20/2024 02:16:09 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/20/2024 02:16:09 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/20/2024 02:16:09 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:16:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:16:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:16:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:16:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:16:09 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/20/2024 02:16:09 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:16:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:16:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:16:09 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/20/2024 02:16:09 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 86...
[0m[1;37mINFO[0m: [1mCheckpoint 86: 
-----------------------------------
Train ACCURACY: 0.8799
Train Loss: 0.4851
ID Validation ACCURACY: 0.8757
ID Validation Loss: 0.5174
ID Test ACCURACY: 0.8873
ID Test Loss: 0.4680
OOD Validation ACCURACY: 0.6670
OOD Validation Loss: 0.9447
OOD Test ACCURACY: 0.4367
OOD Test Loss: 3.0736

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 58...
[0m[1;37mINFO[0m: [1mCheckpoint 58: 
-----------------------------------
Train ACCURACY: 0.8507
Train Loss: 0.4884
ID Validation ACCURACY: 0.8450
ID Validation Loss: 0.5152
ID Test ACCURACY: 0.8610
ID Test Loss: 0.4707
OOD Validation ACCURACY: 0.9313
OOD Validation Loss: 0.4447
OOD Test ACCURACY: 0.3857
OOD Test Loss: 4.2847

[0m[1;37mINFO[0m: [1mChartInfo 0.8873 0.4367 0.8610 0.3857 0.8450 0.9313[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.6 = 0.583
WIoU for r=0.6 = 0.685
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.6 = 0.798
WIoU for r=0.6 = 1.000
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.6 = 0.504
WIoU for r=0.6 = 0.393
Size bank for r=0.6 -> 1500


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.877
Model XAI F1 of binarized graphs for r=0.6 =  0.58283125
Model XAI WIoU of binarized graphs for r=0.6 =  0.68527375
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.462
NEC for r=0.6 class 0 = 0.575 +- 0.267 (in-sample avg dev_std = 0.656)
NEC for r=0.6 class 1 = 0.544 +- 0.267 (in-sample avg dev_std = 0.656)
NEC for r=0.6 class 2 = 0.657 +- 0.267 (in-sample avg dev_std = 0.656)
NEC for r=0.6 all KL = 0.707 +- 0.267 (in-sample avg dev_std = 0.656)
NEC for r=0.6 all L1 = 0.593 +- 0.173 (in-sample avg dev_std = 0.656)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.665
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.494
NEC for r=0.6 class 0 = 0.345 +- 0.323 (in-sample avg dev_std = 0.542)
NEC for r=0.6 class 1 = 0.382 +- 0.323 (in-sample avg dev_std = 0.542)
NEC for r=0.6 class 2 = 0.512 +- 0.323 (in-sample avg dev_std = 0.542)
NEC for r=0.6 all KL = 0.487 +- 0.323 (in-sample avg dev_std = 0.542)
NEC for r=0.6 all L1 = 0.413 +- 0.229 (in-sample avg dev_std = 0.542)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.449
Model XAI F1 of binarized graphs for r=0.6 =  0.5036999999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.39258249999999995
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.447
NEC for r=0.6 class 0 = 0.352 +- 0.335 (in-sample avg dev_std = 0.463)
NEC for r=0.6 class 1 = 0.092 +- 0.335 (in-sample avg dev_std = 0.463)
NEC for r=0.6 class 2 = 0.422 +- 0.335 (in-sample avg dev_std = 0.463)
NEC for r=0.6 all KL = 0.374 +- 0.335 (in-sample avg dev_std = 0.463)
NEC for r=0.6 all L1 = 0.292 +- 0.269 (in-sample avg dev_std = 0.463)


Evaluating SUFF for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.877
Model XAI F1 of binarized graphs for r=0.6 =  0.58283125
Model XAI WIoU of binarized graphs for r=0.6 =  0.68527375
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.604
SUFF for r=0.6 class 0 = 0.405 +- 0.324 (in-sample avg dev_std = 0.486)
SUFF for r=0.6 class 1 = 0.605 +- 0.324 (in-sample avg dev_std = 0.486)
SUFF for r=0.6 class 2 = 0.544 +- 0.324 (in-sample avg dev_std = 0.486)
SUFF for r=0.6 all KL = 0.429 +- 0.324 (in-sample avg dev_std = 0.486)
SUFF for r=0.6 all L1 = 0.52 +- 0.250 (in-sample avg dev_std = 0.486)



--------------------------------------------------


#D#Computing SUFF over val across ratios (random_expl=False)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.665
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.668
SUFF for r=0.6 class 0 = 0.568 +- 0.325 (in-sample avg dev_std = 0.526)
SUFF for r=0.6 class 1 = 0.42 +- 0.325 (in-sample avg dev_std = 0.526)
SUFF for r=0.6 class 2 = 0.377 +- 0.325 (in-sample avg dev_std = 0.526)
SUFF for r=0.6 all KL = 0.305 +- 0.325 (in-sample avg dev_std = 0.526)
SUFF for r=0.6 all L1 = 0.455 +- 0.255 (in-sample avg dev_std = 0.526)



--------------------------------------------------


#D#Computing SUFF over test across ratios (random_expl=False)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.449
Model XAI F1 of binarized graphs for r=0.6 =  0.5036999999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.39258249999999995
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.344
SUFF for r=0.6 class 0 = 0.728 +- 0.344 (in-sample avg dev_std = 0.437)
SUFF for r=0.6 class 1 = 0.791 +- 0.344 (in-sample avg dev_std = 0.437)
SUFF for r=0.6 class 2 = 0.74 +- 0.344 (in-sample avg dev_std = 0.437)
SUFF for r=0.6 all KL = 0.643 +- 0.344 (in-sample avg dev_std = 0.437)
SUFF for r=0.6 all L1 = 0.752 +- 0.252 (in-sample avg dev_std = 0.437)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Mar 20 14:17:13 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/20/2024 02:17:13 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/20/2024 02:17:25 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/20/2024 02:17:27 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/20/2024 02:17:29 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/20/2024 02:17:31 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/20/2024 02:17:33 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/20/2024 02:17:33 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/20/2024 02:17:33 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/20/2024 02:17:33 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/20/2024 02:17:33 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:17:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:17:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:17:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:17:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:17:33 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/20/2024 02:17:33 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:17:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:17:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:17:33 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/20/2024 02:17:33 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 90...
[0m[1;37mINFO[0m: [1mCheckpoint 90: 
-----------------------------------
Train ACCURACY: 0.9108
Train Loss: 0.4126
ID Validation ACCURACY: 0.9080
ID Validation Loss: 0.4411
ID Test ACCURACY: 0.9153
ID Test Loss: 0.4096
OOD Validation ACCURACY: 0.9047
OOD Validation Loss: 0.4491
OOD Test ACCURACY: 0.4210
OOD Test Loss: 3.6186

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 42...
[0m[1;37mINFO[0m: [1mCheckpoint 42: 
-----------------------------------
Train ACCURACY: 0.8849
Train Loss: 0.5208
ID Validation ACCURACY: 0.8813
ID Validation Loss: 0.5566
ID Test ACCURACY: 0.8920
ID Test Loss: 0.5012
OOD Validation ACCURACY: 0.9313
OOD Validation Loss: 0.4367
OOD Test ACCURACY: 0.3817
OOD Test Loss: 5.1552

[0m[1;37mINFO[0m: [1mChartInfo 0.9153 0.4210 0.8920 0.3817 0.8813 0.9313[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.6 = 0.564
WIoU for r=0.6 = 0.647
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.6 = 0.795
WIoU for r=0.6 = 0.992
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.6 = 0.459
WIoU for r=0.6 = 0.355
Size bank for r=0.6 -> 1500


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.906
Model XAI F1 of binarized graphs for r=0.6 =  0.5639974999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.64702125
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.447
NEC for r=0.6 class 0 = 0.625 +- 0.259 (in-sample avg dev_std = 0.647)
NEC for r=0.6 class 1 = 0.538 +- 0.259 (in-sample avg dev_std = 0.647)
NEC for r=0.6 class 2 = 0.636 +- 0.259 (in-sample avg dev_std = 0.647)
NEC for r=0.6 all KL = 0.703 +- 0.259 (in-sample avg dev_std = 0.647)
NEC for r=0.6 all L1 = 0.6 +- 0.165 (in-sample avg dev_std = 0.647)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.902
Model XAI F1 of binarized graphs for r=0.6 =  0.79503625
Model XAI WIoU of binarized graphs for r=0.6 =  0.99223875
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.534
NEC for r=0.6 class 0 = 0.505 +- 0.289 (in-sample avg dev_std = 0.654)
NEC for r=0.6 class 1 = 0.415 +- 0.289 (in-sample avg dev_std = 0.654)
NEC for r=0.6 class 2 = 0.579 +- 0.289 (in-sample avg dev_std = 0.654)
NEC for r=0.6 all KL = 0.578 +- 0.289 (in-sample avg dev_std = 0.654)
NEC for r=0.6 all L1 = 0.5 +- 0.177 (in-sample avg dev_std = 0.654)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.429
Model XAI F1 of binarized graphs for r=0.6 =  0.45881875
Model XAI WIoU of binarized graphs for r=0.6 =  0.35518249999999996
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.43
NEC for r=0.6 class 0 = 0.336 +- 0.329 (in-sample avg dev_std = 0.443)
NEC for r=0.6 class 1 = 0.095 +- 0.329 (in-sample avg dev_std = 0.443)
NEC for r=0.6 class 2 = 0.369 +- 0.329 (in-sample avg dev_std = 0.443)
NEC for r=0.6 all KL = 0.356 +- 0.329 (in-sample avg dev_std = 0.443)
NEC for r=0.6 all L1 = 0.27 +- 0.268 (in-sample avg dev_std = 0.443)


Evaluating SUFF for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.906
Model XAI F1 of binarized graphs for r=0.6 =  0.5639974999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.64702125
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.587
SUFF for r=0.6 class 0 = 0.347 +- 0.321 (in-sample avg dev_std = 0.496)
SUFF for r=0.6 class 1 = 0.535 +- 0.321 (in-sample avg dev_std = 0.496)
SUFF for r=0.6 class 2 = 0.687 +- 0.321 (in-sample avg dev_std = 0.496)
SUFF for r=0.6 all KL = 0.437 +- 0.321 (in-sample avg dev_std = 0.496)
SUFF for r=0.6 all L1 = 0.527 +- 0.268 (in-sample avg dev_std = 0.496)



--------------------------------------------------


#D#Computing SUFF over val across ratios (random_expl=False)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.902
Model XAI F1 of binarized graphs for r=0.6 =  0.79503625
Model XAI WIoU of binarized graphs for r=0.6 =  0.99223875
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.67
SUFF for r=0.6 class 0 = 0.537 +- 0.351 (in-sample avg dev_std = 0.545)
SUFF for r=0.6 class 1 = 0.642 +- 0.351 (in-sample avg dev_std = 0.545)
SUFF for r=0.6 class 2 = 0.495 +- 0.351 (in-sample avg dev_std = 0.545)
SUFF for r=0.6 all KL = 0.49 +- 0.351 (in-sample avg dev_std = 0.545)
SUFF for r=0.6 all L1 = 0.558 +- 0.232 (in-sample avg dev_std = 0.545)



--------------------------------------------------


#D#Computing SUFF over test across ratios (random_expl=False)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.429
Model XAI F1 of binarized graphs for r=0.6 =  0.45881875
Model XAI WIoU of binarized graphs for r=0.6 =  0.35518249999999996
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.338
SUFF for r=0.6 class 0 = 0.65 +- 0.341 (in-sample avg dev_std = 0.618)
SUFF for r=0.6 class 1 = 0.706 +- 0.341 (in-sample avg dev_std = 0.618)
SUFF for r=0.6 class 2 = 0.682 +- 0.341 (in-sample avg dev_std = 0.618)
SUFF for r=0.6 all KL = 0.434 +- 0.341 (in-sample avg dev_std = 0.618)
SUFF for r=0.6 all L1 = 0.679 +- 0.236 (in-sample avg dev_std = 0.618)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Mar 20 14:18:46 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/20/2024 02:18:46 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/20/2024 02:18:58 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/20/2024 02:19:00 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/20/2024 02:19:02 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/20/2024 02:19:04 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/20/2024 02:19:06 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/20/2024 02:19:06 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/20/2024 02:19:06 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/20/2024 02:19:06 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/20/2024 02:19:06 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:19:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:19:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:19:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:19:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:19:06 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/20/2024 02:19:06 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:19:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:19:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:19:06 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/20/2024 02:19:06 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 72...
[0m[1;37mINFO[0m: [1mCheckpoint 72: 
-----------------------------------
Train ACCURACY: 0.8929
Train Loss: 0.4784
ID Validation ACCURACY: 0.8877
ID Validation Loss: 0.5235
ID Test ACCURACY: 0.9007
ID Test Loss: 0.4658
OOD Validation ACCURACY: 0.8657
OOD Validation Loss: 0.4939
OOD Test ACCURACY: 0.4123
OOD Test Loss: 4.0821

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 0...
[0m[1;37mINFO[0m: [1mCheckpoint 0: 
-----------------------------------
Train ACCURACY: 0.4968
Train Loss: 1.1639
ID Validation ACCURACY: 0.4947
ID Validation Loss: 1.2213
ID Test ACCURACY: 0.4953
ID Test Loss: 1.1575
OOD Validation ACCURACY: 0.9307
OOD Validation Loss: 0.4981
OOD Test ACCURACY: 0.3283
OOD Test Loss: 9.9458

[0m[1;37mINFO[0m: [1mChartInfo 0.9007 0.4123 0.4953 0.3283 0.4947 0.9307[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.6 = 0.581
WIoU for r=0.6 = 0.696
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.6 = 0.798
WIoU for r=0.6 = 1.000
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.6 = 0.471
WIoU for r=0.6 = 0.358
Size bank for r=0.6 -> 1500


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.887
Model XAI F1 of binarized graphs for r=0.6 =  0.58113
Model XAI WIoU of binarized graphs for r=0.6 =  0.69626375
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.405
NEC for r=0.6 class 0 = 0.671 +- 0.233 (in-sample avg dev_std = 0.695)
NEC for r=0.6 class 1 = 0.586 +- 0.233 (in-sample avg dev_std = 0.695)
NEC for r=0.6 class 2 = 0.675 +- 0.233 (in-sample avg dev_std = 0.695)
NEC for r=0.6 all KL = 0.809 +- 0.233 (in-sample avg dev_std = 0.695)
NEC for r=0.6 all L1 = 0.644 +- 0.159 (in-sample avg dev_std = 0.695)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.868
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  0.9999875
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.505
NEC for r=0.6 class 0 = 0.598 +- 0.279 (in-sample avg dev_std = 0.774)
NEC for r=0.6 class 1 = 0.477 +- 0.279 (in-sample avg dev_std = 0.774)
NEC for r=0.6 class 2 = 0.561 +- 0.279 (in-sample avg dev_std = 0.774)
NEC for r=0.6 all KL = 0.704 +- 0.279 (in-sample avg dev_std = 0.774)
NEC for r=0.6 all L1 = 0.546 +- 0.181 (in-sample avg dev_std = 0.774)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.416
Model XAI F1 of binarized graphs for r=0.6 =  0.47148125
Model XAI WIoU of binarized graphs for r=0.6 =  0.35751999999999995
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.453
NEC for r=0.6 class 0 = 0.349 +- 0.343 (in-sample avg dev_std = 0.465)
NEC for r=0.6 class 1 = 0.083 +- 0.343 (in-sample avg dev_std = 0.465)
NEC for r=0.6 class 2 = 0.399 +- 0.343 (in-sample avg dev_std = 0.465)
NEC for r=0.6 all KL = 0.39 +- 0.343 (in-sample avg dev_std = 0.465)
NEC for r=0.6 all L1 = 0.28 +- 0.268 (in-sample avg dev_std = 0.465)


Evaluating SUFF for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.887
Model XAI F1 of binarized graphs for r=0.6 =  0.58113
Model XAI WIoU of binarized graphs for r=0.6 =  0.69626375
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.6
SUFF for r=0.6 class 0 = 0.328 +- 0.355 (in-sample avg dev_std = 0.465)
SUFF for r=0.6 class 1 = 0.657 +- 0.355 (in-sample avg dev_std = 0.465)
SUFF for r=0.6 class 2 = 0.65 +- 0.355 (in-sample avg dev_std = 0.465)
SUFF for r=0.6 all KL = 0.437 +- 0.355 (in-sample avg dev_std = 0.465)
SUFF for r=0.6 all L1 = 0.55 +- 0.295 (in-sample avg dev_std = 0.465)



--------------------------------------------------


#D#Computing SUFF over val across ratios (random_expl=False)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.868
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  0.9999875
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.704
SUFF for r=0.6 class 0 = 0.531 +- 0.382 (in-sample avg dev_std = 0.540)
SUFF for r=0.6 class 1 = 0.66 +- 0.382 (in-sample avg dev_std = 0.540)
SUFF for r=0.6 class 2 = 0.508 +- 0.382 (in-sample avg dev_std = 0.540)
SUFF for r=0.6 all KL = 0.449 +- 0.382 (in-sample avg dev_std = 0.540)
SUFF for r=0.6 all L1 = 0.566 +- 0.286 (in-sample avg dev_std = 0.540)



--------------------------------------------------


#D#Computing SUFF over test across ratios (random_expl=False)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.416
Model XAI F1 of binarized graphs for r=0.6 =  0.47148125
Model XAI WIoU of binarized graphs for r=0.6 =  0.35751999999999995
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.348
SUFF for r=0.6 class 0 = 0.739 +- 0.355 (in-sample avg dev_std = 0.499)
SUFF for r=0.6 class 1 = 0.773 +- 0.355 (in-sample avg dev_std = 0.499)
SUFF for r=0.6 class 2 = 0.734 +- 0.355 (in-sample avg dev_std = 0.499)
SUFF for r=0.6 all KL = 0.615 +- 0.355 (in-sample avg dev_std = 0.499)
SUFF for r=0.6 all L1 = 0.748 +- 0.249 (in-sample avg dev_std = 0.499)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Mar 20 14:20:10 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/20/2024 02:20:10 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/20/2024 02:20:22 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/20/2024 02:20:24 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/20/2024 02:20:26 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/20/2024 02:20:28 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/20/2024 02:20:30 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/20/2024 02:20:30 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/20/2024 02:20:30 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/20/2024 02:20:30 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/20/2024 02:20:30 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:20:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:20:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:20:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:20:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:20:30 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/20/2024 02:20:30 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:20:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:20:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:20:30 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/20/2024 02:20:30 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 16...
[0m[1;37mINFO[0m: [1mCheckpoint 16: 
-----------------------------------
Train ACCURACY: 0.8887
Train Loss: 0.4924
ID Validation ACCURACY: 0.8847
ID Validation Loss: 0.5324
ID Test ACCURACY: 0.8977
ID Test Loss: 0.4691
OOD Validation ACCURACY: 0.7167
OOD Validation Loss: 1.3877
OOD Test ACCURACY: 0.3873
OOD Test Loss: 3.5672

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 45...
[0m[1;37mINFO[0m: [1mCheckpoint 45: 
-----------------------------------
Train ACCURACY: 0.8089
Train Loss: 0.6907
ID Validation ACCURACY: 0.8030
ID Validation Loss: 0.7150
ID Test ACCURACY: 0.8183
ID Test Loss: 0.6665
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.4273
OOD Test ACCURACY: 0.4333
OOD Test Loss: 4.3285

[0m[1;37mINFO[0m: [1mChartInfo 0.8977 0.3873 0.8183 0.4333 0.8030 0.9317[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.6 = 0.584
WIoU for r=0.6 = 0.660
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.6 = 0.798
WIoU for r=0.6 = 1.000
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.6 = 0.503
WIoU for r=0.6 = 0.393
Size bank for r=0.6 -> 1500


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.887
Model XAI F1 of binarized graphs for r=0.6 =  0.5835112499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.6602475
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.417
NEC for r=0.6 class 0 = 0.64 +- 0.245 (in-sample avg dev_std = 0.692)
NEC for r=0.6 class 1 = 0.559 +- 0.245 (in-sample avg dev_std = 0.692)
NEC for r=0.6 class 2 = 0.669 +- 0.245 (in-sample avg dev_std = 0.692)
NEC for r=0.6 all KL = 0.754 +- 0.245 (in-sample avg dev_std = 0.692)
NEC for r=0.6 all L1 = 0.623 +- 0.168 (in-sample avg dev_std = 0.692)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.731
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  0.9997787500000002
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.422
NEC for r=0.6 class 0 = 0.457 +- 0.374 (in-sample avg dev_std = 0.693)
NEC for r=0.6 class 1 = 0.299 +- 0.374 (in-sample avg dev_std = 0.693)
NEC for r=0.6 class 2 = 0.581 +- 0.374 (in-sample avg dev_std = 0.693)
NEC for r=0.6 all KL = 0.594 +- 0.374 (in-sample avg dev_std = 0.693)
NEC for r=0.6 all L1 = 0.446 +- 0.256 (in-sample avg dev_std = 0.693)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.396
Model XAI F1 of binarized graphs for r=0.6 =  0.5030625
Model XAI WIoU of binarized graphs for r=0.6 =  0.39301375
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.445
NEC for r=0.6 class 0 = 0.254 +- 0.343 (in-sample avg dev_std = 0.480)
NEC for r=0.6 class 1 = 0.087 +- 0.343 (in-sample avg dev_std = 0.480)
NEC for r=0.6 class 2 = 0.453 +- 0.343 (in-sample avg dev_std = 0.480)
NEC for r=0.6 all KL = 0.361 +- 0.343 (in-sample avg dev_std = 0.480)
NEC for r=0.6 all L1 = 0.268 +- 0.269 (in-sample avg dev_std = 0.480)


Evaluating SUFF for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.887
Model XAI F1 of binarized graphs for r=0.6 =  0.5835112499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.6602475
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.589
SUFF for r=0.6 class 0 = 0.364 +- 0.340 (in-sample avg dev_std = 0.494)
SUFF for r=0.6 class 1 = 0.694 +- 0.340 (in-sample avg dev_std = 0.494)
SUFF for r=0.6 class 2 = 0.591 +- 0.340 (in-sample avg dev_std = 0.494)
SUFF for r=0.6 all KL = 0.462 +- 0.340 (in-sample avg dev_std = 0.494)
SUFF for r=0.6 all L1 = 0.553 +- 0.275 (in-sample avg dev_std = 0.494)



--------------------------------------------------


#D#Computing SUFF over val across ratios (random_expl=False)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.731
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  0.9997787500000002
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.687
SUFF for r=0.6 class 0 = 0.502 +- 0.358 (in-sample avg dev_std = 0.590)
SUFF for r=0.6 class 1 = 0.378 +- 0.358 (in-sample avg dev_std = 0.590)
SUFF for r=0.6 class 2 = 0.579 +- 0.358 (in-sample avg dev_std = 0.590)
SUFF for r=0.6 all KL = 0.28 +- 0.358 (in-sample avg dev_std = 0.590)
SUFF for r=0.6 all L1 = 0.487 +- 0.288 (in-sample avg dev_std = 0.590)



--------------------------------------------------


#D#Computing SUFF over test across ratios (random_expl=False)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.396
Model XAI F1 of binarized graphs for r=0.6 =  0.5030625
Model XAI WIoU of binarized graphs for r=0.6 =  0.39301375
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.385
SUFF for r=0.6 class 0 = 0.819 +- 0.301 (in-sample avg dev_std = 0.441)
SUFF for r=0.6 class 1 = 0.896 +- 0.301 (in-sample avg dev_std = 0.441)
SUFF for r=0.6 class 2 = 0.722 +- 0.301 (in-sample avg dev_std = 0.441)
SUFF for r=0.6 all KL = 0.686 +- 0.301 (in-sample avg dev_std = 0.441)
SUFF for r=0.6 all L1 = 0.811 +- 0.200 (in-sample avg dev_std = 0.441)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
nec = [defaultdict(<class 'list'>, {'all_KL': [0.671], 'all_L1': [0.601]}), defaultdict(<class 'list'>, {'all_KL': [0.707], 'all_L1': [0.593]}), defaultdict(<class 'list'>, {'all_KL': [0.703], 'all_L1': [0.6]}), defaultdict(<class 'list'>, {'all_KL': [0.809], 'all_L1': [0.644]}), defaultdict(<class 'list'>, {'all_KL': [0.754], 'all_L1': [0.623]})]
suff = [defaultdict(<class 'list'>, {'all_KL': [0.436], 'all_L1': [0.49]}), defaultdict(<class 'list'>, {'all_KL': [0.429], 'all_L1': [0.52]}), defaultdict(<class 'list'>, {'all_KL': [0.437], 'all_L1': [0.527]}), defaultdict(<class 'list'>, {'all_KL': [0.437], 'all_L1': [0.55]}), defaultdict(<class 'list'>, {'all_KL': [0.462], 'all_L1': [0.553]})]

Eval split val
nec = [defaultdict(<class 'list'>, {'all_KL': [0.464], 'all_L1': [0.396]}), defaultdict(<class 'list'>, {'all_KL': [0.487], 'all_L1': [0.413]}), defaultdict(<class 'list'>, {'all_KL': [0.578], 'all_L1': [0.5]}), defaultdict(<class 'list'>, {'all_KL': [0.704], 'all_L1': [0.546]}), defaultdict(<class 'list'>, {'all_KL': [0.594], 'all_L1': [0.446]})]
suff = [defaultdict(<class 'list'>, {'all_KL': [0.239], 'all_L1': [0.441]}), defaultdict(<class 'list'>, {'all_KL': [0.305], 'all_L1': [0.455]}), defaultdict(<class 'list'>, {'all_KL': [0.49], 'all_L1': [0.558]}), defaultdict(<class 'list'>, {'all_KL': [0.449], 'all_L1': [0.566]}), defaultdict(<class 'list'>, {'all_KL': [0.28], 'all_L1': [0.487]})]

Eval split test
nec = [defaultdict(<class 'list'>, {'all_KL': [0.32], 'all_L1': [0.272]}), defaultdict(<class 'list'>, {'all_KL': [0.374], 'all_L1': [0.292]}), defaultdict(<class 'list'>, {'all_KL': [0.356], 'all_L1': [0.27]}), defaultdict(<class 'list'>, {'all_KL': [0.39], 'all_L1': [0.28]}), defaultdict(<class 'list'>, {'all_KL': [0.361], 'all_L1': [0.268]})]
suff = [defaultdict(<class 'list'>, {'all_KL': [0.515], 'all_L1': [0.672]}), defaultdict(<class 'list'>, {'all_KL': [0.643], 'all_L1': [0.752]}), defaultdict(<class 'list'>, {'all_KL': [0.434], 'all_L1': [0.679]}), defaultdict(<class 'list'>, {'all_KL': [0.615], 'all_L1': [0.748]}), defaultdict(<class 'list'>, {'all_KL': [0.686], 'all_L1': [0.811]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
nec class all_KL  =  0.729 +- 0.048
nec class all_L1  =  0.612 +- 0.019
nec_acc_int  =  0.435 +- 0.021
suff class all_KL  =  0.440 +- 0.011
suff class all_L1  =  0.528 +- 0.023
suff_acc_int  =  0.592 +- 0.009

Eval split val
nec class all_KL  =  0.565 +- 0.086
nec class all_L1  =  0.460 +- 0.056
nec_acc_int  =  0.473 +- 0.049
suff class all_KL  =  0.353 +- 0.099
suff class all_L1  =  0.501 +- 0.052
suff_acc_int  =  0.667 +- 0.033

Eval split test
nec class all_KL  =  0.360 +- 0.023
nec class all_L1  =  0.276 +- 0.009
nec_acc_int  =  0.440 +- 0.012
suff class all_KL  =  0.579 +- 0.092
suff class all_L1  =  0.732 +- 0.052
suff_acc_int  =  0.361 +- 0.023


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
torch.Size([5, 1]) torch.Size([5, 1])
torch.Size([5, 1])
Faith. Aritm= 		  =  0.570 +- 0.019
Faith. Armon= 		  =  0.567 +- 0.020
Faith. GMean = 	  =  0.568 +- 0.020

Eval split val
torch.Size([5, 1]) torch.Size([5, 1])
torch.Size([5, 1])
Faith. Aritm= 		  =  0.481 +- 0.053
Faith. Armon= 		  =  0.480 +- 0.054
Faith. GMean = 	  =  0.480 +- 0.053

Eval split test
torch.Size([5, 1]) torch.Size([5, 1])
torch.Size([5, 1])
Faith. Aritm= 		  =  0.504 +- 0.027
Faith. Armon= 		  =  0.401 +- 0.013
Faith. GMean = 	  =  0.450 +- 0.018
Computed for split load_split = id



Completed in  0:07:19.542565  for CIGAGIN GOODMotif/basis



DONE CIGA GOODMotif/basis

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Mar 20 14:21:48 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/20/2024 02:21:48 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/20/2024 02:22:01 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/20/2024 02:22:03 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/20/2024 02:22:05 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/20/2024 02:22:07 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/20/2024 02:22:08 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/20/2024 02:22:08 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/20/2024 02:22:08 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:22:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:22:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:22:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:22:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:22:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:22:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:22:08 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 97...
[0m[1;37mINFO[0m: [1mCheckpoint 97: 
-----------------------------------
Train ACCURACY: 0.9314
Train Loss: 0.3178
ID Validation ACCURACY: 0.9303
ID Validation Loss: 0.3259
ID Test ACCURACY: 0.9280
ID Test Loss: 0.3250
OOD Validation ACCURACY: 0.8527
OOD Validation Loss: 0.5111
OOD Test ACCURACY: 0.6287
OOD Test Loss: 1.1683

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 83...
[0m[1;37mINFO[0m: [1mCheckpoint 83: 
-----------------------------------
Train ACCURACY: 0.9295
Train Loss: 0.3278
ID Validation ACCURACY: 0.9277
ID Validation Loss: 0.3391
ID Test ACCURACY: 0.9287
ID Test Loss: 0.3296
OOD Validation ACCURACY: 0.9320
OOD Validation Loss: 0.3661
OOD Test ACCURACY: 0.5353
OOD Test Loss: 1.3356

[0m[1;37mINFO[0m: [1mChartInfo 0.9280 0.6287 0.9287 0.5353 0.9277 0.9320[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.692
WIoU for r=0.3 = 0.567
F1 for r=0.6 = 0.583
WIoU for r=0.6 = 0.463
F1 for r=0.9 = 0.469
WIoU for r=0.9 = 0.347
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.326
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.869
WIoU for r=0.3 = 0.780
F1 for r=0.6 = 0.798
WIoU for r=0.6 = 0.710
F1 for r=0.9 = 0.618
WIoU for r=0.9 = 0.499
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 0.460
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.353
WIoU for r=0.3 = 0.253
F1 for r=0.6 = 0.626
WIoU for r=0.6 = 0.484
F1 for r=0.9 = 0.592
WIoU for r=0.9 = 0.434
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.401
Size bank for r=0.3 -> 1500
Size bank for r=0.6 -> 1500
Size bank for r=0.9 -> 1168


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.539
Model XAI F1 of binarized graphs for r=0.3 =  0.69200125
Model XAI WIoU of binarized graphs for r=0.3 =  0.5666525
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.342
NEC for r=0.3 class 0 = 0.651 +- 0.304 (in-sample avg dev_std = 0.427)
NEC for r=0.3 class 1 = 0.538 +- 0.304 (in-sample avg dev_std = 0.427)
NEC for r=0.3 class 2 = 0.503 +- 0.304 (in-sample avg dev_std = 0.427)
NEC for r=0.3 all KL = 0.6 +- 0.304 (in-sample avg dev_std = 0.427)
NEC for r=0.3 all L1 = 0.562 +- 0.207 (in-sample avg dev_std = 0.427)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.681
Model XAI F1 of binarized graphs for r=0.6 =  0.58292125
Model XAI WIoU of binarized graphs for r=0.6 =  0.46298
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.391
NEC for r=0.6 class 0 = 0.593 +- 0.246 (in-sample avg dev_std = 0.521)
NEC for r=0.6 class 1 = 0.598 +- 0.246 (in-sample avg dev_std = 0.521)
NEC for r=0.6 class 2 = 0.597 +- 0.246 (in-sample avg dev_std = 0.521)
NEC for r=0.6 all KL = 0.659 +- 0.246 (in-sample avg dev_std = 0.521)
NEC for r=0.6 all L1 = 0.596 +- 0.160 (in-sample avg dev_std = 0.521)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.904
Model XAI F1 of binarized graphs for r=0.9 =  0.4685975
Model XAI WIoU of binarized graphs for r=0.9 =  0.3465525000000001
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.487
NEC for r=0.9 class 0 = 0.614 +- 0.229 (in-sample avg dev_std = 0.610)
NEC for r=0.9 class 1 = 0.549 +- 0.229 (in-sample avg dev_std = 0.610)
NEC for r=0.9 class 2 = 0.555 +- 0.229 (in-sample avg dev_std = 0.610)
NEC for r=0.9 all KL = 0.643 +- 0.229 (in-sample avg dev_std = 0.610)
NEC for r=0.9 all L1 = 0.572 +- 0.153 (in-sample avg dev_std = 0.610)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.929
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.32596125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.515
NEC for r=1.0 class 0 = 0.563 +- 0.243 (in-sample avg dev_std = 0.649)
NEC for r=1.0 class 1 = 0.517 +- 0.243 (in-sample avg dev_std = 0.649)
NEC for r=1.0 class 2 = 0.57 +- 0.243 (in-sample avg dev_std = 0.649)
NEC for r=1.0 all KL = 0.622 +- 0.243 (in-sample avg dev_std = 0.649)
NEC for r=1.0 all L1 = 0.55 +- 0.170 (in-sample avg dev_std = 0.649)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.442
Model XAI F1 of binarized graphs for r=0.3 =  0.86858875
Model XAI WIoU of binarized graphs for r=0.3 =  0.78040875
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.227
NEC for r=0.3 class 0 = 0.675 +- 0.316 (in-sample avg dev_std = 0.486)
NEC for r=0.3 class 1 = 0.48 +- 0.316 (in-sample avg dev_std = 0.486)
NEC for r=0.3 class 2 = 0.62 +- 0.316 (in-sample avg dev_std = 0.486)
NEC for r=0.3 all KL = 0.645 +- 0.316 (in-sample avg dev_std = 0.486)
NEC for r=0.3 all L1 = 0.592 +- 0.209 (in-sample avg dev_std = 0.486)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.65
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  0.7103800000000001
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.436
NEC for r=0.6 class 0 = 0.481 +- 0.319 (in-sample avg dev_std = 0.450)
NEC for r=0.6 class 1 = 0.353 +- 0.319 (in-sample avg dev_std = 0.450)
NEC for r=0.6 class 2 = 0.301 +- 0.319 (in-sample avg dev_std = 0.450)
NEC for r=0.6 all KL = 0.386 +- 0.319 (in-sample avg dev_std = 0.450)
NEC for r=0.6 all L1 = 0.378 +- 0.256 (in-sample avg dev_std = 0.450)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.877
Model XAI F1 of binarized graphs for r=0.9 =  0.61811125
Model XAI WIoU of binarized graphs for r=0.9 =  0.49911875
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.579
NEC for r=0.9 class 0 = 0.425 +- 0.225 (in-sample avg dev_std = 0.557)
NEC for r=0.9 class 1 = 0.351 +- 0.225 (in-sample avg dev_std = 0.557)
NEC for r=0.9 class 2 = 0.369 +- 0.225 (in-sample avg dev_std = 0.557)
NEC for r=0.9 all KL = 0.327 +- 0.225 (in-sample avg dev_std = 0.557)
NEC for r=0.9 all L1 = 0.382 +- 0.162 (in-sample avg dev_std = 0.557)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.87
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  0.45974875000000004
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.623
NEC for r=1.0 class 0 = 0.427 +- 0.226 (in-sample avg dev_std = 0.560)
NEC for r=1.0 class 1 = 0.334 +- 0.226 (in-sample avg dev_std = 0.560)
NEC for r=1.0 class 2 = 0.363 +- 0.226 (in-sample avg dev_std = 0.560)
NEC for r=1.0 all KL = 0.331 +- 0.226 (in-sample avg dev_std = 0.560)
NEC for r=1.0 all L1 = 0.375 +- 0.160 (in-sample avg dev_std = 0.560)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.341
Model XAI F1 of binarized graphs for r=0.3 =  0.35290625000000003
Model XAI WIoU of binarized graphs for r=0.3 =  0.25268625
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.338
NEC for r=0.3 class 0 = 0.518 +- 0.287 (in-sample avg dev_std = 0.406)
NEC for r=0.3 class 1 = 0.307 +- 0.287 (in-sample avg dev_std = 0.406)
NEC for r=0.3 class 2 = 0.434 +- 0.287 (in-sample avg dev_std = 0.406)
NEC for r=0.3 all KL = 0.416 +- 0.287 (in-sample avg dev_std = 0.406)
NEC for r=0.3 all L1 = 0.422 +- 0.205 (in-sample avg dev_std = 0.406)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.46
Model XAI F1 of binarized graphs for r=0.6 =  0.6263275
Model XAI WIoU of binarized graphs for r=0.6 =  0.4838275
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.447
NEC for r=0.6 class 0 = 0.638 +- 0.247 (in-sample avg dev_std = 0.549)
NEC for r=0.6 class 1 = 0.588 +- 0.247 (in-sample avg dev_std = 0.549)
NEC for r=0.6 class 2 = 0.622 +- 0.247 (in-sample avg dev_std = 0.549)
NEC for r=0.6 all KL = 0.661 +- 0.247 (in-sample avg dev_std = 0.549)
NEC for r=0.6 all L1 = 0.616 +- 0.139 (in-sample avg dev_std = 0.549)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.699
Model XAI F1 of binarized graphs for r=0.9 =  0.59177625
Model XAI WIoU of binarized graphs for r=0.9 =  0.43375749999999996
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.533
NEC for r=0.9 class 0 = 0.538 +- 0.213 (in-sample avg dev_std = 0.545)
NEC for r=0.9 class 1 = 0.429 +- 0.213 (in-sample avg dev_std = 0.545)
NEC for r=0.9 class 2 = 0.529 +- 0.213 (in-sample avg dev_std = 0.545)
NEC for r=0.9 all KL = 0.481 +- 0.213 (in-sample avg dev_std = 0.545)
NEC for r=0.9 all L1 = 0.5 +- 0.137 (in-sample avg dev_std = 0.545)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.629
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.401135
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.562
NEC for r=1.0 class 0 = 0.492 +- 0.210 (in-sample avg dev_std = 0.509)
NEC for r=1.0 class 1 = 0.309 +- 0.210 (in-sample avg dev_std = 0.509)
NEC for r=1.0 class 2 = 0.512 +- 0.210 (in-sample avg dev_std = 0.509)
NEC for r=1.0 all KL = 0.432 +- 0.210 (in-sample avg dev_std = 0.509)
NEC for r=1.0 all L1 = 0.44 +- 0.173 (in-sample avg dev_std = 0.509)


Evaluating SUFF for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.538
Model XAI F1 of binarized graphs for r=0.3 =  0.69200125
Model XAI WIoU of binarized graphs for r=0.3 =  0.5666525
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.384
SUFF for r=0.3 class 0 = 0.419 +- 0.276 (in-sample avg dev_std = 0.537)
SUFF for r=0.3 class 1 = 0.495 +- 0.276 (in-sample avg dev_std = 0.537)
SUFF for r=0.3 class 2 = 0.512 +- 0.276 (in-sample avg dev_std = 0.537)
SUFF for r=0.3 all KL = 0.42 +- 0.276 (in-sample avg dev_std = 0.537)
SUFF for r=0.3 all L1 = 0.477 +- 0.176 (in-sample avg dev_std = 0.537)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.68
Model XAI F1 of binarized graphs for r=0.6 =  0.58292125
Model XAI WIoU of binarized graphs for r=0.6 =  0.46298
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.623
SUFF for r=0.6 class 0 = 0.414 +- 0.278 (in-sample avg dev_std = 0.460)
SUFF for r=0.6 class 1 = 0.605 +- 0.278 (in-sample avg dev_std = 0.460)
SUFF for r=0.6 class 2 = 0.634 +- 0.278 (in-sample avg dev_std = 0.460)
SUFF for r=0.6 all KL = 0.523 +- 0.278 (in-sample avg dev_std = 0.460)
SUFF for r=0.6 all L1 = 0.554 +- 0.205 (in-sample avg dev_std = 0.460)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.905
Model XAI F1 of binarized graphs for r=0.9 =  0.4685975
Model XAI WIoU of binarized graphs for r=0.9 =  0.3465525000000001
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.829
SUFF for r=0.9 class 0 = 0.657 +- 0.194 (in-sample avg dev_std = 0.242)
SUFF for r=0.9 class 1 = 0.772 +- 0.194 (in-sample avg dev_std = 0.242)
SUFF for r=0.9 class 2 = 0.838 +- 0.194 (in-sample avg dev_std = 0.242)
SUFF for r=0.9 all KL = 0.825 +- 0.194 (in-sample avg dev_std = 0.242)
SUFF for r=0.9 all L1 = 0.758 +- 0.180 (in-sample avg dev_std = 0.242)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.441
Model XAI F1 of binarized graphs for r=0.3 =  0.86858875
Model XAI WIoU of binarized graphs for r=0.3 =  0.78040875
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.346
SUFF for r=0.3 class 0 = 0.361 +- 0.288 (in-sample avg dev_std = 0.555)
SUFF for r=0.3 class 1 = 0.545 +- 0.288 (in-sample avg dev_std = 0.555)
SUFF for r=0.3 class 2 = 0.419 +- 0.288 (in-sample avg dev_std = 0.555)
SUFF for r=0.3 all KL = 0.384 +- 0.288 (in-sample avg dev_std = 0.555)
SUFF for r=0.3 all L1 = 0.441 +- 0.179 (in-sample avg dev_std = 0.555)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.65
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  0.7103800000000001
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.776
SUFF for r=0.6 class 0 = 0.456 +- 0.313 (in-sample avg dev_std = 0.494)
SUFF for r=0.6 class 1 = 0.428 +- 0.313 (in-sample avg dev_std = 0.494)
SUFF for r=0.6 class 2 = 0.684 +- 0.313 (in-sample avg dev_std = 0.494)
SUFF for r=0.6 all KL = 0.444 +- 0.313 (in-sample avg dev_std = 0.494)
SUFF for r=0.6 all L1 = 0.523 +- 0.232 (in-sample avg dev_std = 0.494)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.877
Model XAI F1 of binarized graphs for r=0.9 =  0.61811125
Model XAI WIoU of binarized graphs for r=0.9 =  0.49911875
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.908
SUFF for r=0.9 class 0 = 0.735 +- 0.123 (in-sample avg dev_std = 0.093)
SUFF for r=0.9 class 1 = 0.779 +- 0.123 (in-sample avg dev_std = 0.093)
SUFF for r=0.9 class 2 = 0.915 +- 0.123 (in-sample avg dev_std = 0.093)
SUFF for r=0.9 all KL = 0.923 +- 0.123 (in-sample avg dev_std = 0.093)
SUFF for r=0.9 all L1 = 0.809 +- 0.146 (in-sample avg dev_std = 0.093)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.34
Model XAI F1 of binarized graphs for r=0.3 =  0.35290625000000003
Model XAI WIoU of binarized graphs for r=0.3 =  0.25268625
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.333
SUFF for r=0.3 class 0 = 0.596 +- 0.226 (in-sample avg dev_std = 0.428)
SUFF for r=0.3 class 1 = 0.635 +- 0.226 (in-sample avg dev_std = 0.428)
SUFF for r=0.3 class 2 = 0.589 +- 0.226 (in-sample avg dev_std = 0.428)
SUFF for r=0.3 all KL = 0.605 +- 0.226 (in-sample avg dev_std = 0.428)
SUFF for r=0.3 all L1 = 0.606 +- 0.149 (in-sample avg dev_std = 0.428)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.459
Model XAI F1 of binarized graphs for r=0.6 =  0.6263275
Model XAI WIoU of binarized graphs for r=0.6 =  0.4838275
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.456
SUFF for r=0.6 class 0 = 0.474 +- 0.238 (in-sample avg dev_std = 0.520)
SUFF for r=0.6 class 1 = 0.569 +- 0.238 (in-sample avg dev_std = 0.520)
SUFF for r=0.6 class 2 = 0.583 +- 0.238 (in-sample avg dev_std = 0.520)
SUFF for r=0.6 all KL = 0.54 +- 0.238 (in-sample avg dev_std = 0.520)
SUFF for r=0.6 all L1 = 0.542 +- 0.167 (in-sample avg dev_std = 0.520)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.699
Model XAI F1 of binarized graphs for r=0.9 =  0.59177625
Model XAI WIoU of binarized graphs for r=0.9 =  0.43375749999999996
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.568
SUFF for r=0.9 class 0 = 0.633 +- 0.230 (in-sample avg dev_std = 0.262)
SUFF for r=0.9 class 1 = 0.863 +- 0.230 (in-sample avg dev_std = 0.262)
SUFF for r=0.9 class 2 = 0.664 +- 0.230 (in-sample avg dev_std = 0.262)
SUFF for r=0.9 all KL = 0.801 +- 0.230 (in-sample avg dev_std = 0.262)
SUFF for r=0.9 all L1 = 0.717 +- 0.230 (in-sample avg dev_std = 0.262)


ratio=1.0



Zero intervened samples, skipping weight=1.0

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Mar 20 14:25:47 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/20/2024 02:25:47 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/20/2024 02:25:59 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/20/2024 02:26:02 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/20/2024 02:26:04 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/20/2024 02:26:05 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/20/2024 02:26:07 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/20/2024 02:26:07 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/20/2024 02:26:07 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:26:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:26:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:26:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:26:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:26:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:26:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:26:07 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 141...
[0m[1;37mINFO[0m: [1mCheckpoint 141: 
-----------------------------------
Train ACCURACY: 0.9309
Train Loss: 0.3119
ID Validation ACCURACY: 0.9300
ID Validation Loss: 0.3271
ID Test ACCURACY: 0.9277
ID Test Loss: 0.3181
OOD Validation ACCURACY: 0.7947
OOD Validation Loss: 0.6208
OOD Test ACCURACY: 0.5837
OOD Test Loss: 1.2346

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 90...
[0m[1;37mINFO[0m: [1mCheckpoint 90: 
-----------------------------------
Train ACCURACY: 0.9266
Train Loss: 0.3279
ID Validation ACCURACY: 0.9250
ID Validation Loss: 0.3353
ID Test ACCURACY: 0.9243
ID Test Loss: 0.3312
OOD Validation ACCURACY: 0.9310
OOD Validation Loss: 0.3368
OOD Test ACCURACY: 0.5587
OOD Test Loss: 1.1490

[0m[1;37mINFO[0m: [1mChartInfo 0.9277 0.5837 0.9243 0.5587 0.9250 0.9310[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.712
WIoU for r=0.3 = 0.588
F1 for r=0.6 = 0.608
WIoU for r=0.6 = 0.491
F1 for r=0.9 = 0.474
WIoU for r=0.9 = 0.354
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.329
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.869
WIoU for r=0.3 = 0.781
F1 for r=0.6 = 0.798
WIoU for r=0.6 = 0.697
F1 for r=0.9 = 0.618
WIoU for r=0.9 = 0.484
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 0.445
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.362
WIoU for r=0.3 = 0.265
F1 for r=0.6 = 0.628
WIoU for r=0.6 = 0.491
F1 for r=0.9 = 0.590
WIoU for r=0.9 = 0.432
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.402
Size bank for r=0.3 -> 1500
Size bank for r=0.6 -> 1500
Size bank for r=0.9 -> 1031


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.496
Model XAI F1 of binarized graphs for r=0.3 =  0.7124174999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.5877512500000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.332
NEC for r=0.3 class 0 = 0.615 +- 0.267 (in-sample avg dev_std = 0.415)
NEC for r=0.3 class 1 = 0.52 +- 0.267 (in-sample avg dev_std = 0.415)
NEC for r=0.3 class 2 = 0.595 +- 0.267 (in-sample avg dev_std = 0.415)
NEC for r=0.3 all KL = 0.552 +- 0.267 (in-sample avg dev_std = 0.415)
NEC for r=0.3 all L1 = 0.576 +- 0.139 (in-sample avg dev_std = 0.415)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.683
Model XAI F1 of binarized graphs for r=0.6 =  0.60751
Model XAI WIoU of binarized graphs for r=0.6 =  0.49118375000000003
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.389
NEC for r=0.6 class 0 = 0.623 +- 0.272 (in-sample avg dev_std = 0.479)
NEC for r=0.6 class 1 = 0.54 +- 0.272 (in-sample avg dev_std = 0.479)
NEC for r=0.6 class 2 = 0.603 +- 0.272 (in-sample avg dev_std = 0.479)
NEC for r=0.6 all KL = 0.614 +- 0.272 (in-sample avg dev_std = 0.479)
NEC for r=0.6 all L1 = 0.588 +- 0.158 (in-sample avg dev_std = 0.479)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.895
Model XAI F1 of binarized graphs for r=0.9 =  0.47401625
Model XAI WIoU of binarized graphs for r=0.9 =  0.35372499999999996
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.501
NEC for r=0.9 class 0 = 0.619 +- 0.232 (in-sample avg dev_std = 0.571)
NEC for r=0.9 class 1 = 0.493 +- 0.232 (in-sample avg dev_std = 0.571)
NEC for r=0.9 class 2 = 0.575 +- 0.232 (in-sample avg dev_std = 0.571)
NEC for r=0.9 all KL = 0.604 +- 0.232 (in-sample avg dev_std = 0.571)
NEC for r=0.9 all L1 = 0.561 +- 0.158 (in-sample avg dev_std = 0.571)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.929
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.329255
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.559
NEC for r=1.0 class 0 = 0.565 +- 0.245 (in-sample avg dev_std = 0.593)
NEC for r=1.0 class 1 = 0.422 +- 0.245 (in-sample avg dev_std = 0.593)
NEC for r=1.0 class 2 = 0.55 +- 0.245 (in-sample avg dev_std = 0.593)
NEC for r=1.0 all KL = 0.54 +- 0.245 (in-sample avg dev_std = 0.593)
NEC for r=1.0 all L1 = 0.512 +- 0.175 (in-sample avg dev_std = 0.593)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.439
Model XAI F1 of binarized graphs for r=0.3 =  0.86858875
Model XAI WIoU of binarized graphs for r=0.3 =  0.78059125
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.209
NEC for r=0.3 class 0 = 0.676 +- 0.302 (in-sample avg dev_std = 0.389)
NEC for r=0.3 class 1 = 0.575 +- 0.302 (in-sample avg dev_std = 0.389)
NEC for r=0.3 class 2 = 0.552 +- 0.302 (in-sample avg dev_std = 0.389)
NEC for r=0.3 all KL = 0.662 +- 0.302 (in-sample avg dev_std = 0.389)
NEC for r=0.3 all L1 = 0.602 +- 0.204 (in-sample avg dev_std = 0.389)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.736
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  0.6969562499999999
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.437
NEC for r=0.6 class 0 = 0.501 +- 0.322 (in-sample avg dev_std = 0.499)
NEC for r=0.6 class 1 = 0.384 +- 0.322 (in-sample avg dev_std = 0.499)
NEC for r=0.6 class 2 = 0.38 +- 0.322 (in-sample avg dev_std = 0.499)
NEC for r=0.6 all KL = 0.448 +- 0.322 (in-sample avg dev_std = 0.499)
NEC for r=0.6 all L1 = 0.422 +- 0.248 (in-sample avg dev_std = 0.499)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.825
Model XAI F1 of binarized graphs for r=0.9 =  0.61811125
Model XAI WIoU of binarized graphs for r=0.9 =  0.48420875
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.627
NEC for r=0.9 class 0 = 0.406 +- 0.211 (in-sample avg dev_std = 0.492)
NEC for r=0.9 class 1 = 0.194 +- 0.211 (in-sample avg dev_std = 0.492)
NEC for r=0.9 class 2 = 0.391 +- 0.211 (in-sample avg dev_std = 0.492)
NEC for r=0.9 all KL = 0.259 +- 0.211 (in-sample avg dev_std = 0.492)
NEC for r=0.9 all L1 = 0.331 +- 0.171 (in-sample avg dev_std = 0.492)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.8
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  0.44504875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.619
NEC for r=1.0 class 0 = 0.412 +- 0.199 (in-sample avg dev_std = 0.453)
NEC for r=1.0 class 1 = 0.163 +- 0.199 (in-sample avg dev_std = 0.453)
NEC for r=1.0 class 2 = 0.337 +- 0.199 (in-sample avg dev_std = 0.453)
NEC for r=1.0 all KL = 0.225 +- 0.199 (in-sample avg dev_std = 0.453)
NEC for r=1.0 all L1 = 0.305 +- 0.184 (in-sample avg dev_std = 0.453)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.28
Model XAI F1 of binarized graphs for r=0.3 =  0.36158124999999997
Model XAI WIoU of binarized graphs for r=0.3 =  0.26469750000000003
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.332
NEC for r=0.3 class 0 = 0.578 +- 0.237 (in-sample avg dev_std = 0.357)
NEC for r=0.3 class 1 = 0.528 +- 0.237 (in-sample avg dev_std = 0.357)
NEC for r=0.3 class 2 = 0.536 +- 0.237 (in-sample avg dev_std = 0.357)
NEC for r=0.3 all KL = 0.464 +- 0.237 (in-sample avg dev_std = 0.357)
NEC for r=0.3 all L1 = 0.548 +- 0.154 (in-sample avg dev_std = 0.357)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.635
Model XAI F1 of binarized graphs for r=0.6 =  0.62756625
Model XAI WIoU of binarized graphs for r=0.6 =  0.49079625
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.484
NEC for r=0.6 class 0 = 0.541 +- 0.287 (in-sample avg dev_std = 0.554)
NEC for r=0.6 class 1 = 0.344 +- 0.287 (in-sample avg dev_std = 0.554)
NEC for r=0.6 class 2 = 0.613 +- 0.287 (in-sample avg dev_std = 0.554)
NEC for r=0.6 all KL = 0.55 +- 0.287 (in-sample avg dev_std = 0.554)
NEC for r=0.6 all L1 = 0.502 +- 0.203 (in-sample avg dev_std = 0.554)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.663
Model XAI F1 of binarized graphs for r=0.9 =  0.5903499999999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.43229999999999996
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.555
NEC for r=0.9 class 0 = 0.479 +- 0.241 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 1 = 0.204 +- 0.241 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 2 = 0.52 +- 0.241 (in-sample avg dev_std = 0.457)
NEC for r=0.9 all KL = 0.359 +- 0.241 (in-sample avg dev_std = 0.457)
NEC for r=0.9 all L1 = 0.404 +- 0.204 (in-sample avg dev_std = 0.457)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.586
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.4020425
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.536
NEC for r=1.0 class 0 = 0.407 +- 0.230 (in-sample avg dev_std = 0.425)
NEC for r=1.0 class 1 = 0.149 +- 0.230 (in-sample avg dev_std = 0.425)
NEC for r=1.0 class 2 = 0.49 +- 0.230 (in-sample avg dev_std = 0.425)
NEC for r=1.0 all KL = 0.3 +- 0.230 (in-sample avg dev_std = 0.425)
NEC for r=1.0 all L1 = 0.352 +- 0.208 (in-sample avg dev_std = 0.425)


Evaluating SUFF for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.499
Model XAI F1 of binarized graphs for r=0.3 =  0.7124174999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.5877512500000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.438
SUFF for r=0.3 class 0 = 0.426 +- 0.257 (in-sample avg dev_std = 0.487)
SUFF for r=0.3 class 1 = 0.51 +- 0.257 (in-sample avg dev_std = 0.487)
SUFF for r=0.3 class 2 = 0.461 +- 0.257 (in-sample avg dev_std = 0.487)
SUFF for r=0.3 all KL = 0.484 +- 0.257 (in-sample avg dev_std = 0.487)
SUFF for r=0.3 all L1 = 0.466 +- 0.132 (in-sample avg dev_std = 0.487)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.679
Model XAI F1 of binarized graphs for r=0.6 =  0.60751
Model XAI WIoU of binarized graphs for r=0.6 =  0.49118375000000003
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.647
SUFF for r=0.6 class 0 = 0.437 +- 0.270 (in-sample avg dev_std = 0.397)
SUFF for r=0.6 class 1 = 0.701 +- 0.270 (in-sample avg dev_std = 0.397)
SUFF for r=0.6 class 2 = 0.661 +- 0.270 (in-sample avg dev_std = 0.397)
SUFF for r=0.6 all KL = 0.624 +- 0.270 (in-sample avg dev_std = 0.397)
SUFF for r=0.6 all L1 = 0.602 +- 0.213 (in-sample avg dev_std = 0.397)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.894
Model XAI F1 of binarized graphs for r=0.9 =  0.47401625
Model XAI WIoU of binarized graphs for r=0.9 =  0.35372499999999996
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.848
SUFF for r=0.9 class 0 = 0.634 +- 0.188 (in-sample avg dev_std = 0.244)
SUFF for r=0.9 class 1 = 0.829 +- 0.188 (in-sample avg dev_std = 0.244)
SUFF for r=0.9 class 2 = 0.851 +- 0.188 (in-sample avg dev_std = 0.244)
SUFF for r=0.9 all KL = 0.845 +- 0.188 (in-sample avg dev_std = 0.244)
SUFF for r=0.9 all L1 = 0.774 +- 0.172 (in-sample avg dev_std = 0.244)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.439
Model XAI F1 of binarized graphs for r=0.3 =  0.86858875
Model XAI WIoU of binarized graphs for r=0.3 =  0.78059125
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.431
SUFF for r=0.3 class 0 = 0.386 +- 0.255 (in-sample avg dev_std = 0.562)
SUFF for r=0.3 class 1 = 0.546 +- 0.255 (in-sample avg dev_std = 0.562)
SUFF for r=0.3 class 2 = 0.415 +- 0.255 (in-sample avg dev_std = 0.562)
SUFF for r=0.3 all KL = 0.361 +- 0.255 (in-sample avg dev_std = 0.562)
SUFF for r=0.3 all L1 = 0.449 +- 0.145 (in-sample avg dev_std = 0.562)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.736
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  0.6969562499999999
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.812
SUFF for r=0.6 class 0 = 0.454 +- 0.320 (in-sample avg dev_std = 0.381)
SUFF for r=0.6 class 1 = 0.608 +- 0.320 (in-sample avg dev_std = 0.381)
SUFF for r=0.6 class 2 = 0.842 +- 0.320 (in-sample avg dev_std = 0.381)
SUFF for r=0.6 all KL = 0.617 +- 0.320 (in-sample avg dev_std = 0.381)
SUFF for r=0.6 all L1 = 0.634 +- 0.268 (in-sample avg dev_std = 0.381)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.825
Model XAI F1 of binarized graphs for r=0.9 =  0.61811125
Model XAI WIoU of binarized graphs for r=0.9 =  0.48420875
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.912
SUFF for r=0.9 class 0 = 0.789 +- 0.099 (in-sample avg dev_std = 0.106)
SUFF for r=0.9 class 1 = 0.882 +- 0.099 (in-sample avg dev_std = 0.106)
SUFF for r=0.9 class 2 = 0.762 +- 0.099 (in-sample avg dev_std = 0.106)
SUFF for r=0.9 all KL = 0.921 +- 0.099 (in-sample avg dev_std = 0.106)
SUFF for r=0.9 all L1 = 0.811 +- 0.155 (in-sample avg dev_std = 0.106)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.28
Model XAI F1 of binarized graphs for r=0.3 =  0.36158124999999997
Model XAI WIoU of binarized graphs for r=0.3 =  0.26469750000000003
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.33
SUFF for r=0.3 class 0 = 0.548 +- 0.207 (in-sample avg dev_std = 0.429)
SUFF for r=0.3 class 1 = 0.461 +- 0.207 (in-sample avg dev_std = 0.429)
SUFF for r=0.3 class 2 = 0.5 +- 0.207 (in-sample avg dev_std = 0.429)
SUFF for r=0.3 all KL = 0.602 +- 0.207 (in-sample avg dev_std = 0.429)
SUFF for r=0.3 all L1 = 0.504 +- 0.130 (in-sample avg dev_std = 0.429)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.636
Model XAI F1 of binarized graphs for r=0.6 =  0.62756625
Model XAI WIoU of binarized graphs for r=0.6 =  0.49079625
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.595
SUFF for r=0.6 class 0 = 0.711 +- 0.193 (in-sample avg dev_std = 0.347)
SUFF for r=0.6 class 1 = 0.781 +- 0.193 (in-sample avg dev_std = 0.347)
SUFF for r=0.6 class 2 = 0.772 +- 0.193 (in-sample avg dev_std = 0.347)
SUFF for r=0.6 all KL = 0.794 +- 0.193 (in-sample avg dev_std = 0.347)
SUFF for r=0.6 all L1 = 0.754 +- 0.162 (in-sample avg dev_std = 0.347)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.663
Model XAI F1 of binarized graphs for r=0.9 =  0.5903499999999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.43229999999999996
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.551
SUFF for r=0.9 class 0 = 0.716 +- 0.150 (in-sample avg dev_std = 0.147)
SUFF for r=0.9 class 1 = 0.949 +- 0.150 (in-sample avg dev_std = 0.147)
SUFF for r=0.9 class 2 = 0.73 +- 0.150 (in-sample avg dev_std = 0.147)
SUFF for r=0.9 all KL = 0.892 +- 0.150 (in-sample avg dev_std = 0.147)
SUFF for r=0.9 all L1 = 0.796 +- 0.195 (in-sample avg dev_std = 0.147)


ratio=1.0



Zero intervened samples, skipping weight=1.0

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Mar 20 14:29:44 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/20/2024 02:29:44 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/20/2024 02:29:57 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/20/2024 02:29:59 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/20/2024 02:30:01 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/20/2024 02:30:03 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/20/2024 02:30:04 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/20/2024 02:30:04 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/20/2024 02:30:04 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:30:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:30:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:30:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:30:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:30:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:30:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:30:04 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 156...
[0m[1;37mINFO[0m: [1mCheckpoint 156: 
-----------------------------------
Train ACCURACY: 0.9315
Train Loss: 0.3074
ID Validation ACCURACY: 0.9300
ID Validation Loss: 0.3203
ID Test ACCURACY: 0.9287
ID Test Loss: 0.3132
OOD Validation ACCURACY: 0.6043
OOD Validation Loss: 1.1704
OOD Test ACCURACY: 0.5793
OOD Test Loss: 1.3878

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 93...
[0m[1;37mINFO[0m: [1mCheckpoint 93: 
-----------------------------------
Train ACCURACY: 0.9269
Train Loss: 0.3333
ID Validation ACCURACY: 0.9240
ID Validation Loss: 0.3419
ID Test ACCURACY: 0.9233
ID Test Loss: 0.3373
OOD Validation ACCURACY: 0.9313
OOD Validation Loss: 0.3663
OOD Test ACCURACY: 0.5720
OOD Test Loss: 1.3522

[0m[1;37mINFO[0m: [1mChartInfo 0.9287 0.5793 0.9233 0.5720 0.9240 0.9313[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.709
WIoU for r=0.3 = 0.582
F1 for r=0.6 = 0.609
WIoU for r=0.6 = 0.489
F1 for r=0.9 = 0.474
WIoU for r=0.9 = 0.350
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.326
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.869
WIoU for r=0.3 = 0.781
F1 for r=0.6 = 0.798
WIoU for r=0.6 = 0.700
F1 for r=0.9 = 0.618
WIoU for r=0.9 = 0.486
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 0.447
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.409
WIoU for r=0.3 = 0.308
F1 for r=0.6 = 0.616
WIoU for r=0.6 = 0.484
F1 for r=0.9 = 0.575
WIoU for r=0.9 = 0.419
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.400
Size bank for r=0.3 -> 1500
Size bank for r=0.6 -> 1500
Size bank for r=0.9 -> 992


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.534
Model XAI F1 of binarized graphs for r=0.3 =  0.7088412500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.58233125
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.369
NEC for r=0.3 class 0 = 0.619 +- 0.274 (in-sample avg dev_std = 0.424)
NEC for r=0.3 class 1 = 0.506 +- 0.274 (in-sample avg dev_std = 0.424)
NEC for r=0.3 class 2 = 0.592 +- 0.274 (in-sample avg dev_std = 0.424)
NEC for r=0.3 all KL = 0.558 +- 0.274 (in-sample avg dev_std = 0.424)
NEC for r=0.3 all L1 = 0.572 +- 0.155 (in-sample avg dev_std = 0.424)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.69
Model XAI F1 of binarized graphs for r=0.6 =  0.6085575
Model XAI WIoU of binarized graphs for r=0.6 =  0.48855000000000004
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.423
NEC for r=0.6 class 0 = 0.568 +- 0.282 (in-sample avg dev_std = 0.499)
NEC for r=0.6 class 1 = 0.492 +- 0.282 (in-sample avg dev_std = 0.499)
NEC for r=0.6 class 2 = 0.634 +- 0.282 (in-sample avg dev_std = 0.499)
NEC for r=0.6 all KL = 0.61 +- 0.282 (in-sample avg dev_std = 0.499)
NEC for r=0.6 all L1 = 0.565 +- 0.182 (in-sample avg dev_std = 0.499)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.906
Model XAI F1 of binarized graphs for r=0.9 =  0.4740412500000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.350205
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.501
NEC for r=0.9 class 0 = 0.638 +- 0.227 (in-sample avg dev_std = 0.578)
NEC for r=0.9 class 1 = 0.477 +- 0.227 (in-sample avg dev_std = 0.578)
NEC for r=0.9 class 2 = 0.558 +- 0.227 (in-sample avg dev_std = 0.578)
NEC for r=0.9 all KL = 0.61 +- 0.227 (in-sample avg dev_std = 0.578)
NEC for r=0.9 all L1 = 0.557 +- 0.158 (in-sample avg dev_std = 0.578)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.929
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.32575249999999994
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.546
NEC for r=1.0 class 0 = 0.584 +- 0.236 (in-sample avg dev_std = 0.621)
NEC for r=1.0 class 1 = 0.433 +- 0.236 (in-sample avg dev_std = 0.621)
NEC for r=1.0 class 2 = 0.592 +- 0.236 (in-sample avg dev_std = 0.621)
NEC for r=1.0 all KL = 0.589 +- 0.236 (in-sample avg dev_std = 0.621)
NEC for r=1.0 all L1 = 0.536 +- 0.173 (in-sample avg dev_std = 0.621)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.466
Model XAI F1 of binarized graphs for r=0.3 =  0.86858875
Model XAI WIoU of binarized graphs for r=0.3 =  0.78103625
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.284
NEC for r=0.3 class 0 = 0.681 +- 0.269 (in-sample avg dev_std = 0.450)
NEC for r=0.3 class 1 = 0.586 +- 0.269 (in-sample avg dev_std = 0.450)
NEC for r=0.3 class 2 = 0.593 +- 0.269 (in-sample avg dev_std = 0.450)
NEC for r=0.3 all KL = 0.698 +- 0.269 (in-sample avg dev_std = 0.450)
NEC for r=0.3 all L1 = 0.62 +- 0.160 (in-sample avg dev_std = 0.450)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.74
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  0.6999175
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.466
NEC for r=0.6 class 0 = 0.492 +- 0.317 (in-sample avg dev_std = 0.489)
NEC for r=0.6 class 1 = 0.384 +- 0.317 (in-sample avg dev_std = 0.489)
NEC for r=0.6 class 2 = 0.324 +- 0.317 (in-sample avg dev_std = 0.489)
NEC for r=0.6 all KL = 0.416 +- 0.317 (in-sample avg dev_std = 0.489)
NEC for r=0.6 all L1 = 0.4 +- 0.256 (in-sample avg dev_std = 0.489)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.723
Model XAI F1 of binarized graphs for r=0.9 =  0.61811125
Model XAI WIoU of binarized graphs for r=0.9 =  0.4864625
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.577
NEC for r=0.9 class 0 = 0.366 +- 0.207 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 1 = 0.175 +- 0.207 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 2 = 0.369 +- 0.207 (in-sample avg dev_std = 0.441)
NEC for r=0.9 all KL = 0.229 +- 0.207 (in-sample avg dev_std = 0.441)
NEC for r=0.9 all L1 = 0.304 +- 0.180 (in-sample avg dev_std = 0.441)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.62
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  0.4470975
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.52
NEC for r=1.0 class 0 = 0.298 +- 0.186 (in-sample avg dev_std = 0.361)
NEC for r=1.0 class 1 = 0.116 +- 0.186 (in-sample avg dev_std = 0.361)
NEC for r=1.0 class 2 = 0.349 +- 0.186 (in-sample avg dev_std = 0.361)
NEC for r=1.0 all KL = 0.175 +- 0.186 (in-sample avg dev_std = 0.361)
NEC for r=1.0 all L1 = 0.255 +- 0.191 (in-sample avg dev_std = 0.361)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.264
Model XAI F1 of binarized graphs for r=0.3 =  0.40918
Model XAI WIoU of binarized graphs for r=0.3 =  0.30753875
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.252
NEC for r=0.3 class 0 = 0.582 +- 0.241 (in-sample avg dev_std = 0.362)
NEC for r=0.3 class 1 = 0.526 +- 0.241 (in-sample avg dev_std = 0.362)
NEC for r=0.3 class 2 = 0.521 +- 0.241 (in-sample avg dev_std = 0.362)
NEC for r=0.3 all KL = 0.452 +- 0.241 (in-sample avg dev_std = 0.362)
NEC for r=0.3 all L1 = 0.543 +- 0.155 (in-sample avg dev_std = 0.362)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.631
Model XAI F1 of binarized graphs for r=0.6 =  0.6164625
Model XAI WIoU of binarized graphs for r=0.6 =  0.4838675
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.493
NEC for r=0.6 class 0 = 0.574 +- 0.277 (in-sample avg dev_std = 0.569)
NEC for r=0.6 class 1 = 0.431 +- 0.277 (in-sample avg dev_std = 0.569)
NEC for r=0.6 class 2 = 0.616 +- 0.277 (in-sample avg dev_std = 0.569)
NEC for r=0.6 all KL = 0.577 +- 0.277 (in-sample avg dev_std = 0.569)
NEC for r=0.6 all L1 = 0.542 +- 0.177 (in-sample avg dev_std = 0.569)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.668
Model XAI F1 of binarized graphs for r=0.9 =  0.57488375
Model XAI WIoU of binarized graphs for r=0.9 =  0.418655
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.566
NEC for r=0.9 class 0 = 0.476 +- 0.241 (in-sample avg dev_std = 0.468)
NEC for r=0.9 class 1 = 0.221 +- 0.241 (in-sample avg dev_std = 0.468)
NEC for r=0.9 class 2 = 0.517 +- 0.241 (in-sample avg dev_std = 0.468)
NEC for r=0.9 all KL = 0.385 +- 0.241 (in-sample avg dev_std = 0.468)
NEC for r=0.9 all L1 = 0.408 +- 0.198 (in-sample avg dev_std = 0.468)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.582
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.3998625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.536
NEC for r=1.0 class 0 = 0.384 +- 0.228 (in-sample avg dev_std = 0.416)
NEC for r=1.0 class 1 = 0.147 +- 0.228 (in-sample avg dev_std = 0.416)
NEC for r=1.0 class 2 = 0.492 +- 0.228 (in-sample avg dev_std = 0.416)
NEC for r=1.0 all KL = 0.3 +- 0.228 (in-sample avg dev_std = 0.416)
NEC for r=1.0 all L1 = 0.345 +- 0.207 (in-sample avg dev_std = 0.416)


Evaluating SUFF for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.534
Model XAI F1 of binarized graphs for r=0.3 =  0.7088412500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.58233125
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.416
SUFF for r=0.3 class 0 = 0.409 +- 0.261 (in-sample avg dev_std = 0.514)
SUFF for r=0.3 class 1 = 0.464 +- 0.261 (in-sample avg dev_std = 0.514)
SUFF for r=0.3 class 2 = 0.45 +- 0.261 (in-sample avg dev_std = 0.514)
SUFF for r=0.3 all KL = 0.438 +- 0.261 (in-sample avg dev_std = 0.514)
SUFF for r=0.3 all L1 = 0.442 +- 0.126 (in-sample avg dev_std = 0.514)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.691
Model XAI F1 of binarized graphs for r=0.6 =  0.6085575
Model XAI WIoU of binarized graphs for r=0.6 =  0.48855000000000004
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.665
SUFF for r=0.6 class 0 = 0.443 +- 0.279 (in-sample avg dev_std = 0.408)
SUFF for r=0.6 class 1 = 0.703 +- 0.279 (in-sample avg dev_std = 0.408)
SUFF for r=0.6 class 2 = 0.598 +- 0.279 (in-sample avg dev_std = 0.408)
SUFF for r=0.6 all KL = 0.576 +- 0.279 (in-sample avg dev_std = 0.408)
SUFF for r=0.6 all L1 = 0.584 +- 0.211 (in-sample avg dev_std = 0.408)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.908
Model XAI F1 of binarized graphs for r=0.9 =  0.4740412500000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.350205
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.859
SUFF for r=0.9 class 0 = 0.662 +- 0.194 (in-sample avg dev_std = 0.254)
SUFF for r=0.9 class 1 = 0.825 +- 0.194 (in-sample avg dev_std = 0.254)
SUFF for r=0.9 class 2 = 0.833 +- 0.194 (in-sample avg dev_std = 0.254)
SUFF for r=0.9 all KL = 0.84 +- 0.194 (in-sample avg dev_std = 0.254)
SUFF for r=0.9 all L1 = 0.775 +- 0.166 (in-sample avg dev_std = 0.254)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.466
Model XAI F1 of binarized graphs for r=0.3 =  0.86858875
Model XAI WIoU of binarized graphs for r=0.3 =  0.78103625
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.404
SUFF for r=0.3 class 0 = 0.359 +- 0.247 (in-sample avg dev_std = 0.595)
SUFF for r=0.3 class 1 = 0.437 +- 0.247 (in-sample avg dev_std = 0.595)
SUFF for r=0.3 class 2 = 0.409 +- 0.247 (in-sample avg dev_std = 0.595)
SUFF for r=0.3 all KL = 0.298 +- 0.247 (in-sample avg dev_std = 0.595)
SUFF for r=0.3 all L1 = 0.401 +- 0.116 (in-sample avg dev_std = 0.595)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.74
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  0.6999175
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.816
SUFF for r=0.6 class 0 = 0.466 +- 0.320 (in-sample avg dev_std = 0.446)
SUFF for r=0.6 class 1 = 0.553 +- 0.320 (in-sample avg dev_std = 0.446)
SUFF for r=0.6 class 2 = 0.742 +- 0.320 (in-sample avg dev_std = 0.446)
SUFF for r=0.6 all KL = 0.539 +- 0.320 (in-sample avg dev_std = 0.446)
SUFF for r=0.6 all L1 = 0.587 +- 0.250 (in-sample avg dev_std = 0.446)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.723
Model XAI F1 of binarized graphs for r=0.9 =  0.61811125
Model XAI WIoU of binarized graphs for r=0.9 =  0.4864625
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.814
SUFF for r=0.9 class 0 = 0.606 +- 0.174 (in-sample avg dev_std = 0.102)
SUFF for r=0.9 class 1 = 0.862 +- 0.174 (in-sample avg dev_std = 0.102)
SUFF for r=0.9 class 2 = 0.761 +- 0.174 (in-sample avg dev_std = 0.102)
SUFF for r=0.9 all KL = 0.853 +- 0.174 (in-sample avg dev_std = 0.102)
SUFF for r=0.9 all L1 = 0.742 +- 0.202 (in-sample avg dev_std = 0.102)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.265
Model XAI F1 of binarized graphs for r=0.3 =  0.40918
Model XAI WIoU of binarized graphs for r=0.3 =  0.30753875
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.322
SUFF for r=0.3 class 0 = 0.465 +- 0.209 (in-sample avg dev_std = 0.430)
SUFF for r=0.3 class 1 = 0.461 +- 0.209 (in-sample avg dev_std = 0.430)
SUFF for r=0.3 class 2 = 0.471 +- 0.209 (in-sample avg dev_std = 0.430)
SUFF for r=0.3 all KL = 0.559 +- 0.209 (in-sample avg dev_std = 0.430)
SUFF for r=0.3 all L1 = 0.466 +- 0.113 (in-sample avg dev_std = 0.430)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.631
Model XAI F1 of binarized graphs for r=0.6 =  0.6164625
Model XAI WIoU of binarized graphs for r=0.6 =  0.4838675
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.585
SUFF for r=0.6 class 0 = 0.654 +- 0.197 (in-sample avg dev_std = 0.397)
SUFF for r=0.6 class 1 = 0.694 +- 0.197 (in-sample avg dev_std = 0.397)
SUFF for r=0.6 class 2 = 0.711 +- 0.197 (in-sample avg dev_std = 0.397)
SUFF for r=0.6 all KL = 0.73 +- 0.197 (in-sample avg dev_std = 0.397)
SUFF for r=0.6 all L1 = 0.686 +- 0.152 (in-sample avg dev_std = 0.397)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.668
Model XAI F1 of binarized graphs for r=0.9 =  0.57488375
Model XAI WIoU of binarized graphs for r=0.9 =  0.418655
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.572
SUFF for r=0.9 class 0 = 0.732 +- 0.161 (in-sample avg dev_std = 0.185)
SUFF for r=0.9 class 1 = 0.945 +- 0.161 (in-sample avg dev_std = 0.185)
SUFF for r=0.9 class 2 = 0.72 +- 0.161 (in-sample avg dev_std = 0.185)
SUFF for r=0.9 all KL = 0.881 +- 0.161 (in-sample avg dev_std = 0.185)
SUFF for r=0.9 all L1 = 0.796 +- 0.182 (in-sample avg dev_std = 0.185)


ratio=1.0



Zero intervened samples, skipping weight=1.0

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Mar 20 14:33:40 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/20/2024 02:33:40 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/20/2024 02:33:52 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/20/2024 02:33:54 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/20/2024 02:33:56 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/20/2024 02:33:58 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/20/2024 02:34:00 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/20/2024 02:34:00 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/20/2024 02:34:00 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:34:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:34:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:34:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:34:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:34:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:34:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:34:00 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 136...
[0m[1;37mINFO[0m: [1mCheckpoint 136: 
-----------------------------------
Train ACCURACY: 0.9312
Train Loss: 0.3182
ID Validation ACCURACY: 0.9303
ID Validation Loss: 0.3316
ID Test ACCURACY: 0.9280
ID Test Loss: 0.3271
OOD Validation ACCURACY: 0.9293
OOD Validation Loss: 0.4588
OOD Test ACCURACY: 0.5283
OOD Test Loss: 1.4435

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 30...
[0m[1;37mINFO[0m: [1mCheckpoint 30: 
-----------------------------------
Train ACCURACY: 0.9285
Train Loss: 0.3202
ID Validation ACCURACY: 0.9270
ID Validation Loss: 0.3310
ID Test ACCURACY: 0.9270
ID Test Loss: 0.3274
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.3340
OOD Test ACCURACY: 0.5837
OOD Test Loss: 1.2512

[0m[1;37mINFO[0m: [1mChartInfo 0.9280 0.5283 0.9270 0.5837 0.9270 0.9317[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.703
WIoU for r=0.3 = 0.578
F1 for r=0.6 = 0.592
WIoU for r=0.6 = 0.475
F1 for r=0.9 = 0.466
WIoU for r=0.9 = 0.343
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.325
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.869
WIoU for r=0.3 = 0.780
F1 for r=0.6 = 0.798
WIoU for r=0.6 = 0.699
F1 for r=0.9 = 0.618
WIoU for r=0.9 = 0.484
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 0.445
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.357
WIoU for r=0.3 = 0.258
F1 for r=0.6 = 0.596
WIoU for r=0.6 = 0.453
F1 for r=0.9 = 0.587
WIoU for r=0.9 = 0.425
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.398
Size bank for r=0.3 -> 1500
Size bank for r=0.6 -> 1500
Size bank for r=0.9 -> 1037


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.51
Model XAI F1 of binarized graphs for r=0.3 =  0.702765
Model XAI WIoU of binarized graphs for r=0.3 =  0.5784475
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.335
NEC for r=0.3 class 0 = 0.589 +- 0.276 (in-sample avg dev_std = 0.425)
NEC for r=0.3 class 1 = 0.551 +- 0.276 (in-sample avg dev_std = 0.425)
NEC for r=0.3 class 2 = 0.601 +- 0.276 (in-sample avg dev_std = 0.425)
NEC for r=0.3 all KL = 0.57 +- 0.276 (in-sample avg dev_std = 0.425)
NEC for r=0.3 all L1 = 0.58 +- 0.143 (in-sample avg dev_std = 0.425)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.65
Model XAI F1 of binarized graphs for r=0.6 =  0.5916562499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.47481375
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.382
NEC for r=0.6 class 0 = 0.566 +- 0.284 (in-sample avg dev_std = 0.477)
NEC for r=0.6 class 1 = 0.523 +- 0.284 (in-sample avg dev_std = 0.477)
NEC for r=0.6 class 2 = 0.619 +- 0.284 (in-sample avg dev_std = 0.477)
NEC for r=0.6 all KL = 0.615 +- 0.284 (in-sample avg dev_std = 0.477)
NEC for r=0.6 all L1 = 0.57 +- 0.179 (in-sample avg dev_std = 0.477)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.918
Model XAI F1 of binarized graphs for r=0.9 =  0.46628375
Model XAI WIoU of binarized graphs for r=0.9 =  0.34303249999999996
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.516
NEC for r=0.9 class 0 = 0.594 +- 0.226 (in-sample avg dev_std = 0.594)
NEC for r=0.9 class 1 = 0.492 +- 0.226 (in-sample avg dev_std = 0.594)
NEC for r=0.9 class 2 = 0.557 +- 0.226 (in-sample avg dev_std = 0.594)
NEC for r=0.9 all KL = 0.607 +- 0.226 (in-sample avg dev_std = 0.594)
NEC for r=0.9 all L1 = 0.547 +- 0.167 (in-sample avg dev_std = 0.594)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.929
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.32451625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.535
NEC for r=1.0 class 0 = 0.572 +- 0.226 (in-sample avg dev_std = 0.633)
NEC for r=1.0 class 1 = 0.456 +- 0.226 (in-sample avg dev_std = 0.633)
NEC for r=1.0 class 2 = 0.578 +- 0.226 (in-sample avg dev_std = 0.633)
NEC for r=1.0 all KL = 0.6 +- 0.226 (in-sample avg dev_std = 0.633)
NEC for r=1.0 all L1 = 0.535 +- 0.171 (in-sample avg dev_std = 0.633)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.419
Model XAI F1 of binarized graphs for r=0.3 =  0.86858875
Model XAI WIoU of binarized graphs for r=0.3 =  0.7796799999999999
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.312
NEC for r=0.3 class 0 = 0.641 +- 0.288 (in-sample avg dev_std = 0.437)
NEC for r=0.3 class 1 = 0.55 +- 0.288 (in-sample avg dev_std = 0.437)
NEC for r=0.3 class 2 = 0.619 +- 0.288 (in-sample avg dev_std = 0.437)
NEC for r=0.3 all KL = 0.62 +- 0.288 (in-sample avg dev_std = 0.437)
NEC for r=0.3 all L1 = 0.604 +- 0.160 (in-sample avg dev_std = 0.437)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.712
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  0.6985062500000001
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.446
NEC for r=0.6 class 0 = 0.481 +- 0.323 (in-sample avg dev_std = 0.505)
NEC for r=0.6 class 1 = 0.373 +- 0.323 (in-sample avg dev_std = 0.505)
NEC for r=0.6 class 2 = 0.351 +- 0.323 (in-sample avg dev_std = 0.505)
NEC for r=0.6 all KL = 0.433 +- 0.323 (in-sample avg dev_std = 0.505)
NEC for r=0.6 all L1 = 0.402 +- 0.257 (in-sample avg dev_std = 0.505)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.889
Model XAI F1 of binarized graphs for r=0.9 =  0.61811125
Model XAI WIoU of binarized graphs for r=0.9 =  0.48391999999999996
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.663
NEC for r=0.9 class 0 = 0.395 +- 0.195 (in-sample avg dev_std = 0.496)
NEC for r=0.9 class 1 = 0.239 +- 0.195 (in-sample avg dev_std = 0.496)
NEC for r=0.9 class 2 = 0.362 +- 0.195 (in-sample avg dev_std = 0.496)
NEC for r=0.9 all KL = 0.265 +- 0.195 (in-sample avg dev_std = 0.496)
NEC for r=0.9 all L1 = 0.332 +- 0.168 (in-sample avg dev_std = 0.496)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.933
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  0.44457749999999996
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.695
NEC for r=1.0 class 0 = 0.394 +- 0.177 (in-sample avg dev_std = 0.486)
NEC for r=1.0 class 1 = 0.225 +- 0.177 (in-sample avg dev_std = 0.486)
NEC for r=1.0 class 2 = 0.36 +- 0.177 (in-sample avg dev_std = 0.486)
NEC for r=1.0 all KL = 0.246 +- 0.177 (in-sample avg dev_std = 0.486)
NEC for r=1.0 all L1 = 0.327 +- 0.164 (in-sample avg dev_std = 0.486)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.179
Model XAI F1 of binarized graphs for r=0.3 =  0.3568325
Model XAI WIoU of binarized graphs for r=0.3 =  0.25753875
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.293
NEC for r=0.3 class 0 = 0.565 +- 0.232 (in-sample avg dev_std = 0.347)
NEC for r=0.3 class 1 = 0.503 +- 0.232 (in-sample avg dev_std = 0.347)
NEC for r=0.3 class 2 = 0.527 +- 0.232 (in-sample avg dev_std = 0.347)
NEC for r=0.3 all KL = 0.436 +- 0.232 (in-sample avg dev_std = 0.347)
NEC for r=0.3 all L1 = 0.532 +- 0.153 (in-sample avg dev_std = 0.347)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.579
Model XAI F1 of binarized graphs for r=0.6 =  0.596425
Model XAI WIoU of binarized graphs for r=0.6 =  0.45335875000000003
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.486
NEC for r=0.6 class 0 = 0.567 +- 0.270 (in-sample avg dev_std = 0.520)
NEC for r=0.6 class 1 = 0.46 +- 0.270 (in-sample avg dev_std = 0.520)
NEC for r=0.6 class 2 = 0.63 +- 0.270 (in-sample avg dev_std = 0.520)
NEC for r=0.6 all KL = 0.557 +- 0.270 (in-sample avg dev_std = 0.520)
NEC for r=0.6 all L1 = 0.554 +- 0.167 (in-sample avg dev_std = 0.520)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.671
Model XAI F1 of binarized graphs for r=0.9 =  0.58662625
Model XAI WIoU of binarized graphs for r=0.9 =  0.42531874999999997
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.573
NEC for r=0.9 class 0 = 0.479 +- 0.218 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 1 = 0.274 +- 0.218 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 2 = 0.496 +- 0.218 (in-sample avg dev_std = 0.450)
NEC for r=0.9 all KL = 0.361 +- 0.218 (in-sample avg dev_std = 0.450)
NEC for r=0.9 all L1 = 0.419 +- 0.172 (in-sample avg dev_std = 0.450)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.521
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.39820125000000006
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.532
NEC for r=1.0 class 0 = 0.415 +- 0.219 (in-sample avg dev_std = 0.441)
NEC for r=1.0 class 1 = 0.176 +- 0.219 (in-sample avg dev_std = 0.441)
NEC for r=1.0 class 2 = 0.473 +- 0.219 (in-sample avg dev_std = 0.441)
NEC for r=1.0 all KL = 0.317 +- 0.219 (in-sample avg dev_std = 0.441)
NEC for r=1.0 all L1 = 0.358 +- 0.196 (in-sample avg dev_std = 0.441)


Evaluating SUFF for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.519
Model XAI F1 of binarized graphs for r=0.3 =  0.702765
Model XAI WIoU of binarized graphs for r=0.3 =  0.5784475
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.411
SUFF for r=0.3 class 0 = 0.438 +- 0.278 (in-sample avg dev_std = 0.494)
SUFF for r=0.3 class 1 = 0.457 +- 0.278 (in-sample avg dev_std = 0.494)
SUFF for r=0.3 class 2 = 0.461 +- 0.278 (in-sample avg dev_std = 0.494)
SUFF for r=0.3 all KL = 0.45 +- 0.278 (in-sample avg dev_std = 0.494)
SUFF for r=0.3 all L1 = 0.452 +- 0.132 (in-sample avg dev_std = 0.494)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.649
Model XAI F1 of binarized graphs for r=0.6 =  0.5916562499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.47481375
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.685
SUFF for r=0.6 class 0 = 0.457 +- 0.292 (in-sample avg dev_std = 0.400)
SUFF for r=0.6 class 1 = 0.712 +- 0.292 (in-sample avg dev_std = 0.400)
SUFF for r=0.6 class 2 = 0.57 +- 0.292 (in-sample avg dev_std = 0.400)
SUFF for r=0.6 all KL = 0.591 +- 0.292 (in-sample avg dev_std = 0.400)
SUFF for r=0.6 all L1 = 0.581 +- 0.218 (in-sample avg dev_std = 0.400)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.919
Model XAI F1 of binarized graphs for r=0.9 =  0.46628375
Model XAI WIoU of binarized graphs for r=0.9 =  0.34303249999999996
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.84
SUFF for r=0.9 class 0 = 0.64 +- 0.198 (in-sample avg dev_std = 0.238)
SUFF for r=0.9 class 1 = 0.863 +- 0.198 (in-sample avg dev_std = 0.238)
SUFF for r=0.9 class 2 = 0.809 +- 0.198 (in-sample avg dev_std = 0.238)
SUFF for r=0.9 all KL = 0.844 +- 0.198 (in-sample avg dev_std = 0.238)
SUFF for r=0.9 all L1 = 0.773 +- 0.180 (in-sample avg dev_std = 0.238)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.419
Model XAI F1 of binarized graphs for r=0.3 =  0.86858875
Model XAI WIoU of binarized graphs for r=0.3 =  0.7796799999999999
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.385
SUFF for r=0.3 class 0 = 0.391 +- 0.266 (in-sample avg dev_std = 0.540)
SUFF for r=0.3 class 1 = 0.448 +- 0.266 (in-sample avg dev_std = 0.540)
SUFF for r=0.3 class 2 = 0.424 +- 0.266 (in-sample avg dev_std = 0.540)
SUFF for r=0.3 all KL = 0.385 +- 0.266 (in-sample avg dev_std = 0.540)
SUFF for r=0.3 all L1 = 0.421 +- 0.117 (in-sample avg dev_std = 0.540)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.712
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  0.6985062500000001
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.782
SUFF for r=0.6 class 0 = 0.455 +- 0.342 (in-sample avg dev_std = 0.468)
SUFF for r=0.6 class 1 = 0.581 +- 0.342 (in-sample avg dev_std = 0.468)
SUFF for r=0.6 class 2 = 0.62 +- 0.342 (in-sample avg dev_std = 0.468)
SUFF for r=0.6 all KL = 0.493 +- 0.342 (in-sample avg dev_std = 0.468)
SUFF for r=0.6 all L1 = 0.552 +- 0.253 (in-sample avg dev_std = 0.468)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.889
Model XAI F1 of binarized graphs for r=0.9 =  0.61811125
Model XAI WIoU of binarized graphs for r=0.9 =  0.48391999999999996
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.908
SUFF for r=0.9 class 0 = 0.758 +- 0.113 (in-sample avg dev_std = 0.117)
SUFF for r=0.9 class 1 = 0.871 +- 0.113 (in-sample avg dev_std = 0.117)
SUFF for r=0.9 class 2 = 0.833 +- 0.113 (in-sample avg dev_std = 0.117)
SUFF for r=0.9 all KL = 0.927 +- 0.113 (in-sample avg dev_std = 0.117)
SUFF for r=0.9 all L1 = 0.82 +- 0.138 (in-sample avg dev_std = 0.117)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.179
Model XAI F1 of binarized graphs for r=0.3 =  0.3568325
Model XAI WIoU of binarized graphs for r=0.3 =  0.25753875
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.316
SUFF for r=0.3 class 0 = 0.472 +- 0.194 (in-sample avg dev_std = 0.419)
SUFF for r=0.3 class 1 = 0.487 +- 0.194 (in-sample avg dev_std = 0.419)
SUFF for r=0.3 class 2 = 0.521 +- 0.194 (in-sample avg dev_std = 0.419)
SUFF for r=0.3 all KL = 0.598 +- 0.194 (in-sample avg dev_std = 0.419)
SUFF for r=0.3 all L1 = 0.493 +- 0.110 (in-sample avg dev_std = 0.419)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.579
Model XAI F1 of binarized graphs for r=0.6 =  0.596425
Model XAI WIoU of binarized graphs for r=0.6 =  0.45335875000000003
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.479
SUFF for r=0.6 class 0 = 0.542 +- 0.225 (in-sample avg dev_std = 0.398)
SUFF for r=0.6 class 1 = 0.71 +- 0.225 (in-sample avg dev_std = 0.398)
SUFF for r=0.6 class 2 = 0.614 +- 0.225 (in-sample avg dev_std = 0.398)
SUFF for r=0.6 all KL = 0.674 +- 0.225 (in-sample avg dev_std = 0.398)
SUFF for r=0.6 all L1 = 0.62 +- 0.188 (in-sample avg dev_std = 0.398)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.671
Model XAI F1 of binarized graphs for r=0.9 =  0.58662625
Model XAI WIoU of binarized graphs for r=0.9 =  0.42531874999999997
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.54
SUFF for r=0.9 class 0 = 0.7 +- 0.176 (in-sample avg dev_std = 0.197)
SUFF for r=0.9 class 1 = 0.922 +- 0.176 (in-sample avg dev_std = 0.197)
SUFF for r=0.9 class 2 = 0.686 +- 0.176 (in-sample avg dev_std = 0.197)
SUFF for r=0.9 all KL = 0.861 +- 0.176 (in-sample avg dev_std = 0.197)
SUFF for r=0.9 all L1 = 0.766 +- 0.208 (in-sample avg dev_std = 0.197)


ratio=1.0



Zero intervened samples, skipping weight=1.0

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Mar 20 14:37:36 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/20/2024 02:37:36 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/20/2024 02:37:49 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/20/2024 02:37:51 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/20/2024 02:37:53 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/20/2024 02:37:54 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/20/2024 02:37:56 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/20/2024 02:37:56 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/20/2024 02:37:56 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:37:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:37:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:37:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:37:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:37:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:37:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:37:56 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 90...
[0m[1;37mINFO[0m: [1mCheckpoint 90: 
-----------------------------------
Train ACCURACY: 0.9313
Train Loss: 0.3152
ID Validation ACCURACY: 0.9303
ID Validation Loss: 0.3261
ID Test ACCURACY: 0.9280
ID Test Loss: 0.3206
OOD Validation ACCURACY: 0.5570
OOD Validation Loss: 1.0961
OOD Test ACCURACY: 0.5530
OOD Test Loss: 1.3591

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 46...
[0m[1;37mINFO[0m: [1mCheckpoint 46: 
-----------------------------------
Train ACCURACY: 0.9284
Train Loss: 0.3274
ID Validation ACCURACY: 0.9277
ID Validation Loss: 0.3360
ID Test ACCURACY: 0.9260
ID Test Loss: 0.3348
OOD Validation ACCURACY: 0.9320
OOD Validation Loss: 0.3331
OOD Test ACCURACY: 0.5507
OOD Test Loss: 1.5619

[0m[1;37mINFO[0m: [1mChartInfo 0.9280 0.5530 0.9260 0.5507 0.9277 0.9320[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.657
WIoU for r=0.3 = 0.531
F1 for r=0.6 = 0.571
WIoU for r=0.6 = 0.452
F1 for r=0.9 = 0.455
WIoU for r=0.9 = 0.333
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.324
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.869
WIoU for r=0.3 = 0.781
F1 for r=0.6 = 0.798
WIoU for r=0.6 = 0.709
F1 for r=0.9 = 0.618
WIoU for r=0.9 = 0.497
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 0.458
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.336
WIoU for r=0.3 = 0.243
F1 for r=0.6 = 0.584
WIoU for r=0.6 = 0.447
F1 for r=0.9 = 0.579
WIoU for r=0.9 = 0.419
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.398
Size bank for r=0.3 -> 1500
Size bank for r=0.6 -> 1500
Size bank for r=0.9 -> 1017


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.548
Model XAI F1 of binarized graphs for r=0.3 =  0.6567374999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.53097875
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.363
NEC for r=0.3 class 0 = 0.598 +- 0.278 (in-sample avg dev_std = 0.425)
NEC for r=0.3 class 1 = 0.527 +- 0.278 (in-sample avg dev_std = 0.425)
NEC for r=0.3 class 2 = 0.525 +- 0.278 (in-sample avg dev_std = 0.425)
NEC for r=0.3 all KL = 0.54 +- 0.278 (in-sample avg dev_std = 0.425)
NEC for r=0.3 all L1 = 0.549 +- 0.154 (in-sample avg dev_std = 0.425)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.635
Model XAI F1 of binarized graphs for r=0.6 =  0.57065625
Model XAI WIoU of binarized graphs for r=0.6 =  0.4520375
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.367
NEC for r=0.6 class 0 = 0.577 +- 0.284 (in-sample avg dev_std = 0.489)
NEC for r=0.6 class 1 = 0.551 +- 0.284 (in-sample avg dev_std = 0.489)
NEC for r=0.6 class 2 = 0.627 +- 0.284 (in-sample avg dev_std = 0.489)
NEC for r=0.6 all KL = 0.637 +- 0.284 (in-sample avg dev_std = 0.489)
NEC for r=0.6 all L1 = 0.585 +- 0.179 (in-sample avg dev_std = 0.489)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.9
Model XAI F1 of binarized graphs for r=0.9 =  0.45470749999999993
Model XAI WIoU of binarized graphs for r=0.9 =  0.33283
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.48
NEC for r=0.9 class 0 = 0.59 +- 0.241 (in-sample avg dev_std = 0.591)
NEC for r=0.9 class 1 = 0.535 +- 0.241 (in-sample avg dev_std = 0.591)
NEC for r=0.9 class 2 = 0.574 +- 0.241 (in-sample avg dev_std = 0.591)
NEC for r=0.9 all KL = 0.625 +- 0.241 (in-sample avg dev_std = 0.591)
NEC for r=0.9 all L1 = 0.566 +- 0.150 (in-sample avg dev_std = 0.591)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.929
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.32355625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.524
NEC for r=1.0 class 0 = 0.566 +- 0.242 (in-sample avg dev_std = 0.626)
NEC for r=1.0 class 1 = 0.476 +- 0.242 (in-sample avg dev_std = 0.626)
NEC for r=1.0 class 2 = 0.577 +- 0.242 (in-sample avg dev_std = 0.626)
NEC for r=1.0 all KL = 0.596 +- 0.242 (in-sample avg dev_std = 0.626)
NEC for r=1.0 all L1 = 0.54 +- 0.170 (in-sample avg dev_std = 0.626)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.461
Model XAI F1 of binarized graphs for r=0.3 =  0.86858875
Model XAI WIoU of binarized graphs for r=0.3 =  0.78127375
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.278
NEC for r=0.3 class 0 = 0.631 +- 0.315 (in-sample avg dev_std = 0.374)
NEC for r=0.3 class 1 = 0.496 +- 0.315 (in-sample avg dev_std = 0.374)
NEC for r=0.3 class 2 = 0.6 +- 0.315 (in-sample avg dev_std = 0.374)
NEC for r=0.3 all KL = 0.576 +- 0.315 (in-sample avg dev_std = 0.374)
NEC for r=0.3 all L1 = 0.576 +- 0.179 (in-sample avg dev_std = 0.374)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.752
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  0.70853875
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.466
NEC for r=0.6 class 0 = 0.525 +- 0.313 (in-sample avg dev_std = 0.549)
NEC for r=0.6 class 1 = 0.427 +- 0.313 (in-sample avg dev_std = 0.549)
NEC for r=0.6 class 2 = 0.402 +- 0.313 (in-sample avg dev_std = 0.549)
NEC for r=0.6 all KL = 0.487 +- 0.313 (in-sample avg dev_std = 0.549)
NEC for r=0.6 all L1 = 0.452 +- 0.221 (in-sample avg dev_std = 0.549)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.68
Model XAI F1 of binarized graphs for r=0.9 =  0.61811125
Model XAI WIoU of binarized graphs for r=0.9 =  0.49698875000000003
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.551
NEC for r=0.9 class 0 = 0.38 +- 0.232 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 1 = 0.17 +- 0.232 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 2 = 0.376 +- 0.232 (in-sample avg dev_std = 0.457)
NEC for r=0.9 all KL = 0.257 +- 0.232 (in-sample avg dev_std = 0.457)
NEC for r=0.9 all L1 = 0.309 +- 0.193 (in-sample avg dev_std = 0.457)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.58
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  0.45765874999999995
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.506
NEC for r=1.0 class 0 = 0.32 +- 0.208 (in-sample avg dev_std = 0.367)
NEC for r=1.0 class 1 = 0.112 +- 0.208 (in-sample avg dev_std = 0.367)
NEC for r=1.0 class 2 = 0.314 +- 0.208 (in-sample avg dev_std = 0.367)
NEC for r=1.0 all KL = 0.19 +- 0.208 (in-sample avg dev_std = 0.367)
NEC for r=1.0 all L1 = 0.249 +- 0.200 (in-sample avg dev_std = 0.367)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.373
Model XAI F1 of binarized graphs for r=0.3 =  0.33567499999999995
Model XAI WIoU of binarized graphs for r=0.3 =  0.24335875
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.324
NEC for r=0.3 class 0 = 0.513 +- 0.229 (in-sample avg dev_std = 0.336)
NEC for r=0.3 class 1 = 0.368 +- 0.229 (in-sample avg dev_std = 0.336)
NEC for r=0.3 class 2 = 0.448 +- 0.229 (in-sample avg dev_std = 0.336)
NEC for r=0.3 all KL = 0.347 +- 0.229 (in-sample avg dev_std = 0.336)
NEC for r=0.3 all L1 = 0.444 +- 0.170 (in-sample avg dev_std = 0.336)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.479
Model XAI F1 of binarized graphs for r=0.6 =  0.584365
Model XAI WIoU of binarized graphs for r=0.6 =  0.4468237499999999
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.478
NEC for r=0.6 class 0 = 0.603 +- 0.260 (in-sample avg dev_std = 0.543)
NEC for r=0.6 class 1 = 0.513 +- 0.260 (in-sample avg dev_std = 0.543)
NEC for r=0.6 class 2 = 0.621 +- 0.260 (in-sample avg dev_std = 0.543)
NEC for r=0.6 all KL = 0.61 +- 0.260 (in-sample avg dev_std = 0.543)
NEC for r=0.6 all L1 = 0.58 +- 0.155 (in-sample avg dev_std = 0.543)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.65
Model XAI F1 of binarized graphs for r=0.9 =  0.5792587499999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.41902750000000005
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.533
NEC for r=0.9 class 0 = 0.502 +- 0.252 (in-sample avg dev_std = 0.513)
NEC for r=0.9 class 1 = 0.295 +- 0.252 (in-sample avg dev_std = 0.513)
NEC for r=0.9 class 2 = 0.541 +- 0.252 (in-sample avg dev_std = 0.513)
NEC for r=0.9 all KL = 0.436 +- 0.252 (in-sample avg dev_std = 0.513)
NEC for r=0.9 all L1 = 0.449 +- 0.180 (in-sample avg dev_std = 0.513)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.554
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.39755250000000003
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.536
NEC for r=1.0 class 0 = 0.419 +- 0.221 (in-sample avg dev_std = 0.456)
NEC for r=1.0 class 1 = 0.201 +- 0.221 (in-sample avg dev_std = 0.456)
NEC for r=1.0 class 2 = 0.494 +- 0.221 (in-sample avg dev_std = 0.456)
NEC for r=1.0 all KL = 0.346 +- 0.221 (in-sample avg dev_std = 0.456)
NEC for r=1.0 all L1 = 0.375 +- 0.195 (in-sample avg dev_std = 0.456)


Evaluating SUFF for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.548
Model XAI F1 of binarized graphs for r=0.3 =  0.6567374999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.53097875
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.375
SUFF for r=0.3 class 0 = 0.467 +- 0.280 (in-sample avg dev_std = 0.482)
SUFF for r=0.3 class 1 = 0.491 +- 0.280 (in-sample avg dev_std = 0.482)
SUFF for r=0.3 class 2 = 0.528 +- 0.280 (in-sample avg dev_std = 0.482)
SUFF for r=0.3 all KL = 0.501 +- 0.280 (in-sample avg dev_std = 0.482)
SUFF for r=0.3 all L1 = 0.496 +- 0.148 (in-sample avg dev_std = 0.482)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.634
Model XAI F1 of binarized graphs for r=0.6 =  0.57065625
Model XAI WIoU of binarized graphs for r=0.6 =  0.4520375
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.635
SUFF for r=0.6 class 0 = 0.388 +- 0.280 (in-sample avg dev_std = 0.441)
SUFF for r=0.6 class 1 = 0.61 +- 0.280 (in-sample avg dev_std = 0.441)
SUFF for r=0.6 class 2 = 0.582 +- 0.280 (in-sample avg dev_std = 0.441)
SUFF for r=0.6 all KL = 0.506 +- 0.280 (in-sample avg dev_std = 0.441)
SUFF for r=0.6 all L1 = 0.529 +- 0.215 (in-sample avg dev_std = 0.441)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.899
Model XAI F1 of binarized graphs for r=0.9 =  0.45470749999999993
Model XAI WIoU of binarized graphs for r=0.9 =  0.33283
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.766
SUFF for r=0.9 class 0 = 0.514 +- 0.226 (in-sample avg dev_std = 0.304)
SUFF for r=0.9 class 1 = 0.769 +- 0.226 (in-sample avg dev_std = 0.304)
SUFF for r=0.9 class 2 = 0.843 +- 0.226 (in-sample avg dev_std = 0.304)
SUFF for r=0.9 all KL = 0.773 +- 0.226 (in-sample avg dev_std = 0.304)
SUFF for r=0.9 all L1 = 0.713 +- 0.210 (in-sample avg dev_std = 0.304)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.459
Model XAI F1 of binarized graphs for r=0.3 =  0.86858875
Model XAI WIoU of binarized graphs for r=0.3 =  0.78127375
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.325
SUFF for r=0.3 class 0 = 0.383 +- 0.302 (in-sample avg dev_std = 0.497)
SUFF for r=0.3 class 1 = 0.515 +- 0.302 (in-sample avg dev_std = 0.497)
SUFF for r=0.3 class 2 = 0.424 +- 0.302 (in-sample avg dev_std = 0.497)
SUFF for r=0.3 all KL = 0.424 +- 0.302 (in-sample avg dev_std = 0.497)
SUFF for r=0.3 all L1 = 0.44 +- 0.156 (in-sample avg dev_std = 0.497)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.752
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  0.70853875
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.826
SUFF for r=0.6 class 0 = 0.481 +- 0.310 (in-sample avg dev_std = 0.429)
SUFF for r=0.6 class 1 = 0.678 +- 0.310 (in-sample avg dev_std = 0.429)
SUFF for r=0.6 class 2 = 0.775 +- 0.310 (in-sample avg dev_std = 0.429)
SUFF for r=0.6 all KL = 0.596 +- 0.310 (in-sample avg dev_std = 0.429)
SUFF for r=0.6 all L1 = 0.644 +- 0.247 (in-sample avg dev_std = 0.429)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.68
Model XAI F1 of binarized graphs for r=0.9 =  0.61811125
Model XAI WIoU of binarized graphs for r=0.9 =  0.49698875000000003
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.847
SUFF for r=0.9 class 0 = 0.706 +- 0.146 (in-sample avg dev_std = 0.089)
SUFF for r=0.9 class 1 = 0.91 +- 0.146 (in-sample avg dev_std = 0.089)
SUFF for r=0.9 class 2 = 0.714 +- 0.146 (in-sample avg dev_std = 0.089)
SUFF for r=0.9 all KL = 0.887 +- 0.146 (in-sample avg dev_std = 0.089)
SUFF for r=0.9 all L1 = 0.776 +- 0.198 (in-sample avg dev_std = 0.089)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.373
Model XAI F1 of binarized graphs for r=0.3 =  0.33567499999999995
Model XAI WIoU of binarized graphs for r=0.3 =  0.24335875
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.343
SUFF for r=0.3 class 0 = 0.569 +- 0.178 (in-sample avg dev_std = 0.379)
SUFF for r=0.3 class 1 = 0.603 +- 0.178 (in-sample avg dev_std = 0.379)
SUFF for r=0.3 class 2 = 0.611 +- 0.178 (in-sample avg dev_std = 0.379)
SUFF for r=0.3 all KL = 0.7 +- 0.178 (in-sample avg dev_std = 0.379)
SUFF for r=0.3 all L1 = 0.594 +- 0.121 (in-sample avg dev_std = 0.379)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.479
Model XAI F1 of binarized graphs for r=0.6 =  0.584365
Model XAI WIoU of binarized graphs for r=0.6 =  0.4468237499999999
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.443
SUFF for r=0.6 class 0 = 0.563 +- 0.236 (in-sample avg dev_std = 0.416)
SUFF for r=0.6 class 1 = 0.653 +- 0.236 (in-sample avg dev_std = 0.416)
SUFF for r=0.6 class 2 = 0.631 +- 0.236 (in-sample avg dev_std = 0.416)
SUFF for r=0.6 all KL = 0.653 +- 0.236 (in-sample avg dev_std = 0.416)
SUFF for r=0.6 all L1 = 0.615 +- 0.199 (in-sample avg dev_std = 0.416)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.65
Model XAI F1 of binarized graphs for r=0.9 =  0.5792587499999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.41902750000000005
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.502
SUFF for r=0.9 class 0 = 0.664 +- 0.228 (in-sample avg dev_std = 0.233)
SUFF for r=0.9 class 1 = 0.914 +- 0.228 (in-sample avg dev_std = 0.233)
SUFF for r=0.9 class 2 = 0.657 +- 0.228 (in-sample avg dev_std = 0.233)
SUFF for r=0.9 all KL = 0.816 +- 0.228 (in-sample avg dev_std = 0.233)
SUFF for r=0.9 all L1 = 0.742 +- 0.238 (in-sample avg dev_std = 0.233)


ratio=1.0



Zero intervened samples, skipping weight=1.0


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
nec = [defaultdict(<class 'list'>, {'all_KL': [0.6, 0.659, 0.643, 0.622], 'all_L1': [0.562, 0.596, 0.572, 0.55]}), defaultdict(<class 'list'>, {'all_KL': [0.552, 0.614, 0.604, 0.54], 'all_L1': [0.576, 0.588, 0.561, 0.512]}), defaultdict(<class 'list'>, {'all_KL': [0.558, 0.61, 0.61, 0.589], 'all_L1': [0.572, 0.565, 0.557, 0.536]}), defaultdict(<class 'list'>, {'all_KL': [0.57, 0.615, 0.607, 0.6], 'all_L1': [0.58, 0.57, 0.547, 0.535]}), defaultdict(<class 'list'>, {'all_KL': [0.54, 0.637, 0.625, 0.596], 'all_L1': [0.549, 0.585, 0.566, 0.54]})]
suff = [defaultdict(<class 'list'>, {'all_KL': [0.42, 0.523, 0.825, 1.0], 'all_L1': [0.477, 0.554, 0.758, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.484, 0.624, 0.845, 1.0], 'all_L1': [0.466, 0.602, 0.774, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.438, 0.576, 0.84, 1.0], 'all_L1': [0.442, 0.584, 0.775, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.45, 0.591, 0.844, 1.0], 'all_L1': [0.452, 0.581, 0.773, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.501, 0.506, 0.773, 1.0], 'all_L1': [0.496, 0.529, 0.713, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]

Eval split val
nec = [defaultdict(<class 'list'>, {'all_KL': [0.645, 0.386, 0.327, 0.331], 'all_L1': [0.592, 0.378, 0.382, 0.375]}), defaultdict(<class 'list'>, {'all_KL': [0.662, 0.448, 0.259, 0.225], 'all_L1': [0.602, 0.422, 0.331, 0.305]}), defaultdict(<class 'list'>, {'all_KL': [0.698, 0.416, 0.229, 0.175], 'all_L1': [0.62, 0.4, 0.304, 0.255]}), defaultdict(<class 'list'>, {'all_KL': [0.62, 0.433, 0.265, 0.246], 'all_L1': [0.604, 0.402, 0.332, 0.327]}), defaultdict(<class 'list'>, {'all_KL': [0.576, 0.487, 0.257, 0.19], 'all_L1': [0.576, 0.452, 0.309, 0.249]})]
suff = [defaultdict(<class 'list'>, {'all_KL': [0.384, 0.444, 0.923, 1.0], 'all_L1': [0.441, 0.523, 0.809, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.361, 0.617, 0.921, 1.0], 'all_L1': [0.449, 0.634, 0.811, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.298, 0.539, 0.853, 1.0], 'all_L1': [0.401, 0.587, 0.742, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.385, 0.493, 0.927, 1.0], 'all_L1': [0.421, 0.552, 0.82, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.424, 0.596, 0.887, 1.0], 'all_L1': [0.44, 0.644, 0.776, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]

Eval split test
nec = [defaultdict(<class 'list'>, {'all_KL': [0.416, 0.661, 0.481, 0.432], 'all_L1': [0.422, 0.616, 0.5, 0.44]}), defaultdict(<class 'list'>, {'all_KL': [0.464, 0.55, 0.359, 0.3], 'all_L1': [0.548, 0.502, 0.404, 0.352]}), defaultdict(<class 'list'>, {'all_KL': [0.452, 0.577, 0.385, 0.3], 'all_L1': [0.543, 0.542, 0.408, 0.345]}), defaultdict(<class 'list'>, {'all_KL': [0.436, 0.557, 0.361, 0.317], 'all_L1': [0.532, 0.554, 0.419, 0.358]}), defaultdict(<class 'list'>, {'all_KL': [0.347, 0.61, 0.436, 0.346], 'all_L1': [0.444, 0.58, 0.449, 0.375]})]
suff = [defaultdict(<class 'list'>, {'all_KL': [0.605, 0.54, 0.801, 1.0], 'all_L1': [0.606, 0.542, 0.717, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.602, 0.794, 0.892, 1.0], 'all_L1': [0.504, 0.754, 0.796, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.559, 0.73, 0.881, 1.0], 'all_L1': [0.466, 0.686, 0.796, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.598, 0.674, 0.861, 1.0], 'all_L1': [0.493, 0.62, 0.766, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.7, 0.653, 0.816, 1.0], 'all_L1': [0.594, 0.615, 0.742, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
nec class all_KL  =  0.564 +- 0.020, 0.627 +- 0.019, 0.618 +- 0.015, 0.589 +- 0.027
nec class all_L1  =  0.568 +- 0.011, 0.581 +- 0.012, 0.561 +- 0.008, 0.535 +- 0.012
nec_acc_int  =  0.348 +- 0.015, 0.390 +- 0.018, 0.497 +- 0.013, 0.536 +- 0.015
suff class all_KL  =  0.459 +- 0.030, 0.564 +- 0.044, 0.825 +- 0.027, 1.000 +- 0.000
suff class all_L1  =  0.467 +- 0.019, 0.570 +- 0.026, 0.759 +- 0.024, 1.000 +- 0.000
suff class 0  =  1.000 +- 0.000
suff class 1  =  1.000 +- 0.000
suff class 2  =  1.000 +- 0.000
suff_acc_int  =  0.405 +- 0.023, 0.651 +- 0.022, 0.829 +- 0.033

Eval split val
nec class all_KL  =  0.640 +- 0.041, 0.434 +- 0.034, 0.267 +- 0.032, 0.233 +- 0.055
nec class all_L1  =  0.599 +- 0.015, 0.411 +- 0.025, 0.332 +- 0.028, 0.302 +- 0.047
nec_acc_int  =  0.262 +- 0.038, 0.450 +- 0.014, 0.599 +- 0.040, 0.593 +- 0.070
suff class all_KL  =  0.370 +- 0.041, 0.538 +- 0.064, 0.902 +- 0.028, 1.000 +- 0.000
suff class all_L1  =  0.430 +- 0.017, 0.588 +- 0.046, 0.792 +- 0.029, 1.000 +- 0.000
suff class 0  =  1.000 +- 0.000
suff class 1  =  1.000 +- 0.000
suff class 2  =  1.000 +- 0.000
suff_acc_int  =  0.378 +- 0.039, 0.802 +- 0.020, 0.878 +- 0.040

Eval split test
nec class all_KL  =  0.423 +- 0.041, 0.591 +- 0.041, 0.404 +- 0.047, 0.339 +- 0.049
nec class all_L1  =  0.498 +- 0.054, 0.559 +- 0.038, 0.436 +- 0.036, 0.374 +- 0.034
nec_acc_int  =  0.308 +- 0.032, 0.478 +- 0.016, 0.552 +- 0.017, 0.540 +- 0.011
suff class all_KL  =  0.613 +- 0.047, 0.678 +- 0.085, 0.850 +- 0.036, 1.000 +- 0.000
suff class all_L1  =  0.533 +- 0.057, 0.643 +- 0.072, 0.763 +- 0.031, 1.000 +- 0.000
suff class 0  =  1.000 +- 0.000
suff class 1  =  1.000 +- 0.000
suff class 2  =  1.000 +- 0.000
suff_acc_int  =  0.329 +- 0.009, 0.512 +- 0.065, 0.547 +- 0.025


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
torch.Size([5, 4]) torch.Size([5, 4])
torch.Size([5, 4])
Faith. Aritm= 		  =  0.517 +- 0.006, 0.575 +- 0.012, 0.660 +- 0.010, 0.767 +- 0.006
Faith. Armon= 		  =  0.512 +- 0.008, 0.575 +- 0.012, 0.644 +- 0.008, 0.697 +- 0.011
Faith. GMean = 	  =  0.515 +- 0.007, 0.575 +- 0.012, 0.652 +- 0.009, 0.731 +- 0.009

Eval split val
torch.Size([5, 4]) torch.Size([5, 4])
torch.Size([5, 4])
Faith. Aritm= 		  =  0.515 +- 0.006, 0.499 +- 0.035, 0.562 +- 0.026, 0.651 +- 0.023
Faith. Armon= 		  =  0.500 +- 0.009, 0.484 +- 0.032, 0.467 +- 0.030, 0.462 +- 0.055
Faith. GMean = 	  =  0.507 +- 0.007, 0.491 +- 0.034, 0.512 +- 0.028, 0.548 +- 0.042

Eval split test
torch.Size([5, 4]) torch.Size([5, 4])
torch.Size([5, 4])
Faith. Aritm= 		  =  0.515 +- 0.007, 0.601 +- 0.018, 0.600 +- 0.006, 0.687 +- 0.017
Faith. Armon= 		  =  0.509 +- 0.010, 0.593 +- 0.011, 0.553 +- 0.020, 0.544 +- 0.035
Faith. GMean = 	  =  0.512 +- 0.008, 0.597 +- 0.014, 0.576 +- 0.012, 0.611 +- 0.027
Computed for split load_split = id



Completed in  0:19:58.578553  for GSATGIN GOODMotif/basis



DONE GSAT GOODMotif/basis

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Mar 20 14:42:00 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:42:00 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 102...
[0m[1;37mINFO[0m: [1mCheckpoint 102: 
-----------------------------------
Train ACCURACY: 0.8846
Train Loss: 0.4663
ID Validation ACCURACY: 0.8883
ID Validation Loss: 0.4567
ID Test ACCURACY: 0.8753
ID Test Loss: 0.4923
OOD Validation ACCURACY: 0.8767
OOD Validation Loss: 0.5561
OOD Test ACCURACY: 0.8990
OOD Test Loss: 0.4482

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 149...
[0m[1;37mINFO[0m: [1mCheckpoint 149: 
-----------------------------------
Train ACCURACY: 0.8700
Train Loss: 0.4809
ID Validation ACCURACY: 0.8710
ID Validation Loss: 0.4691
ID Test ACCURACY: 0.8660
ID Test Loss: 0.5000
OOD Validation ACCURACY: 0.9313
OOD Validation Loss: 0.4306
OOD Test ACCURACY: 0.6947
OOD Test Loss: 0.8828

[0m[1;37mINFO[0m: [1mChartInfo 0.8753 0.8990 0.8660 0.6947 0.8710 0.9313[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.714
WIoU for r=0.3 = 0.664
F1 for r=0.6 = 0.625
WIoU for r=0.6 = 0.747
F1 for r=0.9 = 0.481
WIoU for r=0.9 = 0.741
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.741
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.668
WIoU for r=0.3 = 0.989
F1 for r=0.6 = 0.409
WIoU for r=0.6 = 0.989
F1 for r=0.9 = 0.295
WIoU for r=0.9 = 0.989
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.989
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.782
WIoU for r=0.3 = 0.908
F1 for r=0.6 = 0.565
WIoU for r=0.6 = 0.958
F1 for r=0.9 = 0.424
WIoU for r=0.9 = 0.956
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.956
Size bank for r=0.3 -> 1500
Size bank for r=0.6 -> 1500
Size bank for r=0.9 -> 1355


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.527
Model XAI F1 of binarized graphs for r=0.3 =  0.71358375
Model XAI WIoU of binarized graphs for r=0.3 =  0.6644225
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.372
NEC for r=0.3 class 0 = 0.563 +- 0.292 (in-sample avg dev_std = 0.438)
NEC for r=0.3 class 1 = 0.509 +- 0.292 (in-sample avg dev_std = 0.438)
NEC for r=0.3 class 2 = 0.577 +- 0.292 (in-sample avg dev_std = 0.438)
NEC for r=0.3 all KL = 0.588 +- 0.292 (in-sample avg dev_std = 0.438)
NEC for r=0.3 all L1 = 0.55 +- 0.172 (in-sample avg dev_std = 0.438)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.892
Model XAI F1 of binarized graphs for r=0.6 =  0.62462125
Model XAI WIoU of binarized graphs for r=0.6 =  0.74658125
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.495
NEC for r=0.6 class 0 = 0.592 +- 0.317 (in-sample avg dev_std = 0.478)
NEC for r=0.6 class 1 = 0.421 +- 0.317 (in-sample avg dev_std = 0.478)
NEC for r=0.6 class 2 = 0.599 +- 0.317 (in-sample avg dev_std = 0.478)
NEC for r=0.6 all KL = 0.545 +- 0.317 (in-sample avg dev_std = 0.478)
NEC for r=0.6 all L1 = 0.537 +- 0.180 (in-sample avg dev_std = 0.478)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.897
Model XAI F1 of binarized graphs for r=0.9 =  0.4814387499999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.7407374999999999
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.595
NEC for r=0.9 class 0 = 0.52 +- 0.302 (in-sample avg dev_std = 0.513)
NEC for r=0.9 class 1 = 0.396 +- 0.302 (in-sample avg dev_std = 0.513)
NEC for r=0.9 class 2 = 0.507 +- 0.302 (in-sample avg dev_std = 0.513)
NEC for r=0.9 all KL = 0.466 +- 0.302 (in-sample avg dev_std = 0.513)
NEC for r=0.9 all L1 = 0.474 +- 0.171 (in-sample avg dev_std = 0.513)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.9
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.7406275
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.603
NEC for r=1.0 class 0 = 0.51 +- 0.296 (in-sample avg dev_std = 0.516)
NEC for r=1.0 class 1 = 0.396 +- 0.296 (in-sample avg dev_std = 0.516)
NEC for r=1.0 class 2 = 0.512 +- 0.296 (in-sample avg dev_std = 0.516)
NEC for r=1.0 all KL = 0.463 +- 0.296 (in-sample avg dev_std = 0.516)
NEC for r=1.0 all L1 = 0.472 +- 0.161 (in-sample avg dev_std = 0.516)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.877
Model XAI F1 of binarized graphs for r=0.3 =  0.668295
Model XAI WIoU of binarized graphs for r=0.3 =  0.9887725
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.376
NEC for r=0.3 class 0 = 0.675 +- 0.282 (in-sample avg dev_std = 0.424)
NEC for r=0.3 class 1 = 0.507 +- 0.282 (in-sample avg dev_std = 0.424)
NEC for r=0.3 class 2 = 0.705 +- 0.282 (in-sample avg dev_std = 0.424)
NEC for r=0.3 all KL = 0.645 +- 0.282 (in-sample avg dev_std = 0.424)
NEC for r=0.3 all L1 = 0.63 +- 0.133 (in-sample avg dev_std = 0.424)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  0.40889125
Model XAI WIoU of binarized graphs for r=0.6 =  0.9887725
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.502
NEC for r=0.6 class 0 = 0.523 +- 0.217 (in-sample avg dev_std = 0.469)
NEC for r=0.6 class 1 = 0.477 +- 0.217 (in-sample avg dev_std = 0.469)
NEC for r=0.6 class 2 = 0.561 +- 0.217 (in-sample avg dev_std = 0.469)
NEC for r=0.6 all KL = 0.44 +- 0.217 (in-sample avg dev_std = 0.469)
NEC for r=0.6 all L1 = 0.521 +- 0.113 (in-sample avg dev_std = 0.469)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.884
Model XAI F1 of binarized graphs for r=0.9 =  0.29531124999999997
Model XAI WIoU of binarized graphs for r=0.9 =  0.9887762500000001
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.556
NEC for r=0.9 class 0 = 0.455 +- 0.195 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 1 = 0.424 +- 0.195 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 2 = 0.497 +- 0.195 (in-sample avg dev_std = 0.426)
NEC for r=0.9 all KL = 0.341 +- 0.195 (in-sample avg dev_std = 0.426)
NEC for r=0.9 all L1 = 0.459 +- 0.117 (in-sample avg dev_std = 0.426)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.884
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.9887762500000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.569
NEC for r=1.0 class 0 = 0.448 +- 0.195 (in-sample avg dev_std = 0.425)
NEC for r=1.0 class 1 = 0.425 +- 0.195 (in-sample avg dev_std = 0.425)
NEC for r=1.0 class 2 = 0.485 +- 0.195 (in-sample avg dev_std = 0.425)
NEC for r=1.0 all KL = 0.334 +- 0.195 (in-sample avg dev_std = 0.425)
NEC for r=1.0 all L1 = 0.453 +- 0.118 (in-sample avg dev_std = 0.425)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.699
Model XAI F1 of binarized graphs for r=0.3 =  0.7824275
Model XAI WIoU of binarized graphs for r=0.3 =  0.90822125
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.377
NEC for r=0.3 class 0 = 0.659 +- 0.299 (in-sample avg dev_std = 0.482)
NEC for r=0.3 class 1 = 0.473 +- 0.299 (in-sample avg dev_std = 0.482)
NEC for r=0.3 class 2 = 0.629 +- 0.299 (in-sample avg dev_std = 0.482)
NEC for r=0.3 all KL = 0.658 +- 0.299 (in-sample avg dev_std = 0.482)
NEC for r=0.3 all L1 = 0.585 +- 0.153 (in-sample avg dev_std = 0.482)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.899
Model XAI F1 of binarized graphs for r=0.6 =  0.5651437500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.95768625
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.552
NEC for r=0.6 class 0 = 0.516 +- 0.353 (in-sample avg dev_std = 0.499)
NEC for r=0.6 class 1 = 0.339 +- 0.353 (in-sample avg dev_std = 0.499)
NEC for r=0.6 class 2 = 0.542 +- 0.353 (in-sample avg dev_std = 0.499)
NEC for r=0.6 all KL = 0.501 +- 0.353 (in-sample avg dev_std = 0.499)
NEC for r=0.6 all L1 = 0.464 +- 0.206 (in-sample avg dev_std = 0.499)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.899
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.95569125
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.65
NEC for r=0.9 class 0 = 0.422 +- 0.318 (in-sample avg dev_std = 0.531)
NEC for r=0.9 class 1 = 0.286 +- 0.318 (in-sample avg dev_std = 0.531)
NEC for r=0.9 class 2 = 0.439 +- 0.318 (in-sample avg dev_std = 0.531)
NEC for r=0.9 all KL = 0.405 +- 0.318 (in-sample avg dev_std = 0.531)
NEC for r=0.9 all L1 = 0.381 +- 0.191 (in-sample avg dev_std = 0.531)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.899
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.95569125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.678
NEC for r=1.0 class 0 = 0.395 +- 0.316 (in-sample avg dev_std = 0.527)
NEC for r=1.0 class 1 = 0.284 +- 0.316 (in-sample avg dev_std = 0.527)
NEC for r=1.0 class 2 = 0.432 +- 0.316 (in-sample avg dev_std = 0.527)
NEC for r=1.0 all KL = 0.393 +- 0.316 (in-sample avg dev_std = 0.527)
NEC for r=1.0 all L1 = 0.369 +- 0.190 (in-sample avg dev_std = 0.527)


Evaluating SUFF for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.527
Model XAI F1 of binarized graphs for r=0.3 =  0.71358375
Model XAI WIoU of binarized graphs for r=0.3 =  0.6644225
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.548
SUFF for r=0.3 class 0 = 0.542 +- 0.295 (in-sample avg dev_std = 0.501)
SUFF for r=0.3 class 1 = 0.543 +- 0.295 (in-sample avg dev_std = 0.501)
SUFF for r=0.3 class 2 = 0.523 +- 0.295 (in-sample avg dev_std = 0.501)
SUFF for r=0.3 all KL = 0.491 +- 0.295 (in-sample avg dev_std = 0.501)
SUFF for r=0.3 all L1 = 0.536 +- 0.187 (in-sample avg dev_std = 0.501)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.892
Model XAI F1 of binarized graphs for r=0.6 =  0.62462125
Model XAI WIoU of binarized graphs for r=0.6 =  0.74658125
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.781
SUFF for r=0.6 class 0 = 0.692 +- 0.206 (in-sample avg dev_std = 0.313)
SUFF for r=0.6 class 1 = 0.66 +- 0.206 (in-sample avg dev_std = 0.313)
SUFF for r=0.6 class 2 = 0.665 +- 0.206 (in-sample avg dev_std = 0.313)
SUFF for r=0.6 all KL = 0.721 +- 0.206 (in-sample avg dev_std = 0.313)
SUFF for r=0.6 all L1 = 0.672 +- 0.177 (in-sample avg dev_std = 0.313)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.897
Model XAI F1 of binarized graphs for r=0.9 =  0.4814387499999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.7407374999999999
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.858
SUFF for r=0.9 class 0 = 0.805 +- 0.159 (in-sample avg dev_std = 0.213)
SUFF for r=0.9 class 1 = 0.713 +- 0.159 (in-sample avg dev_std = 0.213)
SUFF for r=0.9 class 2 = 0.83 +- 0.159 (in-sample avg dev_std = 0.213)
SUFF for r=0.9 all KL = 0.873 +- 0.159 (in-sample avg dev_std = 0.213)
SUFF for r=0.9 all L1 = 0.782 +- 0.164 (in-sample avg dev_std = 0.213)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.877
Model XAI F1 of binarized graphs for r=0.3 =  0.668295
Model XAI WIoU of binarized graphs for r=0.3 =  0.9887725
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.761
SUFF for r=0.3 class 0 = 0.619 +- 0.261 (in-sample avg dev_std = 0.442)
SUFF for r=0.3 class 1 = 0.624 +- 0.261 (in-sample avg dev_std = 0.442)
SUFF for r=0.3 class 2 = 0.651 +- 0.261 (in-sample avg dev_std = 0.442)
SUFF for r=0.3 all KL = 0.643 +- 0.261 (in-sample avg dev_std = 0.442)
SUFF for r=0.3 all L1 = 0.632 +- 0.167 (in-sample avg dev_std = 0.442)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.882
Model XAI F1 of binarized graphs for r=0.6 =  0.40889125
Model XAI WIoU of binarized graphs for r=0.6 =  0.9887725
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.755
SUFF for r=0.6 class 0 = 0.64 +- 0.173 (in-sample avg dev_std = 0.305)
SUFF for r=0.6 class 1 = 0.645 +- 0.173 (in-sample avg dev_std = 0.305)
SUFF for r=0.6 class 2 = 0.617 +- 0.173 (in-sample avg dev_std = 0.305)
SUFF for r=0.6 all KL = 0.762 +- 0.173 (in-sample avg dev_std = 0.305)
SUFF for r=0.6 all L1 = 0.634 +- 0.134 (in-sample avg dev_std = 0.305)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.884
Model XAI F1 of binarized graphs for r=0.9 =  0.29531124999999997
Model XAI WIoU of binarized graphs for r=0.9 =  0.9887762500000001
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.818
SUFF for r=0.9 class 0 = 0.786 +- 0.131 (in-sample avg dev_std = 0.168)
SUFF for r=0.9 class 1 = 0.781 +- 0.131 (in-sample avg dev_std = 0.168)
SUFF for r=0.9 class 2 = 0.802 +- 0.131 (in-sample avg dev_std = 0.168)
SUFF for r=0.9 all KL = 0.913 +- 0.131 (in-sample avg dev_std = 0.168)
SUFF for r=0.9 all L1 = 0.79 +- 0.152 (in-sample avg dev_std = 0.168)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.699
Model XAI F1 of binarized graphs for r=0.3 =  0.7824275
Model XAI WIoU of binarized graphs for r=0.3 =  0.90822125
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.642
SUFF for r=0.3 class 0 = 0.514 +- 0.318 (in-sample avg dev_std = 0.525)
SUFF for r=0.3 class 1 = 0.64 +- 0.318 (in-sample avg dev_std = 0.525)
SUFF for r=0.3 class 2 = 0.493 +- 0.318 (in-sample avg dev_std = 0.525)
SUFF for r=0.3 all KL = 0.481 +- 0.318 (in-sample avg dev_std = 0.525)
SUFF for r=0.3 all L1 = 0.55 +- 0.194 (in-sample avg dev_std = 0.525)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.899
Model XAI F1 of binarized graphs for r=0.6 =  0.5651437500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.95768625
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.799
SUFF for r=0.6 class 0 = 0.685 +- 0.165 (in-sample avg dev_std = 0.277)
SUFF for r=0.6 class 1 = 0.67 +- 0.165 (in-sample avg dev_std = 0.277)
SUFF for r=0.6 class 2 = 0.714 +- 0.165 (in-sample avg dev_std = 0.277)
SUFF for r=0.6 all KL = 0.746 +- 0.165 (in-sample avg dev_std = 0.277)
SUFF for r=0.6 all L1 = 0.689 +- 0.167 (in-sample avg dev_std = 0.277)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.899
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.95569125
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.877
SUFF for r=0.9 class 0 = 0.849 +- 0.140 (in-sample avg dev_std = 0.132)
SUFF for r=0.9 class 1 = 0.81 +- 0.140 (in-sample avg dev_std = 0.132)
SUFF for r=0.9 class 2 = 0.818 +- 0.140 (in-sample avg dev_std = 0.132)
SUFF for r=0.9 all KL = 0.9 +- 0.140 (in-sample avg dev_std = 0.132)
SUFF for r=0.9 all L1 = 0.826 +- 0.143 (in-sample avg dev_std = 0.132)


ratio=1.0



Zero intervened samples, skipping weight=1.0

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Mar 20 14:47:08 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:47:08 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 110...
[0m[1;37mINFO[0m: [1mCheckpoint 110: 
-----------------------------------
Train ACCURACY: 0.8872
Train Loss: 0.4454
ID Validation ACCURACY: 0.8927
ID Validation Loss: 0.4356
ID Test ACCURACY: 0.8933
ID Test Loss: 0.4534
OOD Validation ACCURACY: 0.8837
OOD Validation Loss: 0.4829
OOD Test ACCURACY: 0.8907
OOD Test Loss: 0.4426

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 127...
[0m[1;37mINFO[0m: [1mCheckpoint 127: 
-----------------------------------
Train ACCURACY: 0.8367
Train Loss: 0.5254
ID Validation ACCURACY: 0.8440
ID Validation Loss: 0.5010
ID Test ACCURACY: 0.8350
ID Test Loss: 0.5355
OOD Validation ACCURACY: 0.9210
OOD Validation Loss: 0.5277
OOD Test ACCURACY: 0.8627
OOD Test Loss: 0.5303

[0m[1;37mINFO[0m: [1mChartInfo 0.8933 0.8907 0.8350 0.8627 0.8440 0.9210[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.736
WIoU for r=0.3 = 0.706
F1 for r=0.6 = 0.625
WIoU for r=0.6 = 0.774
F1 for r=0.9 = 0.481
WIoU for r=0.9 = 0.771
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.771
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.669
WIoU for r=0.3 = 0.994
F1 for r=0.6 = 0.409
WIoU for r=0.6 = 0.994
F1 for r=0.9 = 0.295
WIoU for r=0.9 = 0.994
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.994
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.726
WIoU for r=0.3 = 0.842
F1 for r=0.6 = 0.565
WIoU for r=0.6 = 0.846
F1 for r=0.9 = 0.424
WIoU for r=0.9 = 0.795
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.788
Size bank for r=0.3 -> 1500
Size bank for r=0.6 -> 1500
Size bank for r=0.9 -> 942


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.654
Model XAI F1 of binarized graphs for r=0.3 =  0.7361749999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.70589
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.375
NEC for r=0.3 class 0 = 0.554 +- 0.289 (in-sample avg dev_std = 0.390)
NEC for r=0.3 class 1 = 0.503 +- 0.289 (in-sample avg dev_std = 0.390)
NEC for r=0.3 class 2 = 0.587 +- 0.289 (in-sample avg dev_std = 0.390)
NEC for r=0.3 all KL = 0.603 +- 0.289 (in-sample avg dev_std = 0.390)
NEC for r=0.3 all L1 = 0.548 +- 0.157 (in-sample avg dev_std = 0.390)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.88
Model XAI F1 of binarized graphs for r=0.6 =  0.6250312499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.7738725
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.426
NEC for r=0.6 class 0 = 0.565 +- 0.306 (in-sample avg dev_std = 0.451)
NEC for r=0.6 class 1 = 0.531 +- 0.306 (in-sample avg dev_std = 0.451)
NEC for r=0.6 class 2 = 0.621 +- 0.306 (in-sample avg dev_std = 0.451)
NEC for r=0.6 all KL = 0.614 +- 0.306 (in-sample avg dev_std = 0.451)
NEC for r=0.6 all L1 = 0.572 +- 0.160 (in-sample avg dev_std = 0.451)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.894
Model XAI F1 of binarized graphs for r=0.9 =  0.48110875
Model XAI WIoU of binarized graphs for r=0.9 =  0.7711312499999999
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.52
NEC for r=0.9 class 0 = 0.511 +- 0.282 (in-sample avg dev_std = 0.500)
NEC for r=0.9 class 1 = 0.478 +- 0.282 (in-sample avg dev_std = 0.500)
NEC for r=0.9 class 2 = 0.559 +- 0.282 (in-sample avg dev_std = 0.500)
NEC for r=0.9 all KL = 0.521 +- 0.282 (in-sample avg dev_std = 0.500)
NEC for r=0.9 all L1 = 0.516 +- 0.159 (in-sample avg dev_std = 0.500)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.897
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.77129875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.525
NEC for r=1.0 class 0 = 0.51 +- 0.279 (in-sample avg dev_std = 0.499)
NEC for r=1.0 class 1 = 0.482 +- 0.279 (in-sample avg dev_std = 0.499)
NEC for r=1.0 class 2 = 0.543 +- 0.279 (in-sample avg dev_std = 0.499)
NEC for r=1.0 all KL = 0.515 +- 0.279 (in-sample avg dev_std = 0.499)
NEC for r=1.0 all L1 = 0.511 +- 0.158 (in-sample avg dev_std = 0.499)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.894
Model XAI F1 of binarized graphs for r=0.3 =  0.6689275000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.99412375
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.376
NEC for r=0.3 class 0 = 0.656 +- 0.279 (in-sample avg dev_std = 0.449)
NEC for r=0.3 class 1 = 0.511 +- 0.279 (in-sample avg dev_std = 0.449)
NEC for r=0.3 class 2 = 0.734 +- 0.279 (in-sample avg dev_std = 0.449)
NEC for r=0.3 all KL = 0.676 +- 0.279 (in-sample avg dev_std = 0.449)
NEC for r=0.3 all L1 = 0.635 +- 0.145 (in-sample avg dev_std = 0.449)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.892
Model XAI F1 of binarized graphs for r=0.6 =  0.40945499999999996
Model XAI WIoU of binarized graphs for r=0.6 =  0.99422125
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.481
NEC for r=0.6 class 0 = 0.542 +- 0.221 (in-sample avg dev_std = 0.475)
NEC for r=0.6 class 1 = 0.47 +- 0.221 (in-sample avg dev_std = 0.475)
NEC for r=0.6 class 2 = 0.569 +- 0.221 (in-sample avg dev_std = 0.475)
NEC for r=0.6 all KL = 0.444 +- 0.221 (in-sample avg dev_std = 0.475)
NEC for r=0.6 all L1 = 0.527 +- 0.121 (in-sample avg dev_std = 0.475)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.894
Model XAI F1 of binarized graphs for r=0.9 =  0.295315
Model XAI WIoU of binarized graphs for r=0.9 =  0.9942025000000001
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.553
NEC for r=0.9 class 0 = 0.473 +- 0.195 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 1 = 0.433 +- 0.195 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 2 = 0.478 +- 0.195 (in-sample avg dev_std = 0.447)
NEC for r=0.9 all KL = 0.342 +- 0.195 (in-sample avg dev_std = 0.447)
NEC for r=0.9 all L1 = 0.462 +- 0.116 (in-sample avg dev_std = 0.447)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.894
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.9941987499999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.555
NEC for r=1.0 class 0 = 0.47 +- 0.192 (in-sample avg dev_std = 0.441)
NEC for r=1.0 class 1 = 0.423 +- 0.192 (in-sample avg dev_std = 0.441)
NEC for r=1.0 class 2 = 0.478 +- 0.192 (in-sample avg dev_std = 0.441)
NEC for r=1.0 all KL = 0.334 +- 0.192 (in-sample avg dev_std = 0.441)
NEC for r=1.0 all L1 = 0.457 +- 0.115 (in-sample avg dev_std = 0.441)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.56
Model XAI F1 of binarized graphs for r=0.3 =  0.7263150000000002
Model XAI WIoU of binarized graphs for r=0.3 =  0.8424875000000001
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.445
NEC for r=0.3 class 0 = 0.486 +- 0.220 (in-sample avg dev_std = 0.470)
NEC for r=0.3 class 1 = 0.503 +- 0.220 (in-sample avg dev_std = 0.470)
NEC for r=0.3 class 2 = 0.576 +- 0.220 (in-sample avg dev_std = 0.470)
NEC for r=0.3 all KL = 0.478 +- 0.220 (in-sample avg dev_std = 0.470)
NEC for r=0.3 all L1 = 0.522 +- 0.127 (in-sample avg dev_std = 0.470)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.891
Model XAI F1 of binarized graphs for r=0.6 =  0.5651437500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.8456575000000001
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.534
NEC for r=0.6 class 0 = 0.442 +- 0.347 (in-sample avg dev_std = 0.529)
NEC for r=0.6 class 1 = 0.46 +- 0.347 (in-sample avg dev_std = 0.529)
NEC for r=0.6 class 2 = 0.531 +- 0.347 (in-sample avg dev_std = 0.529)
NEC for r=0.6 all KL = 0.477 +- 0.347 (in-sample avg dev_std = 0.529)
NEC for r=0.6 all L1 = 0.478 +- 0.202 (in-sample avg dev_std = 0.529)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.891
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.7951375000000002
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.604
NEC for r=0.9 class 0 = 0.414 +- 0.330 (in-sample avg dev_std = 0.576)
NEC for r=0.9 class 1 = 0.442 +- 0.330 (in-sample avg dev_std = 0.576)
NEC for r=0.9 class 2 = 0.443 +- 0.330 (in-sample avg dev_std = 0.576)
NEC for r=0.9 all KL = 0.446 +- 0.330 (in-sample avg dev_std = 0.576)
NEC for r=0.9 all L1 = 0.433 +- 0.193 (in-sample avg dev_std = 0.576)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.891
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.7882975000000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.603
NEC for r=1.0 class 0 = 0.419 +- 0.324 (in-sample avg dev_std = 0.576)
NEC for r=1.0 class 1 = 0.435 +- 0.324 (in-sample avg dev_std = 0.576)
NEC for r=1.0 class 2 = 0.44 +- 0.324 (in-sample avg dev_std = 0.576)
NEC for r=1.0 all KL = 0.444 +- 0.324 (in-sample avg dev_std = 0.576)
NEC for r=1.0 all L1 = 0.431 +- 0.186 (in-sample avg dev_std = 0.576)


Evaluating SUFF for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.65
Model XAI F1 of binarized graphs for r=0.3 =  0.7361749999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.70589
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.514
SUFF for r=0.3 class 0 = 0.51 +- 0.262 (in-sample avg dev_std = 0.504)
SUFF for r=0.3 class 1 = 0.646 +- 0.262 (in-sample avg dev_std = 0.504)
SUFF for r=0.3 class 2 = 0.525 +- 0.262 (in-sample avg dev_std = 0.504)
SUFF for r=0.3 all KL = 0.502 +- 0.262 (in-sample avg dev_std = 0.504)
SUFF for r=0.3 all L1 = 0.561 +- 0.154 (in-sample avg dev_std = 0.504)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.88
Model XAI F1 of binarized graphs for r=0.6 =  0.6250312499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.7738725
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.738
SUFF for r=0.6 class 0 = 0.615 +- 0.239 (in-sample avg dev_std = 0.430)
SUFF for r=0.6 class 1 = 0.635 +- 0.239 (in-sample avg dev_std = 0.430)
SUFF for r=0.6 class 2 = 0.666 +- 0.239 (in-sample avg dev_std = 0.430)
SUFF for r=0.6 all KL = 0.625 +- 0.239 (in-sample avg dev_std = 0.430)
SUFF for r=0.6 all L1 = 0.639 +- 0.177 (in-sample avg dev_std = 0.430)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.894
Model XAI F1 of binarized graphs for r=0.9 =  0.48110875
Model XAI WIoU of binarized graphs for r=0.9 =  0.7711312499999999
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.834
SUFF for r=0.9 class 0 = 0.734 +- 0.216 (in-sample avg dev_std = 0.210)
SUFF for r=0.9 class 1 = 0.783 +- 0.216 (in-sample avg dev_std = 0.210)
SUFF for r=0.9 class 2 = 0.784 +- 0.216 (in-sample avg dev_std = 0.210)
SUFF for r=0.9 all KL = 0.839 +- 0.216 (in-sample avg dev_std = 0.210)
SUFF for r=0.9 all L1 = 0.767 +- 0.191 (in-sample avg dev_std = 0.210)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.894
Model XAI F1 of binarized graphs for r=0.3 =  0.6689275000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.99412375
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.628
SUFF for r=0.3 class 0 = 0.476 +- 0.284 (in-sample avg dev_std = 0.571)
SUFF for r=0.3 class 1 = 0.651 +- 0.284 (in-sample avg dev_std = 0.571)
SUFF for r=0.3 class 2 = 0.496 +- 0.284 (in-sample avg dev_std = 0.571)
SUFF for r=0.3 all KL = 0.493 +- 0.284 (in-sample avg dev_std = 0.571)
SUFF for r=0.3 all L1 = 0.54 +- 0.173 (in-sample avg dev_std = 0.571)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.892
Model XAI F1 of binarized graphs for r=0.6 =  0.40945499999999996
Model XAI WIoU of binarized graphs for r=0.6 =  0.99422125
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.727
SUFF for r=0.6 class 0 = 0.572 +- 0.162 (in-sample avg dev_std = 0.368)
SUFF for r=0.6 class 1 = 0.628 +- 0.162 (in-sample avg dev_std = 0.368)
SUFF for r=0.6 class 2 = 0.646 +- 0.162 (in-sample avg dev_std = 0.368)
SUFF for r=0.6 all KL = 0.735 +- 0.162 (in-sample avg dev_std = 0.368)
SUFF for r=0.6 all L1 = 0.615 +- 0.118 (in-sample avg dev_std = 0.368)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.894
Model XAI F1 of binarized graphs for r=0.9 =  0.295315
Model XAI WIoU of binarized graphs for r=0.9 =  0.9942025000000001
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.821
SUFF for r=0.9 class 0 = 0.759 +- 0.118 (in-sample avg dev_std = 0.238)
SUFF for r=0.9 class 1 = 0.746 +- 0.118 (in-sample avg dev_std = 0.238)
SUFF for r=0.9 class 2 = 0.724 +- 0.118 (in-sample avg dev_std = 0.238)
SUFF for r=0.9 all KL = 0.885 +- 0.118 (in-sample avg dev_std = 0.238)
SUFF for r=0.9 all L1 = 0.743 +- 0.128 (in-sample avg dev_std = 0.238)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.56
Model XAI F1 of binarized graphs for r=0.3 =  0.7263150000000002
Model XAI WIoU of binarized graphs for r=0.3 =  0.8424875000000001
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.565
SUFF for r=0.3 class 0 = 0.542 +- 0.218 (in-sample avg dev_std = 0.486)
SUFF for r=0.3 class 1 = 0.573 +- 0.218 (in-sample avg dev_std = 0.486)
SUFF for r=0.3 class 2 = 0.54 +- 0.218 (in-sample avg dev_std = 0.486)
SUFF for r=0.3 all KL = 0.587 +- 0.218 (in-sample avg dev_std = 0.486)
SUFF for r=0.3 all L1 = 0.552 +- 0.150 (in-sample avg dev_std = 0.486)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.891
Model XAI F1 of binarized graphs for r=0.6 =  0.5651437500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.8456575000000001
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.764
SUFF for r=0.6 class 0 = 0.612 +- 0.209 (in-sample avg dev_std = 0.419)
SUFF for r=0.6 class 1 = 0.594 +- 0.209 (in-sample avg dev_std = 0.419)
SUFF for r=0.6 class 2 = 0.683 +- 0.209 (in-sample avg dev_std = 0.419)
SUFF for r=0.6 all KL = 0.654 +- 0.209 (in-sample avg dev_std = 0.419)
SUFF for r=0.6 all L1 = 0.629 +- 0.142 (in-sample avg dev_std = 0.419)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.891
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.7951375000000002
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.788
SUFF for r=0.9 class 0 = 0.637 +- 0.303 (in-sample avg dev_std = 0.403)
SUFF for r=0.9 class 1 = 0.68 +- 0.303 (in-sample avg dev_std = 0.403)
SUFF for r=0.9 class 2 = 0.813 +- 0.303 (in-sample avg dev_std = 0.403)
SUFF for r=0.9 all KL = 0.729 +- 0.303 (in-sample avg dev_std = 0.403)
SUFF for r=0.9 all L1 = 0.711 +- 0.204 (in-sample avg dev_std = 0.403)


ratio=1.0



Zero intervened samples, skipping weight=1.0

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Mar 20 14:51:28 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:51:28 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 138...
[0m[1;37mINFO[0m: [1mCheckpoint 138: 
-----------------------------------
Train ACCURACY: 0.9123
Train Loss: 0.4007
ID Validation ACCURACY: 0.9150
ID Validation Loss: 0.3813
ID Test ACCURACY: 0.9053
ID Test Loss: 0.4430
OOD Validation ACCURACY: 0.9293
OOD Validation Loss: 0.3879
OOD Test ACCURACY: 0.7097
OOD Test Loss: 0.7779

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 129...
[0m[1;37mINFO[0m: [1mCheckpoint 129: 
-----------------------------------
Train ACCURACY: 0.8903
Train Loss: 0.4322
ID Validation ACCURACY: 0.8910
ID Validation Loss: 0.4222
ID Test ACCURACY: 0.8893
ID Test Loss: 0.4666
OOD Validation ACCURACY: 0.9303
OOD Validation Loss: 0.3953
OOD Test ACCURACY: 0.8417
OOD Test Loss: 0.6994

[0m[1;37mINFO[0m: [1mChartInfo 0.9053 0.7097 0.8893 0.8417 0.8910 0.9303[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.678
WIoU for r=0.3 = 0.597
F1 for r=0.6 = 0.610
WIoU for r=0.6 = 0.691
F1 for r=0.9 = 0.481
WIoU for r=0.9 = 0.703
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.703
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.669
WIoU for r=0.3 = 0.994
F1 for r=0.6 = 0.410
WIoU for r=0.6 = 0.994
F1 for r=0.9 = 0.295
WIoU for r=0.9 = 0.994
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.994
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.782
WIoU for r=0.3 = 0.880
F1 for r=0.6 = 0.544
WIoU for r=0.6 = 0.750
F1 for r=0.9 = 0.424
WIoU for r=0.9 = 0.694
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.691
Size bank for r=0.3 -> 1500
Size bank for r=0.6 -> 1500
Size bank for r=0.9 -> 1082


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.504
Model XAI F1 of binarized graphs for r=0.3 =  0.678015
Model XAI WIoU of binarized graphs for r=0.3 =  0.5967325
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.34
NEC for r=0.3 class 0 = 0.585 +- 0.282 (in-sample avg dev_std = 0.459)
NEC for r=0.3 class 1 = 0.544 +- 0.282 (in-sample avg dev_std = 0.459)
NEC for r=0.3 class 2 = 0.576 +- 0.282 (in-sample avg dev_std = 0.459)
NEC for r=0.3 all KL = 0.607 +- 0.282 (in-sample avg dev_std = 0.459)
NEC for r=0.3 all L1 = 0.568 +- 0.164 (in-sample avg dev_std = 0.459)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.86
Model XAI F1 of binarized graphs for r=0.6 =  0.61004875
Model XAI WIoU of binarized graphs for r=0.6 =  0.6905325000000001
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.442
NEC for r=0.6 class 0 = 0.581 +- 0.282 (in-sample avg dev_std = 0.539)
NEC for r=0.6 class 1 = 0.516 +- 0.282 (in-sample avg dev_std = 0.539)
NEC for r=0.6 class 2 = 0.634 +- 0.282 (in-sample avg dev_std = 0.539)
NEC for r=0.6 all KL = 0.639 +- 0.282 (in-sample avg dev_std = 0.539)
NEC for r=0.6 all L1 = 0.576 +- 0.166 (in-sample avg dev_std = 0.539)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.923
Model XAI F1 of binarized graphs for r=0.9 =  0.48117374999999996
Model XAI WIoU of binarized graphs for r=0.9 =  0.70282375
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.53
NEC for r=0.9 class 0 = 0.532 +- 0.293 (in-sample avg dev_std = 0.577)
NEC for r=0.9 class 1 = 0.477 +- 0.293 (in-sample avg dev_std = 0.577)
NEC for r=0.9 class 2 = 0.571 +- 0.293 (in-sample avg dev_std = 0.577)
NEC for r=0.9 all KL = 0.569 +- 0.293 (in-sample avg dev_std = 0.577)
NEC for r=0.9 all L1 = 0.526 +- 0.168 (in-sample avg dev_std = 0.577)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.926
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.7028725
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.552
NEC for r=1.0 class 0 = 0.527 +- 0.285 (in-sample avg dev_std = 0.577)
NEC for r=1.0 class 1 = 0.469 +- 0.285 (in-sample avg dev_std = 0.577)
NEC for r=1.0 class 2 = 0.553 +- 0.285 (in-sample avg dev_std = 0.577)
NEC for r=1.0 all KL = 0.555 +- 0.285 (in-sample avg dev_std = 0.577)
NEC for r=1.0 all L1 = 0.516 +- 0.163 (in-sample avg dev_std = 0.577)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.928
Model XAI F1 of binarized graphs for r=0.3 =  0.6694275000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.9939325
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.383
NEC for r=0.3 class 0 = 0.669 +- 0.220 (in-sample avg dev_std = 0.490)
NEC for r=0.3 class 1 = 0.568 +- 0.220 (in-sample avg dev_std = 0.490)
NEC for r=0.3 class 2 = 0.771 +- 0.220 (in-sample avg dev_std = 0.490)
NEC for r=0.3 all KL = 0.779 +- 0.220 (in-sample avg dev_std = 0.490)
NEC for r=0.3 all L1 = 0.67 +- 0.126 (in-sample avg dev_std = 0.490)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.928
Model XAI F1 of binarized graphs for r=0.6 =  0.40952875000000005
Model XAI WIoU of binarized graphs for r=0.6 =  0.9939325
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.516
NEC for r=0.6 class 0 = 0.528 +- 0.245 (in-sample avg dev_std = 0.556)
NEC for r=0.6 class 1 = 0.468 +- 0.245 (in-sample avg dev_std = 0.556)
NEC for r=0.6 class 2 = 0.634 +- 0.245 (in-sample avg dev_std = 0.556)
NEC for r=0.6 all KL = 0.526 +- 0.245 (in-sample avg dev_std = 0.556)
NEC for r=0.6 all L1 = 0.544 +- 0.137 (in-sample avg dev_std = 0.556)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.929
Model XAI F1 of binarized graphs for r=0.9 =  0.29536875
Model XAI WIoU of binarized graphs for r=0.9 =  0.9939325
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.573
NEC for r=0.9 class 0 = 0.467 +- 0.203 (in-sample avg dev_std = 0.521)
NEC for r=0.9 class 1 = 0.46 +- 0.203 (in-sample avg dev_std = 0.521)
NEC for r=0.9 class 2 = 0.508 +- 0.203 (in-sample avg dev_std = 0.521)
NEC for r=0.9 all KL = 0.4 +- 0.203 (in-sample avg dev_std = 0.521)
NEC for r=0.9 all L1 = 0.478 +- 0.117 (in-sample avg dev_std = 0.521)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.929
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.9939325
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.585
NEC for r=1.0 class 0 = 0.469 +- 0.204 (in-sample avg dev_std = 0.518)
NEC for r=1.0 class 1 = 0.47 +- 0.204 (in-sample avg dev_std = 0.518)
NEC for r=1.0 class 2 = 0.482 +- 0.204 (in-sample avg dev_std = 0.518)
NEC for r=1.0 all KL = 0.397 +- 0.204 (in-sample avg dev_std = 0.518)
NEC for r=1.0 all L1 = 0.474 +- 0.121 (in-sample avg dev_std = 0.518)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.493
Model XAI F1 of binarized graphs for r=0.3 =  0.782
Model XAI WIoU of binarized graphs for r=0.3 =  0.8802100000000002
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.404
NEC for r=0.3 class 0 = 0.547 +- 0.268 (in-sample avg dev_std = 0.558)
NEC for r=0.3 class 1 = 0.444 +- 0.268 (in-sample avg dev_std = 0.558)
NEC for r=0.3 class 2 = 0.608 +- 0.268 (in-sample avg dev_std = 0.558)
NEC for r=0.3 all KL = 0.587 +- 0.268 (in-sample avg dev_std = 0.558)
NEC for r=0.3 all L1 = 0.533 +- 0.134 (in-sample avg dev_std = 0.558)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.874
Model XAI F1 of binarized graphs for r=0.6 =  0.5438937500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.7503025
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.582
NEC for r=0.6 class 0 = 0.409 +- 0.356 (in-sample avg dev_std = 0.594)
NEC for r=0.6 class 1 = 0.472 +- 0.356 (in-sample avg dev_std = 0.594)
NEC for r=0.6 class 2 = 0.544 +- 0.356 (in-sample avg dev_std = 0.594)
NEC for r=0.6 all KL = 0.524 +- 0.356 (in-sample avg dev_std = 0.594)
NEC for r=0.6 all L1 = 0.475 +- 0.233 (in-sample avg dev_std = 0.594)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.664
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.6935862500000001
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.634
NEC for r=0.9 class 0 = 0.408 +- 0.307 (in-sample avg dev_std = 0.538)
NEC for r=0.9 class 1 = 0.406 +- 0.307 (in-sample avg dev_std = 0.538)
NEC for r=0.9 class 2 = 0.348 +- 0.307 (in-sample avg dev_std = 0.538)
NEC for r=0.9 all KL = 0.439 +- 0.307 (in-sample avg dev_std = 0.538)
NEC for r=0.9 all L1 = 0.387 +- 0.194 (in-sample avg dev_std = 0.538)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.71
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.69095
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.638
NEC for r=1.0 class 0 = 0.403 +- 0.298 (in-sample avg dev_std = 0.536)
NEC for r=1.0 class 1 = 0.427 +- 0.298 (in-sample avg dev_std = 0.536)
NEC for r=1.0 class 2 = 0.326 +- 0.298 (in-sample avg dev_std = 0.536)
NEC for r=1.0 all KL = 0.441 +- 0.298 (in-sample avg dev_std = 0.536)
NEC for r=1.0 all L1 = 0.386 +- 0.199 (in-sample avg dev_std = 0.536)


Evaluating SUFF for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.505
Model XAI F1 of binarized graphs for r=0.3 =  0.678015
Model XAI WIoU of binarized graphs for r=0.3 =  0.5967325
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.47
SUFF for r=0.3 class 0 = 0.51 +- 0.269 (in-sample avg dev_std = 0.517)
SUFF for r=0.3 class 1 = 0.565 +- 0.269 (in-sample avg dev_std = 0.517)
SUFF for r=0.3 class 2 = 0.494 +- 0.269 (in-sample avg dev_std = 0.517)
SUFF for r=0.3 all KL = 0.479 +- 0.269 (in-sample avg dev_std = 0.517)
SUFF for r=0.3 all L1 = 0.523 +- 0.175 (in-sample avg dev_std = 0.517)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.86
Model XAI F1 of binarized graphs for r=0.6 =  0.61004875
Model XAI WIoU of binarized graphs for r=0.6 =  0.6905325000000001
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.762
SUFF for r=0.6 class 0 = 0.647 +- 0.254 (in-sample avg dev_std = 0.398)
SUFF for r=0.6 class 1 = 0.66 +- 0.254 (in-sample avg dev_std = 0.398)
SUFF for r=0.6 class 2 = 0.685 +- 0.254 (in-sample avg dev_std = 0.398)
SUFF for r=0.6 all KL = 0.641 +- 0.254 (in-sample avg dev_std = 0.398)
SUFF for r=0.6 all L1 = 0.664 +- 0.206 (in-sample avg dev_std = 0.398)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.923
Model XAI F1 of binarized graphs for r=0.9 =  0.48117374999999996
Model XAI WIoU of binarized graphs for r=0.9 =  0.70282375
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.88
SUFF for r=0.9 class 0 = 0.785 +- 0.192 (in-sample avg dev_std = 0.212)
SUFF for r=0.9 class 1 = 0.798 +- 0.192 (in-sample avg dev_std = 0.212)
SUFF for r=0.9 class 2 = 0.832 +- 0.192 (in-sample avg dev_std = 0.212)
SUFF for r=0.9 all KL = 0.85 +- 0.192 (in-sample avg dev_std = 0.212)
SUFF for r=0.9 all L1 = 0.805 +- 0.167 (in-sample avg dev_std = 0.212)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.928
Model XAI F1 of binarized graphs for r=0.3 =  0.6694275000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.9939325
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.692
SUFF for r=0.3 class 0 = 0.61 +- 0.310 (in-sample avg dev_std = 0.572)
SUFF for r=0.3 class 1 = 0.695 +- 0.310 (in-sample avg dev_std = 0.572)
SUFF for r=0.3 class 2 = 0.539 +- 0.310 (in-sample avg dev_std = 0.572)
SUFF for r=0.3 all KL = 0.506 +- 0.310 (in-sample avg dev_std = 0.572)
SUFF for r=0.3 all L1 = 0.614 +- 0.201 (in-sample avg dev_std = 0.572)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.928
Model XAI F1 of binarized graphs for r=0.6 =  0.40952875000000005
Model XAI WIoU of binarized graphs for r=0.6 =  0.9939325
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.749
SUFF for r=0.6 class 0 = 0.629 +- 0.212 (in-sample avg dev_std = 0.388)
SUFF for r=0.6 class 1 = 0.646 +- 0.212 (in-sample avg dev_std = 0.388)
SUFF for r=0.6 class 2 = 0.666 +- 0.212 (in-sample avg dev_std = 0.388)
SUFF for r=0.6 all KL = 0.711 +- 0.212 (in-sample avg dev_std = 0.388)
SUFF for r=0.6 all L1 = 0.647 +- 0.162 (in-sample avg dev_std = 0.388)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.929
Model XAI F1 of binarized graphs for r=0.9 =  0.29536875
Model XAI WIoU of binarized graphs for r=0.9 =  0.9939325
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.88
SUFF for r=0.9 class 0 = 0.831 +- 0.132 (in-sample avg dev_std = 0.167)
SUFF for r=0.9 class 1 = 0.859 +- 0.132 (in-sample avg dev_std = 0.167)
SUFF for r=0.9 class 2 = 0.83 +- 0.132 (in-sample avg dev_std = 0.167)
SUFF for r=0.9 all KL = 0.926 +- 0.132 (in-sample avg dev_std = 0.167)
SUFF for r=0.9 all L1 = 0.84 +- 0.145 (in-sample avg dev_std = 0.167)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.493
Model XAI F1 of binarized graphs for r=0.3 =  0.782
Model XAI WIoU of binarized graphs for r=0.3 =  0.8802100000000002
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.569
SUFF for r=0.3 class 0 = 0.525 +- 0.281 (in-sample avg dev_std = 0.576)
SUFF for r=0.3 class 1 = 0.594 +- 0.281 (in-sample avg dev_std = 0.576)
SUFF for r=0.3 class 2 = 0.462 +- 0.281 (in-sample avg dev_std = 0.576)
SUFF for r=0.3 all KL = 0.47 +- 0.281 (in-sample avg dev_std = 0.576)
SUFF for r=0.3 all L1 = 0.527 +- 0.154 (in-sample avg dev_std = 0.576)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.871
Model XAI F1 of binarized graphs for r=0.6 =  0.5438937500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.7503025
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.762
SUFF for r=0.6 class 0 = 0.56 +- 0.249 (in-sample avg dev_std = 0.452)
SUFF for r=0.6 class 1 = 0.658 +- 0.249 (in-sample avg dev_std = 0.452)
SUFF for r=0.6 class 2 = 0.729 +- 0.249 (in-sample avg dev_std = 0.452)
SUFF for r=0.6 all KL = 0.634 +- 0.249 (in-sample avg dev_std = 0.452)
SUFF for r=0.6 all L1 = 0.65 +- 0.176 (in-sample avg dev_std = 0.452)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.666
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.6935862500000001
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.752
SUFF for r=0.9 class 0 = 0.677 +- 0.281 (in-sample avg dev_std = 0.320)
SUFF for r=0.9 class 1 = 0.658 +- 0.281 (in-sample avg dev_std = 0.320)
SUFF for r=0.9 class 2 = 0.884 +- 0.281 (in-sample avg dev_std = 0.320)
SUFF for r=0.9 all KL = 0.758 +- 0.281 (in-sample avg dev_std = 0.320)
SUFF for r=0.9 all L1 = 0.74 +- 0.253 (in-sample avg dev_std = 0.320)


ratio=1.0



Zero intervened samples, skipping weight=1.0

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Mar 20 14:55:49 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 02:55:49 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 120...
[0m[1;37mINFO[0m: [1mCheckpoint 120: 
-----------------------------------
Train ACCURACY: 0.8893
Train Loss: 0.5315
ID Validation ACCURACY: 0.8940
ID Validation Loss: 0.5268
ID Test ACCURACY: 0.8807
ID Test Loss: 0.5595
OOD Validation ACCURACY: 0.8480
OOD Validation Loss: 0.5785
OOD Test ACCURACY: 0.9053
OOD Test Loss: 0.4997

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 116...
[0m[1;37mINFO[0m: [1mCheckpoint 116: 
-----------------------------------
Train ACCURACY: 0.8415
Train Loss: 0.5162
ID Validation ACCURACY: 0.8440
ID Validation Loss: 0.4990
ID Test ACCURACY: 0.8423
ID Test Loss: 0.5364
OOD Validation ACCURACY: 0.9043
OOD Validation Loss: 0.5293
OOD Test ACCURACY: 0.7010
OOD Test Loss: 0.9220

[0m[1;37mINFO[0m: [1mChartInfo 0.8807 0.9053 0.8423 0.7010 0.8440 0.9043[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.750
WIoU for r=0.3 = 0.849
F1 for r=0.6 = 0.616
WIoU for r=0.6 = 0.907
F1 for r=0.9 = 0.481
WIoU for r=0.9 = 0.910
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.910
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.669
WIoU for r=0.3 = 0.995
F1 for r=0.6 = 0.410
WIoU for r=0.6 = 0.995
F1 for r=0.9 = 0.295
WIoU for r=0.9 = 0.995
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.995
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.752
WIoU for r=0.3 = 0.847
F1 for r=0.6 = 0.555
WIoU for r=0.6 = 0.845
F1 for r=0.9 = 0.424
WIoU for r=0.9 = 0.845
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.845
Size bank for r=0.3 -> 1500
Size bank for r=0.6 -> 1500
Size bank for r=0.9 -> 1129


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.673
Model XAI F1 of binarized graphs for r=0.3 =  0.7501737499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.8490125000000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.352
NEC for r=0.3 class 0 = 0.449 +- 0.346 (in-sample avg dev_std = 0.379)
NEC for r=0.3 class 1 = 0.465 +- 0.346 (in-sample avg dev_std = 0.379)
NEC for r=0.3 class 2 = 0.591 +- 0.346 (in-sample avg dev_std = 0.379)
NEC for r=0.3 all KL = 0.484 +- 0.346 (in-sample avg dev_std = 0.379)
NEC for r=0.3 all L1 = 0.501 +- 0.180 (in-sample avg dev_std = 0.379)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.897
Model XAI F1 of binarized graphs for r=0.6 =  0.61604125
Model XAI WIoU of binarized graphs for r=0.6 =  0.90689125
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.474
NEC for r=0.6 class 0 = 0.417 +- 0.308 (in-sample avg dev_std = 0.452)
NEC for r=0.6 class 1 = 0.437 +- 0.308 (in-sample avg dev_std = 0.452)
NEC for r=0.6 class 2 = 0.591 +- 0.308 (in-sample avg dev_std = 0.452)
NEC for r=0.6 all KL = 0.436 +- 0.308 (in-sample avg dev_std = 0.452)
NEC for r=0.6 all L1 = 0.481 +- 0.176 (in-sample avg dev_std = 0.452)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.902
Model XAI F1 of binarized graphs for r=0.9 =  0.48057625000000004
Model XAI WIoU of binarized graphs for r=0.9 =  0.90993125
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.54
NEC for r=0.9 class 0 = 0.372 +- 0.296 (in-sample avg dev_std = 0.462)
NEC for r=0.9 class 1 = 0.388 +- 0.296 (in-sample avg dev_std = 0.462)
NEC for r=0.9 class 2 = 0.528 +- 0.296 (in-sample avg dev_std = 0.462)
NEC for r=0.9 all KL = 0.359 +- 0.296 (in-sample avg dev_std = 0.462)
NEC for r=0.9 all L1 = 0.428 +- 0.171 (in-sample avg dev_std = 0.462)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.902
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.90993125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.556
NEC for r=1.0 class 0 = 0.372 +- 0.295 (in-sample avg dev_std = 0.462)
NEC for r=1.0 class 1 = 0.371 +- 0.295 (in-sample avg dev_std = 0.462)
NEC for r=1.0 class 2 = 0.511 +- 0.295 (in-sample avg dev_std = 0.462)
NEC for r=1.0 all KL = 0.347 +- 0.295 (in-sample avg dev_std = 0.462)
NEC for r=1.0 all L1 = 0.417 +- 0.171 (in-sample avg dev_std = 0.462)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.906
Model XAI F1 of binarized graphs for r=0.3 =  0.6692275000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.9953387499999999
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.399
NEC for r=0.3 class 0 = 0.437 +- 0.332 (in-sample avg dev_std = 0.408)
NEC for r=0.3 class 1 = 0.484 +- 0.332 (in-sample avg dev_std = 0.408)
NEC for r=0.3 class 2 = 0.721 +- 0.332 (in-sample avg dev_std = 0.408)
NEC for r=0.3 all KL = 0.534 +- 0.332 (in-sample avg dev_std = 0.408)
NEC for r=0.3 all L1 = 0.548 +- 0.187 (in-sample avg dev_std = 0.408)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  0.40952875000000005
Model XAI WIoU of binarized graphs for r=0.6 =  0.9953387499999999
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.515
NEC for r=0.6 class 0 = 0.373 +- 0.271 (in-sample avg dev_std = 0.425)
NEC for r=0.6 class 1 = 0.364 +- 0.271 (in-sample avg dev_std = 0.425)
NEC for r=0.6 class 2 = 0.587 +- 0.271 (in-sample avg dev_std = 0.425)
NEC for r=0.6 all KL = 0.34 +- 0.271 (in-sample avg dev_std = 0.425)
NEC for r=0.6 all L1 = 0.442 +- 0.168 (in-sample avg dev_std = 0.425)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.868
Model XAI F1 of binarized graphs for r=0.9 =  0.29536875
Model XAI WIoU of binarized graphs for r=0.9 =  0.9953387499999999
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.579
NEC for r=0.9 class 0 = 0.331 +- 0.201 (in-sample avg dev_std = 0.386)
NEC for r=0.9 class 1 = 0.309 +- 0.201 (in-sample avg dev_std = 0.386)
NEC for r=0.9 class 2 = 0.47 +- 0.201 (in-sample avg dev_std = 0.386)
NEC for r=0.9 all KL = 0.231 +- 0.201 (in-sample avg dev_std = 0.386)
NEC for r=0.9 all L1 = 0.371 +- 0.144 (in-sample avg dev_std = 0.386)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.868
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.9953387499999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.595
NEC for r=1.0 class 0 = 0.335 +- 0.190 (in-sample avg dev_std = 0.387)
NEC for r=1.0 class 1 = 0.311 +- 0.190 (in-sample avg dev_std = 0.387)
NEC for r=1.0 class 2 = 0.45 +- 0.190 (in-sample avg dev_std = 0.387)
NEC for r=1.0 all KL = 0.225 +- 0.190 (in-sample avg dev_std = 0.387)
NEC for r=1.0 all L1 = 0.366 +- 0.137 (in-sample avg dev_std = 0.387)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.744
Model XAI F1 of binarized graphs for r=0.3 =  0.7515675000000002
Model XAI WIoU of binarized graphs for r=0.3 =  0.8466300000000001
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.327
NEC for r=0.3 class 0 = 0.486 +- 0.322 (in-sample avg dev_std = 0.414)
NEC for r=0.3 class 1 = 0.477 +- 0.322 (in-sample avg dev_std = 0.414)
NEC for r=0.3 class 2 = 0.587 +- 0.322 (in-sample avg dev_std = 0.414)
NEC for r=0.3 all KL = 0.525 +- 0.322 (in-sample avg dev_std = 0.414)
NEC for r=0.3 all L1 = 0.517 +- 0.154 (in-sample avg dev_std = 0.414)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.897
Model XAI F1 of binarized graphs for r=0.6 =  0.5545187500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.84512
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.535
NEC for r=0.6 class 0 = 0.355 +- 0.347 (in-sample avg dev_std = 0.464)
NEC for r=0.6 class 1 = 0.412 +- 0.347 (in-sample avg dev_std = 0.464)
NEC for r=0.6 class 2 = 0.53 +- 0.347 (in-sample avg dev_std = 0.464)
NEC for r=0.6 all KL = 0.405 +- 0.347 (in-sample avg dev_std = 0.464)
NEC for r=0.6 all L1 = 0.433 +- 0.204 (in-sample avg dev_std = 0.464)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.897
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.84512
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.601
NEC for r=0.9 class 0 = 0.353 +- 0.308 (in-sample avg dev_std = 0.509)
NEC for r=0.9 class 1 = 0.35 +- 0.308 (in-sample avg dev_std = 0.509)
NEC for r=0.9 class 2 = 0.461 +- 0.308 (in-sample avg dev_std = 0.509)
NEC for r=0.9 all KL = 0.36 +- 0.308 (in-sample avg dev_std = 0.509)
NEC for r=0.9 all L1 = 0.388 +- 0.183 (in-sample avg dev_std = 0.509)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.897
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.84512
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.598
NEC for r=1.0 class 0 = 0.369 +- 0.305 (in-sample avg dev_std = 0.511)
NEC for r=1.0 class 1 = 0.355 +- 0.305 (in-sample avg dev_std = 0.511)
NEC for r=1.0 class 2 = 0.458 +- 0.305 (in-sample avg dev_std = 0.511)
NEC for r=1.0 all KL = 0.366 +- 0.305 (in-sample avg dev_std = 0.511)
NEC for r=1.0 all L1 = 0.394 +- 0.182 (in-sample avg dev_std = 0.511)


Evaluating SUFF for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.671
Model XAI F1 of binarized graphs for r=0.3 =  0.7501737499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.8490125000000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.567
SUFF for r=0.3 class 0 = 0.514 +- 0.292 (in-sample avg dev_std = 0.421)
SUFF for r=0.3 class 1 = 0.662 +- 0.292 (in-sample avg dev_std = 0.421)
SUFF for r=0.3 class 2 = 0.536 +- 0.292 (in-sample avg dev_std = 0.421)
SUFF for r=0.3 all KL = 0.585 +- 0.292 (in-sample avg dev_std = 0.421)
SUFF for r=0.3 all L1 = 0.571 +- 0.178 (in-sample avg dev_std = 0.421)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.897
Model XAI F1 of binarized graphs for r=0.6 =  0.61604125
Model XAI WIoU of binarized graphs for r=0.6 =  0.90689125
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.743
SUFF for r=0.6 class 0 = 0.621 +- 0.210 (in-sample avg dev_std = 0.292)
SUFF for r=0.6 class 1 = 0.728 +- 0.210 (in-sample avg dev_std = 0.292)
SUFF for r=0.6 class 2 = 0.732 +- 0.210 (in-sample avg dev_std = 0.292)
SUFF for r=0.6 all KL = 0.777 +- 0.210 (in-sample avg dev_std = 0.292)
SUFF for r=0.6 all L1 = 0.694 +- 0.169 (in-sample avg dev_std = 0.292)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.902
Model XAI F1 of binarized graphs for r=0.9 =  0.48057625000000004
Model XAI WIoU of binarized graphs for r=0.9 =  0.90993125
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.856
SUFF for r=0.9 class 0 = 0.834 +- 0.108 (in-sample avg dev_std = 0.154)
SUFF for r=0.9 class 1 = 0.841 +- 0.108 (in-sample avg dev_std = 0.154)
SUFF for r=0.9 class 2 = 0.884 +- 0.108 (in-sample avg dev_std = 0.154)
SUFF for r=0.9 all KL = 0.938 +- 0.108 (in-sample avg dev_std = 0.154)
SUFF for r=0.9 all L1 = 0.853 +- 0.128 (in-sample avg dev_std = 0.154)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.908
Model XAI F1 of binarized graphs for r=0.3 =  0.6692275000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.9953387499999999
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.63
SUFF for r=0.3 class 0 = 0.545 +- 0.295 (in-sample avg dev_std = 0.374)
SUFF for r=0.3 class 1 = 0.701 +- 0.295 (in-sample avg dev_std = 0.374)
SUFF for r=0.3 class 2 = 0.619 +- 0.295 (in-sample avg dev_std = 0.374)
SUFF for r=0.3 all KL = 0.656 +- 0.295 (in-sample avg dev_std = 0.374)
SUFF for r=0.3 all L1 = 0.621 +- 0.212 (in-sample avg dev_std = 0.374)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  0.40952875000000005
Model XAI WIoU of binarized graphs for r=0.6 =  0.9953387499999999
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.78
SUFF for r=0.6 class 0 = 0.734 +- 0.165 (in-sample avg dev_std = 0.212)
SUFF for r=0.6 class 1 = 0.769 +- 0.165 (in-sample avg dev_std = 0.212)
SUFF for r=0.6 class 2 = 0.73 +- 0.165 (in-sample avg dev_std = 0.212)
SUFF for r=0.6 all KL = 0.869 +- 0.165 (in-sample avg dev_std = 0.212)
SUFF for r=0.6 all L1 = 0.744 +- 0.150 (in-sample avg dev_std = 0.212)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.868
Model XAI F1 of binarized graphs for r=0.9 =  0.29536875
Model XAI WIoU of binarized graphs for r=0.9 =  0.9953387499999999
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.841
SUFF for r=0.9 class 0 = 0.852 +- 0.062 (in-sample avg dev_std = 0.139)
SUFF for r=0.9 class 1 = 0.873 +- 0.062 (in-sample avg dev_std = 0.139)
SUFF for r=0.9 class 2 = 0.886 +- 0.062 (in-sample avg dev_std = 0.139)
SUFF for r=0.9 all KL = 0.964 +- 0.062 (in-sample avg dev_std = 0.139)
SUFF for r=0.9 all L1 = 0.87 +- 0.086 (in-sample avg dev_std = 0.139)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.744
Model XAI F1 of binarized graphs for r=0.3 =  0.7515675000000002
Model XAI WIoU of binarized graphs for r=0.3 =  0.8466300000000001
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.499
SUFF for r=0.3 class 0 = 0.471 +- 0.315 (in-sample avg dev_std = 0.402)
SUFF for r=0.3 class 1 = 0.635 +- 0.315 (in-sample avg dev_std = 0.402)
SUFF for r=0.3 class 2 = 0.474 +- 0.315 (in-sample avg dev_std = 0.402)
SUFF for r=0.3 all KL = 0.544 +- 0.315 (in-sample avg dev_std = 0.402)
SUFF for r=0.3 all L1 = 0.528 +- 0.189 (in-sample avg dev_std = 0.402)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.897
Model XAI F1 of binarized graphs for r=0.6 =  0.5545187500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.84512
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.681
SUFF for r=0.6 class 0 = 0.54 +- 0.166 (in-sample avg dev_std = 0.313)
SUFF for r=0.6 class 1 = 0.721 +- 0.166 (in-sample avg dev_std = 0.313)
SUFF for r=0.6 class 2 = 0.754 +- 0.166 (in-sample avg dev_std = 0.313)
SUFF for r=0.6 all KL = 0.763 +- 0.166 (in-sample avg dev_std = 0.313)
SUFF for r=0.6 all L1 = 0.674 +- 0.169 (in-sample avg dev_std = 0.313)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.897
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.84512
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.791
SUFF for r=0.9 class 0 = 0.728 +- 0.123 (in-sample avg dev_std = 0.224)
SUFF for r=0.9 class 1 = 0.775 +- 0.123 (in-sample avg dev_std = 0.224)
SUFF for r=0.9 class 2 = 0.853 +- 0.123 (in-sample avg dev_std = 0.224)
SUFF for r=0.9 all KL = 0.882 +- 0.123 (in-sample avg dev_std = 0.224)
SUFF for r=0.9 all L1 = 0.786 +- 0.143 (in-sample avg dev_std = 0.224)


ratio=1.0



Zero intervened samples, skipping weight=1.0

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Mar 20 15:00:13 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:00:13 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 109...
[0m[1;37mINFO[0m: [1mCheckpoint 109: 
-----------------------------------
Train ACCURACY: 0.8887
Train Loss: 0.4987
ID Validation ACCURACY: 0.8910
ID Validation Loss: 0.4744
ID Test ACCURACY: 0.8860
ID Test Loss: 0.5215
OOD Validation ACCURACY: 0.8970
OOD Validation Loss: 0.5042
OOD Test ACCURACY: 0.8647
OOD Test Loss: 0.5045

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 119...
[0m[1;37mINFO[0m: [1mCheckpoint 119: 
-----------------------------------
Train ACCURACY: 0.7957
Train Loss: 0.6628
ID Validation ACCURACY: 0.7933
ID Validation Loss: 0.6550
ID Test ACCURACY: 0.7830
ID Test Loss: 0.7186
OOD Validation ACCURACY: 0.9107
OOD Validation Loss: 0.5086
OOD Test ACCURACY: 0.8793
OOD Test Loss: 0.5214

[0m[1;37mINFO[0m: [1mChartInfo 0.8860 0.8647 0.7830 0.8793 0.7933 0.9107[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.711
WIoU for r=0.3 = 0.661
F1 for r=0.6 = 0.613
WIoU for r=0.6 = 0.726
F1 for r=0.9 = 0.481
WIoU for r=0.9 = 0.719
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.719
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.664
WIoU for r=0.3 = 0.929
F1 for r=0.6 = 0.409
WIoU for r=0.6 = 0.926
F1 for r=0.9 = 0.295
WIoU for r=0.9 = 0.926
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.926
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.769
WIoU for r=0.3 = 0.900
F1 for r=0.6 = 0.544
WIoU for r=0.6 = 0.849
F1 for r=0.9 = 0.424
WIoU for r=0.9 = 0.827
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.827
Size bank for r=0.3 -> 1500
Size bank for r=0.6 -> 1500
Size bank for r=0.9 -> 1114


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.564
Model XAI F1 of binarized graphs for r=0.3 =  0.7107625
Model XAI WIoU of binarized graphs for r=0.3 =  0.6609200000000002
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.39
NEC for r=0.3 class 0 = 0.606 +- 0.290 (in-sample avg dev_std = 0.561)
NEC for r=0.3 class 1 = 0.539 +- 0.290 (in-sample avg dev_std = 0.561)
NEC for r=0.3 class 2 = 0.667 +- 0.290 (in-sample avg dev_std = 0.561)
NEC for r=0.3 all KL = 0.719 +- 0.290 (in-sample avg dev_std = 0.561)
NEC for r=0.3 all L1 = 0.604 +- 0.159 (in-sample avg dev_std = 0.561)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.837
Model XAI F1 of binarized graphs for r=0.6 =  0.61280625
Model XAI WIoU of binarized graphs for r=0.6 =  0.7261012499999999
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.486
NEC for r=0.6 class 0 = 0.511 +- 0.317 (in-sample avg dev_std = 0.562)
NEC for r=0.6 class 1 = 0.483 +- 0.317 (in-sample avg dev_std = 0.562)
NEC for r=0.6 class 2 = 0.633 +- 0.317 (in-sample avg dev_std = 0.562)
NEC for r=0.6 all KL = 0.634 +- 0.317 (in-sample avg dev_std = 0.562)
NEC for r=0.6 all L1 = 0.542 +- 0.171 (in-sample avg dev_std = 0.562)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.905
Model XAI F1 of binarized graphs for r=0.9 =  0.48108249999999997
Model XAI WIoU of binarized graphs for r=0.9 =  0.71949875
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.584
NEC for r=0.9 class 0 = 0.463 +- 0.311 (in-sample avg dev_std = 0.566)
NEC for r=0.9 class 1 = 0.43 +- 0.311 (in-sample avg dev_std = 0.566)
NEC for r=0.9 class 2 = 0.547 +- 0.311 (in-sample avg dev_std = 0.566)
NEC for r=0.9 all KL = 0.529 +- 0.311 (in-sample avg dev_std = 0.566)
NEC for r=0.9 all L1 = 0.48 +- 0.169 (in-sample avg dev_std = 0.566)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.905
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.719315
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.581
NEC for r=1.0 class 0 = 0.459 +- 0.308 (in-sample avg dev_std = 0.568)
NEC for r=1.0 class 1 = 0.422 +- 0.308 (in-sample avg dev_std = 0.568)
NEC for r=1.0 class 2 = 0.545 +- 0.308 (in-sample avg dev_std = 0.568)
NEC for r=1.0 all KL = 0.528 +- 0.308 (in-sample avg dev_std = 0.568)
NEC for r=1.0 all L1 = 0.475 +- 0.169 (in-sample avg dev_std = 0.568)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.873
Model XAI F1 of binarized graphs for r=0.3 =  0.6636587499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.9293250000000001
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.4
NEC for r=0.3 class 0 = 0.573 +- 0.306 (in-sample avg dev_std = 0.480)
NEC for r=0.3 class 1 = 0.536 +- 0.306 (in-sample avg dev_std = 0.480)
NEC for r=0.3 class 2 = 0.718 +- 0.306 (in-sample avg dev_std = 0.480)
NEC for r=0.3 all KL = 0.676 +- 0.306 (in-sample avg dev_std = 0.480)
NEC for r=0.3 all L1 = 0.61 +- 0.154 (in-sample avg dev_std = 0.480)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.899
Model XAI F1 of binarized graphs for r=0.6 =  0.40876375
Model XAI WIoU of binarized graphs for r=0.6 =  0.92616625
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.549
NEC for r=0.6 class 0 = 0.446 +- 0.285 (in-sample avg dev_std = 0.509)
NEC for r=0.6 class 1 = 0.42 +- 0.285 (in-sample avg dev_std = 0.509)
NEC for r=0.6 class 2 = 0.572 +- 0.285 (in-sample avg dev_std = 0.509)
NEC for r=0.6 all KL = 0.445 +- 0.285 (in-sample avg dev_std = 0.509)
NEC for r=0.6 all L1 = 0.48 +- 0.144 (in-sample avg dev_std = 0.509)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.902
Model XAI F1 of binarized graphs for r=0.9 =  0.29531125
Model XAI WIoU of binarized graphs for r=0.9 =  0.92616625
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.614
NEC for r=0.9 class 0 = 0.396 +- 0.249 (in-sample avg dev_std = 0.487)
NEC for r=0.9 class 1 = 0.393 +- 0.249 (in-sample avg dev_std = 0.487)
NEC for r=0.9 class 2 = 0.473 +- 0.249 (in-sample avg dev_std = 0.487)
NEC for r=0.9 all KL = 0.357 +- 0.249 (in-sample avg dev_std = 0.487)
NEC for r=0.9 all L1 = 0.421 +- 0.136 (in-sample avg dev_std = 0.487)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.902
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.92616625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.61
NEC for r=1.0 class 0 = 0.402 +- 0.244 (in-sample avg dev_std = 0.493)
NEC for r=1.0 class 1 = 0.398 +- 0.244 (in-sample avg dev_std = 0.493)
NEC for r=1.0 class 2 = 0.468 +- 0.244 (in-sample avg dev_std = 0.493)
NEC for r=1.0 all KL = 0.358 +- 0.244 (in-sample avg dev_std = 0.493)
NEC for r=1.0 all L1 = 0.423 +- 0.127 (in-sample avg dev_std = 0.493)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.863
Model XAI F1 of binarized graphs for r=0.3 =  0.7685775000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.8999287499999999
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.412
NEC for r=0.3 class 0 = 0.607 +- 0.285 (in-sample avg dev_std = 0.516)
NEC for r=0.3 class 1 = 0.524 +- 0.285 (in-sample avg dev_std = 0.516)
NEC for r=0.3 class 2 = 0.642 +- 0.285 (in-sample avg dev_std = 0.516)
NEC for r=0.3 all KL = 0.641 +- 0.285 (in-sample avg dev_std = 0.516)
NEC for r=0.3 all L1 = 0.59 +- 0.139 (in-sample avg dev_std = 0.516)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.865
Model XAI F1 of binarized graphs for r=0.6 =  0.5438937500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.8493262500000001
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.582
NEC for r=0.6 class 0 = 0.435 +- 0.333 (in-sample avg dev_std = 0.540)
NEC for r=0.6 class 1 = 0.397 +- 0.333 (in-sample avg dev_std = 0.540)
NEC for r=0.6 class 2 = 0.538 +- 0.333 (in-sample avg dev_std = 0.540)
NEC for r=0.6 all KL = 0.484 +- 0.333 (in-sample avg dev_std = 0.540)
NEC for r=0.6 all L1 = 0.456 +- 0.195 (in-sample avg dev_std = 0.540)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.865
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.827495
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.642
NEC for r=0.9 class 0 = 0.395 +- 0.329 (in-sample avg dev_std = 0.566)
NEC for r=0.9 class 1 = 0.356 +- 0.329 (in-sample avg dev_std = 0.566)
NEC for r=0.9 class 2 = 0.464 +- 0.329 (in-sample avg dev_std = 0.566)
NEC for r=0.9 all KL = 0.452 +- 0.329 (in-sample avg dev_std = 0.566)
NEC for r=0.9 all L1 = 0.405 +- 0.189 (in-sample avg dev_std = 0.566)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.865
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.827495
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.648
NEC for r=1.0 class 0 = 0.388 +- 0.319 (in-sample avg dev_std = 0.583)
NEC for r=1.0 class 1 = 0.349 +- 0.319 (in-sample avg dev_std = 0.583)
NEC for r=1.0 class 2 = 0.457 +- 0.319 (in-sample avg dev_std = 0.583)
NEC for r=1.0 all KL = 0.449 +- 0.319 (in-sample avg dev_std = 0.583)
NEC for r=1.0 all L1 = 0.397 +- 0.174 (in-sample avg dev_std = 0.583)


Evaluating SUFF for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.566
Model XAI F1 of binarized graphs for r=0.3 =  0.7107625
Model XAI WIoU of binarized graphs for r=0.3 =  0.6609200000000002
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.57
SUFF for r=0.3 class 0 = 0.482 +- 0.301 (in-sample avg dev_std = 0.551)
SUFF for r=0.3 class 1 = 0.539 +- 0.301 (in-sample avg dev_std = 0.551)
SUFF for r=0.3 class 2 = 0.481 +- 0.301 (in-sample avg dev_std = 0.551)
SUFF for r=0.3 all KL = 0.372 +- 0.301 (in-sample avg dev_std = 0.551)
SUFF for r=0.3 all L1 = 0.501 +- 0.199 (in-sample avg dev_std = 0.551)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.837
Model XAI F1 of binarized graphs for r=0.6 =  0.61280625
Model XAI WIoU of binarized graphs for r=0.6 =  0.7261012499999999
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.74
SUFF for r=0.6 class 0 = 0.609 +- 0.307 (in-sample avg dev_std = 0.457)
SUFF for r=0.6 class 1 = 0.651 +- 0.307 (in-sample avg dev_std = 0.457)
SUFF for r=0.6 class 2 = 0.668 +- 0.307 (in-sample avg dev_std = 0.457)
SUFF for r=0.6 all KL = 0.57 +- 0.307 (in-sample avg dev_std = 0.457)
SUFF for r=0.6 all L1 = 0.643 +- 0.206 (in-sample avg dev_std = 0.457)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.905
Model XAI F1 of binarized graphs for r=0.9 =  0.48108249999999997
Model XAI WIoU of binarized graphs for r=0.9 =  0.71949875
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.871
SUFF for r=0.9 class 0 = 0.779 +- 0.214 (in-sample avg dev_std = 0.191)
SUFF for r=0.9 class 1 = 0.8 +- 0.214 (in-sample avg dev_std = 0.191)
SUFF for r=0.9 class 2 = 0.864 +- 0.214 (in-sample avg dev_std = 0.191)
SUFF for r=0.9 all KL = 0.862 +- 0.214 (in-sample avg dev_std = 0.191)
SUFF for r=0.9 all L1 = 0.814 +- 0.194 (in-sample avg dev_std = 0.191)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.873
Model XAI F1 of binarized graphs for r=0.3 =  0.6636587499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.9293250000000001
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.651
SUFF for r=0.3 class 0 = 0.519 +- 0.326 (in-sample avg dev_std = 0.546)
SUFF for r=0.3 class 1 = 0.636 +- 0.326 (in-sample avg dev_std = 0.546)
SUFF for r=0.3 class 2 = 0.565 +- 0.326 (in-sample avg dev_std = 0.546)
SUFF for r=0.3 all KL = 0.49 +- 0.326 (in-sample avg dev_std = 0.546)
SUFF for r=0.3 all L1 = 0.573 +- 0.203 (in-sample avg dev_std = 0.546)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.899
Model XAI F1 of binarized graphs for r=0.6 =  0.40876375
Model XAI WIoU of binarized graphs for r=0.6 =  0.92616625
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.695
SUFF for r=0.6 class 0 = 0.647 +- 0.261 (in-sample avg dev_std = 0.318)
SUFF for r=0.6 class 1 = 0.656 +- 0.261 (in-sample avg dev_std = 0.318)
SUFF for r=0.6 class 2 = 0.638 +- 0.261 (in-sample avg dev_std = 0.318)
SUFF for r=0.6 all KL = 0.72 +- 0.261 (in-sample avg dev_std = 0.318)
SUFF for r=0.6 all L1 = 0.647 +- 0.196 (in-sample avg dev_std = 0.318)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.902
Model XAI F1 of binarized graphs for r=0.9 =  0.29531125
Model XAI WIoU of binarized graphs for r=0.9 =  0.92616625
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.843
SUFF for r=0.9 class 0 = 0.829 +- 0.148 (in-sample avg dev_std = 0.161)
SUFF for r=0.9 class 1 = 0.827 +- 0.148 (in-sample avg dev_std = 0.161)
SUFF for r=0.9 class 2 = 0.862 +- 0.148 (in-sample avg dev_std = 0.161)
SUFF for r=0.9 all KL = 0.922 +- 0.148 (in-sample avg dev_std = 0.161)
SUFF for r=0.9 all L1 = 0.839 +- 0.148 (in-sample avg dev_std = 0.161)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.863
Model XAI F1 of binarized graphs for r=0.3 =  0.7685775000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.8999287499999999
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.624
SUFF for r=0.3 class 0 = 0.489 +- 0.299 (in-sample avg dev_std = 0.525)
SUFF for r=0.3 class 1 = 0.612 +- 0.299 (in-sample avg dev_std = 0.525)
SUFF for r=0.3 class 2 = 0.456 +- 0.299 (in-sample avg dev_std = 0.525)
SUFF for r=0.3 all KL = 0.469 +- 0.299 (in-sample avg dev_std = 0.525)
SUFF for r=0.3 all L1 = 0.52 +- 0.190 (in-sample avg dev_std = 0.525)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.865
Model XAI F1 of binarized graphs for r=0.6 =  0.5438937500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.8493262500000001
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.707
SUFF for r=0.6 class 0 = 0.492 +- 0.274 (in-sample avg dev_std = 0.463)
SUFF for r=0.6 class 1 = 0.661 +- 0.274 (in-sample avg dev_std = 0.463)
SUFF for r=0.6 class 2 = 0.657 +- 0.274 (in-sample avg dev_std = 0.463)
SUFF for r=0.6 all KL = 0.597 +- 0.274 (in-sample avg dev_std = 0.463)
SUFF for r=0.6 all L1 = 0.605 +- 0.186 (in-sample avg dev_std = 0.463)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.865
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.827495
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.871
SUFF for r=0.9 class 0 = 0.784 +- 0.175 (in-sample avg dev_std = 0.178)
SUFF for r=0.9 class 1 = 0.855 +- 0.175 (in-sample avg dev_std = 0.178)
SUFF for r=0.9 class 2 = 0.858 +- 0.175 (in-sample avg dev_std = 0.178)
SUFF for r=0.9 all KL = 0.894 +- 0.175 (in-sample avg dev_std = 0.178)
SUFF for r=0.9 all L1 = 0.833 +- 0.181 (in-sample avg dev_std = 0.178)


ratio=1.0



Zero intervened samples, skipping weight=1.0


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
nec = [defaultdict(<class 'list'>, {'all_KL': [0.588, 0.545, 0.466, 0.463], 'all_L1': [0.55, 0.537, 0.474, 0.472]}), defaultdict(<class 'list'>, {'all_KL': [0.603, 0.614, 0.521, 0.515], 'all_L1': [0.548, 0.572, 0.516, 0.511]}), defaultdict(<class 'list'>, {'all_KL': [0.607, 0.639, 0.569, 0.555], 'all_L1': [0.568, 0.576, 0.526, 0.516]}), defaultdict(<class 'list'>, {'all_KL': [0.484, 0.436, 0.359, 0.347], 'all_L1': [0.501, 0.481, 0.428, 0.417]}), defaultdict(<class 'list'>, {'all_KL': [0.719, 0.634, 0.529, 0.528], 'all_L1': [0.604, 0.542, 0.48, 0.475]})]
suff = [defaultdict(<class 'list'>, {'all_KL': [0.491, 0.721, 0.873, 1.0], 'all_L1': [0.536, 0.672, 0.782, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.502, 0.625, 0.839, 1.0], 'all_L1': [0.561, 0.639, 0.767, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.479, 0.641, 0.85, 1.0], 'all_L1': [0.523, 0.664, 0.805, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.585, 0.777, 0.938, 1.0], 'all_L1': [0.571, 0.694, 0.853, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.372, 0.57, 0.862, 1.0], 'all_L1': [0.501, 0.643, 0.814, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]

Eval split val
nec = [defaultdict(<class 'list'>, {'all_KL': [0.645, 0.44, 0.341, 0.334], 'all_L1': [0.63, 0.521, 0.459, 0.453]}), defaultdict(<class 'list'>, {'all_KL': [0.676, 0.444, 0.342, 0.334], 'all_L1': [0.635, 0.527, 0.462, 0.457]}), defaultdict(<class 'list'>, {'all_KL': [0.779, 0.526, 0.4, 0.397], 'all_L1': [0.67, 0.544, 0.478, 0.474]}), defaultdict(<class 'list'>, {'all_KL': [0.534, 0.34, 0.231, 0.225], 'all_L1': [0.548, 0.442, 0.371, 0.366]}), defaultdict(<class 'list'>, {'all_KL': [0.676, 0.445, 0.357, 0.358], 'all_L1': [0.61, 0.48, 0.421, 0.423]})]
suff = [defaultdict(<class 'list'>, {'all_KL': [0.643, 0.762, 0.913, 1.0], 'all_L1': [0.632, 0.634, 0.79, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.493, 0.735, 0.885, 1.0], 'all_L1': [0.54, 0.615, 0.743, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.506, 0.711, 0.926, 1.0], 'all_L1': [0.614, 0.647, 0.84, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.656, 0.869, 0.964, 1.0], 'all_L1': [0.621, 0.744, 0.87, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.49, 0.72, 0.922, 1.0], 'all_L1': [0.573, 0.647, 0.839, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]

Eval split test
nec = [defaultdict(<class 'list'>, {'all_KL': [0.658, 0.501, 0.405, 0.393], 'all_L1': [0.585, 0.464, 0.381, 0.369]}), defaultdict(<class 'list'>, {'all_KL': [0.478, 0.477, 0.446, 0.444], 'all_L1': [0.522, 0.478, 0.433, 0.431]}), defaultdict(<class 'list'>, {'all_KL': [0.587, 0.524, 0.439, 0.441], 'all_L1': [0.533, 0.475, 0.387, 0.386]}), defaultdict(<class 'list'>, {'all_KL': [0.525, 0.405, 0.36, 0.366], 'all_L1': [0.517, 0.433, 0.388, 0.394]}), defaultdict(<class 'list'>, {'all_KL': [0.641, 0.484, 0.452, 0.449], 'all_L1': [0.59, 0.456, 0.405, 0.397]})]
suff = [defaultdict(<class 'list'>, {'all_KL': [0.481, 0.746, 0.9, 1.0], 'all_L1': [0.55, 0.689, 0.826, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.587, 0.654, 0.729, 1.0], 'all_L1': [0.552, 0.629, 0.711, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.47, 0.634, 0.758, 1.0], 'all_L1': [0.527, 0.65, 0.74, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.544, 0.763, 0.882, 1.0], 'all_L1': [0.528, 0.674, 0.786, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.469, 0.597, 0.894, 1.0], 'all_L1': [0.52, 0.605, 0.833, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
nec class all_KL  =  0.600 +- 0.075, 0.574 +- 0.077, 0.489 +- 0.073, 0.482 +- 0.074
nec class all_L1  =  0.554 +- 0.033, 0.542 +- 0.034, 0.485 +- 0.035, 0.478 +- 0.035
nec_acc_int  =  0.366 +- 0.018, 0.465 +- 0.026, 0.554 +- 0.030, 0.563 +- 0.027
suff class all_KL  =  0.486 +- 0.068, 0.667 +- 0.073, 0.872 +- 0.035, 1.000 +- 0.000
suff class all_L1  =  0.538 +- 0.025, 0.662 +- 0.020, 0.804 +- 0.030, 1.000 +- 0.000
suff class 0  =  1.000 +- 0.000
suff class 1  =  1.000 +- 0.000
suff class 2  =  1.000 +- 0.000
suff_acc_int  =  0.534 +- 0.038, 0.753 +- 0.017, 0.860 +- 0.016

Eval split val
nec class all_KL  =  0.662 +- 0.078, 0.439 +- 0.059, 0.334 +- 0.056, 0.330 +- 0.057
nec class all_L1  =  0.619 +- 0.040, 0.503 +- 0.037, 0.438 +- 0.038, 0.435 +- 0.038
nec_acc_int  =  0.387 +- 0.011, 0.513 +- 0.022, 0.575 +- 0.022, 0.583 +- 0.019
suff class all_KL  =  0.558 +- 0.075, 0.759 +- 0.057, 0.922 +- 0.025, 1.000 +- 0.000
suff class all_L1  =  0.596 +- 0.034, 0.657 +- 0.045, 0.816 +- 0.045, 1.000 +- 0.000
suff class 0  =  1.000 +- 0.000
suff class 1  =  1.000 +- 0.000
suff class 2  =  1.000 +- 0.000
suff_acc_int  =  0.672 +- 0.050, 0.741 +- 0.029, 0.841 +- 0.022

Eval split test
nec class all_KL  =  0.578 +- 0.068, 0.478 +- 0.040, 0.420 +- 0.034, 0.419 +- 0.033
nec class all_L1  =  0.549 +- 0.032, 0.461 +- 0.016, 0.399 +- 0.019, 0.395 +- 0.020
nec_acc_int  =  0.393 +- 0.039, 0.557 +- 0.021, 0.626 +- 0.020, 0.633 +- 0.030
suff class all_KL  =  0.510 +- 0.047, 0.679 +- 0.065, 0.833 +- 0.074, 1.000 +- 0.000
suff class all_L1  =  0.535 +- 0.013, 0.649 +- 0.030, 0.779 +- 0.048, 1.000 +- 0.000
suff class 0  =  1.000 +- 0.000
suff class 1  =  1.000 +- 0.000
suff class 2  =  1.000 +- 0.000
suff_acc_int  =  0.580 +- 0.050, 0.743 +- 0.043, 0.816 +- 0.049


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
torch.Size([5, 4]) torch.Size([5, 4])
torch.Size([5, 4])
Faith. Aritm= 		  =  0.546 +- 0.007, 0.602 +- 0.011, 0.645 +- 0.012, 0.739 +- 0.018
Faith. Armon= 		  =  0.545 +- 0.007, 0.595 +- 0.016, 0.603 +- 0.023, 0.646 +- 0.033
Faith. GMean = 	  =  0.545 +- 0.007, 0.598 +- 0.014, 0.624 +- 0.017, 0.691 +- 0.026

Eval split val
torch.Size([5, 4]) torch.Size([5, 4])
torch.Size([5, 4])
Faith. Aritm= 		  =  0.607 +- 0.024, 0.580 +- 0.012, 0.627 +- 0.018, 0.717 +- 0.019
Faith. Armon= 		  =  0.606 +- 0.025, 0.567 +- 0.014, 0.568 +- 0.029, 0.605 +- 0.038
Faith. GMean = 	  =  0.607 +- 0.025, 0.574 +- 0.012, 0.597 +- 0.022, 0.659 +- 0.029

Eval split test
torch.Size([5, 4]) torch.Size([5, 4])
torch.Size([5, 4])
Faith. Aritm= 		  =  0.542 +- 0.017, 0.555 +- 0.015, 0.589 +- 0.020, 0.698 +- 0.010
Faith. Armon= 		  =  0.542 +- 0.016, 0.539 +- 0.013, 0.526 +- 0.013, 0.566 +- 0.021
Faith. GMean = 	  =  0.542 +- 0.016, 0.547 +- 0.014, 0.557 +- 0.015, 0.629 +- 0.016
Computed for split load_split = id



Completed in  0:22:38.044436  for LECIGIN GOODMotif2/basis



DONE LECI GOODMotif2/basis

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Mar 20 15:04:49 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 03/20/2024 03:04:49 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/20/2024 03:04:49 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/20/2024 03:04:49 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/20/2024 03:04:49 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/20/2024 03:04:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 03:04:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:04:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:04:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:04:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:04:49 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/20/2024 03:04:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 03:04:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:04:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:04:49 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/20/2024 03:04:49 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 105...
[0m[1;37mINFO[0m: [1mCheckpoint 105: 
-----------------------------------
Train ACCURACY: 0.9248
Train Loss: 0.3767
ID Validation ACCURACY: 0.9243
ID Validation Loss: 0.3771
ID Test ACCURACY: 0.9193
ID Test Loss: 0.4310
OOD Validation ACCURACY: 0.9260
OOD Validation Loss: 0.3978
OOD Test ACCURACY: 0.4087
OOD Test Loss: 27.1216

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 105...
[0m[1;37mINFO[0m: [1mCheckpoint 105: 
-----------------------------------
Train ACCURACY: 0.9248
Train Loss: 0.3767
ID Validation ACCURACY: 0.9243
ID Validation Loss: 0.3771
ID Test ACCURACY: 0.9193
ID Test Loss: 0.4310
OOD Validation ACCURACY: 0.9260
OOD Validation Loss: 0.3978
OOD Test ACCURACY: 0.4087
OOD Test Loss: 27.1216

[0m[1;37mINFO[0m: [1mChartInfo 0.9193 0.4087 0.9193 0.4087 0.9243 0.9260[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.8 = 0.516
WIoU for r=0.8 = 0.652
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.8 = 0.307
WIoU for r=0.8 = 0.893
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.8 = 0.343
WIoU for r=0.8 = 0.231
Size bank for r=0.8 -> 1491


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.8 =  0.933
Model XAI F1 of binarized graphs for r=0.8 =  0.5163575
Model XAI WIoU of binarized graphs for r=0.8 =  0.65161
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.443
NEC for r=0.8 class 0 = 0.65 +- 0.224 (in-sample avg dev_std = 0.703)
NEC for r=0.8 class 1 = 0.612 +- 0.224 (in-sample avg dev_std = 0.703)
NEC for r=0.8 class 2 = 0.575 +- 0.224 (in-sample avg dev_std = 0.703)
NEC for r=0.8 all KL = 0.733 +- 0.224 (in-sample avg dev_std = 0.703)
NEC for r=0.8 all L1 = 0.612 +- 0.152 (in-sample avg dev_std = 0.703)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.8


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.8 =  0.928
Model XAI F1 of binarized graphs for r=0.8 =  0.3072525
Model XAI WIoU of binarized graphs for r=0.8 =  0.89316125
len(reference) = 800
Effective ratio: 0.806 +- 0.005
Model Accuracy over intervened graphs for r=0.8 =  0.498
NEC for r=0.8 class 0 = 0.59 +- 0.217 (in-sample avg dev_std = 0.610)
NEC for r=0.8 class 1 = 0.56 +- 0.217 (in-sample avg dev_std = 0.610)
NEC for r=0.8 class 2 = 0.468 +- 0.217 (in-sample avg dev_std = 0.610)
NEC for r=0.8 all KL = 0.576 +- 0.217 (in-sample avg dev_std = 0.610)
NEC for r=0.8 all L1 = 0.539 +- 0.142 (in-sample avg dev_std = 0.610)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.8 =  0.404
Model XAI F1 of binarized graphs for r=0.8 =  0.34301874999999993
Model XAI WIoU of binarized graphs for r=0.8 =  0.23099499999999998
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.393
NEC for r=0.8 class 0 = 0.261 +- 0.446 (in-sample avg dev_std = 0.496)
NEC for r=0.8 class 1 = 0.25 +- 0.446 (in-sample avg dev_std = 0.496)
NEC for r=0.8 class 2 = 0.139 +- 0.446 (in-sample avg dev_std = 0.496)
NEC for r=0.8 all KL = 0.386 +- 0.446 (in-sample avg dev_std = 0.496)
NEC for r=0.8 all L1 = 0.216 +- 0.283 (in-sample avg dev_std = 0.496)


Evaluating SUFF for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.8 =  0.933
Model XAI F1 of binarized graphs for r=0.8 =  0.5163575
Model XAI WIoU of binarized graphs for r=0.8 =  0.65161
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.63
SUFF for r=0.8 class 0 = 0.351 +- 0.336 (in-sample avg dev_std = 0.445)
SUFF for r=0.8 class 1 = 0.522 +- 0.336 (in-sample avg dev_std = 0.445)
SUFF for r=0.8 class 2 = 0.865 +- 0.336 (in-sample avg dev_std = 0.445)
SUFF for r=0.8 all KL = 0.53 +- 0.336 (in-sample avg dev_std = 0.445)
SUFF for r=0.8 all L1 = 0.578 +- 0.285 (in-sample avg dev_std = 0.445)



--------------------------------------------------


#D#Computing SUFF over val across ratios (random_expl=False)


ratio=0.8


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.8 =  0.928
Model XAI F1 of binarized graphs for r=0.8 =  0.3072525
Model XAI WIoU of binarized graphs for r=0.8 =  0.89316125
len(reference) = 800
Effective ratio: 0.806 +- 0.005
Model Accuracy over intervened graphs for r=0.8 =  0.529
SUFF for r=0.8 class 0 = 0.358 +- 0.280 (in-sample avg dev_std = 0.442)
SUFF for r=0.8 class 1 = 0.445 +- 0.280 (in-sample avg dev_std = 0.442)
SUFF for r=0.8 class 2 = 0.812 +- 0.280 (in-sample avg dev_std = 0.442)
SUFF for r=0.8 all KL = 0.554 +- 0.280 (in-sample avg dev_std = 0.442)
SUFF for r=0.8 all L1 = 0.539 +- 0.263 (in-sample avg dev_std = 0.442)



--------------------------------------------------


#D#Computing SUFF over test across ratios (random_expl=False)


ratio=0.8


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.8 =  0.404
Model XAI F1 of binarized graphs for r=0.8 =  0.34301874999999993
Model XAI WIoU of binarized graphs for r=0.8 =  0.23099499999999998
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.371
SUFF for r=0.8 class 0 = 0.802 +- 0.373 (in-sample avg dev_std = 0.340)
SUFF for r=0.8 class 1 = 0.791 +- 0.373 (in-sample avg dev_std = 0.340)
SUFF for r=0.8 class 2 = 0.965 +- 0.373 (in-sample avg dev_std = 0.340)
SUFF for r=0.8 all KL = 0.785 +- 0.373 (in-sample avg dev_std = 0.340)
SUFF for r=0.8 all L1 = 0.853 +- 0.279 (in-sample avg dev_std = 0.340)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Mar 20 15:06:23 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 03/20/2024 03:06:23 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/20/2024 03:06:23 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/20/2024 03:06:23 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/20/2024 03:06:23 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/20/2024 03:06:23 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 03:06:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:06:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:06:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:06:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:06:23 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/20/2024 03:06:23 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 03:06:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:06:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:06:23 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/20/2024 03:06:23 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 15...
[0m[1;37mINFO[0m: [1mCheckpoint 15: 
-----------------------------------
Train ACCURACY: 0.8638
Train Loss: 0.5776
ID Validation ACCURACY: 0.8760
ID Validation Loss: 0.5248
ID Test ACCURACY: 0.8623
ID Test Loss: 0.5892
OOD Validation ACCURACY: 0.8237
OOD Validation Loss: 0.5364
OOD Test ACCURACY: 0.6500
OOD Test Loss: 2.0536

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 84...
[0m[1;37mINFO[0m: [1mCheckpoint 84: 
-----------------------------------
Train ACCURACY: 0.8533
Train Loss: 0.5252
ID Validation ACCURACY: 0.8630
ID Validation Loss: 0.4912
ID Test ACCURACY: 0.8500
ID Test Loss: 0.5371
OOD Validation ACCURACY: 0.8757
OOD Validation Loss: 0.4826
OOD Test ACCURACY: 0.4940
OOD Test Loss: 5.1451

[0m[1;37mINFO[0m: [1mChartInfo 0.8623 0.6500 0.8500 0.4940 0.8630 0.8757[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.8 = 0.514
WIoU for r=0.8 = 0.726
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.8 = 0.325
WIoU for r=0.8 = 0.972
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.8 = 0.421
WIoU for r=0.8 = 0.491
Size bank for r=0.8 -> 1497


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.8 =  0.88
Model XAI F1 of binarized graphs for r=0.8 =  0.51448625
Model XAI WIoU of binarized graphs for r=0.8 =  0.7255637500000001
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.458
NEC for r=0.8 class 0 = 0.573 +- 0.259 (in-sample avg dev_std = 0.727)
NEC for r=0.8 class 1 = 0.471 +- 0.259 (in-sample avg dev_std = 0.727)
NEC for r=0.8 class 2 = 0.667 +- 0.259 (in-sample avg dev_std = 0.727)
NEC for r=0.8 all KL = 0.722 +- 0.259 (in-sample avg dev_std = 0.727)
NEC for r=0.8 all L1 = 0.57 +- 0.198 (in-sample avg dev_std = 0.727)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.8


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.8 =  0.815
Model XAI F1 of binarized graphs for r=0.8 =  0.32483249999999997
Model XAI WIoU of binarized graphs for r=0.8 =  0.97190125
len(reference) = 800
Effective ratio: 0.806 +- 0.005
Model Accuracy over intervened graphs for r=0.8 =  0.495
NEC for r=0.8 class 0 = 0.547 +- 0.222 (in-sample avg dev_std = 0.650)
NEC for r=0.8 class 1 = 0.497 +- 0.222 (in-sample avg dev_std = 0.650)
NEC for r=0.8 class 2 = 0.564 +- 0.222 (in-sample avg dev_std = 0.650)
NEC for r=0.8 all KL = 0.594 +- 0.222 (in-sample avg dev_std = 0.650)
NEC for r=0.8 all L1 = 0.537 +- 0.143 (in-sample avg dev_std = 0.650)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.8 =  0.642
Model XAI F1 of binarized graphs for r=0.8 =  0.42105750000000003
Model XAI WIoU of binarized graphs for r=0.8 =  0.49111374999999996
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.525
NEC for r=0.8 class 0 = 0.541 +- 0.312 (in-sample avg dev_std = 0.630)
NEC for r=0.8 class 1 = 0.349 +- 0.312 (in-sample avg dev_std = 0.630)
NEC for r=0.8 class 2 = 0.476 +- 0.312 (in-sample avg dev_std = 0.630)
NEC for r=0.8 all KL = 0.616 +- 0.312 (in-sample avg dev_std = 0.630)
NEC for r=0.8 all L1 = 0.454 +- 0.183 (in-sample avg dev_std = 0.630)


Evaluating SUFF for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.8 =  0.88
Model XAI F1 of binarized graphs for r=0.8 =  0.51448625
Model XAI WIoU of binarized graphs for r=0.8 =  0.7255637500000001
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.747
SUFF for r=0.8 class 0 = 0.601 +- 0.267 (in-sample avg dev_std = 0.365)
SUFF for r=0.8 class 1 = 0.925 +- 0.267 (in-sample avg dev_std = 0.365)
SUFF for r=0.8 class 2 = 0.679 +- 0.267 (in-sample avg dev_std = 0.365)
SUFF for r=0.8 all KL = 0.729 +- 0.267 (in-sample avg dev_std = 0.365)
SUFF for r=0.8 all L1 = 0.736 +- 0.246 (in-sample avg dev_std = 0.365)



--------------------------------------------------


#D#Computing SUFF over val across ratios (random_expl=False)


ratio=0.8


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.8 =  0.815
Model XAI F1 of binarized graphs for r=0.8 =  0.32483249999999997
Model XAI WIoU of binarized graphs for r=0.8 =  0.97190125
len(reference) = 800
Effective ratio: 0.806 +- 0.005
Model Accuracy over intervened graphs for r=0.8 =  0.743
SUFF for r=0.8 class 0 = 0.724 +- 0.195 (in-sample avg dev_std = 0.337)
SUFF for r=0.8 class 1 = 0.841 +- 0.195 (in-sample avg dev_std = 0.337)
SUFF for r=0.8 class 2 = 0.639 +- 0.195 (in-sample avg dev_std = 0.337)
SUFF for r=0.8 all KL = 0.792 +- 0.195 (in-sample avg dev_std = 0.337)
SUFF for r=0.8 all L1 = 0.733 +- 0.176 (in-sample avg dev_std = 0.337)



--------------------------------------------------


#D#Computing SUFF over test across ratios (random_expl=False)


ratio=0.8


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.8 =  0.642
Model XAI F1 of binarized graphs for r=0.8 =  0.42105750000000003
Model XAI WIoU of binarized graphs for r=0.8 =  0.49111374999999996
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.596
SUFF for r=0.8 class 0 = 0.583 +- 0.249 (in-sample avg dev_std = 0.364)
SUFF for r=0.8 class 1 = 0.822 +- 0.249 (in-sample avg dev_std = 0.364)
SUFF for r=0.8 class 2 = 0.747 +- 0.249 (in-sample avg dev_std = 0.364)
SUFF for r=0.8 all KL = 0.693 +- 0.249 (in-sample avg dev_std = 0.364)
SUFF for r=0.8 all L1 = 0.719 +- 0.178 (in-sample avg dev_std = 0.364)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Mar 20 15:07:43 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 03/20/2024 03:07:43 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/20/2024 03:07:43 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/20/2024 03:07:43 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/20/2024 03:07:43 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/20/2024 03:07:43 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 03:07:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:07:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:07:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:07:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:07:43 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/20/2024 03:07:43 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 03:07:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:07:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:07:43 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/20/2024 03:07:43 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 17...
[0m[1;37mINFO[0m: [1mCheckpoint 17: 
-----------------------------------
Train ACCURACY: 0.9147
Train Loss: 0.4936
ID Validation ACCURACY: 0.9210
ID Validation Loss: 0.4879
ID Test ACCURACY: 0.9093
ID Test Loss: 0.5467
OOD Validation ACCURACY: 0.8387
OOD Validation Loss: 0.5746
OOD Test ACCURACY: 0.4087
OOD Test Loss: 32.4148

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 30...
[0m[1;37mINFO[0m: [1mCheckpoint 30: 
-----------------------------------
Train ACCURACY: 0.8200
Train Loss: 0.6115
ID Validation ACCURACY: 0.8157
ID Validation Loss: 0.6203
ID Test ACCURACY: 0.8157
ID Test Loss: 0.6734
OOD Validation ACCURACY: 0.8897
OOD Validation Loss: 0.4646
OOD Test ACCURACY: 0.3343
OOD Test Loss: 29.0064

[0m[1;37mINFO[0m: [1mChartInfo 0.9093 0.4087 0.8157 0.3343 0.8157 0.8897[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.8 = 0.518
WIoU for r=0.8 = 0.501
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.8 = 0.324
WIoU for r=0.8 = 0.261
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.8 = 0.302
WIoU for r=0.8 = 0.200
Size bank for r=0.8 -> 1498


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.8 =  0.925
Model XAI F1 of binarized graphs for r=0.8 =  0.51809375
Model XAI WIoU of binarized graphs for r=0.8 =  0.5013487499999999
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.459
NEC for r=0.8 class 0 = 0.642 +- 0.245 (in-sample avg dev_std = 0.718)
NEC for r=0.8 class 1 = 0.591 +- 0.245 (in-sample avg dev_std = 0.718)
NEC for r=0.8 class 2 = 0.571 +- 0.245 (in-sample avg dev_std = 0.718)
NEC for r=0.8 all KL = 0.776 +- 0.245 (in-sample avg dev_std = 0.718)
NEC for r=0.8 all L1 = 0.602 +- 0.170 (in-sample avg dev_std = 0.718)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.8


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.8 =  0.831
Model XAI F1 of binarized graphs for r=0.8 =  0.32363625
Model XAI WIoU of binarized graphs for r=0.8 =  0.2613325
len(reference) = 800
Effective ratio: 0.806 +- 0.005
Model Accuracy over intervened graphs for r=0.8 =  0.412
NEC for r=0.8 class 0 = 0.633 +- 0.220 (in-sample avg dev_std = 0.541)
NEC for r=0.8 class 1 = 0.616 +- 0.220 (in-sample avg dev_std = 0.541)
NEC for r=0.8 class 2 = 0.364 +- 0.220 (in-sample avg dev_std = 0.541)
NEC for r=0.8 all KL = 0.605 +- 0.220 (in-sample avg dev_std = 0.541)
NEC for r=0.8 all L1 = 0.537 +- 0.181 (in-sample avg dev_std = 0.541)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.8 =  0.404
Model XAI F1 of binarized graphs for r=0.8 =  0.3022025
Model XAI WIoU of binarized graphs for r=0.8 =  0.19976875
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.385
NEC for r=0.8 class 0 = 0.223 +- 0.414 (in-sample avg dev_std = 0.364)
NEC for r=0.8 class 1 = 0.2 +- 0.414 (in-sample avg dev_std = 0.364)
NEC for r=0.8 class 2 = 0.098 +- 0.414 (in-sample avg dev_std = 0.364)
NEC for r=0.8 all KL = 0.315 +- 0.414 (in-sample avg dev_std = 0.364)
NEC for r=0.8 all L1 = 0.173 +- 0.262 (in-sample avg dev_std = 0.364)


Evaluating SUFF for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.8 =  0.925
Model XAI F1 of binarized graphs for r=0.8 =  0.51809375
Model XAI WIoU of binarized graphs for r=0.8 =  0.5013487499999999
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.626
SUFF for r=0.8 class 0 = 0.363 +- 0.342 (in-sample avg dev_std = 0.427)
SUFF for r=0.8 class 1 = 0.535 +- 0.342 (in-sample avg dev_std = 0.427)
SUFF for r=0.8 class 2 = 0.909 +- 0.342 (in-sample avg dev_std = 0.427)
SUFF for r=0.8 all KL = 0.584 +- 0.342 (in-sample avg dev_std = 0.427)
SUFF for r=0.8 all L1 = 0.601 +- 0.295 (in-sample avg dev_std = 0.427)



--------------------------------------------------


#D#Computing SUFF over val across ratios (random_expl=False)


ratio=0.8


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.8 =  0.831
Model XAI F1 of binarized graphs for r=0.8 =  0.32363625
Model XAI WIoU of binarized graphs for r=0.8 =  0.2613325
len(reference) = 800
Effective ratio: 0.806 +- 0.005
Model Accuracy over intervened graphs for r=0.8 =  0.485
SUFF for r=0.8 class 0 = 0.398 +- 0.285 (in-sample avg dev_std = 0.368)
SUFF for r=0.8 class 1 = 0.435 +- 0.285 (in-sample avg dev_std = 0.368)
SUFF for r=0.8 class 2 = 0.892 +- 0.285 (in-sample avg dev_std = 0.368)
SUFF for r=0.8 all KL = 0.626 +- 0.285 (in-sample avg dev_std = 0.368)
SUFF for r=0.8 all L1 = 0.577 +- 0.286 (in-sample avg dev_std = 0.368)



--------------------------------------------------


#D#Computing SUFF over test across ratios (random_expl=False)


ratio=0.8


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.8 =  0.404
Model XAI F1 of binarized graphs for r=0.8 =  0.3022025
Model XAI WIoU of binarized graphs for r=0.8 =  0.19976875
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.335
SUFF for r=0.8 class 0 = 0.874 +- 0.198 (in-sample avg dev_std = 0.121)
SUFF for r=0.8 class 1 = 0.84 +- 0.198 (in-sample avg dev_std = 0.121)
SUFF for r=0.8 class 2 = 0.996 +- 0.198 (in-sample avg dev_std = 0.121)
SUFF for r=0.8 all KL = 0.917 +- 0.198 (in-sample avg dev_std = 0.121)
SUFF for r=0.8 all L1 = 0.903 +- 0.227 (in-sample avg dev_std = 0.121)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Mar 20 15:09:03 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 03/20/2024 03:09:03 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/20/2024 03:09:03 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/20/2024 03:09:03 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/20/2024 03:09:03 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/20/2024 03:09:03 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 03:09:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:09:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:09:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:09:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:09:03 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/20/2024 03:09:03 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 03:09:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:09:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:09:03 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/20/2024 03:09:03 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 17...
[0m[1;37mINFO[0m: [1mCheckpoint 17: 
-----------------------------------
Train ACCURACY: 0.9185
Train Loss: 0.4761
ID Validation ACCURACY: 0.9243
ID Validation Loss: 0.4624
ID Test ACCURACY: 0.9137
ID Test Loss: 0.5178
OOD Validation ACCURACY: 0.8713
OOD Validation Loss: 0.5049
OOD Test ACCURACY: 0.4087
OOD Test Loss: 34.3607

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 20...
[0m[1;37mINFO[0m: [1mCheckpoint 20: 
-----------------------------------
Train ACCURACY: 0.9192
Train Loss: 0.4721
ID Validation ACCURACY: 0.9240
ID Validation Loss: 0.4583
ID Test ACCURACY: 0.9157
ID Test Loss: 0.5307
OOD Validation ACCURACY: 0.9143
OOD Validation Loss: 0.4105
OOD Test ACCURACY: 0.4087
OOD Test Loss: 17.9440

[0m[1;37mINFO[0m: [1mChartInfo 0.9137 0.4087 0.9157 0.4087 0.9240 0.9143[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.8 = 0.521
WIoU for r=0.8 = 0.522
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.8 = 0.324
WIoU for r=0.8 = 0.295
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.8 = 0.309
WIoU for r=0.8 = 0.202
Size bank for r=0.8 -> 1496


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.8 =  0.933
Model XAI F1 of binarized graphs for r=0.8 =  0.5208375000000001
Model XAI WIoU of binarized graphs for r=0.8 =  0.5218050000000001
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.459
NEC for r=0.8 class 0 = 0.665 +- 0.238 (in-sample avg dev_std = 0.723)
NEC for r=0.8 class 1 = 0.574 +- 0.238 (in-sample avg dev_std = 0.723)
NEC for r=0.8 class 2 = 0.582 +- 0.238 (in-sample avg dev_std = 0.723)
NEC for r=0.8 all KL = 0.777 +- 0.238 (in-sample avg dev_std = 0.723)
NEC for r=0.8 all L1 = 0.607 +- 0.173 (in-sample avg dev_std = 0.723)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.8


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.8 =  0.879
Model XAI F1 of binarized graphs for r=0.8 =  0.32405
Model XAI WIoU of binarized graphs for r=0.8 =  0.2951175
len(reference) = 800
Effective ratio: 0.806 +- 0.005
Model Accuracy over intervened graphs for r=0.8 =  0.418
NEC for r=0.8 class 0 = 0.691 +- 0.215 (in-sample avg dev_std = 0.569)
NEC for r=0.8 class 1 = 0.6 +- 0.215 (in-sample avg dev_std = 0.569)
NEC for r=0.8 class 2 = 0.385 +- 0.215 (in-sample avg dev_std = 0.569)
NEC for r=0.8 all KL = 0.632 +- 0.215 (in-sample avg dev_std = 0.569)
NEC for r=0.8 all L1 = 0.558 +- 0.182 (in-sample avg dev_std = 0.569)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.8 =  0.405
Model XAI F1 of binarized graphs for r=0.8 =  0.30855
Model XAI WIoU of binarized graphs for r=0.8 =  0.20215000000000002
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.367
NEC for r=0.8 class 0 = 0.246 +- 0.452 (in-sample avg dev_std = 0.447)
NEC for r=0.8 class 1 = 0.236 +- 0.452 (in-sample avg dev_std = 0.447)
NEC for r=0.8 class 2 = 0.166 +- 0.452 (in-sample avg dev_std = 0.447)
NEC for r=0.8 all KL = 0.412 +- 0.452 (in-sample avg dev_std = 0.447)
NEC for r=0.8 all L1 = 0.216 +- 0.276 (in-sample avg dev_std = 0.447)


Evaluating SUFF for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.8 =  0.933
Model XAI F1 of binarized graphs for r=0.8 =  0.5208375000000001
Model XAI WIoU of binarized graphs for r=0.8 =  0.5218050000000001
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.705
SUFF for r=0.8 class 0 = 0.475 +- 0.313 (in-sample avg dev_std = 0.487)
SUFF for r=0.8 class 1 = 0.581 +- 0.313 (in-sample avg dev_std = 0.487)
SUFF for r=0.8 class 2 = 0.884 +- 0.313 (in-sample avg dev_std = 0.487)
SUFF for r=0.8 all KL = 0.6 +- 0.313 (in-sample avg dev_std = 0.487)
SUFF for r=0.8 all L1 = 0.646 +- 0.253 (in-sample avg dev_std = 0.487)



--------------------------------------------------


#D#Computing SUFF over val across ratios (random_expl=False)


ratio=0.8


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.8 =  0.879
Model XAI F1 of binarized graphs for r=0.8 =  0.32405
Model XAI WIoU of binarized graphs for r=0.8 =  0.2951175
len(reference) = 800
Effective ratio: 0.806 +- 0.005
Model Accuracy over intervened graphs for r=0.8 =  0.557
SUFF for r=0.8 class 0 = 0.459 +- 0.263 (in-sample avg dev_std = 0.437)
SUFF for r=0.8 class 1 = 0.482 +- 0.263 (in-sample avg dev_std = 0.437)
SUFF for r=0.8 class 2 = 0.851 +- 0.263 (in-sample avg dev_std = 0.437)
SUFF for r=0.8 all KL = 0.641 +- 0.263 (in-sample avg dev_std = 0.437)
SUFF for r=0.8 all L1 = 0.599 +- 0.253 (in-sample avg dev_std = 0.437)



--------------------------------------------------


#D#Computing SUFF over test across ratios (random_expl=False)


ratio=0.8


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.8 =  0.405
Model XAI F1 of binarized graphs for r=0.8 =  0.30855
Model XAI WIoU of binarized graphs for r=0.8 =  0.20215000000000002
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.352
SUFF for r=0.8 class 0 = 0.877 +- 0.188 (in-sample avg dev_std = 0.182)
SUFF for r=0.8 class 1 = 0.857 +- 0.188 (in-sample avg dev_std = 0.182)
SUFF for r=0.8 class 2 = 0.996 +- 0.188 (in-sample avg dev_std = 0.182)
SUFF for r=0.8 all KL = 0.925 +- 0.188 (in-sample avg dev_std = 0.182)
SUFF for r=0.8 all L1 = 0.91 +- 0.213 (in-sample avg dev_std = 0.182)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Mar 20 15:10:23 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 03/20/2024 03:10:23 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/20/2024 03:10:23 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/20/2024 03:10:23 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/20/2024 03:10:23 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/20/2024 03:10:23 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 03:10:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:10:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:10:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:10:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:10:23 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/20/2024 03:10:23 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 03:10:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:10:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:10:23 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/20/2024 03:10:23 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 183...
[0m[1;37mINFO[0m: [1mCheckpoint 183: 
-----------------------------------
Train ACCURACY: 0.8962
Train Loss: 0.4182
ID Validation ACCURACY: 0.9057
ID Validation Loss: 0.4121
ID Test ACCURACY: 0.8953
ID Test Loss: 0.4527
OOD Validation ACCURACY: 0.9027
OOD Validation Loss: 0.4390
OOD Test ACCURACY: 0.4087
OOD Test Loss: 28.0354

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 129...
[0m[1;37mINFO[0m: [1mCheckpoint 129: 
-----------------------------------
Train ACCURACY: 0.8330
Train Loss: 0.5186
ID Validation ACCURACY: 0.8323
ID Validation Loss: 0.5186
ID Test ACCURACY: 0.8267
ID Test Loss: 0.5417
OOD Validation ACCURACY: 0.9140
OOD Validation Loss: 0.4398
OOD Test ACCURACY: 0.4087
OOD Test Loss: 25.0431

[0m[1;37mINFO[0m: [1mChartInfo 0.8953 0.4087 0.8267 0.4087 0.8323 0.9140[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.8 = 0.481
WIoU for r=0.8 = 0.660
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.8 = 0.300
WIoU for r=0.8 = 0.800
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.8 = 0.186
WIoU for r=0.8 = 0.101
Size bank for r=0.8 -> 1498


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.8 =  0.914
Model XAI F1 of binarized graphs for r=0.8 =  0.480535
Model XAI WIoU of binarized graphs for r=0.8 =  0.66007125
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.465
NEC for r=0.8 class 0 = 0.628 +- 0.232 (in-sample avg dev_std = 0.697)
NEC for r=0.8 class 1 = 0.575 +- 0.232 (in-sample avg dev_std = 0.697)
NEC for r=0.8 class 2 = 0.608 +- 0.232 (in-sample avg dev_std = 0.697)
NEC for r=0.8 all KL = 0.711 +- 0.232 (in-sample avg dev_std = 0.697)
NEC for r=0.8 all L1 = 0.604 +- 0.149 (in-sample avg dev_std = 0.697)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.8


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.8 =  0.908
Model XAI F1 of binarized graphs for r=0.8 =  0.3002225
Model XAI WIoU of binarized graphs for r=0.8 =  0.80019875
len(reference) = 800
Effective ratio: 0.806 +- 0.005
Model Accuracy over intervened graphs for r=0.8 =  0.497
NEC for r=0.8 class 0 = 0.579 +- 0.220 (in-sample avg dev_std = 0.573)
NEC for r=0.8 class 1 = 0.529 +- 0.220 (in-sample avg dev_std = 0.573)
NEC for r=0.8 class 2 = 0.5 +- 0.220 (in-sample avg dev_std = 0.573)
NEC for r=0.8 all KL = 0.562 +- 0.220 (in-sample avg dev_std = 0.573)
NEC for r=0.8 all L1 = 0.536 +- 0.121 (in-sample avg dev_std = 0.573)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.8 =  0.404
Model XAI F1 of binarized graphs for r=0.8 =  0.18561999999999998
Model XAI WIoU of binarized graphs for r=0.8 =  0.1005675
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.404
NEC for r=0.8 class 0 = 0.275 +- 0.445 (in-sample avg dev_std = 0.482)
NEC for r=0.8 class 1 = 0.222 +- 0.445 (in-sample avg dev_std = 0.482)
NEC for r=0.8 class 2 = 0.16 +- 0.445 (in-sample avg dev_std = 0.482)
NEC for r=0.8 all KL = 0.415 +- 0.445 (in-sample avg dev_std = 0.482)
NEC for r=0.8 all L1 = 0.219 +- 0.280 (in-sample avg dev_std = 0.482)


Evaluating SUFF for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.8 =  0.914
Model XAI F1 of binarized graphs for r=0.8 =  0.480535
Model XAI WIoU of binarized graphs for r=0.8 =  0.66007125
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.59
SUFF for r=0.8 class 0 = 0.331 +- 0.307 (in-sample avg dev_std = 0.477)
SUFF for r=0.8 class 1 = 0.55 +- 0.307 (in-sample avg dev_std = 0.477)
SUFF for r=0.8 class 2 = 0.647 +- 0.307 (in-sample avg dev_std = 0.477)
SUFF for r=0.8 all KL = 0.45 +- 0.307 (in-sample avg dev_std = 0.477)
SUFF for r=0.8 all L1 = 0.509 +- 0.241 (in-sample avg dev_std = 0.477)



--------------------------------------------------


#D#Computing SUFF over val across ratios (random_expl=False)


ratio=0.8


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.8 =  0.908
Model XAI F1 of binarized graphs for r=0.8 =  0.3002225
Model XAI WIoU of binarized graphs for r=0.8 =  0.80019875
len(reference) = 800
Effective ratio: 0.806 +- 0.005
Model Accuracy over intervened graphs for r=0.8 =  0.553
SUFF for r=0.8 class 0 = 0.357 +- 0.249 (in-sample avg dev_std = 0.419)
SUFF for r=0.8 class 1 = 0.575 +- 0.249 (in-sample avg dev_std = 0.419)
SUFF for r=0.8 class 2 = 0.773 +- 0.249 (in-sample avg dev_std = 0.419)
SUFF for r=0.8 all KL = 0.611 +- 0.249 (in-sample avg dev_std = 0.419)
SUFF for r=0.8 all L1 = 0.569 +- 0.236 (in-sample avg dev_std = 0.419)



--------------------------------------------------


#D#Computing SUFF over test across ratios (random_expl=False)


ratio=0.8


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.8 =  0.404
Model XAI F1 of binarized graphs for r=0.8 =  0.18561999999999998
Model XAI WIoU of binarized graphs for r=0.8 =  0.1005675
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.354
SUFF for r=0.8 class 0 = 0.89 +- 0.262 (in-sample avg dev_std = 0.251)
SUFF for r=0.8 class 1 = 0.843 +- 0.262 (in-sample avg dev_std = 0.251)
SUFF for r=0.8 class 2 = 0.968 +- 0.262 (in-sample avg dev_std = 0.251)
SUFF for r=0.8 all KL = 0.895 +- 0.262 (in-sample avg dev_std = 0.251)
SUFF for r=0.8 all L1 = 0.9 +- 0.221 (in-sample avg dev_std = 0.251)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
nec = [defaultdict(<class 'list'>, {'all_KL': [0.733], 'all_L1': [0.612]}), defaultdict(<class 'list'>, {'all_KL': [0.722], 'all_L1': [0.57]}), defaultdict(<class 'list'>, {'all_KL': [0.776], 'all_L1': [0.602]}), defaultdict(<class 'list'>, {'all_KL': [0.777], 'all_L1': [0.607]}), defaultdict(<class 'list'>, {'all_KL': [0.711], 'all_L1': [0.604]})]
suff = [defaultdict(<class 'list'>, {'all_KL': [0.53], 'all_L1': [0.578]}), defaultdict(<class 'list'>, {'all_KL': [0.729], 'all_L1': [0.736]}), defaultdict(<class 'list'>, {'all_KL': [0.584], 'all_L1': [0.601]}), defaultdict(<class 'list'>, {'all_KL': [0.6], 'all_L1': [0.646]}), defaultdict(<class 'list'>, {'all_KL': [0.45], 'all_L1': [0.509]})]

Eval split val
nec = [defaultdict(<class 'list'>, {'all_KL': [0.576], 'all_L1': [0.539]}), defaultdict(<class 'list'>, {'all_KL': [0.594], 'all_L1': [0.537]}), defaultdict(<class 'list'>, {'all_KL': [0.605], 'all_L1': [0.537]}), defaultdict(<class 'list'>, {'all_KL': [0.632], 'all_L1': [0.558]}), defaultdict(<class 'list'>, {'all_KL': [0.562], 'all_L1': [0.536]})]
suff = [defaultdict(<class 'list'>, {'all_KL': [0.554], 'all_L1': [0.539]}), defaultdict(<class 'list'>, {'all_KL': [0.792], 'all_L1': [0.733]}), defaultdict(<class 'list'>, {'all_KL': [0.626], 'all_L1': [0.577]}), defaultdict(<class 'list'>, {'all_KL': [0.641], 'all_L1': [0.599]}), defaultdict(<class 'list'>, {'all_KL': [0.611], 'all_L1': [0.569]})]

Eval split test
nec = [defaultdict(<class 'list'>, {'all_KL': [0.386], 'all_L1': [0.216]}), defaultdict(<class 'list'>, {'all_KL': [0.616], 'all_L1': [0.454]}), defaultdict(<class 'list'>, {'all_KL': [0.315], 'all_L1': [0.173]}), defaultdict(<class 'list'>, {'all_KL': [0.412], 'all_L1': [0.216]}), defaultdict(<class 'list'>, {'all_KL': [0.415], 'all_L1': [0.219]})]
suff = [defaultdict(<class 'list'>, {'all_KL': [0.785], 'all_L1': [0.853]}), defaultdict(<class 'list'>, {'all_KL': [0.693], 'all_L1': [0.719]}), defaultdict(<class 'list'>, {'all_KL': [0.917], 'all_L1': [0.903]}), defaultdict(<class 'list'>, {'all_KL': [0.925], 'all_L1': [0.91]}), defaultdict(<class 'list'>, {'all_KL': [0.895], 'all_L1': [0.9]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
nec class all_KL  =  0.744 +- 0.028
nec class all_L1  =  0.599 +- 0.015
nec_acc_int  =  0.457 +- 0.007
suff class all_KL  =  0.579 +- 0.092
suff class all_L1  =  0.614 +- 0.075
suff_acc_int  =  0.660 +- 0.057

Eval split val
nec class all_KL  =  0.594 +- 0.024
nec class all_L1  =  0.541 +- 0.008
nec_acc_int  =  0.464 +- 0.040
suff class all_KL  =  0.645 +- 0.079
suff class all_L1  =  0.603 +- 0.068
suff_acc_int  =  0.573 +- 0.089

Eval split test
nec class all_KL  =  0.429 +- 0.100
nec class all_L1  =  0.256 +- 0.101
nec_acc_int  =  0.415 +- 0.056
suff class all_KL  =  0.843 +- 0.090
suff class all_L1  =  0.857 +- 0.072
suff_acc_int  =  0.402 +- 0.098


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
torch.Size([5, 1]) torch.Size([5, 1])
torch.Size([5, 1])
Faith. Aritm= 		  =  0.607 +- 0.032
Faith. Armon= 		  =  0.603 +- 0.031
Faith. GMean = 	  =  0.605 +- 0.031

Eval split val
torch.Size([5, 1]) torch.Size([5, 1])
torch.Size([5, 1])
Faith. Aritm= 		  =  0.572 +- 0.034
Faith. Armon= 		  =  0.569 +- 0.028
Faith. GMean = 	  =  0.571 +- 0.031

Eval split test
torch.Size([5, 1]) torch.Size([5, 1])
torch.Size([5, 1])
Faith. Aritm= 		  =  0.556 +- 0.019
Faith. Armon= 		  =  0.379 +- 0.092
Faith. GMean = 	  =  0.457 +- 0.060
Computed for split load_split = id



Completed in  0:06:58.291393  for CIGAGIN GOODMotif2/basis



DONE CIGA GOODMotif2/basis

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Mar 20 15:11:59 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 03/20/2024 03:11:59 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/20/2024 03:11:59 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/20/2024 03:11:59 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 03:11:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:11:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:11:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:11:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:11:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:11:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:11:59 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 107...
[0m[1;37mINFO[0m: [1mCheckpoint 107: 
-----------------------------------
Train ACCURACY: 0.9297
Train Loss: 0.3252
ID Validation ACCURACY: 0.9357
ID Validation Loss: 0.3127
ID Test ACCURACY: 0.9257
ID Test Loss: 0.3421
OOD Validation ACCURACY: 0.9270
OOD Validation Loss: 0.4181
OOD Test ACCURACY: 0.7947
OOD Test Loss: 0.8208

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 47...
[0m[1;37mINFO[0m: [1mCheckpoint 47: 
-----------------------------------
Train ACCURACY: 0.9265
Train Loss: 0.3388
ID Validation ACCURACY: 0.9317
ID Validation Loss: 0.3254
ID Test ACCURACY: 0.9243
ID Test Loss: 0.3540
OOD Validation ACCURACY: 0.9300
OOD Validation Loss: 0.3738
OOD Test ACCURACY: 0.6353
OOD Test Loss: 1.7363

[0m[1;37mINFO[0m: [1mChartInfo 0.9257 0.7947 0.9243 0.6353 0.9317 0.9300[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.690
WIoU for r=0.3 = 0.571
F1 for r=0.6 = 0.574
WIoU for r=0.6 = 0.453
F1 for r=0.9 = 0.464
WIoU for r=0.9 = 0.339
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.328
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.481
WIoU for r=0.3 = 0.372
F1 for r=0.6 = 0.313
WIoU for r=0.6 = 0.211
F1 for r=0.9 = 0.252
WIoU for r=0.9 = 0.161
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.169
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.570
WIoU for r=0.3 = 0.454
F1 for r=0.6 = 0.495
WIoU for r=0.6 = 0.360
F1 for r=0.9 = 0.413
WIoU for r=0.9 = 0.282
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.264
Size bank for r=0.3 -> 1500
Size bank for r=0.6 -> 1500
Size bank for r=0.9 -> 1431


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.436
Model XAI F1 of binarized graphs for r=0.3 =  0.6901037500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.5714425
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.32
NEC for r=0.3 class 0 = 0.587 +- 0.307 (in-sample avg dev_std = 0.372)
NEC for r=0.3 class 1 = 0.462 +- 0.307 (in-sample avg dev_std = 0.372)
NEC for r=0.3 class 2 = 0.631 +- 0.307 (in-sample avg dev_std = 0.372)
NEC for r=0.3 all KL = 0.557 +- 0.307 (in-sample avg dev_std = 0.372)
NEC for r=0.3 all L1 = 0.56 +- 0.194 (in-sample avg dev_std = 0.372)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.669
Model XAI F1 of binarized graphs for r=0.6 =  0.5735825
Model XAI WIoU of binarized graphs for r=0.6 =  0.45319249999999994
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.404
NEC for r=0.6 class 0 = 0.578 +- 0.269 (in-sample avg dev_std = 0.453)
NEC for r=0.6 class 1 = 0.468 +- 0.269 (in-sample avg dev_std = 0.453)
NEC for r=0.6 class 2 = 0.658 +- 0.269 (in-sample avg dev_std = 0.453)
NEC for r=0.6 all KL = 0.613 +- 0.269 (in-sample avg dev_std = 0.453)
NEC for r=0.6 all L1 = 0.567 +- 0.175 (in-sample avg dev_std = 0.453)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.914
Model XAI F1 of binarized graphs for r=0.9 =  0.4635787500000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.33889125
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.514
NEC for r=0.9 class 0 = 0.61 +- 0.222 (in-sample avg dev_std = 0.571)
NEC for r=0.9 class 1 = 0.461 +- 0.222 (in-sample avg dev_std = 0.571)
NEC for r=0.9 class 2 = 0.586 +- 0.222 (in-sample avg dev_std = 0.571)
NEC for r=0.9 all KL = 0.582 +- 0.222 (in-sample avg dev_std = 0.571)
NEC for r=0.9 all L1 = 0.552 +- 0.155 (in-sample avg dev_std = 0.571)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.942
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.32798125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.549
NEC for r=1.0 class 0 = 0.563 +- 0.231 (in-sample avg dev_std = 0.616)
NEC for r=1.0 class 1 = 0.428 +- 0.231 (in-sample avg dev_std = 0.616)
NEC for r=1.0 class 2 = 0.566 +- 0.231 (in-sample avg dev_std = 0.616)
NEC for r=1.0 all KL = 0.553 +- 0.231 (in-sample avg dev_std = 0.616)
NEC for r=1.0 all L1 = 0.519 +- 0.168 (in-sample avg dev_std = 0.616)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.57
Model XAI F1 of binarized graphs for r=0.3 =  0.48095625
Model XAI WIoU of binarized graphs for r=0.3 =  0.3720125
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.339
NEC for r=0.3 class 0 = 0.441 +- 0.272 (in-sample avg dev_std = 0.341)
NEC for r=0.3 class 1 = 0.478 +- 0.272 (in-sample avg dev_std = 0.341)
NEC for r=0.3 class 2 = 0.674 +- 0.272 (in-sample avg dev_std = 0.341)
NEC for r=0.3 all KL = 0.455 +- 0.272 (in-sample avg dev_std = 0.341)
NEC for r=0.3 all L1 = 0.532 +- 0.159 (in-sample avg dev_std = 0.341)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.679
Model XAI F1 of binarized graphs for r=0.6 =  0.3126775
Model XAI WIoU of binarized graphs for r=0.6 =  0.21100875000000002
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.437
NEC for r=0.6 class 0 = 0.563 +- 0.218 (in-sample avg dev_std = 0.400)
NEC for r=0.6 class 1 = 0.422 +- 0.218 (in-sample avg dev_std = 0.400)
NEC for r=0.6 class 2 = 0.561 +- 0.218 (in-sample avg dev_std = 0.400)
NEC for r=0.6 all KL = 0.416 +- 0.218 (in-sample avg dev_std = 0.400)
NEC for r=0.6 all L1 = 0.516 +- 0.135 (in-sample avg dev_std = 0.400)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.842
Model XAI F1 of binarized graphs for r=0.9 =  0.2524925
Model XAI WIoU of binarized graphs for r=0.9 =  0.1609675
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.535
NEC for r=0.9 class 0 = 0.54 +- 0.182 (in-sample avg dev_std = 0.484)
NEC for r=0.9 class 1 = 0.483 +- 0.182 (in-sample avg dev_std = 0.484)
NEC for r=0.9 class 2 = 0.482 +- 0.182 (in-sample avg dev_std = 0.484)
NEC for r=0.9 all KL = 0.446 +- 0.182 (in-sample avg dev_std = 0.484)
NEC for r=0.9 all L1 = 0.502 +- 0.109 (in-sample avg dev_std = 0.484)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.929
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.16925374999999998
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.573
NEC for r=1.0 class 0 = 0.483 +- 0.208 (in-sample avg dev_std = 0.542)
NEC for r=1.0 class 1 = 0.459 +- 0.208 (in-sample avg dev_std = 0.542)
NEC for r=1.0 class 2 = 0.522 +- 0.208 (in-sample avg dev_std = 0.542)
NEC for r=1.0 all KL = 0.478 +- 0.208 (in-sample avg dev_std = 0.542)
NEC for r=1.0 all L1 = 0.488 +- 0.121 (in-sample avg dev_std = 0.542)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.359
Model XAI F1 of binarized graphs for r=0.3 =  0.56971625
Model XAI WIoU of binarized graphs for r=0.3 =  0.45398375
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.408
NEC for r=0.3 class 0 = 0.467 +- 0.260 (in-sample avg dev_std = 0.405)
NEC for r=0.3 class 1 = 0.543 +- 0.260 (in-sample avg dev_std = 0.405)
NEC for r=0.3 class 2 = 0.577 +- 0.260 (in-sample avg dev_std = 0.405)
NEC for r=0.3 all KL = 0.513 +- 0.260 (in-sample avg dev_std = 0.405)
NEC for r=0.3 all L1 = 0.53 +- 0.156 (in-sample avg dev_std = 0.405)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.766
Model XAI F1 of binarized graphs for r=0.6 =  0.4948887500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.35975250000000003
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.446
NEC for r=0.6 class 0 = 0.612 +- 0.253 (in-sample avg dev_std = 0.545)
NEC for r=0.6 class 1 = 0.418 +- 0.253 (in-sample avg dev_std = 0.545)
NEC for r=0.6 class 2 = 0.621 +- 0.253 (in-sample avg dev_std = 0.545)
NEC for r=0.6 all KL = 0.565 +- 0.253 (in-sample avg dev_std = 0.545)
NEC for r=0.6 all L1 = 0.549 +- 0.180 (in-sample avg dev_std = 0.545)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.754
Model XAI F1 of binarized graphs for r=0.9 =  0.4132875
Model XAI WIoU of binarized graphs for r=0.9 =  0.281845
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.588
NEC for r=0.9 class 0 = 0.536 +- 0.236 (in-sample avg dev_std = 0.496)
NEC for r=0.9 class 1 = 0.35 +- 0.236 (in-sample avg dev_std = 0.496)
NEC for r=0.9 class 2 = 0.428 +- 0.236 (in-sample avg dev_std = 0.496)
NEC for r=0.9 all KL = 0.395 +- 0.236 (in-sample avg dev_std = 0.496)
NEC for r=0.9 all L1 = 0.436 +- 0.179 (in-sample avg dev_std = 0.496)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.809
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.26427125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.608
NEC for r=1.0 class 0 = 0.457 +- 0.259 (in-sample avg dev_std = 0.473)
NEC for r=1.0 class 1 = 0.331 +- 0.259 (in-sample avg dev_std = 0.473)
NEC for r=1.0 class 2 = 0.407 +- 0.259 (in-sample avg dev_std = 0.473)
NEC for r=1.0 all KL = 0.369 +- 0.259 (in-sample avg dev_std = 0.473)
NEC for r=1.0 all L1 = 0.397 +- 0.174 (in-sample avg dev_std = 0.473)


Evaluating SUFF for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.434
Model XAI F1 of binarized graphs for r=0.3 =  0.6901037500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.5714425
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.467
SUFF for r=0.3 class 0 = 0.516 +- 0.272 (in-sample avg dev_std = 0.440)
SUFF for r=0.3 class 1 = 0.553 +- 0.272 (in-sample avg dev_std = 0.440)
SUFF for r=0.3 class 2 = 0.502 +- 0.272 (in-sample avg dev_std = 0.440)
SUFF for r=0.3 all KL = 0.547 +- 0.272 (in-sample avg dev_std = 0.440)
SUFF for r=0.3 all L1 = 0.524 +- 0.151 (in-sample avg dev_std = 0.440)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.669
Model XAI F1 of binarized graphs for r=0.6 =  0.5735825
Model XAI WIoU of binarized graphs for r=0.6 =  0.45319249999999994
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.592
SUFF for r=0.6 class 0 = 0.442 +- 0.250 (in-sample avg dev_std = 0.353)
SUFF for r=0.6 class 1 = 0.783 +- 0.250 (in-sample avg dev_std = 0.353)
SUFF for r=0.6 class 2 = 0.599 +- 0.250 (in-sample avg dev_std = 0.353)
SUFF for r=0.6 all KL = 0.624 +- 0.250 (in-sample avg dev_std = 0.353)
SUFF for r=0.6 all L1 = 0.608 +- 0.201 (in-sample avg dev_std = 0.353)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.913
Model XAI F1 of binarized graphs for r=0.9 =  0.4635787500000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.33889125
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.811
SUFF for r=0.9 class 0 = 0.541 +- 0.211 (in-sample avg dev_std = 0.320)
SUFF for r=0.9 class 1 = 0.818 +- 0.211 (in-sample avg dev_std = 0.320)
SUFF for r=0.9 class 2 = 0.75 +- 0.211 (in-sample avg dev_std = 0.320)
SUFF for r=0.9 all KL = 0.775 +- 0.211 (in-sample avg dev_std = 0.320)
SUFF for r=0.9 all L1 = 0.703 +- 0.181 (in-sample avg dev_std = 0.320)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.57
Model XAI F1 of binarized graphs for r=0.3 =  0.48095625
Model XAI WIoU of binarized graphs for r=0.3 =  0.3720125
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.525
SUFF for r=0.3 class 0 = 0.583 +- 0.237 (in-sample avg dev_std = 0.389)
SUFF for r=0.3 class 1 = 0.642 +- 0.237 (in-sample avg dev_std = 0.389)
SUFF for r=0.3 class 2 = 0.521 +- 0.237 (in-sample avg dev_std = 0.389)
SUFF for r=0.3 all KL = 0.671 +- 0.237 (in-sample avg dev_std = 0.389)
SUFF for r=0.3 all L1 = 0.581 +- 0.161 (in-sample avg dev_std = 0.389)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.681
Model XAI F1 of binarized graphs for r=0.6 =  0.3126775
Model XAI WIoU of binarized graphs for r=0.6 =  0.21100875000000002
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.508
SUFF for r=0.6 class 0 = 0.45 +- 0.212 (in-sample avg dev_std = 0.297)
SUFF for r=0.6 class 1 = 0.698 +- 0.212 (in-sample avg dev_std = 0.297)
SUFF for r=0.6 class 2 = 0.548 +- 0.212 (in-sample avg dev_std = 0.297)
SUFF for r=0.6 all KL = 0.691 +- 0.212 (in-sample avg dev_std = 0.297)
SUFF for r=0.6 all L1 = 0.564 +- 0.164 (in-sample avg dev_std = 0.297)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.842
Model XAI F1 of binarized graphs for r=0.9 =  0.2524925
Model XAI WIoU of binarized graphs for r=0.9 =  0.1609675
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.736
SUFF for r=0.9 class 0 = 0.564 +- 0.170 (in-sample avg dev_std = 0.310)
SUFF for r=0.9 class 1 = 0.734 +- 0.170 (in-sample avg dev_std = 0.310)
SUFF for r=0.9 class 2 = 0.696 +- 0.170 (in-sample avg dev_std = 0.310)
SUFF for r=0.9 all KL = 0.781 +- 0.170 (in-sample avg dev_std = 0.310)
SUFF for r=0.9 all L1 = 0.664 +- 0.144 (in-sample avg dev_std = 0.310)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.359
Model XAI F1 of binarized graphs for r=0.3 =  0.56971625
Model XAI WIoU of binarized graphs for r=0.3 =  0.45398375
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.466
SUFF for r=0.3 class 0 = 0.589 +- 0.256 (in-sample avg dev_std = 0.378)
SUFF for r=0.3 class 1 = 0.583 +- 0.256 (in-sample avg dev_std = 0.378)
SUFF for r=0.3 class 2 = 0.527 +- 0.256 (in-sample avg dev_std = 0.378)
SUFF for r=0.3 all KL = 0.609 +- 0.256 (in-sample avg dev_std = 0.378)
SUFF for r=0.3 all L1 = 0.566 +- 0.145 (in-sample avg dev_std = 0.378)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.766
Model XAI F1 of binarized graphs for r=0.6 =  0.4948887500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.35975250000000003
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.619
SUFF for r=0.6 class 0 = 0.413 +- 0.213 (in-sample avg dev_std = 0.334)
SUFF for r=0.6 class 1 = 0.77 +- 0.213 (in-sample avg dev_std = 0.334)
SUFF for r=0.6 class 2 = 0.629 +- 0.213 (in-sample avg dev_std = 0.334)
SUFF for r=0.6 all KL = 0.671 +- 0.213 (in-sample avg dev_std = 0.334)
SUFF for r=0.6 all L1 = 0.607 +- 0.196 (in-sample avg dev_std = 0.334)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.754
Model XAI F1 of binarized graphs for r=0.9 =  0.4132875
Model XAI WIoU of binarized graphs for r=0.9 =  0.281845
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.698
SUFF for r=0.9 class 0 = 0.578 +- 0.142 (in-sample avg dev_std = 0.258)
SUFF for r=0.9 class 1 = 0.798 +- 0.142 (in-sample avg dev_std = 0.258)
SUFF for r=0.9 class 2 = 0.792 +- 0.142 (in-sample avg dev_std = 0.258)
SUFF for r=0.9 all KL = 0.834 +- 0.142 (in-sample avg dev_std = 0.258)
SUFF for r=0.9 all L1 = 0.725 +- 0.158 (in-sample avg dev_std = 0.258)


ratio=1.0



Zero intervened samples, skipping weight=1.0

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Mar 20 15:16:45 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 03/20/2024 03:16:45 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/20/2024 03:16:45 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/20/2024 03:16:45 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 03:16:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:16:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:16:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:16:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:16:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:16:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:16:45 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 133...
[0m[1;37mINFO[0m: [1mCheckpoint 133: 
-----------------------------------
Train ACCURACY: 0.9303
Train Loss: 0.3173
ID Validation ACCURACY: 0.9357
ID Validation Loss: 0.3076
ID Test ACCURACY: 0.9260
ID Test Loss: 0.3411
OOD Validation ACCURACY: 0.8477
OOD Validation Loss: 0.4798
OOD Test ACCURACY: 0.6430
OOD Test Loss: 0.9596

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 13...
[0m[1;37mINFO[0m: [1mCheckpoint 13: 
-----------------------------------
Train ACCURACY: 0.9249
Train Loss: 0.3435
ID Validation ACCURACY: 0.9297
ID Validation Loss: 0.3292
ID Test ACCURACY: 0.9200
ID Test Loss: 0.3609
OOD Validation ACCURACY: 0.9273
OOD Validation Loss: 0.3859
OOD Test ACCURACY: 0.5833
OOD Test Loss: 1.8691

[0m[1;37mINFO[0m: [1mChartInfo 0.9260 0.6430 0.9200 0.5833 0.9297 0.9273[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.733
WIoU for r=0.3 = 0.617
F1 for r=0.6 = 0.605
WIoU for r=0.6 = 0.483
F1 for r=0.9 = 0.479
WIoU for r=0.9 = 0.356
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.332
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.553
WIoU for r=0.3 = 0.427
F1 for r=0.6 = 0.362
WIoU for r=0.6 = 0.244
F1 for r=0.9 = 0.277
WIoU for r=0.9 = 0.178
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.172
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.676
WIoU for r=0.3 = 0.547
F1 for r=0.6 = 0.508
WIoU for r=0.6 = 0.374
F1 for r=0.9 = 0.413
WIoU for r=0.9 = 0.285
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.268
Size bank for r=0.3 -> 1500
Size bank for r=0.6 -> 1500
Size bank for r=0.9 -> 1371


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.494
Model XAI F1 of binarized graphs for r=0.3 =  0.7330737500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.6167475
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.31
NEC for r=0.3 class 0 = 0.645 +- 0.269 (in-sample avg dev_std = 0.409)
NEC for r=0.3 class 1 = 0.595 +- 0.269 (in-sample avg dev_std = 0.409)
NEC for r=0.3 class 2 = 0.631 +- 0.269 (in-sample avg dev_std = 0.409)
NEC for r=0.3 all KL = 0.629 +- 0.269 (in-sample avg dev_std = 0.409)
NEC for r=0.3 all L1 = 0.624 +- 0.150 (in-sample avg dev_std = 0.409)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.771
Model XAI F1 of binarized graphs for r=0.6 =  0.604735
Model XAI WIoU of binarized graphs for r=0.6 =  0.48319
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.385
NEC for r=0.6 class 0 = 0.614 +- 0.290 (in-sample avg dev_std = 0.477)
NEC for r=0.6 class 1 = 0.465 +- 0.290 (in-sample avg dev_std = 0.477)
NEC for r=0.6 class 2 = 0.653 +- 0.290 (in-sample avg dev_std = 0.477)
NEC for r=0.6 all KL = 0.611 +- 0.290 (in-sample avg dev_std = 0.477)
NEC for r=0.6 all L1 = 0.577 +- 0.193 (in-sample avg dev_std = 0.477)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.909
Model XAI F1 of binarized graphs for r=0.9 =  0.47906499999999996
Model XAI WIoU of binarized graphs for r=0.9 =  0.3562675
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.528
NEC for r=0.9 class 0 = 0.592 +- 0.242 (in-sample avg dev_std = 0.573)
NEC for r=0.9 class 1 = 0.485 +- 0.242 (in-sample avg dev_std = 0.573)
NEC for r=0.9 class 2 = 0.551 +- 0.242 (in-sample avg dev_std = 0.573)
NEC for r=0.9 all KL = 0.572 +- 0.242 (in-sample avg dev_std = 0.573)
NEC for r=0.9 all L1 = 0.542 +- 0.155 (in-sample avg dev_std = 0.573)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.942
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.3318175
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.538
NEC for r=1.0 class 0 = 0.551 +- 0.236 (in-sample avg dev_std = 0.609)
NEC for r=1.0 class 1 = 0.448 +- 0.236 (in-sample avg dev_std = 0.609)
NEC for r=1.0 class 2 = 0.555 +- 0.236 (in-sample avg dev_std = 0.609)
NEC for r=1.0 all KL = 0.553 +- 0.236 (in-sample avg dev_std = 0.609)
NEC for r=1.0 all L1 = 0.518 +- 0.164 (in-sample avg dev_std = 0.609)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.789
Model XAI F1 of binarized graphs for r=0.3 =  0.55335375
Model XAI WIoU of binarized graphs for r=0.3 =  0.4268925
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.309
NEC for r=0.3 class 0 = 0.611 +- 0.280 (in-sample avg dev_std = 0.425)
NEC for r=0.3 class 1 = 0.548 +- 0.280 (in-sample avg dev_std = 0.425)
NEC for r=0.3 class 2 = 0.728 +- 0.280 (in-sample avg dev_std = 0.425)
NEC for r=0.3 all KL = 0.64 +- 0.280 (in-sample avg dev_std = 0.425)
NEC for r=0.3 all L1 = 0.63 +- 0.143 (in-sample avg dev_std = 0.425)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.776
Model XAI F1 of binarized graphs for r=0.6 =  0.36238249999999994
Model XAI WIoU of binarized graphs for r=0.6 =  0.24410375
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.437
NEC for r=0.6 class 0 = 0.605 +- 0.236 (in-sample avg dev_std = 0.456)
NEC for r=0.6 class 1 = 0.476 +- 0.236 (in-sample avg dev_std = 0.456)
NEC for r=0.6 class 2 = 0.61 +- 0.236 (in-sample avg dev_std = 0.456)
NEC for r=0.6 all KL = 0.521 +- 0.236 (in-sample avg dev_std = 0.456)
NEC for r=0.6 all L1 = 0.565 +- 0.129 (in-sample avg dev_std = 0.456)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.754
Model XAI F1 of binarized graphs for r=0.9 =  0.2766025
Model XAI WIoU of binarized graphs for r=0.9 =  0.17758000000000002
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.496
NEC for r=0.9 class 0 = 0.546 +- 0.191 (in-sample avg dev_std = 0.474)
NEC for r=0.9 class 1 = 0.545 +- 0.191 (in-sample avg dev_std = 0.474)
NEC for r=0.9 class 2 = 0.451 +- 0.191 (in-sample avg dev_std = 0.474)
NEC for r=0.9 all KL = 0.453 +- 0.191 (in-sample avg dev_std = 0.474)
NEC for r=0.9 all L1 = 0.514 +- 0.117 (in-sample avg dev_std = 0.474)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.85
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.1719625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.567
NEC for r=1.0 class 0 = 0.504 +- 0.207 (in-sample avg dev_std = 0.532)
NEC for r=1.0 class 1 = 0.475 +- 0.207 (in-sample avg dev_std = 0.532)
NEC for r=1.0 class 2 = 0.503 +- 0.207 (in-sample avg dev_std = 0.532)
NEC for r=1.0 all KL = 0.471 +- 0.207 (in-sample avg dev_std = 0.532)
NEC for r=1.0 all L1 = 0.494 +- 0.110 (in-sample avg dev_std = 0.532)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.694
Model XAI F1 of binarized graphs for r=0.3 =  0.6756125000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.5474874999999999
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.438
NEC for r=0.3 class 0 = 0.586 +- 0.243 (in-sample avg dev_std = 0.492)
NEC for r=0.3 class 1 = 0.605 +- 0.243 (in-sample avg dev_std = 0.492)
NEC for r=0.3 class 2 = 0.637 +- 0.243 (in-sample avg dev_std = 0.492)
NEC for r=0.3 all KL = 0.663 +- 0.243 (in-sample avg dev_std = 0.492)
NEC for r=0.3 all L1 = 0.61 +- 0.135 (in-sample avg dev_std = 0.492)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.751
Model XAI F1 of binarized graphs for r=0.6 =  0.50813
Model XAI WIoU of binarized graphs for r=0.6 =  0.374095
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.44
NEC for r=0.6 class 0 = 0.609 +- 0.246 (in-sample avg dev_std = 0.578)
NEC for r=0.6 class 1 = 0.554 +- 0.246 (in-sample avg dev_std = 0.578)
NEC for r=0.6 class 2 = 0.605 +- 0.246 (in-sample avg dev_std = 0.578)
NEC for r=0.6 all KL = 0.643 +- 0.246 (in-sample avg dev_std = 0.578)
NEC for r=0.6 all L1 = 0.589 +- 0.135 (in-sample avg dev_std = 0.578)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.754
Model XAI F1 of binarized graphs for r=0.9 =  0.413335
Model XAI WIoU of binarized graphs for r=0.9 =  0.2854925
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.57
NEC for r=0.9 class 0 = 0.543 +- 0.289 (in-sample avg dev_std = 0.567)
NEC for r=0.9 class 1 = 0.439 +- 0.289 (in-sample avg dev_std = 0.567)
NEC for r=0.9 class 2 = 0.445 +- 0.289 (in-sample avg dev_std = 0.567)
NEC for r=0.9 all KL = 0.549 +- 0.289 (in-sample avg dev_std = 0.567)
NEC for r=0.9 all L1 = 0.475 +- 0.157 (in-sample avg dev_std = 0.567)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.656
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.26764499999999997
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.575
NEC for r=1.0 class 0 = 0.454 +- 0.235 (in-sample avg dev_std = 0.455)
NEC for r=1.0 class 1 = 0.407 +- 0.235 (in-sample avg dev_std = 0.455)
NEC for r=1.0 class 2 = 0.327 +- 0.235 (in-sample avg dev_std = 0.455)
NEC for r=1.0 all KL = 0.378 +- 0.235 (in-sample avg dev_std = 0.455)
NEC for r=1.0 all L1 = 0.396 +- 0.150 (in-sample avg dev_std = 0.455)


Evaluating SUFF for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.493
Model XAI F1 of binarized graphs for r=0.3 =  0.7330737500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.6167475
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.489
SUFF for r=0.3 class 0 = 0.463 +- 0.293 (in-sample avg dev_std = 0.462)
SUFF for r=0.3 class 1 = 0.496 +- 0.293 (in-sample avg dev_std = 0.462)
SUFF for r=0.3 class 2 = 0.524 +- 0.293 (in-sample avg dev_std = 0.462)
SUFF for r=0.3 all KL = 0.509 +- 0.293 (in-sample avg dev_std = 0.462)
SUFF for r=0.3 all L1 = 0.494 +- 0.167 (in-sample avg dev_std = 0.462)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.771
Model XAI F1 of binarized graphs for r=0.6 =  0.604735
Model XAI WIoU of binarized graphs for r=0.6 =  0.48319
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.678
SUFF for r=0.6 class 0 = 0.423 +- 0.258 (in-sample avg dev_std = 0.411)
SUFF for r=0.6 class 1 = 0.67 +- 0.258 (in-sample avg dev_std = 0.411)
SUFF for r=0.6 class 2 = 0.609 +- 0.258 (in-sample avg dev_std = 0.411)
SUFF for r=0.6 all KL = 0.566 +- 0.258 (in-sample avg dev_std = 0.411)
SUFF for r=0.6 all L1 = 0.568 +- 0.187 (in-sample avg dev_std = 0.411)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.906
Model XAI F1 of binarized graphs for r=0.9 =  0.47906499999999996
Model XAI WIoU of binarized graphs for r=0.9 =  0.3562675
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.86
SUFF for r=0.9 class 0 = 0.654 +- 0.197 (in-sample avg dev_std = 0.282)
SUFF for r=0.9 class 1 = 0.784 +- 0.197 (in-sample avg dev_std = 0.282)
SUFF for r=0.9 class 2 = 0.814 +- 0.197 (in-sample avg dev_std = 0.282)
SUFF for r=0.9 all KL = 0.82 +- 0.197 (in-sample avg dev_std = 0.282)
SUFF for r=0.9 all L1 = 0.751 +- 0.175 (in-sample avg dev_std = 0.282)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.785
Model XAI F1 of binarized graphs for r=0.3 =  0.55335375
Model XAI WIoU of binarized graphs for r=0.3 =  0.4268925
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.582
SUFF for r=0.3 class 0 = 0.43 +- 0.281 (in-sample avg dev_std = 0.479)
SUFF for r=0.3 class 1 = 0.616 +- 0.281 (in-sample avg dev_std = 0.479)
SUFF for r=0.3 class 2 = 0.604 +- 0.281 (in-sample avg dev_std = 0.479)
SUFF for r=0.3 all KL = 0.549 +- 0.281 (in-sample avg dev_std = 0.479)
SUFF for r=0.3 all L1 = 0.549 +- 0.183 (in-sample avg dev_std = 0.479)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.775
Model XAI F1 of binarized graphs for r=0.6 =  0.36238249999999994
Model XAI WIoU of binarized graphs for r=0.6 =  0.24410375
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.643
SUFF for r=0.6 class 0 = 0.441 +- 0.227 (in-sample avg dev_std = 0.330)
SUFF for r=0.6 class 1 = 0.657 +- 0.227 (in-sample avg dev_std = 0.330)
SUFF for r=0.6 class 2 = 0.575 +- 0.227 (in-sample avg dev_std = 0.330)
SUFF for r=0.6 all KL = 0.645 +- 0.227 (in-sample avg dev_std = 0.330)
SUFF for r=0.6 all L1 = 0.557 +- 0.160 (in-sample avg dev_std = 0.330)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.752
Model XAI F1 of binarized graphs for r=0.9 =  0.2766025
Model XAI WIoU of binarized graphs for r=0.9 =  0.17758000000000002
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.739
SUFF for r=0.9 class 0 = 0.552 +- 0.174 (in-sample avg dev_std = 0.296)
SUFF for r=0.9 class 1 = 0.65 +- 0.174 (in-sample avg dev_std = 0.296)
SUFF for r=0.9 class 2 = 0.725 +- 0.174 (in-sample avg dev_std = 0.296)
SUFF for r=0.9 all KL = 0.764 +- 0.174 (in-sample avg dev_std = 0.296)
SUFF for r=0.9 all L1 = 0.643 +- 0.145 (in-sample avg dev_std = 0.296)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.694
Model XAI F1 of binarized graphs for r=0.3 =  0.6756125000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.5474874999999999
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.502
SUFF for r=0.3 class 0 = 0.454 +- 0.298 (in-sample avg dev_std = 0.462)
SUFF for r=0.3 class 1 = 0.579 +- 0.298 (in-sample avg dev_std = 0.462)
SUFF for r=0.3 class 2 = 0.454 +- 0.298 (in-sample avg dev_std = 0.462)
SUFF for r=0.3 all KL = 0.493 +- 0.298 (in-sample avg dev_std = 0.462)
SUFF for r=0.3 all L1 = 0.497 +- 0.176 (in-sample avg dev_std = 0.462)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.75
Model XAI F1 of binarized graphs for r=0.6 =  0.50813
Model XAI WIoU of binarized graphs for r=0.6 =  0.374095
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.659
SUFF for r=0.6 class 0 = 0.397 +- 0.247 (in-sample avg dev_std = 0.385)
SUFF for r=0.6 class 1 = 0.679 +- 0.247 (in-sample avg dev_std = 0.385)
SUFF for r=0.6 class 2 = 0.664 +- 0.247 (in-sample avg dev_std = 0.385)
SUFF for r=0.6 all KL = 0.598 +- 0.247 (in-sample avg dev_std = 0.385)
SUFF for r=0.6 all L1 = 0.583 +- 0.185 (in-sample avg dev_std = 0.385)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.755
Model XAI F1 of binarized graphs for r=0.9 =  0.413335
Model XAI WIoU of binarized graphs for r=0.9 =  0.2854925
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.668
SUFF for r=0.9 class 0 = 0.627 +- 0.149 (in-sample avg dev_std = 0.266)
SUFF for r=0.9 class 1 = 0.705 +- 0.149 (in-sample avg dev_std = 0.266)
SUFF for r=0.9 class 2 = 0.895 +- 0.149 (in-sample avg dev_std = 0.266)
SUFF for r=0.9 all KL = 0.813 +- 0.149 (in-sample avg dev_std = 0.266)
SUFF for r=0.9 all L1 = 0.743 +- 0.177 (in-sample avg dev_std = 0.266)


ratio=1.0



Zero intervened samples, skipping weight=1.0

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Mar 20 15:22:00 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 03/20/2024 03:22:00 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/20/2024 03:22:00 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/20/2024 03:22:00 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 03:22:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:22:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:22:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:22:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:22:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:22:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:22:00 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 110...
[0m[1;37mINFO[0m: [1mCheckpoint 110: 
-----------------------------------
Train ACCURACY: 0.9289
Train Loss: 0.3303
ID Validation ACCURACY: 0.9350
ID Validation Loss: 0.3133
ID Test ACCURACY: 0.9257
ID Test Loss: 0.3501
OOD Validation ACCURACY: 0.8013
OOD Validation Loss: 0.5544
OOD Test ACCURACY: 0.7917
OOD Test Loss: 0.8351

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 33...
[0m[1;37mINFO[0m: [1mCheckpoint 33: 
-----------------------------------
Train ACCURACY: 0.9260
Train Loss: 0.3556
ID Validation ACCURACY: 0.9317
ID Validation Loss: 0.3333
ID Test ACCURACY: 0.9233
ID Test Loss: 0.3700
OOD Validation ACCURACY: 0.9260
OOD Validation Loss: 0.4586
OOD Test ACCURACY: 0.6470
OOD Test Loss: 1.3751

[0m[1;37mINFO[0m: [1mChartInfo 0.9257 0.7917 0.9233 0.6470 0.9317 0.9260[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.674
WIoU for r=0.3 = 0.553
F1 for r=0.6 = 0.558
WIoU for r=0.6 = 0.434
F1 for r=0.9 = 0.469
WIoU for r=0.9 = 0.342
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.325
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.426
WIoU for r=0.3 = 0.329
F1 for r=0.6 = 0.284
WIoU for r=0.6 = 0.187
F1 for r=0.9 = 0.247
WIoU for r=0.9 = 0.151
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.163
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.636
WIoU for r=0.3 = 0.515
F1 for r=0.6 = 0.490
WIoU for r=0.6 = 0.355
F1 for r=0.9 = 0.411
WIoU for r=0.9 = 0.279
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.263
Size bank for r=0.3 -> 1500
Size bank for r=0.6 -> 1500
Size bank for r=0.9 -> 1427


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.464
Model XAI F1 of binarized graphs for r=0.3 =  0.6743412499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.55327125
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.315
NEC for r=0.3 class 0 = 0.628 +- 0.244 (in-sample avg dev_std = 0.452)
NEC for r=0.3 class 1 = 0.549 +- 0.244 (in-sample avg dev_std = 0.452)
NEC for r=0.3 class 2 = 0.677 +- 0.244 (in-sample avg dev_std = 0.452)
NEC for r=0.3 all KL = 0.639 +- 0.244 (in-sample avg dev_std = 0.452)
NEC for r=0.3 all L1 = 0.618 +- 0.151 (in-sample avg dev_std = 0.452)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.663
Model XAI F1 of binarized graphs for r=0.6 =  0.5575725
Model XAI WIoU of binarized graphs for r=0.6 =  0.4339775
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.393
NEC for r=0.6 class 0 = 0.59 +- 0.273 (in-sample avg dev_std = 0.470)
NEC for r=0.6 class 1 = 0.461 +- 0.273 (in-sample avg dev_std = 0.470)
NEC for r=0.6 class 2 = 0.65 +- 0.273 (in-sample avg dev_std = 0.470)
NEC for r=0.6 all KL = 0.606 +- 0.273 (in-sample avg dev_std = 0.470)
NEC for r=0.6 all L1 = 0.566 +- 0.182 (in-sample avg dev_std = 0.470)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.91
Model XAI F1 of binarized graphs for r=0.9 =  0.4692375
Model XAI WIoU of binarized graphs for r=0.9 =  0.34176125
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.509
NEC for r=0.9 class 0 = 0.628 +- 0.218 (in-sample avg dev_std = 0.592)
NEC for r=0.9 class 1 = 0.463 +- 0.218 (in-sample avg dev_std = 0.592)
NEC for r=0.9 class 2 = 0.577 +- 0.218 (in-sample avg dev_std = 0.592)
NEC for r=0.9 all KL = 0.621 +- 0.218 (in-sample avg dev_std = 0.592)
NEC for r=0.9 all L1 = 0.556 +- 0.155 (in-sample avg dev_std = 0.592)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.942
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.32542875000000004
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.563
NEC for r=1.0 class 0 = 0.576 +- 0.240 (in-sample avg dev_std = 0.617)
NEC for r=1.0 class 1 = 0.399 +- 0.240 (in-sample avg dev_std = 0.617)
NEC for r=1.0 class 2 = 0.568 +- 0.240 (in-sample avg dev_std = 0.617)
NEC for r=1.0 all KL = 0.572 +- 0.240 (in-sample avg dev_std = 0.617)
NEC for r=1.0 all L1 = 0.514 +- 0.176 (in-sample avg dev_std = 0.617)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.683
Model XAI F1 of binarized graphs for r=0.3 =  0.42621375
Model XAI WIoU of binarized graphs for r=0.3 =  0.3291075
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.34
NEC for r=0.3 class 0 = 0.561 +- 0.261 (in-sample avg dev_std = 0.405)
NEC for r=0.3 class 1 = 0.51 +- 0.261 (in-sample avg dev_std = 0.405)
NEC for r=0.3 class 2 = 0.664 +- 0.261 (in-sample avg dev_std = 0.405)
NEC for r=0.3 all KL = 0.57 +- 0.261 (in-sample avg dev_std = 0.405)
NEC for r=0.3 all L1 = 0.579 +- 0.143 (in-sample avg dev_std = 0.405)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.714
Model XAI F1 of binarized graphs for r=0.6 =  0.28413124999999995
Model XAI WIoU of binarized graphs for r=0.6 =  0.1874425
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.418
NEC for r=0.6 class 0 = 0.622 +- 0.225 (in-sample avg dev_std = 0.411)
NEC for r=0.6 class 1 = 0.455 +- 0.225 (in-sample avg dev_std = 0.411)
NEC for r=0.6 class 2 = 0.585 +- 0.225 (in-sample avg dev_std = 0.411)
NEC for r=0.6 all KL = 0.495 +- 0.225 (in-sample avg dev_std = 0.411)
NEC for r=0.6 all L1 = 0.555 +- 0.139 (in-sample avg dev_std = 0.411)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.641
Model XAI F1 of binarized graphs for r=0.9 =  0.24661249999999998
Model XAI WIoU of binarized graphs for r=0.9 =  0.15134125
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.53
NEC for r=0.9 class 0 = 0.595 +- 0.184 (in-sample avg dev_std = 0.478)
NEC for r=0.9 class 1 = 0.489 +- 0.184 (in-sample avg dev_std = 0.478)
NEC for r=0.9 class 2 = 0.483 +- 0.184 (in-sample avg dev_std = 0.478)
NEC for r=0.9 all KL = 0.468 +- 0.184 (in-sample avg dev_std = 0.478)
NEC for r=0.9 all L1 = 0.523 +- 0.119 (in-sample avg dev_std = 0.478)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.809
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.16315125000000003
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.598
NEC for r=1.0 class 0 = 0.555 +- 0.203 (in-sample avg dev_std = 0.507)
NEC for r=1.0 class 1 = 0.457 +- 0.203 (in-sample avg dev_std = 0.507)
NEC for r=1.0 class 2 = 0.524 +- 0.203 (in-sample avg dev_std = 0.507)
NEC for r=1.0 all KL = 0.47 +- 0.203 (in-sample avg dev_std = 0.507)
NEC for r=1.0 all L1 = 0.512 +- 0.115 (in-sample avg dev_std = 0.507)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.688
Model XAI F1 of binarized graphs for r=0.3 =  0.63566625
Model XAI WIoU of binarized graphs for r=0.3 =  0.515265
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.365
NEC for r=0.3 class 0 = 0.653 +- 0.241 (in-sample avg dev_std = 0.467)
NEC for r=0.3 class 1 = 0.515 +- 0.241 (in-sample avg dev_std = 0.467)
NEC for r=0.3 class 2 = 0.657 +- 0.241 (in-sample avg dev_std = 0.467)
NEC for r=0.3 all KL = 0.637 +- 0.241 (in-sample avg dev_std = 0.467)
NEC for r=0.3 all L1 = 0.607 +- 0.138 (in-sample avg dev_std = 0.467)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.681
Model XAI F1 of binarized graphs for r=0.6 =  0.48989374999999996
Model XAI WIoU of binarized graphs for r=0.6 =  0.35478499999999996
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.463
NEC for r=0.6 class 0 = 0.571 +- 0.225 (in-sample avg dev_std = 0.457)
NEC for r=0.6 class 1 = 0.422 +- 0.225 (in-sample avg dev_std = 0.457)
NEC for r=0.6 class 2 = 0.564 +- 0.225 (in-sample avg dev_std = 0.457)
NEC for r=0.6 all KL = 0.48 +- 0.225 (in-sample avg dev_std = 0.457)
NEC for r=0.6 all L1 = 0.517 +- 0.160 (in-sample avg dev_std = 0.457)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.736
Model XAI F1 of binarized graphs for r=0.9 =  0.41095375000000006
Model XAI WIoU of binarized graphs for r=0.9 =  0.2793825
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.58
NEC for r=0.9 class 0 = 0.608 +- 0.294 (in-sample avg dev_std = 0.534)
NEC for r=0.9 class 1 = 0.385 +- 0.294 (in-sample avg dev_std = 0.534)
NEC for r=0.9 class 2 = 0.46 +- 0.294 (in-sample avg dev_std = 0.534)
NEC for r=0.9 all KL = 0.509 +- 0.294 (in-sample avg dev_std = 0.534)
NEC for r=0.9 all L1 = 0.482 +- 0.174 (in-sample avg dev_std = 0.534)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.806
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.26323375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.613
NEC for r=1.0 class 0 = 0.502 +- 0.262 (in-sample avg dev_std = 0.548)
NEC for r=1.0 class 1 = 0.369 +- 0.262 (in-sample avg dev_std = 0.548)
NEC for r=1.0 class 2 = 0.394 +- 0.262 (in-sample avg dev_std = 0.548)
NEC for r=1.0 all KL = 0.438 +- 0.262 (in-sample avg dev_std = 0.548)
NEC for r=1.0 all L1 = 0.42 +- 0.171 (in-sample avg dev_std = 0.548)


Evaluating SUFF for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.464
Model XAI F1 of binarized graphs for r=0.3 =  0.6743412499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.55327125
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.48
SUFF for r=0.3 class 0 = 0.453 +- 0.248 (in-sample avg dev_std = 0.478)
SUFF for r=0.3 class 1 = 0.493 +- 0.248 (in-sample avg dev_std = 0.478)
SUFF for r=0.3 class 2 = 0.497 +- 0.248 (in-sample avg dev_std = 0.478)
SUFF for r=0.3 all KL = 0.471 +- 0.248 (in-sample avg dev_std = 0.478)
SUFF for r=0.3 all L1 = 0.481 +- 0.157 (in-sample avg dev_std = 0.478)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.664
Model XAI F1 of binarized graphs for r=0.6 =  0.5575725
Model XAI WIoU of binarized graphs for r=0.6 =  0.4339775
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.645
SUFF for r=0.6 class 0 = 0.42 +- 0.251 (in-sample avg dev_std = 0.386)
SUFF for r=0.6 class 1 = 0.675 +- 0.251 (in-sample avg dev_std = 0.386)
SUFF for r=0.6 class 2 = 0.615 +- 0.251 (in-sample avg dev_std = 0.386)
SUFF for r=0.6 all KL = 0.577 +- 0.251 (in-sample avg dev_std = 0.386)
SUFF for r=0.6 all L1 = 0.57 +- 0.192 (in-sample avg dev_std = 0.386)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.911
Model XAI F1 of binarized graphs for r=0.9 =  0.4692375
Model XAI WIoU of binarized graphs for r=0.9 =  0.34176125
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.823
SUFF for r=0.9 class 0 = 0.567 +- 0.214 (in-sample avg dev_std = 0.307)
SUFF for r=0.9 class 1 = 0.826 +- 0.214 (in-sample avg dev_std = 0.307)
SUFF for r=0.9 class 2 = 0.793 +- 0.214 (in-sample avg dev_std = 0.307)
SUFF for r=0.9 all KL = 0.786 +- 0.214 (in-sample avg dev_std = 0.307)
SUFF for r=0.9 all L1 = 0.729 +- 0.184 (in-sample avg dev_std = 0.307)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.681
Model XAI F1 of binarized graphs for r=0.3 =  0.42621375
Model XAI WIoU of binarized graphs for r=0.3 =  0.3291075
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.554
SUFF for r=0.3 class 0 = 0.444 +- 0.251 (in-sample avg dev_std = 0.421)
SUFF for r=0.3 class 1 = 0.629 +- 0.251 (in-sample avg dev_std = 0.421)
SUFF for r=0.3 class 2 = 0.558 +- 0.251 (in-sample avg dev_std = 0.421)
SUFF for r=0.3 all KL = 0.583 +- 0.251 (in-sample avg dev_std = 0.421)
SUFF for r=0.3 all L1 = 0.543 +- 0.174 (in-sample avg dev_std = 0.421)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.719
Model XAI F1 of binarized graphs for r=0.6 =  0.28413124999999995
Model XAI WIoU of binarized graphs for r=0.6 =  0.1874425
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.6
SUFF for r=0.6 class 0 = 0.404 +- 0.244 (in-sample avg dev_std = 0.328)
SUFF for r=0.6 class 1 = 0.638 +- 0.244 (in-sample avg dev_std = 0.328)
SUFF for r=0.6 class 2 = 0.566 +- 0.244 (in-sample avg dev_std = 0.328)
SUFF for r=0.6 all KL = 0.627 +- 0.244 (in-sample avg dev_std = 0.328)
SUFF for r=0.6 all L1 = 0.535 +- 0.176 (in-sample avg dev_std = 0.328)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.634
Model XAI F1 of binarized graphs for r=0.9 =  0.24661249999999998
Model XAI WIoU of binarized graphs for r=0.9 =  0.15134125
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.647
SUFF for r=0.9 class 0 = 0.589 +- 0.170 (in-sample avg dev_std = 0.314)
SUFF for r=0.9 class 1 = 0.693 +- 0.170 (in-sample avg dev_std = 0.314)
SUFF for r=0.9 class 2 = 0.666 +- 0.170 (in-sample avg dev_std = 0.314)
SUFF for r=0.9 all KL = 0.771 +- 0.170 (in-sample avg dev_std = 0.314)
SUFF for r=0.9 all L1 = 0.649 +- 0.137 (in-sample avg dev_std = 0.314)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.688
Model XAI F1 of binarized graphs for r=0.3 =  0.63566625
Model XAI WIoU of binarized graphs for r=0.3 =  0.515265
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.507
SUFF for r=0.3 class 0 = 0.505 +- 0.263 (in-sample avg dev_std = 0.455)
SUFF for r=0.3 class 1 = 0.592 +- 0.263 (in-sample avg dev_std = 0.455)
SUFF for r=0.3 class 2 = 0.464 +- 0.263 (in-sample avg dev_std = 0.455)
SUFF for r=0.3 all KL = 0.536 +- 0.263 (in-sample avg dev_std = 0.455)
SUFF for r=0.3 all L1 = 0.521 +- 0.162 (in-sample avg dev_std = 0.455)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.681
Model XAI F1 of binarized graphs for r=0.6 =  0.48989374999999996
Model XAI WIoU of binarized graphs for r=0.6 =  0.35478499999999996
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.602
SUFF for r=0.6 class 0 = 0.449 +- 0.199 (in-sample avg dev_std = 0.313)
SUFF for r=0.6 class 1 = 0.714 +- 0.199 (in-sample avg dev_std = 0.313)
SUFF for r=0.6 class 2 = 0.657 +- 0.199 (in-sample avg dev_std = 0.313)
SUFF for r=0.6 all KL = 0.712 +- 0.199 (in-sample avg dev_std = 0.313)
SUFF for r=0.6 all L1 = 0.609 +- 0.180 (in-sample avg dev_std = 0.313)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.738
Model XAI F1 of binarized graphs for r=0.9 =  0.41095375000000006
Model XAI WIoU of binarized graphs for r=0.9 =  0.2793825
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.655
SUFF for r=0.9 class 0 = 0.601 +- 0.198 (in-sample avg dev_std = 0.285)
SUFF for r=0.9 class 1 = 0.712 +- 0.198 (in-sample avg dev_std = 0.285)
SUFF for r=0.9 class 2 = 0.799 +- 0.198 (in-sample avg dev_std = 0.285)
SUFF for r=0.9 all KL = 0.774 +- 0.198 (in-sample avg dev_std = 0.285)
SUFF for r=0.9 all L1 = 0.705 +- 0.190 (in-sample avg dev_std = 0.285)


ratio=1.0



Zero intervened samples, skipping weight=1.0

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Mar 20 15:26:27 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 03/20/2024 03:26:27 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/20/2024 03:26:27 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/20/2024 03:26:27 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/20/2024 03:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/20/2024 03:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/20/2024 03:26:28 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 111...
[0m[1;37mINFO[0m: [1mCheckpoint 111: 
-----------------------------------
Train ACCURACY: 0.9303
Train Loss: 0.3118
ID Validation ACCURACY: 0.9357
ID Validation Loss: 0.3016
ID Test ACCURACY: 0.9260
ID Test Loss: 0.3358
OOD Validation ACCURACY: 0.8073
OOD Validation Loss: 0.5158
OOD Test ACCURACY: 0.7527
OOD Test Loss: 1.0888

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 138...
[0m[1;37mINFO[0m: [1mCheckpoint 138: 
-----------------------------------
Train ACCURACY: 0.9293
Train Loss: 0.3258
ID Validation ACCURACY: 0.9347
ID Validation Loss: 0.3155
ID Test ACCURACY: 0.9257
ID Test Loss: 0.3465
OOD Validation ACCURACY: 0.9260
OOD Validation Loss: 0.4445
OOD Test ACCURACY: 0.5280
OOD Test Loss: 1.3857

[0m[1;37mINFO[0m: [1mChartInfo 0.9260 0.7527 0.9257 0.5280 0.9347 0.9260[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.729
WIoU for r=0.3 = 0.612
F1 for r=0.6 = 0.603
WIoU for r=0.6 = 0.479
F1 for r=0.9 = 0.477
WIoU for r=0.9 = 0.353
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.331
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.536
WIoU for r=0.3 = 0.413
F1 for r=0.6 = 0.342
WIoU for r=0.6 = 0.228
F1 for r=0.9 = 0.265
WIoU for r=0.9 = 0.168
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.169
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.654
WIoU for r=0.3 = 0.519
F1 for r=0.6 = 0.483
WIoU for r=0.6 = 0.348
F1 for r=0.9 = 0.390
WIoU for r=0.9 = 0.262
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.263
Size bank for r=0.3 -> 1500
Size bank for r=0.6 -> 1500
Size bank for r=0.9 -> 1398


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.485
Model XAI F1 of binarized graphs for r=0.3 =  0.72892875
Model XAI WIoU of binarized graphs for r=0.3 =  0.6118412500000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.314
NEC for r=0.3 class 0 = 0.626 +- 0.267 (in-sample avg dev_std = 0.388)
NEC for r=0.3 class 1 = 0.47 +- 0.267 (in-sample avg dev_std = 0.388)
NEC for r=0.3 class 2 = 0.603 +- 0.267 (in-sample avg dev_std = 0.388)
NEC for r=0.3 all KL = 0.559 +- 0.267 (in-sample avg dev_std = 0.388)
NEC for r=0.3 all L1 = 0.566 +- 0.172 (in-sample avg dev_std = 0.388)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.798
Model XAI F1 of binarized graphs for r=0.6 =  0.602595
Model XAI WIoU of binarized graphs for r=0.6 =  0.47919875000000006
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.438
NEC for r=0.6 class 0 = 0.652 +- 0.252 (in-sample avg dev_std = 0.465)
NEC for r=0.6 class 1 = 0.466 +- 0.252 (in-sample avg dev_std = 0.465)
NEC for r=0.6 class 2 = 0.629 +- 0.252 (in-sample avg dev_std = 0.465)
NEC for r=0.6 all KL = 0.58 +- 0.252 (in-sample avg dev_std = 0.465)
NEC for r=0.6 all L1 = 0.582 +- 0.162 (in-sample avg dev_std = 0.465)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.925
Model XAI F1 of binarized graphs for r=0.9 =  0.47736125
Model XAI WIoU of binarized graphs for r=0.9 =  0.35338875000000003
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.511
NEC for r=0.9 class 0 = 0.616 +- 0.216 (in-sample avg dev_std = 0.558)
NEC for r=0.9 class 1 = 0.447 +- 0.216 (in-sample avg dev_std = 0.558)
NEC for r=0.9 class 2 = 0.577 +- 0.216 (in-sample avg dev_std = 0.558)
NEC for r=0.9 all KL = 0.564 +- 0.216 (in-sample avg dev_std = 0.558)
NEC for r=0.9 all L1 = 0.546 +- 0.159 (in-sample avg dev_std = 0.558)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.944
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.3305025
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.55
NEC for r=1.0 class 0 = 0.579 +- 0.246 (in-sample avg dev_std = 0.617)
NEC for r=1.0 class 1 = 0.389 +- 0.246 (in-sample avg dev_std = 0.617)
NEC for r=1.0 class 2 = 0.576 +- 0.246 (in-sample avg dev_std = 0.617)
NEC for r=1.0 all KL = 0.555 +- 0.246 (in-sample avg dev_std = 0.617)
NEC for r=1.0 all L1 = 0.514 +- 0.180 (in-sample avg dev_std = 0.617)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.629
Model XAI F1 of binarized graphs for r=0.3 =  0.5358762499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.41256875
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.322
NEC for r=0.3 class 0 = 0.504 +- 0.262 (in-sample avg dev_std = 0.372)
NEC for r=0.3 class 1 = 0.49 +- 0.262 (in-sample avg dev_std = 0.372)
NEC for r=0.3 class 2 = 0.67 +- 0.262 (in-sample avg dev_std = 0.372)
NEC for r=0.3 all KL = 0.492 +- 0.262 (in-sample avg dev_std = 0.372)
NEC for r=0.3 all L1 = 0.555 +- 0.158 (in-sample avg dev_std = 0.372)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.661
Model XAI F1 of binarized graphs for r=0.6 =  0.3415975
Model XAI WIoU of binarized graphs for r=0.6 =  0.22754249999999998
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.412
NEC for r=0.6 class 0 = 0.57 +- 0.200 (in-sample avg dev_std = 0.459)
NEC for r=0.6 class 1 = 0.506 +- 0.200 (in-sample avg dev_std = 0.459)
NEC for r=0.6 class 2 = 0.587 +- 0.200 (in-sample avg dev_std = 0.459)
NEC for r=0.6 all KL = 0.482 +- 0.200 (in-sample avg dev_std = 0.459)
NEC for r=0.6 all L1 = 0.555 +- 0.112 (in-sample avg dev_std = 0.459)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.766
Model XAI F1 of binarized graphs for r=0.9 =  0.265325
Model XAI WIoU of binarized graphs for r=0.9 =  0.16789
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.54
NEC for r=0.9 class 0 = 0.597 +- 0.186 (in-sample avg dev_std = 0.533)
NEC for r=0.9 class 1 = 0.536 +- 0.186 (in-sample avg dev_std = 0.533)
NEC for r=0.9 class 2 = 0.487 +- 0.186 (in-sample avg dev_std = 0.533)
NEC for r=0.9 all KL = 0.521 +- 0.186 (in-sample avg dev_std = 0.533)
NEC for r=0.9 all L1 = 0.54 +- 0.118 (in-sample avg dev_std = 0.533)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.804
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.16923624999999998
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.577
NEC for r=1.0 class 0 = 0.581 +- 0.207 (in-sample avg dev_std = 0.565)
NEC for r=1.0 class 1 = 0.465 +- 0.207 (in-sample avg dev_std = 0.565)
NEC for r=1.0 class 2 = 0.551 +- 0.207 (in-sample avg dev_std = 0.565)
NEC for r=1.0 all KL = 0.54 +- 0.207 (in-sample avg dev_std = 0.565)
NEC for r=1.0 all L1 = 0.533 +- 0.123 (in-sample avg dev_std = 0.565)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.455
Model XAI F1 of binarized graphs for r=0.3 =  0.6542587499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.51921125
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.41
NEC for r=0.3 class 0 = 0.514 +- 0.229 (in-sample avg dev_std = 0.483)
NEC for r=0.3 class 1 = 0.572 +- 0.229 (in-sample avg dev_std = 0.483)
NEC for r=0.3 class 2 = 0.582 +- 0.229 (in-sample avg dev_std = 0.483)
NEC for r=0.3 all KL = 0.603 +- 0.229 (in-sample avg dev_std = 0.483)
NEC for r=0.3 all L1 = 0.557 +- 0.171 (in-sample avg dev_std = 0.483)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.59
Model XAI F1 of binarized graphs for r=0.6 =  0.48279250000000007
Model XAI WIoU of binarized graphs for r=0.6 =  0.3483737499999999
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.454
NEC for r=0.6 class 0 = 0.586 +- 0.235 (in-sample avg dev_std = 0.435)
NEC for r=0.6 class 1 = 0.487 +- 0.235 (in-sample avg dev_std = 0.435)
NEC for r=0.6 class 2 = 0.532 +- 0.235 (in-sample avg dev_std = 0.435)
NEC for r=0.6 all KL = 0.486 +- 0.235 (in-sample avg dev_std = 0.435)
NEC for r=0.6 all L1 = 0.534 +- 0.147 (in-sample avg dev_std = 0.435)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.76
Model XAI F1 of binarized graphs for r=0.9 =  0.38961875
Model XAI WIoU of binarized graphs for r=0.9 =  0.26186
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.6
NEC for r=0.9 class 0 = 0.528 +- 0.297 (in-sample avg dev_std = 0.531)
NEC for r=0.9 class 1 = 0.387 +- 0.297 (in-sample avg dev_std = 0.531)
NEC for r=0.9 class 2 = 0.409 +- 0.297 (in-sample avg dev_std = 0.531)
NEC for r=0.9 all KL = 0.44 +- 0.297 (in-sample avg dev_std = 0.531)
NEC for r=0.9 all L1 = 0.44 +- 0.183 (in-sample avg dev_std = 0.531)


ratio=1.0


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=1.0 =  0.772
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.26257375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.609
NEC for r=1.0 class 0 = 0.472 +- 0.289 (in-sample avg dev_std = 0.507)
NEC for r=1.0 class 1 = 0.362 +- 0.289 (in-sample avg dev_std = 0.507)
NEC for r=1.0 class 2 = 0.357 +- 0.289 (in-sample avg dev_std = 0.507)
NEC for r=1.0 all KL = 0.413 +- 0.289 (in-sample avg dev_std = 0.507)
NEC for r=1.0 all L1 = 0.396 +- 0.176 (in-sample avg dev_std = 0.507)


Evaluating SUFF for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.484
Model XAI F1 of binarized graphs for r=0.3 =  0.72892875
Model XAI WIoU of binarized graphs for r=0.3 =  0.6118412500000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.502
SUFF for r=0.3 class 0 = 0.444 +- 0.256 (in-sample avg dev_std = 0.437)
SUFF for r=0.3 class 1 = 0.598 +- 0.256 (in-sample avg dev_std = 0.437)
SUFF for r=0.3 class 2 = 0.539 +- 0.256 (in-sample avg dev_std = 0.437)
SUFF for r=0.3 all KL = 0.563 +- 0.256 (in-sample avg dev_std = 0.437)
SUFF for r=0.3 all L1 = 0.527 +- 0.166 (in-sample avg dev_std = 0.437)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.796
Model XAI F1 of binarized graphs for r=0.6 =  0.602595
Model XAI WIoU of binarized graphs for r=0.6 =  0.47919875000000006
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.656
SUFF for r=0.6 class 0 = 0.401 +- 0.265 (in-sample avg dev_std = 0.375)
SUFF for r=0.6 class 1 = 0.742 +- 0.265 (in-sample avg dev_std = 0.375)
SUFF for r=0.6 class 2 = 0.632 +- 0.265 (in-sample avg dev_std = 0.375)
SUFF for r=0.6 all KL = 0.651 +- 0.265 (in-sample avg dev_std = 0.375)
SUFF for r=0.6 all L1 = 0.592 +- 0.204 (in-sample avg dev_std = 0.375)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.925
Model XAI F1 of binarized graphs for r=0.9 =  0.47736125
Model XAI WIoU of binarized graphs for r=0.9 =  0.35338875000000003
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.869
SUFF for r=0.9 class 0 = 0.666 +- 0.186 (in-sample avg dev_std = 0.276)
SUFF for r=0.9 class 1 = 0.822 +- 0.186 (in-sample avg dev_std = 0.276)
SUFF for r=0.9 class 2 = 0.801 +- 0.186 (in-sample avg dev_std = 0.276)
SUFF for r=0.9 all KL = 0.839 +- 0.186 (in-sample avg dev_std = 0.276)
SUFF for r=0.9 all L1 = 0.763 +- 0.164 (in-sample avg dev_std = 0.276)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over val across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.632
Model XAI F1 of binarized graphs for r=0.3 =  0.5358762499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.41256875
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.558
SUFF for r=0.3 class 0 = 0.515 +- 0.255 (in-sample avg dev_std = 0.360)
SUFF for r=0.3 class 1 = 0.699 +- 0.255 (in-sample avg dev_std = 0.360)
SUFF for r=0.3 class 2 = 0.561 +- 0.255 (in-sample avg dev_std = 0.360)
SUFF for r=0.3 all KL = 0.682 +- 0.255 (in-sample avg dev_std = 0.360)
SUFF for r=0.3 all L1 = 0.591 +- 0.188 (in-sample avg dev_std = 0.360)


ratio=0.6


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.6 =  0.661
Model XAI F1 of binarized graphs for r=0.6 =  0.3415975
Model XAI WIoU of binarized graphs for r=0.6 =  0.22754249999999998
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.573
SUFF for r=0.6 class 0 = 0.467 +- 0.208 (in-sample avg dev_std = 0.308)
SUFF for r=0.6 class 1 = 0.691 +- 0.208 (in-sample avg dev_std = 0.308)
SUFF for r=0.6 class 2 = 0.556 +- 0.208 (in-sample avg dev_std = 0.308)
SUFF for r=0.6 all KL = 0.687 +- 0.208 (in-sample avg dev_std = 0.308)
SUFF for r=0.6 all L1 = 0.57 +- 0.160 (in-sample avg dev_std = 0.308)


ratio=0.9


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.9 =  0.772
Model XAI F1 of binarized graphs for r=0.9 =  0.265325
Model XAI WIoU of binarized graphs for r=0.9 =  0.16789
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.738
SUFF for r=0.9 class 0 = 0.566 +- 0.178 (in-sample avg dev_std = 0.314)
SUFF for r=0.9 class 1 = 0.739 +- 0.178 (in-sample avg dev_std = 0.314)
SUFF for r=0.9 class 2 = 0.707 +- 0.178 (in-sample avg dev_std = 0.314)
SUFF for r=0.9 all KL = 0.775 +- 0.178 (in-sample avg dev_std = 0.314)
SUFF for r=0.9 all L1 = 0.67 +- 0.153 (in-sample avg dev_std = 0.314)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF over test across ratios (random_expl=False)


ratio=0.3


Computing with masking
7200
torch.Size([7200, 3])
7200

Model Accuracy of binarized graphs for r=0.3 =  0.456
Model XAI F1 of binarized graphs for r=0.3 =  0.6542587499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.51921125
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.493
SUFF for r=0.3 class 0 = 0.474 +- 0.302 (in-sample avg dev_std = 0.423)
SUFF for r=0.3 class 1 = 0.605 +- 0.302 (in-sample avg dev_std = 0.423)
SUFF for r=0.3 class 2 = 0.493 +- 0.302 (in-sample avg dev_std = 0.423)
SUFF for r=0.3 all KL = 0.533 +- 0.302 (in-sample avg dev_std = 0.423)
SUFF for r=0.3 all L1 = 0.525 +- 0.184 (in-sample avg dev_std = 0.423)


ratio=0.6


Computing with masking
[1;31mERROR[0m: 03/20/2024 03:30:44 PM - utils.py - line 87 : [1mTraceback (most recent call last):
  File "/mnt/cimec-storage6/users/steve.azzolin/venv/leci/bin/goodtg", line 33, in <module>
    sys.exit(load_entry_point('graph-ood', 'console_scripts', 'goodtg')())
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/kernel/main.py", line 508, in goodtg
    main()
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/kernel/main.py", line 446, in main
    evaluate_metric(args)
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/kernel/main.py", line 303, in evaluate_metric
    score, acc_int, results = pipeline.compute_metric_ratio(
  File "/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/kernel/pipelines/basic_pipeline.py", line 900, in compute_metric_ratio
    preds_eval, belonging = self.evaluate_graphs(loader, log=False if "fid" in metric else True, weight=ratio, is_ratio=is_ratio, eval_kl=True)
  File "/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/kernel/pipelines/basic_pipeline.py", line 482, in evaluate_graphs
    output = self.model.log_probs(data=data, edge_weight=None, ood_algorithm=self.ood_algorithm, **kwargs)
  File "/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/networks/models/GSATGNNs.py", line 144, in log_probs
    logits, att, edge_att = self(*args, **kwargs)
  File "/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/networks/models/GSATGNNs.py", line 65, in forward
    if is_undirected(data.edge_index):
  File "/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/utils/undirected.py", line 71, in is_undirected
    edge_index2, edge_attrs2 = sort_edge_index(
  File "/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/utils/sort_edge_index.py", line 80, in sort_edge_index
    idx += edge_index[int(sort_by_row)]
KeyboardInterrupt
[0m