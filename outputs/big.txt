nohup: ignoring input

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 19:07:52 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/22/2024 07:07:52 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:04 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:06 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:08 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:09 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:08:11 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 132...
[0m[1;37mINFO[0m: [1mCheckpoint 132: 
-----------------------------------
Train ACCURACY: 0.9035
Train Loss: 0.4128
ID Validation ACCURACY: 0.9023
ID Validation Loss: 0.4270
ID Test ACCURACY: 0.8953
ID Test Loss: 0.4215
OOD Validation ACCURACY: 0.8670
OOD Validation Loss: 0.4795
OOD Test ACCURACY: 0.6793
OOD Test Loss: 0.8040

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 124...
[0m[1;37mINFO[0m: [1mCheckpoint 124: 
-----------------------------------
Train ACCURACY: 0.8663
Train Loss: 0.4837
ID Validation ACCURACY: 0.8677
ID Validation Loss: 0.4913
ID Test ACCURACY: 0.8707
ID Test Loss: 0.4812
OOD Validation ACCURACY: 0.9310
OOD Validation Loss: 0.4154
OOD Test ACCURACY: 0.7697
OOD Test Loss: 0.6769

[0m[1;37mINFO[0m: [1mChartInfo 0.8953 0.6793 0.8707 0.7697 0.8677 0.9310[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.707
WIoU for r=0.3 = 0.658
F1 for r=0.6 = 0.602
WIoU for r=0.6 = 0.745
F1 for r=0.9 = 0.476
WIoU for r=0.9 = 0.758
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.758
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.824
WIoU for r=0.3 = 0.888
F1 for r=0.6 = 0.723
WIoU for r=0.6 = 1.000
F1 for r=0.9 = 0.598
WIoU for r=0.9 = 1.000
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 1.000
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.398
WIoU for r=0.3 = 0.264
F1 for r=0.6 = 0.551
WIoU for r=0.6 = 0.400
F1 for r=0.9 = 0.592
WIoU for r=0.9 = 0.448
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.447


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.655
Model XAI F1 of binarized graphs for r=0.3 =  0.7066849999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.6576274999999999
len(reference) = 791
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.478
SUFF++ for r=0.3 class 0 = 0.482 +- 0.283 (in-sample avg dev_std = 0.571)
SUFF++ for r=0.3 class 1 = 0.514 +- 0.283 (in-sample avg dev_std = 0.571)
SUFF++ for r=0.3 class 2 = 0.477 +- 0.283 (in-sample avg dev_std = 0.571)
SUFF++ for r=0.3 all KL = 0.422 +- 0.283 (in-sample avg dev_std = 0.571)
SUFF++ for r=0.3 all L1 = 0.491 +- 0.163 (in-sample avg dev_std = 0.571)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.845
Model XAI F1 of binarized graphs for r=0.6 =  0.60239375
Model XAI WIoU of binarized graphs for r=0.6 =  0.74490875
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.717
SUFF++ for r=0.6 class 0 = 0.637 +- 0.261 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.6 class 1 = 0.648 +- 0.261 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.6 class 2 = 0.667 +- 0.261 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.6 all KL = 0.64 +- 0.261 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.6 all L1 = 0.651 +- 0.181 (in-sample avg dev_std = 0.472)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.904
Model XAI F1 of binarized graphs for r=0.9 =  0.47577375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.7579224999999999
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.863
SUFF++ for r=0.9 class 0 = 0.854 +- 0.168 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 class 1 = 0.812 +- 0.168 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 class 2 = 0.859 +- 0.168 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 all KL = 0.885 +- 0.168 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 all L1 = 0.842 +- 0.163 (in-sample avg dev_std = 0.244)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.62
Model XAI F1 of binarized graphs for r=0.3 =  0.8242675000000002
Model XAI WIoU of binarized graphs for r=0.3 =  0.8881399999999999
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.54
SUFF++ for r=0.3 class 0 = 0.626 +- 0.317 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 class 1 = 0.769 +- 0.317 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 class 2 = 0.643 +- 0.317 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 all KL = 0.544 +- 0.317 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 all L1 = 0.679 +- 0.201 (in-sample avg dev_std = 0.563)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.871
Model XAI F1 of binarized graphs for r=0.6 =  0.72317875
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.829
SUFF++ for r=0.6 class 0 = 0.85 +- 0.228 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.6 class 1 = 0.802 +- 0.228 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.6 class 2 = 0.825 +- 0.228 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.6 all KL = 0.802 +- 0.228 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.6 all L1 = 0.826 +- 0.148 (in-sample avg dev_std = 0.428)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.871
Model XAI F1 of binarized graphs for r=0.9 =  0.597645
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.874
SUFF++ for r=0.9 class 0 = 0.965 +- 0.077 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.9 class 1 = 0.954 +- 0.077 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.9 class 2 = 0.95 +- 0.077 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.9 all KL = 0.979 +- 0.077 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.9 all L1 = 0.956 +- 0.083 (in-sample avg dev_std = 0.148)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.327
Model XAI F1 of binarized graphs for r=0.3 =  0.39848749999999994
Model XAI WIoU of binarized graphs for r=0.3 =  0.2644925
len(reference) = 744
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.326
SUFF++ for r=0.3 class 0 = 0.658 +- 0.160 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 class 1 = 0.635 +- 0.160 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 class 2 = 0.648 +- 0.160 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 all KL = 0.755 +- 0.160 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 all L1 = 0.647 +- 0.117 (in-sample avg dev_std = 0.456)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.494
Model XAI F1 of binarized graphs for r=0.6 =  0.55061625
Model XAI WIoU of binarized graphs for r=0.6 =  0.39973375000000005
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.46
SUFF++ for r=0.6 class 0 = 0.629 +- 0.252 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.6 class 1 = 0.646 +- 0.252 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.6 class 2 = 0.583 +- 0.252 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.6 all KL = 0.676 +- 0.252 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.6 all L1 = 0.619 +- 0.164 (in-sample avg dev_std = 0.488)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.689
Model XAI F1 of binarized graphs for r=0.9 =  0.59211875
Model XAI WIoU of binarized graphs for r=0.9 =  0.44840374999999993
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.729
SUFF++ for r=0.9 class 0 = 0.741 +- 0.106 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.9 class 1 = 0.972 +- 0.106 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.9 class 2 = 0.778 +- 0.106 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.9 all KL = 0.91 +- 0.106 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.9 all L1 = 0.828 +- 0.159 (in-sample avg dev_std = 0.218)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.651
Model XAI F1 of binarized graphs for r=0.3 =  0.7066849999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.6576274999999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.368
NEC for r=0.3 class 0 = 0.575 +- 0.299 (in-sample avg dev_std = 0.492)
NEC for r=0.3 class 1 = 0.507 +- 0.299 (in-sample avg dev_std = 0.492)
NEC for r=0.3 class 2 = 0.616 +- 0.299 (in-sample avg dev_std = 0.492)
NEC for r=0.3 all KL = 0.613 +- 0.299 (in-sample avg dev_std = 0.492)
NEC for r=0.3 all L1 = 0.566 +- 0.178 (in-sample avg dev_std = 0.492)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.845
Model XAI F1 of binarized graphs for r=0.6 =  0.60239375
Model XAI WIoU of binarized graphs for r=0.6 =  0.74490875
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.487
NEC for r=0.6 class 0 = 0.53 +- 0.301 (in-sample avg dev_std = 0.531)
NEC for r=0.6 class 1 = 0.469 +- 0.301 (in-sample avg dev_std = 0.531)
NEC for r=0.6 class 2 = 0.604 +- 0.301 (in-sample avg dev_std = 0.531)
NEC for r=0.6 all KL = 0.569 +- 0.301 (in-sample avg dev_std = 0.531)
NEC for r=0.6 all L1 = 0.535 +- 0.183 (in-sample avg dev_std = 0.531)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.904
Model XAI F1 of binarized graphs for r=0.9 =  0.47577375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.7579224999999999
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.559
NEC for r=0.9 class 0 = 0.459 +- 0.292 (in-sample avg dev_std = 0.568)
NEC for r=0.9 class 1 = 0.456 +- 0.292 (in-sample avg dev_std = 0.568)
NEC for r=0.9 class 2 = 0.577 +- 0.292 (in-sample avg dev_std = 0.568)
NEC for r=0.9 all KL = 0.523 +- 0.292 (in-sample avg dev_std = 0.568)
NEC for r=0.9 all L1 = 0.499 +- 0.165 (in-sample avg dev_std = 0.568)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.905
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.75789125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.56
NEC for r=1.0 class 0 = 0.47 +- 0.296 (in-sample avg dev_std = 0.565)
NEC for r=1.0 class 1 = 0.459 +- 0.296 (in-sample avg dev_std = 0.565)
NEC for r=1.0 class 2 = 0.562 +- 0.296 (in-sample avg dev_std = 0.565)
NEC for r=1.0 all KL = 0.521 +- 0.296 (in-sample avg dev_std = 0.565)
NEC for r=1.0 all L1 = 0.498 +- 0.167 (in-sample avg dev_std = 0.565)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.62
Model XAI F1 of binarized graphs for r=0.3 =  0.8242675000000002
Model XAI WIoU of binarized graphs for r=0.3 =  0.8881399999999999
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.382
NEC for r=0.3 class 0 = 0.56 +- 0.309 (in-sample avg dev_std = 0.653)
NEC for r=0.3 class 1 = 0.469 +- 0.309 (in-sample avg dev_std = 0.653)
NEC for r=0.3 class 2 = 0.569 +- 0.309 (in-sample avg dev_std = 0.653)
NEC for r=0.3 all KL = 0.67 +- 0.309 (in-sample avg dev_std = 0.653)
NEC for r=0.3 all L1 = 0.533 +- 0.212 (in-sample avg dev_std = 0.653)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.871
Model XAI F1 of binarized graphs for r=0.6 =  0.72317875
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.625
NEC for r=0.6 class 0 = 0.347 +- 0.299 (in-sample avg dev_std = 0.609)
NEC for r=0.6 class 1 = 0.324 +- 0.299 (in-sample avg dev_std = 0.609)
NEC for r=0.6 class 2 = 0.465 +- 0.299 (in-sample avg dev_std = 0.609)
NEC for r=0.6 all KL = 0.455 +- 0.299 (in-sample avg dev_std = 0.609)
NEC for r=0.6 all L1 = 0.378 +- 0.168 (in-sample avg dev_std = 0.609)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.871
Model XAI F1 of binarized graphs for r=0.9 =  0.597645
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.682
NEC for r=0.9 class 0 = 0.292 +- 0.250 (in-sample avg dev_std = 0.558)
NEC for r=0.9 class 1 = 0.268 +- 0.250 (in-sample avg dev_std = 0.558)
NEC for r=0.9 class 2 = 0.373 +- 0.250 (in-sample avg dev_std = 0.558)
NEC for r=0.9 all KL = 0.33 +- 0.250 (in-sample avg dev_std = 0.558)
NEC for r=0.9 all L1 = 0.311 +- 0.148 (in-sample avg dev_std = 0.558)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.871
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  1.0
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.683
NEC for r=1.0 class 0 = 0.264 +- 0.250 (in-sample avg dev_std = 0.546)
NEC for r=1.0 class 1 = 0.261 +- 0.250 (in-sample avg dev_std = 0.546)
NEC for r=1.0 class 2 = 0.39 +- 0.250 (in-sample avg dev_std = 0.546)
NEC for r=1.0 all KL = 0.319 +- 0.250 (in-sample avg dev_std = 0.546)
NEC for r=1.0 all L1 = 0.305 +- 0.156 (in-sample avg dev_std = 0.546)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.319
Model XAI F1 of binarized graphs for r=0.3 =  0.39848749999999994
Model XAI WIoU of binarized graphs for r=0.3 =  0.2644925
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.35
NEC for r=0.3 class 0 = 0.251 +- 0.176 (in-sample avg dev_std = 0.321)
NEC for r=0.3 class 1 = 0.319 +- 0.176 (in-sample avg dev_std = 0.321)
NEC for r=0.3 class 2 = 0.298 +- 0.176 (in-sample avg dev_std = 0.321)
NEC for r=0.3 all KL = 0.166 +- 0.176 (in-sample avg dev_std = 0.321)
NEC for r=0.3 all L1 = 0.289 +- 0.152 (in-sample avg dev_std = 0.321)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.494
Model XAI F1 of binarized graphs for r=0.6 =  0.55061625
Model XAI WIoU of binarized graphs for r=0.6 =  0.39973375000000005
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.478
NEC for r=0.6 class 0 = 0.441 +- 0.277 (in-sample avg dev_std = 0.517)
NEC for r=0.6 class 1 = 0.424 +- 0.277 (in-sample avg dev_std = 0.517)
NEC for r=0.6 class 2 = 0.502 +- 0.277 (in-sample avg dev_std = 0.517)
NEC for r=0.6 all KL = 0.416 +- 0.277 (in-sample avg dev_std = 0.517)
NEC for r=0.6 all L1 = 0.456 +- 0.170 (in-sample avg dev_std = 0.517)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.689
Model XAI F1 of binarized graphs for r=0.9 =  0.59211875
Model XAI WIoU of binarized graphs for r=0.9 =  0.44840374999999993
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.613
NEC for r=0.9 class 0 = 0.454 +- 0.248 (in-sample avg dev_std = 0.508)
NEC for r=0.9 class 1 = 0.217 +- 0.248 (in-sample avg dev_std = 0.508)
NEC for r=0.9 class 2 = 0.548 +- 0.248 (in-sample avg dev_std = 0.508)
NEC for r=0.9 all KL = 0.43 +- 0.248 (in-sample avg dev_std = 0.508)
NEC for r=0.9 all L1 = 0.41 +- 0.200 (in-sample avg dev_std = 0.508)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.691
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.446735
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.631
NEC for r=1.0 class 0 = 0.441 +- 0.227 (in-sample avg dev_std = 0.488)
NEC for r=1.0 class 1 = 0.213 +- 0.227 (in-sample avg dev_std = 0.488)
NEC for r=1.0 class 2 = 0.514 +- 0.227 (in-sample avg dev_std = 0.488)
NEC for r=1.0 all KL = 0.391 +- 0.227 (in-sample avg dev_std = 0.488)
NEC for r=1.0 all L1 = 0.392 +- 0.187 (in-sample avg dev_std = 0.488)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 19:11:15 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:15 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:27 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:29 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:31 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:33 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:11:34 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 133...
[0m[1;37mINFO[0m: [1mCheckpoint 133: 
-----------------------------------
Train ACCURACY: 0.8972
Train Loss: 0.4272
ID Validation ACCURACY: 0.8990
ID Validation Loss: 0.4477
ID Test ACCURACY: 0.9030
ID Test Loss: 0.4154
OOD Validation ACCURACY: 0.9210
OOD Validation Loss: 0.3677
OOD Test ACCURACY: 0.6950
OOD Test Loss: 0.7662

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 132...
[0m[1;37mINFO[0m: [1mCheckpoint 132: 
-----------------------------------
Train ACCURACY: 0.8812
Train Loss: 0.4545
ID Validation ACCURACY: 0.8767
ID Validation Loss: 0.4837
ID Test ACCURACY: 0.8840
ID Test Loss: 0.4477
OOD Validation ACCURACY: 0.9280
OOD Validation Loss: 0.3667
OOD Test ACCURACY: 0.6257
OOD Test Loss: 1.1210

[0m[1;37mINFO[0m: [1mChartInfo 0.9030 0.6950 0.8840 0.6257 0.8767 0.9280[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.686
WIoU for r=0.3 = 0.633
F1 for r=0.6 = 0.608
WIoU for r=0.6 = 0.744
F1 for r=0.9 = 0.475
WIoU for r=0.9 = 0.747
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.747
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.869
WIoU for r=0.3 = 0.874
F1 for r=0.6 = 0.770
WIoU for r=0.6 = 1.000
F1 for r=0.9 = 0.598
WIoU for r=0.9 = 1.000
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 1.000
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.415
WIoU for r=0.3 = 0.282
F1 for r=0.6 = 0.573
WIoU for r=0.6 = 0.431
F1 for r=0.9 = 0.588
WIoU for r=0.9 = 0.473
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.467


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.611
Model XAI F1 of binarized graphs for r=0.3 =  0.68556875
Model XAI WIoU of binarized graphs for r=0.3 =  0.63299125
len(reference) = 791
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.45
SUFF++ for r=0.3 class 0 = 0.494 +- 0.266 (in-sample avg dev_std = 0.589)
SUFF++ for r=0.3 class 1 = 0.477 +- 0.266 (in-sample avg dev_std = 0.589)
SUFF++ for r=0.3 class 2 = 0.446 +- 0.266 (in-sample avg dev_std = 0.589)
SUFF++ for r=0.3 all KL = 0.413 +- 0.266 (in-sample avg dev_std = 0.589)
SUFF++ for r=0.3 all L1 = 0.472 +- 0.150 (in-sample avg dev_std = 0.589)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.846
Model XAI F1 of binarized graphs for r=0.6 =  0.6081150000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.74435625
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.712
SUFF++ for r=0.6 class 0 = 0.625 +- 0.264 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.6 class 1 = 0.684 +- 0.264 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.6 class 2 = 0.604 +- 0.264 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.6 all KL = 0.649 +- 0.264 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.6 all L1 = 0.637 +- 0.180 (in-sample avg dev_std = 0.448)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.899
Model XAI F1 of binarized graphs for r=0.9 =  0.47530500000000003
Model XAI WIoU of binarized graphs for r=0.9 =  0.7473650000000001
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.82
SUFF++ for r=0.9 class 0 = 0.776 +- 0.181 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.9 class 1 = 0.788 +- 0.181 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.9 class 2 = 0.795 +- 0.181 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.9 all KL = 0.859 +- 0.181 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.9 all L1 = 0.787 +- 0.173 (in-sample avg dev_std = 0.258)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.605
Model XAI F1 of binarized graphs for r=0.3 =  0.86858875
Model XAI WIoU of binarized graphs for r=0.3 =  0.873595
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.549
SUFF++ for r=0.3 class 0 = 0.672 +- 0.333 (in-sample avg dev_std = 0.514)
SUFF++ for r=0.3 class 1 = 0.827 +- 0.333 (in-sample avg dev_std = 0.514)
SUFF++ for r=0.3 class 2 = 0.574 +- 0.333 (in-sample avg dev_std = 0.514)
SUFF++ for r=0.3 all KL = 0.591 +- 0.333 (in-sample avg dev_std = 0.514)
SUFF++ for r=0.3 all L1 = 0.69 +- 0.214 (in-sample avg dev_std = 0.514)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.926
Model XAI F1 of binarized graphs for r=0.6 =  0.77017625
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.915
SUFF++ for r=0.6 class 0 = 0.926 +- 0.166 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.6 class 1 = 0.862 +- 0.166 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.6 class 2 = 0.915 +- 0.166 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.6 all KL = 0.915 +- 0.166 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.6 all L1 = 0.901 +- 0.110 (in-sample avg dev_std = 0.245)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.926
Model XAI F1 of binarized graphs for r=0.9 =  0.5983625
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.899
SUFF++ for r=0.9 class 0 = 0.959 +- 0.184 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 class 1 = 0.894 +- 0.184 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 class 2 = 0.87 +- 0.184 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 all KL = 0.937 +- 0.184 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 all L1 = 0.908 +- 0.138 (in-sample avg dev_std = 0.222)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.349
Model XAI F1 of binarized graphs for r=0.3 =  0.41494749999999997
Model XAI WIoU of binarized graphs for r=0.3 =  0.28239
len(reference) = 769
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.347
SUFF++ for r=0.3 class 0 = 0.543 +- 0.262 (in-sample avg dev_std = 0.619)
SUFF++ for r=0.3 class 1 = 0.527 +- 0.262 (in-sample avg dev_std = 0.619)
SUFF++ for r=0.3 class 2 = 0.525 +- 0.262 (in-sample avg dev_std = 0.619)
SUFF++ for r=0.3 all KL = 0.406 +- 0.262 (in-sample avg dev_std = 0.619)
SUFF++ for r=0.3 all L1 = 0.532 +- 0.120 (in-sample avg dev_std = 0.619)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.506
Model XAI F1 of binarized graphs for r=0.6 =  0.5729099999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.43138750000000003
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.475
SUFF++ for r=0.6 class 0 = 0.61 +- 0.262 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.6 class 1 = 0.679 +- 0.262 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.6 class 2 = 0.616 +- 0.262 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.6 all KL = 0.666 +- 0.262 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.6 all L1 = 0.634 +- 0.196 (in-sample avg dev_std = 0.470)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.748
Model XAI F1 of binarized graphs for r=0.9 =  0.5884075
Model XAI WIoU of binarized graphs for r=0.9 =  0.47348
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.736
SUFF++ for r=0.9 class 0 = 0.794 +- 0.073 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.9 class 1 = 0.953 +- 0.073 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.9 class 2 = 0.829 +- 0.073 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.9 all KL = 0.943 +- 0.073 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.9 all L1 = 0.857 +- 0.128 (in-sample avg dev_std = 0.155)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.604
Model XAI F1 of binarized graphs for r=0.3 =  0.68556875
Model XAI WIoU of binarized graphs for r=0.3 =  0.63299125
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.375
NEC for r=0.3 class 0 = 0.576 +- 0.283 (in-sample avg dev_std = 0.486)
NEC for r=0.3 class 1 = 0.479 +- 0.283 (in-sample avg dev_std = 0.486)
NEC for r=0.3 class 2 = 0.619 +- 0.283 (in-sample avg dev_std = 0.486)
NEC for r=0.3 all KL = 0.593 +- 0.283 (in-sample avg dev_std = 0.486)
NEC for r=0.3 all L1 = 0.558 +- 0.163 (in-sample avg dev_std = 0.486)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.846
Model XAI F1 of binarized graphs for r=0.6 =  0.6081150000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.74435625
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.459
NEC for r=0.6 class 0 = 0.559 +- 0.301 (in-sample avg dev_std = 0.484)
NEC for r=0.6 class 1 = 0.442 +- 0.301 (in-sample avg dev_std = 0.484)
NEC for r=0.6 class 2 = 0.637 +- 0.301 (in-sample avg dev_std = 0.484)
NEC for r=0.6 all KL = 0.549 +- 0.301 (in-sample avg dev_std = 0.484)
NEC for r=0.6 all L1 = 0.547 +- 0.176 (in-sample avg dev_std = 0.484)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.899
Model XAI F1 of binarized graphs for r=0.9 =  0.47530500000000003
Model XAI WIoU of binarized graphs for r=0.9 =  0.7473650000000001
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.522
NEC for r=0.9 class 0 = 0.508 +- 0.306 (in-sample avg dev_std = 0.516)
NEC for r=0.9 class 1 = 0.431 +- 0.306 (in-sample avg dev_std = 0.516)
NEC for r=0.9 class 2 = 0.592 +- 0.306 (in-sample avg dev_std = 0.516)
NEC for r=0.9 all KL = 0.511 +- 0.306 (in-sample avg dev_std = 0.516)
NEC for r=0.9 all L1 = 0.511 +- 0.177 (in-sample avg dev_std = 0.516)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.899
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.747375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.557
NEC for r=1.0 class 0 = 0.491 +- 0.305 (in-sample avg dev_std = 0.508)
NEC for r=1.0 class 1 = 0.403 +- 0.305 (in-sample avg dev_std = 0.508)
NEC for r=1.0 class 2 = 0.571 +- 0.305 (in-sample avg dev_std = 0.508)
NEC for r=1.0 all KL = 0.483 +- 0.305 (in-sample avg dev_std = 0.508)
NEC for r=1.0 all L1 = 0.489 +- 0.178 (in-sample avg dev_std = 0.508)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.605
Model XAI F1 of binarized graphs for r=0.3 =  0.86858875
Model XAI WIoU of binarized graphs for r=0.3 =  0.873595
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.241
NEC for r=0.3 class 0 = 0.559 +- 0.287 (in-sample avg dev_std = 0.468)
NEC for r=0.3 class 1 = 0.532 +- 0.287 (in-sample avg dev_std = 0.468)
NEC for r=0.3 class 2 = 0.562 +- 0.287 (in-sample avg dev_std = 0.468)
NEC for r=0.3 all KL = 0.642 +- 0.287 (in-sample avg dev_std = 0.468)
NEC for r=0.3 all L1 = 0.551 +- 0.208 (in-sample avg dev_std = 0.468)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.926
Model XAI F1 of binarized graphs for r=0.6 =  0.77017625
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.576
NEC for r=0.6 class 0 = 0.511 +- 0.336 (in-sample avg dev_std = 0.623)
NEC for r=0.6 class 1 = 0.273 +- 0.336 (in-sample avg dev_std = 0.623)
NEC for r=0.6 class 2 = 0.538 +- 0.336 (in-sample avg dev_std = 0.623)
NEC for r=0.6 all KL = 0.534 +- 0.336 (in-sample avg dev_std = 0.623)
NEC for r=0.6 all L1 = 0.442 +- 0.195 (in-sample avg dev_std = 0.623)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.926
Model XAI F1 of binarized graphs for r=0.9 =  0.5983625
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.655
NEC for r=0.9 class 0 = 0.39 +- 0.267 (in-sample avg dev_std = 0.575)
NEC for r=0.9 class 1 = 0.219 +- 0.267 (in-sample avg dev_std = 0.575)
NEC for r=0.9 class 2 = 0.433 +- 0.267 (in-sample avg dev_std = 0.575)
NEC for r=0.9 all KL = 0.363 +- 0.267 (in-sample avg dev_std = 0.575)
NEC for r=0.9 all L1 = 0.348 +- 0.174 (in-sample avg dev_std = 0.575)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.926
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  1.0
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.67
NEC for r=1.0 class 0 = 0.382 +- 0.264 (in-sample avg dev_std = 0.574)
NEC for r=1.0 class 1 = 0.211 +- 0.264 (in-sample avg dev_std = 0.574)
NEC for r=1.0 class 2 = 0.424 +- 0.264 (in-sample avg dev_std = 0.574)
NEC for r=1.0 all KL = 0.353 +- 0.264 (in-sample avg dev_std = 0.574)
NEC for r=1.0 all L1 = 0.34 +- 0.170 (in-sample avg dev_std = 0.574)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.343
Model XAI F1 of binarized graphs for r=0.3 =  0.41494749999999997
Model XAI WIoU of binarized graphs for r=0.3 =  0.28239
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.377
NEC for r=0.3 class 0 = 0.311 +- 0.311 (in-sample avg dev_std = 0.385)
NEC for r=0.3 class 1 = 0.416 +- 0.311 (in-sample avg dev_std = 0.385)
NEC for r=0.3 class 2 = 0.345 +- 0.311 (in-sample avg dev_std = 0.385)
NEC for r=0.3 all KL = 0.369 +- 0.311 (in-sample avg dev_std = 0.385)
NEC for r=0.3 all L1 = 0.357 +- 0.206 (in-sample avg dev_std = 0.385)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.506
Model XAI F1 of binarized graphs for r=0.6 =  0.5729099999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.43138750000000003
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.488
NEC for r=0.6 class 0 = 0.494 +- 0.309 (in-sample avg dev_std = 0.528)
NEC for r=0.6 class 1 = 0.339 +- 0.309 (in-sample avg dev_std = 0.528)
NEC for r=0.6 class 2 = 0.598 +- 0.309 (in-sample avg dev_std = 0.528)
NEC for r=0.6 all KL = 0.471 +- 0.309 (in-sample avg dev_std = 0.528)
NEC for r=0.6 all L1 = 0.48 +- 0.215 (in-sample avg dev_std = 0.528)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.748
Model XAI F1 of binarized graphs for r=0.9 =  0.5884075
Model XAI WIoU of binarized graphs for r=0.9 =  0.47348
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.603
NEC for r=0.9 class 0 = 0.438 +- 0.262 (in-sample avg dev_std = 0.478)
NEC for r=0.9 class 1 = 0.147 +- 0.262 (in-sample avg dev_std = 0.478)
NEC for r=0.9 class 2 = 0.535 +- 0.262 (in-sample avg dev_std = 0.478)
NEC for r=0.9 all KL = 0.342 +- 0.262 (in-sample avg dev_std = 0.478)
NEC for r=0.9 all L1 = 0.377 +- 0.220 (in-sample avg dev_std = 0.478)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.706
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.46704375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.593
NEC for r=1.0 class 0 = 0.397 +- 0.241 (in-sample avg dev_std = 0.449)
NEC for r=1.0 class 1 = 0.144 +- 0.241 (in-sample avg dev_std = 0.449)
NEC for r=1.0 class 2 = 0.519 +- 0.241 (in-sample avg dev_std = 0.449)
NEC for r=1.0 all KL = 0.305 +- 0.241 (in-sample avg dev_std = 0.449)
NEC for r=1.0 all L1 = 0.357 +- 0.209 (in-sample avg dev_std = 0.449)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 19:14:40 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/22/2024 07:14:40 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 07:14:52 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 07:14:54 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 07:14:56 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 07:14:58 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:15:00 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 124...
[0m[1;37mINFO[0m: [1mCheckpoint 124: 
-----------------------------------
Train ACCURACY: 0.8979
Train Loss: 0.4207
ID Validation ACCURACY: 0.8973
ID Validation Loss: 0.4417
ID Test ACCURACY: 0.8983
ID Test Loss: 0.4343
OOD Validation ACCURACY: 0.8787
OOD Validation Loss: 0.4566
OOD Test ACCURACY: 0.7470
OOD Test Loss: 0.7194

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 109...
[0m[1;37mINFO[0m: [1mCheckpoint 109: 
-----------------------------------
Train ACCURACY: 0.8898
Train Loss: 0.4455
ID Validation ACCURACY: 0.8893
ID Validation Loss: 0.4661
ID Test ACCURACY: 0.8897
ID Test Loss: 0.4398
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.3359
OOD Test ACCURACY: 0.7320
OOD Test Loss: 0.7218

[0m[1;37mINFO[0m: [1mChartInfo 0.8983 0.7470 0.8897 0.7320 0.8893 0.9317[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.724
WIoU for r=0.3 = 0.707
F1 for r=0.6 = 0.620
WIoU for r=0.6 = 0.784
F1 for r=0.9 = 0.476
WIoU for r=0.9 = 0.784
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.784
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.817
WIoU for r=0.3 = 0.880
F1 for r=0.6 = 0.690
WIoU for r=0.6 = 1.000
F1 for r=0.9 = 0.563
WIoU for r=0.9 = 1.000
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 1.000
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.505
WIoU for r=0.3 = 0.413
F1 for r=0.6 = 0.677
WIoU for r=0.6 = 0.587
F1 for r=0.9 = 0.592
WIoU for r=0.9 = 0.612
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.612


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.657
Model XAI F1 of binarized graphs for r=0.3 =  0.72384
Model XAI WIoU of binarized graphs for r=0.3 =  0.70700375
len(reference) = 799
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.476
SUFF++ for r=0.3 class 0 = 0.485 +- 0.282 (in-sample avg dev_std = 0.599)
SUFF++ for r=0.3 class 1 = 0.563 +- 0.282 (in-sample avg dev_std = 0.599)
SUFF++ for r=0.3 class 2 = 0.46 +- 0.282 (in-sample avg dev_std = 0.599)
SUFF++ for r=0.3 all KL = 0.41 +- 0.282 (in-sample avg dev_std = 0.599)
SUFF++ for r=0.3 all L1 = 0.503 +- 0.176 (in-sample avg dev_std = 0.599)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.856
Model XAI F1 of binarized graphs for r=0.6 =  0.61969
Model XAI WIoU of binarized graphs for r=0.6 =  0.7843725
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.692
SUFF++ for r=0.6 class 0 = 0.542 +- 0.296 (in-sample avg dev_std = 0.484)
SUFF++ for r=0.6 class 1 = 0.743 +- 0.296 (in-sample avg dev_std = 0.484)
SUFF++ for r=0.6 class 2 = 0.598 +- 0.296 (in-sample avg dev_std = 0.484)
SUFF++ for r=0.6 all KL = 0.592 +- 0.296 (in-sample avg dev_std = 0.484)
SUFF++ for r=0.6 all L1 = 0.629 +- 0.216 (in-sample avg dev_std = 0.484)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.896
Model XAI F1 of binarized graphs for r=0.9 =  0.4756975
Model XAI WIoU of binarized graphs for r=0.9 =  0.7844737500000001
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.801
SUFF++ for r=0.9 class 0 = 0.675 +- 0.237 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 class 1 = 0.779 +- 0.237 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 class 2 = 0.837 +- 0.237 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 all KL = 0.818 +- 0.237 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 all L1 = 0.766 +- 0.213 (in-sample avg dev_std = 0.274)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.585
Model XAI F1 of binarized graphs for r=0.3 =  0.8170425
Model XAI WIoU of binarized graphs for r=0.3 =  0.88028
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.515
SUFF++ for r=0.3 class 0 = 0.626 +- 0.319 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.3 class 1 = 0.779 +- 0.319 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.3 class 2 = 0.589 +- 0.319 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.3 all KL = 0.539 +- 0.319 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.3 all L1 = 0.664 +- 0.206 (in-sample avg dev_std = 0.532)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  0.6904699999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.9999849999999999
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.838
SUFF++ for r=0.6 class 0 = 0.851 +- 0.217 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.6 class 1 = 0.777 +- 0.217 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.6 class 2 = 0.882 +- 0.217 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.6 all KL = 0.832 +- 0.217 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.6 all L1 = 0.837 +- 0.177 (in-sample avg dev_std = 0.367)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.881
Model XAI F1 of binarized graphs for r=0.9 =  0.56300125
Model XAI WIoU of binarized graphs for r=0.9 =  0.9999549999999999
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.847
SUFF++ for r=0.9 class 0 = 0.816 +- 0.203 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.9 class 1 = 0.817 +- 0.203 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.9 class 2 = 0.92 +- 0.203 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.9 all KL = 0.876 +- 0.203 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.9 all L1 = 0.851 +- 0.196 (in-sample avg dev_std = 0.294)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.323
Model XAI F1 of binarized graphs for r=0.3 =  0.50527125
Model XAI WIoU of binarized graphs for r=0.3 =  0.41275999999999996
len(reference) = 792
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.372
SUFF++ for r=0.3 class 0 = 0.538 +- 0.230 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.3 class 1 = 0.506 +- 0.230 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.3 class 2 = 0.53 +- 0.230 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.3 all KL = 0.587 +- 0.230 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.3 all L1 = 0.525 +- 0.141 (in-sample avg dev_std = 0.495)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.649
Model XAI F1 of binarized graphs for r=0.6 =  0.67744
Model XAI WIoU of binarized graphs for r=0.6 =  0.5872175
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.673
SUFF++ for r=0.6 class 0 = 0.576 +- 0.247 (in-sample avg dev_std = 0.435)
SUFF++ for r=0.6 class 1 = 0.88 +- 0.247 (in-sample avg dev_std = 0.435)
SUFF++ for r=0.6 class 2 = 0.734 +- 0.247 (in-sample avg dev_std = 0.435)
SUFF++ for r=0.6 all KL = 0.734 +- 0.247 (in-sample avg dev_std = 0.435)
SUFF++ for r=0.6 all L1 = 0.727 +- 0.211 (in-sample avg dev_std = 0.435)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.759
Model XAI F1 of binarized graphs for r=0.9 =  0.592455
Model XAI WIoU of binarized graphs for r=0.9 =  0.6116812500000001
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.777
SUFF++ for r=0.9 class 0 = 0.668 +- 0.137 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 class 1 = 0.942 +- 0.137 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 class 2 = 0.859 +- 0.137 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 all KL = 0.901 +- 0.137 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 all L1 = 0.821 +- 0.179 (in-sample avg dev_std = 0.217)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.655
Model XAI F1 of binarized graphs for r=0.3 =  0.72384
Model XAI WIoU of binarized graphs for r=0.3 =  0.70700375
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.405
NEC for r=0.3 class 0 = 0.6 +- 0.278 (in-sample avg dev_std = 0.467)
NEC for r=0.3 class 1 = 0.538 +- 0.278 (in-sample avg dev_std = 0.467)
NEC for r=0.3 class 2 = 0.622 +- 0.278 (in-sample avg dev_std = 0.467)
NEC for r=0.3 all KL = 0.657 +- 0.278 (in-sample avg dev_std = 0.467)
NEC for r=0.3 all L1 = 0.587 +- 0.152 (in-sample avg dev_std = 0.467)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.858
Model XAI F1 of binarized graphs for r=0.6 =  0.61969
Model XAI WIoU of binarized graphs for r=0.6 =  0.7843725
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.464
NEC for r=0.6 class 0 = 0.573 +- 0.291 (in-sample avg dev_std = 0.479)
NEC for r=0.6 class 1 = 0.531 +- 0.291 (in-sample avg dev_std = 0.479)
NEC for r=0.6 class 2 = 0.606 +- 0.291 (in-sample avg dev_std = 0.479)
NEC for r=0.6 all KL = 0.623 +- 0.291 (in-sample avg dev_std = 0.479)
NEC for r=0.6 all L1 = 0.57 +- 0.161 (in-sample avg dev_std = 0.479)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.896
Model XAI F1 of binarized graphs for r=0.9 =  0.4756975
Model XAI WIoU of binarized graphs for r=0.9 =  0.7844737500000001
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.54
NEC for r=0.9 class 0 = 0.528 +- 0.290 (in-sample avg dev_std = 0.542)
NEC for r=0.9 class 1 = 0.49 +- 0.290 (in-sample avg dev_std = 0.542)
NEC for r=0.9 class 2 = 0.54 +- 0.290 (in-sample avg dev_std = 0.542)
NEC for r=0.9 all KL = 0.556 +- 0.290 (in-sample avg dev_std = 0.542)
NEC for r=0.9 all L1 = 0.519 +- 0.161 (in-sample avg dev_std = 0.542)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.896
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.78447125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.533
NEC for r=1.0 class 0 = 0.537 +- 0.288 (in-sample avg dev_std = 0.548)
NEC for r=1.0 class 1 = 0.491 +- 0.288 (in-sample avg dev_std = 0.548)
NEC for r=1.0 class 2 = 0.529 +- 0.288 (in-sample avg dev_std = 0.548)
NEC for r=1.0 all KL = 0.556 +- 0.288 (in-sample avg dev_std = 0.548)
NEC for r=1.0 all L1 = 0.519 +- 0.161 (in-sample avg dev_std = 0.548)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.585
Model XAI F1 of binarized graphs for r=0.3 =  0.8170425
Model XAI WIoU of binarized graphs for r=0.3 =  0.88028
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.155
NEC for r=0.3 class 0 = 0.589 +- 0.263 (in-sample avg dev_std = 0.441)
NEC for r=0.3 class 1 = 0.646 +- 0.263 (in-sample avg dev_std = 0.441)
NEC for r=0.3 class 2 = 0.536 +- 0.263 (in-sample avg dev_std = 0.441)
NEC for r=0.3 all KL = 0.725 +- 0.263 (in-sample avg dev_std = 0.441)
NEC for r=0.3 all L1 = 0.59 +- 0.177 (in-sample avg dev_std = 0.441)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  0.6904699999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.9999849999999999
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.53
NEC for r=0.6 class 0 = 0.489 +- 0.291 (in-sample avg dev_std = 0.642)
NEC for r=0.6 class 1 = 0.388 +- 0.291 (in-sample avg dev_std = 0.642)
NEC for r=0.6 class 2 = 0.431 +- 0.291 (in-sample avg dev_std = 0.642)
NEC for r=0.6 all KL = 0.556 +- 0.291 (in-sample avg dev_std = 0.642)
NEC for r=0.6 all L1 = 0.436 +- 0.176 (in-sample avg dev_std = 0.642)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.881
Model XAI F1 of binarized graphs for r=0.9 =  0.56300125
Model XAI WIoU of binarized graphs for r=0.9 =  0.9999549999999999
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.601
NEC for r=0.9 class 0 = 0.402 +- 0.244 (in-sample avg dev_std = 0.599)
NEC for r=0.9 class 1 = 0.358 +- 0.244 (in-sample avg dev_std = 0.599)
NEC for r=0.9 class 2 = 0.356 +- 0.244 (in-sample avg dev_std = 0.599)
NEC for r=0.9 all KL = 0.415 +- 0.244 (in-sample avg dev_std = 0.599)
NEC for r=0.9 all L1 = 0.372 +- 0.162 (in-sample avg dev_std = 0.599)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.881
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  0.9999549999999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.61
NEC for r=1.0 class 0 = 0.401 +- 0.243 (in-sample avg dev_std = 0.605)
NEC for r=1.0 class 1 = 0.336 +- 0.243 (in-sample avg dev_std = 0.605)
NEC for r=1.0 class 2 = 0.356 +- 0.243 (in-sample avg dev_std = 0.605)
NEC for r=1.0 all KL = 0.41 +- 0.243 (in-sample avg dev_std = 0.605)
NEC for r=1.0 all L1 = 0.364 +- 0.157 (in-sample avg dev_std = 0.605)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.322
Model XAI F1 of binarized graphs for r=0.3 =  0.50527125
Model XAI WIoU of binarized graphs for r=0.3 =  0.41275999999999996
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.359
NEC for r=0.3 class 0 = 0.503 +- 0.276 (in-sample avg dev_std = 0.388)
NEC for r=0.3 class 1 = 0.586 +- 0.276 (in-sample avg dev_std = 0.388)
NEC for r=0.3 class 2 = 0.505 +- 0.276 (in-sample avg dev_std = 0.388)
NEC for r=0.3 all KL = 0.476 +- 0.276 (in-sample avg dev_std = 0.388)
NEC for r=0.3 all L1 = 0.53 +- 0.178 (in-sample avg dev_std = 0.388)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.649
Model XAI F1 of binarized graphs for r=0.6 =  0.67744
Model XAI WIoU of binarized graphs for r=0.6 =  0.5872175
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.529
NEC for r=0.6 class 0 = 0.483 +- 0.304 (in-sample avg dev_std = 0.595)
NEC for r=0.6 class 1 = 0.378 +- 0.304 (in-sample avg dev_std = 0.595)
NEC for r=0.6 class 2 = 0.621 +- 0.304 (in-sample avg dev_std = 0.595)
NEC for r=0.6 all KL = 0.559 +- 0.304 (in-sample avg dev_std = 0.595)
NEC for r=0.6 all L1 = 0.496 +- 0.185 (in-sample avg dev_std = 0.595)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.759
Model XAI F1 of binarized graphs for r=0.9 =  0.592455
Model XAI WIoU of binarized graphs for r=0.9 =  0.6116812500000001
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.612
NEC for r=0.9 class 0 = 0.44 +- 0.244 (in-sample avg dev_std = 0.551)
NEC for r=0.9 class 1 = 0.332 +- 0.244 (in-sample avg dev_std = 0.551)
NEC for r=0.9 class 2 = 0.499 +- 0.244 (in-sample avg dev_std = 0.551)
NEC for r=0.9 all KL = 0.438 +- 0.244 (in-sample avg dev_std = 0.551)
NEC for r=0.9 all L1 = 0.425 +- 0.154 (in-sample avg dev_std = 0.551)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.759
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.61195375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.635
NEC for r=1.0 class 0 = 0.438 +- 0.237 (in-sample avg dev_std = 0.549)
NEC for r=1.0 class 1 = 0.313 +- 0.237 (in-sample avg dev_std = 0.549)
NEC for r=1.0 class 2 = 0.472 +- 0.237 (in-sample avg dev_std = 0.549)
NEC for r=1.0 all KL = 0.419 +- 0.237 (in-sample avg dev_std = 0.549)
NEC for r=1.0 all L1 = 0.409 +- 0.152 (in-sample avg dev_std = 0.549)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 19:18:04 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:04 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:16 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:18 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:20 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:22 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:18:24 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 112...
[0m[1;37mINFO[0m: [1mCheckpoint 112: 
-----------------------------------
Train ACCURACY: 0.9111
Train Loss: 0.4118
ID Validation ACCURACY: 0.9100
ID Validation Loss: 0.4282
ID Test ACCURACY: 0.9093
ID Test Loss: 0.4292
OOD Validation ACCURACY: 0.8720
OOD Validation Loss: 0.4700
OOD Test ACCURACY: 0.6660
OOD Test Loss: 0.8918

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 146...
[0m[1;37mINFO[0m: [1mCheckpoint 146: 
-----------------------------------
Train ACCURACY: 0.8854
Train Loss: 0.4498
ID Validation ACCURACY: 0.8820
ID Validation Loss: 0.4694
ID Test ACCURACY: 0.8770
ID Test Loss: 0.4720
OOD Validation ACCURACY: 0.9293
OOD Validation Loss: 0.3373
OOD Test ACCURACY: 0.5787
OOD Test Loss: 1.0425

[0m[1;37mINFO[0m: [1mChartInfo 0.9093 0.6660 0.8770 0.5787 0.8820 0.9293[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.733
WIoU for r=0.3 = 0.726
F1 for r=0.6 = 0.611
WIoU for r=0.6 = 0.824
F1 for r=0.9 = 0.475
WIoU for r=0.9 = 0.817
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.817
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.829
WIoU for r=0.3 = 0.884
F1 for r=0.6 = 0.694
WIoU for r=0.6 = 0.981
F1 for r=0.9 = 0.549
WIoU for r=0.9 = 0.981
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 0.981
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.516
WIoU for r=0.3 = 0.414
F1 for r=0.6 = 0.652
WIoU for r=0.6 = 0.552
F1 for r=0.9 = 0.579
WIoU for r=0.9 = 0.515
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.509


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.715
Model XAI F1 of binarized graphs for r=0.3 =  0.7329237499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.7262937500000001
len(reference) = 794
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.514
SUFF++ for r=0.3 class 0 = 0.538 +- 0.286 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.3 class 1 = 0.532 +- 0.286 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.3 class 2 = 0.474 +- 0.286 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.3 all KL = 0.407 +- 0.286 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.3 all L1 = 0.514 +- 0.172 (in-sample avg dev_std = 0.604)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.865
Model XAI F1 of binarized graphs for r=0.6 =  0.6113262500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.8242512500000001
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.743
SUFF++ for r=0.6 class 0 = 0.632 +- 0.271 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.6 class 1 = 0.675 +- 0.271 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.6 class 2 = 0.686 +- 0.271 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.6 all KL = 0.658 +- 0.271 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.6 all L1 = 0.665 +- 0.188 (in-sample avg dev_std = 0.451)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.905
Model XAI F1 of binarized graphs for r=0.9 =  0.47540499999999997
Model XAI WIoU of binarized graphs for r=0.9 =  0.8168412500000001
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.851
SUFF++ for r=0.9 class 0 = 0.781 +- 0.199 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.9 class 1 = 0.805 +- 0.199 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.9 class 2 = 0.876 +- 0.199 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.9 all KL = 0.866 +- 0.199 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.9 all L1 = 0.822 +- 0.162 (in-sample avg dev_std = 0.284)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.64
Model XAI F1 of binarized graphs for r=0.3 =  0.8285925000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.883925
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.561
SUFF++ for r=0.3 class 0 = 0.651 +- 0.342 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.3 class 1 = 0.801 +- 0.342 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.3 class 2 = 0.573 +- 0.342 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.3 all KL = 0.536 +- 0.342 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.3 all L1 = 0.675 +- 0.213 (in-sample avg dev_std = 0.555)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.876
Model XAI F1 of binarized graphs for r=0.6 =  0.6938037499999998
Model XAI WIoU of binarized graphs for r=0.6 =  0.9806912499999999
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.841
SUFF++ for r=0.6 class 0 = 0.743 +- 0.291 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.6 class 1 = 0.875 +- 0.291 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.6 class 2 = 0.892 +- 0.291 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.6 all KL = 0.788 +- 0.291 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.6 all L1 = 0.836 +- 0.175 (in-sample avg dev_std = 0.423)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.876
Model XAI F1 of binarized graphs for r=0.9 =  0.5493487499999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.9806912499999999
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.851
SUFF++ for r=0.9 class 0 = 0.79 +- 0.222 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.9 class 1 = 0.935 +- 0.222 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.9 class 2 = 0.945 +- 0.222 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.9 all KL = 0.876 +- 0.222 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.9 all L1 = 0.89 +- 0.152 (in-sample avg dev_std = 0.327)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.313
Model XAI F1 of binarized graphs for r=0.3 =  0.5158937499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.41417375
len(reference) = 785
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.34
SUFF++ for r=0.3 class 0 = 0.484 +- 0.243 (in-sample avg dev_std = 0.611)
SUFF++ for r=0.3 class 1 = 0.479 +- 0.243 (in-sample avg dev_std = 0.611)
SUFF++ for r=0.3 class 2 = 0.489 +- 0.243 (in-sample avg dev_std = 0.611)
SUFF++ for r=0.3 all KL = 0.436 +- 0.243 (in-sample avg dev_std = 0.611)
SUFF++ for r=0.3 all L1 = 0.484 +- 0.123 (in-sample avg dev_std = 0.611)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.632
Model XAI F1 of binarized graphs for r=0.6 =  0.6516525
Model XAI WIoU of binarized graphs for r=0.6 =  0.55193625
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.639
SUFF++ for r=0.6 class 0 = 0.553 +- 0.266 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 class 1 = 0.791 +- 0.266 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 class 2 = 0.703 +- 0.266 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 all KL = 0.664 +- 0.266 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 all L1 = 0.681 +- 0.221 (in-sample avg dev_std = 0.483)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.685
Model XAI F1 of binarized graphs for r=0.9 =  0.57940875
Model XAI WIoU of binarized graphs for r=0.9 =  0.51532875
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.685
SUFF++ for r=0.9 class 0 = 0.571 +- 0.227 (in-sample avg dev_std = 0.331)
SUFF++ for r=0.9 class 1 = 0.941 +- 0.227 (in-sample avg dev_std = 0.331)
SUFF++ for r=0.9 class 2 = 0.774 +- 0.227 (in-sample avg dev_std = 0.331)
SUFF++ for r=0.9 all KL = 0.817 +- 0.227 (in-sample avg dev_std = 0.331)
SUFF++ for r=0.9 all L1 = 0.759 +- 0.222 (in-sample avg dev_std = 0.331)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.71
Model XAI F1 of binarized graphs for r=0.3 =  0.7329237499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.7262937500000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.395
NEC for r=0.3 class 0 = 0.599 +- 0.282 (in-sample avg dev_std = 0.494)
NEC for r=0.3 class 1 = 0.526 +- 0.282 (in-sample avg dev_std = 0.494)
NEC for r=0.3 class 2 = 0.65 +- 0.282 (in-sample avg dev_std = 0.494)
NEC for r=0.3 all KL = 0.684 +- 0.282 (in-sample avg dev_std = 0.494)
NEC for r=0.3 all L1 = 0.592 +- 0.144 (in-sample avg dev_std = 0.494)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.865
Model XAI F1 of binarized graphs for r=0.6 =  0.6113262500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.8242512500000001
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.472
NEC for r=0.6 class 0 = 0.548 +- 0.301 (in-sample avg dev_std = 0.491)
NEC for r=0.6 class 1 = 0.499 +- 0.301 (in-sample avg dev_std = 0.491)
NEC for r=0.6 class 2 = 0.629 +- 0.301 (in-sample avg dev_std = 0.491)
NEC for r=0.6 all KL = 0.584 +- 0.301 (in-sample avg dev_std = 0.491)
NEC for r=0.6 all L1 = 0.56 +- 0.161 (in-sample avg dev_std = 0.491)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.905
Model XAI F1 of binarized graphs for r=0.9 =  0.47540499999999997
Model XAI WIoU of binarized graphs for r=0.9 =  0.8168412500000001
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.551
NEC for r=0.9 class 0 = 0.495 +- 0.301 (in-sample avg dev_std = 0.545)
NEC for r=0.9 class 1 = 0.445 +- 0.301 (in-sample avg dev_std = 0.545)
NEC for r=0.9 class 2 = 0.584 +- 0.301 (in-sample avg dev_std = 0.545)
NEC for r=0.9 all KL = 0.528 +- 0.301 (in-sample avg dev_std = 0.545)
NEC for r=0.9 all L1 = 0.509 +- 0.171 (in-sample avg dev_std = 0.545)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.905
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.81683125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.565
NEC for r=1.0 class 0 = 0.486 +- 0.302 (in-sample avg dev_std = 0.537)
NEC for r=1.0 class 1 = 0.438 +- 0.302 (in-sample avg dev_std = 0.537)
NEC for r=1.0 class 2 = 0.557 +- 0.302 (in-sample avg dev_std = 0.537)
NEC for r=1.0 all KL = 0.51 +- 0.302 (in-sample avg dev_std = 0.537)
NEC for r=1.0 all L1 = 0.494 +- 0.173 (in-sample avg dev_std = 0.537)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.64
Model XAI F1 of binarized graphs for r=0.3 =  0.8285925000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.883925
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.357
NEC for r=0.3 class 0 = 0.613 +- 0.257 (in-sample avg dev_std = 0.438)
NEC for r=0.3 class 1 = 0.581 +- 0.257 (in-sample avg dev_std = 0.438)
NEC for r=0.3 class 2 = 0.632 +- 0.257 (in-sample avg dev_std = 0.438)
NEC for r=0.3 all KL = 0.743 +- 0.257 (in-sample avg dev_std = 0.438)
NEC for r=0.3 all L1 = 0.609 +- 0.153 (in-sample avg dev_std = 0.438)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.876
Model XAI F1 of binarized graphs for r=0.6 =  0.6938037499999998
Model XAI WIoU of binarized graphs for r=0.6 =  0.9806912499999999
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.611
NEC for r=0.6 class 0 = 0.497 +- 0.312 (in-sample avg dev_std = 0.599)
NEC for r=0.6 class 1 = 0.373 +- 0.312 (in-sample avg dev_std = 0.599)
NEC for r=0.6 class 2 = 0.481 +- 0.312 (in-sample avg dev_std = 0.599)
NEC for r=0.6 all KL = 0.556 +- 0.312 (in-sample avg dev_std = 0.599)
NEC for r=0.6 all L1 = 0.451 +- 0.170 (in-sample avg dev_std = 0.599)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.876
Model XAI F1 of binarized graphs for r=0.9 =  0.5493487499999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.9806912499999999
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.666
NEC for r=0.9 class 0 = 0.414 +- 0.271 (in-sample avg dev_std = 0.577)
NEC for r=0.9 class 1 = 0.31 +- 0.271 (in-sample avg dev_std = 0.577)
NEC for r=0.9 class 2 = 0.405 +- 0.271 (in-sample avg dev_std = 0.577)
NEC for r=0.9 all KL = 0.415 +- 0.271 (in-sample avg dev_std = 0.577)
NEC for r=0.9 all L1 = 0.377 +- 0.158 (in-sample avg dev_std = 0.577)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.876
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  0.9806912499999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.666
NEC for r=1.0 class 0 = 0.382 +- 0.271 (in-sample avg dev_std = 0.573)
NEC for r=1.0 class 1 = 0.297 +- 0.271 (in-sample avg dev_std = 0.573)
NEC for r=1.0 class 2 = 0.394 +- 0.271 (in-sample avg dev_std = 0.573)
NEC for r=1.0 all KL = 0.398 +- 0.271 (in-sample avg dev_std = 0.573)
NEC for r=1.0 all L1 = 0.358 +- 0.160 (in-sample avg dev_std = 0.573)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.311
Model XAI F1 of binarized graphs for r=0.3 =  0.5158937499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.41417375
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.372
NEC for r=0.3 class 0 = 0.48 +- 0.288 (in-sample avg dev_std = 0.496)
NEC for r=0.3 class 1 = 0.535 +- 0.288 (in-sample avg dev_std = 0.496)
NEC for r=0.3 class 2 = 0.535 +- 0.288 (in-sample avg dev_std = 0.496)
NEC for r=0.3 all KL = 0.548 +- 0.288 (in-sample avg dev_std = 0.496)
NEC for r=0.3 all L1 = 0.516 +- 0.173 (in-sample avg dev_std = 0.496)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.632
Model XAI F1 of binarized graphs for r=0.6 =  0.6516525
Model XAI WIoU of binarized graphs for r=0.6 =  0.55193625
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.504
NEC for r=0.6 class 0 = 0.428 +- 0.321 (in-sample avg dev_std = 0.549)
NEC for r=0.6 class 1 = 0.342 +- 0.321 (in-sample avg dev_std = 0.549)
NEC for r=0.6 class 2 = 0.631 +- 0.321 (in-sample avg dev_std = 0.549)
NEC for r=0.6 all KL = 0.518 +- 0.321 (in-sample avg dev_std = 0.549)
NEC for r=0.6 all L1 = 0.469 +- 0.222 (in-sample avg dev_std = 0.549)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.685
Model XAI F1 of binarized graphs for r=0.9 =  0.57940875
Model XAI WIoU of binarized graphs for r=0.9 =  0.51532875
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.573
NEC for r=0.9 class 0 = 0.443 +- 0.257 (in-sample avg dev_std = 0.514)
NEC for r=0.9 class 1 = 0.217 +- 0.257 (in-sample avg dev_std = 0.514)
NEC for r=0.9 class 2 = 0.506 +- 0.257 (in-sample avg dev_std = 0.514)
NEC for r=0.9 all KL = 0.394 +- 0.257 (in-sample avg dev_std = 0.514)
NEC for r=0.9 all L1 = 0.392 +- 0.196 (in-sample avg dev_std = 0.514)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.674
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.50932125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.574
NEC for r=1.0 class 0 = 0.438 +- 0.254 (in-sample avg dev_std = 0.507)
NEC for r=1.0 class 1 = 0.204 +- 0.254 (in-sample avg dev_std = 0.507)
NEC for r=1.0 class 2 = 0.498 +- 0.254 (in-sample avg dev_std = 0.507)
NEC for r=1.0 all KL = 0.379 +- 0.254 (in-sample avg dev_std = 0.507)
NEC for r=1.0 all L1 = 0.383 +- 0.198 (in-sample avg dev_std = 0.507)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 19:21:31 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:31 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:43 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:45 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:47 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:49 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:21:50 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 137...
[0m[1;37mINFO[0m: [1mCheckpoint 137: 
-----------------------------------
Train ACCURACY: 0.9082
Train Loss: 0.4161
ID Validation ACCURACY: 0.9060
ID Validation Loss: 0.4276
ID Test ACCURACY: 0.9077
ID Test Loss: 0.4175
OOD Validation ACCURACY: 0.9313
OOD Validation Loss: 0.3282
OOD Test ACCURACY: 0.8457
OOD Test Loss: 0.4898

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 115...
[0m[1;37mINFO[0m: [1mCheckpoint 115: 
-----------------------------------
Train ACCURACY: 0.8790
Train Loss: 0.4656
ID Validation ACCURACY: 0.8803
ID Validation Loss: 0.4735
ID Test ACCURACY: 0.8743
ID Test Loss: 0.4768
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.3354
OOD Test ACCURACY: 0.8413
OOD Test Loss: 0.5178

[0m[1;37mINFO[0m: [1mChartInfo 0.9077 0.8457 0.8743 0.8413 0.8803 0.9317[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.728
WIoU for r=0.3 = 0.704
F1 for r=0.6 = 0.614
WIoU for r=0.6 = 0.800
F1 for r=0.9 = 0.476
WIoU for r=0.9 = 0.797
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.797
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.869
WIoU for r=0.3 = 0.783
F1 for r=0.6 = 0.798
WIoU for r=0.6 = 1.000
F1 for r=0.9 = 0.618
WIoU for r=0.9 = 1.000
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 1.000
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.540
WIoU for r=0.3 = 0.420
F1 for r=0.6 = 0.646
WIoU for r=0.6 = 0.510
F1 for r=0.9 = 0.592
WIoU for r=0.9 = 0.496
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.495


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.652
Model XAI F1 of binarized graphs for r=0.3 =  0.7277025
Model XAI WIoU of binarized graphs for r=0.3 =  0.70377375
len(reference) = 796
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.459
SUFF++ for r=0.3 class 0 = 0.482 +- 0.271 (in-sample avg dev_std = 0.600)
SUFF++ for r=0.3 class 1 = 0.513 +- 0.271 (in-sample avg dev_std = 0.600)
SUFF++ for r=0.3 class 2 = 0.424 +- 0.271 (in-sample avg dev_std = 0.600)
SUFF++ for r=0.3 all KL = 0.394 +- 0.271 (in-sample avg dev_std = 0.600)
SUFF++ for r=0.3 all L1 = 0.473 +- 0.149 (in-sample avg dev_std = 0.600)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.846
Model XAI F1 of binarized graphs for r=0.6 =  0.6144775
Model XAI WIoU of binarized graphs for r=0.6 =  0.80013
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.719
SUFF++ for r=0.6 class 0 = 0.588 +- 0.283 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.6 class 1 = 0.711 +- 0.283 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.6 class 2 = 0.635 +- 0.283 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.6 all KL = 0.618 +- 0.283 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.6 all L1 = 0.645 +- 0.198 (in-sample avg dev_std = 0.467)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.905
Model XAI F1 of binarized graphs for r=0.9 =  0.4757187500000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.79734375
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.823
SUFF++ for r=0.9 class 0 = 0.73 +- 0.223 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 class 1 = 0.769 +- 0.223 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 class 2 = 0.809 +- 0.223 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 all KL = 0.824 +- 0.223 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 all L1 = 0.77 +- 0.199 (in-sample avg dev_std = 0.296)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.466
Model XAI F1 of binarized graphs for r=0.3 =  0.86858875
Model XAI WIoU of binarized graphs for r=0.3 =  0.7829925
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.419
SUFF++ for r=0.3 class 0 = 0.555 +- 0.284 (in-sample avg dev_std = 0.527)
SUFF++ for r=0.3 class 1 = 0.643 +- 0.284 (in-sample avg dev_std = 0.527)
SUFF++ for r=0.3 class 2 = 0.486 +- 0.284 (in-sample avg dev_std = 0.527)
SUFF++ for r=0.3 all KL = 0.526 +- 0.284 (in-sample avg dev_std = 0.527)
SUFF++ for r=0.3 all L1 = 0.561 +- 0.191 (in-sample avg dev_std = 0.527)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.934
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  0.9999750000000001
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.861
SUFF++ for r=0.6 class 0 = 0.746 +- 0.323 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 class 1 = 0.931 +- 0.323 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 class 2 = 0.891 +- 0.323 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 all KL = 0.784 +- 0.323 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 all L1 = 0.855 +- 0.187 (in-sample avg dev_std = 0.456)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.934
Model XAI F1 of binarized graphs for r=0.9 =  0.61811125
Model XAI WIoU of binarized graphs for r=0.9 =  0.9999750000000001
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.934
SUFF++ for r=0.9 class 0 = 0.979 +- 0.020 (in-sample avg dev_std = 0.032)
SUFF++ for r=0.9 class 1 = 0.98 +- 0.020 (in-sample avg dev_std = 0.032)
SUFF++ for r=0.9 class 2 = 0.991 +- 0.020 (in-sample avg dev_std = 0.032)
SUFF++ for r=0.9 all KL = 0.998 +- 0.020 (in-sample avg dev_std = 0.032)
SUFF++ for r=0.9 all L1 = 0.984 +- 0.030 (in-sample avg dev_std = 0.032)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.324
Model XAI F1 of binarized graphs for r=0.3 =  0.53952625
Model XAI WIoU of binarized graphs for r=0.3 =  0.41968249999999996
len(reference) = 787
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.346
SUFF++ for r=0.3 class 0 = 0.55 +- 0.196 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.3 class 1 = 0.576 +- 0.196 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.3 class 2 = 0.559 +- 0.196 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.3 all KL = 0.645 +- 0.196 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.3 all L1 = 0.561 +- 0.134 (in-sample avg dev_std = 0.530)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.738
Model XAI F1 of binarized graphs for r=0.6 =  0.6458625000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.50951875
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.663
SUFF++ for r=0.6 class 0 = 0.565 +- 0.259 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 class 1 = 0.763 +- 0.259 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 class 2 = 0.669 +- 0.259 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 all KL = 0.676 +- 0.259 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 all L1 = 0.664 +- 0.192 (in-sample avg dev_std = 0.468)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.87
Model XAI F1 of binarized graphs for r=0.9 =  0.59204375
Model XAI WIoU of binarized graphs for r=0.9 =  0.49600875
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.755
SUFF++ for r=0.9 class 0 = 0.672 +- 0.240 (in-sample avg dev_std = 0.368)
SUFF++ for r=0.9 class 1 = 0.912 +- 0.240 (in-sample avg dev_std = 0.368)
SUFF++ for r=0.9 class 2 = 0.689 +- 0.240 (in-sample avg dev_std = 0.368)
SUFF++ for r=0.9 all KL = 0.808 +- 0.240 (in-sample avg dev_std = 0.368)
SUFF++ for r=0.9 all L1 = 0.755 +- 0.206 (in-sample avg dev_std = 0.368)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.65
Model XAI F1 of binarized graphs for r=0.3 =  0.7277025
Model XAI WIoU of binarized graphs for r=0.3 =  0.70377375
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.342
NEC for r=0.3 class 0 = 0.607 +- 0.292 (in-sample avg dev_std = 0.483)
NEC for r=0.3 class 1 = 0.578 +- 0.292 (in-sample avg dev_std = 0.483)
NEC for r=0.3 class 2 = 0.622 +- 0.292 (in-sample avg dev_std = 0.483)
NEC for r=0.3 all KL = 0.665 +- 0.292 (in-sample avg dev_std = 0.483)
NEC for r=0.3 all L1 = 0.603 +- 0.161 (in-sample avg dev_std = 0.483)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.846
Model XAI F1 of binarized graphs for r=0.6 =  0.6144775
Model XAI WIoU of binarized graphs for r=0.6 =  0.80013
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.448
NEC for r=0.6 class 0 = 0.542 +- 0.290 (in-sample avg dev_std = 0.501)
NEC for r=0.6 class 1 = 0.571 +- 0.290 (in-sample avg dev_std = 0.501)
NEC for r=0.6 class 2 = 0.613 +- 0.290 (in-sample avg dev_std = 0.501)
NEC for r=0.6 all KL = 0.625 +- 0.290 (in-sample avg dev_std = 0.501)
NEC for r=0.6 all L1 = 0.576 +- 0.162 (in-sample avg dev_std = 0.501)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.905
Model XAI F1 of binarized graphs for r=0.9 =  0.4757187500000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.79734375
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.529
NEC for r=0.9 class 0 = 0.483 +- 0.283 (in-sample avg dev_std = 0.528)
NEC for r=0.9 class 1 = 0.529 +- 0.283 (in-sample avg dev_std = 0.528)
NEC for r=0.9 class 2 = 0.555 +- 0.283 (in-sample avg dev_std = 0.528)
NEC for r=0.9 all KL = 0.549 +- 0.283 (in-sample avg dev_std = 0.528)
NEC for r=0.9 all L1 = 0.524 +- 0.164 (in-sample avg dev_std = 0.528)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.906
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.7967962499999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.54
NEC for r=1.0 class 0 = 0.481 +- 0.281 (in-sample avg dev_std = 0.533)
NEC for r=1.0 class 1 = 0.508 +- 0.281 (in-sample avg dev_std = 0.533)
NEC for r=1.0 class 2 = 0.547 +- 0.281 (in-sample avg dev_std = 0.533)
NEC for r=1.0 all KL = 0.539 +- 0.281 (in-sample avg dev_std = 0.533)
NEC for r=1.0 all L1 = 0.513 +- 0.160 (in-sample avg dev_std = 0.533)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.466
Model XAI F1 of binarized graphs for r=0.3 =  0.86858875
Model XAI WIoU of binarized graphs for r=0.3 =  0.7829925
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.215
NEC for r=0.3 class 0 = 0.572 +- 0.290 (in-sample avg dev_std = 0.430)
NEC for r=0.3 class 1 = 0.618 +- 0.290 (in-sample avg dev_std = 0.430)
NEC for r=0.3 class 2 = 0.627 +- 0.290 (in-sample avg dev_std = 0.430)
NEC for r=0.3 all KL = 0.62 +- 0.290 (in-sample avg dev_std = 0.430)
NEC for r=0.3 all L1 = 0.605 +- 0.150 (in-sample avg dev_std = 0.430)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.934
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  0.9999750000000001
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.513
NEC for r=0.6 class 0 = 0.522 +- 0.239 (in-sample avg dev_std = 0.651)
NEC for r=0.6 class 1 = 0.543 +- 0.239 (in-sample avg dev_std = 0.651)
NEC for r=0.6 class 2 = 0.559 +- 0.239 (in-sample avg dev_std = 0.651)
NEC for r=0.6 all KL = 0.717 +- 0.239 (in-sample avg dev_std = 0.651)
NEC for r=0.6 all L1 = 0.541 +- 0.153 (in-sample avg dev_std = 0.651)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.934
Model XAI F1 of binarized graphs for r=0.9 =  0.61811125
Model XAI WIoU of binarized graphs for r=0.9 =  0.9999750000000001
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.653
NEC for r=0.9 class 0 = 0.38 +- 0.237 (in-sample avg dev_std = 0.624)
NEC for r=0.9 class 1 = 0.398 +- 0.237 (in-sample avg dev_std = 0.624)
NEC for r=0.9 class 2 = 0.434 +- 0.237 (in-sample avg dev_std = 0.624)
NEC for r=0.9 all KL = 0.461 +- 0.237 (in-sample avg dev_std = 0.624)
NEC for r=0.9 all L1 = 0.404 +- 0.150 (in-sample avg dev_std = 0.624)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.934
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  0.9999750000000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.654
NEC for r=1.0 class 0 = 0.379 +- 0.226 (in-sample avg dev_std = 0.625)
NEC for r=1.0 class 1 = 0.403 +- 0.226 (in-sample avg dev_std = 0.625)
NEC for r=1.0 class 2 = 0.431 +- 0.226 (in-sample avg dev_std = 0.625)
NEC for r=1.0 all KL = 0.457 +- 0.226 (in-sample avg dev_std = 0.625)
NEC for r=1.0 all L1 = 0.405 +- 0.143 (in-sample avg dev_std = 0.625)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.321
Model XAI F1 of binarized graphs for r=0.3 =  0.53952625
Model XAI WIoU of binarized graphs for r=0.3 =  0.41968249999999996
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.343
NEC for r=0.3 class 0 = 0.488 +- 0.246 (in-sample avg dev_std = 0.462)
NEC for r=0.3 class 1 = 0.517 +- 0.246 (in-sample avg dev_std = 0.462)
NEC for r=0.3 class 2 = 0.474 +- 0.246 (in-sample avg dev_std = 0.462)
NEC for r=0.3 all KL = 0.409 +- 0.246 (in-sample avg dev_std = 0.462)
NEC for r=0.3 all L1 = 0.492 +- 0.185 (in-sample avg dev_std = 0.462)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.739
Model XAI F1 of binarized graphs for r=0.6 =  0.6458625000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.50951875
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.523
NEC for r=0.6 class 0 = 0.543 +- 0.274 (in-sample avg dev_std = 0.589)
NEC for r=0.6 class 1 = 0.503 +- 0.274 (in-sample avg dev_std = 0.589)
NEC for r=0.6 class 2 = 0.623 +- 0.274 (in-sample avg dev_std = 0.589)
NEC for r=0.6 all KL = 0.603 +- 0.274 (in-sample avg dev_std = 0.589)
NEC for r=0.6 all L1 = 0.557 +- 0.144 (in-sample avg dev_std = 0.589)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.87
Model XAI F1 of binarized graphs for r=0.9 =  0.59204375
Model XAI WIoU of binarized graphs for r=0.9 =  0.49600875
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.625
NEC for r=0.9 class 0 = 0.45 +- 0.241 (in-sample avg dev_std = 0.564)
NEC for r=0.9 class 1 = 0.423 +- 0.241 (in-sample avg dev_std = 0.564)
NEC for r=0.9 class 2 = 0.521 +- 0.241 (in-sample avg dev_std = 0.564)
NEC for r=0.9 all KL = 0.496 +- 0.241 (in-sample avg dev_std = 0.564)
NEC for r=0.9 all L1 = 0.466 +- 0.146 (in-sample avg dev_std = 0.564)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.864
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.49549374999999996
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.642
NEC for r=1.0 class 0 = 0.445 +- 0.235 (in-sample avg dev_std = 0.569)
NEC for r=1.0 class 1 = 0.407 +- 0.235 (in-sample avg dev_std = 0.569)
NEC for r=1.0 class 2 = 0.504 +- 0.235 (in-sample avg dev_std = 0.569)
NEC for r=1.0 all KL = 0.482 +- 0.235 (in-sample avg dev_std = 0.569)
NEC for r=1.0 all L1 = 0.453 +- 0.142 (in-sample avg dev_std = 0.569)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.422, 0.64, 0.885, 1.0], 'all_L1': [0.491, 0.651, 0.842, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.413, 0.649, 0.859, 1.0], 'all_L1': [0.472, 0.637, 0.787, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.41, 0.592, 0.818, 1.0], 'all_L1': [0.503, 0.629, 0.766, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.407, 0.658, 0.866, 1.0], 'all_L1': [0.514, 0.665, 0.822, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.394, 0.618, 0.824, 1.0], 'all_L1': [0.473, 0.645, 0.77, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.613, 0.569, 0.523, 0.521], 'all_L1': [0.566, 0.535, 0.499, 0.498]}), defaultdict(<class 'list'>, {'all_KL': [0.593, 0.549, 0.511, 0.483], 'all_L1': [0.558, 0.547, 0.511, 0.489]}), defaultdict(<class 'list'>, {'all_KL': [0.657, 0.623, 0.556, 0.556], 'all_L1': [0.587, 0.57, 0.519, 0.519]}), defaultdict(<class 'list'>, {'all_KL': [0.684, 0.584, 0.528, 0.51], 'all_L1': [0.592, 0.56, 0.509, 0.494]}), defaultdict(<class 'list'>, {'all_KL': [0.665, 0.625, 0.549, 0.539], 'all_L1': [0.603, 0.576, 0.524, 0.513]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.544, 0.802, 0.979, 1.0], 'all_L1': [0.679, 0.826, 0.956, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.591, 0.915, 0.937, 1.0], 'all_L1': [0.69, 0.901, 0.908, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.539, 0.832, 0.876, 1.0], 'all_L1': [0.664, 0.837, 0.851, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.536, 0.788, 0.876, 1.0], 'all_L1': [0.675, 0.836, 0.89, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.526, 0.784, 0.998, 1.0], 'all_L1': [0.561, 0.855, 0.984, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.67, 0.455, 0.33, 0.319], 'all_L1': [0.533, 0.378, 0.311, 0.305]}), defaultdict(<class 'list'>, {'all_KL': [0.642, 0.534, 0.363, 0.353], 'all_L1': [0.551, 0.442, 0.348, 0.34]}), defaultdict(<class 'list'>, {'all_KL': [0.725, 0.556, 0.415, 0.41], 'all_L1': [0.59, 0.436, 0.372, 0.364]}), defaultdict(<class 'list'>, {'all_KL': [0.743, 0.556, 0.415, 0.398], 'all_L1': [0.609, 0.451, 0.377, 0.358]}), defaultdict(<class 'list'>, {'all_KL': [0.62, 0.717, 0.461, 0.457], 'all_L1': [0.605, 0.541, 0.404, 0.405]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.755, 0.676, 0.91, 1.0], 'all_L1': [0.647, 0.619, 0.828, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.406, 0.666, 0.943, 1.0], 'all_L1': [0.532, 0.634, 0.857, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.587, 0.734, 0.901, 1.0], 'all_L1': [0.525, 0.727, 0.821, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.436, 0.664, 0.817, 1.0], 'all_L1': [0.484, 0.681, 0.759, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.645, 0.676, 0.808, 1.0], 'all_L1': [0.561, 0.664, 0.755, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.166, 0.416, 0.43, 0.391], 'all_L1': [0.289, 0.456, 0.41, 0.392]}), defaultdict(<class 'list'>, {'all_KL': [0.369, 0.471, 0.342, 0.305], 'all_L1': [0.357, 0.48, 0.377, 0.357]}), defaultdict(<class 'list'>, {'all_KL': [0.476, 0.559, 0.438, 0.419], 'all_L1': [0.53, 0.496, 0.425, 0.409]}), defaultdict(<class 'list'>, {'all_KL': [0.548, 0.518, 0.394, 0.379], 'all_L1': [0.516, 0.469, 0.392, 0.383]}), defaultdict(<class 'list'>, {'all_KL': [0.409, 0.603, 0.496, 0.482], 'all_L1': [0.492, 0.557, 0.466, 0.453]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.491 +- 0.016, 0.645 +- 0.012, 0.797 +- 0.030, 1.000 +- 0.000
suff++ class all_KL  =  0.409 +- 0.009, 0.631 +- 0.024, 0.850 +- 0.026, 1.000 +- 0.000
suff++_acc_int  =  0.475 +- 0.022, 0.716 +- 0.016, 0.831 +- 0.022
nec class all_L1  =  0.581 +- 0.017, 0.558 +- 0.015, 0.512 +- 0.009, 0.503 +- 0.011
nec class all_KL  =  0.642 +- 0.034, 0.590 +- 0.030, 0.533 +- 0.017, 0.522 +- 0.025
nec_acc_int  =  0.377 +- 0.022, 0.466 +- 0.013, 0.540 +- 0.014, 0.551 +- 0.012

Eval split val
suff++ class all_L1  =  0.654 +- 0.047, 0.851 +- 0.027, 0.918 +- 0.047, 1.000 +- 0.000
suff++ class all_KL  =  0.547 +- 0.023, 0.824 +- 0.048, 0.933 +- 0.051, 1.000 +- 0.000
suff++_acc_int  =  0.517 +- 0.051, 0.857 +- 0.031, 0.881 +- 0.032
nec class all_L1  =  0.578 +- 0.030, 0.450 +- 0.052, 0.362 +- 0.031, 0.354 +- 0.033
nec class all_KL  =  0.680 +- 0.047, 0.564 +- 0.085, 0.397 +- 0.046, 0.387 +- 0.048
nec_acc_int  =  0.270 +- 0.086, 0.571 +- 0.044, 0.652 +- 0.027, 0.657 +- 0.025

Eval split test
suff++ class all_L1  =  0.550 +- 0.054, 0.665 +- 0.038, 0.804 +- 0.040, 1.000 +- 0.000
suff++ class all_KL  =  0.566 +- 0.130, 0.683 +- 0.026, 0.876 +- 0.054, 1.000 +- 0.000
suff++_acc_int  =  0.346 +- 0.015, 0.582 +- 0.094, 0.736 +- 0.031
nec class all_L1  =  0.437 +- 0.096, 0.492 +- 0.035, 0.414 +- 0.031, 0.399 +- 0.032
nec class all_KL  =  0.394 +- 0.129, 0.513 +- 0.065, 0.420 +- 0.051, 0.395 +- 0.057
nec_acc_int  =  0.360 +- 0.013, 0.504 +- 0.019, 0.605 +- 0.018, 0.615 +- 0.027


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
torch.Size([5, 4])
Faith. Aritm (L1)= 		  =  0.536 +- 0.013, 0.602 +- 0.009, 0.655 +- 0.011, 0.751 +- 0.006
Faith. Armon (L1)= 		  =  0.532 +- 0.013, 0.598 +- 0.009, 0.623 +- 0.004, 0.669 +- 0.010
Faith. GMean (L1)= 	  =  0.534 +- 0.013, 0.600 +- 0.009, 0.639 +- 0.007, 0.709 +- 0.008
torch.Size([5, 4])
Faith. Aritm (KL)= 		  =  0.526 +- 0.014, 0.611 +- 0.009, 0.692 +- 0.007, 0.761 +- 0.012
Faith. Armon (KL)= 		  =  0.499 +- 0.008, 0.609 +- 0.010, 0.655 +- 0.007, 0.685 +- 0.022
Faith. GMean (KL)= 	  =  0.512 +- 0.011, 0.610 +- 0.009, 0.673 +- 0.006, 0.722 +- 0.017

Eval split val
torch.Size([5, 4])
Faith. Aritm (L1)= 		  =  0.616 +- 0.020, 0.650 +- 0.033, 0.640 +- 0.028, 0.677 +- 0.016
Faith. Armon (L1)= 		  =  0.611 +- 0.020, 0.587 +- 0.046, 0.519 +- 0.034, 0.522 +- 0.036
Faith. GMean (L1)= 	  =  0.614 +- 0.020, 0.618 +- 0.039, 0.576 +- 0.029, 0.595 +- 0.027
torch.Size([5, 4])
Faith. Aritm (KL)= 		  =  0.614 +- 0.023, 0.694 +- 0.042, 0.665 +- 0.032, 0.694 +- 0.024
Faith. Armon (KL)= 		  =  0.605 +- 0.020, 0.665 +- 0.054, 0.555 +- 0.046, 0.557 +- 0.050
Faith. GMean (KL)= 	  =  0.609 +- 0.021, 0.679 +- 0.048, 0.607 +- 0.038, 0.621 +- 0.038

Eval split test
torch.Size([5, 4])
Faith. Aritm (L1)= 		  =  0.493 +- 0.033, 0.578 +- 0.029, 0.609 +- 0.017, 0.699 +- 0.016
Faith. Armon (L1)= 		  =  0.476 +- 0.052, 0.564 +- 0.029, 0.545 +- 0.022, 0.569 +- 0.032
Faith. GMean (L1)= 	  =  0.484 +- 0.042, 0.571 +- 0.029, 0.576 +- 0.018, 0.631 +- 0.025
torch.Size([5, 4])
Faith. Aritm (KL)= 		  =  0.480 +- 0.053, 0.598 +- 0.039, 0.648 +- 0.024, 0.698 +- 0.029
Faith. Armon (KL)= 		  =  0.434 +- 0.094, 0.584 +- 0.047, 0.564 +- 0.041, 0.564 +- 0.060
Faith. GMean (KL)= 	  =  0.454 +- 0.070, 0.591 +- 0.043, 0.604 +- 0.030, 0.627 +- 0.046
Computed for split load_split = id



Completed in  0:17:07.961637  for LECIGIN GOODMotif/basis



DONE LECI GOODMotif/basis

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 19:25:15 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/22/2024 07:25:16 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 07:25:28 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 07:25:30 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 07:25:32 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 07:25:33 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 07:25:35 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 07:25:35 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 07:25:35 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/22/2024 07:25:35 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 07:25:35 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:25:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:25:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:25:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:25:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:25:35 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/22/2024 07:25:35 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:25:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:25:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:25:35 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/22/2024 07:25:35 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 32...
[0m[1;37mINFO[0m: [1mCheckpoint 32: 
-----------------------------------
Train ACCURACY: 0.8933
Train Loss: 0.4689
ID Validation ACCURACY: 0.8867
ID Validation Loss: 0.4937
ID Test ACCURACY: 0.9010
ID Test Loss: 0.4439
OOD Validation ACCURACY: 0.6550
OOD Validation Loss: 1.5131
OOD Test ACCURACY: 0.3787
OOD Test Loss: 2.5757

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 3...
[0m[1;37mINFO[0m: [1mCheckpoint 3: 
-----------------------------------
Train ACCURACY: 0.5774
Train Loss: 1.3209
ID Validation ACCURACY: 0.5740
ID Validation Loss: 1.3483
ID Test ACCURACY: 0.5860
ID Test Loss: 1.2983
OOD Validation ACCURACY: 0.9227
OOD Validation Loss: 0.4906
OOD Test ACCURACY: 0.3487
OOD Test Loss: 9.0129

[0m[1;37mINFO[0m: [1mChartInfo 0.9010 0.3787 0.5860 0.3487 0.5740 0.9227[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.6 = 0.551
WIoU for r=0.6 = 0.675
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.6 = 0.795
WIoU for r=0.6 = 0.996
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.6 = 0.446
WIoU for r=0.6 = 0.351


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.887
Model XAI F1 of binarized graphs for r=0.6 =  0.5512824999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.67477125
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.622
SUFF++ for r=0.6 class 0 = 0.416 +- 0.275 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.6 class 1 = 0.551 +- 0.275 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.6 class 2 = 0.609 +- 0.275 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.6 all KL = 0.48 +- 0.275 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.6 all L1 = 0.528 +- 0.204 (in-sample avg dev_std = 0.554)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.654
Model XAI F1 of binarized graphs for r=0.6 =  0.7952750000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.9961325
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.674
SUFF++ for r=0.6 class 0 = 0.792 +- 0.336 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.6 class 1 = 0.548 +- 0.336 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.6 class 2 = 0.696 +- 0.336 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.6 all KL = 0.507 +- 0.336 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.6 all L1 = 0.68 +- 0.202 (in-sample avg dev_std = 0.595)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.377
Model XAI F1 of binarized graphs for r=0.6 =  0.44613375
Model XAI WIoU of binarized graphs for r=0.6 =  0.35077749999999996
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.398
SUFF++ for r=0.6 class 0 = 0.759 +- 0.257 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.6 class 1 = 0.845 +- 0.257 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.6 class 2 = 0.664 +- 0.257 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.6 all KL = 0.674 +- 0.257 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.6 all L1 = 0.754 +- 0.192 (in-sample avg dev_std = 0.450)


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.887
Model XAI F1 of binarized graphs for r=0.6 =  0.5512824999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.67477125
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.445
NEC for r=0.6 class 0 = 0.6 +- 0.257 (in-sample avg dev_std = 0.625)
NEC for r=0.6 class 1 = 0.544 +- 0.257 (in-sample avg dev_std = 0.625)
NEC for r=0.6 class 2 = 0.661 +- 0.257 (in-sample avg dev_std = 0.625)
NEC for r=0.6 all KL = 0.671 +- 0.257 (in-sample avg dev_std = 0.625)
NEC for r=0.6 all L1 = 0.602 +- 0.157 (in-sample avg dev_std = 0.625)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.654
Model XAI F1 of binarized graphs for r=0.6 =  0.7952750000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.9961325
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.409
NEC for r=0.6 class 0 = 0.375 +- 0.326 (in-sample avg dev_std = 0.562)
NEC for r=0.6 class 1 = 0.269 +- 0.326 (in-sample avg dev_std = 0.562)
NEC for r=0.6 class 2 = 0.541 +- 0.326 (in-sample avg dev_std = 0.562)
NEC for r=0.6 all KL = 0.464 +- 0.326 (in-sample avg dev_std = 0.562)
NEC for r=0.6 all L1 = 0.396 +- 0.219 (in-sample avg dev_std = 0.562)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.377
Model XAI F1 of binarized graphs for r=0.6 =  0.44613375
Model XAI WIoU of binarized graphs for r=0.6 =  0.35077749999999996
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.421
NEC for r=0.6 class 0 = 0.31 +- 0.284 (in-sample avg dev_std = 0.430)
NEC for r=0.6 class 1 = 0.144 +- 0.284 (in-sample avg dev_std = 0.430)
NEC for r=0.6 class 2 = 0.359 +- 0.284 (in-sample avg dev_std = 0.430)
NEC for r=0.6 all KL = 0.32 +- 0.284 (in-sample avg dev_std = 0.430)
NEC for r=0.6 all L1 = 0.273 +- 0.221 (in-sample avg dev_std = 0.430)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 19:26:34 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/22/2024 07:26:34 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 07:26:47 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 07:26:49 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 07:26:51 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 07:26:52 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 07:26:54 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 07:26:54 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 07:26:54 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/22/2024 07:26:54 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 07:26:54 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:26:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:26:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:26:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:26:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:26:54 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/22/2024 07:26:54 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:26:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:26:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:26:54 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/22/2024 07:26:54 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 86...
[0m[1;37mINFO[0m: [1mCheckpoint 86: 
-----------------------------------
Train ACCURACY: 0.8799
Train Loss: 0.4851
ID Validation ACCURACY: 0.8757
ID Validation Loss: 0.5174
ID Test ACCURACY: 0.8873
ID Test Loss: 0.4680
OOD Validation ACCURACY: 0.6670
OOD Validation Loss: 0.9447
OOD Test ACCURACY: 0.4367
OOD Test Loss: 3.0736

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 58...
[0m[1;37mINFO[0m: [1mCheckpoint 58: 
-----------------------------------
Train ACCURACY: 0.8507
Train Loss: 0.4884
ID Validation ACCURACY: 0.8450
ID Validation Loss: 0.5152
ID Test ACCURACY: 0.8610
ID Test Loss: 0.4707
OOD Validation ACCURACY: 0.9313
OOD Validation Loss: 0.4447
OOD Test ACCURACY: 0.3857
OOD Test Loss: 4.2847

[0m[1;37mINFO[0m: [1mChartInfo 0.8873 0.4367 0.8610 0.3857 0.8450 0.9313[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.6 = 0.583
WIoU for r=0.6 = 0.685
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.6 = 0.798
WIoU for r=0.6 = 1.000
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.6 = 0.503
WIoU for r=0.6 = 0.392


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.877
Model XAI F1 of binarized graphs for r=0.6 =  0.5826612499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.68527375
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.649
SUFF++ for r=0.6 class 0 = 0.481 +- 0.294 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.6 class 1 = 0.621 +- 0.294 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.6 class 2 = 0.59 +- 0.294 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.6 all KL = 0.468 +- 0.294 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.6 all L1 = 0.566 +- 0.208 (in-sample avg dev_std = 0.577)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.665
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.682
SUFF++ for r=0.6 class 0 = 0.729 +- 0.374 (in-sample avg dev_std = 0.642)
SUFF++ for r=0.6 class 1 = 0.579 +- 0.374 (in-sample avg dev_std = 0.642)
SUFF++ for r=0.6 class 2 = 0.56 +- 0.374 (in-sample avg dev_std = 0.642)
SUFF++ for r=0.6 all KL = 0.496 +- 0.374 (in-sample avg dev_std = 0.642)
SUFF++ for r=0.6 all L1 = 0.623 +- 0.229 (in-sample avg dev_std = 0.642)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.449
Model XAI F1 of binarized graphs for r=0.6 =  0.5030675
Model XAI WIoU of binarized graphs for r=0.6 =  0.39181875000000005
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.402
SUFF++ for r=0.6 class 0 = 0.764 +- 0.288 (in-sample avg dev_std = 0.373)
SUFF++ for r=0.6 class 1 = 0.899 +- 0.288 (in-sample avg dev_std = 0.373)
SUFF++ for r=0.6 class 2 = 0.767 +- 0.288 (in-sample avg dev_std = 0.373)
SUFF++ for r=0.6 all KL = 0.753 +- 0.288 (in-sample avg dev_std = 0.373)
SUFF++ for r=0.6 all L1 = 0.809 +- 0.224 (in-sample avg dev_std = 0.373)


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.877
Model XAI F1 of binarized graphs for r=0.6 =  0.5826612499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.68527375
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.455
NEC for r=0.6 class 0 = 0.588 +- 0.262 (in-sample avg dev_std = 0.658)
NEC for r=0.6 class 1 = 0.55 +- 0.262 (in-sample avg dev_std = 0.658)
NEC for r=0.6 class 2 = 0.666 +- 0.262 (in-sample avg dev_std = 0.658)
NEC for r=0.6 all KL = 0.716 +- 0.262 (in-sample avg dev_std = 0.658)
NEC for r=0.6 all L1 = 0.602 +- 0.170 (in-sample avg dev_std = 0.658)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.665
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.494
NEC for r=0.6 class 0 = 0.345 +- 0.323 (in-sample avg dev_std = 0.542)
NEC for r=0.6 class 1 = 0.382 +- 0.323 (in-sample avg dev_std = 0.542)
NEC for r=0.6 class 2 = 0.512 +- 0.323 (in-sample avg dev_std = 0.542)
NEC for r=0.6 all KL = 0.487 +- 0.323 (in-sample avg dev_std = 0.542)
NEC for r=0.6 all L1 = 0.413 +- 0.229 (in-sample avg dev_std = 0.542)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.449
Model XAI F1 of binarized graphs for r=0.6 =  0.5030675
Model XAI WIoU of binarized graphs for r=0.6 =  0.39181875000000005
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.45
NEC for r=0.6 class 0 = 0.353 +- 0.336 (in-sample avg dev_std = 0.460)
NEC for r=0.6 class 1 = 0.09 +- 0.336 (in-sample avg dev_std = 0.460)
NEC for r=0.6 class 2 = 0.419 +- 0.336 (in-sample avg dev_std = 0.460)
NEC for r=0.6 all KL = 0.37 +- 0.336 (in-sample avg dev_std = 0.460)
NEC for r=0.6 all L1 = 0.291 +- 0.269 (in-sample avg dev_std = 0.460)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 19:27:54 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/22/2024 07:27:54 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 07:28:06 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 07:28:08 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 07:28:10 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 07:28:12 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 07:28:14 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 07:28:14 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 07:28:14 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/22/2024 07:28:14 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 07:28:14 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:28:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:28:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:28:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:28:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:28:14 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/22/2024 07:28:14 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:28:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:28:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:28:14 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/22/2024 07:28:14 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 90...
[0m[1;37mINFO[0m: [1mCheckpoint 90: 
-----------------------------------
Train ACCURACY: 0.9108
Train Loss: 0.4126
ID Validation ACCURACY: 0.9080
ID Validation Loss: 0.4411
ID Test ACCURACY: 0.9153
ID Test Loss: 0.4096
OOD Validation ACCURACY: 0.9047
OOD Validation Loss: 0.4491
OOD Test ACCURACY: 0.4210
OOD Test Loss: 3.6186

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 42...
[0m[1;37mINFO[0m: [1mCheckpoint 42: 
-----------------------------------
Train ACCURACY: 0.8849
Train Loss: 0.5208
ID Validation ACCURACY: 0.8813
ID Validation Loss: 0.5566
ID Test ACCURACY: 0.8920
ID Test Loss: 0.5012
OOD Validation ACCURACY: 0.9313
OOD Validation Loss: 0.4367
OOD Test ACCURACY: 0.3817
OOD Test Loss: 5.1552

[0m[1;37mINFO[0m: [1mChartInfo 0.9153 0.4210 0.8920 0.3817 0.8813 0.9313[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.6 = 0.564
WIoU for r=0.6 = 0.647
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.6 = 0.795
WIoU for r=0.6 = 0.992
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.6 = 0.459
WIoU for r=0.6 = 0.355


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.906
Model XAI F1 of binarized graphs for r=0.6 =  0.5638562500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.64702125
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.639
SUFF++ for r=0.6 class 0 = 0.409 +- 0.295 (in-sample avg dev_std = 0.605)
SUFF++ for r=0.6 class 1 = 0.571 +- 0.295 (in-sample avg dev_std = 0.605)
SUFF++ for r=0.6 class 2 = 0.676 +- 0.295 (in-sample avg dev_std = 0.605)
SUFF++ for r=0.6 all KL = 0.457 +- 0.295 (in-sample avg dev_std = 0.605)
SUFF++ for r=0.6 all L1 = 0.556 +- 0.227 (in-sample avg dev_std = 0.605)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.902
Model XAI F1 of binarized graphs for r=0.6 =  0.79503625
Model XAI WIoU of binarized graphs for r=0.6 =  0.99223875
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.781
SUFF++ for r=0.6 class 0 = 0.706 +- 0.362 (in-sample avg dev_std = 0.560)
SUFF++ for r=0.6 class 1 = 0.772 +- 0.362 (in-sample avg dev_std = 0.560)
SUFF++ for r=0.6 class 2 = 0.647 +- 0.362 (in-sample avg dev_std = 0.560)
SUFF++ for r=0.6 all KL = 0.647 +- 0.362 (in-sample avg dev_std = 0.560)
SUFF++ for r=0.6 all L1 = 0.708 +- 0.207 (in-sample avg dev_std = 0.560)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.429
Model XAI F1 of binarized graphs for r=0.6 =  0.4586675
Model XAI WIoU of binarized graphs for r=0.6 =  0.35519375000000003
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.369
SUFF++ for r=0.6 class 0 = 0.801 +- 0.285 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.6 class 1 = 0.92 +- 0.285 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.6 class 2 = 0.829 +- 0.285 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.6 all KL = 0.801 +- 0.285 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.6 all L1 = 0.849 +- 0.220 (in-sample avg dev_std = 0.322)


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.906
Model XAI F1 of binarized graphs for r=0.6 =  0.5638562500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.64702125
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.454
NEC for r=0.6 class 0 = 0.618 +- 0.263 (in-sample avg dev_std = 0.648)
NEC for r=0.6 class 1 = 0.528 +- 0.263 (in-sample avg dev_std = 0.648)
NEC for r=0.6 class 2 = 0.643 +- 0.263 (in-sample avg dev_std = 0.648)
NEC for r=0.6 all KL = 0.699 +- 0.263 (in-sample avg dev_std = 0.648)
NEC for r=0.6 all L1 = 0.596 +- 0.166 (in-sample avg dev_std = 0.648)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.902
Model XAI F1 of binarized graphs for r=0.6 =  0.79503625
Model XAI WIoU of binarized graphs for r=0.6 =  0.99223875
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.534
NEC for r=0.6 class 0 = 0.505 +- 0.289 (in-sample avg dev_std = 0.654)
NEC for r=0.6 class 1 = 0.415 +- 0.289 (in-sample avg dev_std = 0.654)
NEC for r=0.6 class 2 = 0.579 +- 0.289 (in-sample avg dev_std = 0.654)
NEC for r=0.6 all KL = 0.578 +- 0.289 (in-sample avg dev_std = 0.654)
NEC for r=0.6 all L1 = 0.5 +- 0.177 (in-sample avg dev_std = 0.654)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.429
Model XAI F1 of binarized graphs for r=0.6 =  0.4586675
Model XAI WIoU of binarized graphs for r=0.6 =  0.35519375000000003
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.431
NEC for r=0.6 class 0 = 0.339 +- 0.328 (in-sample avg dev_std = 0.440)
NEC for r=0.6 class 1 = 0.089 +- 0.328 (in-sample avg dev_std = 0.440)
NEC for r=0.6 class 2 = 0.364 +- 0.328 (in-sample avg dev_std = 0.440)
NEC for r=0.6 all KL = 0.352 +- 0.328 (in-sample avg dev_std = 0.440)
NEC for r=0.6 all L1 = 0.267 +- 0.268 (in-sample avg dev_std = 0.440)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 19:29:12 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/22/2024 07:29:12 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 07:29:24 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 07:29:26 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 07:29:28 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 07:29:30 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 07:29:32 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 07:29:32 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 07:29:32 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/22/2024 07:29:32 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 07:29:32 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:29:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:29:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:29:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:29:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:29:32 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/22/2024 07:29:32 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:29:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:29:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:29:32 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/22/2024 07:29:32 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 72...
[0m[1;37mINFO[0m: [1mCheckpoint 72: 
-----------------------------------
Train ACCURACY: 0.8929
Train Loss: 0.4784
ID Validation ACCURACY: 0.8877
ID Validation Loss: 0.5235
ID Test ACCURACY: 0.9007
ID Test Loss: 0.4658
OOD Validation ACCURACY: 0.8657
OOD Validation Loss: 0.4939
OOD Test ACCURACY: 0.4123
OOD Test Loss: 4.0821

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 0...
[0m[1;37mINFO[0m: [1mCheckpoint 0: 
-----------------------------------
Train ACCURACY: 0.4968
Train Loss: 1.1639
ID Validation ACCURACY: 0.4947
ID Validation Loss: 1.2213
ID Test ACCURACY: 0.4953
ID Test Loss: 1.1575
OOD Validation ACCURACY: 0.9307
OOD Validation Loss: 0.4981
OOD Test ACCURACY: 0.3283
OOD Test Loss: 9.9458

[0m[1;37mINFO[0m: [1mChartInfo 0.9007 0.4123 0.4953 0.3283 0.4947 0.9307[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.6 = 0.581
WIoU for r=0.6 = 0.696
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.6 = 0.798
WIoU for r=0.6 = 1.000
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.6 = 0.471
WIoU for r=0.6 = 0.357


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.887
Model XAI F1 of binarized graphs for r=0.6 =  0.58119625
Model XAI WIoU of binarized graphs for r=0.6 =  0.69626375
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.664
SUFF++ for r=0.6 class 0 = 0.409 +- 0.342 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.6 class 1 = 0.71 +- 0.342 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.6 class 2 = 0.696 +- 0.342 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.6 all KL = 0.498 +- 0.342 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.6 all L1 = 0.609 +- 0.267 (in-sample avg dev_std = 0.564)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.868
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  0.9999875
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.781
SUFF++ for r=0.6 class 0 = 0.692 +- 0.406 (in-sample avg dev_std = 0.633)
SUFF++ for r=0.6 class 1 = 0.744 +- 0.406 (in-sample avg dev_std = 0.633)
SUFF++ for r=0.6 class 2 = 0.656 +- 0.406 (in-sample avg dev_std = 0.633)
SUFF++ for r=0.6 all KL = 0.599 +- 0.406 (in-sample avg dev_std = 0.633)
SUFF++ for r=0.6 all L1 = 0.697 +- 0.252 (in-sample avg dev_std = 0.633)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.416
Model XAI F1 of binarized graphs for r=0.6 =  0.47126125
Model XAI WIoU of binarized graphs for r=0.6 =  0.357025
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.379
SUFF++ for r=0.6 class 0 = 0.804 +- 0.292 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.6 class 1 = 0.902 +- 0.292 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.6 class 2 = 0.776 +- 0.292 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.6 all KL = 0.768 +- 0.292 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.6 all L1 = 0.826 +- 0.223 (in-sample avg dev_std = 0.372)


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.887
Model XAI F1 of binarized graphs for r=0.6 =  0.58119625
Model XAI WIoU of binarized graphs for r=0.6 =  0.69626375
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.418
NEC for r=0.6 class 0 = 0.649 +- 0.235 (in-sample avg dev_std = 0.697)
NEC for r=0.6 class 1 = 0.586 +- 0.235 (in-sample avg dev_std = 0.697)
NEC for r=0.6 class 2 = 0.679 +- 0.235 (in-sample avg dev_std = 0.697)
NEC for r=0.6 all KL = 0.805 +- 0.235 (in-sample avg dev_std = 0.697)
NEC for r=0.6 all L1 = 0.638 +- 0.161 (in-sample avg dev_std = 0.697)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.868
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  0.9999875
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.505
NEC for r=0.6 class 0 = 0.598 +- 0.279 (in-sample avg dev_std = 0.774)
NEC for r=0.6 class 1 = 0.477 +- 0.279 (in-sample avg dev_std = 0.774)
NEC for r=0.6 class 2 = 0.561 +- 0.279 (in-sample avg dev_std = 0.774)
NEC for r=0.6 all KL = 0.704 +- 0.279 (in-sample avg dev_std = 0.774)
NEC for r=0.6 all L1 = 0.546 +- 0.181 (in-sample avg dev_std = 0.774)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.416
Model XAI F1 of binarized graphs for r=0.6 =  0.47126125
Model XAI WIoU of binarized graphs for r=0.6 =  0.357025
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.457
NEC for r=0.6 class 0 = 0.364 +- 0.346 (in-sample avg dev_std = 0.472)
NEC for r=0.6 class 1 = 0.084 +- 0.346 (in-sample avg dev_std = 0.472)
NEC for r=0.6 class 2 = 0.396 +- 0.346 (in-sample avg dev_std = 0.472)
NEC for r=0.6 all KL = 0.393 +- 0.346 (in-sample avg dev_std = 0.472)
NEC for r=0.6 all L1 = 0.285 +- 0.271 (in-sample avg dev_std = 0.472)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 19:30:30 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/22/2024 07:30:30 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 07:30:44 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 07:30:46 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 07:30:48 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 07:30:50 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 07:30:52 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 07:30:52 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 07:30:52 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/22/2024 07:30:52 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 07:30:52 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:30:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:30:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:30:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:30:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:30:52 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/22/2024 07:30:52 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:30:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:30:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:30:52 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/22/2024 07:30:52 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 16...
[0m[1;37mINFO[0m: [1mCheckpoint 16: 
-----------------------------------
Train ACCURACY: 0.8887
Train Loss: 0.4924
ID Validation ACCURACY: 0.8847
ID Validation Loss: 0.5324
ID Test ACCURACY: 0.8977
ID Test Loss: 0.4691
OOD Validation ACCURACY: 0.7167
OOD Validation Loss: 1.3877
OOD Test ACCURACY: 0.3873
OOD Test Loss: 3.5672

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 45...
[0m[1;37mINFO[0m: [1mCheckpoint 45: 
-----------------------------------
Train ACCURACY: 0.8089
Train Loss: 0.6907
ID Validation ACCURACY: 0.8030
ID Validation Loss: 0.7150
ID Test ACCURACY: 0.8183
ID Test Loss: 0.6665
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.4273
OOD Test ACCURACY: 0.4333
OOD Test Loss: 4.3285

[0m[1;37mINFO[0m: [1mChartInfo 0.8977 0.3873 0.8183 0.4333 0.8030 0.9317[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.6 = 0.584
WIoU for r=0.6 = 0.660
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.6 = 0.798
WIoU for r=0.6 = 1.000
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.6 = 0.503
WIoU for r=0.6 = 0.393


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.887
Model XAI F1 of binarized graphs for r=0.6 =  0.5835112499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.6602475
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.649
SUFF++ for r=0.6 class 0 = 0.419 +- 0.323 (in-sample avg dev_std = 0.556)
SUFF++ for r=0.6 class 1 = 0.742 +- 0.323 (in-sample avg dev_std = 0.556)
SUFF++ for r=0.6 class 2 = 0.641 +- 0.323 (in-sample avg dev_std = 0.556)
SUFF++ for r=0.6 all KL = 0.512 +- 0.323 (in-sample avg dev_std = 0.556)
SUFF++ for r=0.6 all L1 = 0.604 +- 0.253 (in-sample avg dev_std = 0.556)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.731
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  0.9997787500000002
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.719
SUFF++ for r=0.6 class 0 = 0.726 +- 0.425 (in-sample avg dev_std = 0.686)
SUFF++ for r=0.6 class 1 = 0.536 +- 0.425 (in-sample avg dev_std = 0.686)
SUFF++ for r=0.6 class 2 = 0.697 +- 0.425 (in-sample avg dev_std = 0.686)
SUFF++ for r=0.6 all KL = 0.455 +- 0.425 (in-sample avg dev_std = 0.686)
SUFF++ for r=0.6 all L1 = 0.654 +- 0.253 (in-sample avg dev_std = 0.686)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.396
Model XAI F1 of binarized graphs for r=0.6 =  0.50348375
Model XAI WIoU of binarized graphs for r=0.6 =  0.39348250000000007
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.397
SUFF++ for r=0.6 class 0 = 0.842 +- 0.277 (in-sample avg dev_std = 0.389)
SUFF++ for r=0.6 class 1 = 0.938 +- 0.277 (in-sample avg dev_std = 0.389)
SUFF++ for r=0.6 class 2 = 0.736 +- 0.277 (in-sample avg dev_std = 0.389)
SUFF++ for r=0.6 all KL = 0.754 +- 0.277 (in-sample avg dev_std = 0.389)
SUFF++ for r=0.6 all L1 = 0.837 +- 0.194 (in-sample avg dev_std = 0.389)


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.887
Model XAI F1 of binarized graphs for r=0.6 =  0.5835112499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.6602475
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.425
NEC for r=0.6 class 0 = 0.635 +- 0.244 (in-sample avg dev_std = 0.677)
NEC for r=0.6 class 1 = 0.543 +- 0.244 (in-sample avg dev_std = 0.677)
NEC for r=0.6 class 2 = 0.678 +- 0.244 (in-sample avg dev_std = 0.677)
NEC for r=0.6 all KL = 0.749 +- 0.244 (in-sample avg dev_std = 0.677)
NEC for r=0.6 all L1 = 0.619 +- 0.171 (in-sample avg dev_std = 0.677)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.731
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  0.9997787500000002
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.422
NEC for r=0.6 class 0 = 0.457 +- 0.374 (in-sample avg dev_std = 0.693)
NEC for r=0.6 class 1 = 0.299 +- 0.374 (in-sample avg dev_std = 0.693)
NEC for r=0.6 class 2 = 0.581 +- 0.374 (in-sample avg dev_std = 0.693)
NEC for r=0.6 all KL = 0.594 +- 0.374 (in-sample avg dev_std = 0.693)
NEC for r=0.6 all L1 = 0.446 +- 0.256 (in-sample avg dev_std = 0.693)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.396
Model XAI F1 of binarized graphs for r=0.6 =  0.50348375
Model XAI WIoU of binarized graphs for r=0.6 =  0.39348250000000007
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.448
NEC for r=0.6 class 0 = 0.238 +- 0.344 (in-sample avg dev_std = 0.476)
NEC for r=0.6 class 1 = 0.08 +- 0.344 (in-sample avg dev_std = 0.476)
NEC for r=0.6 class 2 = 0.471 +- 0.344 (in-sample avg dev_std = 0.476)
NEC for r=0.6 all KL = 0.357 +- 0.344 (in-sample avg dev_std = 0.476)
NEC for r=0.6 all L1 = 0.267 +- 0.272 (in-sample avg dev_std = 0.476)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.48], 'all_L1': [0.528]}), defaultdict(<class 'list'>, {'all_KL': [0.468], 'all_L1': [0.566]}), defaultdict(<class 'list'>, {'all_KL': [0.457], 'all_L1': [0.556]}), defaultdict(<class 'list'>, {'all_KL': [0.498], 'all_L1': [0.609]}), defaultdict(<class 'list'>, {'all_KL': [0.512], 'all_L1': [0.604]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.671], 'all_L1': [0.602]}), defaultdict(<class 'list'>, {'all_KL': [0.716], 'all_L1': [0.602]}), defaultdict(<class 'list'>, {'all_KL': [0.699], 'all_L1': [0.596]}), defaultdict(<class 'list'>, {'all_KL': [0.805], 'all_L1': [0.638]}), defaultdict(<class 'list'>, {'all_KL': [0.749], 'all_L1': [0.619]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.507], 'all_L1': [0.68]}), defaultdict(<class 'list'>, {'all_KL': [0.496], 'all_L1': [0.623]}), defaultdict(<class 'list'>, {'all_KL': [0.647], 'all_L1': [0.708]}), defaultdict(<class 'list'>, {'all_KL': [0.599], 'all_L1': [0.697]}), defaultdict(<class 'list'>, {'all_KL': [0.455], 'all_L1': [0.654]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.464], 'all_L1': [0.396]}), defaultdict(<class 'list'>, {'all_KL': [0.487], 'all_L1': [0.413]}), defaultdict(<class 'list'>, {'all_KL': [0.578], 'all_L1': [0.5]}), defaultdict(<class 'list'>, {'all_KL': [0.704], 'all_L1': [0.546]}), defaultdict(<class 'list'>, {'all_KL': [0.594], 'all_L1': [0.446]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.674], 'all_L1': [0.754]}), defaultdict(<class 'list'>, {'all_KL': [0.753], 'all_L1': [0.809]}), defaultdict(<class 'list'>, {'all_KL': [0.801], 'all_L1': [0.849]}), defaultdict(<class 'list'>, {'all_KL': [0.768], 'all_L1': [0.826]}), defaultdict(<class 'list'>, {'all_KL': [0.754], 'all_L1': [0.837]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.32], 'all_L1': [0.273]}), defaultdict(<class 'list'>, {'all_KL': [0.37], 'all_L1': [0.291]}), defaultdict(<class 'list'>, {'all_KL': [0.352], 'all_L1': [0.267]}), defaultdict(<class 'list'>, {'all_KL': [0.393], 'all_L1': [0.285]}), defaultdict(<class 'list'>, {'all_KL': [0.357], 'all_L1': [0.267]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.573 +- 0.030
suff++ class all_KL  =  0.483 +- 0.020
suff++_acc_int  =  0.644 +- 0.014
nec class all_L1  =  0.611 +- 0.015
nec class all_KL  =  0.728 +- 0.046
nec_acc_int  =  0.440 +- 0.015

Eval split val
suff++ class all_L1  =  0.672 +- 0.031
suff++ class all_KL  =  0.541 +- 0.071
suff++_acc_int  =  0.727 +- 0.046
nec class all_L1  =  0.460 +- 0.056
nec class all_KL  =  0.565 +- 0.086
nec_acc_int  =  0.473 +- 0.049

Eval split test
suff++ class all_L1  =  0.815 +- 0.033
suff++ class all_KL  =  0.750 +- 0.042
suff++_acc_int  =  0.389 +- 0.013
nec class all_L1  =  0.277 +- 0.010
nec class all_KL  =  0.358 +- 0.024
nec_acc_int  =  0.441 +- 0.014


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.592 +- 0.022
Faith. Armon (L1)= 		  =  0.591 +- 0.023
Faith. GMean (L1)= 	  =  0.592 +- 0.022
Faith. Aritm (KL)= 		  =  0.606 +- 0.030
Faith. Armon (KL)= 		  =  0.580 +- 0.026
Faith. GMean (KL)= 	  =  0.593 +- 0.028

Eval split val
Faith. Aritm (L1)= 		  =  0.566 +- 0.040
Faith. Armon (L1)= 		  =  0.545 +- 0.046
Faith. GMean (L1)= 	  =  0.556 +- 0.043
Faith. Aritm (KL)= 		  =  0.553 +- 0.067
Faith. Armon (KL)= 		  =  0.550 +- 0.066
Faith. GMean (KL)= 	  =  0.551 +- 0.067

Eval split test
Faith. Aritm (L1)= 		  =  0.546 +- 0.016
Faith. Armon (L1)= 		  =  0.413 +- 0.011
Faith. GMean (L1)= 	  =  0.475 +- 0.012
Faith. Aritm (KL)= 		  =  0.554 +- 0.030
Faith. Armon (KL)= 		  =  0.485 +- 0.028
Faith. GMean (KL)= 	  =  0.518 +- 0.029
Computed for split load_split = id



Completed in  0:06:36.467669  for CIGAGIN GOODMotif/basis



DONE CIGA GOODMotif/basis

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 19:32:04 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/22/2024 07:32:04 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 07:32:16 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 07:32:18 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 07:32:20 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 07:32:22 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 07:32:24 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 07:32:24 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 07:32:24 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:32:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:32:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:32:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:32:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:32:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:32:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:32:24 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 97...
[0m[1;37mINFO[0m: [1mCheckpoint 97: 
-----------------------------------
Train ACCURACY: 0.9314
Train Loss: 0.3178
ID Validation ACCURACY: 0.9303
ID Validation Loss: 0.3259
ID Test ACCURACY: 0.9280
ID Test Loss: 0.3250
OOD Validation ACCURACY: 0.8527
OOD Validation Loss: 0.5111
OOD Test ACCURACY: 0.6287
OOD Test Loss: 1.1683

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 83...
[0m[1;37mINFO[0m: [1mCheckpoint 83: 
-----------------------------------
Train ACCURACY: 0.9295
Train Loss: 0.3278
ID Validation ACCURACY: 0.9277
ID Validation Loss: 0.3391
ID Test ACCURACY: 0.9287
ID Test Loss: 0.3296
OOD Validation ACCURACY: 0.9320
OOD Validation Loss: 0.3661
OOD Test ACCURACY: 0.5353
OOD Test Loss: 1.3356

[0m[1;37mINFO[0m: [1mChartInfo 0.9280 0.6287 0.9287 0.5353 0.9277 0.9320[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.692
WIoU for r=0.3 = 0.567
F1 for r=0.6 = 0.583
WIoU for r=0.6 = 0.463
F1 for r=0.9 = 0.469
WIoU for r=0.9 = 0.347
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.326
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.869
WIoU for r=0.3 = 0.780
F1 for r=0.6 = 0.798
WIoU for r=0.6 = 0.710
F1 for r=0.9 = 0.618
WIoU for r=0.9 = 0.499
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 0.460
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.353
WIoU for r=0.3 = 0.253
F1 for r=0.6 = 0.626
WIoU for r=0.6 = 0.484
F1 for r=0.9 = 0.592
WIoU for r=0.9 = 0.434
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.401


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.539
Model XAI F1 of binarized graphs for r=0.3 =  0.69200125
Model XAI WIoU of binarized graphs for r=0.3 =  0.5666525
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.425
SUFF++ for r=0.3 class 0 = 0.412 +- 0.281 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.3 class 1 = 0.535 +- 0.281 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.3 class 2 = 0.587 +- 0.281 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.3 all KL = 0.478 +- 0.281 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.3 all L1 = 0.514 +- 0.199 (in-sample avg dev_std = 0.494)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.681
Model XAI F1 of binarized graphs for r=0.6 =  0.58292125
Model XAI WIoU of binarized graphs for r=0.6 =  0.46298
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.605
SUFF++ for r=0.6 class 0 = 0.419 +- 0.290 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.6 class 1 = 0.548 +- 0.290 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.6 class 2 = 0.653 +- 0.290 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.6 all KL = 0.519 +- 0.290 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.6 all L1 = 0.543 +- 0.210 (in-sample avg dev_std = 0.508)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.904
Model XAI F1 of binarized graphs for r=0.9 =  0.4685975
Model XAI WIoU of binarized graphs for r=0.9 =  0.3465525000000001
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.838
SUFF++ for r=0.9 class 0 = 0.668 +- 0.167 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 class 1 = 0.798 +- 0.167 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 class 2 = 0.858 +- 0.167 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 all KL = 0.846 +- 0.167 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 all L1 = 0.777 +- 0.166 (in-sample avg dev_std = 0.256)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.441
Model XAI F1 of binarized graphs for r=0.3 =  0.86858875
Model XAI WIoU of binarized graphs for r=0.3 =  0.78040875
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.375
SUFF++ for r=0.3 class 0 = 0.469 +- 0.320 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.3 class 1 = 0.641 +- 0.320 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.3 class 2 = 0.561 +- 0.320 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.3 all KL = 0.494 +- 0.320 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.3 all L1 = 0.557 +- 0.200 (in-sample avg dev_std = 0.586)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.65
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  0.7103800000000001
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.74
SUFF++ for r=0.6 class 0 = 0.621 +- 0.322 (in-sample avg dev_std = 0.546)
SUFF++ for r=0.6 class 1 = 0.579 +- 0.322 (in-sample avg dev_std = 0.546)
SUFF++ for r=0.6 class 2 = 0.757 +- 0.322 (in-sample avg dev_std = 0.546)
SUFF++ for r=0.6 all KL = 0.589 +- 0.322 (in-sample avg dev_std = 0.546)
SUFF++ for r=0.6 all L1 = 0.652 +- 0.198 (in-sample avg dev_std = 0.546)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.877
Model XAI F1 of binarized graphs for r=0.9 =  0.61811125
Model XAI WIoU of binarized graphs for r=0.9 =  0.49911875
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.873
SUFF++ for r=0.9 class 0 = 0.796 +- 0.118 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.9 class 1 = 0.828 +- 0.118 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.9 class 2 = 0.946 +- 0.118 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.9 all KL = 0.937 +- 0.118 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.9 all L1 = 0.857 +- 0.128 (in-sample avg dev_std = 0.204)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.34
Model XAI F1 of binarized graphs for r=0.3 =  0.35290625000000003
Model XAI WIoU of binarized graphs for r=0.3 =  0.25268625
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.352
SUFF++ for r=0.3 class 0 = 0.609 +- 0.229 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.3 class 1 = 0.672 +- 0.229 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.3 class 2 = 0.635 +- 0.229 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.3 all KL = 0.652 +- 0.229 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.3 all L1 = 0.638 +- 0.160 (in-sample avg dev_std = 0.407)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.461
Model XAI F1 of binarized graphs for r=0.6 =  0.62602
Model XAI WIoU of binarized graphs for r=0.6 =  0.48355125
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.511
SUFF++ for r=0.6 class 0 = 0.457 +- 0.256 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.6 class 1 = 0.553 +- 0.256 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.6 class 2 = 0.566 +- 0.256 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.6 all KL = 0.514 +- 0.256 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.6 all L1 = 0.525 +- 0.192 (in-sample avg dev_std = 0.532)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.699
Model XAI F1 of binarized graphs for r=0.9 =  0.59177625
Model XAI WIoU of binarized graphs for r=0.9 =  0.43375749999999996
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.676
SUFF++ for r=0.9 class 0 = 0.665 +- 0.172 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 1 = 0.887 +- 0.172 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 2 = 0.739 +- 0.172 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 all KL = 0.85 +- 0.172 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 all L1 = 0.762 +- 0.189 (in-sample avg dev_std = 0.303)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.541
Model XAI F1 of binarized graphs for r=0.3 =  0.69200125
Model XAI WIoU of binarized graphs for r=0.3 =  0.5666525
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.342
NEC for r=0.3 class 0 = 0.647 +- 0.306 (in-sample avg dev_std = 0.427)
NEC for r=0.3 class 1 = 0.537 +- 0.306 (in-sample avg dev_std = 0.427)
NEC for r=0.3 class 2 = 0.499 +- 0.306 (in-sample avg dev_std = 0.427)
NEC for r=0.3 all KL = 0.597 +- 0.306 (in-sample avg dev_std = 0.427)
NEC for r=0.3 all L1 = 0.559 +- 0.209 (in-sample avg dev_std = 0.427)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.681
Model XAI F1 of binarized graphs for r=0.6 =  0.58292125
Model XAI WIoU of binarized graphs for r=0.6 =  0.46298
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.393
NEC for r=0.6 class 0 = 0.582 +- 0.259 (in-sample avg dev_std = 0.511)
NEC for r=0.6 class 1 = 0.591 +- 0.259 (in-sample avg dev_std = 0.511)
NEC for r=0.6 class 2 = 0.598 +- 0.259 (in-sample avg dev_std = 0.511)
NEC for r=0.6 all KL = 0.651 +- 0.259 (in-sample avg dev_std = 0.511)
NEC for r=0.6 all L1 = 0.591 +- 0.167 (in-sample avg dev_std = 0.511)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.904
Model XAI F1 of binarized graphs for r=0.9 =  0.4685975
Model XAI WIoU of binarized graphs for r=0.9 =  0.3465525000000001
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.488
NEC for r=0.9 class 0 = 0.624 +- 0.219 (in-sample avg dev_std = 0.613)
NEC for r=0.9 class 1 = 0.554 +- 0.219 (in-sample avg dev_std = 0.613)
NEC for r=0.9 class 2 = 0.548 +- 0.219 (in-sample avg dev_std = 0.613)
NEC for r=0.9 all KL = 0.648 +- 0.219 (in-sample avg dev_std = 0.613)
NEC for r=0.9 all L1 = 0.574 +- 0.147 (in-sample avg dev_std = 0.613)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.929
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.32596125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.515
NEC for r=1.0 class 0 = 0.563 +- 0.243 (in-sample avg dev_std = 0.649)
NEC for r=1.0 class 1 = 0.517 +- 0.243 (in-sample avg dev_std = 0.649)
NEC for r=1.0 class 2 = 0.57 +- 0.243 (in-sample avg dev_std = 0.649)
NEC for r=1.0 all KL = 0.622 +- 0.243 (in-sample avg dev_std = 0.649)
NEC for r=1.0 all L1 = 0.55 +- 0.170 (in-sample avg dev_std = 0.649)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.442
Model XAI F1 of binarized graphs for r=0.3 =  0.86858875
Model XAI WIoU of binarized graphs for r=0.3 =  0.78040875
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.223
NEC for r=0.3 class 0 = 0.676 +- 0.317 (in-sample avg dev_std = 0.487)
NEC for r=0.3 class 1 = 0.478 +- 0.317 (in-sample avg dev_std = 0.487)
NEC for r=0.3 class 2 = 0.615 +- 0.317 (in-sample avg dev_std = 0.487)
NEC for r=0.3 all KL = 0.644 +- 0.317 (in-sample avg dev_std = 0.487)
NEC for r=0.3 all L1 = 0.59 +- 0.211 (in-sample avg dev_std = 0.487)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.65
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  0.7103800000000001
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.436
NEC for r=0.6 class 0 = 0.481 +- 0.319 (in-sample avg dev_std = 0.450)
NEC for r=0.6 class 1 = 0.353 +- 0.319 (in-sample avg dev_std = 0.450)
NEC for r=0.6 class 2 = 0.301 +- 0.319 (in-sample avg dev_std = 0.450)
NEC for r=0.6 all KL = 0.386 +- 0.319 (in-sample avg dev_std = 0.450)
NEC for r=0.6 all L1 = 0.378 +- 0.256 (in-sample avg dev_std = 0.450)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.877
Model XAI F1 of binarized graphs for r=0.9 =  0.61811125
Model XAI WIoU of binarized graphs for r=0.9 =  0.49911875
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.579
NEC for r=0.9 class 0 = 0.425 +- 0.225 (in-sample avg dev_std = 0.557)
NEC for r=0.9 class 1 = 0.351 +- 0.225 (in-sample avg dev_std = 0.557)
NEC for r=0.9 class 2 = 0.369 +- 0.225 (in-sample avg dev_std = 0.557)
NEC for r=0.9 all KL = 0.327 +- 0.225 (in-sample avg dev_std = 0.557)
NEC for r=0.9 all L1 = 0.382 +- 0.162 (in-sample avg dev_std = 0.557)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.87
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  0.45974875000000004
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.623
NEC for r=1.0 class 0 = 0.427 +- 0.226 (in-sample avg dev_std = 0.560)
NEC for r=1.0 class 1 = 0.334 +- 0.226 (in-sample avg dev_std = 0.560)
NEC for r=1.0 class 2 = 0.363 +- 0.226 (in-sample avg dev_std = 0.560)
NEC for r=1.0 all KL = 0.331 +- 0.226 (in-sample avg dev_std = 0.560)
NEC for r=1.0 all L1 = 0.375 +- 0.160 (in-sample avg dev_std = 0.560)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.341
Model XAI F1 of binarized graphs for r=0.3 =  0.35290625000000003
Model XAI WIoU of binarized graphs for r=0.3 =  0.25268625
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.337
NEC for r=0.3 class 0 = 0.518 +- 0.287 (in-sample avg dev_std = 0.405)
NEC for r=0.3 class 1 = 0.306 +- 0.287 (in-sample avg dev_std = 0.405)
NEC for r=0.3 class 2 = 0.434 +- 0.287 (in-sample avg dev_std = 0.405)
NEC for r=0.3 all KL = 0.415 +- 0.287 (in-sample avg dev_std = 0.405)
NEC for r=0.3 all L1 = 0.421 +- 0.205 (in-sample avg dev_std = 0.405)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.459
Model XAI F1 of binarized graphs for r=0.6 =  0.62602
Model XAI WIoU of binarized graphs for r=0.6 =  0.48355125
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.447
NEC for r=0.6 class 0 = 0.643 +- 0.248 (in-sample avg dev_std = 0.552)
NEC for r=0.6 class 1 = 0.586 +- 0.248 (in-sample avg dev_std = 0.552)
NEC for r=0.6 class 2 = 0.621 +- 0.248 (in-sample avg dev_std = 0.552)
NEC for r=0.6 all KL = 0.661 +- 0.248 (in-sample avg dev_std = 0.552)
NEC for r=0.6 all L1 = 0.617 +- 0.137 (in-sample avg dev_std = 0.552)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.699
Model XAI F1 of binarized graphs for r=0.9 =  0.59177625
Model XAI WIoU of binarized graphs for r=0.9 =  0.43375749999999996
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.533
NEC for r=0.9 class 0 = 0.538 +- 0.214 (in-sample avg dev_std = 0.546)
NEC for r=0.9 class 1 = 0.429 +- 0.214 (in-sample avg dev_std = 0.546)
NEC for r=0.9 class 2 = 0.529 +- 0.214 (in-sample avg dev_std = 0.546)
NEC for r=0.9 all KL = 0.481 +- 0.214 (in-sample avg dev_std = 0.546)
NEC for r=0.9 all L1 = 0.5 +- 0.137 (in-sample avg dev_std = 0.546)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.629
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.401135
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.562
NEC for r=1.0 class 0 = 0.492 +- 0.210 (in-sample avg dev_std = 0.509)
NEC for r=1.0 class 1 = 0.309 +- 0.210 (in-sample avg dev_std = 0.509)
NEC for r=1.0 class 2 = 0.512 +- 0.210 (in-sample avg dev_std = 0.509)
NEC for r=1.0 all KL = 0.432 +- 0.210 (in-sample avg dev_std = 0.509)
NEC for r=1.0 all L1 = 0.44 +- 0.173 (in-sample avg dev_std = 0.509)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 19:35:41 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/22/2024 07:35:41 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 07:35:53 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 07:35:55 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 07:35:57 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 07:35:58 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 07:36:00 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 07:36:00 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 07:36:00 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:36:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:36:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:36:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:36:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:36:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:36:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:36:00 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 141...
[0m[1;37mINFO[0m: [1mCheckpoint 141: 
-----------------------------------
Train ACCURACY: 0.9309
Train Loss: 0.3119
ID Validation ACCURACY: 0.9300
ID Validation Loss: 0.3271
ID Test ACCURACY: 0.9277
ID Test Loss: 0.3181
OOD Validation ACCURACY: 0.7947
OOD Validation Loss: 0.6208
OOD Test ACCURACY: 0.5837
OOD Test Loss: 1.2346

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 90...
[0m[1;37mINFO[0m: [1mCheckpoint 90: 
-----------------------------------
Train ACCURACY: 0.9266
Train Loss: 0.3279
ID Validation ACCURACY: 0.9250
ID Validation Loss: 0.3353
ID Test ACCURACY: 0.9243
ID Test Loss: 0.3312
OOD Validation ACCURACY: 0.9310
OOD Validation Loss: 0.3368
OOD Test ACCURACY: 0.5587
OOD Test Loss: 1.1490

[0m[1;37mINFO[0m: [1mChartInfo 0.9277 0.5837 0.9243 0.5587 0.9250 0.9310[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.713
WIoU for r=0.3 = 0.588
F1 for r=0.6 = 0.607
WIoU for r=0.6 = 0.491
F1 for r=0.9 = 0.474
WIoU for r=0.9 = 0.354
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.329
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.869
WIoU for r=0.3 = 0.781
F1 for r=0.6 = 0.798
WIoU for r=0.6 = 0.697
F1 for r=0.9 = 0.618
WIoU for r=0.9 = 0.484
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 0.445
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.361
WIoU for r=0.3 = 0.265
F1 for r=0.6 = 0.627
WIoU for r=0.6 = 0.491
F1 for r=0.9 = 0.590
WIoU for r=0.9 = 0.432
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.402


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.498
Model XAI F1 of binarized graphs for r=0.3 =  0.71258375
Model XAI WIoU of binarized graphs for r=0.3 =  0.5879375
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.461
SUFF++ for r=0.3 class 0 = 0.441 +- 0.256 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 class 1 = 0.54 +- 0.256 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 class 2 = 0.561 +- 0.256 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 all KL = 0.544 +- 0.256 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 all L1 = 0.516 +- 0.152 (in-sample avg dev_std = 0.475)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.683
Model XAI F1 of binarized graphs for r=0.6 =  0.60747375
Model XAI WIoU of binarized graphs for r=0.6 =  0.49116125000000005
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.626
SUFF++ for r=0.6 class 0 = 0.454 +- 0.275 (in-sample avg dev_std = 0.440)
SUFF++ for r=0.6 class 1 = 0.677 +- 0.275 (in-sample avg dev_std = 0.440)
SUFF++ for r=0.6 class 2 = 0.666 +- 0.275 (in-sample avg dev_std = 0.440)
SUFF++ for r=0.6 all KL = 0.62 +- 0.275 (in-sample avg dev_std = 0.440)
SUFF++ for r=0.6 all L1 = 0.602 +- 0.204 (in-sample avg dev_std = 0.440)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.894
Model XAI F1 of binarized graphs for r=0.9 =  0.47404125
Model XAI WIoU of binarized graphs for r=0.9 =  0.35373875
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.85
SUFF++ for r=0.9 class 0 = 0.65 +- 0.180 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.9 class 1 = 0.829 +- 0.180 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.9 class 2 = 0.872 +- 0.180 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.9 all KL = 0.853 +- 0.180 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.9 all L1 = 0.787 +- 0.170 (in-sample avg dev_std = 0.258)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.439
Model XAI F1 of binarized graphs for r=0.3 =  0.86858875
Model XAI WIoU of binarized graphs for r=0.3 =  0.78059125
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.414
SUFF++ for r=0.3 class 0 = 0.534 +- 0.294 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.3 class 1 = 0.74 +- 0.294 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.3 class 2 = 0.561 +- 0.294 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.3 all KL = 0.551 +- 0.294 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.3 all L1 = 0.611 +- 0.196 (in-sample avg dev_std = 0.532)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.736
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  0.6969562499999999
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.798
SUFF++ for r=0.6 class 0 = 0.647 +- 0.280 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.6 class 1 = 0.712 +- 0.280 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.6 class 2 = 0.939 +- 0.280 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.6 all KL = 0.787 +- 0.280 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.6 all L1 = 0.766 +- 0.224 (in-sample avg dev_std = 0.383)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.825
Model XAI F1 of binarized graphs for r=0.9 =  0.61811125
Model XAI WIoU of binarized graphs for r=0.9 =  0.48420875
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.866
SUFF++ for r=0.9 class 0 = 0.855 +- 0.076 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.9 class 1 = 0.942 +- 0.076 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.9 class 2 = 0.852 +- 0.076 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.9 all KL = 0.952 +- 0.076 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.9 all L1 = 0.882 +- 0.119 (in-sample avg dev_std = 0.174)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.278
Model XAI F1 of binarized graphs for r=0.3 =  0.36146124999999996
Model XAI WIoU of binarized graphs for r=0.3 =  0.26462250000000004
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.308
SUFF++ for r=0.3 class 0 = 0.52 +- 0.181 (in-sample avg dev_std = 0.454)
SUFF++ for r=0.3 class 1 = 0.519 +- 0.181 (in-sample avg dev_std = 0.454)
SUFF++ for r=0.3 class 2 = 0.532 +- 0.181 (in-sample avg dev_std = 0.454)
SUFF++ for r=0.3 all KL = 0.619 +- 0.181 (in-sample avg dev_std = 0.454)
SUFF++ for r=0.3 all L1 = 0.524 +- 0.113 (in-sample avg dev_std = 0.454)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.634
Model XAI F1 of binarized graphs for r=0.6 =  0.62741
Model XAI WIoU of binarized graphs for r=0.6 =  0.49064875
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.608
SUFF++ for r=0.6 class 0 = 0.685 +- 0.227 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.6 class 1 = 0.772 +- 0.227 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.6 class 2 = 0.772 +- 0.227 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.6 all KL = 0.769 +- 0.227 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.6 all L1 = 0.742 +- 0.184 (in-sample avg dev_std = 0.390)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.663
Model XAI F1 of binarized graphs for r=0.9 =  0.5903499999999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.43229999999999996
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.644
SUFF++ for r=0.9 class 0 = 0.74 +- 0.106 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.9 class 1 = 0.96 +- 0.106 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.9 class 2 = 0.786 +- 0.106 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.9 all KL = 0.92 +- 0.106 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.9 all L1 = 0.826 +- 0.160 (in-sample avg dev_std = 0.184)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.496
Model XAI F1 of binarized graphs for r=0.3 =  0.71258375
Model XAI WIoU of binarized graphs for r=0.3 =  0.5879375
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.334
NEC for r=0.3 class 0 = 0.613 +- 0.266 (in-sample avg dev_std = 0.412)
NEC for r=0.3 class 1 = 0.519 +- 0.266 (in-sample avg dev_std = 0.412)
NEC for r=0.3 class 2 = 0.593 +- 0.266 (in-sample avg dev_std = 0.412)
NEC for r=0.3 all KL = 0.549 +- 0.266 (in-sample avg dev_std = 0.412)
NEC for r=0.3 all L1 = 0.575 +- 0.139 (in-sample avg dev_std = 0.412)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.683
Model XAI F1 of binarized graphs for r=0.6 =  0.60747375
Model XAI WIoU of binarized graphs for r=0.6 =  0.49116125000000005
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.385
NEC for r=0.6 class 0 = 0.628 +- 0.268 (in-sample avg dev_std = 0.488)
NEC for r=0.6 class 1 = 0.541 +- 0.268 (in-sample avg dev_std = 0.488)
NEC for r=0.6 class 2 = 0.607 +- 0.268 (in-sample avg dev_std = 0.488)
NEC for r=0.6 all KL = 0.623 +- 0.268 (in-sample avg dev_std = 0.488)
NEC for r=0.6 all L1 = 0.592 +- 0.156 (in-sample avg dev_std = 0.488)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.895
Model XAI F1 of binarized graphs for r=0.9 =  0.47404125
Model XAI WIoU of binarized graphs for r=0.9 =  0.35373875
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.503
NEC for r=0.9 class 0 = 0.627 +- 0.235 (in-sample avg dev_std = 0.566)
NEC for r=0.9 class 1 = 0.489 +- 0.235 (in-sample avg dev_std = 0.566)
NEC for r=0.9 class 2 = 0.573 +- 0.235 (in-sample avg dev_std = 0.566)
NEC for r=0.9 all KL = 0.604 +- 0.235 (in-sample avg dev_std = 0.566)
NEC for r=0.9 all L1 = 0.562 +- 0.160 (in-sample avg dev_std = 0.566)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.929
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.329255
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.559
NEC for r=1.0 class 0 = 0.565 +- 0.245 (in-sample avg dev_std = 0.593)
NEC for r=1.0 class 1 = 0.422 +- 0.245 (in-sample avg dev_std = 0.593)
NEC for r=1.0 class 2 = 0.55 +- 0.245 (in-sample avg dev_std = 0.593)
NEC for r=1.0 all KL = 0.54 +- 0.245 (in-sample avg dev_std = 0.593)
NEC for r=1.0 all L1 = 0.512 +- 0.175 (in-sample avg dev_std = 0.593)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.439
Model XAI F1 of binarized graphs for r=0.3 =  0.86858875
Model XAI WIoU of binarized graphs for r=0.3 =  0.78059125
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.209
NEC for r=0.3 class 0 = 0.676 +- 0.302 (in-sample avg dev_std = 0.389)
NEC for r=0.3 class 1 = 0.575 +- 0.302 (in-sample avg dev_std = 0.389)
NEC for r=0.3 class 2 = 0.552 +- 0.302 (in-sample avg dev_std = 0.389)
NEC for r=0.3 all KL = 0.662 +- 0.302 (in-sample avg dev_std = 0.389)
NEC for r=0.3 all L1 = 0.602 +- 0.204 (in-sample avg dev_std = 0.389)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.736
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  0.6969562499999999
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.437
NEC for r=0.6 class 0 = 0.501 +- 0.322 (in-sample avg dev_std = 0.499)
NEC for r=0.6 class 1 = 0.384 +- 0.322 (in-sample avg dev_std = 0.499)
NEC for r=0.6 class 2 = 0.38 +- 0.322 (in-sample avg dev_std = 0.499)
NEC for r=0.6 all KL = 0.448 +- 0.322 (in-sample avg dev_std = 0.499)
NEC for r=0.6 all L1 = 0.422 +- 0.248 (in-sample avg dev_std = 0.499)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.825
Model XAI F1 of binarized graphs for r=0.9 =  0.61811125
Model XAI WIoU of binarized graphs for r=0.9 =  0.48420875
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.627
NEC for r=0.9 class 0 = 0.406 +- 0.211 (in-sample avg dev_std = 0.492)
NEC for r=0.9 class 1 = 0.194 +- 0.211 (in-sample avg dev_std = 0.492)
NEC for r=0.9 class 2 = 0.391 +- 0.211 (in-sample avg dev_std = 0.492)
NEC for r=0.9 all KL = 0.259 +- 0.211 (in-sample avg dev_std = 0.492)
NEC for r=0.9 all L1 = 0.331 +- 0.171 (in-sample avg dev_std = 0.492)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.8
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  0.44504875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.619
NEC for r=1.0 class 0 = 0.412 +- 0.199 (in-sample avg dev_std = 0.453)
NEC for r=1.0 class 1 = 0.163 +- 0.199 (in-sample avg dev_std = 0.453)
NEC for r=1.0 class 2 = 0.337 +- 0.199 (in-sample avg dev_std = 0.453)
NEC for r=1.0 all KL = 0.225 +- 0.199 (in-sample avg dev_std = 0.453)
NEC for r=1.0 all L1 = 0.305 +- 0.184 (in-sample avg dev_std = 0.453)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.284
Model XAI F1 of binarized graphs for r=0.3 =  0.36146124999999996
Model XAI WIoU of binarized graphs for r=0.3 =  0.26462250000000004
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.323
NEC for r=0.3 class 0 = 0.577 +- 0.237 (in-sample avg dev_std = 0.360)
NEC for r=0.3 class 1 = 0.527 +- 0.237 (in-sample avg dev_std = 0.360)
NEC for r=0.3 class 2 = 0.535 +- 0.237 (in-sample avg dev_std = 0.360)
NEC for r=0.3 all KL = 0.462 +- 0.237 (in-sample avg dev_std = 0.360)
NEC for r=0.3 all L1 = 0.547 +- 0.155 (in-sample avg dev_std = 0.360)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.634
Model XAI F1 of binarized graphs for r=0.6 =  0.62741
Model XAI WIoU of binarized graphs for r=0.6 =  0.49064875
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.48
NEC for r=0.6 class 0 = 0.547 +- 0.291 (in-sample avg dev_std = 0.554)
NEC for r=0.6 class 1 = 0.343 +- 0.291 (in-sample avg dev_std = 0.554)
NEC for r=0.6 class 2 = 0.621 +- 0.291 (in-sample avg dev_std = 0.554)
NEC for r=0.6 all KL = 0.556 +- 0.291 (in-sample avg dev_std = 0.554)
NEC for r=0.6 all L1 = 0.507 +- 0.206 (in-sample avg dev_std = 0.554)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.663
Model XAI F1 of binarized graphs for r=0.9 =  0.5903499999999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.43229999999999996
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.555
NEC for r=0.9 class 0 = 0.479 +- 0.242 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 1 = 0.204 +- 0.242 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 2 = 0.52 +- 0.242 (in-sample avg dev_std = 0.457)
NEC for r=0.9 all KL = 0.359 +- 0.242 (in-sample avg dev_std = 0.457)
NEC for r=0.9 all L1 = 0.405 +- 0.204 (in-sample avg dev_std = 0.457)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.586
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.4020425
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.536
NEC for r=1.0 class 0 = 0.407 +- 0.230 (in-sample avg dev_std = 0.425)
NEC for r=1.0 class 1 = 0.149 +- 0.230 (in-sample avg dev_std = 0.425)
NEC for r=1.0 class 2 = 0.49 +- 0.230 (in-sample avg dev_std = 0.425)
NEC for r=1.0 all KL = 0.3 +- 0.230 (in-sample avg dev_std = 0.425)
NEC for r=1.0 all L1 = 0.352 +- 0.208 (in-sample avg dev_std = 0.425)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 19:39:15 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/22/2024 07:39:15 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 07:39:27 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 07:39:29 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 07:39:31 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 07:39:33 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 07:39:35 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 07:39:35 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 07:39:35 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:39:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:39:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:39:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:39:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:39:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:39:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:39:35 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 156...
[0m[1;37mINFO[0m: [1mCheckpoint 156: 
-----------------------------------
Train ACCURACY: 0.9315
Train Loss: 0.3074
ID Validation ACCURACY: 0.9300
ID Validation Loss: 0.3203
ID Test ACCURACY: 0.9287
ID Test Loss: 0.3132
OOD Validation ACCURACY: 0.6043
OOD Validation Loss: 1.1704
OOD Test ACCURACY: 0.5793
OOD Test Loss: 1.3878

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 93...
[0m[1;37mINFO[0m: [1mCheckpoint 93: 
-----------------------------------
Train ACCURACY: 0.9269
Train Loss: 0.3333
ID Validation ACCURACY: 0.9240
ID Validation Loss: 0.3419
ID Test ACCURACY: 0.9233
ID Test Loss: 0.3373
OOD Validation ACCURACY: 0.9313
OOD Validation Loss: 0.3663
OOD Test ACCURACY: 0.5720
OOD Test Loss: 1.3522

[0m[1;37mINFO[0m: [1mChartInfo 0.9287 0.5793 0.9233 0.5720 0.9240 0.9313[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.709
WIoU for r=0.3 = 0.582
F1 for r=0.6 = 0.609
WIoU for r=0.6 = 0.489
F1 for r=0.9 = 0.474
WIoU for r=0.9 = 0.350
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.326
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.869
WIoU for r=0.3 = 0.781
F1 for r=0.6 = 0.798
WIoU for r=0.6 = 0.700
F1 for r=0.9 = 0.618
WIoU for r=0.9 = 0.486
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 0.447
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.409
WIoU for r=0.3 = 0.307
F1 for r=0.6 = 0.616
WIoU for r=0.6 = 0.483
F1 for r=0.9 = 0.575
WIoU for r=0.9 = 0.419
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.400


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.531
Model XAI F1 of binarized graphs for r=0.3 =  0.7089462499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.58243875
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.467
SUFF++ for r=0.3 class 0 = 0.43 +- 0.257 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.3 class 1 = 0.519 +- 0.257 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.3 class 2 = 0.531 +- 0.257 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.3 all KL = 0.5 +- 0.257 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.3 all L1 = 0.495 +- 0.145 (in-sample avg dev_std = 0.508)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.691
Model XAI F1 of binarized graphs for r=0.6 =  0.6085575
Model XAI WIoU of binarized graphs for r=0.6 =  0.48855000000000004
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.629
SUFF++ for r=0.6 class 0 = 0.453 +- 0.275 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 class 1 = 0.637 +- 0.275 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 class 2 = 0.625 +- 0.275 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 all KL = 0.558 +- 0.275 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 all L1 = 0.574 +- 0.197 (in-sample avg dev_std = 0.468)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.908
Model XAI F1 of binarized graphs for r=0.9 =  0.4740412500000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.350205
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.853
SUFF++ for r=0.9 class 0 = 0.675 +- 0.186 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 1 = 0.858 +- 0.186 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 2 = 0.856 +- 0.186 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 all KL = 0.854 +- 0.186 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 all L1 = 0.799 +- 0.163 (in-sample avg dev_std = 0.261)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.468
Model XAI F1 of binarized graphs for r=0.3 =  0.86858875
Model XAI WIoU of binarized graphs for r=0.3 =  0.78103625
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.44
SUFF++ for r=0.3 class 0 = 0.483 +- 0.269 (in-sample avg dev_std = 0.630)
SUFF++ for r=0.3 class 1 = 0.608 +- 0.269 (in-sample avg dev_std = 0.630)
SUFF++ for r=0.3 class 2 = 0.555 +- 0.269 (in-sample avg dev_std = 0.630)
SUFF++ for r=0.3 all KL = 0.444 +- 0.269 (in-sample avg dev_std = 0.630)
SUFF++ for r=0.3 all L1 = 0.548 +- 0.165 (in-sample avg dev_std = 0.630)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.74
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  0.6999175
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.798
SUFF++ for r=0.6 class 0 = 0.658 +- 0.314 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 class 1 = 0.665 +- 0.314 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 class 2 = 0.817 +- 0.314 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 all KL = 0.69 +- 0.314 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 all L1 = 0.713 +- 0.214 (in-sample avg dev_std = 0.483)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.723
Model XAI F1 of binarized graphs for r=0.9 =  0.61811125
Model XAI WIoU of binarized graphs for r=0.9 =  0.4864625
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.762
SUFF++ for r=0.9 class 0 = 0.743 +- 0.121 (in-sample avg dev_std = 0.225)
SUFF++ for r=0.9 class 1 = 0.923 +- 0.121 (in-sample avg dev_std = 0.225)
SUFF++ for r=0.9 class 2 = 0.851 +- 0.121 (in-sample avg dev_std = 0.225)
SUFF++ for r=0.9 all KL = 0.913 +- 0.121 (in-sample avg dev_std = 0.225)
SUFF++ for r=0.9 all L1 = 0.838 +- 0.153 (in-sample avg dev_std = 0.225)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.264
Model XAI F1 of binarized graphs for r=0.3 =  0.4089425
Model XAI WIoU of binarized graphs for r=0.3 =  0.30743
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.302
SUFF++ for r=0.3 class 0 = 0.492 +- 0.197 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 class 1 = 0.516 +- 0.197 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 class 2 = 0.504 +- 0.197 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 all KL = 0.603 +- 0.197 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 all L1 = 0.504 +- 0.110 (in-sample avg dev_std = 0.441)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.631
Model XAI F1 of binarized graphs for r=0.6 =  0.61599375
Model XAI WIoU of binarized graphs for r=0.6 =  0.48344625
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.624
SUFF++ for r=0.6 class 0 = 0.629 +- 0.218 (in-sample avg dev_std = 0.410)
SUFF++ for r=0.6 class 1 = 0.71 +- 0.218 (in-sample avg dev_std = 0.410)
SUFF++ for r=0.6 class 2 = 0.739 +- 0.218 (in-sample avg dev_std = 0.410)
SUFF++ for r=0.6 all KL = 0.73 +- 0.218 (in-sample avg dev_std = 0.410)
SUFF++ for r=0.6 all L1 = 0.692 +- 0.182 (in-sample avg dev_std = 0.410)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.668
Model XAI F1 of binarized graphs for r=0.9 =  0.57488375
Model XAI WIoU of binarized graphs for r=0.9 =  0.418655
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.656
SUFF++ for r=0.9 class 0 = 0.729 +- 0.130 (in-sample avg dev_std = 0.215)
SUFF++ for r=0.9 class 1 = 0.947 +- 0.130 (in-sample avg dev_std = 0.215)
SUFF++ for r=0.9 class 2 = 0.747 +- 0.130 (in-sample avg dev_std = 0.215)
SUFF++ for r=0.9 all KL = 0.894 +- 0.130 (in-sample avg dev_std = 0.215)
SUFF++ for r=0.9 all L1 = 0.805 +- 0.161 (in-sample avg dev_std = 0.215)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.534
Model XAI F1 of binarized graphs for r=0.3 =  0.7089462499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.58243875
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.373
NEC for r=0.3 class 0 = 0.622 +- 0.270 (in-sample avg dev_std = 0.429)
NEC for r=0.3 class 1 = 0.5 +- 0.270 (in-sample avg dev_std = 0.429)
NEC for r=0.3 class 2 = 0.593 +- 0.270 (in-sample avg dev_std = 0.429)
NEC for r=0.3 all KL = 0.557 +- 0.270 (in-sample avg dev_std = 0.429)
NEC for r=0.3 all L1 = 0.571 +- 0.152 (in-sample avg dev_std = 0.429)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.691
Model XAI F1 of binarized graphs for r=0.6 =  0.6085575
Model XAI WIoU of binarized graphs for r=0.6 =  0.48855000000000004
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.415
NEC for r=0.6 class 0 = 0.573 +- 0.278 (in-sample avg dev_std = 0.495)
NEC for r=0.6 class 1 = 0.488 +- 0.278 (in-sample avg dev_std = 0.495)
NEC for r=0.6 class 2 = 0.632 +- 0.278 (in-sample avg dev_std = 0.495)
NEC for r=0.6 all KL = 0.611 +- 0.278 (in-sample avg dev_std = 0.495)
NEC for r=0.6 all L1 = 0.565 +- 0.180 (in-sample avg dev_std = 0.495)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.909
Model XAI F1 of binarized graphs for r=0.9 =  0.4740412500000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.350205
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.502
NEC for r=0.9 class 0 = 0.637 +- 0.226 (in-sample avg dev_std = 0.578)
NEC for r=0.9 class 1 = 0.479 +- 0.226 (in-sample avg dev_std = 0.578)
NEC for r=0.9 class 2 = 0.556 +- 0.226 (in-sample avg dev_std = 0.578)
NEC for r=0.9 all KL = 0.609 +- 0.226 (in-sample avg dev_std = 0.578)
NEC for r=0.9 all L1 = 0.556 +- 0.155 (in-sample avg dev_std = 0.578)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.929
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.32575249999999994
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.546
NEC for r=1.0 class 0 = 0.584 +- 0.236 (in-sample avg dev_std = 0.621)
NEC for r=1.0 class 1 = 0.433 +- 0.236 (in-sample avg dev_std = 0.621)
NEC for r=1.0 class 2 = 0.592 +- 0.236 (in-sample avg dev_std = 0.621)
NEC for r=1.0 all KL = 0.589 +- 0.236 (in-sample avg dev_std = 0.621)
NEC for r=1.0 all L1 = 0.536 +- 0.173 (in-sample avg dev_std = 0.621)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.466
Model XAI F1 of binarized graphs for r=0.3 =  0.86858875
Model XAI WIoU of binarized graphs for r=0.3 =  0.78103625
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.284
NEC for r=0.3 class 0 = 0.687 +- 0.274 (in-sample avg dev_std = 0.441)
NEC for r=0.3 class 1 = 0.592 +- 0.274 (in-sample avg dev_std = 0.441)
NEC for r=0.3 class 2 = 0.588 +- 0.274 (in-sample avg dev_std = 0.441)
NEC for r=0.3 all KL = 0.699 +- 0.274 (in-sample avg dev_std = 0.441)
NEC for r=0.3 all L1 = 0.623 +- 0.164 (in-sample avg dev_std = 0.441)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.74
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  0.6999175
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.466
NEC for r=0.6 class 0 = 0.492 +- 0.317 (in-sample avg dev_std = 0.489)
NEC for r=0.6 class 1 = 0.384 +- 0.317 (in-sample avg dev_std = 0.489)
NEC for r=0.6 class 2 = 0.324 +- 0.317 (in-sample avg dev_std = 0.489)
NEC for r=0.6 all KL = 0.416 +- 0.317 (in-sample avg dev_std = 0.489)
NEC for r=0.6 all L1 = 0.4 +- 0.256 (in-sample avg dev_std = 0.489)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.723
Model XAI F1 of binarized graphs for r=0.9 =  0.61811125
Model XAI WIoU of binarized graphs for r=0.9 =  0.4864625
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.577
NEC for r=0.9 class 0 = 0.366 +- 0.207 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 1 = 0.175 +- 0.207 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 2 = 0.369 +- 0.207 (in-sample avg dev_std = 0.441)
NEC for r=0.9 all KL = 0.229 +- 0.207 (in-sample avg dev_std = 0.441)
NEC for r=0.9 all L1 = 0.304 +- 0.180 (in-sample avg dev_std = 0.441)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.62
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  0.4470975
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.52
NEC for r=1.0 class 0 = 0.298 +- 0.186 (in-sample avg dev_std = 0.361)
NEC for r=1.0 class 1 = 0.116 +- 0.186 (in-sample avg dev_std = 0.361)
NEC for r=1.0 class 2 = 0.349 +- 0.186 (in-sample avg dev_std = 0.361)
NEC for r=1.0 all KL = 0.175 +- 0.186 (in-sample avg dev_std = 0.361)
NEC for r=1.0 all L1 = 0.255 +- 0.191 (in-sample avg dev_std = 0.361)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.264
Model XAI F1 of binarized graphs for r=0.3 =  0.4089425
Model XAI WIoU of binarized graphs for r=0.3 =  0.30743
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.259
NEC for r=0.3 class 0 = 0.58 +- 0.241 (in-sample avg dev_std = 0.362)
NEC for r=0.3 class 1 = 0.524 +- 0.241 (in-sample avg dev_std = 0.362)
NEC for r=0.3 class 2 = 0.511 +- 0.241 (in-sample avg dev_std = 0.362)
NEC for r=0.3 all KL = 0.448 +- 0.241 (in-sample avg dev_std = 0.362)
NEC for r=0.3 all L1 = 0.539 +- 0.158 (in-sample avg dev_std = 0.362)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.631
Model XAI F1 of binarized graphs for r=0.6 =  0.61599375
Model XAI WIoU of binarized graphs for r=0.6 =  0.48344625
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.493
NEC for r=0.6 class 0 = 0.578 +- 0.277 (in-sample avg dev_std = 0.566)
NEC for r=0.6 class 1 = 0.435 +- 0.277 (in-sample avg dev_std = 0.566)
NEC for r=0.6 class 2 = 0.621 +- 0.277 (in-sample avg dev_std = 0.566)
NEC for r=0.6 all KL = 0.581 +- 0.277 (in-sample avg dev_std = 0.566)
NEC for r=0.6 all L1 = 0.546 +- 0.179 (in-sample avg dev_std = 0.566)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.668
Model XAI F1 of binarized graphs for r=0.9 =  0.57488375
Model XAI WIoU of binarized graphs for r=0.9 =  0.418655
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.561
NEC for r=0.9 class 0 = 0.464 +- 0.240 (in-sample avg dev_std = 0.464)
NEC for r=0.9 class 1 = 0.227 +- 0.240 (in-sample avg dev_std = 0.464)
NEC for r=0.9 class 2 = 0.512 +- 0.240 (in-sample avg dev_std = 0.464)
NEC for r=0.9 all KL = 0.381 +- 0.240 (in-sample avg dev_std = 0.464)
NEC for r=0.9 all L1 = 0.404 +- 0.196 (in-sample avg dev_std = 0.464)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.582
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.3998625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.536
NEC for r=1.0 class 0 = 0.384 +- 0.228 (in-sample avg dev_std = 0.416)
NEC for r=1.0 class 1 = 0.147 +- 0.228 (in-sample avg dev_std = 0.416)
NEC for r=1.0 class 2 = 0.492 +- 0.228 (in-sample avg dev_std = 0.416)
NEC for r=1.0 all KL = 0.3 +- 0.228 (in-sample avg dev_std = 0.416)
NEC for r=1.0 all L1 = 0.345 +- 0.207 (in-sample avg dev_std = 0.416)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 19:42:51 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/22/2024 07:42:51 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 07:43:04 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 07:43:06 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 07:43:08 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 07:43:10 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 07:43:12 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 07:43:12 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 07:43:12 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:43:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:43:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:43:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:43:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:43:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:43:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:43:12 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 136...
[0m[1;37mINFO[0m: [1mCheckpoint 136: 
-----------------------------------
Train ACCURACY: 0.9312
Train Loss: 0.3182
ID Validation ACCURACY: 0.9303
ID Validation Loss: 0.3316
ID Test ACCURACY: 0.9280
ID Test Loss: 0.3271
OOD Validation ACCURACY: 0.9293
OOD Validation Loss: 0.4588
OOD Test ACCURACY: 0.5283
OOD Test Loss: 1.4435

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 30...
[0m[1;37mINFO[0m: [1mCheckpoint 30: 
-----------------------------------
Train ACCURACY: 0.9285
Train Loss: 0.3202
ID Validation ACCURACY: 0.9270
ID Validation Loss: 0.3310
ID Test ACCURACY: 0.9270
ID Test Loss: 0.3274
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.3340
OOD Test ACCURACY: 0.5837
OOD Test Loss: 1.2512

[0m[1;37mINFO[0m: [1mChartInfo 0.9280 0.5283 0.9270 0.5837 0.9270 0.9317[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.703
WIoU for r=0.3 = 0.578
F1 for r=0.6 = 0.592
WIoU for r=0.6 = 0.475
F1 for r=0.9 = 0.466
WIoU for r=0.9 = 0.343
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.325
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.869
WIoU for r=0.3 = 0.780
F1 for r=0.6 = 0.798
WIoU for r=0.6 = 0.699
F1 for r=0.9 = 0.618
WIoU for r=0.9 = 0.484
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 0.445
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.357
WIoU for r=0.3 = 0.258
F1 for r=0.6 = 0.596
WIoU for r=0.6 = 0.453
F1 for r=0.9 = 0.587
WIoU for r=0.9 = 0.425
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.398


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.512
Model XAI F1 of binarized graphs for r=0.3 =  0.702765
Model XAI WIoU of binarized graphs for r=0.3 =  0.5784475
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.454
SUFF++ for r=0.3 class 0 = 0.434 +- 0.267 (in-sample avg dev_std = 0.484)
SUFF++ for r=0.3 class 1 = 0.511 +- 0.267 (in-sample avg dev_std = 0.484)
SUFF++ for r=0.3 class 2 = 0.55 +- 0.267 (in-sample avg dev_std = 0.484)
SUFF++ for r=0.3 all KL = 0.512 +- 0.267 (in-sample avg dev_std = 0.484)
SUFF++ for r=0.3 all L1 = 0.5 +- 0.152 (in-sample avg dev_std = 0.484)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.649
Model XAI F1 of binarized graphs for r=0.6 =  0.5916562499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.47481375
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.641
SUFF++ for r=0.6 class 0 = 0.468 +- 0.291 (in-sample avg dev_std = 0.457)
SUFF++ for r=0.6 class 1 = 0.677 +- 0.291 (in-sample avg dev_std = 0.457)
SUFF++ for r=0.6 class 2 = 0.601 +- 0.291 (in-sample avg dev_std = 0.457)
SUFF++ for r=0.6 all KL = 0.586 +- 0.291 (in-sample avg dev_std = 0.457)
SUFF++ for r=0.6 all L1 = 0.584 +- 0.205 (in-sample avg dev_std = 0.457)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.918
Model XAI F1 of binarized graphs for r=0.9 =  0.46628375
Model XAI WIoU of binarized graphs for r=0.9 =  0.34303249999999996
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.859
SUFF++ for r=0.9 class 0 = 0.681 +- 0.166 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.9 class 1 = 0.864 +- 0.166 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.9 class 2 = 0.813 +- 0.166 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.9 all KL = 0.859 +- 0.166 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.9 all L1 = 0.788 +- 0.154 (in-sample avg dev_std = 0.258)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.419
Model XAI F1 of binarized graphs for r=0.3 =  0.86858875
Model XAI WIoU of binarized graphs for r=0.3 =  0.7796799999999999
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.392
SUFF++ for r=0.3 class 0 = 0.513 +- 0.269 (in-sample avg dev_std = 0.589)
SUFF++ for r=0.3 class 1 = 0.527 +- 0.269 (in-sample avg dev_std = 0.589)
SUFF++ for r=0.3 class 2 = 0.57 +- 0.269 (in-sample avg dev_std = 0.589)
SUFF++ for r=0.3 all KL = 0.488 +- 0.269 (in-sample avg dev_std = 0.589)
SUFF++ for r=0.3 all L1 = 0.537 +- 0.149 (in-sample avg dev_std = 0.589)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.712
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  0.6985062500000001
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.768
SUFF++ for r=0.6 class 0 = 0.616 +- 0.349 (in-sample avg dev_std = 0.544)
SUFF++ for r=0.6 class 1 = 0.692 +- 0.349 (in-sample avg dev_std = 0.544)
SUFF++ for r=0.6 class 2 = 0.731 +- 0.349 (in-sample avg dev_std = 0.544)
SUFF++ for r=0.6 all KL = 0.634 +- 0.349 (in-sample avg dev_std = 0.544)
SUFF++ for r=0.6 all L1 = 0.68 +- 0.225 (in-sample avg dev_std = 0.544)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.889
Model XAI F1 of binarized graphs for r=0.9 =  0.61811125
Model XAI WIoU of binarized graphs for r=0.9 =  0.48391999999999996
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.888
SUFF++ for r=0.9 class 0 = 0.831 +- 0.094 (in-sample avg dev_std = 0.178)
SUFF++ for r=0.9 class 1 = 0.928 +- 0.094 (in-sample avg dev_std = 0.178)
SUFF++ for r=0.9 class 2 = 0.896 +- 0.094 (in-sample avg dev_std = 0.178)
SUFF++ for r=0.9 all KL = 0.951 +- 0.094 (in-sample avg dev_std = 0.178)
SUFF++ for r=0.9 all L1 = 0.885 +- 0.117 (in-sample avg dev_std = 0.178)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.18
Model XAI F1 of binarized graphs for r=0.3 =  0.3568325
Model XAI WIoU of binarized graphs for r=0.3 =  0.25753875
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.287
SUFF++ for r=0.3 class 0 = 0.495 +- 0.189 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.3 class 1 = 0.532 +- 0.189 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.3 class 2 = 0.537 +- 0.189 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.3 all KL = 0.632 +- 0.189 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.3 all L1 = 0.521 +- 0.113 (in-sample avg dev_std = 0.430)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.579
Model XAI F1 of binarized graphs for r=0.6 =  0.59626875
Model XAI WIoU of binarized graphs for r=0.6 =  0.45321625
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.549
SUFF++ for r=0.6 class 0 = 0.536 +- 0.227 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.6 class 1 = 0.697 +- 0.227 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.6 class 2 = 0.624 +- 0.227 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.6 all KL = 0.664 +- 0.227 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.6 all L1 = 0.618 +- 0.196 (in-sample avg dev_std = 0.420)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.671
Model XAI F1 of binarized graphs for r=0.9 =  0.58662625
Model XAI WIoU of binarized graphs for r=0.9 =  0.42531874999999997
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.649
SUFF++ for r=0.9 class 0 = 0.67 +- 0.145 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.9 class 1 = 0.917 +- 0.145 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.9 class 2 = 0.698 +- 0.145 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.9 all KL = 0.862 +- 0.145 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.9 all L1 = 0.759 +- 0.179 (in-sample avg dev_std = 0.272)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.509
Model XAI F1 of binarized graphs for r=0.3 =  0.702765
Model XAI WIoU of binarized graphs for r=0.3 =  0.5784475
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.331
NEC for r=0.3 class 0 = 0.587 +- 0.278 (in-sample avg dev_std = 0.424)
NEC for r=0.3 class 1 = 0.551 +- 0.278 (in-sample avg dev_std = 0.424)
NEC for r=0.3 class 2 = 0.589 +- 0.278 (in-sample avg dev_std = 0.424)
NEC for r=0.3 all KL = 0.567 +- 0.278 (in-sample avg dev_std = 0.424)
NEC for r=0.3 all L1 = 0.576 +- 0.146 (in-sample avg dev_std = 0.424)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.65
Model XAI F1 of binarized graphs for r=0.6 =  0.5916562499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.47481375
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.383
NEC for r=0.6 class 0 = 0.567 +- 0.283 (in-sample avg dev_std = 0.477)
NEC for r=0.6 class 1 = 0.522 +- 0.283 (in-sample avg dev_std = 0.477)
NEC for r=0.6 class 2 = 0.615 +- 0.283 (in-sample avg dev_std = 0.477)
NEC for r=0.6 all KL = 0.612 +- 0.283 (in-sample avg dev_std = 0.477)
NEC for r=0.6 all L1 = 0.569 +- 0.180 (in-sample avg dev_std = 0.477)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.919
Model XAI F1 of binarized graphs for r=0.9 =  0.46628375
Model XAI WIoU of binarized graphs for r=0.9 =  0.34303249999999996
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.507
NEC for r=0.9 class 0 = 0.608 +- 0.222 (in-sample avg dev_std = 0.597)
NEC for r=0.9 class 1 = 0.501 +- 0.222 (in-sample avg dev_std = 0.597)
NEC for r=0.9 class 2 = 0.559 +- 0.222 (in-sample avg dev_std = 0.597)
NEC for r=0.9 all KL = 0.616 +- 0.222 (in-sample avg dev_std = 0.597)
NEC for r=0.9 all L1 = 0.555 +- 0.161 (in-sample avg dev_std = 0.597)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.929
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.32451625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.535
NEC for r=1.0 class 0 = 0.572 +- 0.226 (in-sample avg dev_std = 0.633)
NEC for r=1.0 class 1 = 0.456 +- 0.226 (in-sample avg dev_std = 0.633)
NEC for r=1.0 class 2 = 0.578 +- 0.226 (in-sample avg dev_std = 0.633)
NEC for r=1.0 all KL = 0.6 +- 0.226 (in-sample avg dev_std = 0.633)
NEC for r=1.0 all L1 = 0.535 +- 0.171 (in-sample avg dev_std = 0.633)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.419
Model XAI F1 of binarized graphs for r=0.3 =  0.86858875
Model XAI WIoU of binarized graphs for r=0.3 =  0.7796799999999999
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.312
NEC for r=0.3 class 0 = 0.641 +- 0.288 (in-sample avg dev_std = 0.437)
NEC for r=0.3 class 1 = 0.55 +- 0.288 (in-sample avg dev_std = 0.437)
NEC for r=0.3 class 2 = 0.619 +- 0.288 (in-sample avg dev_std = 0.437)
NEC for r=0.3 all KL = 0.62 +- 0.288 (in-sample avg dev_std = 0.437)
NEC for r=0.3 all L1 = 0.604 +- 0.160 (in-sample avg dev_std = 0.437)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.712
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  0.6985062500000001
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.446
NEC for r=0.6 class 0 = 0.481 +- 0.323 (in-sample avg dev_std = 0.505)
NEC for r=0.6 class 1 = 0.373 +- 0.323 (in-sample avg dev_std = 0.505)
NEC for r=0.6 class 2 = 0.351 +- 0.323 (in-sample avg dev_std = 0.505)
NEC for r=0.6 all KL = 0.433 +- 0.323 (in-sample avg dev_std = 0.505)
NEC for r=0.6 all L1 = 0.402 +- 0.257 (in-sample avg dev_std = 0.505)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.889
Model XAI F1 of binarized graphs for r=0.9 =  0.61811125
Model XAI WIoU of binarized graphs for r=0.9 =  0.48391999999999996
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.663
NEC for r=0.9 class 0 = 0.395 +- 0.195 (in-sample avg dev_std = 0.496)
NEC for r=0.9 class 1 = 0.239 +- 0.195 (in-sample avg dev_std = 0.496)
NEC for r=0.9 class 2 = 0.362 +- 0.195 (in-sample avg dev_std = 0.496)
NEC for r=0.9 all KL = 0.265 +- 0.195 (in-sample avg dev_std = 0.496)
NEC for r=0.9 all L1 = 0.332 +- 0.168 (in-sample avg dev_std = 0.496)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.933
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  0.44457749999999996
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.695
NEC for r=1.0 class 0 = 0.394 +- 0.177 (in-sample avg dev_std = 0.486)
NEC for r=1.0 class 1 = 0.225 +- 0.177 (in-sample avg dev_std = 0.486)
NEC for r=1.0 class 2 = 0.36 +- 0.177 (in-sample avg dev_std = 0.486)
NEC for r=1.0 all KL = 0.246 +- 0.177 (in-sample avg dev_std = 0.486)
NEC for r=1.0 all L1 = 0.327 +- 0.164 (in-sample avg dev_std = 0.486)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.179
Model XAI F1 of binarized graphs for r=0.3 =  0.3568325
Model XAI WIoU of binarized graphs for r=0.3 =  0.25753875
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.288
NEC for r=0.3 class 0 = 0.558 +- 0.231 (in-sample avg dev_std = 0.350)
NEC for r=0.3 class 1 = 0.504 +- 0.231 (in-sample avg dev_std = 0.350)
NEC for r=0.3 class 2 = 0.527 +- 0.231 (in-sample avg dev_std = 0.350)
NEC for r=0.3 all KL = 0.434 +- 0.231 (in-sample avg dev_std = 0.350)
NEC for r=0.3 all L1 = 0.53 +- 0.152 (in-sample avg dev_std = 0.350)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.577
Model XAI F1 of binarized graphs for r=0.6 =  0.59626875
Model XAI WIoU of binarized graphs for r=0.6 =  0.45321625
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.482
NEC for r=0.6 class 0 = 0.57 +- 0.275 (in-sample avg dev_std = 0.511)
NEC for r=0.6 class 1 = 0.456 +- 0.275 (in-sample avg dev_std = 0.511)
NEC for r=0.6 class 2 = 0.634 +- 0.275 (in-sample avg dev_std = 0.511)
NEC for r=0.6 all KL = 0.558 +- 0.275 (in-sample avg dev_std = 0.511)
NEC for r=0.6 all L1 = 0.555 +- 0.171 (in-sample avg dev_std = 0.511)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.671
Model XAI F1 of binarized graphs for r=0.9 =  0.58662625
Model XAI WIoU of binarized graphs for r=0.9 =  0.42531874999999997
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.575
NEC for r=0.9 class 0 = 0.474 +- 0.221 (in-sample avg dev_std = 0.455)
NEC for r=0.9 class 1 = 0.266 +- 0.221 (in-sample avg dev_std = 0.455)
NEC for r=0.9 class 2 = 0.499 +- 0.221 (in-sample avg dev_std = 0.455)
NEC for r=0.9 all KL = 0.359 +- 0.221 (in-sample avg dev_std = 0.455)
NEC for r=0.9 all L1 = 0.416 +- 0.173 (in-sample avg dev_std = 0.455)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.521
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.39820125000000006
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.532
NEC for r=1.0 class 0 = 0.415 +- 0.219 (in-sample avg dev_std = 0.441)
NEC for r=1.0 class 1 = 0.176 +- 0.219 (in-sample avg dev_std = 0.441)
NEC for r=1.0 class 2 = 0.473 +- 0.219 (in-sample avg dev_std = 0.441)
NEC for r=1.0 all KL = 0.317 +- 0.219 (in-sample avg dev_std = 0.441)
NEC for r=1.0 all L1 = 0.358 +- 0.196 (in-sample avg dev_std = 0.441)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 19:46:25 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/22/2024 07:46:25 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 07:46:38 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 07:46:40 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 07:46:43 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 07:46:44 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 07:46:46 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 07:46:46 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 07:46:46 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:46:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:46:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:46:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:46:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:46:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:46:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:46:46 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 90...
[0m[1;37mINFO[0m: [1mCheckpoint 90: 
-----------------------------------
Train ACCURACY: 0.9313
Train Loss: 0.3152
ID Validation ACCURACY: 0.9303
ID Validation Loss: 0.3261
ID Test ACCURACY: 0.9280
ID Test Loss: 0.3206
OOD Validation ACCURACY: 0.5570
OOD Validation Loss: 1.0961
OOD Test ACCURACY: 0.5530
OOD Test Loss: 1.3591

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 46...
[0m[1;37mINFO[0m: [1mCheckpoint 46: 
-----------------------------------
Train ACCURACY: 0.9284
Train Loss: 0.3274
ID Validation ACCURACY: 0.9277
ID Validation Loss: 0.3360
ID Test ACCURACY: 0.9260
ID Test Loss: 0.3348
OOD Validation ACCURACY: 0.9320
OOD Validation Loss: 0.3331
OOD Test ACCURACY: 0.5507
OOD Test Loss: 1.5619

[0m[1;37mINFO[0m: [1mChartInfo 0.9280 0.5530 0.9260 0.5507 0.9277 0.9320[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.657
WIoU for r=0.3 = 0.531
F1 for r=0.6 = 0.571
WIoU for r=0.6 = 0.452
F1 for r=0.9 = 0.455
WIoU for r=0.9 = 0.333
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.324
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.869
WIoU for r=0.3 = 0.781
F1 for r=0.6 = 0.798
WIoU for r=0.6 = 0.709
F1 for r=0.9 = 0.618
WIoU for r=0.9 = 0.497
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 0.458
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.335
WIoU for r=0.3 = 0.243
F1 for r=0.6 = 0.584
WIoU for r=0.6 = 0.447
F1 for r=0.9 = 0.579
WIoU for r=0.9 = 0.419
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.398


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.548
Model XAI F1 of binarized graphs for r=0.3 =  0.6567374999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.53097875
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.43
SUFF++ for r=0.3 class 0 = 0.459 +- 0.268 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.3 class 1 = 0.554 +- 0.268 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.3 class 2 = 0.605 +- 0.268 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.3 all KL = 0.552 +- 0.268 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.3 all L1 = 0.541 +- 0.166 (in-sample avg dev_std = 0.469)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.637
Model XAI F1 of binarized graphs for r=0.6 =  0.57065625
Model XAI WIoU of binarized graphs for r=0.6 =  0.4520375
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.61
SUFF++ for r=0.6 class 0 = 0.418 +- 0.281 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.6 class 1 = 0.607 +- 0.281 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.6 class 2 = 0.608 +- 0.281 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.6 all KL = 0.519 +- 0.281 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.6 all L1 = 0.546 +- 0.206 (in-sample avg dev_std = 0.501)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.9
Model XAI F1 of binarized graphs for r=0.9 =  0.4546725
Model XAI WIoU of binarized graphs for r=0.9 =  0.33281
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.796
SUFF++ for r=0.9 class 0 = 0.566 +- 0.200 (in-sample avg dev_std = 0.308)
SUFF++ for r=0.9 class 1 = 0.788 +- 0.200 (in-sample avg dev_std = 0.308)
SUFF++ for r=0.9 class 2 = 0.857 +- 0.200 (in-sample avg dev_std = 0.308)
SUFF++ for r=0.9 all KL = 0.801 +- 0.200 (in-sample avg dev_std = 0.308)
SUFF++ for r=0.9 all L1 = 0.741 +- 0.193 (in-sample avg dev_std = 0.308)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.46
Model XAI F1 of binarized graphs for r=0.3 =  0.86858875
Model XAI WIoU of binarized graphs for r=0.3 =  0.78127375
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.362
SUFF++ for r=0.3 class 0 = 0.477 +- 0.314 (in-sample avg dev_std = 0.552)
SUFF++ for r=0.3 class 1 = 0.637 +- 0.314 (in-sample avg dev_std = 0.552)
SUFF++ for r=0.3 class 2 = 0.564 +- 0.314 (in-sample avg dev_std = 0.552)
SUFF++ for r=0.3 all KL = 0.517 +- 0.314 (in-sample avg dev_std = 0.552)
SUFF++ for r=0.3 all L1 = 0.559 +- 0.180 (in-sample avg dev_std = 0.552)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.752
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  0.70853875
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.831
SUFF++ for r=0.6 class 0 = 0.646 +- 0.292 (in-sample avg dev_std = 0.373)
SUFF++ for r=0.6 class 1 = 0.781 +- 0.292 (in-sample avg dev_std = 0.373)
SUFF++ for r=0.6 class 2 = 0.907 +- 0.292 (in-sample avg dev_std = 0.373)
SUFF++ for r=0.6 all KL = 0.779 +- 0.292 (in-sample avg dev_std = 0.373)
SUFF++ for r=0.6 all L1 = 0.778 +- 0.225 (in-sample avg dev_std = 0.373)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.68
Model XAI F1 of binarized graphs for r=0.9 =  0.61811125
Model XAI WIoU of binarized graphs for r=0.9 =  0.49698875000000003
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.757
SUFF++ for r=0.9 class 0 = 0.815 +- 0.102 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.9 class 1 = 0.962 +- 0.102 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.9 class 2 = 0.825 +- 0.102 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.9 all KL = 0.937 +- 0.102 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.9 all L1 = 0.867 +- 0.136 (in-sample avg dev_std = 0.229)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.373
Model XAI F1 of binarized graphs for r=0.3 =  0.33527
Model XAI WIoU of binarized graphs for r=0.3 =  0.24301125
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.348
SUFF++ for r=0.3 class 0 = 0.583 +- 0.179 (in-sample avg dev_std = 0.361)
SUFF++ for r=0.3 class 1 = 0.645 +- 0.179 (in-sample avg dev_std = 0.361)
SUFF++ for r=0.3 class 2 = 0.619 +- 0.179 (in-sample avg dev_std = 0.361)
SUFF++ for r=0.3 all KL = 0.723 +- 0.179 (in-sample avg dev_std = 0.361)
SUFF++ for r=0.3 all L1 = 0.615 +- 0.128 (in-sample avg dev_std = 0.361)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.48
Model XAI F1 of binarized graphs for r=0.6 =  0.584365
Model XAI WIoU of binarized graphs for r=0.6 =  0.4468237499999999
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.506
SUFF++ for r=0.6 class 0 = 0.533 +- 0.237 (in-sample avg dev_std = 0.464)
SUFF++ for r=0.6 class 1 = 0.636 +- 0.237 (in-sample avg dev_std = 0.464)
SUFF++ for r=0.6 class 2 = 0.632 +- 0.237 (in-sample avg dev_std = 0.464)
SUFF++ for r=0.6 all KL = 0.622 +- 0.237 (in-sample avg dev_std = 0.464)
SUFF++ for r=0.6 all L1 = 0.6 +- 0.203 (in-sample avg dev_std = 0.464)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.65
Model XAI F1 of binarized graphs for r=0.9 =  0.5792587499999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.41902750000000005
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.624
SUFF++ for r=0.9 class 0 = 0.655 +- 0.181 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.9 class 1 = 0.919 +- 0.181 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.9 class 2 = 0.691 +- 0.181 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.9 all KL = 0.831 +- 0.181 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.9 all L1 = 0.752 +- 0.197 (in-sample avg dev_std = 0.321)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.549
Model XAI F1 of binarized graphs for r=0.3 =  0.6567374999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.53097875
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.363
NEC for r=0.3 class 0 = 0.61 +- 0.276 (in-sample avg dev_std = 0.422)
NEC for r=0.3 class 1 = 0.528 +- 0.276 (in-sample avg dev_std = 0.422)
NEC for r=0.3 class 2 = 0.522 +- 0.276 (in-sample avg dev_std = 0.422)
NEC for r=0.3 all KL = 0.545 +- 0.276 (in-sample avg dev_std = 0.422)
NEC for r=0.3 all L1 = 0.552 +- 0.154 (in-sample avg dev_std = 0.422)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.635
Model XAI F1 of binarized graphs for r=0.6 =  0.57065625
Model XAI WIoU of binarized graphs for r=0.6 =  0.4520375
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.365
NEC for r=0.6 class 0 = 0.583 +- 0.281 (in-sample avg dev_std = 0.499)
NEC for r=0.6 class 1 = 0.55 +- 0.281 (in-sample avg dev_std = 0.499)
NEC for r=0.6 class 2 = 0.628 +- 0.281 (in-sample avg dev_std = 0.499)
NEC for r=0.6 all KL = 0.642 +- 0.281 (in-sample avg dev_std = 0.499)
NEC for r=0.6 all L1 = 0.587 +- 0.175 (in-sample avg dev_std = 0.499)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.9
Model XAI F1 of binarized graphs for r=0.9 =  0.4546725
Model XAI WIoU of binarized graphs for r=0.9 =  0.33281
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.485
NEC for r=0.9 class 0 = 0.597 +- 0.237 (in-sample avg dev_std = 0.582)
NEC for r=0.9 class 1 = 0.536 +- 0.237 (in-sample avg dev_std = 0.582)
NEC for r=0.9 class 2 = 0.568 +- 0.237 (in-sample avg dev_std = 0.582)
NEC for r=0.9 all KL = 0.627 +- 0.237 (in-sample avg dev_std = 0.582)
NEC for r=0.9 all L1 = 0.567 +- 0.152 (in-sample avg dev_std = 0.582)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.929
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.32355625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.524
NEC for r=1.0 class 0 = 0.566 +- 0.242 (in-sample avg dev_std = 0.626)
NEC for r=1.0 class 1 = 0.476 +- 0.242 (in-sample avg dev_std = 0.626)
NEC for r=1.0 class 2 = 0.577 +- 0.242 (in-sample avg dev_std = 0.626)
NEC for r=1.0 all KL = 0.596 +- 0.242 (in-sample avg dev_std = 0.626)
NEC for r=1.0 all L1 = 0.54 +- 0.170 (in-sample avg dev_std = 0.626)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.46
Model XAI F1 of binarized graphs for r=0.3 =  0.86858875
Model XAI WIoU of binarized graphs for r=0.3 =  0.78127375
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.279
NEC for r=0.3 class 0 = 0.634 +- 0.312 (in-sample avg dev_std = 0.371)
NEC for r=0.3 class 1 = 0.499 +- 0.312 (in-sample avg dev_std = 0.371)
NEC for r=0.3 class 2 = 0.603 +- 0.312 (in-sample avg dev_std = 0.371)
NEC for r=0.3 all KL = 0.579 +- 0.312 (in-sample avg dev_std = 0.371)
NEC for r=0.3 all L1 = 0.579 +- 0.176 (in-sample avg dev_std = 0.371)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.752
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  0.70853875
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.466
NEC for r=0.6 class 0 = 0.525 +- 0.313 (in-sample avg dev_std = 0.549)
NEC for r=0.6 class 1 = 0.427 +- 0.313 (in-sample avg dev_std = 0.549)
NEC for r=0.6 class 2 = 0.402 +- 0.313 (in-sample avg dev_std = 0.549)
NEC for r=0.6 all KL = 0.487 +- 0.313 (in-sample avg dev_std = 0.549)
NEC for r=0.6 all L1 = 0.452 +- 0.221 (in-sample avg dev_std = 0.549)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.68
Model XAI F1 of binarized graphs for r=0.9 =  0.61811125
Model XAI WIoU of binarized graphs for r=0.9 =  0.49698875000000003
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.551
NEC for r=0.9 class 0 = 0.38 +- 0.232 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 1 = 0.17 +- 0.232 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 2 = 0.376 +- 0.232 (in-sample avg dev_std = 0.457)
NEC for r=0.9 all KL = 0.257 +- 0.232 (in-sample avg dev_std = 0.457)
NEC for r=0.9 all L1 = 0.309 +- 0.193 (in-sample avg dev_std = 0.457)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.58
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  0.45765874999999995
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.506
NEC for r=1.0 class 0 = 0.32 +- 0.208 (in-sample avg dev_std = 0.367)
NEC for r=1.0 class 1 = 0.112 +- 0.208 (in-sample avg dev_std = 0.367)
NEC for r=1.0 class 2 = 0.314 +- 0.208 (in-sample avg dev_std = 0.367)
NEC for r=1.0 all KL = 0.19 +- 0.208 (in-sample avg dev_std = 0.367)
NEC for r=1.0 all L1 = 0.249 +- 0.200 (in-sample avg dev_std = 0.367)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.373
Model XAI F1 of binarized graphs for r=0.3 =  0.33527
Model XAI WIoU of binarized graphs for r=0.3 =  0.24301125
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.327
NEC for r=0.3 class 0 = 0.514 +- 0.228 (in-sample avg dev_std = 0.333)
NEC for r=0.3 class 1 = 0.368 +- 0.228 (in-sample avg dev_std = 0.333)
NEC for r=0.3 class 2 = 0.445 +- 0.228 (in-sample avg dev_std = 0.333)
NEC for r=0.3 all KL = 0.346 +- 0.228 (in-sample avg dev_std = 0.333)
NEC for r=0.3 all L1 = 0.444 +- 0.171 (in-sample avg dev_std = 0.333)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.48
Model XAI F1 of binarized graphs for r=0.6 =  0.584365
Model XAI WIoU of binarized graphs for r=0.6 =  0.4468237499999999
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.477
NEC for r=0.6 class 0 = 0.604 +- 0.260 (in-sample avg dev_std = 0.542)
NEC for r=0.6 class 1 = 0.511 +- 0.260 (in-sample avg dev_std = 0.542)
NEC for r=0.6 class 2 = 0.621 +- 0.260 (in-sample avg dev_std = 0.542)
NEC for r=0.6 all KL = 0.61 +- 0.260 (in-sample avg dev_std = 0.542)
NEC for r=0.6 all L1 = 0.58 +- 0.155 (in-sample avg dev_std = 0.542)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.65
Model XAI F1 of binarized graphs for r=0.9 =  0.5792587499999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.41902750000000005
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.539
NEC for r=0.9 class 0 = 0.503 +- 0.252 (in-sample avg dev_std = 0.511)
NEC for r=0.9 class 1 = 0.295 +- 0.252 (in-sample avg dev_std = 0.511)
NEC for r=0.9 class 2 = 0.545 +- 0.252 (in-sample avg dev_std = 0.511)
NEC for r=0.9 all KL = 0.438 +- 0.252 (in-sample avg dev_std = 0.511)
NEC for r=0.9 all L1 = 0.451 +- 0.180 (in-sample avg dev_std = 0.511)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.554
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.39755250000000003
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.536
NEC for r=1.0 class 0 = 0.419 +- 0.221 (in-sample avg dev_std = 0.456)
NEC for r=1.0 class 1 = 0.201 +- 0.221 (in-sample avg dev_std = 0.456)
NEC for r=1.0 class 2 = 0.494 +- 0.221 (in-sample avg dev_std = 0.456)
NEC for r=1.0 all KL = 0.346 +- 0.221 (in-sample avg dev_std = 0.456)
NEC for r=1.0 all L1 = 0.375 +- 0.195 (in-sample avg dev_std = 0.456)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.478, 0.519, 0.846, 1.0], 'all_L1': [0.514, 0.543, 0.777, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.544, 0.62, 0.853, 1.0], 'all_L1': [0.516, 0.602, 0.787, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.5, 0.558, 0.854, 1.0], 'all_L1': [0.495, 0.574, 0.799, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.512, 0.586, 0.859, 1.0], 'all_L1': [0.5, 0.584, 0.788, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.552, 0.519, 0.801, 1.0], 'all_L1': [0.541, 0.546, 0.741, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.597, 0.651, 0.648, 0.622], 'all_L1': [0.559, 0.591, 0.574, 0.55]}), defaultdict(<class 'list'>, {'all_KL': [0.549, 0.623, 0.604, 0.54], 'all_L1': [0.575, 0.592, 0.562, 0.512]}), defaultdict(<class 'list'>, {'all_KL': [0.557, 0.611, 0.609, 0.589], 'all_L1': [0.571, 0.565, 0.556, 0.536]}), defaultdict(<class 'list'>, {'all_KL': [0.567, 0.612, 0.616, 0.6], 'all_L1': [0.576, 0.569, 0.555, 0.535]}), defaultdict(<class 'list'>, {'all_KL': [0.545, 0.642, 0.627, 0.596], 'all_L1': [0.552, 0.587, 0.567, 0.54]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.494, 0.589, 0.937, 1.0], 'all_L1': [0.557, 0.652, 0.857, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.551, 0.787, 0.952, 1.0], 'all_L1': [0.611, 0.766, 0.882, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.444, 0.69, 0.913, 1.0], 'all_L1': [0.548, 0.713, 0.838, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.488, 0.634, 0.951, 1.0], 'all_L1': [0.537, 0.68, 0.885, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.517, 0.779, 0.937, 1.0], 'all_L1': [0.559, 0.778, 0.867, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.644, 0.386, 0.327, 0.331], 'all_L1': [0.59, 0.378, 0.382, 0.375]}), defaultdict(<class 'list'>, {'all_KL': [0.662, 0.448, 0.259, 0.225], 'all_L1': [0.602, 0.422, 0.331, 0.305]}), defaultdict(<class 'list'>, {'all_KL': [0.699, 0.416, 0.229, 0.175], 'all_L1': [0.623, 0.4, 0.304, 0.255]}), defaultdict(<class 'list'>, {'all_KL': [0.62, 0.433, 0.265, 0.246], 'all_L1': [0.604, 0.402, 0.332, 0.327]}), defaultdict(<class 'list'>, {'all_KL': [0.579, 0.487, 0.257, 0.19], 'all_L1': [0.579, 0.452, 0.309, 0.249]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.652, 0.514, 0.85, 1.0], 'all_L1': [0.638, 0.525, 0.762, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.619, 0.769, 0.92, 1.0], 'all_L1': [0.524, 0.742, 0.826, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.603, 0.73, 0.894, 1.0], 'all_L1': [0.504, 0.692, 0.805, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.632, 0.664, 0.862, 1.0], 'all_L1': [0.521, 0.618, 0.759, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.723, 0.622, 0.831, 1.0], 'all_L1': [0.615, 0.6, 0.752, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.415, 0.661, 0.481, 0.432], 'all_L1': [0.421, 0.617, 0.5, 0.44]}), defaultdict(<class 'list'>, {'all_KL': [0.462, 0.556, 0.359, 0.3], 'all_L1': [0.547, 0.507, 0.405, 0.352]}), defaultdict(<class 'list'>, {'all_KL': [0.448, 0.581, 0.381, 0.3], 'all_L1': [0.539, 0.546, 0.404, 0.345]}), defaultdict(<class 'list'>, {'all_KL': [0.434, 0.558, 0.359, 0.317], 'all_L1': [0.53, 0.555, 0.416, 0.358]}), defaultdict(<class 'list'>, {'all_KL': [0.346, 0.61, 0.438, 0.346], 'all_L1': [0.444, 0.58, 0.451, 0.375]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.513 +- 0.016, 0.570 +- 0.023, 0.778 +- 0.020, 1.000 +- 0.000
suff++ class all_KL  =  0.517 +- 0.028, 0.560 +- 0.039, 0.843 +- 0.021, 1.000 +- 0.000
suff++_acc_int  =  0.447 +- 0.017, 0.622 +- 0.013, 0.839 +- 0.023
nec class all_L1  =  0.567 +- 0.009, 0.581 +- 0.011, 0.563 +- 0.007, 0.535 +- 0.012
nec class all_KL  =  0.563 +- 0.019, 0.628 +- 0.016, 0.621 +- 0.016, 0.589 +- 0.027
nec_acc_int  =  0.349 +- 0.016, 0.388 +- 0.016, 0.497 +- 0.009, 0.536 +- 0.015

Eval split val
suff++ class all_L1  =  0.562 +- 0.026, 0.718 +- 0.048, 0.866 +- 0.017, 1.000 +- 0.000
suff++ class all_KL  =  0.499 +- 0.035, 0.696 +- 0.078, 0.938 +- 0.014, 1.000 +- 0.000
suff++_acc_int  =  0.396 +- 0.028, 0.787 +- 0.031, 0.829 +- 0.057
nec class all_L1  =  0.600 +- 0.015, 0.411 +- 0.025, 0.332 +- 0.028, 0.302 +- 0.047
nec class all_KL  =  0.641 +- 0.040, 0.434 +- 0.034, 0.267 +- 0.032, 0.233 +- 0.055
nec_acc_int  =  0.262 +- 0.039, 0.450 +- 0.014, 0.599 +- 0.040, 0.593 +- 0.070

Eval split test
suff++ class all_L1  =  0.560 +- 0.055, 0.635 +- 0.075, 0.781 +- 0.029, 1.000 +- 0.000
suff++ class all_KL  =  0.646 +- 0.042, 0.660 +- 0.089, 0.871 +- 0.032, 1.000 +- 0.000
suff++_acc_int  =  0.319 +- 0.026, 0.560 +- 0.049, 0.650 +- 0.017
nec class all_L1  =  0.496 +- 0.053, 0.561 +- 0.037, 0.435 +- 0.037, 0.374 +- 0.034
nec class all_KL  =  0.421 +- 0.041, 0.593 +- 0.039, 0.404 +- 0.048, 0.339 +- 0.049
nec_acc_int  =  0.307 +- 0.029, 0.476 +- 0.015, 0.552 +- 0.015, 0.540 +- 0.011


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.540 +- 0.005, 0.575 +- 0.011, 0.671 +- 0.009, 0.767 +- 0.006
Faith. Armon (L1)= 		  =  0.538 +- 0.006, 0.575 +- 0.012, 0.653 +- 0.006, 0.697 +- 0.011
Faith. GMean (L1)= 	  =  0.539 +- 0.006, 0.575 +- 0.012, 0.662 +- 0.007, 0.731 +- 0.009
Faith. Aritm (KL)= 		  =  0.540 +- 0.007, 0.594 +- 0.015, 0.732 +- 0.011, 0.795 +- 0.014
Faith. Armon (KL)= 		  =  0.538 +- 0.008, 0.591 +- 0.017, 0.715 +- 0.011, 0.741 +- 0.022
Faith. GMean (KL)= 	  =  0.539 +- 0.008, 0.593 +- 0.016, 0.723 +- 0.011, 0.768 +- 0.018

Eval split val
Faith. Aritm (L1)= 		  =  0.581 +- 0.014, 0.564 +- 0.036, 0.599 +- 0.017, 0.651 +- 0.023
Faith. Armon (L1)= 		  =  0.580 +- 0.014, 0.522 +- 0.032, 0.479 +- 0.029, 0.462 +- 0.055
Faith. GMean (L1)= 	  =  0.580 +- 0.014, 0.543 +- 0.034, 0.535 +- 0.023, 0.548 +- 0.042
Faith. Aritm (KL)= 		  =  0.570 +- 0.020, 0.565 +- 0.054, 0.603 +- 0.020, 0.617 +- 0.027
Faith. Armon (KL)= 		  =  0.559 +- 0.022, 0.534 +- 0.046, 0.415 +- 0.039, 0.375 +- 0.070
Faith. GMean (KL)= 	  =  0.564 +- 0.021, 0.549 +- 0.050, 0.500 +- 0.031, 0.480 +- 0.055

Eval split test
Faith. Aritm (L1)= 		  =  0.528 +- 0.005, 0.598 +- 0.020, 0.608 +- 0.015, 0.687 +- 0.017
Faith. Armon (L1)= 		  =  0.521 +- 0.009, 0.591 +- 0.015, 0.557 +- 0.025, 0.544 +- 0.035
Faith. GMean (L1)= 	  =  0.525 +- 0.006, 0.595 +- 0.017, 0.582 +- 0.019, 0.611 +- 0.027
Faith. Aritm (KL)= 		  =  0.533 +- 0.005, 0.627 +- 0.028, 0.637 +- 0.017, 0.669 +- 0.025
Faith. Armon (KL)= 		  =  0.507 +- 0.021, 0.619 +- 0.026, 0.549 +- 0.040, 0.504 +- 0.053
Faith. GMean (KL)= 	  =  0.520 +- 0.011, 0.623 +- 0.027, 0.591 +- 0.028, 0.581 +- 0.041
Computed for split load_split = id



Completed in  0:18:00.332855  for GSATGIN GOODMotif/basis



DONE GSAT GOODMotif/basis

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 19:50:16 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:50:16 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 102...
[0m[1;37mINFO[0m: [1mCheckpoint 102: 
-----------------------------------
Train ACCURACY: 0.8846
Train Loss: 0.4663
ID Validation ACCURACY: 0.8883
ID Validation Loss: 0.4567
ID Test ACCURACY: 0.8753
ID Test Loss: 0.4923
OOD Validation ACCURACY: 0.8767
OOD Validation Loss: 0.5561
OOD Test ACCURACY: 0.8990
OOD Test Loss: 0.4482

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 149...
[0m[1;37mINFO[0m: [1mCheckpoint 149: 
-----------------------------------
Train ACCURACY: 0.8700
Train Loss: 0.4809
ID Validation ACCURACY: 0.8710
ID Validation Loss: 0.4691
ID Test ACCURACY: 0.8660
ID Test Loss: 0.5000
OOD Validation ACCURACY: 0.9313
OOD Validation Loss: 0.4306
OOD Test ACCURACY: 0.6947
OOD Test Loss: 0.8828

[0m[1;37mINFO[0m: [1mChartInfo 0.8753 0.8990 0.8660 0.6947 0.8710 0.9313[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.714
WIoU for r=0.3 = 0.664
F1 for r=0.6 = 0.625
WIoU for r=0.6 = 0.747
F1 for r=0.9 = 0.481
WIoU for r=0.9 = 0.741
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.741
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.668
WIoU for r=0.3 = 0.989
F1 for r=0.6 = 0.409
WIoU for r=0.6 = 0.989
F1 for r=0.9 = 0.295
WIoU for r=0.9 = 0.989
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.989
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.782
WIoU for r=0.3 = 0.908
F1 for r=0.6 = 0.565
WIoU for r=0.6 = 0.958
F1 for r=0.9 = 0.424
WIoU for r=0.9 = 0.956
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.956


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.527
Model XAI F1 of binarized graphs for r=0.3 =  0.71358375
Model XAI WIoU of binarized graphs for r=0.3 =  0.6644225
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.519
SUFF++ for r=0.3 class 0 = 0.566 +- 0.297 (in-sample avg dev_std = 0.524)
SUFF++ for r=0.3 class 1 = 0.544 +- 0.297 (in-sample avg dev_std = 0.524)
SUFF++ for r=0.3 class 2 = 0.526 +- 0.297 (in-sample avg dev_std = 0.524)
SUFF++ for r=0.3 all KL = 0.497 +- 0.297 (in-sample avg dev_std = 0.524)
SUFF++ for r=0.3 all L1 = 0.546 +- 0.200 (in-sample avg dev_std = 0.524)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.892
Model XAI F1 of binarized graphs for r=0.6 =  0.6246137500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.7465437500000001
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.772
SUFF++ for r=0.6 class 0 = 0.706 +- 0.245 (in-sample avg dev_std = 0.386)
SUFF++ for r=0.6 class 1 = 0.665 +- 0.245 (in-sample avg dev_std = 0.386)
SUFF++ for r=0.6 class 2 = 0.686 +- 0.245 (in-sample avg dev_std = 0.386)
SUFF++ for r=0.6 all KL = 0.721 +- 0.245 (in-sample avg dev_std = 0.386)
SUFF++ for r=0.6 all L1 = 0.686 +- 0.202 (in-sample avg dev_std = 0.386)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.897
Model XAI F1 of binarized graphs for r=0.9 =  0.4814387499999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.7407374999999999
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.834
SUFF++ for r=0.9 class 0 = 0.799 +- 0.201 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 class 1 = 0.719 +- 0.201 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 class 2 = 0.804 +- 0.201 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 all KL = 0.852 +- 0.201 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 all L1 = 0.774 +- 0.195 (in-sample avg dev_std = 0.266)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.877
Model XAI F1 of binarized graphs for r=0.3 =  0.668295
Model XAI WIoU of binarized graphs for r=0.3 =  0.9887725
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.658
SUFF++ for r=0.3 class 0 = 0.484 +- 0.292 (in-sample avg dev_std = 0.547)
SUFF++ for r=0.3 class 1 = 0.581 +- 0.292 (in-sample avg dev_std = 0.547)
SUFF++ for r=0.3 class 2 = 0.507 +- 0.292 (in-sample avg dev_std = 0.547)
SUFF++ for r=0.3 all KL = 0.502 +- 0.292 (in-sample avg dev_std = 0.547)
SUFF++ for r=0.3 all L1 = 0.523 +- 0.151 (in-sample avg dev_std = 0.547)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  0.40889125
Model XAI WIoU of binarized graphs for r=0.6 =  0.9887725
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.731
SUFF++ for r=0.6 class 0 = 0.616 +- 0.185 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.6 class 1 = 0.597 +- 0.185 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.6 class 2 = 0.606 +- 0.185 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.6 all KL = 0.721 +- 0.185 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.6 all L1 = 0.607 +- 0.132 (in-sample avg dev_std = 0.362)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.884
Model XAI F1 of binarized graphs for r=0.9 =  0.29531124999999997
Model XAI WIoU of binarized graphs for r=0.9 =  0.9887762500000001
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.801
SUFF++ for r=0.9 class 0 = 0.747 +- 0.143 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.9 class 1 = 0.724 +- 0.143 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.9 class 2 = 0.781 +- 0.143 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.9 all KL = 0.882 +- 0.143 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.9 all L1 = 0.751 +- 0.155 (in-sample avg dev_std = 0.223)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.699
Model XAI F1 of binarized graphs for r=0.3 =  0.7824275
Model XAI WIoU of binarized graphs for r=0.3 =  0.90822125
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.653
SUFF++ for r=0.3 class 0 = 0.618 +- 0.329 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.3 class 1 = 0.68 +- 0.329 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.3 class 2 = 0.638 +- 0.329 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.3 all KL = 0.584 +- 0.329 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.3 all L1 = 0.646 +- 0.212 (in-sample avg dev_std = 0.557)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.899
Model XAI F1 of binarized graphs for r=0.6 =  0.5651437500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.95768625
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.829
SUFF++ for r=0.6 class 0 = 0.783 +- 0.190 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.6 class 1 = 0.695 +- 0.190 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.6 class 2 = 0.822 +- 0.190 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.6 all KL = 0.801 +- 0.190 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.6 all L1 = 0.766 +- 0.148 (in-sample avg dev_std = 0.371)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.899
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.95569125
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.883
SUFF++ for r=0.9 class 0 = 0.908 +- 0.121 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.9 class 1 = 0.804 +- 0.121 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.9 class 2 = 0.875 +- 0.121 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.9 all KL = 0.929 +- 0.121 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.9 all L1 = 0.862 +- 0.156 (in-sample avg dev_std = 0.120)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.527
Model XAI F1 of binarized graphs for r=0.3 =  0.71358375
Model XAI WIoU of binarized graphs for r=0.3 =  0.6644225
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.368
NEC for r=0.3 class 0 = 0.563 +- 0.294 (in-sample avg dev_std = 0.439)
NEC for r=0.3 class 1 = 0.514 +- 0.294 (in-sample avg dev_std = 0.439)
NEC for r=0.3 class 2 = 0.582 +- 0.294 (in-sample avg dev_std = 0.439)
NEC for r=0.3 all KL = 0.591 +- 0.294 (in-sample avg dev_std = 0.439)
NEC for r=0.3 all L1 = 0.553 +- 0.173 (in-sample avg dev_std = 0.439)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.891
Model XAI F1 of binarized graphs for r=0.6 =  0.6246137500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.7465437500000001
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.493
NEC for r=0.6 class 0 = 0.595 +- 0.314 (in-sample avg dev_std = 0.473)
NEC for r=0.6 class 1 = 0.438 +- 0.314 (in-sample avg dev_std = 0.473)
NEC for r=0.6 class 2 = 0.6 +- 0.314 (in-sample avg dev_std = 0.473)
NEC for r=0.6 all KL = 0.553 +- 0.314 (in-sample avg dev_std = 0.473)
NEC for r=0.6 all L1 = 0.544 +- 0.177 (in-sample avg dev_std = 0.473)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.897
Model XAI F1 of binarized graphs for r=0.9 =  0.4814387499999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.7407374999999999
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.608
NEC for r=0.9 class 0 = 0.52 +- 0.302 (in-sample avg dev_std = 0.515)
NEC for r=0.9 class 1 = 0.393 +- 0.302 (in-sample avg dev_std = 0.515)
NEC for r=0.9 class 2 = 0.503 +- 0.302 (in-sample avg dev_std = 0.515)
NEC for r=0.9 all KL = 0.463 +- 0.302 (in-sample avg dev_std = 0.515)
NEC for r=0.9 all L1 = 0.472 +- 0.170 (in-sample avg dev_std = 0.515)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.9
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.7406275
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.603
NEC for r=1.0 class 0 = 0.51 +- 0.296 (in-sample avg dev_std = 0.516)
NEC for r=1.0 class 1 = 0.396 +- 0.296 (in-sample avg dev_std = 0.516)
NEC for r=1.0 class 2 = 0.512 +- 0.296 (in-sample avg dev_std = 0.516)
NEC for r=1.0 all KL = 0.463 +- 0.296 (in-sample avg dev_std = 0.516)
NEC for r=1.0 all L1 = 0.472 +- 0.161 (in-sample avg dev_std = 0.516)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.877
Model XAI F1 of binarized graphs for r=0.3 =  0.668295
Model XAI WIoU of binarized graphs for r=0.3 =  0.9887725
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.372
NEC for r=0.3 class 0 = 0.674 +- 0.283 (in-sample avg dev_std = 0.421)
NEC for r=0.3 class 1 = 0.51 +- 0.283 (in-sample avg dev_std = 0.421)
NEC for r=0.3 class 2 = 0.706 +- 0.283 (in-sample avg dev_std = 0.421)
NEC for r=0.3 all KL = 0.646 +- 0.283 (in-sample avg dev_std = 0.421)
NEC for r=0.3 all L1 = 0.631 +- 0.133 (in-sample avg dev_std = 0.421)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.882
Model XAI F1 of binarized graphs for r=0.6 =  0.40889125
Model XAI WIoU of binarized graphs for r=0.6 =  0.9887725
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.494
NEC for r=0.6 class 0 = 0.532 +- 0.219 (in-sample avg dev_std = 0.468)
NEC for r=0.6 class 1 = 0.472 +- 0.219 (in-sample avg dev_std = 0.468)
NEC for r=0.6 class 2 = 0.565 +- 0.219 (in-sample avg dev_std = 0.468)
NEC for r=0.6 all KL = 0.444 +- 0.219 (in-sample avg dev_std = 0.468)
NEC for r=0.6 all L1 = 0.524 +- 0.113 (in-sample avg dev_std = 0.468)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.884
Model XAI F1 of binarized graphs for r=0.9 =  0.29531124999999997
Model XAI WIoU of binarized graphs for r=0.9 =  0.9887762500000001
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.546
NEC for r=0.9 class 0 = 0.458 +- 0.190 (in-sample avg dev_std = 0.434)
NEC for r=0.9 class 1 = 0.431 +- 0.190 (in-sample avg dev_std = 0.434)
NEC for r=0.9 class 2 = 0.509 +- 0.190 (in-sample avg dev_std = 0.434)
NEC for r=0.9 all KL = 0.349 +- 0.190 (in-sample avg dev_std = 0.434)
NEC for r=0.9 all L1 = 0.466 +- 0.113 (in-sample avg dev_std = 0.434)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.884
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.9887762500000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.569
NEC for r=1.0 class 0 = 0.448 +- 0.195 (in-sample avg dev_std = 0.425)
NEC for r=1.0 class 1 = 0.425 +- 0.195 (in-sample avg dev_std = 0.425)
NEC for r=1.0 class 2 = 0.485 +- 0.195 (in-sample avg dev_std = 0.425)
NEC for r=1.0 all KL = 0.334 +- 0.195 (in-sample avg dev_std = 0.425)
NEC for r=1.0 all L1 = 0.453 +- 0.118 (in-sample avg dev_std = 0.425)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.699
Model XAI F1 of binarized graphs for r=0.3 =  0.7824275
Model XAI WIoU of binarized graphs for r=0.3 =  0.90822125
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.372
NEC for r=0.3 class 0 = 0.665 +- 0.295 (in-sample avg dev_std = 0.482)
NEC for r=0.3 class 1 = 0.475 +- 0.295 (in-sample avg dev_std = 0.482)
NEC for r=0.3 class 2 = 0.616 +- 0.295 (in-sample avg dev_std = 0.482)
NEC for r=0.3 all KL = 0.655 +- 0.295 (in-sample avg dev_std = 0.482)
NEC for r=0.3 all L1 = 0.584 +- 0.149 (in-sample avg dev_std = 0.482)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.899
Model XAI F1 of binarized graphs for r=0.6 =  0.5651437500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.95768625
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.548
NEC for r=0.6 class 0 = 0.509 +- 0.351 (in-sample avg dev_std = 0.493)
NEC for r=0.6 class 1 = 0.352 +- 0.351 (in-sample avg dev_std = 0.493)
NEC for r=0.6 class 2 = 0.547 +- 0.351 (in-sample avg dev_std = 0.493)
NEC for r=0.6 all KL = 0.502 +- 0.351 (in-sample avg dev_std = 0.493)
NEC for r=0.6 all L1 = 0.468 +- 0.203 (in-sample avg dev_std = 0.493)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.899
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.95569125
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.651
NEC for r=0.9 class 0 = 0.422 +- 0.317 (in-sample avg dev_std = 0.531)
NEC for r=0.9 class 1 = 0.286 +- 0.317 (in-sample avg dev_std = 0.531)
NEC for r=0.9 class 2 = 0.439 +- 0.317 (in-sample avg dev_std = 0.531)
NEC for r=0.9 all KL = 0.405 +- 0.317 (in-sample avg dev_std = 0.531)
NEC for r=0.9 all L1 = 0.381 +- 0.190 (in-sample avg dev_std = 0.531)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.899
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.95569125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.678
NEC for r=1.0 class 0 = 0.395 +- 0.316 (in-sample avg dev_std = 0.527)
NEC for r=1.0 class 1 = 0.284 +- 0.316 (in-sample avg dev_std = 0.527)
NEC for r=1.0 class 2 = 0.432 +- 0.316 (in-sample avg dev_std = 0.527)
NEC for r=1.0 all KL = 0.393 +- 0.316 (in-sample avg dev_std = 0.527)
NEC for r=1.0 all L1 = 0.369 +- 0.190 (in-sample avg dev_std = 0.527)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 19:54:11 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:11 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:11 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:11 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:11 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
[1;34mDEBUG[0m: 03/22/2024 07:54:11 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:11 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:11 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:12 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:54:12 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 110...
[0m[1;37mINFO[0m: [1mCheckpoint 110: 
-----------------------------------
Train ACCURACY: 0.8872
Train Loss: 0.4454
ID Validation ACCURACY: 0.8927
ID Validation Loss: 0.4356
ID Test ACCURACY: 0.8933
ID Test Loss: 0.4534
OOD Validation ACCURACY: 0.8837
OOD Validation Loss: 0.4829
OOD Test ACCURACY: 0.8907
OOD Test Loss: 0.4426

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 127...
[0m[1;37mINFO[0m: [1mCheckpoint 127: 
-----------------------------------
Train ACCURACY: 0.8367
Train Loss: 0.5254
ID Validation ACCURACY: 0.8440
ID Validation Loss: 0.5010
ID Test ACCURACY: 0.8350
ID Test Loss: 0.5355
OOD Validation ACCURACY: 0.9210
OOD Validation Loss: 0.5277
OOD Test ACCURACY: 0.8627
OOD Test Loss: 0.5303

[0m[1;37mINFO[0m: [1mChartInfo 0.8933 0.8907 0.8350 0.8627 0.8440 0.9210[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.736
WIoU for r=0.3 = 0.706
F1 for r=0.6 = 0.625
WIoU for r=0.6 = 0.774
F1 for r=0.9 = 0.481
WIoU for r=0.9 = 0.771
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.771
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.669
WIoU for r=0.3 = 0.994
F1 for r=0.6 = 0.409
WIoU for r=0.6 = 0.994
F1 for r=0.9 = 0.295
WIoU for r=0.9 = 0.994
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.994
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.726
WIoU for r=0.3 = 0.842
F1 for r=0.6 = 0.565
WIoU for r=0.6 = 0.846
F1 for r=0.9 = 0.424
WIoU for r=0.9 = 0.795
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.788


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.651
Model XAI F1 of binarized graphs for r=0.3 =  0.7359749999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.705805
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.501
SUFF++ for r=0.3 class 0 = 0.5 +- 0.268 (in-sample avg dev_std = 0.527)
SUFF++ for r=0.3 class 1 = 0.636 +- 0.268 (in-sample avg dev_std = 0.527)
SUFF++ for r=0.3 class 2 = 0.506 +- 0.268 (in-sample avg dev_std = 0.527)
SUFF++ for r=0.3 all KL = 0.488 +- 0.268 (in-sample avg dev_std = 0.527)
SUFF++ for r=0.3 all L1 = 0.548 +- 0.161 (in-sample avg dev_std = 0.527)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.88
Model XAI F1 of binarized graphs for r=0.6 =  0.6250312499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.7738725
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.729
SUFF++ for r=0.6 class 0 = 0.642 +- 0.254 (in-sample avg dev_std = 0.449)
SUFF++ for r=0.6 class 1 = 0.652 +- 0.254 (in-sample avg dev_std = 0.449)
SUFF++ for r=0.6 class 2 = 0.662 +- 0.254 (in-sample avg dev_std = 0.449)
SUFF++ for r=0.6 all KL = 0.64 +- 0.254 (in-sample avg dev_std = 0.449)
SUFF++ for r=0.6 all L1 = 0.652 +- 0.190 (in-sample avg dev_std = 0.449)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.894
Model XAI F1 of binarized graphs for r=0.9 =  0.48110875
Model XAI WIoU of binarized graphs for r=0.9 =  0.7711312499999999
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.832
SUFF++ for r=0.9 class 0 = 0.786 +- 0.205 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.9 class 1 = 0.797 +- 0.205 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.9 class 2 = 0.798 +- 0.205 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.9 all KL = 0.85 +- 0.205 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.9 all L1 = 0.794 +- 0.190 (in-sample avg dev_std = 0.284)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.894
Model XAI F1 of binarized graphs for r=0.3 =  0.6689275000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.99412375
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.605
SUFF++ for r=0.3 class 0 = 0.437 +- 0.290 (in-sample avg dev_std = 0.574)
SUFF++ for r=0.3 class 1 = 0.631 +- 0.290 (in-sample avg dev_std = 0.574)
SUFF++ for r=0.3 class 2 = 0.497 +- 0.290 (in-sample avg dev_std = 0.574)
SUFF++ for r=0.3 all KL = 0.47 +- 0.290 (in-sample avg dev_std = 0.574)
SUFF++ for r=0.3 all L1 = 0.521 +- 0.165 (in-sample avg dev_std = 0.574)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.892
Model XAI F1 of binarized graphs for r=0.6 =  0.40945499999999996
Model XAI WIoU of binarized graphs for r=0.6 =  0.99422125
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.707
SUFF++ for r=0.6 class 0 = 0.585 +- 0.167 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.6 class 1 = 0.612 +- 0.167 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.6 class 2 = 0.608 +- 0.167 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.6 all KL = 0.716 +- 0.167 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.6 all L1 = 0.602 +- 0.112 (in-sample avg dev_std = 0.397)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.894
Model XAI F1 of binarized graphs for r=0.9 =  0.295315
Model XAI WIoU of binarized graphs for r=0.9 =  0.9942025000000001
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.738
SUFF++ for r=0.9 class 0 = 0.716 +- 0.173 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.9 class 1 = 0.74 +- 0.173 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.9 class 2 = 0.578 +- 0.173 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.9 all KL = 0.82 +- 0.173 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.9 all L1 = 0.677 +- 0.160 (in-sample avg dev_std = 0.289)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.561
Model XAI F1 of binarized graphs for r=0.3 =  0.7263150000000002
Model XAI WIoU of binarized graphs for r=0.3 =  0.8424875000000001
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.592
SUFF++ for r=0.3 class 0 = 0.59 +- 0.234 (in-sample avg dev_std = 0.499)
SUFF++ for r=0.3 class 1 = 0.608 +- 0.234 (in-sample avg dev_std = 0.499)
SUFF++ for r=0.3 class 2 = 0.583 +- 0.234 (in-sample avg dev_std = 0.499)
SUFF++ for r=0.3 all KL = 0.621 +- 0.234 (in-sample avg dev_std = 0.499)
SUFF++ for r=0.3 all L1 = 0.594 +- 0.177 (in-sample avg dev_std = 0.499)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.891
Model XAI F1 of binarized graphs for r=0.6 =  0.5651437500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.8456575000000001
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.782
SUFF++ for r=0.6 class 0 = 0.679 +- 0.254 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.6 class 1 = 0.637 +- 0.254 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.6 class 2 = 0.722 +- 0.254 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.6 all KL = 0.682 +- 0.254 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.6 all L1 = 0.679 +- 0.167 (in-sample avg dev_std = 0.470)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.891
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.7951375000000002
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.728
SUFF++ for r=0.9 class 0 = 0.645 +- 0.373 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.9 class 1 = 0.689 +- 0.373 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.9 class 2 = 0.891 +- 0.373 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.9 all KL = 0.716 +- 0.373 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.9 all L1 = 0.742 +- 0.281 (in-sample avg dev_std = 0.466)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.652
Model XAI F1 of binarized graphs for r=0.3 =  0.7359749999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.705805
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.374
NEC for r=0.3 class 0 = 0.553 +- 0.286 (in-sample avg dev_std = 0.392)
NEC for r=0.3 class 1 = 0.505 +- 0.286 (in-sample avg dev_std = 0.392)
NEC for r=0.3 class 2 = 0.592 +- 0.286 (in-sample avg dev_std = 0.392)
NEC for r=0.3 all KL = 0.605 +- 0.286 (in-sample avg dev_std = 0.392)
NEC for r=0.3 all L1 = 0.55 +- 0.154 (in-sample avg dev_std = 0.392)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.88
Model XAI F1 of binarized graphs for r=0.6 =  0.6250312499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.7738725
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.425
NEC for r=0.6 class 0 = 0.564 +- 0.308 (in-sample avg dev_std = 0.450)
NEC for r=0.6 class 1 = 0.534 +- 0.308 (in-sample avg dev_std = 0.450)
NEC for r=0.6 class 2 = 0.615 +- 0.308 (in-sample avg dev_std = 0.450)
NEC for r=0.6 all KL = 0.612 +- 0.308 (in-sample avg dev_std = 0.450)
NEC for r=0.6 all L1 = 0.571 +- 0.161 (in-sample avg dev_std = 0.450)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.894
Model XAI F1 of binarized graphs for r=0.9 =  0.48110875
Model XAI WIoU of binarized graphs for r=0.9 =  0.7711312499999999
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.52
NEC for r=0.9 class 0 = 0.505 +- 0.284 (in-sample avg dev_std = 0.501)
NEC for r=0.9 class 1 = 0.48 +- 0.284 (in-sample avg dev_std = 0.501)
NEC for r=0.9 class 2 = 0.571 +- 0.284 (in-sample avg dev_std = 0.501)
NEC for r=0.9 all KL = 0.524 +- 0.284 (in-sample avg dev_std = 0.501)
NEC for r=0.9 all L1 = 0.519 +- 0.161 (in-sample avg dev_std = 0.501)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.897
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.77129875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.525
NEC for r=1.0 class 0 = 0.51 +- 0.279 (in-sample avg dev_std = 0.499)
NEC for r=1.0 class 1 = 0.482 +- 0.279 (in-sample avg dev_std = 0.499)
NEC for r=1.0 class 2 = 0.543 +- 0.279 (in-sample avg dev_std = 0.499)
NEC for r=1.0 all KL = 0.515 +- 0.279 (in-sample avg dev_std = 0.499)
NEC for r=1.0 all L1 = 0.511 +- 0.158 (in-sample avg dev_std = 0.499)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.894
Model XAI F1 of binarized graphs for r=0.3 =  0.6689275000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.99412375
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.372
NEC for r=0.3 class 0 = 0.659 +- 0.276 (in-sample avg dev_std = 0.437)
NEC for r=0.3 class 1 = 0.521 +- 0.276 (in-sample avg dev_std = 0.437)
NEC for r=0.3 class 2 = 0.734 +- 0.276 (in-sample avg dev_std = 0.437)
NEC for r=0.3 all KL = 0.68 +- 0.276 (in-sample avg dev_std = 0.437)
NEC for r=0.3 all L1 = 0.639 +- 0.141 (in-sample avg dev_std = 0.437)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.892
Model XAI F1 of binarized graphs for r=0.6 =  0.40945499999999996
Model XAI WIoU of binarized graphs for r=0.6 =  0.99422125
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.494
NEC for r=0.6 class 0 = 0.543 +- 0.223 (in-sample avg dev_std = 0.478)
NEC for r=0.6 class 1 = 0.467 +- 0.223 (in-sample avg dev_std = 0.478)
NEC for r=0.6 class 2 = 0.562 +- 0.223 (in-sample avg dev_std = 0.478)
NEC for r=0.6 all KL = 0.441 +- 0.223 (in-sample avg dev_std = 0.478)
NEC for r=0.6 all L1 = 0.525 +- 0.123 (in-sample avg dev_std = 0.478)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.894
Model XAI F1 of binarized graphs for r=0.9 =  0.295315
Model XAI WIoU of binarized graphs for r=0.9 =  0.9942025000000001
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.542
NEC for r=0.9 class 0 = 0.483 +- 0.195 (in-sample avg dev_std = 0.445)
NEC for r=0.9 class 1 = 0.434 +- 0.195 (in-sample avg dev_std = 0.445)
NEC for r=0.9 class 2 = 0.482 +- 0.195 (in-sample avg dev_std = 0.445)
NEC for r=0.9 all KL = 0.346 +- 0.195 (in-sample avg dev_std = 0.445)
NEC for r=0.9 all L1 = 0.467 +- 0.117 (in-sample avg dev_std = 0.445)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.894
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.9941987499999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.555
NEC for r=1.0 class 0 = 0.47 +- 0.192 (in-sample avg dev_std = 0.441)
NEC for r=1.0 class 1 = 0.423 +- 0.192 (in-sample avg dev_std = 0.441)
NEC for r=1.0 class 2 = 0.478 +- 0.192 (in-sample avg dev_std = 0.441)
NEC for r=1.0 all KL = 0.334 +- 0.192 (in-sample avg dev_std = 0.441)
NEC for r=1.0 all L1 = 0.457 +- 0.115 (in-sample avg dev_std = 0.441)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.558
Model XAI F1 of binarized graphs for r=0.3 =  0.7263150000000002
Model XAI WIoU of binarized graphs for r=0.3 =  0.8424875000000001
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.44
NEC for r=0.3 class 0 = 0.484 +- 0.224 (in-sample avg dev_std = 0.474)
NEC for r=0.3 class 1 = 0.503 +- 0.224 (in-sample avg dev_std = 0.474)
NEC for r=0.3 class 2 = 0.581 +- 0.224 (in-sample avg dev_std = 0.474)
NEC for r=0.3 all KL = 0.479 +- 0.224 (in-sample avg dev_std = 0.474)
NEC for r=0.3 all L1 = 0.523 +- 0.127 (in-sample avg dev_std = 0.474)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.891
Model XAI F1 of binarized graphs for r=0.6 =  0.5651437500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.8456575000000001
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.523
NEC for r=0.6 class 0 = 0.432 +- 0.344 (in-sample avg dev_std = 0.522)
NEC for r=0.6 class 1 = 0.476 +- 0.344 (in-sample avg dev_std = 0.522)
NEC for r=0.6 class 2 = 0.528 +- 0.344 (in-sample avg dev_std = 0.522)
NEC for r=0.6 all KL = 0.474 +- 0.344 (in-sample avg dev_std = 0.522)
NEC for r=0.6 all L1 = 0.479 +- 0.201 (in-sample avg dev_std = 0.522)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.891
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.7951375000000002
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.603
NEC for r=0.9 class 0 = 0.414 +- 0.330 (in-sample avg dev_std = 0.576)
NEC for r=0.9 class 1 = 0.443 +- 0.330 (in-sample avg dev_std = 0.576)
NEC for r=0.9 class 2 = 0.444 +- 0.330 (in-sample avg dev_std = 0.576)
NEC for r=0.9 all KL = 0.446 +- 0.330 (in-sample avg dev_std = 0.576)
NEC for r=0.9 all L1 = 0.434 +- 0.194 (in-sample avg dev_std = 0.576)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.891
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.7882975000000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.603
NEC for r=1.0 class 0 = 0.419 +- 0.324 (in-sample avg dev_std = 0.576)
NEC for r=1.0 class 1 = 0.435 +- 0.324 (in-sample avg dev_std = 0.576)
NEC for r=1.0 class 2 = 0.44 +- 0.324 (in-sample avg dev_std = 0.576)
NEC for r=1.0 all KL = 0.444 +- 0.324 (in-sample avg dev_std = 0.576)
NEC for r=1.0 all L1 = 0.431 +- 0.186 (in-sample avg dev_std = 0.576)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 19:58:01 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 07:58:01 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 138...
[0m[1;37mINFO[0m: [1mCheckpoint 138: 
-----------------------------------
Train ACCURACY: 0.9123
Train Loss: 0.4007
ID Validation ACCURACY: 0.9150
ID Validation Loss: 0.3813
ID Test ACCURACY: 0.9053
ID Test Loss: 0.4430
OOD Validation ACCURACY: 0.9293
OOD Validation Loss: 0.3879
OOD Test ACCURACY: 0.7097
OOD Test Loss: 0.7779

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 129...
[0m[1;37mINFO[0m: [1mCheckpoint 129: 
-----------------------------------
Train ACCURACY: 0.8903
Train Loss: 0.4322
ID Validation ACCURACY: 0.8910
ID Validation Loss: 0.4222
ID Test ACCURACY: 0.8893
ID Test Loss: 0.4666
OOD Validation ACCURACY: 0.9303
OOD Validation Loss: 0.3953
OOD Test ACCURACY: 0.8417
OOD Test Loss: 0.6994

[0m[1;37mINFO[0m: [1mChartInfo 0.9053 0.7097 0.8893 0.8417 0.8910 0.9303[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.678
WIoU for r=0.3 = 0.597
F1 for r=0.6 = 0.610
WIoU for r=0.6 = 0.691
F1 for r=0.9 = 0.481
WIoU for r=0.9 = 0.703
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.703
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.669
WIoU for r=0.3 = 0.994
F1 for r=0.6 = 0.410
WIoU for r=0.6 = 0.994
F1 for r=0.9 = 0.295
WIoU for r=0.9 = 0.994
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.994
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.782
WIoU for r=0.3 = 0.880
F1 for r=0.6 = 0.544
WIoU for r=0.6 = 0.750
F1 for r=0.9 = 0.424
WIoU for r=0.9 = 0.694
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.691


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.504
Model XAI F1 of binarized graphs for r=0.3 =  0.67808875
Model XAI WIoU of binarized graphs for r=0.3 =  0.5967325
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.423
SUFF++ for r=0.3 class 0 = 0.502 +- 0.248 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.3 class 1 = 0.526 +- 0.248 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.3 class 2 = 0.46 +- 0.248 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.3 all KL = 0.44 +- 0.248 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.3 all L1 = 0.496 +- 0.152 (in-sample avg dev_std = 0.555)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.86
Model XAI F1 of binarized graphs for r=0.6 =  0.61004875
Model XAI WIoU of binarized graphs for r=0.6 =  0.6905325000000001
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.744
SUFF++ for r=0.6 class 0 = 0.636 +- 0.287 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.6 class 1 = 0.67 +- 0.287 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.6 class 2 = 0.69 +- 0.287 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.6 all KL = 0.629 +- 0.287 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.6 all L1 = 0.665 +- 0.212 (in-sample avg dev_std = 0.469)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.923
Model XAI F1 of binarized graphs for r=0.9 =  0.48117374999999996
Model XAI WIoU of binarized graphs for r=0.9 =  0.70282375
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.858
SUFF++ for r=0.9 class 0 = 0.8 +- 0.198 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 1 = 0.795 +- 0.198 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 2 = 0.83 +- 0.198 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 all KL = 0.848 +- 0.198 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 all L1 = 0.808 +- 0.177 (in-sample avg dev_std = 0.253)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.928
Model XAI F1 of binarized graphs for r=0.3 =  0.6694275000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.9939325
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.613
SUFF++ for r=0.3 class 0 = 0.486 +- 0.288 (in-sample avg dev_std = 0.658)
SUFF++ for r=0.3 class 1 = 0.634 +- 0.288 (in-sample avg dev_std = 0.658)
SUFF++ for r=0.3 class 2 = 0.423 +- 0.288 (in-sample avg dev_std = 0.658)
SUFF++ for r=0.3 all KL = 0.378 +- 0.288 (in-sample avg dev_std = 0.658)
SUFF++ for r=0.3 all L1 = 0.513 +- 0.170 (in-sample avg dev_std = 0.658)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.928
Model XAI F1 of binarized graphs for r=0.6 =  0.40952875000000005
Model XAI WIoU of binarized graphs for r=0.6 =  0.9939325
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.729
SUFF++ for r=0.6 class 0 = 0.595 +- 0.205 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.6 class 1 = 0.614 +- 0.205 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.6 class 2 = 0.652 +- 0.205 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.6 all KL = 0.669 +- 0.205 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.6 all L1 = 0.621 +- 0.138 (in-sample avg dev_std = 0.466)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.929
Model XAI F1 of binarized graphs for r=0.9 =  0.29536875
Model XAI WIoU of binarized graphs for r=0.9 =  0.9939325
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.846
SUFF++ for r=0.9 class 0 = 0.753 +- 0.177 (in-sample avg dev_std = 0.290)
SUFF++ for r=0.9 class 1 = 0.761 +- 0.177 (in-sample avg dev_std = 0.290)
SUFF++ for r=0.9 class 2 = 0.816 +- 0.177 (in-sample avg dev_std = 0.290)
SUFF++ for r=0.9 all KL = 0.872 +- 0.177 (in-sample avg dev_std = 0.290)
SUFF++ for r=0.9 all L1 = 0.776 +- 0.147 (in-sample avg dev_std = 0.290)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.493
Model XAI F1 of binarized graphs for r=0.3 =  0.782
Model XAI WIoU of binarized graphs for r=0.3 =  0.8802100000000002
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.586
SUFF++ for r=0.3 class 0 = 0.607 +- 0.298 (in-sample avg dev_std = 0.544)
SUFF++ for r=0.3 class 1 = 0.657 +- 0.298 (in-sample avg dev_std = 0.544)
SUFF++ for r=0.3 class 2 = 0.558 +- 0.298 (in-sample avg dev_std = 0.544)
SUFF++ for r=0.3 all KL = 0.563 +- 0.298 (in-sample avg dev_std = 0.544)
SUFF++ for r=0.3 all L1 = 0.608 +- 0.180 (in-sample avg dev_std = 0.544)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.87
Model XAI F1 of binarized graphs for r=0.6 =  0.5438937500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.7503025
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.739
SUFF++ for r=0.6 class 0 = 0.609 +- 0.344 (in-sample avg dev_std = 0.578)
SUFF++ for r=0.6 class 1 = 0.703 +- 0.344 (in-sample avg dev_std = 0.578)
SUFF++ for r=0.6 class 2 = 0.636 +- 0.344 (in-sample avg dev_std = 0.578)
SUFF++ for r=0.6 all KL = 0.592 +- 0.344 (in-sample avg dev_std = 0.578)
SUFF++ for r=0.6 all L1 = 0.65 +- 0.199 (in-sample avg dev_std = 0.578)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.666
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.6935862500000001
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.837
SUFF++ for r=0.9 class 0 = 0.659 +- 0.312 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.9 class 1 = 0.735 +- 0.312 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.9 class 2 = 0.911 +- 0.312 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.9 all KL = 0.745 +- 0.312 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.9 all L1 = 0.77 +- 0.288 (in-sample avg dev_std = 0.304)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.504
Model XAI F1 of binarized graphs for r=0.3 =  0.67808875
Model XAI WIoU of binarized graphs for r=0.3 =  0.5967325
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.34
NEC for r=0.3 class 0 = 0.582 +- 0.280 (in-sample avg dev_std = 0.464)
NEC for r=0.3 class 1 = 0.545 +- 0.280 (in-sample avg dev_std = 0.464)
NEC for r=0.3 class 2 = 0.579 +- 0.280 (in-sample avg dev_std = 0.464)
NEC for r=0.3 all KL = 0.607 +- 0.280 (in-sample avg dev_std = 0.464)
NEC for r=0.3 all L1 = 0.569 +- 0.161 (in-sample avg dev_std = 0.464)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.86
Model XAI F1 of binarized graphs for r=0.6 =  0.61004875
Model XAI WIoU of binarized graphs for r=0.6 =  0.6905325000000001
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.44
NEC for r=0.6 class 0 = 0.585 +- 0.281 (in-sample avg dev_std = 0.539)
NEC for r=0.6 class 1 = 0.521 +- 0.281 (in-sample avg dev_std = 0.539)
NEC for r=0.6 class 2 = 0.634 +- 0.281 (in-sample avg dev_std = 0.539)
NEC for r=0.6 all KL = 0.643 +- 0.281 (in-sample avg dev_std = 0.539)
NEC for r=0.6 all L1 = 0.58 +- 0.165 (in-sample avg dev_std = 0.539)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.923
Model XAI F1 of binarized graphs for r=0.9 =  0.48117374999999996
Model XAI WIoU of binarized graphs for r=0.9 =  0.70282375
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.524
NEC for r=0.9 class 0 = 0.53 +- 0.296 (in-sample avg dev_std = 0.575)
NEC for r=0.9 class 1 = 0.479 +- 0.296 (in-sample avg dev_std = 0.575)
NEC for r=0.9 class 2 = 0.58 +- 0.296 (in-sample avg dev_std = 0.575)
NEC for r=0.9 all KL = 0.571 +- 0.296 (in-sample avg dev_std = 0.575)
NEC for r=0.9 all L1 = 0.529 +- 0.169 (in-sample avg dev_std = 0.575)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.926
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.7028725
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.552
NEC for r=1.0 class 0 = 0.527 +- 0.285 (in-sample avg dev_std = 0.577)
NEC for r=1.0 class 1 = 0.469 +- 0.285 (in-sample avg dev_std = 0.577)
NEC for r=1.0 class 2 = 0.553 +- 0.285 (in-sample avg dev_std = 0.577)
NEC for r=1.0 all KL = 0.555 +- 0.285 (in-sample avg dev_std = 0.577)
NEC for r=1.0 all L1 = 0.516 +- 0.163 (in-sample avg dev_std = 0.577)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.928
Model XAI F1 of binarized graphs for r=0.3 =  0.6694275000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.9939325
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.383
NEC for r=0.3 class 0 = 0.669 +- 0.222 (in-sample avg dev_std = 0.495)
NEC for r=0.3 class 1 = 0.568 +- 0.222 (in-sample avg dev_std = 0.495)
NEC for r=0.3 class 2 = 0.763 +- 0.222 (in-sample avg dev_std = 0.495)
NEC for r=0.3 all KL = 0.776 +- 0.222 (in-sample avg dev_std = 0.495)
NEC for r=0.3 all L1 = 0.668 +- 0.127 (in-sample avg dev_std = 0.495)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.928
Model XAI F1 of binarized graphs for r=0.6 =  0.40952875000000005
Model XAI WIoU of binarized graphs for r=0.6 =  0.9939325
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.508
NEC for r=0.6 class 0 = 0.549 +- 0.243 (in-sample avg dev_std = 0.561)
NEC for r=0.6 class 1 = 0.471 +- 0.243 (in-sample avg dev_std = 0.561)
NEC for r=0.6 class 2 = 0.623 +- 0.243 (in-sample avg dev_std = 0.561)
NEC for r=0.6 all KL = 0.533 +- 0.243 (in-sample avg dev_std = 0.561)
NEC for r=0.6 all L1 = 0.548 +- 0.137 (in-sample avg dev_std = 0.561)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.929
Model XAI F1 of binarized graphs for r=0.9 =  0.29536875
Model XAI WIoU of binarized graphs for r=0.9 =  0.9939325
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.569
NEC for r=0.9 class 0 = 0.47 +- 0.205 (in-sample avg dev_std = 0.521)
NEC for r=0.9 class 1 = 0.466 +- 0.205 (in-sample avg dev_std = 0.521)
NEC for r=0.9 class 2 = 0.51 +- 0.205 (in-sample avg dev_std = 0.521)
NEC for r=0.9 all KL = 0.405 +- 0.205 (in-sample avg dev_std = 0.521)
NEC for r=0.9 all L1 = 0.482 +- 0.120 (in-sample avg dev_std = 0.521)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.929
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.9939325
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.585
NEC for r=1.0 class 0 = 0.469 +- 0.204 (in-sample avg dev_std = 0.518)
NEC for r=1.0 class 1 = 0.47 +- 0.204 (in-sample avg dev_std = 0.518)
NEC for r=1.0 class 2 = 0.482 +- 0.204 (in-sample avg dev_std = 0.518)
NEC for r=1.0 all KL = 0.397 +- 0.204 (in-sample avg dev_std = 0.518)
NEC for r=1.0 all L1 = 0.474 +- 0.121 (in-sample avg dev_std = 0.518)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.493
Model XAI F1 of binarized graphs for r=0.3 =  0.782
Model XAI WIoU of binarized graphs for r=0.3 =  0.8802100000000002
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.404
NEC for r=0.3 class 0 = 0.547 +- 0.268 (in-sample avg dev_std = 0.558)
NEC for r=0.3 class 1 = 0.445 +- 0.268 (in-sample avg dev_std = 0.558)
NEC for r=0.3 class 2 = 0.608 +- 0.268 (in-sample avg dev_std = 0.558)
NEC for r=0.3 all KL = 0.587 +- 0.268 (in-sample avg dev_std = 0.558)
NEC for r=0.3 all L1 = 0.533 +- 0.134 (in-sample avg dev_std = 0.558)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.869
Model XAI F1 of binarized graphs for r=0.6 =  0.5438937500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.7503025
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.578
NEC for r=0.6 class 0 = 0.41 +- 0.357 (in-sample avg dev_std = 0.597)
NEC for r=0.6 class 1 = 0.469 +- 0.357 (in-sample avg dev_std = 0.597)
NEC for r=0.6 class 2 = 0.546 +- 0.357 (in-sample avg dev_std = 0.597)
NEC for r=0.6 all KL = 0.526 +- 0.357 (in-sample avg dev_std = 0.597)
NEC for r=0.6 all L1 = 0.475 +- 0.232 (in-sample avg dev_std = 0.597)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.665
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.6935862500000001
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.634
NEC for r=0.9 class 0 = 0.41 +- 0.309 (in-sample avg dev_std = 0.540)
NEC for r=0.9 class 1 = 0.407 +- 0.309 (in-sample avg dev_std = 0.540)
NEC for r=0.9 class 2 = 0.351 +- 0.309 (in-sample avg dev_std = 0.540)
NEC for r=0.9 all KL = 0.442 +- 0.309 (in-sample avg dev_std = 0.540)
NEC for r=0.9 all L1 = 0.389 +- 0.195 (in-sample avg dev_std = 0.540)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.71
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.69095
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.638
NEC for r=1.0 class 0 = 0.403 +- 0.298 (in-sample avg dev_std = 0.536)
NEC for r=1.0 class 1 = 0.427 +- 0.298 (in-sample avg dev_std = 0.536)
NEC for r=1.0 class 2 = 0.326 +- 0.298 (in-sample avg dev_std = 0.536)
NEC for r=1.0 all KL = 0.441 +- 0.298 (in-sample avg dev_std = 0.536)
NEC for r=1.0 all L1 = 0.386 +- 0.199 (in-sample avg dev_std = 0.536)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 20:01:50 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:01:50 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 120...
[0m[1;37mINFO[0m: [1mCheckpoint 120: 
-----------------------------------
Train ACCURACY: 0.8893
Train Loss: 0.5315
ID Validation ACCURACY: 0.8940
ID Validation Loss: 0.5268
ID Test ACCURACY: 0.8807
ID Test Loss: 0.5595
OOD Validation ACCURACY: 0.8480
OOD Validation Loss: 0.5785
OOD Test ACCURACY: 0.9053
OOD Test Loss: 0.4997

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 116...
[0m[1;37mINFO[0m: [1mCheckpoint 116: 
-----------------------------------
Train ACCURACY: 0.8415
Train Loss: 0.5162
ID Validation ACCURACY: 0.8440
ID Validation Loss: 0.4990
ID Test ACCURACY: 0.8423
ID Test Loss: 0.5364
OOD Validation ACCURACY: 0.9043
OOD Validation Loss: 0.5293
OOD Test ACCURACY: 0.7010
OOD Test Loss: 0.9220

[0m[1;37mINFO[0m: [1mChartInfo 0.8807 0.9053 0.8423 0.7010 0.8440 0.9043[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.750
WIoU for r=0.3 = 0.849
F1 for r=0.6 = 0.616
WIoU for r=0.6 = 0.907
F1 for r=0.9 = 0.481
WIoU for r=0.9 = 0.910
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.910
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.669
WIoU for r=0.3 = 0.995
F1 for r=0.6 = 0.410
WIoU for r=0.6 = 0.995
F1 for r=0.9 = 0.295
WIoU for r=0.9 = 0.995
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.995
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.752
WIoU for r=0.3 = 0.847
F1 for r=0.6 = 0.555
WIoU for r=0.6 = 0.845
F1 for r=0.9 = 0.424
WIoU for r=0.9 = 0.845
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.845


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.673
Model XAI F1 of binarized graphs for r=0.3 =  0.75049875
Model XAI WIoU of binarized graphs for r=0.3 =  0.8490125000000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.519
SUFF++ for r=0.3 class 0 = 0.53 +- 0.295 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.3 class 1 = 0.664 +- 0.295 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.3 class 2 = 0.524 +- 0.295 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.3 all KL = 0.579 +- 0.295 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.3 all L1 = 0.573 +- 0.162 (in-sample avg dev_std = 0.463)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.897
Model XAI F1 of binarized graphs for r=0.6 =  0.61591
Model XAI WIoU of binarized graphs for r=0.6 =  0.90689125
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.756
SUFF++ for r=0.6 class 0 = 0.626 +- 0.196 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.6 class 1 = 0.749 +- 0.196 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.6 class 2 = 0.773 +- 0.196 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.6 all KL = 0.8 +- 0.196 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.6 all L1 = 0.716 +- 0.176 (in-sample avg dev_std = 0.319)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.902
Model XAI F1 of binarized graphs for r=0.9 =  0.48057625000000004
Model XAI WIoU of binarized graphs for r=0.9 =  0.90993125
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.864
SUFF++ for r=0.9 class 0 = 0.827 +- 0.102 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.9 class 1 = 0.851 +- 0.102 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.9 class 2 = 0.893 +- 0.102 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.9 all KL = 0.937 +- 0.102 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.9 all L1 = 0.857 +- 0.134 (in-sample avg dev_std = 0.174)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.905
Model XAI F1 of binarized graphs for r=0.3 =  0.6692275000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.9953387499999999
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.647
SUFF++ for r=0.3 class 0 = 0.543 +- 0.287 (in-sample avg dev_std = 0.431)
SUFF++ for r=0.3 class 1 = 0.691 +- 0.287 (in-sample avg dev_std = 0.431)
SUFF++ for r=0.3 class 2 = 0.652 +- 0.287 (in-sample avg dev_std = 0.431)
SUFF++ for r=0.3 all KL = 0.657 +- 0.287 (in-sample avg dev_std = 0.431)
SUFF++ for r=0.3 all L1 = 0.628 +- 0.185 (in-sample avg dev_std = 0.431)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  0.40952875000000005
Model XAI WIoU of binarized graphs for r=0.6 =  0.9953387499999999
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.758
SUFF++ for r=0.6 class 0 = 0.686 +- 0.138 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.6 class 1 = 0.729 +- 0.138 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.6 class 2 = 0.743 +- 0.138 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.6 all KL = 0.853 +- 0.138 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.6 all L1 = 0.719 +- 0.121 (in-sample avg dev_std = 0.271)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.868
Model XAI F1 of binarized graphs for r=0.9 =  0.29536875
Model XAI WIoU of binarized graphs for r=0.9 =  0.9953387499999999
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.798
SUFF++ for r=0.9 class 0 = 0.747 +- 0.107 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 class 1 = 0.781 +- 0.107 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 class 2 = 0.846 +- 0.107 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 all KL = 0.914 +- 0.107 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 all L1 = 0.791 +- 0.119 (in-sample avg dev_std = 0.237)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.744
Model XAI F1 of binarized graphs for r=0.3 =  0.7515675000000002
Model XAI WIoU of binarized graphs for r=0.3 =  0.8466300000000001
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.542
SUFF++ for r=0.3 class 0 = 0.515 +- 0.310 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.3 class 1 = 0.665 +- 0.310 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.3 class 2 = 0.591 +- 0.310 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.3 all KL = 0.591 +- 0.310 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.3 all L1 = 0.592 +- 0.173 (in-sample avg dev_std = 0.488)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.897
Model XAI F1 of binarized graphs for r=0.6 =  0.5545187500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.84512
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.722
SUFF++ for r=0.6 class 0 = 0.582 +- 0.210 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.6 class 1 = 0.786 +- 0.210 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.6 class 2 = 0.803 +- 0.210 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.6 all KL = 0.784 +- 0.210 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.6 all L1 = 0.726 +- 0.184 (in-sample avg dev_std = 0.365)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.897
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.84512
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.811
SUFF++ for r=0.9 class 0 = 0.771 +- 0.090 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.9 class 1 = 0.862 +- 0.090 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.9 class 2 = 0.935 +- 0.090 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.9 all KL = 0.928 +- 0.090 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.9 all L1 = 0.857 +- 0.148 (in-sample avg dev_std = 0.185)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.669
Model XAI F1 of binarized graphs for r=0.3 =  0.75049875
Model XAI WIoU of binarized graphs for r=0.3 =  0.8490125000000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.35
NEC for r=0.3 class 0 = 0.451 +- 0.345 (in-sample avg dev_std = 0.380)
NEC for r=0.3 class 1 = 0.472 +- 0.345 (in-sample avg dev_std = 0.380)
NEC for r=0.3 class 2 = 0.596 +- 0.345 (in-sample avg dev_std = 0.380)
NEC for r=0.3 all KL = 0.49 +- 0.345 (in-sample avg dev_std = 0.380)
NEC for r=0.3 all L1 = 0.506 +- 0.179 (in-sample avg dev_std = 0.380)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.897
Model XAI F1 of binarized graphs for r=0.6 =  0.61591
Model XAI WIoU of binarized graphs for r=0.6 =  0.90689125
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.465
NEC for r=0.6 class 0 = 0.419 +- 0.305 (in-sample avg dev_std = 0.451)
NEC for r=0.6 class 1 = 0.445 +- 0.305 (in-sample avg dev_std = 0.451)
NEC for r=0.6 class 2 = 0.588 +- 0.305 (in-sample avg dev_std = 0.451)
NEC for r=0.6 all KL = 0.438 +- 0.305 (in-sample avg dev_std = 0.451)
NEC for r=0.6 all L1 = 0.484 +- 0.175 (in-sample avg dev_std = 0.451)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.902
Model XAI F1 of binarized graphs for r=0.9 =  0.48057625000000004
Model XAI WIoU of binarized graphs for r=0.9 =  0.90993125
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.545
NEC for r=0.9 class 0 = 0.365 +- 0.294 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 1 = 0.381 +- 0.294 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 2 = 0.527 +- 0.294 (in-sample avg dev_std = 0.458)
NEC for r=0.9 all KL = 0.353 +- 0.294 (in-sample avg dev_std = 0.458)
NEC for r=0.9 all L1 = 0.424 +- 0.173 (in-sample avg dev_std = 0.458)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.902
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.90993125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.556
NEC for r=1.0 class 0 = 0.372 +- 0.295 (in-sample avg dev_std = 0.462)
NEC for r=1.0 class 1 = 0.371 +- 0.295 (in-sample avg dev_std = 0.462)
NEC for r=1.0 class 2 = 0.511 +- 0.295 (in-sample avg dev_std = 0.462)
NEC for r=1.0 all KL = 0.347 +- 0.295 (in-sample avg dev_std = 0.462)
NEC for r=1.0 all L1 = 0.417 +- 0.171 (in-sample avg dev_std = 0.462)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.906
Model XAI F1 of binarized graphs for r=0.3 =  0.6692275000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.9953387499999999
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.398
NEC for r=0.3 class 0 = 0.449 +- 0.332 (in-sample avg dev_std = 0.398)
NEC for r=0.3 class 1 = 0.485 +- 0.332 (in-sample avg dev_std = 0.398)
NEC for r=0.3 class 2 = 0.72 +- 0.332 (in-sample avg dev_std = 0.398)
NEC for r=0.3 all KL = 0.537 +- 0.332 (in-sample avg dev_std = 0.398)
NEC for r=0.3 all L1 = 0.552 +- 0.187 (in-sample avg dev_std = 0.398)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  0.40952875000000005
Model XAI WIoU of binarized graphs for r=0.6 =  0.9953387499999999
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.526
NEC for r=0.6 class 0 = 0.372 +- 0.266 (in-sample avg dev_std = 0.431)
NEC for r=0.6 class 1 = 0.366 +- 0.266 (in-sample avg dev_std = 0.431)
NEC for r=0.6 class 2 = 0.577 +- 0.266 (in-sample avg dev_std = 0.431)
NEC for r=0.6 all KL = 0.336 +- 0.266 (in-sample avg dev_std = 0.431)
NEC for r=0.6 all L1 = 0.439 +- 0.164 (in-sample avg dev_std = 0.431)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.868
Model XAI F1 of binarized graphs for r=0.9 =  0.29536875
Model XAI WIoU of binarized graphs for r=0.9 =  0.9953387499999999
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.605
NEC for r=0.9 class 0 = 0.324 +- 0.193 (in-sample avg dev_std = 0.374)
NEC for r=0.9 class 1 = 0.311 +- 0.193 (in-sample avg dev_std = 0.374)
NEC for r=0.9 class 2 = 0.45 +- 0.193 (in-sample avg dev_std = 0.374)
NEC for r=0.9 all KL = 0.221 +- 0.193 (in-sample avg dev_std = 0.374)
NEC for r=0.9 all L1 = 0.362 +- 0.143 (in-sample avg dev_std = 0.374)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.868
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.9953387499999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.595
NEC for r=1.0 class 0 = 0.335 +- 0.190 (in-sample avg dev_std = 0.387)
NEC for r=1.0 class 1 = 0.311 +- 0.190 (in-sample avg dev_std = 0.387)
NEC for r=1.0 class 2 = 0.45 +- 0.190 (in-sample avg dev_std = 0.387)
NEC for r=1.0 all KL = 0.225 +- 0.190 (in-sample avg dev_std = 0.387)
NEC for r=1.0 all L1 = 0.366 +- 0.137 (in-sample avg dev_std = 0.387)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.744
Model XAI F1 of binarized graphs for r=0.3 =  0.7515675000000002
Model XAI WIoU of binarized graphs for r=0.3 =  0.8466300000000001
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.33
NEC for r=0.3 class 0 = 0.482 +- 0.320 (in-sample avg dev_std = 0.414)
NEC for r=0.3 class 1 = 0.485 +- 0.320 (in-sample avg dev_std = 0.414)
NEC for r=0.3 class 2 = 0.584 +- 0.320 (in-sample avg dev_std = 0.414)
NEC for r=0.3 all KL = 0.526 +- 0.320 (in-sample avg dev_std = 0.414)
NEC for r=0.3 all L1 = 0.517 +- 0.156 (in-sample avg dev_std = 0.414)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.897
Model XAI F1 of binarized graphs for r=0.6 =  0.5545187500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.84512
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.536
NEC for r=0.6 class 0 = 0.348 +- 0.345 (in-sample avg dev_std = 0.469)
NEC for r=0.6 class 1 = 0.406 +- 0.345 (in-sample avg dev_std = 0.469)
NEC for r=0.6 class 2 = 0.542 +- 0.345 (in-sample avg dev_std = 0.469)
NEC for r=0.6 all KL = 0.405 +- 0.345 (in-sample avg dev_std = 0.469)
NEC for r=0.6 all L1 = 0.433 +- 0.202 (in-sample avg dev_std = 0.469)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.897
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.84512
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.602
NEC for r=0.9 class 0 = 0.356 +- 0.306 (in-sample avg dev_std = 0.510)
NEC for r=0.9 class 1 = 0.348 +- 0.306 (in-sample avg dev_std = 0.510)
NEC for r=0.9 class 2 = 0.46 +- 0.306 (in-sample avg dev_std = 0.510)
NEC for r=0.9 all KL = 0.36 +- 0.306 (in-sample avg dev_std = 0.510)
NEC for r=0.9 all L1 = 0.388 +- 0.182 (in-sample avg dev_std = 0.510)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.897
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.84512
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.598
NEC for r=1.0 class 0 = 0.369 +- 0.305 (in-sample avg dev_std = 0.511)
NEC for r=1.0 class 1 = 0.355 +- 0.305 (in-sample avg dev_std = 0.511)
NEC for r=1.0 class 2 = 0.458 +- 0.305 (in-sample avg dev_std = 0.511)
NEC for r=1.0 all KL = 0.366 +- 0.305 (in-sample avg dev_std = 0.511)
NEC for r=1.0 all L1 = 0.394 +- 0.182 (in-sample avg dev_std = 0.511)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 20:05:42 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:05:42 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 109...
[0m[1;37mINFO[0m: [1mCheckpoint 109: 
-----------------------------------
Train ACCURACY: 0.8887
Train Loss: 0.4987
ID Validation ACCURACY: 0.8910
ID Validation Loss: 0.4744
ID Test ACCURACY: 0.8860
ID Test Loss: 0.5215
OOD Validation ACCURACY: 0.8970
OOD Validation Loss: 0.5042
OOD Test ACCURACY: 0.8647
OOD Test Loss: 0.5045

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 119...
[0m[1;37mINFO[0m: [1mCheckpoint 119: 
-----------------------------------
Train ACCURACY: 0.7957
Train Loss: 0.6628
ID Validation ACCURACY: 0.7933
ID Validation Loss: 0.6550
ID Test ACCURACY: 0.7830
ID Test Loss: 0.7186
OOD Validation ACCURACY: 0.9107
OOD Validation Loss: 0.5086
OOD Test ACCURACY: 0.8793
OOD Test Loss: 0.5214

[0m[1;37mINFO[0m: [1mChartInfo 0.8860 0.8647 0.7830 0.8793 0.7933 0.9107[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.711
WIoU for r=0.3 = 0.661
F1 for r=0.6 = 0.613
WIoU for r=0.6 = 0.726
F1 for r=0.9 = 0.481
WIoU for r=0.9 = 0.719
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.719
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.664
WIoU for r=0.3 = 0.929
F1 for r=0.6 = 0.409
WIoU for r=0.6 = 0.926
F1 for r=0.9 = 0.295
WIoU for r=0.9 = 0.926
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.926
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.769
WIoU for r=0.3 = 0.900
F1 for r=0.6 = 0.544
WIoU for r=0.6 = 0.849
F1 for r=0.9 = 0.424
WIoU for r=0.9 = 0.827
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.827


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.567
Model XAI F1 of binarized graphs for r=0.3 =  0.7105624999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.6608125000000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.541
SUFF++ for r=0.3 class 0 = 0.453 +- 0.297 (in-sample avg dev_std = 0.610)
SUFF++ for r=0.3 class 1 = 0.536 +- 0.297 (in-sample avg dev_std = 0.610)
SUFF++ for r=0.3 class 2 = 0.469 +- 0.297 (in-sample avg dev_std = 0.610)
SUFF++ for r=0.3 all KL = 0.348 +- 0.297 (in-sample avg dev_std = 0.610)
SUFF++ for r=0.3 all L1 = 0.486 +- 0.190 (in-sample avg dev_std = 0.610)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.837
Model XAI F1 of binarized graphs for r=0.6 =  0.61280625
Model XAI WIoU of binarized graphs for r=0.6 =  0.7261012499999999
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.774
SUFF++ for r=0.6 class 0 = 0.604 +- 0.306 (in-sample avg dev_std = 0.440)
SUFF++ for r=0.6 class 1 = 0.708 +- 0.306 (in-sample avg dev_std = 0.440)
SUFF++ for r=0.6 class 2 = 0.737 +- 0.306 (in-sample avg dev_std = 0.440)
SUFF++ for r=0.6 all KL = 0.635 +- 0.306 (in-sample avg dev_std = 0.440)
SUFF++ for r=0.6 all L1 = 0.683 +- 0.224 (in-sample avg dev_std = 0.440)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.905
Model XAI F1 of binarized graphs for r=0.9 =  0.48108249999999997
Model XAI WIoU of binarized graphs for r=0.9 =  0.71949875
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.861
SUFF++ for r=0.9 class 0 = 0.74 +- 0.245 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.9 class 1 = 0.808 +- 0.245 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.9 class 2 = 0.856 +- 0.245 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.9 all KL = 0.831 +- 0.245 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.9 all L1 = 0.801 +- 0.204 (in-sample avg dev_std = 0.278)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.873
Model XAI F1 of binarized graphs for r=0.3 =  0.6636587499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.9293250000000001
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.653
SUFF++ for r=0.3 class 0 = 0.521 +- 0.311 (in-sample avg dev_std = 0.579)
SUFF++ for r=0.3 class 1 = 0.638 +- 0.311 (in-sample avg dev_std = 0.579)
SUFF++ for r=0.3 class 2 = 0.58 +- 0.311 (in-sample avg dev_std = 0.579)
SUFF++ for r=0.3 all KL = 0.492 +- 0.311 (in-sample avg dev_std = 0.579)
SUFF++ for r=0.3 all L1 = 0.579 +- 0.187 (in-sample avg dev_std = 0.579)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.897
Model XAI F1 of binarized graphs for r=0.6 =  0.40876375
Model XAI WIoU of binarized graphs for r=0.6 =  0.92616625
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.697
SUFF++ for r=0.6 class 0 = 0.603 +- 0.230 (in-sample avg dev_std = 0.406)
SUFF++ for r=0.6 class 1 = 0.637 +- 0.230 (in-sample avg dev_std = 0.406)
SUFF++ for r=0.6 class 2 = 0.654 +- 0.230 (in-sample avg dev_std = 0.406)
SUFF++ for r=0.6 all KL = 0.696 +- 0.230 (in-sample avg dev_std = 0.406)
SUFF++ for r=0.6 all L1 = 0.631 +- 0.161 (in-sample avg dev_std = 0.406)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.902
Model XAI F1 of binarized graphs for r=0.9 =  0.29531125
Model XAI WIoU of binarized graphs for r=0.9 =  0.92616625
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.757
SUFF++ for r=0.9 class 0 = 0.719 +- 0.193 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 class 1 = 0.701 +- 0.193 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 class 2 = 0.823 +- 0.193 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 all KL = 0.845 +- 0.193 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 all L1 = 0.748 +- 0.171 (in-sample avg dev_std = 0.296)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.863
Model XAI F1 of binarized graphs for r=0.3 =  0.7685775000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.8999287499999999
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.691
SUFF++ for r=0.3 class 0 = 0.561 +- 0.317 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.3 class 1 = 0.654 +- 0.317 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.3 class 2 = 0.526 +- 0.317 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.3 all KL = 0.547 +- 0.317 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.3 all L1 = 0.581 +- 0.221 (in-sample avg dev_std = 0.515)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.865
Model XAI F1 of binarized graphs for r=0.6 =  0.5438937500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.8493262500000001
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.774
SUFF++ for r=0.6 class 0 = 0.583 +- 0.304 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.6 class 1 = 0.755 +- 0.304 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.6 class 2 = 0.689 +- 0.304 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.6 all KL = 0.649 +- 0.304 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.6 all L1 = 0.677 +- 0.182 (in-sample avg dev_std = 0.503)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.865
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.827495
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.874
SUFF++ for r=0.9 class 0 = 0.82 +- 0.125 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.9 class 1 = 0.936 +- 0.125 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.9 class 2 = 0.924 +- 0.125 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.9 all KL = 0.939 +- 0.125 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.9 all L1 = 0.894 +- 0.147 (in-sample avg dev_std = 0.228)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.566
Model XAI F1 of binarized graphs for r=0.3 =  0.7105624999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.6608125000000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.387
NEC for r=0.3 class 0 = 0.607 +- 0.294 (in-sample avg dev_std = 0.551)
NEC for r=0.3 class 1 = 0.536 +- 0.294 (in-sample avg dev_std = 0.551)
NEC for r=0.3 class 2 = 0.659 +- 0.294 (in-sample avg dev_std = 0.551)
NEC for r=0.3 all KL = 0.715 +- 0.294 (in-sample avg dev_std = 0.551)
NEC for r=0.3 all L1 = 0.6 +- 0.164 (in-sample avg dev_std = 0.551)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.837
Model XAI F1 of binarized graphs for r=0.6 =  0.61280625
Model XAI WIoU of binarized graphs for r=0.6 =  0.7261012499999999
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.492
NEC for r=0.6 class 0 = 0.516 +- 0.315 (in-sample avg dev_std = 0.560)
NEC for r=0.6 class 1 = 0.489 +- 0.315 (in-sample avg dev_std = 0.560)
NEC for r=0.6 class 2 = 0.628 +- 0.315 (in-sample avg dev_std = 0.560)
NEC for r=0.6 all KL = 0.635 +- 0.315 (in-sample avg dev_std = 0.560)
NEC for r=0.6 all L1 = 0.544 +- 0.172 (in-sample avg dev_std = 0.560)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.905
Model XAI F1 of binarized graphs for r=0.9 =  0.48108249999999997
Model XAI WIoU of binarized graphs for r=0.9 =  0.71949875
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.58
NEC for r=0.9 class 0 = 0.466 +- 0.307 (in-sample avg dev_std = 0.569)
NEC for r=0.9 class 1 = 0.439 +- 0.307 (in-sample avg dev_std = 0.569)
NEC for r=0.9 class 2 = 0.545 +- 0.307 (in-sample avg dev_std = 0.569)
NEC for r=0.9 all KL = 0.536 +- 0.307 (in-sample avg dev_std = 0.569)
NEC for r=0.9 all L1 = 0.483 +- 0.166 (in-sample avg dev_std = 0.569)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.905
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.719315
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.581
NEC for r=1.0 class 0 = 0.459 +- 0.308 (in-sample avg dev_std = 0.568)
NEC for r=1.0 class 1 = 0.422 +- 0.308 (in-sample avg dev_std = 0.568)
NEC for r=1.0 class 2 = 0.545 +- 0.308 (in-sample avg dev_std = 0.568)
NEC for r=1.0 all KL = 0.528 +- 0.308 (in-sample avg dev_std = 0.568)
NEC for r=1.0 all L1 = 0.475 +- 0.169 (in-sample avg dev_std = 0.568)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.873
Model XAI F1 of binarized graphs for r=0.3 =  0.6636587499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.9293250000000001
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.395
NEC for r=0.3 class 0 = 0.579 +- 0.304 (in-sample avg dev_std = 0.479)
NEC for r=0.3 class 1 = 0.538 +- 0.304 (in-sample avg dev_std = 0.479)
NEC for r=0.3 class 2 = 0.722 +- 0.304 (in-sample avg dev_std = 0.479)
NEC for r=0.3 all KL = 0.678 +- 0.304 (in-sample avg dev_std = 0.479)
NEC for r=0.3 all L1 = 0.614 +- 0.152 (in-sample avg dev_std = 0.479)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.897
Model XAI F1 of binarized graphs for r=0.6 =  0.40876375
Model XAI WIoU of binarized graphs for r=0.6 =  0.92616625
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.556
NEC for r=0.6 class 0 = 0.434 +- 0.286 (in-sample avg dev_std = 0.504)
NEC for r=0.6 class 1 = 0.416 +- 0.286 (in-sample avg dev_std = 0.504)
NEC for r=0.6 class 2 = 0.564 +- 0.286 (in-sample avg dev_std = 0.504)
NEC for r=0.6 all KL = 0.434 +- 0.286 (in-sample avg dev_std = 0.504)
NEC for r=0.6 all L1 = 0.472 +- 0.145 (in-sample avg dev_std = 0.504)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.902
Model XAI F1 of binarized graphs for r=0.9 =  0.29531125
Model XAI WIoU of binarized graphs for r=0.9 =  0.92616625
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.612
NEC for r=0.9 class 0 = 0.397 +- 0.249 (in-sample avg dev_std = 0.491)
NEC for r=0.9 class 1 = 0.389 +- 0.249 (in-sample avg dev_std = 0.491)
NEC for r=0.9 class 2 = 0.488 +- 0.249 (in-sample avg dev_std = 0.491)
NEC for r=0.9 all KL = 0.36 +- 0.249 (in-sample avg dev_std = 0.491)
NEC for r=0.9 all L1 = 0.425 +- 0.132 (in-sample avg dev_std = 0.491)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.902
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.92616625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.61
NEC for r=1.0 class 0 = 0.402 +- 0.244 (in-sample avg dev_std = 0.493)
NEC for r=1.0 class 1 = 0.398 +- 0.244 (in-sample avg dev_std = 0.493)
NEC for r=1.0 class 2 = 0.468 +- 0.244 (in-sample avg dev_std = 0.493)
NEC for r=1.0 all KL = 0.358 +- 0.244 (in-sample avg dev_std = 0.493)
NEC for r=1.0 all L1 = 0.423 +- 0.127 (in-sample avg dev_std = 0.493)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.863
Model XAI F1 of binarized graphs for r=0.3 =  0.7685775000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.8999287499999999
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.415
NEC for r=0.3 class 0 = 0.605 +- 0.282 (in-sample avg dev_std = 0.514)
NEC for r=0.3 class 1 = 0.524 +- 0.282 (in-sample avg dev_std = 0.514)
NEC for r=0.3 class 2 = 0.639 +- 0.282 (in-sample avg dev_std = 0.514)
NEC for r=0.3 all KL = 0.639 +- 0.282 (in-sample avg dev_std = 0.514)
NEC for r=0.3 all L1 = 0.589 +- 0.138 (in-sample avg dev_std = 0.514)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.865
Model XAI F1 of binarized graphs for r=0.6 =  0.5438937500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.8493262500000001
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.589
NEC for r=0.6 class 0 = 0.429 +- 0.336 (in-sample avg dev_std = 0.543)
NEC for r=0.6 class 1 = 0.408 +- 0.336 (in-sample avg dev_std = 0.543)
NEC for r=0.6 class 2 = 0.543 +- 0.336 (in-sample avg dev_std = 0.543)
NEC for r=0.6 all KL = 0.488 +- 0.336 (in-sample avg dev_std = 0.543)
NEC for r=0.6 all L1 = 0.46 +- 0.195 (in-sample avg dev_std = 0.543)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.865
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.827495
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.642
NEC for r=0.9 class 0 = 0.395 +- 0.329 (in-sample avg dev_std = 0.566)
NEC for r=0.9 class 1 = 0.356 +- 0.329 (in-sample avg dev_std = 0.566)
NEC for r=0.9 class 2 = 0.464 +- 0.329 (in-sample avg dev_std = 0.566)
NEC for r=0.9 all KL = 0.452 +- 0.329 (in-sample avg dev_std = 0.566)
NEC for r=0.9 all L1 = 0.405 +- 0.189 (in-sample avg dev_std = 0.566)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.865
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.827495
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.648
NEC for r=1.0 class 0 = 0.388 +- 0.319 (in-sample avg dev_std = 0.583)
NEC for r=1.0 class 1 = 0.349 +- 0.319 (in-sample avg dev_std = 0.583)
NEC for r=1.0 class 2 = 0.457 +- 0.319 (in-sample avg dev_std = 0.583)
NEC for r=1.0 all KL = 0.449 +- 0.319 (in-sample avg dev_std = 0.583)
NEC for r=1.0 all L1 = 0.397 +- 0.174 (in-sample avg dev_std = 0.583)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.497, 0.721, 0.852, 1.0], 'all_L1': [0.546, 0.686, 0.774, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.488, 0.64, 0.85, 1.0], 'all_L1': [0.548, 0.652, 0.794, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.44, 0.629, 0.848, 1.0], 'all_L1': [0.496, 0.665, 0.808, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.579, 0.8, 0.937, 1.0], 'all_L1': [0.573, 0.716, 0.857, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.348, 0.635, 0.831, 1.0], 'all_L1': [0.486, 0.683, 0.801, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.591, 0.553, 0.463, 0.463], 'all_L1': [0.553, 0.544, 0.472, 0.472]}), defaultdict(<class 'list'>, {'all_KL': [0.605, 0.612, 0.524, 0.515], 'all_L1': [0.55, 0.571, 0.519, 0.511]}), defaultdict(<class 'list'>, {'all_KL': [0.607, 0.643, 0.571, 0.555], 'all_L1': [0.569, 0.58, 0.529, 0.516]}), defaultdict(<class 'list'>, {'all_KL': [0.49, 0.438, 0.353, 0.347], 'all_L1': [0.506, 0.484, 0.424, 0.417]}), defaultdict(<class 'list'>, {'all_KL': [0.715, 0.635, 0.536, 0.528], 'all_L1': [0.6, 0.544, 0.483, 0.475]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.502, 0.721, 0.882, 1.0], 'all_L1': [0.523, 0.607, 0.751, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.47, 0.716, 0.82, 1.0], 'all_L1': [0.521, 0.602, 0.677, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.378, 0.669, 0.872, 1.0], 'all_L1': [0.513, 0.621, 0.776, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.657, 0.853, 0.914, 1.0], 'all_L1': [0.628, 0.719, 0.791, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.492, 0.696, 0.845, 1.0], 'all_L1': [0.579, 0.631, 0.748, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.646, 0.444, 0.349, 0.334], 'all_L1': [0.631, 0.524, 0.466, 0.453]}), defaultdict(<class 'list'>, {'all_KL': [0.68, 0.441, 0.346, 0.334], 'all_L1': [0.639, 0.525, 0.467, 0.457]}), defaultdict(<class 'list'>, {'all_KL': [0.776, 0.533, 0.405, 0.397], 'all_L1': [0.668, 0.548, 0.482, 0.474]}), defaultdict(<class 'list'>, {'all_KL': [0.537, 0.336, 0.221, 0.225], 'all_L1': [0.552, 0.439, 0.362, 0.366]}), defaultdict(<class 'list'>, {'all_KL': [0.678, 0.434, 0.36, 0.358], 'all_L1': [0.614, 0.472, 0.425, 0.423]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.584, 0.801, 0.929, 1.0], 'all_L1': [0.646, 0.766, 0.862, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.621, 0.682, 0.716, 1.0], 'all_L1': [0.594, 0.679, 0.742, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.563, 0.592, 0.745, 1.0], 'all_L1': [0.608, 0.65, 0.77, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.591, 0.784, 0.928, 1.0], 'all_L1': [0.592, 0.726, 0.857, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.547, 0.649, 0.939, 1.0], 'all_L1': [0.581, 0.677, 0.894, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.655, 0.502, 0.405, 0.393], 'all_L1': [0.584, 0.468, 0.381, 0.369]}), defaultdict(<class 'list'>, {'all_KL': [0.479, 0.474, 0.446, 0.444], 'all_L1': [0.523, 0.479, 0.434, 0.431]}), defaultdict(<class 'list'>, {'all_KL': [0.587, 0.526, 0.442, 0.441], 'all_L1': [0.533, 0.475, 0.389, 0.386]}), defaultdict(<class 'list'>, {'all_KL': [0.526, 0.405, 0.36, 0.366], 'all_L1': [0.517, 0.433, 0.388, 0.394]}), defaultdict(<class 'list'>, {'all_KL': [0.639, 0.488, 0.452, 0.449], 'all_L1': [0.589, 0.46, 0.405, 0.397]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.530 +- 0.033, 0.680 +- 0.022, 0.807 +- 0.028, 1.000 +- 0.000
suff++ class all_KL  =  0.470 +- 0.076, 0.685 +- 0.067, 0.864 +- 0.037, 1.000 +- 0.000
suff++_acc_int  =  0.501 +- 0.041, 0.755 +- 0.017, 0.850 +- 0.014
nec class all_L1  =  0.556 +- 0.030, 0.545 +- 0.034, 0.485 +- 0.037, 0.478 +- 0.035
nec class all_KL  =  0.602 +- 0.071, 0.576 +- 0.076, 0.489 +- 0.077, 0.482 +- 0.074
nec_acc_int  =  0.364 +- 0.017, 0.463 +- 0.027, 0.555 +- 0.034, 0.563 +- 0.027

Eval split val
suff++ class all_L1  =  0.553 +- 0.044, 0.636 +- 0.043, 0.749 +- 0.039, 1.000 +- 0.000
suff++ class all_KL  =  0.500 +- 0.090, 0.731 +- 0.064, 0.867 +- 0.032, 1.000 +- 0.000
suff++_acc_int  =  0.635 +- 0.022, 0.724 +- 0.021, 0.788 +- 0.038
nec class all_L1  =  0.621 +- 0.039, 0.502 +- 0.040, 0.440 +- 0.044, 0.435 +- 0.038
nec class all_KL  =  0.663 +- 0.077, 0.438 +- 0.062, 0.336 +- 0.061, 0.330 +- 0.057
nec_acc_int  =  0.384 +- 0.011, 0.516 +- 0.023, 0.575 +- 0.029, 0.583 +- 0.019

Eval split test
suff++ class all_L1  =  0.604 +- 0.023, 0.700 +- 0.041, 0.825 +- 0.058, 1.000 +- 0.000
suff++ class all_KL  =  0.581 +- 0.025, 0.702 +- 0.080, 0.851 +- 0.099, 1.000 +- 0.000
suff++_acc_int  =  0.613 +- 0.053, 0.769 +- 0.037, 0.827 +- 0.056
nec class all_L1  =  0.549 +- 0.031, 0.463 +- 0.016, 0.399 +- 0.019, 0.395 +- 0.020
nec class all_KL  =  0.577 +- 0.067, 0.479 +- 0.041, 0.421 +- 0.035, 0.419 +- 0.033
nec_acc_int  =  0.392 +- 0.038, 0.555 +- 0.025, 0.627 +- 0.020, 0.633 +- 0.030


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.543 +- 0.006, 0.613 +- 0.007, 0.646 +- 0.015, 0.739 +- 0.018
Faith. Armon (L1)= 		  =  0.541 +- 0.008, 0.604 +- 0.014, 0.605 +- 0.026, 0.646 +- 0.033
Faith. GMean (L1)= 	  =  0.542 +- 0.007, 0.608 +- 0.011, 0.625 +- 0.020, 0.691 +- 0.026
Faith. Aritm (KL)= 		  =  0.536 +- 0.008, 0.631 +- 0.007, 0.676 +- 0.023, 0.741 +- 0.037
Faith. Armon (KL)= 		  =  0.518 +- 0.027, 0.618 +- 0.026, 0.619 +- 0.059, 0.647 +- 0.071
Faith. GMean (KL)= 	  =  0.527 +- 0.017, 0.624 +- 0.016, 0.647 +- 0.042, 0.692 +- 0.055

Eval split val
Faith. Aritm (L1)= 		  =  0.587 +- 0.007, 0.569 +- 0.012, 0.594 +- 0.021, 0.717 +- 0.019
Faith. Armon (L1)= 		  =  0.582 +- 0.009, 0.558 +- 0.015, 0.552 +- 0.033, 0.605 +- 0.038
Faith. GMean (L1)= 	  =  0.584 +- 0.008, 0.563 +- 0.012, 0.573 +- 0.026, 0.659 +- 0.029
Faith. Aritm (KL)= 		  =  0.582 +- 0.009, 0.584 +- 0.013, 0.601 +- 0.025, 0.665 +- 0.029
Faith. Armon (KL)= 		  =  0.558 +- 0.027, 0.541 +- 0.036, 0.480 +- 0.066, 0.493 +- 0.067
Faith. GMean (KL)= 	  =  0.570 +- 0.017, 0.562 +- 0.021, 0.537 +- 0.048, 0.572 +- 0.052

Eval split test
Faith. Aritm (L1)= 		  =  0.577 +- 0.022, 0.581 +- 0.019, 0.612 +- 0.025, 0.698 +- 0.010
Faith. Armon (L1)= 		  =  0.575 +- 0.022, 0.556 +- 0.014, 0.537 +- 0.014, 0.566 +- 0.021
Faith. GMean (L1)= 	  =  0.576 +- 0.022, 0.569 +- 0.016, 0.573 +- 0.017, 0.629 +- 0.016
Faith. Aritm (KL)= 		  =  0.579 +- 0.025, 0.590 +- 0.033, 0.636 +- 0.043, 0.709 +- 0.017
Faith. Armon (KL)= 		  =  0.576 +- 0.027, 0.565 +- 0.028, 0.560 +- 0.030, 0.589 +- 0.033
Faith. GMean (KL)= 	  =  0.578 +- 0.026, 0.577 +- 0.029, 0.596 +- 0.032, 0.646 +- 0.026
Computed for split load_split = id



Completed in  0:19:21.516077  for LECIGIN GOODMotif2/basis



DONE LECI GOODMotif2/basis

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 20:09:50 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 03/22/2024 08:09:50 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 08:09:50 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 08:09:50 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/22/2024 08:09:50 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 08:09:50 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:09:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:09:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:09:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:09:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:09:50 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/22/2024 08:09:50 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:09:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:09:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:09:50 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/22/2024 08:09:50 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 105...
[0m[1;37mINFO[0m: [1mCheckpoint 105: 
-----------------------------------
Train ACCURACY: 0.9248
Train Loss: 0.3767
ID Validation ACCURACY: 0.9243
ID Validation Loss: 0.3771
ID Test ACCURACY: 0.9193
ID Test Loss: 0.4310
OOD Validation ACCURACY: 0.9260
OOD Validation Loss: 0.3978
OOD Test ACCURACY: 0.4087
OOD Test Loss: 27.1216

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 105...
[0m[1;37mINFO[0m: [1mCheckpoint 105: 
-----------------------------------
Train ACCURACY: 0.9248
Train Loss: 0.3767
ID Validation ACCURACY: 0.9243
ID Validation Loss: 0.3771
ID Test ACCURACY: 0.9193
ID Test Loss: 0.4310
OOD Validation ACCURACY: 0.9260
OOD Validation Loss: 0.3978
OOD Test ACCURACY: 0.4087
OOD Test Loss: 27.1216

[0m[1;37mINFO[0m: [1mChartInfo 0.9193 0.4087 0.9193 0.4087 0.9243 0.9260[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.8 = 0.516
WIoU for r=0.8 = 0.652
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.8 = 0.307
WIoU for r=0.8 = 0.893
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.8 = 0.343
WIoU for r=0.8 = 0.231


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.933
Model XAI F1 of binarized graphs for r=0.8 =  0.5163575
Model XAI WIoU of binarized graphs for r=0.8 =  0.65161
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.712
SUFF++ for r=0.8 class 0 = 0.466 +- 0.312 (in-sample avg dev_std = 0.512)
SUFF++ for r=0.8 class 1 = 0.601 +- 0.312 (in-sample avg dev_std = 0.512)
SUFF++ for r=0.8 class 2 = 0.89 +- 0.312 (in-sample avg dev_std = 0.512)
SUFF++ for r=0.8 all KL = 0.621 +- 0.312 (in-sample avg dev_std = 0.512)
SUFF++ for r=0.8 all L1 = 0.651 +- 0.254 (in-sample avg dev_std = 0.512)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.928
Model XAI F1 of binarized graphs for r=0.8 =  0.3071675
Model XAI WIoU of binarized graphs for r=0.8 =  0.89316125
len(reference) = 800
Effective ratio: 0.806 +- 0.005
Model Accuracy over intervened graphs for r=0.8 =  0.591
SUFF++ for r=0.8 class 0 = 0.424 +- 0.252 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.8 class 1 = 0.505 +- 0.252 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.8 class 2 = 0.779 +- 0.252 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.8 all KL = 0.593 +- 0.252 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.8 all L1 = 0.57 +- 0.231 (in-sample avg dev_std = 0.481)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.404
Model XAI F1 of binarized graphs for r=0.8 =  0.34301874999999993
Model XAI WIoU of binarized graphs for r=0.8 =  0.23099499999999998
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.385
SUFF++ for r=0.8 class 0 = 0.78 +- 0.351 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.8 class 1 = 0.855 +- 0.351 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.8 class 2 = 0.974 +- 0.351 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.8 all KL = 0.786 +- 0.351 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.8 all L1 = 0.87 +- 0.252 (in-sample avg dev_std = 0.316)


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.933
Model XAI F1 of binarized graphs for r=0.8 =  0.5163575
Model XAI WIoU of binarized graphs for r=0.8 =  0.65161
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.438
NEC for r=0.8 class 0 = 0.652 +- 0.226 (in-sample avg dev_std = 0.706)
NEC for r=0.8 class 1 = 0.611 +- 0.226 (in-sample avg dev_std = 0.706)
NEC for r=0.8 class 2 = 0.57 +- 0.226 (in-sample avg dev_std = 0.706)
NEC for r=0.8 all KL = 0.732 +- 0.226 (in-sample avg dev_std = 0.706)
NEC for r=0.8 all L1 = 0.611 +- 0.155 (in-sample avg dev_std = 0.706)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.928
Model XAI F1 of binarized graphs for r=0.8 =  0.3071675
Model XAI WIoU of binarized graphs for r=0.8 =  0.89316125
len(reference) = 800
Effective ratio: 0.806 +- 0.005
Model Accuracy over intervened graphs for r=0.8 =  0.488
NEC for r=0.8 class 0 = 0.592 +- 0.210 (in-sample avg dev_std = 0.615)
NEC for r=0.8 class 1 = 0.57 +- 0.210 (in-sample avg dev_std = 0.615)
NEC for r=0.8 class 2 = 0.473 +- 0.210 (in-sample avg dev_std = 0.615)
NEC for r=0.8 all KL = 0.583 +- 0.210 (in-sample avg dev_std = 0.615)
NEC for r=0.8 all L1 = 0.544 +- 0.134 (in-sample avg dev_std = 0.615)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.404
Model XAI F1 of binarized graphs for r=0.8 =  0.34301874999999993
Model XAI WIoU of binarized graphs for r=0.8 =  0.23099499999999998
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.39
NEC for r=0.8 class 0 = 0.264 +- 0.444 (in-sample avg dev_std = 0.499)
NEC for r=0.8 class 1 = 0.255 +- 0.444 (in-sample avg dev_std = 0.499)
NEC for r=0.8 class 2 = 0.136 +- 0.444 (in-sample avg dev_std = 0.499)
NEC for r=0.8 all KL = 0.386 +- 0.444 (in-sample avg dev_std = 0.499)
NEC for r=0.8 all L1 = 0.218 +- 0.287 (in-sample avg dev_std = 0.499)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 20:11:03 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 03/22/2024 08:11:03 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 08:11:03 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 08:11:03 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/22/2024 08:11:03 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 08:11:03 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:11:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:11:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:11:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:11:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:11:03 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/22/2024 08:11:03 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:11:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:11:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:11:03 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/22/2024 08:11:03 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 15...
[0m[1;37mINFO[0m: [1mCheckpoint 15: 
-----------------------------------
Train ACCURACY: 0.8638
Train Loss: 0.5776
ID Validation ACCURACY: 0.8760
ID Validation Loss: 0.5248
ID Test ACCURACY: 0.8623
ID Test Loss: 0.5892
OOD Validation ACCURACY: 0.8237
OOD Validation Loss: 0.5364
OOD Test ACCURACY: 0.6500
OOD Test Loss: 2.0536

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 84...
[0m[1;37mINFO[0m: [1mCheckpoint 84: 
-----------------------------------
Train ACCURACY: 0.8533
Train Loss: 0.5252
ID Validation ACCURACY: 0.8630
ID Validation Loss: 0.4912
ID Test ACCURACY: 0.8500
ID Test Loss: 0.5371
OOD Validation ACCURACY: 0.8757
OOD Validation Loss: 0.4826
OOD Test ACCURACY: 0.4940
OOD Test Loss: 5.1451

[0m[1;37mINFO[0m: [1mChartInfo 0.8623 0.6500 0.8500 0.4940 0.8630 0.8757[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.8 = 0.514
WIoU for r=0.8 = 0.725
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.8 = 0.325
WIoU for r=0.8 = 0.972
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.8 = 0.421
WIoU for r=0.8 = 0.491


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.88
Model XAI F1 of binarized graphs for r=0.8 =  0.5143775
Model XAI WIoU of binarized graphs for r=0.8 =  0.7254775000000001
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.73
SUFF++ for r=0.8 class 0 = 0.591 +- 0.329 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.8 class 1 = 0.91 +- 0.329 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.8 class 2 = 0.674 +- 0.329 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.8 all KL = 0.702 +- 0.329 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.8 all L1 = 0.726 +- 0.262 (in-sample avg dev_std = 0.419)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.815
Model XAI F1 of binarized graphs for r=0.8 =  0.32483249999999997
Model XAI WIoU of binarized graphs for r=0.8 =  0.97190125
len(reference) = 800
Effective ratio: 0.806 +- 0.005
Model Accuracy over intervened graphs for r=0.8 =  0.706
SUFF++ for r=0.8 class 0 = 0.627 +- 0.227 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.8 class 1 = 0.828 +- 0.227 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.8 class 2 = 0.593 +- 0.227 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.8 all KL = 0.724 +- 0.227 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.8 all L1 = 0.681 +- 0.191 (in-sample avg dev_std = 0.412)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.642
Model XAI F1 of binarized graphs for r=0.8 =  0.42105750000000003
Model XAI WIoU of binarized graphs for r=0.8 =  0.49111374999999996
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.522
SUFF++ for r=0.8 class 0 = 0.654 +- 0.359 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.8 class 1 = 0.741 +- 0.359 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.8 class 2 = 0.627 +- 0.359 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.8 all KL = 0.628 +- 0.359 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.8 all L1 = 0.675 +- 0.197 (in-sample avg dev_std = 0.490)


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.88
Model XAI F1 of binarized graphs for r=0.8 =  0.5143775
Model XAI WIoU of binarized graphs for r=0.8 =  0.7254775000000001
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.457
NEC for r=0.8 class 0 = 0.584 +- 0.264 (in-sample avg dev_std = 0.726)
NEC for r=0.8 class 1 = 0.456 +- 0.264 (in-sample avg dev_std = 0.726)
NEC for r=0.8 class 2 = 0.665 +- 0.264 (in-sample avg dev_std = 0.726)
NEC for r=0.8 all KL = 0.721 +- 0.264 (in-sample avg dev_std = 0.726)
NEC for r=0.8 all L1 = 0.568 +- 0.203 (in-sample avg dev_std = 0.726)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.815
Model XAI F1 of binarized graphs for r=0.8 =  0.32483249999999997
Model XAI WIoU of binarized graphs for r=0.8 =  0.97190125
len(reference) = 800
Effective ratio: 0.806 +- 0.005
Model Accuracy over intervened graphs for r=0.8 =  0.504
NEC for r=0.8 class 0 = 0.529 +- 0.231 (in-sample avg dev_std = 0.651)
NEC for r=0.8 class 1 = 0.501 +- 0.231 (in-sample avg dev_std = 0.651)
NEC for r=0.8 class 2 = 0.568 +- 0.231 (in-sample avg dev_std = 0.651)
NEC for r=0.8 all KL = 0.586 +- 0.231 (in-sample avg dev_std = 0.651)
NEC for r=0.8 all L1 = 0.533 +- 0.144 (in-sample avg dev_std = 0.651)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.642
Model XAI F1 of binarized graphs for r=0.8 =  0.42105750000000003
Model XAI WIoU of binarized graphs for r=0.8 =  0.49111374999999996
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.532
NEC for r=0.8 class 0 = 0.535 +- 0.306 (in-sample avg dev_std = 0.626)
NEC for r=0.8 class 1 = 0.342 +- 0.306 (in-sample avg dev_std = 0.626)
NEC for r=0.8 class 2 = 0.462 +- 0.306 (in-sample avg dev_std = 0.626)
NEC for r=0.8 all KL = 0.606 +- 0.306 (in-sample avg dev_std = 0.626)
NEC for r=0.8 all L1 = 0.445 +- 0.179 (in-sample avg dev_std = 0.626)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 20:12:12 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 03/22/2024 08:12:12 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 08:12:12 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 08:12:12 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/22/2024 08:12:12 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 08:12:12 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:12:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:12:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:12:12 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/22/2024 08:12:12 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:12:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:12:12 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/22/2024 08:12:12 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 17...
[0m[1;37mINFO[0m: [1mCheckpoint 17: 
-----------------------------------
Train ACCURACY: 0.9147
Train Loss: 0.4936
ID Validation ACCURACY: 0.9210
ID Validation Loss: 0.4879
ID Test ACCURACY: 0.9093
ID Test Loss: 0.5467
OOD Validation ACCURACY: 0.8387
OOD Validation Loss: 0.5746
OOD Test ACCURACY: 0.4087
OOD Test Loss: 32.4148

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 30...
[0m[1;37mINFO[0m: [1mCheckpoint 30: 
-----------------------------------
Train ACCURACY: 0.8200
Train Loss: 0.6115
ID Validation ACCURACY: 0.8157
ID Validation Loss: 0.6203
ID Test ACCURACY: 0.8157
ID Test Loss: 0.6734
OOD Validation ACCURACY: 0.8897
OOD Validation Loss: 0.4646
OOD Test ACCURACY: 0.3343
OOD Test Loss: 29.0064

[0m[1;37mINFO[0m: [1mChartInfo 0.9093 0.4087 0.8157 0.3343 0.8157 0.8897[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.8 = 0.518
WIoU for r=0.8 = 0.501
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.8 = 0.324
WIoU for r=0.8 = 0.261
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.8 = 0.302
WIoU for r=0.8 = 0.200


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.925
Model XAI F1 of binarized graphs for r=0.8 =  0.51809375
Model XAI WIoU of binarized graphs for r=0.8 =  0.5013487499999999
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.653
SUFF++ for r=0.8 class 0 = 0.445 +- 0.321 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.8 class 1 = 0.565 +- 0.321 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.8 class 2 = 0.919 +- 0.321 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.8 all KL = 0.626 +- 0.321 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.8 all L1 = 0.642 +- 0.268 (in-sample avg dev_std = 0.516)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.831
Model XAI F1 of binarized graphs for r=0.8 =  0.32363625
Model XAI WIoU of binarized graphs for r=0.8 =  0.2613325
len(reference) = 800
Effective ratio: 0.806 +- 0.005
Model Accuracy over intervened graphs for r=0.8 =  0.522
SUFF++ for r=0.8 class 0 = 0.404 +- 0.272 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.8 class 1 = 0.46 +- 0.272 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.8 class 2 = 0.894 +- 0.272 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.8 all KL = 0.64 +- 0.272 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.8 all L1 = 0.587 +- 0.273 (in-sample avg dev_std = 0.394)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.404
Model XAI F1 of binarized graphs for r=0.8 =  0.3022025
Model XAI WIoU of binarized graphs for r=0.8 =  0.19976875
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.344
SUFF++ for r=0.8 class 0 = 0.869 +- 0.184 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.8 class 1 = 0.85 +- 0.184 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.8 class 2 = 0.996 +- 0.184 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.8 all KL = 0.926 +- 0.184 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.8 all L1 = 0.905 +- 0.225 (in-sample avg dev_std = 0.128)


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.925
Model XAI F1 of binarized graphs for r=0.8 =  0.51809375
Model XAI WIoU of binarized graphs for r=0.8 =  0.5013487499999999
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.46
NEC for r=0.8 class 0 = 0.645 +- 0.249 (in-sample avg dev_std = 0.719)
NEC for r=0.8 class 1 = 0.589 +- 0.249 (in-sample avg dev_std = 0.719)
NEC for r=0.8 class 2 = 0.57 +- 0.249 (in-sample avg dev_std = 0.719)
NEC for r=0.8 all KL = 0.775 +- 0.249 (in-sample avg dev_std = 0.719)
NEC for r=0.8 all L1 = 0.601 +- 0.171 (in-sample avg dev_std = 0.719)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.831
Model XAI F1 of binarized graphs for r=0.8 =  0.32363625
Model XAI WIoU of binarized graphs for r=0.8 =  0.2613325
len(reference) = 800
Effective ratio: 0.806 +- 0.005
Model Accuracy over intervened graphs for r=0.8 =  0.413
NEC for r=0.8 class 0 = 0.631 +- 0.225 (in-sample avg dev_std = 0.531)
NEC for r=0.8 class 1 = 0.621 +- 0.225 (in-sample avg dev_std = 0.531)
NEC for r=0.8 class 2 = 0.355 +- 0.225 (in-sample avg dev_std = 0.531)
NEC for r=0.8 all KL = 0.6 +- 0.225 (in-sample avg dev_std = 0.531)
NEC for r=0.8 all L1 = 0.535 +- 0.187 (in-sample avg dev_std = 0.531)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.404
Model XAI F1 of binarized graphs for r=0.8 =  0.3022025
Model XAI WIoU of binarized graphs for r=0.8 =  0.19976875
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.383
NEC for r=0.8 class 0 = 0.228 +- 0.421 (in-sample avg dev_std = 0.372)
NEC for r=0.8 class 1 = 0.204 +- 0.421 (in-sample avg dev_std = 0.372)
NEC for r=0.8 class 2 = 0.102 +- 0.421 (in-sample avg dev_std = 0.372)
NEC for r=0.8 all KL = 0.323 +- 0.421 (in-sample avg dev_std = 0.372)
NEC for r=0.8 all L1 = 0.178 +- 0.264 (in-sample avg dev_std = 0.372)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 20:13:21 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 03/22/2024 08:13:21 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 08:13:21 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 08:13:21 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/22/2024 08:13:21 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 08:13:21 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:13:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:13:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:13:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:13:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:13:21 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/22/2024 08:13:21 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:13:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:13:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:13:21 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/22/2024 08:13:21 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 17...
[0m[1;37mINFO[0m: [1mCheckpoint 17: 
-----------------------------------
Train ACCURACY: 0.9185
Train Loss: 0.4761
ID Validation ACCURACY: 0.9243
ID Validation Loss: 0.4624
ID Test ACCURACY: 0.9137
ID Test Loss: 0.5178
OOD Validation ACCURACY: 0.8713
OOD Validation Loss: 0.5049
OOD Test ACCURACY: 0.4087
OOD Test Loss: 34.3607

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 20...
[0m[1;37mINFO[0m: [1mCheckpoint 20: 
-----------------------------------
Train ACCURACY: 0.9192
Train Loss: 0.4721
ID Validation ACCURACY: 0.9240
ID Validation Loss: 0.4583
ID Test ACCURACY: 0.9157
ID Test Loss: 0.5307
OOD Validation ACCURACY: 0.9143
OOD Validation Loss: 0.4105
OOD Test ACCURACY: 0.4087
OOD Test Loss: 17.9440

[0m[1;37mINFO[0m: [1mChartInfo 0.9137 0.4087 0.9157 0.4087 0.9240 0.9143[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.8 = 0.521
WIoU for r=0.8 = 0.522
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.8 = 0.324
WIoU for r=0.8 = 0.295
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.8 = 0.309
WIoU for r=0.8 = 0.202


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.933
Model XAI F1 of binarized graphs for r=0.8 =  0.5208375000000001
Model XAI WIoU of binarized graphs for r=0.8 =  0.5218050000000001
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.749
SUFF++ for r=0.8 class 0 = 0.539 +- 0.305 (in-sample avg dev_std = 0.442)
SUFF++ for r=0.8 class 1 = 0.644 +- 0.305 (in-sample avg dev_std = 0.442)
SUFF++ for r=0.8 class 2 = 0.893 +- 0.305 (in-sample avg dev_std = 0.442)
SUFF++ for r=0.8 all KL = 0.672 +- 0.305 (in-sample avg dev_std = 0.442)
SUFF++ for r=0.8 all L1 = 0.691 +- 0.253 (in-sample avg dev_std = 0.442)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.879
Model XAI F1 of binarized graphs for r=0.8 =  0.32405
Model XAI WIoU of binarized graphs for r=0.8 =  0.2951175
len(reference) = 800
Effective ratio: 0.806 +- 0.005
Model Accuracy over intervened graphs for r=0.8 =  0.523
SUFF++ for r=0.8 class 0 = 0.374 +- 0.283 (in-sample avg dev_std = 0.457)
SUFF++ for r=0.8 class 1 = 0.473 +- 0.283 (in-sample avg dev_std = 0.457)
SUFF++ for r=0.8 class 2 = 0.852 +- 0.283 (in-sample avg dev_std = 0.457)
SUFF++ for r=0.8 all KL = 0.601 +- 0.283 (in-sample avg dev_std = 0.457)
SUFF++ for r=0.8 all L1 = 0.568 +- 0.263 (in-sample avg dev_std = 0.457)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.405
Model XAI F1 of binarized graphs for r=0.8 =  0.30855
Model XAI WIoU of binarized graphs for r=0.8 =  0.20215000000000002
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.382
SUFF++ for r=0.8 class 0 = 0.872 +- 0.164 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.8 class 1 = 0.902 +- 0.164 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.8 class 2 = 0.972 +- 0.164 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.8 all KL = 0.918 +- 0.164 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.8 all L1 = 0.916 +- 0.178 (in-sample avg dev_std = 0.191)


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.933
Model XAI F1 of binarized graphs for r=0.8 =  0.5208375000000001
Model XAI WIoU of binarized graphs for r=0.8 =  0.5218050000000001
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.444
NEC for r=0.8 class 0 = 0.672 +- 0.237 (in-sample avg dev_std = 0.724)
NEC for r=0.8 class 1 = 0.572 +- 0.237 (in-sample avg dev_std = 0.724)
NEC for r=0.8 class 2 = 0.6 +- 0.237 (in-sample avg dev_std = 0.724)
NEC for r=0.8 all KL = 0.781 +- 0.237 (in-sample avg dev_std = 0.724)
NEC for r=0.8 all L1 = 0.615 +- 0.170 (in-sample avg dev_std = 0.724)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.879
Model XAI F1 of binarized graphs for r=0.8 =  0.32405
Model XAI WIoU of binarized graphs for r=0.8 =  0.2951175
len(reference) = 800
Effective ratio: 0.806 +- 0.005
Model Accuracy over intervened graphs for r=0.8 =  0.406
NEC for r=0.8 class 0 = 0.697 +- 0.229 (in-sample avg dev_std = 0.561)
NEC for r=0.8 class 1 = 0.607 +- 0.229 (in-sample avg dev_std = 0.561)
NEC for r=0.8 class 2 = 0.381 +- 0.229 (in-sample avg dev_std = 0.561)
NEC for r=0.8 all KL = 0.631 +- 0.229 (in-sample avg dev_std = 0.561)
NEC for r=0.8 all L1 = 0.561 +- 0.189 (in-sample avg dev_std = 0.561)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.405
Model XAI F1 of binarized graphs for r=0.8 =  0.30855
Model XAI WIoU of binarized graphs for r=0.8 =  0.20215000000000002
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.361
NEC for r=0.8 class 0 = 0.243 +- 0.453 (in-sample avg dev_std = 0.445)
NEC for r=0.8 class 1 = 0.238 +- 0.453 (in-sample avg dev_std = 0.445)
NEC for r=0.8 class 2 = 0.168 +- 0.453 (in-sample avg dev_std = 0.445)
NEC for r=0.8 all KL = 0.401 +- 0.453 (in-sample avg dev_std = 0.445)
NEC for r=0.8 all L1 = 0.216 +- 0.276 (in-sample avg dev_std = 0.445)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 20:14:33 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 03/22/2024 08:14:33 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 08:14:33 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 08:14:33 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/22/2024 08:14:33 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 08:14:33 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:14:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:14:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:14:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:14:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:14:33 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/22/2024 08:14:33 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:14:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:14:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:14:33 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/22/2024 08:14:33 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 183...
[0m[1;37mINFO[0m: [1mCheckpoint 183: 
-----------------------------------
Train ACCURACY: 0.8962
Train Loss: 0.4182
ID Validation ACCURACY: 0.9057
ID Validation Loss: 0.4121
ID Test ACCURACY: 0.8953
ID Test Loss: 0.4527
OOD Validation ACCURACY: 0.9027
OOD Validation Loss: 0.4390
OOD Test ACCURACY: 0.4087
OOD Test Loss: 28.0354

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 129...
[0m[1;37mINFO[0m: [1mCheckpoint 129: 
-----------------------------------
Train ACCURACY: 0.8330
Train Loss: 0.5186
ID Validation ACCURACY: 0.8323
ID Validation Loss: 0.5186
ID Test ACCURACY: 0.8267
ID Test Loss: 0.5417
OOD Validation ACCURACY: 0.9140
OOD Validation Loss: 0.4398
OOD Test ACCURACY: 0.4087
OOD Test Loss: 25.0431

[0m[1;37mINFO[0m: [1mChartInfo 0.8953 0.4087 0.8267 0.4087 0.8323 0.9140[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.8 = 0.481
WIoU for r=0.8 = 0.660
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.8 = 0.300
WIoU for r=0.8 = 0.800
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.8 = 0.186
WIoU for r=0.8 = 0.101


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.914
Model XAI F1 of binarized graphs for r=0.8 =  0.48077875
Model XAI WIoU of binarized graphs for r=0.8 =  0.66012875
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.591
SUFF++ for r=0.8 class 0 = 0.342 +- 0.330 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.8 class 1 = 0.589 +- 0.330 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.8 class 2 = 0.625 +- 0.330 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.8 all KL = 0.481 +- 0.330 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.8 all L1 = 0.518 +- 0.255 (in-sample avg dev_std = 0.460)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.908
Model XAI F1 of binarized graphs for r=0.8 =  0.3002225
Model XAI WIoU of binarized graphs for r=0.8 =  0.80019875
len(reference) = 800
Effective ratio: 0.806 +- 0.005
Model Accuracy over intervened graphs for r=0.8 =  0.597
SUFF++ for r=0.8 class 0 = 0.376 +- 0.238 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.8 class 1 = 0.663 +- 0.238 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.8 class 2 = 0.742 +- 0.238 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.8 all KL = 0.637 +- 0.238 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.8 all L1 = 0.593 +- 0.223 (in-sample avg dev_std = 0.426)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.404
Model XAI F1 of binarized graphs for r=0.8 =  0.18561999999999998
Model XAI WIoU of binarized graphs for r=0.8 =  0.1005675
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.37
SUFF++ for r=0.8 class 0 = 0.896 +- 0.259 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.8 class 1 = 0.871 +- 0.259 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.8 class 2 = 0.938 +- 0.259 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.8 all KL = 0.884 +- 0.259 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.8 all L1 = 0.901 +- 0.198 (in-sample avg dev_std = 0.300)


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.914
Model XAI F1 of binarized graphs for r=0.8 =  0.48077875
Model XAI WIoU of binarized graphs for r=0.8 =  0.66012875
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.462
NEC for r=0.8 class 0 = 0.618 +- 0.228 (in-sample avg dev_std = 0.702)
NEC for r=0.8 class 1 = 0.588 +- 0.228 (in-sample avg dev_std = 0.702)
NEC for r=0.8 class 2 = 0.615 +- 0.228 (in-sample avg dev_std = 0.702)
NEC for r=0.8 all KL = 0.718 +- 0.228 (in-sample avg dev_std = 0.702)
NEC for r=0.8 all L1 = 0.607 +- 0.143 (in-sample avg dev_std = 0.702)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.908
Model XAI F1 of binarized graphs for r=0.8 =  0.3002225
Model XAI WIoU of binarized graphs for r=0.8 =  0.80019875
len(reference) = 800
Effective ratio: 0.806 +- 0.005
Model Accuracy over intervened graphs for r=0.8 =  0.494
NEC for r=0.8 class 0 = 0.578 +- 0.220 (in-sample avg dev_std = 0.571)
NEC for r=0.8 class 1 = 0.527 +- 0.220 (in-sample avg dev_std = 0.571)
NEC for r=0.8 class 2 = 0.496 +- 0.220 (in-sample avg dev_std = 0.571)
NEC for r=0.8 all KL = 0.558 +- 0.220 (in-sample avg dev_std = 0.571)
NEC for r=0.8 all L1 = 0.534 +- 0.124 (in-sample avg dev_std = 0.571)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.404
Model XAI F1 of binarized graphs for r=0.8 =  0.18561999999999998
Model XAI WIoU of binarized graphs for r=0.8 =  0.1005675
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.412
NEC for r=0.8 class 0 = 0.272 +- 0.443 (in-sample avg dev_std = 0.479)
NEC for r=0.8 class 1 = 0.224 +- 0.443 (in-sample avg dev_std = 0.479)
NEC for r=0.8 class 2 = 0.157 +- 0.443 (in-sample avg dev_std = 0.479)
NEC for r=0.8 all KL = 0.411 +- 0.443 (in-sample avg dev_std = 0.479)
NEC for r=0.8 all L1 = 0.217 +- 0.281 (in-sample avg dev_std = 0.479)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.621], 'all_L1': [0.651]}), defaultdict(<class 'list'>, {'all_KL': [0.702], 'all_L1': [0.726]}), defaultdict(<class 'list'>, {'all_KL': [0.626], 'all_L1': [0.642]}), defaultdict(<class 'list'>, {'all_KL': [0.672], 'all_L1': [0.691]}), defaultdict(<class 'list'>, {'all_KL': [0.481], 'all_L1': [0.518]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.732], 'all_L1': [0.611]}), defaultdict(<class 'list'>, {'all_KL': [0.721], 'all_L1': [0.568]}), defaultdict(<class 'list'>, {'all_KL': [0.775], 'all_L1': [0.601]}), defaultdict(<class 'list'>, {'all_KL': [0.781], 'all_L1': [0.615]}), defaultdict(<class 'list'>, {'all_KL': [0.718], 'all_L1': [0.607]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.593], 'all_L1': [0.57]}), defaultdict(<class 'list'>, {'all_KL': [0.724], 'all_L1': [0.681]}), defaultdict(<class 'list'>, {'all_KL': [0.64], 'all_L1': [0.587]}), defaultdict(<class 'list'>, {'all_KL': [0.601], 'all_L1': [0.568]}), defaultdict(<class 'list'>, {'all_KL': [0.637], 'all_L1': [0.593]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.583], 'all_L1': [0.544]}), defaultdict(<class 'list'>, {'all_KL': [0.586], 'all_L1': [0.533]}), defaultdict(<class 'list'>, {'all_KL': [0.6], 'all_L1': [0.535]}), defaultdict(<class 'list'>, {'all_KL': [0.631], 'all_L1': [0.561]}), defaultdict(<class 'list'>, {'all_KL': [0.558], 'all_L1': [0.534]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.786], 'all_L1': [0.87]}), defaultdict(<class 'list'>, {'all_KL': [0.628], 'all_L1': [0.675]}), defaultdict(<class 'list'>, {'all_KL': [0.926], 'all_L1': [0.905]}), defaultdict(<class 'list'>, {'all_KL': [0.918], 'all_L1': [0.916]}), defaultdict(<class 'list'>, {'all_KL': [0.884], 'all_L1': [0.901]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.386], 'all_L1': [0.218]}), defaultdict(<class 'list'>, {'all_KL': [0.606], 'all_L1': [0.445]}), defaultdict(<class 'list'>, {'all_KL': [0.323], 'all_L1': [0.178]}), defaultdict(<class 'list'>, {'all_KL': [0.401], 'all_L1': [0.216]}), defaultdict(<class 'list'>, {'all_KL': [0.411], 'all_L1': [0.217]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.646 +- 0.070
suff++ class all_KL  =  0.620 +- 0.076
suff++_acc_int  =  0.687 +- 0.058
nec class all_L1  =  0.600 +- 0.017
nec class all_KL  =  0.745 +- 0.027
nec_acc_int  =  0.452 +- 0.010

Eval split val
suff++ class all_L1  =  0.600 +- 0.042
suff++ class all_KL  =  0.639 +- 0.046
suff++_acc_int  =  0.588 +- 0.067
nec class all_L1  =  0.541 +- 0.011
nec class all_KL  =  0.592 +- 0.024
nec_acc_int  =  0.461 +- 0.042

Eval split test
suff++ class all_L1  =  0.853 +- 0.090
suff++ class all_KL  =  0.828 +- 0.112
suff++_acc_int  =  0.401 +- 0.063
nec class all_L1  =  0.255 +- 0.096
nec class all_KL  =  0.425 +- 0.095
nec_acc_int  =  0.416 +- 0.060


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.623 +- 0.032
Faith. Armon (L1)= 		  =  0.620 +- 0.032
Faith. GMean (L1)= 	  =  0.621 +- 0.032
Faith. Aritm (KL)= 		  =  0.683 +- 0.045
Faith. Armon (KL)= 		  =  0.675 +- 0.052
Faith. GMean (KL)= 	  =  0.679 +- 0.049

Eval split val
Faith. Aritm (L1)= 		  =  0.571 +- 0.018
Faith. Armon (L1)= 		  =  0.568 +- 0.015
Faith. GMean (L1)= 	  =  0.569 +- 0.017
Faith. Aritm (KL)= 		  =  0.615 +- 0.023
Faith. Armon (KL)= 		  =  0.613 +- 0.021
Faith. GMean (KL)= 	  =  0.614 +- 0.022

Eval split test
Faith. Aritm (L1)= 		  =  0.554 +- 0.010
Faith. Armon (L1)= 		  =  0.376 +- 0.082
Faith. GMean (L1)= 	  =  0.454 +- 0.049
Faith. Aritm (KL)= 		  =  0.627 +- 0.026
Faith. Armon (KL)= 		  =  0.547 +- 0.046
Faith. GMean (KL)= 	  =  0.585 +- 0.030
Computed for split load_split = id



Completed in  0:05:52.841878  for CIGAGIN GOODMotif2/basis



DONE CIGA GOODMotif2/basis

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 20:15:54 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 03/22/2024 08:15:54 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 08:15:54 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 08:15:54 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:15:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:15:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:15:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:15:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:15:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:15:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:15:54 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 107...
[0m[1;37mINFO[0m: [1mCheckpoint 107: 
-----------------------------------
Train ACCURACY: 0.9297
Train Loss: 0.3252
ID Validation ACCURACY: 0.9357
ID Validation Loss: 0.3127
ID Test ACCURACY: 0.9257
ID Test Loss: 0.3421
OOD Validation ACCURACY: 0.9270
OOD Validation Loss: 0.4181
OOD Test ACCURACY: 0.7947
OOD Test Loss: 0.8208

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 47...
[0m[1;37mINFO[0m: [1mCheckpoint 47: 
-----------------------------------
Train ACCURACY: 0.9265
Train Loss: 0.3388
ID Validation ACCURACY: 0.9317
ID Validation Loss: 0.3254
ID Test ACCURACY: 0.9243
ID Test Loss: 0.3540
OOD Validation ACCURACY: 0.9300
OOD Validation Loss: 0.3738
OOD Test ACCURACY: 0.6353
OOD Test Loss: 1.7363

[0m[1;37mINFO[0m: [1mChartInfo 0.9257 0.7947 0.9243 0.6353 0.9317 0.9300[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.690
WIoU for r=0.3 = 0.572
F1 for r=0.6 = 0.574
WIoU for r=0.6 = 0.453
F1 for r=0.9 = 0.464
WIoU for r=0.9 = 0.339
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.328
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.481
WIoU for r=0.3 = 0.372
F1 for r=0.6 = 0.313
WIoU for r=0.6 = 0.211
F1 for r=0.9 = 0.252
WIoU for r=0.9 = 0.161
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.169
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.570
WIoU for r=0.3 = 0.454
F1 for r=0.6 = 0.495
WIoU for r=0.6 = 0.360
F1 for r=0.9 = 0.413
WIoU for r=0.9 = 0.282
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.264


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.438
Model XAI F1 of binarized graphs for r=0.3 =  0.69020375
Model XAI WIoU of binarized graphs for r=0.3 =  0.5715100000000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.448
SUFF++ for r=0.3 class 0 = 0.506 +- 0.274 (in-sample avg dev_std = 0.458)
SUFF++ for r=0.3 class 1 = 0.582 +- 0.274 (in-sample avg dev_std = 0.458)
SUFF++ for r=0.3 class 2 = 0.516 +- 0.274 (in-sample avg dev_std = 0.458)
SUFF++ for r=0.3 all KL = 0.552 +- 0.274 (in-sample avg dev_std = 0.458)
SUFF++ for r=0.3 all L1 = 0.535 +- 0.158 (in-sample avg dev_std = 0.458)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.67
Model XAI F1 of binarized graphs for r=0.6 =  0.5735825
Model XAI WIoU of binarized graphs for r=0.6 =  0.45319249999999994
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.619
SUFF++ for r=0.6 class 0 = 0.442 +- 0.268 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.6 class 1 = 0.782 +- 0.268 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.6 class 2 = 0.645 +- 0.268 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.6 all KL = 0.642 +- 0.268 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.6 all L1 = 0.623 +- 0.217 (in-sample avg dev_std = 0.387)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.914
Model XAI F1 of binarized graphs for r=0.9 =  0.46355375000000004
Model XAI WIoU of binarized graphs for r=0.9 =  0.33887749999999994
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.823
SUFF++ for r=0.9 class 0 = 0.605 +- 0.186 (in-sample avg dev_std = 0.314)
SUFF++ for r=0.9 class 1 = 0.86 +- 0.186 (in-sample avg dev_std = 0.314)
SUFF++ for r=0.9 class 2 = 0.819 +- 0.186 (in-sample avg dev_std = 0.314)
SUFF++ for r=0.9 all KL = 0.827 +- 0.186 (in-sample avg dev_std = 0.314)
SUFF++ for r=0.9 all L1 = 0.761 +- 0.176 (in-sample avg dev_std = 0.314)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.57
Model XAI F1 of binarized graphs for r=0.3 =  0.48095625
Model XAI WIoU of binarized graphs for r=0.3 =  0.3720125
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.548
SUFF++ for r=0.3 class 0 = 0.594 +- 0.234 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.3 class 1 = 0.644 +- 0.234 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.3 class 2 = 0.549 +- 0.234 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.3 all KL = 0.685 +- 0.234 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.3 all L1 = 0.595 +- 0.156 (in-sample avg dev_std = 0.387)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.676
Model XAI F1 of binarized graphs for r=0.6 =  0.3126775
Model XAI WIoU of binarized graphs for r=0.6 =  0.21100875000000002
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.549
SUFF++ for r=0.6 class 0 = 0.455 +- 0.206 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.6 class 1 = 0.702 +- 0.206 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.6 class 2 = 0.56 +- 0.206 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.6 all KL = 0.697 +- 0.206 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.6 all L1 = 0.571 +- 0.157 (in-sample avg dev_std = 0.322)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.84
Model XAI F1 of binarized graphs for r=0.9 =  0.25246625
Model XAI WIoU of binarized graphs for r=0.9 =  0.1609525
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.726
SUFF++ for r=0.9 class 0 = 0.558 +- 0.173 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 1 = 0.735 +- 0.173 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 2 = 0.705 +- 0.173 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 all KL = 0.781 +- 0.173 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 all L1 = 0.665 +- 0.148 (in-sample avg dev_std = 0.305)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.359
Model XAI F1 of binarized graphs for r=0.3 =  0.56971625
Model XAI WIoU of binarized graphs for r=0.3 =  0.45398375
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.465
SUFF++ for r=0.3 class 0 = 0.567 +- 0.236 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.3 class 1 = 0.643 +- 0.236 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.3 class 2 = 0.615 +- 0.236 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.3 all KL = 0.657 +- 0.236 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.3 all L1 = 0.609 +- 0.164 (in-sample avg dev_std = 0.380)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.766
Model XAI F1 of binarized graphs for r=0.6 =  0.4948887500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.35975250000000003
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.668
SUFF++ for r=0.6 class 0 = 0.472 +- 0.185 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.6 class 1 = 0.804 +- 0.185 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.6 class 2 = 0.682 +- 0.185 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.6 all KL = 0.735 +- 0.185 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.6 all L1 = 0.656 +- 0.192 (in-sample avg dev_std = 0.351)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.754
Model XAI F1 of binarized graphs for r=0.9 =  0.4132875
Model XAI WIoU of binarized graphs for r=0.9 =  0.281845
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.749
SUFF++ for r=0.9 class 0 = 0.595 +- 0.141 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 class 1 = 0.826 +- 0.141 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 class 2 = 0.836 +- 0.141 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 all KL = 0.866 +- 0.141 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 all L1 = 0.755 +- 0.173 (in-sample avg dev_std = 0.217)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.435
Model XAI F1 of binarized graphs for r=0.3 =  0.69020375
Model XAI WIoU of binarized graphs for r=0.3 =  0.5715100000000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.307
NEC for r=0.3 class 0 = 0.58 +- 0.306 (in-sample avg dev_std = 0.374)
NEC for r=0.3 class 1 = 0.463 +- 0.306 (in-sample avg dev_std = 0.374)
NEC for r=0.3 class 2 = 0.635 +- 0.306 (in-sample avg dev_std = 0.374)
NEC for r=0.3 all KL = 0.556 +- 0.306 (in-sample avg dev_std = 0.374)
NEC for r=0.3 all L1 = 0.559 +- 0.193 (in-sample avg dev_std = 0.374)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.671
Model XAI F1 of binarized graphs for r=0.6 =  0.5735825
Model XAI WIoU of binarized graphs for r=0.6 =  0.45319249999999994
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.405
NEC for r=0.6 class 0 = 0.582 +- 0.266 (in-sample avg dev_std = 0.456)
NEC for r=0.6 class 1 = 0.464 +- 0.266 (in-sample avg dev_std = 0.456)
NEC for r=0.6 class 2 = 0.659 +- 0.266 (in-sample avg dev_std = 0.456)
NEC for r=0.6 all KL = 0.616 +- 0.266 (in-sample avg dev_std = 0.456)
NEC for r=0.6 all L1 = 0.568 +- 0.177 (in-sample avg dev_std = 0.456)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.914
Model XAI F1 of binarized graphs for r=0.9 =  0.46355375000000004
Model XAI WIoU of binarized graphs for r=0.9 =  0.33887749999999994
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.521
NEC for r=0.9 class 0 = 0.608 +- 0.220 (in-sample avg dev_std = 0.572)
NEC for r=0.9 class 1 = 0.462 +- 0.220 (in-sample avg dev_std = 0.572)
NEC for r=0.9 class 2 = 0.58 +- 0.220 (in-sample avg dev_std = 0.572)
NEC for r=0.9 all KL = 0.58 +- 0.220 (in-sample avg dev_std = 0.572)
NEC for r=0.9 all L1 = 0.55 +- 0.153 (in-sample avg dev_std = 0.572)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.942
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.32798125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.549
NEC for r=1.0 class 0 = 0.563 +- 0.231 (in-sample avg dev_std = 0.616)
NEC for r=1.0 class 1 = 0.428 +- 0.231 (in-sample avg dev_std = 0.616)
NEC for r=1.0 class 2 = 0.566 +- 0.231 (in-sample avg dev_std = 0.616)
NEC for r=1.0 all KL = 0.553 +- 0.231 (in-sample avg dev_std = 0.616)
NEC for r=1.0 all L1 = 0.519 +- 0.168 (in-sample avg dev_std = 0.616)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.574
Model XAI F1 of binarized graphs for r=0.3 =  0.48095625
Model XAI WIoU of binarized graphs for r=0.3 =  0.3720125
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.343
NEC for r=0.3 class 0 = 0.441 +- 0.271 (in-sample avg dev_std = 0.340)
NEC for r=0.3 class 1 = 0.474 +- 0.271 (in-sample avg dev_std = 0.340)
NEC for r=0.3 class 2 = 0.671 +- 0.271 (in-sample avg dev_std = 0.340)
NEC for r=0.3 all KL = 0.451 +- 0.271 (in-sample avg dev_std = 0.340)
NEC for r=0.3 all L1 = 0.529 +- 0.160 (in-sample avg dev_std = 0.340)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.679
Model XAI F1 of binarized graphs for r=0.6 =  0.3126775
Model XAI WIoU of binarized graphs for r=0.6 =  0.21100875000000002
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.42
NEC for r=0.6 class 0 = 0.562 +- 0.216 (in-sample avg dev_std = 0.405)
NEC for r=0.6 class 1 = 0.432 +- 0.216 (in-sample avg dev_std = 0.405)
NEC for r=0.6 class 2 = 0.564 +- 0.216 (in-sample avg dev_std = 0.405)
NEC for r=0.6 all KL = 0.421 +- 0.216 (in-sample avg dev_std = 0.405)
NEC for r=0.6 all L1 = 0.52 +- 0.133 (in-sample avg dev_std = 0.405)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.841
Model XAI F1 of binarized graphs for r=0.9 =  0.25246625
Model XAI WIoU of binarized graphs for r=0.9 =  0.1609525
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.533
NEC for r=0.9 class 0 = 0.544 +- 0.180 (in-sample avg dev_std = 0.480)
NEC for r=0.9 class 1 = 0.492 +- 0.180 (in-sample avg dev_std = 0.480)
NEC for r=0.9 class 2 = 0.486 +- 0.180 (in-sample avg dev_std = 0.480)
NEC for r=0.9 all KL = 0.454 +- 0.180 (in-sample avg dev_std = 0.480)
NEC for r=0.9 all L1 = 0.508 +- 0.107 (in-sample avg dev_std = 0.480)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.929
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.16925374999999998
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.573
NEC for r=1.0 class 0 = 0.483 +- 0.208 (in-sample avg dev_std = 0.542)
NEC for r=1.0 class 1 = 0.459 +- 0.208 (in-sample avg dev_std = 0.542)
NEC for r=1.0 class 2 = 0.522 +- 0.208 (in-sample avg dev_std = 0.542)
NEC for r=1.0 all KL = 0.478 +- 0.208 (in-sample avg dev_std = 0.542)
NEC for r=1.0 all L1 = 0.488 +- 0.121 (in-sample avg dev_std = 0.542)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.359
Model XAI F1 of binarized graphs for r=0.3 =  0.56971625
Model XAI WIoU of binarized graphs for r=0.3 =  0.45398375
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.407
NEC for r=0.3 class 0 = 0.466 +- 0.261 (in-sample avg dev_std = 0.399)
NEC for r=0.3 class 1 = 0.546 +- 0.261 (in-sample avg dev_std = 0.399)
NEC for r=0.3 class 2 = 0.575 +- 0.261 (in-sample avg dev_std = 0.399)
NEC for r=0.3 all KL = 0.513 +- 0.261 (in-sample avg dev_std = 0.399)
NEC for r=0.3 all L1 = 0.53 +- 0.156 (in-sample avg dev_std = 0.399)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.766
Model XAI F1 of binarized graphs for r=0.6 =  0.4948887500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.35975250000000003
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.429
NEC for r=0.6 class 0 = 0.615 +- 0.246 (in-sample avg dev_std = 0.555)
NEC for r=0.6 class 1 = 0.435 +- 0.246 (in-sample avg dev_std = 0.555)
NEC for r=0.6 class 2 = 0.626 +- 0.246 (in-sample avg dev_std = 0.555)
NEC for r=0.6 all KL = 0.578 +- 0.246 (in-sample avg dev_std = 0.555)
NEC for r=0.6 all L1 = 0.557 +- 0.174 (in-sample avg dev_std = 0.555)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.754
Model XAI F1 of binarized graphs for r=0.9 =  0.4132875
Model XAI WIoU of binarized graphs for r=0.9 =  0.281845
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.582
NEC for r=0.9 class 0 = 0.53 +- 0.236 (in-sample avg dev_std = 0.491)
NEC for r=0.9 class 1 = 0.348 +- 0.236 (in-sample avg dev_std = 0.491)
NEC for r=0.9 class 2 = 0.442 +- 0.236 (in-sample avg dev_std = 0.491)
NEC for r=0.9 all KL = 0.396 +- 0.236 (in-sample avg dev_std = 0.491)
NEC for r=0.9 all L1 = 0.438 +- 0.178 (in-sample avg dev_std = 0.491)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.809
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.26427125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.608
NEC for r=1.0 class 0 = 0.457 +- 0.259 (in-sample avg dev_std = 0.473)
NEC for r=1.0 class 1 = 0.331 +- 0.259 (in-sample avg dev_std = 0.473)
NEC for r=1.0 class 2 = 0.407 +- 0.259 (in-sample avg dev_std = 0.473)
NEC for r=1.0 all KL = 0.369 +- 0.259 (in-sample avg dev_std = 0.473)
NEC for r=1.0 all L1 = 0.397 +- 0.174 (in-sample avg dev_std = 0.473)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 20:19:53 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 03/22/2024 08:19:53 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 08:19:53 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 08:19:53 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:19:53 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 133...
[0m[1;37mINFO[0m: [1mCheckpoint 133: 
-----------------------------------
Train ACCURACY: 0.9303
Train Loss: 0.3173
ID Validation ACCURACY: 0.9357
ID Validation Loss: 0.3076
ID Test ACCURACY: 0.9260
ID Test Loss: 0.3411
OOD Validation ACCURACY: 0.8477
OOD Validation Loss: 0.4798
OOD Test ACCURACY: 0.6430
OOD Test Loss: 0.9596

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 13...
[0m[1;37mINFO[0m: [1mCheckpoint 13: 
-----------------------------------
Train ACCURACY: 0.9249
Train Loss: 0.3435
ID Validation ACCURACY: 0.9297
ID Validation Loss: 0.3292
ID Test ACCURACY: 0.9200
ID Test Loss: 0.3609
OOD Validation ACCURACY: 0.9273
OOD Validation Loss: 0.3859
OOD Test ACCURACY: 0.5833
OOD Test Loss: 1.8691

[0m[1;37mINFO[0m: [1mChartInfo 0.9260 0.6430 0.9200 0.5833 0.9297 0.9273[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.733
WIoU for r=0.3 = 0.617
F1 for r=0.6 = 0.605
WIoU for r=0.6 = 0.483
F1 for r=0.9 = 0.479
WIoU for r=0.9 = 0.356
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.332
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.553
WIoU for r=0.3 = 0.427
F1 for r=0.6 = 0.362
WIoU for r=0.6 = 0.244
F1 for r=0.9 = 0.277
WIoU for r=0.9 = 0.178
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.172
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.676
WIoU for r=0.3 = 0.547
F1 for r=0.6 = 0.508
WIoU for r=0.6 = 0.374
F1 for r=0.9 = 0.413
WIoU for r=0.9 = 0.285
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.268


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.494
Model XAI F1 of binarized graphs for r=0.3 =  0.7330737500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.6167475
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.45
SUFF++ for r=0.3 class 0 = 0.446 +- 0.280 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.3 class 1 = 0.482 +- 0.280 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.3 class 2 = 0.536 +- 0.280 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.3 all KL = 0.501 +- 0.280 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.3 all L1 = 0.488 +- 0.166 (in-sample avg dev_std = 0.482)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.771
Model XAI F1 of binarized graphs for r=0.6 =  0.604735
Model XAI WIoU of binarized graphs for r=0.6 =  0.48319
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.674
SUFF++ for r=0.6 class 0 = 0.46 +- 0.255 (in-sample avg dev_std = 0.439)
SUFF++ for r=0.6 class 1 = 0.707 +- 0.255 (in-sample avg dev_std = 0.439)
SUFF++ for r=0.6 class 2 = 0.676 +- 0.255 (in-sample avg dev_std = 0.439)
SUFF++ for r=0.6 all KL = 0.621 +- 0.255 (in-sample avg dev_std = 0.439)
SUFF++ for r=0.6 all L1 = 0.614 +- 0.193 (in-sample avg dev_std = 0.439)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.911
Model XAI F1 of binarized graphs for r=0.9 =  0.47906499999999996
Model XAI WIoU of binarized graphs for r=0.9 =  0.3562675
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.854
SUFF++ for r=0.9 class 0 = 0.713 +- 0.184 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 class 1 = 0.827 +- 0.184 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 class 2 = 0.83 +- 0.184 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 all KL = 0.854 +- 0.184 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 all L1 = 0.79 +- 0.180 (in-sample avg dev_std = 0.271)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.785
Model XAI F1 of binarized graphs for r=0.3 =  0.55335375
Model XAI WIoU of binarized graphs for r=0.3 =  0.4268925
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.606
SUFF++ for r=0.3 class 0 = 0.436 +- 0.280 (in-sample avg dev_std = 0.453)
SUFF++ for r=0.3 class 1 = 0.607 +- 0.280 (in-sample avg dev_std = 0.453)
SUFF++ for r=0.3 class 2 = 0.647 +- 0.280 (in-sample avg dev_std = 0.453)
SUFF++ for r=0.3 all KL = 0.577 +- 0.280 (in-sample avg dev_std = 0.453)
SUFF++ for r=0.3 all L1 = 0.563 +- 0.189 (in-sample avg dev_std = 0.453)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.777
Model XAI F1 of binarized graphs for r=0.6 =  0.36238249999999994
Model XAI WIoU of binarized graphs for r=0.6 =  0.24410375
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.643
SUFF++ for r=0.6 class 0 = 0.439 +- 0.218 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 class 1 = 0.653 +- 0.218 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 class 2 = 0.59 +- 0.218 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 all KL = 0.648 +- 0.218 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 all L1 = 0.56 +- 0.155 (in-sample avg dev_std = 0.353)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.754
Model XAI F1 of binarized graphs for r=0.9 =  0.2766025
Model XAI WIoU of binarized graphs for r=0.9 =  0.17758000000000002
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.687
SUFF++ for r=0.9 class 0 = 0.544 +- 0.168 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.9 class 1 = 0.625 +- 0.168 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.9 class 2 = 0.736 +- 0.168 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.9 all KL = 0.755 +- 0.168 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.9 all L1 = 0.635 +- 0.153 (in-sample avg dev_std = 0.310)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.694
Model XAI F1 of binarized graphs for r=0.3 =  0.6756125000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.5474874999999999
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.53
SUFF++ for r=0.3 class 0 = 0.48 +- 0.289 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.3 class 1 = 0.627 +- 0.289 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.3 class 2 = 0.596 +- 0.289 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.3 all KL = 0.56 +- 0.289 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.3 all L1 = 0.569 +- 0.190 (in-sample avg dev_std = 0.508)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.75
Model XAI F1 of binarized graphs for r=0.6 =  0.50813
Model XAI WIoU of binarized graphs for r=0.6 =  0.374095
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.685
SUFF++ for r=0.6 class 0 = 0.459 +- 0.235 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.6 class 1 = 0.726 +- 0.235 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.6 class 2 = 0.707 +- 0.235 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.6 all KL = 0.659 +- 0.235 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.6 all L1 = 0.633 +- 0.182 (in-sample avg dev_std = 0.420)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.755
Model XAI F1 of binarized graphs for r=0.9 =  0.413335
Model XAI WIoU of binarized graphs for r=0.9 =  0.2854925
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.705
SUFF++ for r=0.9 class 0 = 0.601 +- 0.225 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.9 class 1 = 0.734 +- 0.225 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.9 class 2 = 0.909 +- 0.225 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.9 all KL = 0.809 +- 0.225 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.9 all L1 = 0.75 +- 0.192 (in-sample avg dev_std = 0.348)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.494
Model XAI F1 of binarized graphs for r=0.3 =  0.7330737500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.6167475
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.31
NEC for r=0.3 class 0 = 0.643 +- 0.269 (in-sample avg dev_std = 0.410)
NEC for r=0.3 class 1 = 0.599 +- 0.269 (in-sample avg dev_std = 0.410)
NEC for r=0.3 class 2 = 0.632 +- 0.269 (in-sample avg dev_std = 0.410)
NEC for r=0.3 all KL = 0.63 +- 0.269 (in-sample avg dev_std = 0.410)
NEC for r=0.3 all L1 = 0.624 +- 0.148 (in-sample avg dev_std = 0.410)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.77
Model XAI F1 of binarized graphs for r=0.6 =  0.604735
Model XAI WIoU of binarized graphs for r=0.6 =  0.48319
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.386
NEC for r=0.6 class 0 = 0.614 +- 0.290 (in-sample avg dev_std = 0.479)
NEC for r=0.6 class 1 = 0.462 +- 0.290 (in-sample avg dev_std = 0.479)
NEC for r=0.6 class 2 = 0.652 +- 0.290 (in-sample avg dev_std = 0.479)
NEC for r=0.6 all KL = 0.61 +- 0.290 (in-sample avg dev_std = 0.479)
NEC for r=0.6 all L1 = 0.575 +- 0.193 (in-sample avg dev_std = 0.479)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.91
Model XAI F1 of binarized graphs for r=0.9 =  0.47906499999999996
Model XAI WIoU of binarized graphs for r=0.9 =  0.3562675
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.522
NEC for r=0.9 class 0 = 0.588 +- 0.241 (in-sample avg dev_std = 0.582)
NEC for r=0.9 class 1 = 0.486 +- 0.241 (in-sample avg dev_std = 0.582)
NEC for r=0.9 class 2 = 0.553 +- 0.241 (in-sample avg dev_std = 0.582)
NEC for r=0.9 all KL = 0.572 +- 0.241 (in-sample avg dev_std = 0.582)
NEC for r=0.9 all L1 = 0.542 +- 0.154 (in-sample avg dev_std = 0.582)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.942
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.3318175
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.538
NEC for r=1.0 class 0 = 0.551 +- 0.236 (in-sample avg dev_std = 0.609)
NEC for r=1.0 class 1 = 0.448 +- 0.236 (in-sample avg dev_std = 0.609)
NEC for r=1.0 class 2 = 0.555 +- 0.236 (in-sample avg dev_std = 0.609)
NEC for r=1.0 all KL = 0.553 +- 0.236 (in-sample avg dev_std = 0.609)
NEC for r=1.0 all L1 = 0.518 +- 0.164 (in-sample avg dev_std = 0.609)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.784
Model XAI F1 of binarized graphs for r=0.3 =  0.55335375
Model XAI WIoU of binarized graphs for r=0.3 =  0.4268925
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.306
NEC for r=0.3 class 0 = 0.605 +- 0.283 (in-sample avg dev_std = 0.423)
NEC for r=0.3 class 1 = 0.547 +- 0.283 (in-sample avg dev_std = 0.423)
NEC for r=0.3 class 2 = 0.728 +- 0.283 (in-sample avg dev_std = 0.423)
NEC for r=0.3 all KL = 0.637 +- 0.283 (in-sample avg dev_std = 0.423)
NEC for r=0.3 all L1 = 0.628 +- 0.145 (in-sample avg dev_std = 0.423)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.771
Model XAI F1 of binarized graphs for r=0.6 =  0.36238249999999994
Model XAI WIoU of binarized graphs for r=0.6 =  0.24410375
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.431
NEC for r=0.6 class 0 = 0.609 +- 0.235 (in-sample avg dev_std = 0.459)
NEC for r=0.6 class 1 = 0.472 +- 0.235 (in-sample avg dev_std = 0.459)
NEC for r=0.6 class 2 = 0.612 +- 0.235 (in-sample avg dev_std = 0.459)
NEC for r=0.6 all KL = 0.524 +- 0.235 (in-sample avg dev_std = 0.459)
NEC for r=0.6 all L1 = 0.565 +- 0.128 (in-sample avg dev_std = 0.459)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.755
Model XAI F1 of binarized graphs for r=0.9 =  0.2766025
Model XAI WIoU of binarized graphs for r=0.9 =  0.17758000000000002
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.482
NEC for r=0.9 class 0 = 0.547 +- 0.198 (in-sample avg dev_std = 0.474)
NEC for r=0.9 class 1 = 0.553 +- 0.198 (in-sample avg dev_std = 0.474)
NEC for r=0.9 class 2 = 0.45 +- 0.198 (in-sample avg dev_std = 0.474)
NEC for r=0.9 all KL = 0.459 +- 0.198 (in-sample avg dev_std = 0.474)
NEC for r=0.9 all L1 = 0.516 +- 0.124 (in-sample avg dev_std = 0.474)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.85
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.1719625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.567
NEC for r=1.0 class 0 = 0.504 +- 0.207 (in-sample avg dev_std = 0.532)
NEC for r=1.0 class 1 = 0.475 +- 0.207 (in-sample avg dev_std = 0.532)
NEC for r=1.0 class 2 = 0.503 +- 0.207 (in-sample avg dev_std = 0.532)
NEC for r=1.0 all KL = 0.471 +- 0.207 (in-sample avg dev_std = 0.532)
NEC for r=1.0 all L1 = 0.494 +- 0.110 (in-sample avg dev_std = 0.532)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.694
Model XAI F1 of binarized graphs for r=0.3 =  0.6756125000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.5474874999999999
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.448
NEC for r=0.3 class 0 = 0.585 +- 0.241 (in-sample avg dev_std = 0.499)
NEC for r=0.3 class 1 = 0.61 +- 0.241 (in-sample avg dev_std = 0.499)
NEC for r=0.3 class 2 = 0.63 +- 0.241 (in-sample avg dev_std = 0.499)
NEC for r=0.3 all KL = 0.662 +- 0.241 (in-sample avg dev_std = 0.499)
NEC for r=0.3 all L1 = 0.609 +- 0.133 (in-sample avg dev_std = 0.499)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.751
Model XAI F1 of binarized graphs for r=0.6 =  0.50813
Model XAI WIoU of binarized graphs for r=0.6 =  0.374095
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.452
NEC for r=0.6 class 0 = 0.605 +- 0.247 (in-sample avg dev_std = 0.574)
NEC for r=0.6 class 1 = 0.544 +- 0.247 (in-sample avg dev_std = 0.574)
NEC for r=0.6 class 2 = 0.6 +- 0.247 (in-sample avg dev_std = 0.574)
NEC for r=0.6 all KL = 0.633 +- 0.247 (in-sample avg dev_std = 0.574)
NEC for r=0.6 all L1 = 0.583 +- 0.138 (in-sample avg dev_std = 0.574)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.754
Model XAI F1 of binarized graphs for r=0.9 =  0.413335
Model XAI WIoU of binarized graphs for r=0.9 =  0.2854925
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.576
NEC for r=0.9 class 0 = 0.545 +- 0.292 (in-sample avg dev_std = 0.561)
NEC for r=0.9 class 1 = 0.432 +- 0.292 (in-sample avg dev_std = 0.561)
NEC for r=0.9 class 2 = 0.438 +- 0.292 (in-sample avg dev_std = 0.561)
NEC for r=0.9 all KL = 0.544 +- 0.292 (in-sample avg dev_std = 0.561)
NEC for r=0.9 all L1 = 0.471 +- 0.161 (in-sample avg dev_std = 0.561)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.656
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.26764499999999997
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.575
NEC for r=1.0 class 0 = 0.454 +- 0.235 (in-sample avg dev_std = 0.455)
NEC for r=1.0 class 1 = 0.407 +- 0.235 (in-sample avg dev_std = 0.455)
NEC for r=1.0 class 2 = 0.327 +- 0.235 (in-sample avg dev_std = 0.455)
NEC for r=1.0 all KL = 0.378 +- 0.235 (in-sample avg dev_std = 0.455)
NEC for r=1.0 all L1 = 0.396 +- 0.150 (in-sample avg dev_std = 0.455)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 20:23:48 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 03/22/2024 08:23:48 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 08:23:48 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 08:23:48 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:23:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:23:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:23:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:23:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:23:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:23:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:23:48 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 110...
[0m[1;37mINFO[0m: [1mCheckpoint 110: 
-----------------------------------
Train ACCURACY: 0.9289
Train Loss: 0.3303
ID Validation ACCURACY: 0.9350
ID Validation Loss: 0.3133
ID Test ACCURACY: 0.9257
ID Test Loss: 0.3501
OOD Validation ACCURACY: 0.8013
OOD Validation Loss: 0.5544
OOD Test ACCURACY: 0.7917
OOD Test Loss: 0.8351

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 33...
[0m[1;37mINFO[0m: [1mCheckpoint 33: 
-----------------------------------
Train ACCURACY: 0.9260
Train Loss: 0.3556
ID Validation ACCURACY: 0.9317
ID Validation Loss: 0.3333
ID Test ACCURACY: 0.9233
ID Test Loss: 0.3700
OOD Validation ACCURACY: 0.9260
OOD Validation Loss: 0.4586
OOD Test ACCURACY: 0.6470
OOD Test Loss: 1.3751

[0m[1;37mINFO[0m: [1mChartInfo 0.9257 0.7917 0.9233 0.6470 0.9317 0.9260[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.674
WIoU for r=0.3 = 0.553
F1 for r=0.6 = 0.558
WIoU for r=0.6 = 0.434
F1 for r=0.9 = 0.469
WIoU for r=0.9 = 0.342
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.325
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.426
WIoU for r=0.3 = 0.329
F1 for r=0.6 = 0.284
WIoU for r=0.6 = 0.187
F1 for r=0.9 = 0.247
WIoU for r=0.9 = 0.151
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.163
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.636
WIoU for r=0.3 = 0.515
F1 for r=0.6 = 0.490
WIoU for r=0.6 = 0.355
F1 for r=0.9 = 0.411
WIoU for r=0.9 = 0.279
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.263


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.463
Model XAI F1 of binarized graphs for r=0.3 =  0.6743412499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.55327125
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.434
SUFF++ for r=0.3 class 0 = 0.417 +- 0.248 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.3 class 1 = 0.506 +- 0.248 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.3 class 2 = 0.488 +- 0.248 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.3 all KL = 0.462 +- 0.248 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.3 all L1 = 0.47 +- 0.167 (in-sample avg dev_std = 0.495)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.666
Model XAI F1 of binarized graphs for r=0.6 =  0.5575725
Model XAI WIoU of binarized graphs for r=0.6 =  0.4339775
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.622
SUFF++ for r=0.6 class 0 = 0.457 +- 0.255 (in-sample avg dev_std = 0.436)
SUFF++ for r=0.6 class 1 = 0.673 +- 0.255 (in-sample avg dev_std = 0.436)
SUFF++ for r=0.6 class 2 = 0.676 +- 0.255 (in-sample avg dev_std = 0.436)
SUFF++ for r=0.6 all KL = 0.605 +- 0.255 (in-sample avg dev_std = 0.436)
SUFF++ for r=0.6 all L1 = 0.602 +- 0.187 (in-sample avg dev_std = 0.436)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.911
Model XAI F1 of binarized graphs for r=0.9 =  0.4692375
Model XAI WIoU of binarized graphs for r=0.9 =  0.34176125
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.844
SUFF++ for r=0.9 class 0 = 0.656 +- 0.194 (in-sample avg dev_std = 0.306)
SUFF++ for r=0.9 class 1 = 0.856 +- 0.194 (in-sample avg dev_std = 0.306)
SUFF++ for r=0.9 class 2 = 0.824 +- 0.194 (in-sample avg dev_std = 0.306)
SUFF++ for r=0.9 all KL = 0.835 +- 0.194 (in-sample avg dev_std = 0.306)
SUFF++ for r=0.9 all L1 = 0.779 +- 0.176 (in-sample avg dev_std = 0.306)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.681
Model XAI F1 of binarized graphs for r=0.3 =  0.42621375
Model XAI WIoU of binarized graphs for r=0.3 =  0.3291075
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.56
SUFF++ for r=0.3 class 0 = 0.443 +- 0.253 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.3 class 1 = 0.61 +- 0.253 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.3 class 2 = 0.59 +- 0.253 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.3 all KL = 0.59 +- 0.253 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.3 all L1 = 0.547 +- 0.173 (in-sample avg dev_std = 0.433)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.712
Model XAI F1 of binarized graphs for r=0.6 =  0.28413124999999995
Model XAI WIoU of binarized graphs for r=0.6 =  0.1874425
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.597
SUFF++ for r=0.6 class 0 = 0.397 +- 0.246 (in-sample avg dev_std = 0.343)
SUFF++ for r=0.6 class 1 = 0.638 +- 0.246 (in-sample avg dev_std = 0.343)
SUFF++ for r=0.6 class 2 = 0.569 +- 0.246 (in-sample avg dev_std = 0.343)
SUFF++ for r=0.6 all KL = 0.623 +- 0.246 (in-sample avg dev_std = 0.343)
SUFF++ for r=0.6 all L1 = 0.534 +- 0.177 (in-sample avg dev_std = 0.343)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.637
Model XAI F1 of binarized graphs for r=0.9 =  0.24661249999999998
Model XAI WIoU of binarized graphs for r=0.9 =  0.15134125
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.632
SUFF++ for r=0.9 class 0 = 0.539 +- 0.191 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.9 class 1 = 0.673 +- 0.191 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.9 class 2 = 0.655 +- 0.191 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.9 all KL = 0.734 +- 0.191 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.9 all L1 = 0.622 +- 0.153 (in-sample avg dev_std = 0.338)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.688
Model XAI F1 of binarized graphs for r=0.3 =  0.63566625
Model XAI WIoU of binarized graphs for r=0.3 =  0.515265
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.519
SUFF++ for r=0.3 class 0 = 0.512 +- 0.278 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.3 class 1 = 0.624 +- 0.278 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.3 class 2 = 0.566 +- 0.278 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.3 all KL = 0.582 +- 0.278 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.3 all L1 = 0.569 +- 0.190 (in-sample avg dev_std = 0.472)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.681
Model XAI F1 of binarized graphs for r=0.6 =  0.48989374999999996
Model XAI WIoU of binarized graphs for r=0.6 =  0.35478499999999996
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.626
SUFF++ for r=0.6 class 0 = 0.478 +- 0.202 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 class 1 = 0.701 +- 0.202 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 class 2 = 0.712 +- 0.202 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 all KL = 0.717 +- 0.202 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 all L1 = 0.633 +- 0.175 (in-sample avg dev_std = 0.348)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.738
Model XAI F1 of binarized graphs for r=0.9 =  0.41095375000000006
Model XAI WIoU of binarized graphs for r=0.9 =  0.2793825
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.692
SUFF++ for r=0.9 class 0 = 0.685 +- 0.168 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.9 class 1 = 0.758 +- 0.168 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.9 class 2 = 0.829 +- 0.168 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.9 all KL = 0.838 +- 0.168 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.9 all L1 = 0.758 +- 0.174 (in-sample avg dev_std = 0.275)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.463
Model XAI F1 of binarized graphs for r=0.3 =  0.6743412499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.55327125
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.313
NEC for r=0.3 class 0 = 0.628 +- 0.244 (in-sample avg dev_std = 0.451)
NEC for r=0.3 class 1 = 0.549 +- 0.244 (in-sample avg dev_std = 0.451)
NEC for r=0.3 class 2 = 0.672 +- 0.244 (in-sample avg dev_std = 0.451)
NEC for r=0.3 all KL = 0.637 +- 0.244 (in-sample avg dev_std = 0.451)
NEC for r=0.3 all L1 = 0.616 +- 0.152 (in-sample avg dev_std = 0.451)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.664
Model XAI F1 of binarized graphs for r=0.6 =  0.5575725
Model XAI WIoU of binarized graphs for r=0.6 =  0.4339775
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.388
NEC for r=0.6 class 0 = 0.591 +- 0.273 (in-sample avg dev_std = 0.485)
NEC for r=0.6 class 1 = 0.458 +- 0.273 (in-sample avg dev_std = 0.485)
NEC for r=0.6 class 2 = 0.648 +- 0.273 (in-sample avg dev_std = 0.485)
NEC for r=0.6 all KL = 0.608 +- 0.273 (in-sample avg dev_std = 0.485)
NEC for r=0.6 all L1 = 0.565 +- 0.179 (in-sample avg dev_std = 0.485)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.91
Model XAI F1 of binarized graphs for r=0.9 =  0.4692375
Model XAI WIoU of binarized graphs for r=0.9 =  0.34176125
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.512
NEC for r=0.9 class 0 = 0.629 +- 0.222 (in-sample avg dev_std = 0.589)
NEC for r=0.9 class 1 = 0.467 +- 0.222 (in-sample avg dev_std = 0.589)
NEC for r=0.9 class 2 = 0.57 +- 0.222 (in-sample avg dev_std = 0.589)
NEC for r=0.9 all KL = 0.621 +- 0.222 (in-sample avg dev_std = 0.589)
NEC for r=0.9 all L1 = 0.555 +- 0.158 (in-sample avg dev_std = 0.589)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.942
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.32542875000000004
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.563
NEC for r=1.0 class 0 = 0.576 +- 0.240 (in-sample avg dev_std = 0.617)
NEC for r=1.0 class 1 = 0.399 +- 0.240 (in-sample avg dev_std = 0.617)
NEC for r=1.0 class 2 = 0.568 +- 0.240 (in-sample avg dev_std = 0.617)
NEC for r=1.0 all KL = 0.572 +- 0.240 (in-sample avg dev_std = 0.617)
NEC for r=1.0 all L1 = 0.514 +- 0.176 (in-sample avg dev_std = 0.617)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.681
Model XAI F1 of binarized graphs for r=0.3 =  0.42621375
Model XAI WIoU of binarized graphs for r=0.3 =  0.3291075
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.349
NEC for r=0.3 class 0 = 0.561 +- 0.264 (in-sample avg dev_std = 0.400)
NEC for r=0.3 class 1 = 0.51 +- 0.264 (in-sample avg dev_std = 0.400)
NEC for r=0.3 class 2 = 0.665 +- 0.264 (in-sample avg dev_std = 0.400)
NEC for r=0.3 all KL = 0.569 +- 0.264 (in-sample avg dev_std = 0.400)
NEC for r=0.3 all L1 = 0.58 +- 0.144 (in-sample avg dev_std = 0.400)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.715
Model XAI F1 of binarized graphs for r=0.6 =  0.28413124999999995
Model XAI WIoU of binarized graphs for r=0.6 =  0.1874425
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.42
NEC for r=0.6 class 0 = 0.622 +- 0.226 (in-sample avg dev_std = 0.415)
NEC for r=0.6 class 1 = 0.46 +- 0.226 (in-sample avg dev_std = 0.415)
NEC for r=0.6 class 2 = 0.581 +- 0.226 (in-sample avg dev_std = 0.415)
NEC for r=0.6 all KL = 0.497 +- 0.226 (in-sample avg dev_std = 0.415)
NEC for r=0.6 all L1 = 0.556 +- 0.139 (in-sample avg dev_std = 0.415)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.635
Model XAI F1 of binarized graphs for r=0.9 =  0.24661249999999998
Model XAI WIoU of binarized graphs for r=0.9 =  0.15134125
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.533
NEC for r=0.9 class 0 = 0.588 +- 0.180 (in-sample avg dev_std = 0.477)
NEC for r=0.9 class 1 = 0.491 +- 0.180 (in-sample avg dev_std = 0.477)
NEC for r=0.9 class 2 = 0.487 +- 0.180 (in-sample avg dev_std = 0.477)
NEC for r=0.9 all KL = 0.465 +- 0.180 (in-sample avg dev_std = 0.477)
NEC for r=0.9 all L1 = 0.522 +- 0.116 (in-sample avg dev_std = 0.477)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.809
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.16315125000000003
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.598
NEC for r=1.0 class 0 = 0.555 +- 0.203 (in-sample avg dev_std = 0.507)
NEC for r=1.0 class 1 = 0.457 +- 0.203 (in-sample avg dev_std = 0.507)
NEC for r=1.0 class 2 = 0.524 +- 0.203 (in-sample avg dev_std = 0.507)
NEC for r=1.0 all KL = 0.47 +- 0.203 (in-sample avg dev_std = 0.507)
NEC for r=1.0 all L1 = 0.512 +- 0.115 (in-sample avg dev_std = 0.507)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.688
Model XAI F1 of binarized graphs for r=0.3 =  0.63566625
Model XAI WIoU of binarized graphs for r=0.3 =  0.515265
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.365
NEC for r=0.3 class 0 = 0.652 +- 0.242 (in-sample avg dev_std = 0.467)
NEC for r=0.3 class 1 = 0.516 +- 0.242 (in-sample avg dev_std = 0.467)
NEC for r=0.3 class 2 = 0.658 +- 0.242 (in-sample avg dev_std = 0.467)
NEC for r=0.3 all KL = 0.637 +- 0.242 (in-sample avg dev_std = 0.467)
NEC for r=0.3 all L1 = 0.607 +- 0.139 (in-sample avg dev_std = 0.467)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.681
Model XAI F1 of binarized graphs for r=0.6 =  0.48989374999999996
Model XAI WIoU of binarized graphs for r=0.6 =  0.35478499999999996
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.47
NEC for r=0.6 class 0 = 0.568 +- 0.227 (in-sample avg dev_std = 0.450)
NEC for r=0.6 class 1 = 0.417 +- 0.227 (in-sample avg dev_std = 0.450)
NEC for r=0.6 class 2 = 0.545 +- 0.227 (in-sample avg dev_std = 0.450)
NEC for r=0.6 all KL = 0.465 +- 0.227 (in-sample avg dev_std = 0.450)
NEC for r=0.6 all L1 = 0.509 +- 0.163 (in-sample avg dev_std = 0.450)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.738
Model XAI F1 of binarized graphs for r=0.9 =  0.41095375000000006
Model XAI WIoU of binarized graphs for r=0.9 =  0.2793825
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.582
NEC for r=0.9 class 0 = 0.603 +- 0.293 (in-sample avg dev_std = 0.534)
NEC for r=0.9 class 1 = 0.382 +- 0.293 (in-sample avg dev_std = 0.534)
NEC for r=0.9 class 2 = 0.459 +- 0.293 (in-sample avg dev_std = 0.534)
NEC for r=0.9 all KL = 0.506 +- 0.293 (in-sample avg dev_std = 0.534)
NEC for r=0.9 all L1 = 0.479 +- 0.174 (in-sample avg dev_std = 0.534)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.806
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.26323375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.613
NEC for r=1.0 class 0 = 0.502 +- 0.262 (in-sample avg dev_std = 0.548)
NEC for r=1.0 class 1 = 0.369 +- 0.262 (in-sample avg dev_std = 0.548)
NEC for r=1.0 class 2 = 0.394 +- 0.262 (in-sample avg dev_std = 0.548)
NEC for r=1.0 all KL = 0.438 +- 0.262 (in-sample avg dev_std = 0.548)
NEC for r=1.0 all L1 = 0.42 +- 0.171 (in-sample avg dev_std = 0.548)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 20:27:43 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 03/22/2024 08:27:43 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 08:27:43 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 08:27:43 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:27:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:27:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:27:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:27:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:27:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:27:43 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:27:43 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 111...
[0m[1;37mINFO[0m: [1mCheckpoint 111: 
-----------------------------------
Train ACCURACY: 0.9303
Train Loss: 0.3118
ID Validation ACCURACY: 0.9357
ID Validation Loss: 0.3016
ID Test ACCURACY: 0.9260
ID Test Loss: 0.3358
OOD Validation ACCURACY: 0.8073
OOD Validation Loss: 0.5158
OOD Test ACCURACY: 0.7527
OOD Test Loss: 1.0888

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 138...
[0m[1;37mINFO[0m: [1mCheckpoint 138: 
-----------------------------------
Train ACCURACY: 0.9293
Train Loss: 0.3258
ID Validation ACCURACY: 0.9347
ID Validation Loss: 0.3155
ID Test ACCURACY: 0.9257
ID Test Loss: 0.3465
OOD Validation ACCURACY: 0.9260
OOD Validation Loss: 0.4445
OOD Test ACCURACY: 0.5280
OOD Test Loss: 1.3857

[0m[1;37mINFO[0m: [1mChartInfo 0.9260 0.7527 0.9257 0.5280 0.9347 0.9260[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.729
WIoU for r=0.3 = 0.612
F1 for r=0.6 = 0.603
WIoU for r=0.6 = 0.479
F1 for r=0.9 = 0.477
WIoU for r=0.9 = 0.353
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.331
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.536
WIoU for r=0.3 = 0.413
F1 for r=0.6 = 0.342
WIoU for r=0.6 = 0.228
F1 for r=0.9 = 0.265
WIoU for r=0.9 = 0.168
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.169
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.654
WIoU for r=0.3 = 0.519
F1 for r=0.6 = 0.483
WIoU for r=0.6 = 0.348
F1 for r=0.9 = 0.390
WIoU for r=0.9 = 0.262
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.263


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.485
Model XAI F1 of binarized graphs for r=0.3 =  0.72892875
Model XAI WIoU of binarized graphs for r=0.3 =  0.6118412500000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.493
SUFF++ for r=0.3 class 0 = 0.477 +- 0.251 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.3 class 1 = 0.619 +- 0.251 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.3 class 2 = 0.542 +- 0.251 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.3 all KL = 0.581 +- 0.251 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.3 all L1 = 0.546 +- 0.162 (in-sample avg dev_std = 0.459)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.798
Model XAI F1 of binarized graphs for r=0.6 =  0.602595
Model XAI WIoU of binarized graphs for r=0.6 =  0.47919875000000006
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.691
SUFF++ for r=0.6 class 0 = 0.458 +- 0.251 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.6 class 1 = 0.734 +- 0.251 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.6 class 2 = 0.694 +- 0.251 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.6 all KL = 0.683 +- 0.251 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.6 all L1 = 0.629 +- 0.197 (in-sample avg dev_std = 0.398)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.925
Model XAI F1 of binarized graphs for r=0.9 =  0.47736125
Model XAI WIoU of binarized graphs for r=0.9 =  0.35338875000000003
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.877
SUFF++ for r=0.9 class 0 = 0.716 +- 0.182 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 class 1 = 0.84 +- 0.182 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 class 2 = 0.825 +- 0.182 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 all KL = 0.862 +- 0.182 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 all L1 = 0.794 +- 0.168 (in-sample avg dev_std = 0.274)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.631
Model XAI F1 of binarized graphs for r=0.3 =  0.5358762499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.41256875
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.562
SUFF++ for r=0.3 class 0 = 0.511 +- 0.249 (in-sample avg dev_std = 0.359)
SUFF++ for r=0.3 class 1 = 0.689 +- 0.249 (in-sample avg dev_std = 0.359)
SUFF++ for r=0.3 class 2 = 0.591 +- 0.249 (in-sample avg dev_std = 0.359)
SUFF++ for r=0.3 all KL = 0.687 +- 0.249 (in-sample avg dev_std = 0.359)
SUFF++ for r=0.3 all L1 = 0.596 +- 0.184 (in-sample avg dev_std = 0.359)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.663
Model XAI F1 of binarized graphs for r=0.6 =  0.34156
Model XAI WIoU of binarized graphs for r=0.6 =  0.22752249999999996
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.603
SUFF++ for r=0.6 class 0 = 0.446 +- 0.209 (in-sample avg dev_std = 0.329)
SUFF++ for r=0.6 class 1 = 0.692 +- 0.209 (in-sample avg dev_std = 0.329)
SUFF++ for r=0.6 class 2 = 0.555 +- 0.209 (in-sample avg dev_std = 0.329)
SUFF++ for r=0.6 all KL = 0.676 +- 0.209 (in-sample avg dev_std = 0.329)
SUFF++ for r=0.6 all L1 = 0.563 +- 0.161 (in-sample avg dev_std = 0.329)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.77
Model XAI F1 of binarized graphs for r=0.9 =  0.265325
Model XAI WIoU of binarized graphs for r=0.9 =  0.16789
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.701
SUFF++ for r=0.9 class 0 = 0.56 +- 0.179 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.9 class 1 = 0.689 +- 0.179 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.9 class 2 = 0.702 +- 0.179 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.9 all KL = 0.754 +- 0.179 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.9 all L1 = 0.65 +- 0.158 (in-sample avg dev_std = 0.330)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.456
Model XAI F1 of binarized graphs for r=0.3 =  0.6542587499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.51921125
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.52
SUFF++ for r=0.3 class 0 = 0.498 +- 0.273 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.3 class 1 = 0.643 +- 0.273 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.3 class 2 = 0.645 +- 0.273 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.3 all KL = 0.598 +- 0.273 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.3 all L1 = 0.596 +- 0.183 (in-sample avg dev_std = 0.468)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.59
Model XAI F1 of binarized graphs for r=0.6 =  0.48279250000000007
Model XAI WIoU of binarized graphs for r=0.6 =  0.3483737499999999
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.688
SUFF++ for r=0.6 class 0 = 0.455 +- 0.203 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.6 class 1 = 0.699 +- 0.203 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.6 class 2 = 0.542 +- 0.203 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.6 all KL = 0.68 +- 0.203 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.6 all L1 = 0.567 +- 0.195 (in-sample avg dev_std = 0.319)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.76
Model XAI F1 of binarized graphs for r=0.9 =  0.38961875
Model XAI WIoU of binarized graphs for r=0.9 =  0.26186
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.696
SUFF++ for r=0.9 class 0 = 0.663 +- 0.154 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 class 1 = 0.819 +- 0.154 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 class 2 = 0.88 +- 0.154 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 all KL = 0.884 +- 0.154 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 all L1 = 0.789 +- 0.183 (in-sample avg dev_std = 0.256)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.484
Model XAI F1 of binarized graphs for r=0.3 =  0.72892875
Model XAI WIoU of binarized graphs for r=0.3 =  0.6118412500000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.323
NEC for r=0.3 class 0 = 0.627 +- 0.266 (in-sample avg dev_std = 0.395)
NEC for r=0.3 class 1 = 0.464 +- 0.266 (in-sample avg dev_std = 0.395)
NEC for r=0.3 class 2 = 0.601 +- 0.266 (in-sample avg dev_std = 0.395)
NEC for r=0.3 all KL = 0.557 +- 0.266 (in-sample avg dev_std = 0.395)
NEC for r=0.3 all L1 = 0.563 +- 0.171 (in-sample avg dev_std = 0.395)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.798
Model XAI F1 of binarized graphs for r=0.6 =  0.602595
Model XAI WIoU of binarized graphs for r=0.6 =  0.47919875000000006
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.449
NEC for r=0.6 class 0 = 0.65 +- 0.258 (in-sample avg dev_std = 0.460)
NEC for r=0.6 class 1 = 0.451 +- 0.258 (in-sample avg dev_std = 0.460)
NEC for r=0.6 class 2 = 0.628 +- 0.258 (in-sample avg dev_std = 0.460)
NEC for r=0.6 all KL = 0.572 +- 0.258 (in-sample avg dev_std = 0.460)
NEC for r=0.6 all L1 = 0.576 +- 0.166 (in-sample avg dev_std = 0.460)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.925
Model XAI F1 of binarized graphs for r=0.9 =  0.47736125
Model XAI WIoU of binarized graphs for r=0.9 =  0.35338875000000003
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.515
NEC for r=0.9 class 0 = 0.608 +- 0.212 (in-sample avg dev_std = 0.563)
NEC for r=0.9 class 1 = 0.45 +- 0.212 (in-sample avg dev_std = 0.563)
NEC for r=0.9 class 2 = 0.57 +- 0.212 (in-sample avg dev_std = 0.563)
NEC for r=0.9 all KL = 0.559 +- 0.212 (in-sample avg dev_std = 0.563)
NEC for r=0.9 all L1 = 0.543 +- 0.156 (in-sample avg dev_std = 0.563)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.944
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.3305025
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.55
NEC for r=1.0 class 0 = 0.579 +- 0.246 (in-sample avg dev_std = 0.617)
NEC for r=1.0 class 1 = 0.389 +- 0.246 (in-sample avg dev_std = 0.617)
NEC for r=1.0 class 2 = 0.576 +- 0.246 (in-sample avg dev_std = 0.617)
NEC for r=1.0 all KL = 0.555 +- 0.246 (in-sample avg dev_std = 0.617)
NEC for r=1.0 all L1 = 0.514 +- 0.180 (in-sample avg dev_std = 0.617)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.627
Model XAI F1 of binarized graphs for r=0.3 =  0.5358762499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.41256875
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.319
NEC for r=0.3 class 0 = 0.501 +- 0.264 (in-sample avg dev_std = 0.369)
NEC for r=0.3 class 1 = 0.486 +- 0.264 (in-sample avg dev_std = 0.369)
NEC for r=0.3 class 2 = 0.667 +- 0.264 (in-sample avg dev_std = 0.369)
NEC for r=0.3 all KL = 0.488 +- 0.264 (in-sample avg dev_std = 0.369)
NEC for r=0.3 all L1 = 0.552 +- 0.161 (in-sample avg dev_std = 0.369)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.661
Model XAI F1 of binarized graphs for r=0.6 =  0.34156
Model XAI WIoU of binarized graphs for r=0.6 =  0.22752249999999996
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.411
NEC for r=0.6 class 0 = 0.572 +- 0.197 (in-sample avg dev_std = 0.459)
NEC for r=0.6 class 1 = 0.502 +- 0.197 (in-sample avg dev_std = 0.459)
NEC for r=0.6 class 2 = 0.588 +- 0.197 (in-sample avg dev_std = 0.459)
NEC for r=0.6 all KL = 0.484 +- 0.197 (in-sample avg dev_std = 0.459)
NEC for r=0.6 all L1 = 0.554 +- 0.111 (in-sample avg dev_std = 0.459)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.771
Model XAI F1 of binarized graphs for r=0.9 =  0.265325
Model XAI WIoU of binarized graphs for r=0.9 =  0.16789
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.535
NEC for r=0.9 class 0 = 0.594 +- 0.188 (in-sample avg dev_std = 0.526)
NEC for r=0.9 class 1 = 0.538 +- 0.188 (in-sample avg dev_std = 0.526)
NEC for r=0.9 class 2 = 0.482 +- 0.188 (in-sample avg dev_std = 0.526)
NEC for r=0.9 all KL = 0.516 +- 0.188 (in-sample avg dev_std = 0.526)
NEC for r=0.9 all L1 = 0.538 +- 0.122 (in-sample avg dev_std = 0.526)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.804
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.16923624999999998
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.577
NEC for r=1.0 class 0 = 0.581 +- 0.207 (in-sample avg dev_std = 0.565)
NEC for r=1.0 class 1 = 0.465 +- 0.207 (in-sample avg dev_std = 0.565)
NEC for r=1.0 class 2 = 0.551 +- 0.207 (in-sample avg dev_std = 0.565)
NEC for r=1.0 all KL = 0.54 +- 0.207 (in-sample avg dev_std = 0.565)
NEC for r=1.0 all L1 = 0.533 +- 0.123 (in-sample avg dev_std = 0.565)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.454
Model XAI F1 of binarized graphs for r=0.3 =  0.6542587499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.51921125
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.412
NEC for r=0.3 class 0 = 0.504 +- 0.235 (in-sample avg dev_std = 0.483)
NEC for r=0.3 class 1 = 0.57 +- 0.235 (in-sample avg dev_std = 0.483)
NEC for r=0.3 class 2 = 0.587 +- 0.235 (in-sample avg dev_std = 0.483)
NEC for r=0.3 all KL = 0.601 +- 0.235 (in-sample avg dev_std = 0.483)
NEC for r=0.3 all L1 = 0.555 +- 0.171 (in-sample avg dev_std = 0.483)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.585
Model XAI F1 of binarized graphs for r=0.6 =  0.48279250000000007
Model XAI WIoU of binarized graphs for r=0.6 =  0.3483737499999999
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.455
NEC for r=0.6 class 0 = 0.579 +- 0.235 (in-sample avg dev_std = 0.433)
NEC for r=0.6 class 1 = 0.484 +- 0.235 (in-sample avg dev_std = 0.433)
NEC for r=0.6 class 2 = 0.532 +- 0.235 (in-sample avg dev_std = 0.433)
NEC for r=0.6 all KL = 0.482 +- 0.235 (in-sample avg dev_std = 0.433)
NEC for r=0.6 all L1 = 0.531 +- 0.146 (in-sample avg dev_std = 0.433)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.76
Model XAI F1 of binarized graphs for r=0.9 =  0.38961875
Model XAI WIoU of binarized graphs for r=0.9 =  0.26186
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.592
NEC for r=0.9 class 0 = 0.526 +- 0.296 (in-sample avg dev_std = 0.529)
NEC for r=0.9 class 1 = 0.388 +- 0.296 (in-sample avg dev_std = 0.529)
NEC for r=0.9 class 2 = 0.421 +- 0.296 (in-sample avg dev_std = 0.529)
NEC for r=0.9 all KL = 0.443 +- 0.296 (in-sample avg dev_std = 0.529)
NEC for r=0.9 all L1 = 0.444 +- 0.182 (in-sample avg dev_std = 0.529)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.772
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.26257375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.609
NEC for r=1.0 class 0 = 0.472 +- 0.289 (in-sample avg dev_std = 0.507)
NEC for r=1.0 class 1 = 0.362 +- 0.289 (in-sample avg dev_std = 0.507)
NEC for r=1.0 class 2 = 0.357 +- 0.289 (in-sample avg dev_std = 0.507)
NEC for r=1.0 all KL = 0.413 +- 0.289 (in-sample avg dev_std = 0.507)
NEC for r=1.0 all L1 = 0.396 +- 0.176 (in-sample avg dev_std = 0.507)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 20:31:42 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 03/22/2024 08:31:42 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 08:31:42 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 08:31:42 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:31:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:31:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:31:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:31:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:31:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:31:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:31:42 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 121...
[0m[1;37mINFO[0m: [1mCheckpoint 121: 
-----------------------------------
Train ACCURACY: 0.9297
Train Loss: 0.3216
ID Validation ACCURACY: 0.9353
ID Validation Loss: 0.3083
ID Test ACCURACY: 0.9257
ID Test Loss: 0.3413
OOD Validation ACCURACY: 0.9157
OOD Validation Loss: 0.4277
OOD Test ACCURACY: 0.7673
OOD Test Loss: 0.8079

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 63...
[0m[1;37mINFO[0m: [1mCheckpoint 63: 
-----------------------------------
Train ACCURACY: 0.9285
Train Loss: 0.3200
ID Validation ACCURACY: 0.9337
ID Validation Loss: 0.3075
ID Test ACCURACY: 0.9250
ID Test Loss: 0.3354
OOD Validation ACCURACY: 0.9280
OOD Validation Loss: 0.3766
OOD Test ACCURACY: 0.7923
OOD Test Loss: 1.1210

[0m[1;37mINFO[0m: [1mChartInfo 0.9257 0.7673 0.9250 0.7923 0.9337 0.9280[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.705
WIoU for r=0.3 = 0.588
F1 for r=0.6 = 0.577
WIoU for r=0.6 = 0.457
F1 for r=0.9 = 0.457
WIoU for r=0.9 = 0.332
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.327
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.478
WIoU for r=0.3 = 0.363
F1 for r=0.6 = 0.308
WIoU for r=0.6 = 0.203
F1 for r=0.9 = 0.244
WIoU for r=0.9 = 0.152
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.165
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.595
WIoU for r=0.3 = 0.477
F1 for r=0.6 = 0.440
WIoU for r=0.6 = 0.317
F1 for r=0.9 = 0.389
WIoU for r=0.9 = 0.261
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.260


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.481
Model XAI F1 of binarized graphs for r=0.3 =  0.70496375
Model XAI WIoU of binarized graphs for r=0.3 =  0.587815
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.45
SUFF++ for r=0.3 class 0 = 0.475 +- 0.270 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.3 class 1 = 0.489 +- 0.270 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.3 class 2 = 0.552 +- 0.270 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.3 all KL = 0.56 +- 0.270 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.3 all L1 = 0.505 +- 0.166 (in-sample avg dev_std = 0.437)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.71
Model XAI F1 of binarized graphs for r=0.6 =  0.57654625
Model XAI WIoU of binarized graphs for r=0.6 =  0.45657375
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.649
SUFF++ for r=0.6 class 0 = 0.479 +- 0.245 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.6 class 1 = 0.713 +- 0.245 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.6 class 2 = 0.679 +- 0.245 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.6 all KL = 0.663 +- 0.245 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.6 all L1 = 0.623 +- 0.187 (in-sample avg dev_std = 0.419)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.933
Model XAI F1 of binarized graphs for r=0.9 =  0.45686875
Model XAI WIoU of binarized graphs for r=0.9 =  0.33242875
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.863
SUFF++ for r=0.9 class 0 = 0.64 +- 0.178 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.9 class 1 = 0.845 +- 0.178 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.9 class 2 = 0.836 +- 0.178 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.9 all KL = 0.841 +- 0.178 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.9 all L1 = 0.773 +- 0.152 (in-sample avg dev_std = 0.319)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.684
Model XAI F1 of binarized graphs for r=0.3 =  0.47763875
Model XAI WIoU of binarized graphs for r=0.3 =  0.36338125
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.613
SUFF++ for r=0.3 class 0 = 0.586 +- 0.214 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.3 class 1 = 0.611 +- 0.214 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.3 class 2 = 0.613 +- 0.214 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.3 all KL = 0.712 +- 0.214 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.3 all L1 = 0.603 +- 0.140 (in-sample avg dev_std = 0.378)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.666
Model XAI F1 of binarized graphs for r=0.6 =  0.30756375
Model XAI WIoU of binarized graphs for r=0.6 =  0.20333125
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.589
SUFF++ for r=0.6 class 0 = 0.472 +- 0.206 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.6 class 1 = 0.672 +- 0.206 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.6 class 2 = 0.548 +- 0.206 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.6 all KL = 0.688 +- 0.206 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.6 all L1 = 0.563 +- 0.150 (in-sample avg dev_std = 0.316)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.834
Model XAI F1 of binarized graphs for r=0.9 =  0.24438125
Model XAI WIoU of binarized graphs for r=0.9 =  0.1524625
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.712
SUFF++ for r=0.9 class 0 = 0.564 +- 0.185 (in-sample avg dev_std = 0.343)
SUFF++ for r=0.9 class 1 = 0.68 +- 0.185 (in-sample avg dev_std = 0.343)
SUFF++ for r=0.9 class 2 = 0.637 +- 0.185 (in-sample avg dev_std = 0.343)
SUFF++ for r=0.9 all KL = 0.733 +- 0.185 (in-sample avg dev_std = 0.343)
SUFF++ for r=0.9 all L1 = 0.627 +- 0.145 (in-sample avg dev_std = 0.343)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.477
Model XAI F1 of binarized graphs for r=0.3 =  0.59546125
Model XAI WIoU of binarized graphs for r=0.3 =  0.47737999999999997
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.535
SUFF++ for r=0.3 class 0 = 0.56 +- 0.276 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.3 class 1 = 0.582 +- 0.276 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.3 class 2 = 0.611 +- 0.276 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.3 all KL = 0.615 +- 0.276 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.3 all L1 = 0.584 +- 0.170 (in-sample avg dev_std = 0.448)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.717
Model XAI F1 of binarized graphs for r=0.6 =  0.44035624999999995
Model XAI WIoU of binarized graphs for r=0.6 =  0.3166975
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.683
SUFF++ for r=0.6 class 0 = 0.431 +- 0.258 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.6 class 1 = 0.662 +- 0.258 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.6 class 2 = 0.642 +- 0.258 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.6 all KL = 0.681 +- 0.258 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.6 all L1 = 0.58 +- 0.186 (in-sample avg dev_std = 0.326)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.705
Model XAI F1 of binarized graphs for r=0.9 =  0.38863
Model XAI WIoU of binarized graphs for r=0.9 =  0.26089125
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.668
SUFF++ for r=0.9 class 0 = 0.592 +- 0.171 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 1 = 0.817 +- 0.171 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 2 = 0.836 +- 0.171 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 all KL = 0.825 +- 0.171 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 all L1 = 0.75 +- 0.153 (in-sample avg dev_std = 0.276)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.481
Model XAI F1 of binarized graphs for r=0.3 =  0.70496375
Model XAI WIoU of binarized graphs for r=0.3 =  0.587815
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.291
NEC for r=0.3 class 0 = 0.604 +- 0.276 (in-sample avg dev_std = 0.400)
NEC for r=0.3 class 1 = 0.581 +- 0.276 (in-sample avg dev_std = 0.400)
NEC for r=0.3 class 2 = 0.591 +- 0.276 (in-sample avg dev_std = 0.400)
NEC for r=0.3 all KL = 0.555 +- 0.276 (in-sample avg dev_std = 0.400)
NEC for r=0.3 all L1 = 0.592 +- 0.151 (in-sample avg dev_std = 0.400)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.71
Model XAI F1 of binarized graphs for r=0.6 =  0.57654625
Model XAI WIoU of binarized graphs for r=0.6 =  0.45657375
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.392
NEC for r=0.6 class 0 = 0.575 +- 0.269 (in-sample avg dev_std = 0.459)
NEC for r=0.6 class 1 = 0.519 +- 0.269 (in-sample avg dev_std = 0.459)
NEC for r=0.6 class 2 = 0.656 +- 0.269 (in-sample avg dev_std = 0.459)
NEC for r=0.6 all KL = 0.59 +- 0.269 (in-sample avg dev_std = 0.459)
NEC for r=0.6 all L1 = 0.583 +- 0.160 (in-sample avg dev_std = 0.459)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.933
Model XAI F1 of binarized graphs for r=0.9 =  0.45686875
Model XAI WIoU of binarized graphs for r=0.9 =  0.33242875
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.512
NEC for r=0.9 class 0 = 0.584 +- 0.211 (in-sample avg dev_std = 0.579)
NEC for r=0.9 class 1 = 0.476 +- 0.211 (in-sample avg dev_std = 0.579)
NEC for r=0.9 class 2 = 0.581 +- 0.211 (in-sample avg dev_std = 0.579)
NEC for r=0.9 all KL = 0.569 +- 0.211 (in-sample avg dev_std = 0.579)
NEC for r=0.9 all L1 = 0.546 +- 0.153 (in-sample avg dev_std = 0.579)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.944
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.326995
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.536
NEC for r=1.0 class 0 = 0.547 +- 0.234 (in-sample avg dev_std = 0.609)
NEC for r=1.0 class 1 = 0.43 +- 0.234 (in-sample avg dev_std = 0.609)
NEC for r=1.0 class 2 = 0.57 +- 0.234 (in-sample avg dev_std = 0.609)
NEC for r=1.0 all KL = 0.539 +- 0.234 (in-sample avg dev_std = 0.609)
NEC for r=1.0 all L1 = 0.515 +- 0.175 (in-sample avg dev_std = 0.609)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.679
Model XAI F1 of binarized graphs for r=0.3 =  0.47763875
Model XAI WIoU of binarized graphs for r=0.3 =  0.36338125
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.301
NEC for r=0.3 class 0 = 0.457 +- 0.284 (in-sample avg dev_std = 0.342)
NEC for r=0.3 class 1 = 0.511 +- 0.284 (in-sample avg dev_std = 0.342)
NEC for r=0.3 class 2 = 0.646 +- 0.284 (in-sample avg dev_std = 0.342)
NEC for r=0.3 all KL = 0.453 +- 0.284 (in-sample avg dev_std = 0.342)
NEC for r=0.3 all L1 = 0.539 +- 0.151 (in-sample avg dev_std = 0.342)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.673
Model XAI F1 of binarized graphs for r=0.6 =  0.30756375
Model XAI WIoU of binarized graphs for r=0.6 =  0.20333125
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.411
NEC for r=0.6 class 0 = 0.558 +- 0.209 (in-sample avg dev_std = 0.384)
NEC for r=0.6 class 1 = 0.431 +- 0.209 (in-sample avg dev_std = 0.384)
NEC for r=0.6 class 2 = 0.589 +- 0.209 (in-sample avg dev_std = 0.384)
NEC for r=0.6 all KL = 0.428 +- 0.209 (in-sample avg dev_std = 0.384)
NEC for r=0.6 all L1 = 0.527 +- 0.130 (in-sample avg dev_std = 0.384)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.835
Model XAI F1 of binarized graphs for r=0.9 =  0.24438125
Model XAI WIoU of binarized graphs for r=0.9 =  0.1524625
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.536
NEC for r=0.9 class 0 = 0.549 +- 0.176 (in-sample avg dev_std = 0.488)
NEC for r=0.9 class 1 = 0.493 +- 0.176 (in-sample avg dev_std = 0.488)
NEC for r=0.9 class 2 = 0.498 +- 0.176 (in-sample avg dev_std = 0.488)
NEC for r=0.9 all KL = 0.458 +- 0.176 (in-sample avg dev_std = 0.488)
NEC for r=0.9 all L1 = 0.513 +- 0.109 (in-sample avg dev_std = 0.488)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.925
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.16467624999999997
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.593
NEC for r=1.0 class 0 = 0.477 +- 0.214 (in-sample avg dev_std = 0.540)
NEC for r=1.0 class 1 = 0.456 +- 0.214 (in-sample avg dev_std = 0.540)
NEC for r=1.0 class 2 = 0.518 +- 0.214 (in-sample avg dev_std = 0.540)
NEC for r=1.0 all KL = 0.453 +- 0.214 (in-sample avg dev_std = 0.540)
NEC for r=1.0 all L1 = 0.484 +- 0.122 (in-sample avg dev_std = 0.540)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.477
Model XAI F1 of binarized graphs for r=0.3 =  0.59546125
Model XAI WIoU of binarized graphs for r=0.3 =  0.47737999999999997
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.437
NEC for r=0.3 class 0 = 0.525 +- 0.260 (in-sample avg dev_std = 0.470)
NEC for r=0.3 class 1 = 0.641 +- 0.260 (in-sample avg dev_std = 0.470)
NEC for r=0.3 class 2 = 0.64 +- 0.260 (in-sample avg dev_std = 0.470)
NEC for r=0.3 all KL = 0.634 +- 0.260 (in-sample avg dev_std = 0.470)
NEC for r=0.3 all L1 = 0.603 +- 0.148 (in-sample avg dev_std = 0.470)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.717
Model XAI F1 of binarized graphs for r=0.6 =  0.44035624999999995
Model XAI WIoU of binarized graphs for r=0.6 =  0.3166975
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.46
NEC for r=0.6 class 0 = 0.596 +- 0.279 (in-sample avg dev_std = 0.416)
NEC for r=0.6 class 1 = 0.454 +- 0.279 (in-sample avg dev_std = 0.416)
NEC for r=0.6 class 2 = 0.589 +- 0.279 (in-sample avg dev_std = 0.416)
NEC for r=0.6 all KL = 0.505 +- 0.279 (in-sample avg dev_std = 0.416)
NEC for r=0.6 all L1 = 0.545 +- 0.162 (in-sample avg dev_std = 0.416)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.705
Model XAI F1 of binarized graphs for r=0.9 =  0.38863
Model XAI WIoU of binarized graphs for r=0.9 =  0.26089125
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.583
NEC for r=0.9 class 0 = 0.561 +- 0.330 (in-sample avg dev_std = 0.505)
NEC for r=0.9 class 1 = 0.358 +- 0.330 (in-sample avg dev_std = 0.505)
NEC for r=0.9 class 2 = 0.486 +- 0.330 (in-sample avg dev_std = 0.505)
NEC for r=0.9 all KL = 0.464 +- 0.330 (in-sample avg dev_std = 0.505)
NEC for r=0.9 all L1 = 0.466 +- 0.194 (in-sample avg dev_std = 0.505)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.771
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.26045625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.604
NEC for r=1.0 class 0 = 0.478 +- 0.250 (in-sample avg dev_std = 0.473)
NEC for r=1.0 class 1 = 0.372 +- 0.250 (in-sample avg dev_std = 0.473)
NEC for r=1.0 class 2 = 0.432 +- 0.250 (in-sample avg dev_std = 0.473)
NEC for r=1.0 all KL = 0.383 +- 0.250 (in-sample avg dev_std = 0.473)
NEC for r=1.0 all L1 = 0.427 +- 0.146 (in-sample avg dev_std = 0.473)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.552, 0.642, 0.827, 1.0], 'all_L1': [0.535, 0.623, 0.761, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.501, 0.621, 0.854, 1.0], 'all_L1': [0.488, 0.614, 0.79, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.462, 0.605, 0.835, 1.0], 'all_L1': [0.47, 0.602, 0.779, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.581, 0.683, 0.862, 1.0], 'all_L1': [0.546, 0.629, 0.794, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.56, 0.663, 0.841, 1.0], 'all_L1': [0.505, 0.623, 0.773, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.556, 0.616, 0.58, 0.553], 'all_L1': [0.559, 0.568, 0.55, 0.519]}), defaultdict(<class 'list'>, {'all_KL': [0.63, 0.61, 0.572, 0.553], 'all_L1': [0.624, 0.575, 0.542, 0.518]}), defaultdict(<class 'list'>, {'all_KL': [0.637, 0.608, 0.621, 0.572], 'all_L1': [0.616, 0.565, 0.555, 0.514]}), defaultdict(<class 'list'>, {'all_KL': [0.557, 0.572, 0.559, 0.555], 'all_L1': [0.563, 0.576, 0.543, 0.514]}), defaultdict(<class 'list'>, {'all_KL': [0.555, 0.59, 0.569, 0.539], 'all_L1': [0.592, 0.583, 0.546, 0.515]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.685, 0.697, 0.781, 1.0], 'all_L1': [0.595, 0.571, 0.665, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.577, 0.648, 0.755, 1.0], 'all_L1': [0.563, 0.56, 0.635, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.59, 0.623, 0.734, 1.0], 'all_L1': [0.547, 0.534, 0.622, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.687, 0.676, 0.754, 1.0], 'all_L1': [0.596, 0.563, 0.65, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.712, 0.688, 0.733, 1.0], 'all_L1': [0.603, 0.563, 0.627, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.451, 0.421, 0.454, 0.478], 'all_L1': [0.529, 0.52, 0.508, 0.488]}), defaultdict(<class 'list'>, {'all_KL': [0.637, 0.524, 0.459, 0.471], 'all_L1': [0.628, 0.565, 0.516, 0.494]}), defaultdict(<class 'list'>, {'all_KL': [0.569, 0.497, 0.465, 0.47], 'all_L1': [0.58, 0.556, 0.522, 0.512]}), defaultdict(<class 'list'>, {'all_KL': [0.488, 0.484, 0.516, 0.54], 'all_L1': [0.552, 0.554, 0.538, 0.533]}), defaultdict(<class 'list'>, {'all_KL': [0.453, 0.428, 0.458, 0.453], 'all_L1': [0.539, 0.527, 0.513, 0.484]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.657, 0.735, 0.866, 1.0], 'all_L1': [0.609, 0.656, 0.755, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.56, 0.659, 0.809, 1.0], 'all_L1': [0.569, 0.633, 0.75, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.582, 0.717, 0.838, 1.0], 'all_L1': [0.569, 0.633, 0.758, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.598, 0.68, 0.884, 1.0], 'all_L1': [0.596, 0.567, 0.789, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.615, 0.681, 0.825, 1.0], 'all_L1': [0.584, 0.58, 0.75, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.513, 0.578, 0.396, 0.369], 'all_L1': [0.53, 0.557, 0.438, 0.397]}), defaultdict(<class 'list'>, {'all_KL': [0.662, 0.633, 0.544, 0.378], 'all_L1': [0.609, 0.583, 0.471, 0.396]}), defaultdict(<class 'list'>, {'all_KL': [0.637, 0.465, 0.506, 0.438], 'all_L1': [0.607, 0.509, 0.479, 0.42]}), defaultdict(<class 'list'>, {'all_KL': [0.601, 0.482, 0.443, 0.413], 'all_L1': [0.555, 0.531, 0.444, 0.396]}), defaultdict(<class 'list'>, {'all_KL': [0.634, 0.505, 0.464, 0.383], 'all_L1': [0.603, 0.545, 0.466, 0.427]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.509 +- 0.028, 0.618 +- 0.009, 0.779 +- 0.012, 1.000 +- 0.000
suff++ class all_KL  =  0.531 +- 0.043, 0.643 +- 0.028, 0.844 +- 0.013, 1.000 +- 0.000
suff++_acc_int  =  0.455 +- 0.020, 0.651 +- 0.028, 0.852 +- 0.018
nec class all_L1  =  0.591 +- 0.027, 0.573 +- 0.006, 0.547 +- 0.005, 0.516 +- 0.002
nec class all_KL  =  0.587 +- 0.038, 0.599 +- 0.016, 0.580 +- 0.021, 0.554 +- 0.010
nec_acc_int  =  0.309 +- 0.010, 0.404 +- 0.023, 0.516 +- 0.004, 0.547 +- 0.010

Eval split val
suff++ class all_L1  =  0.581 +- 0.022, 0.558 +- 0.013, 0.640 +- 0.016, 1.000 +- 0.000
suff++ class all_KL  =  0.650 +- 0.055, 0.666 +- 0.027, 0.751 +- 0.018, 1.000 +- 0.000
suff++_acc_int  =  0.578 +- 0.026, 0.596 +- 0.030, 0.692 +- 0.033
nec class all_L1  =  0.566 +- 0.036, 0.544 +- 0.018, 0.519 +- 0.010, 0.502 +- 0.018
nec class all_KL  =  0.520 +- 0.073, 0.471 +- 0.040, 0.470 +- 0.023, 0.482 +- 0.030
nec_acc_int  =  0.324 +- 0.019, 0.419 +- 0.008, 0.524 +- 0.021, 0.582 +- 0.012

Eval split test
suff++ class all_L1  =  0.585 +- 0.016, 0.614 +- 0.034, 0.760 +- 0.015, 1.000 +- 0.000
suff++ class all_KL  =  0.602 +- 0.033, 0.694 +- 0.028, 0.844 +- 0.027, 1.000 +- 0.000
suff++_acc_int  =  0.514 +- 0.025, 0.670 +- 0.023, 0.702 +- 0.026
nec class all_L1  =  0.581 +- 0.032, 0.545 +- 0.025, 0.460 +- 0.016, 0.407 +- 0.013
nec class all_KL  =  0.609 +- 0.052, 0.533 +- 0.063, 0.471 +- 0.051, 0.396 +- 0.026
nec_acc_int  =  0.414 +- 0.029, 0.453 +- 0.014, 0.583 +- 0.005, 0.602 +- 0.014


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.550 +- 0.005, 0.596 +- 0.007, 0.663 +- 0.005, 0.758 +- 0.001
Faith. Armon (L1)= 		  =  0.545 +- 0.007, 0.595 +- 0.007, 0.643 +- 0.003, 0.681 +- 0.002
Faith. GMean (L1)= 	  =  0.548 +- 0.006, 0.595 +- 0.007, 0.653 +- 0.004, 0.718 +- 0.001
Faith. Aritm (KL)= 		  =  0.559 +- 0.007, 0.621 +- 0.009, 0.712 +- 0.009, 0.777 +- 0.005
Faith. Armon (KL)= 		  =  0.555 +- 0.011, 0.620 +- 0.008, 0.687 +- 0.013, 0.713 +- 0.009
Faith. GMean (KL)= 	  =  0.557 +- 0.009, 0.620 +- 0.008, 0.700 +- 0.011, 0.745 +- 0.007

Eval split val
Faith. Aritm (L1)= 		  =  0.573 +- 0.012, 0.551 +- 0.008, 0.580 +- 0.009, 0.751 +- 0.009
Faith. Armon (L1)= 		  =  0.572 +- 0.012, 0.551 +- 0.008, 0.573 +- 0.009, 0.668 +- 0.016
Faith. GMean (L1)= 	  =  0.573 +- 0.012, 0.551 +- 0.008, 0.576 +- 0.009, 0.709 +- 0.013
Faith. Aritm (KL)= 		  =  0.585 +- 0.013, 0.569 +- 0.012, 0.611 +- 0.014, 0.741 +- 0.015
Faith. Armon (KL)= 		  =  0.571 +- 0.021, 0.550 +- 0.021, 0.578 +- 0.018, 0.650 +- 0.027
Faith. GMean (KL)= 	  =  0.578 +- 0.017, 0.559 +- 0.016, 0.594 +- 0.016, 0.694 +- 0.021

Eval split test
Faith. Aritm (L1)= 		  =  0.583 +- 0.009, 0.579 +- 0.024, 0.610 +- 0.008, 0.704 +- 0.007
Faith. Armon (L1)= 		  =  0.582 +- 0.010, 0.577 +- 0.023, 0.573 +- 0.011, 0.579 +- 0.014
Faith. GMean (L1)= 	  =  0.583 +- 0.009, 0.578 +- 0.024, 0.591 +- 0.009, 0.638 +- 0.011
Faith. Aritm (KL)= 		  =  0.606 +- 0.013, 0.613 +- 0.031, 0.658 +- 0.017, 0.698 +- 0.013
Faith. Armon (KL)= 		  =  0.603 +- 0.016, 0.600 +- 0.038, 0.602 +- 0.037, 0.567 +- 0.026
Faith. GMean (KL)= 	  =  0.604 +- 0.014, 0.607 +- 0.035, 0.629 +- 0.027, 0.629 +- 0.020
Computed for split load_split = id



Completed in  0:19:46.215825  for GSATGIN GOODMotif2/basis



DONE GSAT GOODMotif2/basis

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 20:35:52 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/22/2024 08:35:52 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:05 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:07 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:09 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:12 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:36:19 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 132...
[0m[1;37mINFO[0m: [1mCheckpoint 132: 
-----------------------------------
Train ACCURACY: 0.8827
Train Loss: 0.3987
ID Validation ACCURACY: 0.8930
ID Validation Loss: 0.3834
ID Test ACCURACY: 0.8840
ID Test Loss: 0.4012
OOD Validation ACCURACY: 0.7283
OOD Validation Loss: 1.1107
OOD Test ACCURACY: 0.3310
OOD Test Loss: 21.6677

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 65...
[0m[1;37mINFO[0m: [1mCheckpoint 65: 
-----------------------------------
Train ACCURACY: 0.8045
Train Loss: 0.7745
ID Validation ACCURACY: 0.8013
ID Validation Loss: 0.7842
ID Test ACCURACY: 0.8077
ID Test Loss: 0.7623
OOD Validation ACCURACY: 0.7757
OOD Validation Loss: 3.1424
OOD Test ACCURACY: 0.3323
OOD Test Loss: 22.8137

[0m[1;37mINFO[0m: [1mChartInfo 0.8840 0.3310 0.8077 0.3323 0.8013 0.7757[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.486
WIoU for r=0.3 = 0.364
F1 for r=0.6 = 0.571
WIoU for r=0.6 = 0.454
F1 for r=0.9 = 0.522
WIoU for r=0.9 = 0.418
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.401
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.334
WIoU for r=0.3 = 0.273
F1 for r=0.6 = 0.295
WIoU for r=0.6 = 0.231
F1 for r=0.9 = 0.256
WIoU for r=0.9 = 0.199
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.187
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.192
WIoU for r=0.3 = 0.131
F1 for r=0.6 = 0.147
WIoU for r=0.6 = 0.096
F1 for r=0.9 = 0.122
WIoU for r=0.9 = 0.078
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.073


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.358
Model XAI F1 of binarized graphs for r=0.3 =  0.4858
Model XAI WIoU of binarized graphs for r=0.3 =  0.3643875
len(reference) = 765
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.349
SUFF++ for r=0.3 class 0 = 0.772 +- 0.117 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.3 class 1 = 0.808 +- 0.117 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.3 class 2 = 0.787 +- 0.117 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.3 all KL = 0.906 +- 0.117 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.3 all L1 = 0.788 +- 0.132 (in-sample avg dev_std = 0.249)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.521
Model XAI F1 of binarized graphs for r=0.6 =  0.5708199999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.453915
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.501
SUFF++ for r=0.6 class 0 = 0.723 +- 0.240 (in-sample avg dev_std = 0.374)
SUFF++ for r=0.6 class 1 = 0.856 +- 0.240 (in-sample avg dev_std = 0.374)
SUFF++ for r=0.6 class 2 = 0.736 +- 0.240 (in-sample avg dev_std = 0.374)
SUFF++ for r=0.6 all KL = 0.81 +- 0.240 (in-sample avg dev_std = 0.374)
SUFF++ for r=0.6 all L1 = 0.77 +- 0.209 (in-sample avg dev_std = 0.374)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.793
Model XAI F1 of binarized graphs for r=0.9 =  0.5218200000000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.41843125000000003
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.778
SUFF++ for r=0.9 class 0 = 0.768 +- 0.202 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 class 1 = 0.842 +- 0.202 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 class 2 = 0.826 +- 0.202 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 all KL = 0.866 +- 0.202 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 all L1 = 0.811 +- 0.214 (in-sample avg dev_std = 0.268)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.474
Model XAI F1 of binarized graphs for r=0.3 =  0.33412624999999996
Model XAI WIoU of binarized graphs for r=0.3 =  0.27287
len(reference) = 796
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.449
SUFF++ for r=0.3 class 0 = 0.862 +- 0.116 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.3 class 1 = 0.907 +- 0.116 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.3 class 2 = 0.868 +- 0.116 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.3 all KL = 0.937 +- 0.116 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.3 all L1 = 0.879 +- 0.096 (in-sample avg dev_std = 0.233)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.516
Model XAI F1 of binarized graphs for r=0.6 =  0.2948075
Model XAI WIoU of binarized graphs for r=0.6 =  0.23113375000000003
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.512
SUFF++ for r=0.6 class 0 = 0.707 +- 0.258 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.6 class 1 = 0.802 +- 0.258 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.6 class 2 = 0.705 +- 0.258 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.6 all KL = 0.761 +- 0.258 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.6 all L1 = 0.738 +- 0.220 (in-sample avg dev_std = 0.433)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.716
Model XAI F1 of binarized graphs for r=0.9 =  0.25588125
Model XAI WIoU of binarized graphs for r=0.9 =  0.19924624999999999
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.652
SUFF++ for r=0.9 class 0 = 0.659 +- 0.229 (in-sample avg dev_std = 0.345)
SUFF++ for r=0.9 class 1 = 0.81 +- 0.229 (in-sample avg dev_std = 0.345)
SUFF++ for r=0.9 class 2 = 0.767 +- 0.229 (in-sample avg dev_std = 0.345)
SUFF++ for r=0.9 all KL = 0.793 +- 0.229 (in-sample avg dev_std = 0.345)
SUFF++ for r=0.9 all L1 = 0.745 +- 0.209 (in-sample avg dev_std = 0.345)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.415
Model XAI F1 of binarized graphs for r=0.3 =  0.19157874999999996
Model XAI WIoU of binarized graphs for r=0.3 =  0.13074124999999998
len(reference) = 798
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.411
SUFF++ for r=0.3 class 0 = 0.823 +- 0.200 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.3 class 1 = 0.878 +- 0.200 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.3 class 2 = 0.825 +- 0.200 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.3 all KL = 0.899 +- 0.200 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.3 all L1 = 0.842 +- 0.179 (in-sample avg dev_std = 0.217)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.359
Model XAI F1 of binarized graphs for r=0.6 =  0.14660250000000002
Model XAI WIoU of binarized graphs for r=0.6 =  0.09557874999999999
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.386
SUFF++ for r=0.6 class 0 = 0.604 +- 0.422 (in-sample avg dev_std = 0.540)
SUFF++ for r=0.6 class 1 = 0.595 +- 0.422 (in-sample avg dev_std = 0.540)
SUFF++ for r=0.6 class 2 = 0.627 +- 0.422 (in-sample avg dev_std = 0.540)
SUFF++ for r=0.6 all KL = 0.523 +- 0.422 (in-sample avg dev_std = 0.540)
SUFF++ for r=0.6 all L1 = 0.608 +- 0.303 (in-sample avg dev_std = 0.540)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.349
Model XAI F1 of binarized graphs for r=0.9 =  0.12152625
Model XAI WIoU of binarized graphs for r=0.9 =  0.07779125
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.366
SUFF++ for r=0.9 class 0 = 0.701 +- 0.429 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.9 class 1 = 0.736 +- 0.429 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.9 class 2 = 0.758 +- 0.429 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.9 all KL = 0.579 +- 0.429 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.9 all L1 = 0.731 +- 0.272 (in-sample avg dev_std = 0.468)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.354
Model XAI F1 of binarized graphs for r=0.3 =  0.4858
Model XAI WIoU of binarized graphs for r=0.3 =  0.3643875
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.33
NEC for r=0.3 class 0 = 0.252 +- 0.172 (in-sample avg dev_std = 0.200)
NEC for r=0.3 class 1 = 0.206 +- 0.172 (in-sample avg dev_std = 0.200)
NEC for r=0.3 class 2 = 0.236 +- 0.172 (in-sample avg dev_std = 0.200)
NEC for r=0.3 all KL = 0.112 +- 0.172 (in-sample avg dev_std = 0.200)
NEC for r=0.3 all L1 = 0.232 +- 0.176 (in-sample avg dev_std = 0.200)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.521
Model XAI F1 of binarized graphs for r=0.6 =  0.5708199999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.453915
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.411
NEC for r=0.6 class 0 = 0.401 +- 0.292 (in-sample avg dev_std = 0.449)
NEC for r=0.6 class 1 = 0.244 +- 0.292 (in-sample avg dev_std = 0.449)
NEC for r=0.6 class 2 = 0.441 +- 0.292 (in-sample avg dev_std = 0.449)
NEC for r=0.6 all KL = 0.336 +- 0.292 (in-sample avg dev_std = 0.449)
NEC for r=0.6 all L1 = 0.364 +- 0.244 (in-sample avg dev_std = 0.449)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.793
Model XAI F1 of binarized graphs for r=0.9 =  0.5218200000000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.41843125000000003
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.495
NEC for r=0.9 class 0 = 0.587 +- 0.286 (in-sample avg dev_std = 0.541)
NEC for r=0.9 class 1 = 0.347 +- 0.286 (in-sample avg dev_std = 0.541)
NEC for r=0.9 class 2 = 0.593 +- 0.286 (in-sample avg dev_std = 0.541)
NEC for r=0.9 all KL = 0.51 +- 0.286 (in-sample avg dev_std = 0.541)
NEC for r=0.9 all L1 = 0.511 +- 0.214 (in-sample avg dev_std = 0.541)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.894
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.40064875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.535
NEC for r=1.0 class 0 = 0.549 +- 0.303 (in-sample avg dev_std = 0.561)
NEC for r=1.0 class 1 = 0.327 +- 0.303 (in-sample avg dev_std = 0.561)
NEC for r=1.0 class 2 = 0.552 +- 0.303 (in-sample avg dev_std = 0.561)
NEC for r=1.0 all KL = 0.486 +- 0.303 (in-sample avg dev_std = 0.561)
NEC for r=1.0 all L1 = 0.478 +- 0.221 (in-sample avg dev_std = 0.561)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.472
Model XAI F1 of binarized graphs for r=0.3 =  0.33412624999999996
Model XAI WIoU of binarized graphs for r=0.3 =  0.27287
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.345
NEC for r=0.3 class 0 = 0.239 +- 0.291 (in-sample avg dev_std = 0.153)
NEC for r=0.3 class 1 = 0.144 +- 0.291 (in-sample avg dev_std = 0.153)
NEC for r=0.3 class 2 = 0.229 +- 0.291 (in-sample avg dev_std = 0.153)
NEC for r=0.3 all KL = 0.153 +- 0.291 (in-sample avg dev_std = 0.153)
NEC for r=0.3 all L1 = 0.204 +- 0.249 (in-sample avg dev_std = 0.153)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.516
Model XAI F1 of binarized graphs for r=0.6 =  0.2948075
Model XAI WIoU of binarized graphs for r=0.6 =  0.23113375000000003
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.381
NEC for r=0.6 class 0 = 0.352 +- 0.261 (in-sample avg dev_std = 0.308)
NEC for r=0.6 class 1 = 0.127 +- 0.261 (in-sample avg dev_std = 0.308)
NEC for r=0.6 class 2 = 0.327 +- 0.261 (in-sample avg dev_std = 0.308)
NEC for r=0.6 all KL = 0.221 +- 0.261 (in-sample avg dev_std = 0.308)
NEC for r=0.6 all L1 = 0.268 +- 0.244 (in-sample avg dev_std = 0.308)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.715
Model XAI F1 of binarized graphs for r=0.9 =  0.25588125
Model XAI WIoU of binarized graphs for r=0.9 =  0.19924624999999999
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.464
NEC for r=0.9 class 0 = 0.532 +- 0.301 (in-sample avg dev_std = 0.420)
NEC for r=0.9 class 1 = 0.212 +- 0.301 (in-sample avg dev_std = 0.420)
NEC for r=0.9 class 2 = 0.512 +- 0.301 (in-sample avg dev_std = 0.420)
NEC for r=0.9 all KL = 0.393 +- 0.301 (in-sample avg dev_std = 0.420)
NEC for r=0.9 all L1 = 0.418 +- 0.263 (in-sample avg dev_std = 0.420)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.761
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.18704
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.506
NEC for r=1.0 class 0 = 0.492 +- 0.325 (in-sample avg dev_std = 0.443)
NEC for r=1.0 class 1 = 0.16 +- 0.325 (in-sample avg dev_std = 0.443)
NEC for r=1.0 class 2 = 0.449 +- 0.325 (in-sample avg dev_std = 0.443)
NEC for r=1.0 all KL = 0.359 +- 0.325 (in-sample avg dev_std = 0.443)
NEC for r=1.0 all L1 = 0.367 +- 0.277 (in-sample avg dev_std = 0.443)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.415
Model XAI F1 of binarized graphs for r=0.3 =  0.19157874999999996
Model XAI WIoU of binarized graphs for r=0.3 =  0.13074124999999998
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.353
NEC for r=0.3 class 0 = 0.213 +- 0.254 (in-sample avg dev_std = 0.253)
NEC for r=0.3 class 1 = 0.161 +- 0.254 (in-sample avg dev_std = 0.253)
NEC for r=0.3 class 2 = 0.183 +- 0.254 (in-sample avg dev_std = 0.253)
NEC for r=0.3 all KL = 0.142 +- 0.254 (in-sample avg dev_std = 0.253)
NEC for r=0.3 all L1 = 0.186 +- 0.212 (in-sample avg dev_std = 0.253)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.36
Model XAI F1 of binarized graphs for r=0.6 =  0.14660250000000002
Model XAI WIoU of binarized graphs for r=0.6 =  0.09557874999999999
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.355
NEC for r=0.6 class 0 = 0.335 +- 0.429 (in-sample avg dev_std = 0.269)
NEC for r=0.6 class 1 = 0.329 +- 0.429 (in-sample avg dev_std = 0.269)
NEC for r=0.6 class 2 = 0.354 +- 0.429 (in-sample avg dev_std = 0.269)
NEC for r=0.6 all KL = 0.38 +- 0.429 (in-sample avg dev_std = 0.269)
NEC for r=0.6 all L1 = 0.339 +- 0.328 (in-sample avg dev_std = 0.269)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.349
Model XAI F1 of binarized graphs for r=0.9 =  0.12152625
Model XAI WIoU of binarized graphs for r=0.9 =  0.07779125
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.351
NEC for r=0.9 class 0 = 0.264 +- 0.412 (in-sample avg dev_std = 0.357)
NEC for r=0.9 class 1 = 0.242 +- 0.412 (in-sample avg dev_std = 0.357)
NEC for r=0.9 class 2 = 0.239 +- 0.412 (in-sample avg dev_std = 0.357)
NEC for r=0.9 all KL = 0.357 +- 0.412 (in-sample avg dev_std = 0.357)
NEC for r=0.9 all L1 = 0.248 +- 0.289 (in-sample avg dev_std = 0.357)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.333
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.07303625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.357
NEC for r=1.0 class 0 = 0.271 +- 0.423 (in-sample avg dev_std = 0.307)
NEC for r=1.0 class 1 = 0.248 +- 0.423 (in-sample avg dev_std = 0.307)
NEC for r=1.0 class 2 = 0.271 +- 0.423 (in-sample avg dev_std = 0.307)
NEC for r=1.0 all KL = 0.411 +- 0.423 (in-sample avg dev_std = 0.307)
NEC for r=1.0 all L1 = 0.263 +- 0.273 (in-sample avg dev_std = 0.307)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 20:42:29 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:29 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:42 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:44 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:46 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:49 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:42:56 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 129...
[0m[1;37mINFO[0m: [1mCheckpoint 129: 
-----------------------------------
Train ACCURACY: 0.8893
Train Loss: 0.3913
ID Validation ACCURACY: 0.8960
ID Validation Loss: 0.3740
ID Test ACCURACY: 0.8947
ID Test Loss: 0.3923
OOD Validation ACCURACY: 0.6763
OOD Validation Loss: 1.0331
OOD Test ACCURACY: 0.3673
OOD Test Loss: 6.2730

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 60...
[0m[1;37mINFO[0m: [1mCheckpoint 60: 
-----------------------------------
Train ACCURACY: 0.8292
Train Loss: 0.6194
ID Validation ACCURACY: 0.8333
ID Validation Loss: 0.6112
ID Test ACCURACY: 0.8327
ID Test Loss: 0.6185
OOD Validation ACCURACY: 0.7947
OOD Validation Loss: 2.4540
OOD Test ACCURACY: 0.3827
OOD Test Loss: 9.6786

[0m[1;37mINFO[0m: [1mChartInfo 0.8947 0.3673 0.8327 0.3827 0.8333 0.7947[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.482
WIoU for r=0.3 = 0.360
F1 for r=0.6 = 0.562
WIoU for r=0.6 = 0.446
F1 for r=0.9 = 0.519
WIoU for r=0.9 = 0.426
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.411
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.386
WIoU for r=0.3 = 0.347
F1 for r=0.6 = 0.314
WIoU for r=0.6 = 0.338
F1 for r=0.9 = 0.255
WIoU for r=0.9 = 0.330
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.325
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.245
WIoU for r=0.3 = 0.290
F1 for r=0.6 = 0.156
WIoU for r=0.6 = 0.275
F1 for r=0.9 = 0.122
WIoU for r=0.9 = 0.276
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.275


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.354
Model XAI F1 of binarized graphs for r=0.3 =  0.48195374999999996
Model XAI WIoU of binarized graphs for r=0.3 =  0.36006374999999996
len(reference) = 757
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.336
SUFF++ for r=0.3 class 0 = 0.785 +- 0.135 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.3 class 1 = 0.83 +- 0.135 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.3 class 2 = 0.811 +- 0.135 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.3 all KL = 0.918 +- 0.135 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.3 all L1 = 0.808 +- 0.124 (in-sample avg dev_std = 0.232)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.554
Model XAI F1 of binarized graphs for r=0.6 =  0.56219125
Model XAI WIoU of binarized graphs for r=0.6 =  0.4460825
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.512
SUFF++ for r=0.6 class 0 = 0.668 +- 0.252 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.6 class 1 = 0.793 +- 0.252 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.6 class 2 = 0.706 +- 0.252 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.6 all KL = 0.751 +- 0.252 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.6 all L1 = 0.721 +- 0.199 (in-sample avg dev_std = 0.462)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.779
Model XAI F1 of binarized graphs for r=0.9 =  0.5190312499999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.42578249999999995
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.763
SUFF++ for r=0.9 class 0 = 0.8 +- 0.226 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 1 = 0.872 +- 0.226 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 2 = 0.822 +- 0.226 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 all KL = 0.856 +- 0.226 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 all L1 = 0.831 +- 0.205 (in-sample avg dev_std = 0.305)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.544
Model XAI F1 of binarized graphs for r=0.3 =  0.38594750000000005
Model XAI WIoU of binarized graphs for r=0.3 =  0.34671375
len(reference) = 799
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.519
SUFF++ for r=0.3 class 0 = 0.781 +- 0.197 (in-sample avg dev_std = 0.343)
SUFF++ for r=0.3 class 1 = 0.852 +- 0.197 (in-sample avg dev_std = 0.343)
SUFF++ for r=0.3 class 2 = 0.801 +- 0.197 (in-sample avg dev_std = 0.343)
SUFF++ for r=0.3 all KL = 0.862 +- 0.197 (in-sample avg dev_std = 0.343)
SUFF++ for r=0.3 all L1 = 0.811 +- 0.174 (in-sample avg dev_std = 0.343)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.611
Model XAI F1 of binarized graphs for r=0.6 =  0.31353875000000003
Model XAI WIoU of binarized graphs for r=0.6 =  0.3376925
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.608
SUFF++ for r=0.6 class 0 = 0.728 +- 0.233 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 class 1 = 0.723 +- 0.233 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 class 2 = 0.746 +- 0.233 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 all KL = 0.759 +- 0.233 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 all L1 = 0.732 +- 0.194 (in-sample avg dev_std = 0.415)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.659
Model XAI F1 of binarized graphs for r=0.9 =  0.25537375
Model XAI WIoU of binarized graphs for r=0.9 =  0.32952624999999997
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.688
SUFF++ for r=0.9 class 0 = 0.696 +- 0.247 (in-sample avg dev_std = 0.357)
SUFF++ for r=0.9 class 1 = 0.724 +- 0.247 (in-sample avg dev_std = 0.357)
SUFF++ for r=0.9 class 2 = 0.674 +- 0.247 (in-sample avg dev_std = 0.357)
SUFF++ for r=0.9 all KL = 0.76 +- 0.247 (in-sample avg dev_std = 0.357)
SUFF++ for r=0.9 all L1 = 0.698 +- 0.235 (in-sample avg dev_std = 0.357)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.545
Model XAI F1 of binarized graphs for r=0.3 =  0.24476875
Model XAI WIoU of binarized graphs for r=0.3 =  0.28956
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.57
SUFF++ for r=0.3 class 0 = 0.605 +- 0.323 (in-sample avg dev_std = 0.544)
SUFF++ for r=0.3 class 1 = 0.569 +- 0.323 (in-sample avg dev_std = 0.544)
SUFF++ for r=0.3 class 2 = 0.559 +- 0.323 (in-sample avg dev_std = 0.544)
SUFF++ for r=0.3 all KL = 0.547 +- 0.323 (in-sample avg dev_std = 0.544)
SUFF++ for r=0.3 all L1 = 0.578 +- 0.193 (in-sample avg dev_std = 0.544)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.399
Model XAI F1 of binarized graphs for r=0.6 =  0.155775
Model XAI WIoU of binarized graphs for r=0.6 =  0.27471625000000005
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.472
SUFF++ for r=0.6 class 0 = 0.754 +- 0.355 (in-sample avg dev_std = 0.434)
SUFF++ for r=0.6 class 1 = 0.645 +- 0.355 (in-sample avg dev_std = 0.434)
SUFF++ for r=0.6 class 2 = 0.682 +- 0.355 (in-sample avg dev_std = 0.434)
SUFF++ for r=0.6 all KL = 0.655 +- 0.355 (in-sample avg dev_std = 0.434)
SUFF++ for r=0.6 all L1 = 0.694 +- 0.280 (in-sample avg dev_std = 0.434)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.389
Model XAI F1 of binarized graphs for r=0.9 =  0.12197875
Model XAI WIoU of binarized graphs for r=0.9 =  0.27609875
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.386
SUFF++ for r=0.9 class 0 = 0.846 +- 0.279 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.9 class 1 = 0.846 +- 0.279 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.9 class 2 = 0.847 +- 0.279 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.9 all KL = 0.814 +- 0.279 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.9 all L1 = 0.846 +- 0.232 (in-sample avg dev_std = 0.297)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.356
Model XAI F1 of binarized graphs for r=0.3 =  0.48195374999999996
Model XAI WIoU of binarized graphs for r=0.3 =  0.36006374999999996
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.328
NEC for r=0.3 class 0 = 0.216 +- 0.171 (in-sample avg dev_std = 0.178)
NEC for r=0.3 class 1 = 0.172 +- 0.171 (in-sample avg dev_std = 0.178)
NEC for r=0.3 class 2 = 0.191 +- 0.171 (in-sample avg dev_std = 0.178)
NEC for r=0.3 all KL = 0.089 +- 0.171 (in-sample avg dev_std = 0.178)
NEC for r=0.3 all L1 = 0.194 +- 0.162 (in-sample avg dev_std = 0.178)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.554
Model XAI F1 of binarized graphs for r=0.6 =  0.56219125
Model XAI WIoU of binarized graphs for r=0.6 =  0.4460825
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.409
NEC for r=0.6 class 0 = 0.453 +- 0.311 (in-sample avg dev_std = 0.493)
NEC for r=0.6 class 1 = 0.296 +- 0.311 (in-sample avg dev_std = 0.493)
NEC for r=0.6 class 2 = 0.461 +- 0.311 (in-sample avg dev_std = 0.493)
NEC for r=0.6 all KL = 0.382 +- 0.311 (in-sample avg dev_std = 0.493)
NEC for r=0.6 all L1 = 0.405 +- 0.232 (in-sample avg dev_std = 0.493)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.779
Model XAI F1 of binarized graphs for r=0.9 =  0.5190312499999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.42578249999999995
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.48
NEC for r=0.9 class 0 = 0.562 +- 0.287 (in-sample avg dev_std = 0.598)
NEC for r=0.9 class 1 = 0.366 +- 0.287 (in-sample avg dev_std = 0.598)
NEC for r=0.9 class 2 = 0.582 +- 0.287 (in-sample avg dev_std = 0.598)
NEC for r=0.9 all KL = 0.542 +- 0.287 (in-sample avg dev_std = 0.598)
NEC for r=0.9 all L1 = 0.505 +- 0.206 (in-sample avg dev_std = 0.598)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.897
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.41093
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.522
NEC for r=1.0 class 0 = 0.575 +- 0.304 (in-sample avg dev_std = 0.598)
NEC for r=1.0 class 1 = 0.355 +- 0.304 (in-sample avg dev_std = 0.598)
NEC for r=1.0 class 2 = 0.561 +- 0.304 (in-sample avg dev_std = 0.598)
NEC for r=1.0 all KL = 0.536 +- 0.304 (in-sample avg dev_std = 0.598)
NEC for r=1.0 all L1 = 0.499 +- 0.216 (in-sample avg dev_std = 0.598)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.545
Model XAI F1 of binarized graphs for r=0.3 =  0.38594750000000005
Model XAI WIoU of binarized graphs for r=0.3 =  0.34671375
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.346
NEC for r=0.3 class 0 = 0.36 +- 0.336 (in-sample avg dev_std = 0.264)
NEC for r=0.3 class 1 = 0.266 +- 0.336 (in-sample avg dev_std = 0.264)
NEC for r=0.3 class 2 = 0.377 +- 0.336 (in-sample avg dev_std = 0.264)
NEC for r=0.3 all KL = 0.279 +- 0.336 (in-sample avg dev_std = 0.264)
NEC for r=0.3 all L1 = 0.334 +- 0.270 (in-sample avg dev_std = 0.264)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.611
Model XAI F1 of binarized graphs for r=0.6 =  0.31353875000000003
Model XAI WIoU of binarized graphs for r=0.6 =  0.3376925
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.442
NEC for r=0.6 class 0 = 0.483 +- 0.307 (in-sample avg dev_std = 0.509)
NEC for r=0.6 class 1 = 0.328 +- 0.307 (in-sample avg dev_std = 0.509)
NEC for r=0.6 class 2 = 0.537 +- 0.307 (in-sample avg dev_std = 0.509)
NEC for r=0.6 all KL = 0.466 +- 0.307 (in-sample avg dev_std = 0.509)
NEC for r=0.6 all L1 = 0.448 +- 0.222 (in-sample avg dev_std = 0.509)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.659
Model XAI F1 of binarized graphs for r=0.9 =  0.25537375
Model XAI WIoU of binarized graphs for r=0.9 =  0.32952624999999997
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.517
NEC for r=0.9 class 0 = 0.513 +- 0.258 (in-sample avg dev_std = 0.524)
NEC for r=0.9 class 1 = 0.396 +- 0.258 (in-sample avg dev_std = 0.524)
NEC for r=0.9 class 2 = 0.569 +- 0.258 (in-sample avg dev_std = 0.524)
NEC for r=0.9 all KL = 0.491 +- 0.258 (in-sample avg dev_std = 0.524)
NEC for r=0.9 all L1 = 0.492 +- 0.180 (in-sample avg dev_std = 0.524)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.701
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.32478625000000005
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.528
NEC for r=1.0 class 0 = 0.462 +- 0.311 (in-sample avg dev_std = 0.485)
NEC for r=1.0 class 1 = 0.347 +- 0.311 (in-sample avg dev_std = 0.485)
NEC for r=1.0 class 2 = 0.484 +- 0.311 (in-sample avg dev_std = 0.485)
NEC for r=1.0 all KL = 0.441 +- 0.311 (in-sample avg dev_std = 0.485)
NEC for r=1.0 all L1 = 0.431 +- 0.220 (in-sample avg dev_std = 0.485)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.544
Model XAI F1 of binarized graphs for r=0.3 =  0.24476875
Model XAI WIoU of binarized graphs for r=0.3 =  0.28956
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.357
NEC for r=0.3 class 0 = 0.395 +- 0.326 (in-sample avg dev_std = 0.336)
NEC for r=0.3 class 1 = 0.385 +- 0.326 (in-sample avg dev_std = 0.336)
NEC for r=0.3 class 2 = 0.465 +- 0.326 (in-sample avg dev_std = 0.336)
NEC for r=0.3 all KL = 0.388 +- 0.326 (in-sample avg dev_std = 0.336)
NEC for r=0.3 all L1 = 0.414 +- 0.269 (in-sample avg dev_std = 0.336)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.399
Model XAI F1 of binarized graphs for r=0.6 =  0.155775
Model XAI WIoU of binarized graphs for r=0.6 =  0.27471625000000005
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.353
NEC for r=0.6 class 0 = 0.226 +- 0.280 (in-sample avg dev_std = 0.299)
NEC for r=0.6 class 1 = 0.22 +- 0.280 (in-sample avg dev_std = 0.299)
NEC for r=0.6 class 2 = 0.274 +- 0.280 (in-sample avg dev_std = 0.299)
NEC for r=0.6 all KL = 0.245 +- 0.280 (in-sample avg dev_std = 0.299)
NEC for r=0.6 all L1 = 0.239 +- 0.265 (in-sample avg dev_std = 0.299)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.389
Model XAI F1 of binarized graphs for r=0.9 =  0.12197875
Model XAI WIoU of binarized graphs for r=0.9 =  0.27609875
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.35
NEC for r=0.9 class 0 = 0.192 +- 0.330 (in-sample avg dev_std = 0.281)
NEC for r=0.9 class 1 = 0.148 +- 0.330 (in-sample avg dev_std = 0.281)
NEC for r=0.9 class 2 = 0.139 +- 0.330 (in-sample avg dev_std = 0.281)
NEC for r=0.9 all KL = 0.197 +- 0.330 (in-sample avg dev_std = 0.281)
NEC for r=0.9 all L1 = 0.16 +- 0.262 (in-sample avg dev_std = 0.281)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.37
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.2752525
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.349
NEC for r=1.0 class 0 = 0.168 +- 0.304 (in-sample avg dev_std = 0.270)
NEC for r=1.0 class 1 = 0.125 +- 0.304 (in-sample avg dev_std = 0.270)
NEC for r=1.0 class 2 = 0.112 +- 0.304 (in-sample avg dev_std = 0.270)
NEC for r=1.0 all KL = 0.173 +- 0.304 (in-sample avg dev_std = 0.270)
NEC for r=1.0 all L1 = 0.135 +- 0.233 (in-sample avg dev_std = 0.270)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 20:49:01 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:01 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:13 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:15 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:17 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:21 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:49:27 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 192...
[0m[1;37mINFO[0m: [1mCheckpoint 192: 
-----------------------------------
Train ACCURACY: 0.9289
Train Loss: 0.3014
ID Validation ACCURACY: 0.9363
ID Validation Loss: 0.2957
ID Test ACCURACY: 0.9313
ID Test Loss: 0.3056
OOD Validation ACCURACY: 0.8693
OOD Validation Loss: 0.4349
OOD Test ACCURACY: 0.4197
OOD Test Loss: 3.0359

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 147...
[0m[1;37mINFO[0m: [1mCheckpoint 147: 
-----------------------------------
Train ACCURACY: 0.9283
Train Loss: 0.3001
ID Validation ACCURACY: 0.9340
ID Validation Loss: 0.2878
ID Test ACCURACY: 0.9307
ID Test Loss: 0.3011
OOD Validation ACCURACY: 0.9180
OOD Validation Loss: 0.3532
OOD Test ACCURACY: 0.4307
OOD Test Loss: 2.2044

[0m[1;37mINFO[0m: [1mChartInfo 0.9313 0.4197 0.9307 0.4307 0.9340 0.9180[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.585
WIoU for r=0.3 = 0.472
F1 for r=0.6 = 0.613
WIoU for r=0.6 = 0.579
F1 for r=0.9 = 0.515
WIoU for r=0.9 = 0.577
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.577
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.477
WIoU for r=0.3 = 0.459
F1 for r=0.6 = 0.345
WIoU for r=0.6 = 0.438
F1 for r=0.9 = 0.256
WIoU for r=0.9 = 0.432
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.431
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.277
WIoU for r=0.3 = 0.215
F1 for r=0.6 = 0.173
WIoU for r=0.6 = 0.166
F1 for r=0.9 = 0.123
WIoU for r=0.9 = 0.148
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.144


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.375
Model XAI F1 of binarized graphs for r=0.3 =  0.58452875
Model XAI WIoU of binarized graphs for r=0.3 =  0.47213375
len(reference) = 778
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.351
SUFF++ for r=0.3 class 0 = 0.845 +- 0.208 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.3 class 1 = 0.932 +- 0.208 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.3 class 2 = 0.848 +- 0.208 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.3 all KL = 0.899 +- 0.208 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.3 all L1 = 0.874 +- 0.179 (in-sample avg dev_std = 0.289)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.663
Model XAI F1 of binarized graphs for r=0.6 =  0.613045
Model XAI WIoU of binarized graphs for r=0.6 =  0.5787362500000001
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.628
SUFF++ for r=0.6 class 0 = 0.766 +- 0.234 (in-sample avg dev_std = 0.449)
SUFF++ for r=0.6 class 1 = 0.842 +- 0.234 (in-sample avg dev_std = 0.449)
SUFF++ for r=0.6 class 2 = 0.731 +- 0.234 (in-sample avg dev_std = 0.449)
SUFF++ for r=0.6 all KL = 0.787 +- 0.234 (in-sample avg dev_std = 0.449)
SUFF++ for r=0.6 all L1 = 0.779 +- 0.202 (in-sample avg dev_std = 0.449)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.789
Model XAI F1 of binarized graphs for r=0.9 =  0.51542875
Model XAI WIoU of binarized graphs for r=0.9 =  0.577485
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.784
SUFF++ for r=0.9 class 0 = 0.849 +- 0.188 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.9 class 1 = 0.888 +- 0.188 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.9 class 2 = 0.898 +- 0.188 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.9 all KL = 0.898 +- 0.188 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.9 all L1 = 0.878 +- 0.179 (in-sample avg dev_std = 0.289)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.61
Model XAI F1 of binarized graphs for r=0.3 =  0.4772875
Model XAI WIoU of binarized graphs for r=0.3 =  0.45941375
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.587
SUFF++ for r=0.3 class 0 = 0.798 +- 0.223 (in-sample avg dev_std = 0.386)
SUFF++ for r=0.3 class 1 = 0.903 +- 0.223 (in-sample avg dev_std = 0.386)
SUFF++ for r=0.3 class 2 = 0.802 +- 0.223 (in-sample avg dev_std = 0.386)
SUFF++ for r=0.3 all KL = 0.842 +- 0.223 (in-sample avg dev_std = 0.386)
SUFF++ for r=0.3 all L1 = 0.834 +- 0.189 (in-sample avg dev_std = 0.386)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.719
Model XAI F1 of binarized graphs for r=0.6 =  0.34513875
Model XAI WIoU of binarized graphs for r=0.6 =  0.43772625
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.698
SUFF++ for r=0.6 class 0 = 0.744 +- 0.187 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 class 1 = 0.784 +- 0.187 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 class 2 = 0.742 +- 0.187 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 all KL = 0.822 +- 0.187 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 all L1 = 0.757 +- 0.187 (in-sample avg dev_std = 0.353)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.691
Model XAI F1 of binarized graphs for r=0.9 =  0.25637875
Model XAI WIoU of binarized graphs for r=0.9 =  0.43223625
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.703
SUFF++ for r=0.9 class 0 = 0.754 +- 0.290 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.9 class 1 = 0.839 +- 0.290 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.9 class 2 = 0.797 +- 0.290 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.9 all KL = 0.79 +- 0.290 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.9 all L1 = 0.797 +- 0.233 (in-sample avg dev_std = 0.399)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.671
Model XAI F1 of binarized graphs for r=0.3 =  0.277145
Model XAI WIoU of binarized graphs for r=0.3 =  0.21495
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.634
SUFF++ for r=0.3 class 0 = 0.701 +- 0.185 (in-sample avg dev_std = 0.369)
SUFF++ for r=0.3 class 1 = 0.797 +- 0.185 (in-sample avg dev_std = 0.369)
SUFF++ for r=0.3 class 2 = 0.699 +- 0.185 (in-sample avg dev_std = 0.369)
SUFF++ for r=0.3 all KL = 0.81 +- 0.185 (in-sample avg dev_std = 0.369)
SUFF++ for r=0.3 all L1 = 0.733 +- 0.156 (in-sample avg dev_std = 0.369)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.464
Model XAI F1 of binarized graphs for r=0.6 =  0.17305625
Model XAI WIoU of binarized graphs for r=0.6 =  0.16601999999999997
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.545
SUFF++ for r=0.6 class 0 = 0.655 +- 0.243 (in-sample avg dev_std = 0.357)
SUFF++ for r=0.6 class 1 = 0.799 +- 0.243 (in-sample avg dev_std = 0.357)
SUFF++ for r=0.6 class 2 = 0.767 +- 0.243 (in-sample avg dev_std = 0.357)
SUFF++ for r=0.6 all KL = 0.722 +- 0.243 (in-sample avg dev_std = 0.357)
SUFF++ for r=0.6 all L1 = 0.74 +- 0.211 (in-sample avg dev_std = 0.357)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.365
Model XAI F1 of binarized graphs for r=0.9 =  0.12338625
Model XAI WIoU of binarized graphs for r=0.9 =  0.14814875
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.4
SUFF++ for r=0.9 class 0 = 0.806 +- 0.219 (in-sample avg dev_std = 0.349)
SUFF++ for r=0.9 class 1 = 0.83 +- 0.219 (in-sample avg dev_std = 0.349)
SUFF++ for r=0.9 class 2 = 0.852 +- 0.219 (in-sample avg dev_std = 0.349)
SUFF++ for r=0.9 all KL = 0.834 +- 0.219 (in-sample avg dev_std = 0.349)
SUFF++ for r=0.9 all L1 = 0.829 +- 0.180 (in-sample avg dev_std = 0.349)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.376
Model XAI F1 of binarized graphs for r=0.3 =  0.58452875
Model XAI WIoU of binarized graphs for r=0.3 =  0.47213375
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.331
NEC for r=0.3 class 0 = 0.174 +- 0.245 (in-sample avg dev_std = 0.159)
NEC for r=0.3 class 1 = 0.1 +- 0.245 (in-sample avg dev_std = 0.159)
NEC for r=0.3 class 2 = 0.169 +- 0.245 (in-sample avg dev_std = 0.159)
NEC for r=0.3 all KL = 0.106 +- 0.245 (in-sample avg dev_std = 0.159)
NEC for r=0.3 all L1 = 0.148 +- 0.223 (in-sample avg dev_std = 0.159)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.663
Model XAI F1 of binarized graphs for r=0.6 =  0.613045
Model XAI WIoU of binarized graphs for r=0.6 =  0.5787362500000001
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.39
NEC for r=0.6 class 0 = 0.527 +- 0.368 (in-sample avg dev_std = 0.484)
NEC for r=0.6 class 1 = 0.24 +- 0.368 (in-sample avg dev_std = 0.484)
NEC for r=0.6 class 2 = 0.537 +- 0.368 (in-sample avg dev_std = 0.484)
NEC for r=0.6 all KL = 0.45 +- 0.368 (in-sample avg dev_std = 0.484)
NEC for r=0.6 all L1 = 0.437 +- 0.288 (in-sample avg dev_std = 0.484)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.789
Model XAI F1 of binarized graphs for r=0.9 =  0.51542875
Model XAI WIoU of binarized graphs for r=0.9 =  0.577485
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.486
NEC for r=0.9 class 0 = 0.617 +- 0.328 (in-sample avg dev_std = 0.613)
NEC for r=0.9 class 1 = 0.285 +- 0.328 (in-sample avg dev_std = 0.613)
NEC for r=0.9 class 2 = 0.592 +- 0.328 (in-sample avg dev_std = 0.613)
NEC for r=0.9 all KL = 0.56 +- 0.328 (in-sample avg dev_std = 0.613)
NEC for r=0.9 all L1 = 0.501 +- 0.257 (in-sample avg dev_std = 0.613)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.938
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.5772025
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.548
NEC for r=1.0 class 0 = 0.601 +- 0.335 (in-sample avg dev_std = 0.650)
NEC for r=1.0 class 1 = 0.235 +- 0.335 (in-sample avg dev_std = 0.650)
NEC for r=1.0 class 2 = 0.585 +- 0.335 (in-sample avg dev_std = 0.650)
NEC for r=1.0 all KL = 0.557 +- 0.335 (in-sample avg dev_std = 0.650)
NEC for r=1.0 all L1 = 0.477 +- 0.265 (in-sample avg dev_std = 0.650)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.61
Model XAI F1 of binarized graphs for r=0.3 =  0.4772875
Model XAI WIoU of binarized graphs for r=0.3 =  0.45941375
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.346
NEC for r=0.3 class 0 = 0.43 +- 0.424 (in-sample avg dev_std = 0.178)
NEC for r=0.3 class 1 = 0.082 +- 0.424 (in-sample avg dev_std = 0.178)
NEC for r=0.3 class 2 = 0.422 +- 0.424 (in-sample avg dev_std = 0.178)
NEC for r=0.3 all KL = 0.32 +- 0.424 (in-sample avg dev_std = 0.178)
NEC for r=0.3 all L1 = 0.311 +- 0.362 (in-sample avg dev_std = 0.178)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.719
Model XAI F1 of binarized graphs for r=0.6 =  0.34513875
Model XAI WIoU of binarized graphs for r=0.6 =  0.43772625
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.443
NEC for r=0.6 class 0 = 0.61 +- 0.348 (in-sample avg dev_std = 0.454)
NEC for r=0.6 class 1 = 0.198 +- 0.348 (in-sample avg dev_std = 0.454)
NEC for r=0.6 class 2 = 0.594 +- 0.348 (in-sample avg dev_std = 0.454)
NEC for r=0.6 all KL = 0.448 +- 0.348 (in-sample avg dev_std = 0.454)
NEC for r=0.6 all L1 = 0.466 +- 0.277 (in-sample avg dev_std = 0.454)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.689
Model XAI F1 of binarized graphs for r=0.9 =  0.25637875
Model XAI WIoU of binarized graphs for r=0.9 =  0.43223625
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.499
NEC for r=0.9 class 0 = 0.543 +- 0.321 (in-sample avg dev_std = 0.504)
NEC for r=0.9 class 1 = 0.163 +- 0.321 (in-sample avg dev_std = 0.504)
NEC for r=0.9 class 2 = 0.545 +- 0.321 (in-sample avg dev_std = 0.504)
NEC for r=0.9 all KL = 0.425 +- 0.321 (in-sample avg dev_std = 0.504)
NEC for r=0.9 all L1 = 0.416 +- 0.277 (in-sample avg dev_std = 0.504)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.889
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.43131
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.541
NEC for r=1.0 class 0 = 0.653 +- 0.323 (in-sample avg dev_std = 0.539)
NEC for r=1.0 class 1 = 0.184 +- 0.323 (in-sample avg dev_std = 0.539)
NEC for r=1.0 class 2 = 0.597 +- 0.323 (in-sample avg dev_std = 0.539)
NEC for r=1.0 all KL = 0.492 +- 0.323 (in-sample avg dev_std = 0.539)
NEC for r=1.0 all L1 = 0.477 +- 0.266 (in-sample avg dev_std = 0.539)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.671
Model XAI F1 of binarized graphs for r=0.3 =  0.277145
Model XAI WIoU of binarized graphs for r=0.3 =  0.21495
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.354
NEC for r=0.3 class 0 = 0.529 +- 0.419 (in-sample avg dev_std = 0.180)
NEC for r=0.3 class 1 = 0.164 +- 0.419 (in-sample avg dev_std = 0.180)
NEC for r=0.3 class 2 = 0.516 +- 0.419 (in-sample avg dev_std = 0.180)
NEC for r=0.3 all KL = 0.373 +- 0.419 (in-sample avg dev_std = 0.180)
NEC for r=0.3 all L1 = 0.4 +- 0.341 (in-sample avg dev_std = 0.180)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.464
Model XAI F1 of binarized graphs for r=0.6 =  0.17305625
Model XAI WIoU of binarized graphs for r=0.6 =  0.16601999999999997
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.366
NEC for r=0.6 class 0 = 0.306 +- 0.273 (in-sample avg dev_std = 0.305)
NEC for r=0.6 class 1 = 0.157 +- 0.273 (in-sample avg dev_std = 0.305)
NEC for r=0.6 class 2 = 0.361 +- 0.273 (in-sample avg dev_std = 0.305)
NEC for r=0.6 all KL = 0.269 +- 0.273 (in-sample avg dev_std = 0.305)
NEC for r=0.6 all L1 = 0.272 +- 0.235 (in-sample avg dev_std = 0.305)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.364
Model XAI F1 of binarized graphs for r=0.9 =  0.12338625
Model XAI WIoU of binarized graphs for r=0.9 =  0.14814875
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.35
NEC for r=0.9 class 0 = 0.263 +- 0.233 (in-sample avg dev_std = 0.264)
NEC for r=0.9 class 1 = 0.185 +- 0.233 (in-sample avg dev_std = 0.264)
NEC for r=0.9 class 2 = 0.296 +- 0.233 (in-sample avg dev_std = 0.264)
NEC for r=0.9 all KL = 0.206 +- 0.233 (in-sample avg dev_std = 0.264)
NEC for r=0.9 all L1 = 0.247 +- 0.208 (in-sample avg dev_std = 0.264)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.431
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.14440375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.345
NEC for r=1.0 class 0 = 0.337 +- 0.262 (in-sample avg dev_std = 0.294)
NEC for r=1.0 class 1 = 0.339 +- 0.262 (in-sample avg dev_std = 0.294)
NEC for r=1.0 class 2 = 0.33 +- 0.262 (in-sample avg dev_std = 0.294)
NEC for r=1.0 all KL = 0.328 +- 0.262 (in-sample avg dev_std = 0.294)
NEC for r=1.0 all L1 = 0.335 +- 0.214 (in-sample avg dev_std = 0.294)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 20:55:28 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:28 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:40 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:42 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:44 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:48 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 08:55:54 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 123...
[0m[1;37mINFO[0m: [1mCheckpoint 123: 
-----------------------------------
Train ACCURACY: 0.9266
Train Loss: 0.3084
ID Validation ACCURACY: 0.9333
ID Validation Loss: 0.2927
ID Test ACCURACY: 0.9300
ID Test Loss: 0.3020
OOD Validation ACCURACY: 0.7857
OOD Validation Loss: 0.8791
OOD Test ACCURACY: 0.5160
OOD Test Loss: 2.9408

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 183...
[0m[1;37mINFO[0m: [1mCheckpoint 183: 
-----------------------------------
Train ACCURACY: 0.9069
Train Loss: 0.3431
ID Validation ACCURACY: 0.9113
ID Validation Loss: 0.3325
ID Test ACCURACY: 0.9107
ID Test Loss: 0.3433
OOD Validation ACCURACY: 0.8867
OOD Validation Loss: 0.4057
OOD Test ACCURACY: 0.5663
OOD Test Loss: 1.7709

[0m[1;37mINFO[0m: [1mChartInfo 0.9300 0.5160 0.9107 0.5663 0.9113 0.8867[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.402
WIoU for r=0.3 = 0.345
F1 for r=0.6 = 0.416
WIoU for r=0.6 = 0.357
F1 for r=0.9 = 0.460
WIoU for r=0.9 = 0.394
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.397
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.317
WIoU for r=0.3 = 0.320
F1 for r=0.6 = 0.261
WIoU for r=0.6 = 0.322
F1 for r=0.9 = 0.220
WIoU for r=0.9 = 0.327
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.330
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.167
WIoU for r=0.3 = 0.250
F1 for r=0.6 = 0.134
WIoU for r=0.6 = 0.256
F1 for r=0.9 = 0.102
WIoU for r=0.9 = 0.257
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.262


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.472
Model XAI F1 of binarized graphs for r=0.3 =  0.40208625
Model XAI WIoU of binarized graphs for r=0.3 =  0.3445125
len(reference) = 795
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.399
SUFF++ for r=0.3 class 0 = 0.64 +- 0.313 (in-sample avg dev_std = 0.449)
SUFF++ for r=0.3 class 1 = 0.76 +- 0.313 (in-sample avg dev_std = 0.449)
SUFF++ for r=0.3 class 2 = 0.704 +- 0.313 (in-sample avg dev_std = 0.449)
SUFF++ for r=0.3 all KL = 0.696 +- 0.313 (in-sample avg dev_std = 0.449)
SUFF++ for r=0.3 all L1 = 0.7 +- 0.276 (in-sample avg dev_std = 0.449)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.608
Model XAI F1 of binarized graphs for r=0.6 =  0.416485
Model XAI WIoU of binarized graphs for r=0.6 =  0.35696375
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.465
SUFF++ for r=0.6 class 0 = 0.405 +- 0.275 (in-sample avg dev_std = 0.533)
SUFF++ for r=0.6 class 1 = 0.611 +- 0.275 (in-sample avg dev_std = 0.533)
SUFF++ for r=0.6 class 2 = 0.54 +- 0.275 (in-sample avg dev_std = 0.533)
SUFF++ for r=0.6 all KL = 0.524 +- 0.275 (in-sample avg dev_std = 0.533)
SUFF++ for r=0.6 all L1 = 0.517 +- 0.227 (in-sample avg dev_std = 0.533)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.896
Model XAI F1 of binarized graphs for r=0.9 =  0.45997874999999994
Model XAI WIoU of binarized graphs for r=0.9 =  0.39418
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.704
SUFF++ for r=0.9 class 0 = 0.628 +- 0.307 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.9 class 1 = 0.725 +- 0.307 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.9 class 2 = 0.688 +- 0.307 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.9 all KL = 0.661 +- 0.307 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.9 all L1 = 0.68 +- 0.252 (in-sample avg dev_std = 0.532)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.534
Model XAI F1 of binarized graphs for r=0.3 =  0.31715875
Model XAI WIoU of binarized graphs for r=0.3 =  0.32028875
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.493
SUFF++ for r=0.3 class 0 = 0.549 +- 0.309 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.3 class 1 = 0.731 +- 0.309 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.3 class 2 = 0.672 +- 0.309 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.3 all KL = 0.616 +- 0.309 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.3 all L1 = 0.65 +- 0.263 (in-sample avg dev_std = 0.507)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.605
Model XAI F1 of binarized graphs for r=0.6 =  0.26108750000000003
Model XAI WIoU of binarized graphs for r=0.6 =  0.32176000000000005
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.51
SUFF++ for r=0.6 class 0 = 0.5 +- 0.275 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.6 class 1 = 0.694 +- 0.275 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.6 class 2 = 0.581 +- 0.275 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.6 all KL = 0.64 +- 0.275 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.6 all L1 = 0.591 +- 0.225 (in-sample avg dev_std = 0.466)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.716
Model XAI F1 of binarized graphs for r=0.9 =  0.21979625
Model XAI WIoU of binarized graphs for r=0.9 =  0.32715874999999994
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.614
SUFF++ for r=0.9 class 0 = 0.523 +- 0.306 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.9 class 1 = 0.621 +- 0.306 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.9 class 2 = 0.687 +- 0.306 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.9 all KL = 0.619 +- 0.306 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.9 all L1 = 0.609 +- 0.265 (in-sample avg dev_std = 0.459)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.438
Model XAI F1 of binarized graphs for r=0.3 =  0.16682499999999997
Model XAI WIoU of binarized graphs for r=0.3 =  0.24966875000000002
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.438
SUFF++ for r=0.3 class 0 = 0.534 +- 0.318 (in-sample avg dev_std = 0.598)
SUFF++ for r=0.3 class 1 = 0.548 +- 0.318 (in-sample avg dev_std = 0.598)
SUFF++ for r=0.3 class 2 = 0.575 +- 0.318 (in-sample avg dev_std = 0.598)
SUFF++ for r=0.3 all KL = 0.473 +- 0.318 (in-sample avg dev_std = 0.598)
SUFF++ for r=0.3 all L1 = 0.552 +- 0.244 (in-sample avg dev_std = 0.598)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.394
Model XAI F1 of binarized graphs for r=0.6 =  0.1338175
Model XAI WIoU of binarized graphs for r=0.6 =  0.2557825
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.428
SUFF++ for r=0.6 class 0 = 0.497 +- 0.278 (in-sample avg dev_std = 0.537)
SUFF++ for r=0.6 class 1 = 0.559 +- 0.278 (in-sample avg dev_std = 0.537)
SUFF++ for r=0.6 class 2 = 0.553 +- 0.278 (in-sample avg dev_std = 0.537)
SUFF++ for r=0.6 all KL = 0.495 +- 0.278 (in-sample avg dev_std = 0.537)
SUFF++ for r=0.6 all L1 = 0.536 +- 0.202 (in-sample avg dev_std = 0.537)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.419
Model XAI F1 of binarized graphs for r=0.9 =  0.101945
Model XAI WIoU of binarized graphs for r=0.9 =  0.25745125
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.403
SUFF++ for r=0.9 class 0 = 0.718 +- 0.216 (in-sample avg dev_std = 0.352)
SUFF++ for r=0.9 class 1 = 0.751 +- 0.216 (in-sample avg dev_std = 0.352)
SUFF++ for r=0.9 class 2 = 0.732 +- 0.216 (in-sample avg dev_std = 0.352)
SUFF++ for r=0.9 all KL = 0.776 +- 0.216 (in-sample avg dev_std = 0.352)
SUFF++ for r=0.9 all L1 = 0.734 +- 0.206 (in-sample avg dev_std = 0.352)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.469
Model XAI F1 of binarized graphs for r=0.3 =  0.40208625
Model XAI WIoU of binarized graphs for r=0.3 =  0.3445125
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.342
NEC for r=0.3 class 0 = 0.412 +- 0.363 (in-sample avg dev_std = 0.373)
NEC for r=0.3 class 1 = 0.228 +- 0.363 (in-sample avg dev_std = 0.373)
NEC for r=0.3 class 2 = 0.4 +- 0.363 (in-sample avg dev_std = 0.373)
NEC for r=0.3 all KL = 0.354 +- 0.363 (in-sample avg dev_std = 0.373)
NEC for r=0.3 all L1 = 0.348 +- 0.320 (in-sample avg dev_std = 0.373)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.606
Model XAI F1 of binarized graphs for r=0.6 =  0.416485
Model XAI WIoU of binarized graphs for r=0.6 =  0.35696375
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.419
NEC for r=0.6 class 0 = 0.618 +- 0.310 (in-sample avg dev_std = 0.524)
NEC for r=0.6 class 1 = 0.356 +- 0.310 (in-sample avg dev_std = 0.524)
NEC for r=0.6 class 2 = 0.57 +- 0.310 (in-sample avg dev_std = 0.524)
NEC for r=0.6 all KL = 0.521 +- 0.310 (in-sample avg dev_std = 0.524)
NEC for r=0.6 all L1 = 0.517 +- 0.249 (in-sample avg dev_std = 0.524)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.895
Model XAI F1 of binarized graphs for r=0.9 =  0.45997874999999994
Model XAI WIoU of binarized graphs for r=0.9 =  0.39418
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.522
NEC for r=0.9 class 0 = 0.611 +- 0.314 (in-sample avg dev_std = 0.638)
NEC for r=0.9 class 1 = 0.283 +- 0.314 (in-sample avg dev_std = 0.638)
NEC for r=0.9 class 2 = 0.591 +- 0.314 (in-sample avg dev_std = 0.638)
NEC for r=0.9 all KL = 0.563 +- 0.314 (in-sample avg dev_std = 0.638)
NEC for r=0.9 all L1 = 0.498 +- 0.252 (in-sample avg dev_std = 0.638)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.934
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.39679125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.545
NEC for r=1.0 class 0 = 0.587 +- 0.297 (in-sample avg dev_std = 0.687)
NEC for r=1.0 class 1 = 0.293 +- 0.297 (in-sample avg dev_std = 0.687)
NEC for r=1.0 class 2 = 0.602 +- 0.297 (in-sample avg dev_std = 0.687)
NEC for r=1.0 all KL = 0.583 +- 0.297 (in-sample avg dev_std = 0.687)
NEC for r=1.0 all L1 = 0.497 +- 0.233 (in-sample avg dev_std = 0.687)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.534
Model XAI F1 of binarized graphs for r=0.3 =  0.31715875
Model XAI WIoU of binarized graphs for r=0.3 =  0.32028875
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.379
NEC for r=0.3 class 0 = 0.525 +- 0.406 (in-sample avg dev_std = 0.366)
NEC for r=0.3 class 1 = 0.251 +- 0.406 (in-sample avg dev_std = 0.366)
NEC for r=0.3 class 2 = 0.497 +- 0.406 (in-sample avg dev_std = 0.366)
NEC for r=0.3 all KL = 0.453 +- 0.406 (in-sample avg dev_std = 0.366)
NEC for r=0.3 all L1 = 0.424 +- 0.342 (in-sample avg dev_std = 0.366)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.606
Model XAI F1 of binarized graphs for r=0.6 =  0.26108750000000003
Model XAI WIoU of binarized graphs for r=0.6 =  0.32176000000000005
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.445
NEC for r=0.6 class 0 = 0.565 +- 0.380 (in-sample avg dev_std = 0.449)
NEC for r=0.6 class 1 = 0.308 +- 0.380 (in-sample avg dev_std = 0.449)
NEC for r=0.6 class 2 = 0.575 +- 0.380 (in-sample avg dev_std = 0.449)
NEC for r=0.6 all KL = 0.488 +- 0.380 (in-sample avg dev_std = 0.449)
NEC for r=0.6 all L1 = 0.481 +- 0.279 (in-sample avg dev_std = 0.449)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.716
Model XAI F1 of binarized graphs for r=0.9 =  0.21979625
Model XAI WIoU of binarized graphs for r=0.9 =  0.32715874999999994
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.519
NEC for r=0.9 class 0 = 0.623 +- 0.281 (in-sample avg dev_std = 0.573)
NEC for r=0.9 class 1 = 0.429 +- 0.281 (in-sample avg dev_std = 0.573)
NEC for r=0.9 class 2 = 0.637 +- 0.281 (in-sample avg dev_std = 0.573)
NEC for r=0.9 all KL = 0.62 +- 0.281 (in-sample avg dev_std = 0.573)
NEC for r=0.9 all L1 = 0.562 +- 0.223 (in-sample avg dev_std = 0.573)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.808
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.32957375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.518
NEC for r=1.0 class 0 = 0.609 +- 0.271 (in-sample avg dev_std = 0.602)
NEC for r=1.0 class 1 = 0.45 +- 0.271 (in-sample avg dev_std = 0.602)
NEC for r=1.0 class 2 = 0.619 +- 0.271 (in-sample avg dev_std = 0.602)
NEC for r=1.0 all KL = 0.627 +- 0.271 (in-sample avg dev_std = 0.602)
NEC for r=1.0 all L1 = 0.559 +- 0.213 (in-sample avg dev_std = 0.602)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.438
Model XAI F1 of binarized graphs for r=0.3 =  0.16682499999999997
Model XAI WIoU of binarized graphs for r=0.3 =  0.24966875000000002
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.357
NEC for r=0.3 class 0 = 0.526 +- 0.381 (in-sample avg dev_std = 0.382)
NEC for r=0.3 class 1 = 0.423 +- 0.381 (in-sample avg dev_std = 0.382)
NEC for r=0.3 class 2 = 0.532 +- 0.381 (in-sample avg dev_std = 0.382)
NEC for r=0.3 all KL = 0.523 +- 0.381 (in-sample avg dev_std = 0.382)
NEC for r=0.3 all L1 = 0.492 +- 0.320 (in-sample avg dev_std = 0.382)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.394
Model XAI F1 of binarized graphs for r=0.6 =  0.1338175
Model XAI WIoU of binarized graphs for r=0.6 =  0.2557825
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.369
NEC for r=0.6 class 0 = 0.57 +- 0.369 (in-sample avg dev_std = 0.439)
NEC for r=0.6 class 1 = 0.513 +- 0.369 (in-sample avg dev_std = 0.439)
NEC for r=0.6 class 2 = 0.535 +- 0.369 (in-sample avg dev_std = 0.439)
NEC for r=0.6 all KL = 0.581 +- 0.369 (in-sample avg dev_std = 0.439)
NEC for r=0.6 all L1 = 0.539 +- 0.250 (in-sample avg dev_std = 0.439)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.419
Model XAI F1 of binarized graphs for r=0.9 =  0.101945
Model XAI WIoU of binarized graphs for r=0.9 =  0.25745125
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.336
NEC for r=0.9 class 0 = 0.463 +- 0.340 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 1 = 0.425 +- 0.340 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 2 = 0.359 +- 0.340 (in-sample avg dev_std = 0.429)
NEC for r=0.9 all KL = 0.421 +- 0.340 (in-sample avg dev_std = 0.429)
NEC for r=0.9 all L1 = 0.417 +- 0.235 (in-sample avg dev_std = 0.429)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.509
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.26247375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.356
NEC for r=1.0 class 0 = 0.48 +- 0.346 (in-sample avg dev_std = 0.426)
NEC for r=1.0 class 1 = 0.476 +- 0.346 (in-sample avg dev_std = 0.426)
NEC for r=1.0 class 2 = 0.349 +- 0.346 (in-sample avg dev_std = 0.426)
NEC for r=1.0 all KL = 0.479 +- 0.346 (in-sample avg dev_std = 0.426)
NEC for r=1.0 all L1 = 0.437 +- 0.252 (in-sample avg dev_std = 0.426)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 21:02:04 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:04 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:17 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:19 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:21 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:24 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:02:32 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 112...
[0m[1;37mINFO[0m: [1mCheckpoint 112: 
-----------------------------------
Train ACCURACY: 0.9028
Train Loss: 0.3784
ID Validation ACCURACY: 0.9050
ID Validation Loss: 0.3693
ID Test ACCURACY: 0.9047
ID Test Loss: 0.3724
OOD Validation ACCURACY: 0.8107
OOD Validation Loss: 0.5547
OOD Test ACCURACY: 0.4367
OOD Test Loss: 3.7916

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 184...
[0m[1;37mINFO[0m: [1mCheckpoint 184: 
-----------------------------------
Train ACCURACY: 0.8753
Train Loss: 0.4256
ID Validation ACCURACY: 0.8767
ID Validation Loss: 0.4180
ID Test ACCURACY: 0.8850
ID Test Loss: 0.4110
OOD Validation ACCURACY: 0.8257
OOD Validation Loss: 0.5473
OOD Test ACCURACY: 0.6033
OOD Test Loss: 1.3601

[0m[1;37mINFO[0m: [1mChartInfo 0.9047 0.4367 0.8850 0.6033 0.8767 0.8257[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.312
WIoU for r=0.3 = 0.237
F1 for r=0.6 = 0.403
WIoU for r=0.6 = 0.299
F1 for r=0.9 = 0.492
WIoU for r=0.9 = 0.383
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.386
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.301
WIoU for r=0.3 = 0.279
F1 for r=0.6 = 0.246
WIoU for r=0.6 = 0.243
F1 for r=0.9 = 0.223
WIoU for r=0.9 = 0.231
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.235
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.187
WIoU for r=0.3 = 0.261
F1 for r=0.6 = 0.139
WIoU for r=0.6 = 0.247
F1 for r=0.9 = 0.113
WIoU for r=0.9 = 0.239
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.239


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.309
Model XAI F1 of binarized graphs for r=0.3 =  0.31164250000000004
Model XAI WIoU of binarized graphs for r=0.3 =  0.23715000000000003
len(reference) = 793
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.333
SUFF++ for r=0.3 class 0 = 0.734 +- 0.146 (in-sample avg dev_std = 0.312)
SUFF++ for r=0.3 class 1 = 0.763 +- 0.146 (in-sample avg dev_std = 0.312)
SUFF++ for r=0.3 class 2 = 0.782 +- 0.146 (in-sample avg dev_std = 0.312)
SUFF++ for r=0.3 all KL = 0.867 +- 0.146 (in-sample avg dev_std = 0.312)
SUFF++ for r=0.3 all L1 = 0.759 +- 0.141 (in-sample avg dev_std = 0.312)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.386
Model XAI F1 of binarized graphs for r=0.6 =  0.4027225
Model XAI WIoU of binarized graphs for r=0.6 =  0.29864125
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.393
SUFF++ for r=0.6 class 0 = 0.552 +- 0.260 (in-sample avg dev_std = 0.518)
SUFF++ for r=0.6 class 1 = 0.632 +- 0.260 (in-sample avg dev_std = 0.518)
SUFF++ for r=0.6 class 2 = 0.575 +- 0.260 (in-sample avg dev_std = 0.518)
SUFF++ for r=0.6 all KL = 0.632 +- 0.260 (in-sample avg dev_std = 0.518)
SUFF++ for r=0.6 all L1 = 0.586 +- 0.196 (in-sample avg dev_std = 0.518)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.715
Model XAI F1 of binarized graphs for r=0.9 =  0.49176499999999995
Model XAI WIoU of binarized graphs for r=0.9 =  0.38325250000000005
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.625
SUFF++ for r=0.9 class 0 = 0.568 +- 0.296 (in-sample avg dev_std = 0.477)
SUFF++ for r=0.9 class 1 = 0.789 +- 0.296 (in-sample avg dev_std = 0.477)
SUFF++ for r=0.9 class 2 = 0.615 +- 0.296 (in-sample avg dev_std = 0.477)
SUFF++ for r=0.9 all KL = 0.667 +- 0.296 (in-sample avg dev_std = 0.477)
SUFF++ for r=0.9 all L1 = 0.655 +- 0.266 (in-sample avg dev_std = 0.477)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.504
Model XAI F1 of binarized graphs for r=0.3 =  0.30082125
Model XAI WIoU of binarized graphs for r=0.3 =  0.2791075
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.452
SUFF++ for r=0.3 class 0 = 0.709 +- 0.248 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 class 1 = 0.843 +- 0.248 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 class 2 = 0.709 +- 0.248 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 all KL = 0.784 +- 0.248 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 all L1 = 0.754 +- 0.196 (in-sample avg dev_std = 0.441)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.551
Model XAI F1 of binarized graphs for r=0.6 =  0.24631875
Model XAI WIoU of binarized graphs for r=0.6 =  0.24250875
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.497
SUFF++ for r=0.6 class 0 = 0.617 +- 0.260 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.6 class 1 = 0.798 +- 0.260 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.6 class 2 = 0.62 +- 0.260 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.6 all KL = 0.666 +- 0.260 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.6 all L1 = 0.679 +- 0.221 (in-sample avg dev_std = 0.498)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.618
Model XAI F1 of binarized graphs for r=0.9 =  0.22255875
Model XAI WIoU of binarized graphs for r=0.9 =  0.2309975
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.61
SUFF++ for r=0.9 class 0 = 0.646 +- 0.276 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.9 class 1 = 0.762 +- 0.276 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.9 class 2 = 0.619 +- 0.276 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.9 all KL = 0.722 +- 0.276 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.9 all L1 = 0.677 +- 0.242 (in-sample avg dev_std = 0.420)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.504
Model XAI F1 of binarized graphs for r=0.3 =  0.18709125000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.26083625
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.446
SUFF++ for r=0.3 class 0 = 0.574 +- 0.285 (in-sample avg dev_std = 0.594)
SUFF++ for r=0.3 class 1 = 0.672 +- 0.285 (in-sample avg dev_std = 0.594)
SUFF++ for r=0.3 class 2 = 0.608 +- 0.285 (in-sample avg dev_std = 0.594)
SUFF++ for r=0.3 all KL = 0.585 +- 0.285 (in-sample avg dev_std = 0.594)
SUFF++ for r=0.3 all L1 = 0.618 +- 0.174 (in-sample avg dev_std = 0.594)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.447
Model XAI F1 of binarized graphs for r=0.6 =  0.13887
Model XAI WIoU of binarized graphs for r=0.6 =  0.24737749999999997
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.447
SUFF++ for r=0.6 class 0 = 0.716 +- 0.222 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.6 class 1 = 0.819 +- 0.222 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.6 class 2 = 0.751 +- 0.222 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.6 all KL = 0.803 +- 0.222 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.6 all L1 = 0.762 +- 0.227 (in-sample avg dev_std = 0.401)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.391
Model XAI F1 of binarized graphs for r=0.9 =  0.1129725
Model XAI WIoU of binarized graphs for r=0.9 =  0.23908875000000002
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.404
SUFF++ for r=0.9 class 0 = 0.887 +- 0.163 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.9 class 1 = 0.89 +- 0.163 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.9 class 2 = 0.898 +- 0.163 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.9 all KL = 0.91 +- 0.163 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.9 all L1 = 0.892 +- 0.128 (in-sample avg dev_std = 0.194)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.306
Model XAI F1 of binarized graphs for r=0.3 =  0.31164250000000004
Model XAI WIoU of binarized graphs for r=0.3 =  0.23715000000000003
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.289
NEC for r=0.3 class 0 = 0.251 +- 0.170 (in-sample avg dev_std = 0.200)
NEC for r=0.3 class 1 = 0.221 +- 0.170 (in-sample avg dev_std = 0.200)
NEC for r=0.3 class 2 = 0.2 +- 0.170 (in-sample avg dev_std = 0.200)
NEC for r=0.3 all KL = 0.112 +- 0.170 (in-sample avg dev_std = 0.200)
NEC for r=0.3 all L1 = 0.224 +- 0.182 (in-sample avg dev_std = 0.200)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.386
Model XAI F1 of binarized graphs for r=0.6 =  0.4027225
Model XAI WIoU of binarized graphs for r=0.6 =  0.29864125
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.377
NEC for r=0.6 class 0 = 0.448 +- 0.295 (in-sample avg dev_std = 0.474)
NEC for r=0.6 class 1 = 0.389 +- 0.295 (in-sample avg dev_std = 0.474)
NEC for r=0.6 class 2 = 0.443 +- 0.295 (in-sample avg dev_std = 0.474)
NEC for r=0.6 all KL = 0.377 +- 0.295 (in-sample avg dev_std = 0.474)
NEC for r=0.6 all L1 = 0.427 +- 0.222 (in-sample avg dev_std = 0.474)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.714
Model XAI F1 of binarized graphs for r=0.9 =  0.49176499999999995
Model XAI WIoU of binarized graphs for r=0.9 =  0.38325250000000005
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.488
NEC for r=0.9 class 0 = 0.619 +- 0.312 (in-sample avg dev_std = 0.544)
NEC for r=0.9 class 1 = 0.275 +- 0.312 (in-sample avg dev_std = 0.544)
NEC for r=0.9 class 2 = 0.598 +- 0.312 (in-sample avg dev_std = 0.544)
NEC for r=0.9 all KL = 0.504 +- 0.312 (in-sample avg dev_std = 0.544)
NEC for r=0.9 all L1 = 0.501 +- 0.250 (in-sample avg dev_std = 0.544)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.904
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.38576499999999997
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.544
NEC for r=1.0 class 0 = 0.584 +- 0.324 (in-sample avg dev_std = 0.606)
NEC for r=1.0 class 1 = 0.218 +- 0.324 (in-sample avg dev_std = 0.606)
NEC for r=1.0 class 2 = 0.594 +- 0.324 (in-sample avg dev_std = 0.606)
NEC for r=1.0 all KL = 0.515 +- 0.324 (in-sample avg dev_std = 0.606)
NEC for r=1.0 all L1 = 0.469 +- 0.251 (in-sample avg dev_std = 0.606)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.504
Model XAI F1 of binarized graphs for r=0.3 =  0.30082125
Model XAI WIoU of binarized graphs for r=0.3 =  0.2791075
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.347
NEC for r=0.3 class 0 = 0.335 +- 0.330 (in-sample avg dev_std = 0.202)
NEC for r=0.3 class 1 = 0.135 +- 0.330 (in-sample avg dev_std = 0.202)
NEC for r=0.3 class 2 = 0.324 +- 0.330 (in-sample avg dev_std = 0.202)
NEC for r=0.3 all KL = 0.215 +- 0.330 (in-sample avg dev_std = 0.202)
NEC for r=0.3 all L1 = 0.264 +- 0.280 (in-sample avg dev_std = 0.202)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.551
Model XAI F1 of binarized graphs for r=0.6 =  0.24631875
Model XAI WIoU of binarized graphs for r=0.6 =  0.24250875
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.423
NEC for r=0.6 class 0 = 0.446 +- 0.335 (in-sample avg dev_std = 0.422)
NEC for r=0.6 class 1 = 0.177 +- 0.335 (in-sample avg dev_std = 0.422)
NEC for r=0.6 class 2 = 0.408 +- 0.335 (in-sample avg dev_std = 0.422)
NEC for r=0.6 all KL = 0.349 +- 0.335 (in-sample avg dev_std = 0.422)
NEC for r=0.6 all L1 = 0.343 +- 0.289 (in-sample avg dev_std = 0.422)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.618
Model XAI F1 of binarized graphs for r=0.9 =  0.22255875
Model XAI WIoU of binarized graphs for r=0.9 =  0.2309975
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.464
NEC for r=0.9 class 0 = 0.597 +- 0.320 (in-sample avg dev_std = 0.507)
NEC for r=0.9 class 1 = 0.289 +- 0.320 (in-sample avg dev_std = 0.507)
NEC for r=0.9 class 2 = 0.603 +- 0.320 (in-sample avg dev_std = 0.507)
NEC for r=0.9 all KL = 0.483 +- 0.320 (in-sample avg dev_std = 0.507)
NEC for r=0.9 all L1 = 0.495 +- 0.253 (in-sample avg dev_std = 0.507)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.832
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.235275
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.522
NEC for r=1.0 class 0 = 0.63 +- 0.314 (in-sample avg dev_std = 0.502)
NEC for r=1.0 class 1 = 0.251 +- 0.314 (in-sample avg dev_std = 0.502)
NEC for r=1.0 class 2 = 0.535 +- 0.314 (in-sample avg dev_std = 0.502)
NEC for r=1.0 all KL = 0.462 +- 0.314 (in-sample avg dev_std = 0.502)
NEC for r=1.0 all L1 = 0.472 +- 0.248 (in-sample avg dev_std = 0.502)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.504
Model XAI F1 of binarized graphs for r=0.3 =  0.18709125000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.26083625
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.332
NEC for r=0.3 class 0 = 0.374 +- 0.361 (in-sample avg dev_std = 0.216)
NEC for r=0.3 class 1 = 0.227 +- 0.361 (in-sample avg dev_std = 0.216)
NEC for r=0.3 class 2 = 0.455 +- 0.361 (in-sample avg dev_std = 0.216)
NEC for r=0.3 all KL = 0.312 +- 0.361 (in-sample avg dev_std = 0.216)
NEC for r=0.3 all L1 = 0.349 +- 0.305 (in-sample avg dev_std = 0.216)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.447
Model XAI F1 of binarized graphs for r=0.6 =  0.13887
Model XAI WIoU of binarized graphs for r=0.6 =  0.24737749999999997
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.367
NEC for r=0.6 class 0 = 0.282 +- 0.269 (in-sample avg dev_std = 0.370)
NEC for r=0.6 class 1 = 0.19 +- 0.269 (in-sample avg dev_std = 0.370)
NEC for r=0.6 class 2 = 0.344 +- 0.269 (in-sample avg dev_std = 0.370)
NEC for r=0.6 all KL = 0.228 +- 0.269 (in-sample avg dev_std = 0.370)
NEC for r=0.6 all L1 = 0.27 +- 0.253 (in-sample avg dev_std = 0.370)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.391
Model XAI F1 of binarized graphs for r=0.9 =  0.1129725
Model XAI WIoU of binarized graphs for r=0.9 =  0.23908875000000002
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.367
NEC for r=0.9 class 0 = 0.202 +- 0.265 (in-sample avg dev_std = 0.376)
NEC for r=0.9 class 1 = 0.216 +- 0.265 (in-sample avg dev_std = 0.376)
NEC for r=0.9 class 2 = 0.27 +- 0.265 (in-sample avg dev_std = 0.376)
NEC for r=0.9 all KL = 0.252 +- 0.265 (in-sample avg dev_std = 0.376)
NEC for r=0.9 all L1 = 0.229 +- 0.191 (in-sample avg dev_std = 0.376)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.414
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.23854
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.379
NEC for r=1.0 class 0 = 0.31 +- 0.307 (in-sample avg dev_std = 0.395)
NEC for r=1.0 class 1 = 0.352 +- 0.307 (in-sample avg dev_std = 0.395)
NEC for r=1.0 class 2 = 0.316 +- 0.307 (in-sample avg dev_std = 0.395)
NEC for r=1.0 all KL = 0.326 +- 0.307 (in-sample avg dev_std = 0.395)
NEC for r=1.0 all L1 = 0.326 +- 0.246 (in-sample avg dev_std = 0.395)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.906, 0.81, 0.866, 1.0], 'all_L1': [0.788, 0.77, 0.811, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.918, 0.751, 0.856, 1.0], 'all_L1': [0.808, 0.721, 0.831, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.899, 0.787, 0.898, 1.0], 'all_L1': [0.874, 0.779, 0.878, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.696, 0.524, 0.661, 1.0], 'all_L1': [0.7, 0.517, 0.68, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.867, 0.632, 0.667, 1.0], 'all_L1': [0.759, 0.586, 0.655, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.112, 0.336, 0.51, 0.486], 'all_L1': [0.232, 0.364, 0.511, 0.478]}), defaultdict(<class 'list'>, {'all_KL': [0.089, 0.382, 0.542, 0.536], 'all_L1': [0.194, 0.405, 0.505, 0.499]}), defaultdict(<class 'list'>, {'all_KL': [0.106, 0.45, 0.56, 0.557], 'all_L1': [0.148, 0.437, 0.501, 0.477]}), defaultdict(<class 'list'>, {'all_KL': [0.354, 0.521, 0.563, 0.583], 'all_L1': [0.348, 0.517, 0.498, 0.497]}), defaultdict(<class 'list'>, {'all_KL': [0.112, 0.377, 0.504, 0.515], 'all_L1': [0.224, 0.427, 0.501, 0.469]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.937, 0.761, 0.793, 1.0], 'all_L1': [0.879, 0.738, 0.745, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.862, 0.759, 0.76, 1.0], 'all_L1': [0.811, 0.732, 0.698, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.842, 0.822, 0.79, 1.0], 'all_L1': [0.834, 0.757, 0.797, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.616, 0.64, 0.619, 1.0], 'all_L1': [0.65, 0.591, 0.609, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.784, 0.666, 0.722, 1.0], 'all_L1': [0.754, 0.679, 0.677, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.153, 0.221, 0.393, 0.359], 'all_L1': [0.204, 0.268, 0.418, 0.367]}), defaultdict(<class 'list'>, {'all_KL': [0.279, 0.466, 0.491, 0.441], 'all_L1': [0.334, 0.448, 0.492, 0.431]}), defaultdict(<class 'list'>, {'all_KL': [0.32, 0.448, 0.425, 0.492], 'all_L1': [0.311, 0.466, 0.416, 0.477]}), defaultdict(<class 'list'>, {'all_KL': [0.453, 0.488, 0.62, 0.627], 'all_L1': [0.424, 0.481, 0.562, 0.559]}), defaultdict(<class 'list'>, {'all_KL': [0.215, 0.349, 0.483, 0.462], 'all_L1': [0.264, 0.343, 0.495, 0.472]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.899, 0.523, 0.579, 1.0], 'all_L1': [0.842, 0.608, 0.731, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.547, 0.655, 0.814, 1.0], 'all_L1': [0.578, 0.694, 0.846, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.81, 0.722, 0.834, 1.0], 'all_L1': [0.733, 0.74, 0.829, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.473, 0.495, 0.776, 1.0], 'all_L1': [0.552, 0.536, 0.734, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.585, 0.803, 0.91, 1.0], 'all_L1': [0.618, 0.762, 0.892, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.142, 0.38, 0.357, 0.411], 'all_L1': [0.186, 0.339, 0.248, 0.263]}), defaultdict(<class 'list'>, {'all_KL': [0.388, 0.245, 0.197, 0.173], 'all_L1': [0.414, 0.239, 0.16, 0.135]}), defaultdict(<class 'list'>, {'all_KL': [0.373, 0.269, 0.206, 0.328], 'all_L1': [0.4, 0.272, 0.247, 0.335]}), defaultdict(<class 'list'>, {'all_KL': [0.523, 0.581, 0.421, 0.479], 'all_L1': [0.492, 0.539, 0.417, 0.437]}), defaultdict(<class 'list'>, {'all_KL': [0.312, 0.228, 0.252, 0.326], 'all_L1': [0.349, 0.27, 0.229, 0.326]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.786 +- 0.057, 0.675 +- 0.105, 0.771 +- 0.088, 1.000 +- 0.000
suff++ class all_KL  =  0.857 +- 0.082, 0.701 +- 0.108, 0.790 +- 0.104, 1.000 +- 0.000
suff++_acc_int  =  0.354 +- 0.024, 0.500 +- 0.076, 0.731 +- 0.060
nec class all_L1  =  0.229 +- 0.066, 0.430 +- 0.050, 0.503 +- 0.004, 0.484 +- 0.012
nec class all_KL  =  0.155 +- 0.100, 0.413 +- 0.065, 0.536 +- 0.025, 0.535 +- 0.033
nec_acc_int  =  0.324 +- 0.018, 0.401 +- 0.015, 0.494 +- 0.015, 0.539 +- 0.010

Eval split val
suff++ class all_L1  =  0.786 +- 0.079, 0.699 +- 0.060, 0.705 +- 0.063, 1.000 +- 0.000
suff++ class all_KL  =  0.808 +- 0.108, 0.730 +- 0.067, 0.737 +- 0.064, 1.000 +- 0.000
suff++_acc_int  =  0.500 +- 0.051, 0.565 +- 0.077, 0.653 +- 0.038
nec class all_L1  =  0.307 +- 0.073, 0.401 +- 0.082, 0.477 +- 0.055, 0.461 +- 0.063
nec class all_KL  =  0.284 +- 0.102, 0.394 +- 0.099, 0.482 +- 0.078, 0.476 +- 0.087
nec_acc_int  =  0.353 +- 0.013, 0.427 +- 0.024, 0.493 +- 0.024, 0.523 +- 0.011

Eval split test
suff++ class all_L1  =  0.665 +- 0.108, 0.668 +- 0.085, 0.806 +- 0.064, 1.000 +- 0.000
suff++ class all_KL  =  0.663 +- 0.163, 0.640 +- 0.117, 0.783 +- 0.111, 1.000 +- 0.000
suff++_acc_int  =  0.500 +- 0.087, 0.455 +- 0.053, 0.392 +- 0.015
nec class all_L1  =  0.368 +- 0.102, 0.332 +- 0.109, 0.260 +- 0.085, 0.299 +- 0.099
nec class all_KL  =  0.348 +- 0.124, 0.341 +- 0.131, 0.287 +- 0.088, 0.343 +- 0.103
nec_acc_int  =  0.350 +- 0.009, 0.362 +- 0.006, 0.351 +- 0.010, 0.357 +- 0.012


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.507 +- 0.011, 0.552 +- 0.037, 0.637 +- 0.045, 0.742 +- 0.006
Faith. Armon (L1)= 		  =  0.347 +- 0.069, 0.517 +- 0.024, 0.607 +- 0.030, 0.652 +- 0.011
Faith. GMean (L1)= 	  =  0.418 +- 0.044, 0.534 +- 0.028, 0.622 +- 0.037, 0.696 +- 0.009
Faith. Aritm (KL)= 		  =  0.506 +- 0.011, 0.557 +- 0.040, 0.663 +- 0.055, 0.768 +- 0.017
Faith. Armon (KL)= 		  =  0.244 +- 0.114, 0.510 +- 0.037, 0.636 +- 0.041, 0.697 +- 0.028
Faith. GMean (KL)= 	  =  0.344 +- 0.077, 0.533 +- 0.035, 0.649 +- 0.047, 0.731 +- 0.023

Eval split val
Faith. Aritm (L1)= 		  =  0.547 +- 0.024, 0.550 +- 0.043, 0.591 +- 0.009, 0.731 +- 0.031
Faith. Armon (L1)= 		  =  0.432 +- 0.064, 0.502 +- 0.068, 0.563 +- 0.019, 0.629 +- 0.059
Faith. GMean (L1)= 	  =  0.485 +- 0.042, 0.525 +- 0.055, 0.577 +- 0.010, 0.678 +- 0.046
Faith. Aritm (KL)= 		  =  0.546 +- 0.029, 0.562 +- 0.056, 0.610 +- 0.012, 0.738 +- 0.044
Faith. Armon (KL)= 		  =  0.402 +- 0.092, 0.502 +- 0.091, 0.575 +- 0.033, 0.641 +- 0.078
Faith. GMean (KL)= 	  =  0.465 +- 0.060, 0.531 +- 0.074, 0.592 +- 0.022, 0.687 +- 0.062

Eval split test
Faith. Aritm (L1)= 		  =  0.516 +- 0.028, 0.500 +- 0.027, 0.533 +- 0.033, 0.650 +- 0.050
Faith. Armon (L1)= 		  =  0.454 +- 0.079, 0.425 +- 0.062, 0.383 +- 0.084, 0.451 +- 0.123
Faith. GMean (L1)= 	  =  0.482 +- 0.051, 0.460 +- 0.042, 0.450 +- 0.060, 0.538 +- 0.098
Faith. Aritm (KL)= 		  =  0.505 +- 0.050, 0.490 +- 0.035, 0.535 +- 0.048, 0.672 +- 0.051
Faith. Armon (KL)= 		  =  0.423 +- 0.096, 0.416 +- 0.067, 0.406 +- 0.083, 0.502 +- 0.119
Faith. GMean (KL)= 	  =  0.458 +- 0.065, 0.450 +- 0.046, 0.464 +- 0.061, 0.579 +- 0.093
Computed for split load_split = id



Completed in  0:32:51.986878  for LECIvGIN GOODMotif/size



DONE LECI GOODMotif/size

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 21:08:53 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/22/2024 09:08:53 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 09:09:05 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 09:09:07 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 09:09:08 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 09:09:12 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 09:09:19 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 09:09:19 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 09:09:19 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/22/2024 09:09:19 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 09:09:19 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:09:19 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/22/2024 09:09:19 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:09:19 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/22/2024 09:09:19 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 48...
[0m[1;37mINFO[0m: [1mCheckpoint 48: 
-----------------------------------
Train ACCURACY: 0.8899
Train Loss: 0.5257
ID Validation ACCURACY: 0.8960
ID Validation Loss: 0.4847
ID Test ACCURACY: 0.8937
ID Test Loss: 0.5229
OOD Validation ACCURACY: 0.6193
OOD Validation Loss: 1.1712
OOD Test ACCURACY: 0.4250
OOD Test Loss: 6.2644

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 79...
[0m[1;37mINFO[0m: [1mCheckpoint 79: 
-----------------------------------
Train ACCURACY: 0.8699
Train Loss: 0.5291
ID Validation ACCURACY: 0.8790
ID Validation Loss: 0.4662
ID Test ACCURACY: 0.8723
ID Test Loss: 0.5479
OOD Validation ACCURACY: 0.7500
OOD Validation Loss: 0.6795
OOD Test ACCURACY: 0.4680
OOD Test Loss: 3.3662

[0m[1;37mINFO[0m: [1mChartInfo 0.8937 0.4250 0.8723 0.4680 0.8790 0.7500[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.8 = 0.516
WIoU for r=0.8 = 0.515
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.8 = 0.264
WIoU for r=0.8 = 0.368
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.8 = 0.122
WIoU for r=0.8 = 0.283


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.904
Model XAI F1 of binarized graphs for r=0.8 =  0.516285
Model XAI WIoU of binarized graphs for r=0.8 =  0.5146087500000001
len(reference) = 800
Effective ratio: 0.813 +- 0.011
Model Accuracy over intervened graphs for r=0.8 =  0.71
SUFF++ for r=0.8 class 0 = 0.556 +- 0.369 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.8 class 1 = 0.706 +- 0.369 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.8 class 2 = 0.784 +- 0.369 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.8 all KL = 0.618 +- 0.369 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.8 all L1 = 0.681 +- 0.277 (in-sample avg dev_std = 0.500)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.64
Model XAI F1 of binarized graphs for r=0.8 =  0.26402625
Model XAI WIoU of binarized graphs for r=0.8 =  0.3675925
len(reference) = 800
Effective ratio: 0.806 +- 0.005
Model Accuracy over intervened graphs for r=0.8 =  0.589
SUFF++ for r=0.8 class 0 = 0.519 +- 0.290 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.8 class 1 = 0.603 +- 0.290 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.8 class 2 = 0.652 +- 0.290 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.8 all KL = 0.597 +- 0.290 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.8 all L1 = 0.59 +- 0.198 (in-sample avg dev_std = 0.501)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.43
Model XAI F1 of binarized graphs for r=0.8 =  0.12237124999999999
Model XAI WIoU of binarized graphs for r=0.8 =  0.28337375
len(reference) = 800
Effective ratio: 0.802 +- 0.002
Model Accuracy over intervened graphs for r=0.8 =  0.393
SUFF++ for r=0.8 class 0 = 0.495 +- 0.332 (in-sample avg dev_std = 0.654)
SUFF++ for r=0.8 class 1 = 0.442 +- 0.332 (in-sample avg dev_std = 0.654)
SUFF++ for r=0.8 class 2 = 0.511 +- 0.332 (in-sample avg dev_std = 0.654)
SUFF++ for r=0.8 all KL = 0.383 +- 0.332 (in-sample avg dev_std = 0.654)
SUFF++ for r=0.8 all L1 = 0.482 +- 0.131 (in-sample avg dev_std = 0.654)


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.904
Model XAI F1 of binarized graphs for r=0.8 =  0.516285
Model XAI WIoU of binarized graphs for r=0.8 =  0.5146087500000001
len(reference) = 800
Effective ratio: 0.813 +- 0.011
Model Accuracy over intervened graphs for r=0.8 =  0.443
NEC for r=0.8 class 0 = 0.59 +- 0.255 (in-sample avg dev_std = 0.672)
NEC for r=0.8 class 1 = 0.612 +- 0.255 (in-sample avg dev_std = 0.672)
NEC for r=0.8 class 2 = 0.603 +- 0.255 (in-sample avg dev_std = 0.672)
NEC for r=0.8 all KL = 0.755 +- 0.255 (in-sample avg dev_std = 0.672)
NEC for r=0.8 all L1 = 0.601 +- 0.177 (in-sample avg dev_std = 0.672)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.64
Model XAI F1 of binarized graphs for r=0.8 =  0.26402625
Model XAI WIoU of binarized graphs for r=0.8 =  0.3675925
len(reference) = 800
Effective ratio: 0.806 +- 0.005
Model Accuracy over intervened graphs for r=0.8 =  0.426
NEC for r=0.8 class 0 = 0.399 +- 0.313 (in-sample avg dev_std = 0.379)
NEC for r=0.8 class 1 = 0.445 +- 0.313 (in-sample avg dev_std = 0.379)
NEC for r=0.8 class 2 = 0.472 +- 0.313 (in-sample avg dev_std = 0.379)
NEC for r=0.8 all KL = 0.397 +- 0.313 (in-sample avg dev_std = 0.379)
NEC for r=0.8 all L1 = 0.438 +- 0.245 (in-sample avg dev_std = 0.379)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.43
Model XAI F1 of binarized graphs for r=0.8 =  0.12237124999999999
Model XAI WIoU of binarized graphs for r=0.8 =  0.28337375
len(reference) = 800
Effective ratio: 0.802 +- 0.002
Model Accuracy over intervened graphs for r=0.8 =  0.387
NEC for r=0.8 class 0 = 0.36 +- 0.310 (in-sample avg dev_std = 0.248)
NEC for r=0.8 class 1 = 0.396 +- 0.310 (in-sample avg dev_std = 0.248)
NEC for r=0.8 class 2 = 0.369 +- 0.310 (in-sample avg dev_std = 0.248)
NEC for r=0.8 all KL = 0.339 +- 0.310 (in-sample avg dev_std = 0.248)
NEC for r=0.8 all L1 = 0.375 +- 0.265 (in-sample avg dev_std = 0.248)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 21:11:09 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/22/2024 09:11:09 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 09:11:20 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 09:11:22 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 09:11:24 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 09:11:27 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 09:11:33 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 09:11:33 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 09:11:33 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/22/2024 09:11:33 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 09:11:33 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:11:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:11:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:11:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:11:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:11:33 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/22/2024 09:11:33 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:11:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:11:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:11:33 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/22/2024 09:11:33 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 44...
[0m[1;37mINFO[0m: [1mCheckpoint 44: 
-----------------------------------
Train ACCURACY: 0.8903
Train Loss: 0.5320
ID Validation ACCURACY: 0.8943
ID Validation Loss: 0.4871
ID Test ACCURACY: 0.8910
ID Test Loss: 0.5314
OOD Validation ACCURACY: 0.6970
OOD Validation Loss: 0.9031
OOD Test ACCURACY: 0.5007
OOD Test Loss: 6.0511

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 11...
[0m[1;37mINFO[0m: [1mCheckpoint 11: 
-----------------------------------
Train ACCURACY: 0.8831
Train Loss: 0.5175
ID Validation ACCURACY: 0.8833
ID Validation Loss: 0.4767
ID Test ACCURACY: 0.8860
ID Test Loss: 0.5135
OOD Validation ACCURACY: 0.7723
OOD Validation Loss: 0.6911
OOD Test ACCURACY: 0.4477
OOD Test Loss: 2.0349

[0m[1;37mINFO[0m: [1mChartInfo 0.8910 0.5007 0.8860 0.4477 0.8833 0.7723[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.8 = 0.501
WIoU for r=0.8 = 0.494
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.8 = 0.260
WIoU for r=0.8 = 0.364
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.8 = 0.122
WIoU for r=0.8 = 0.280


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.9
Model XAI F1 of binarized graphs for r=0.8 =  0.5014237500000001
Model XAI WIoU of binarized graphs for r=0.8 =  0.49398
len(reference) = 800
Effective ratio: 0.813 +- 0.011
Model Accuracy over intervened graphs for r=0.8 =  0.675
SUFF++ for r=0.8 class 0 = 0.514 +- 0.380 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.8 class 1 = 0.679 +- 0.380 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.8 class 2 = 0.77 +- 0.380 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.8 all KL = 0.581 +- 0.380 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.8 all L1 = 0.653 +- 0.289 (in-sample avg dev_std = 0.471)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.712
Model XAI F1 of binarized graphs for r=0.8 =  0.25975750000000003
Model XAI WIoU of binarized graphs for r=0.8 =  0.36365250000000005
len(reference) = 800
Effective ratio: 0.806 +- 0.005
Model Accuracy over intervened graphs for r=0.8 =  0.623
SUFF++ for r=0.8 class 0 = 0.535 +- 0.276 (in-sample avg dev_std = 0.473)
SUFF++ for r=0.8 class 1 = 0.564 +- 0.276 (in-sample avg dev_std = 0.473)
SUFF++ for r=0.8 class 2 = 0.708 +- 0.276 (in-sample avg dev_std = 0.473)
SUFF++ for r=0.8 all KL = 0.638 +- 0.276 (in-sample avg dev_std = 0.473)
SUFF++ for r=0.8 all L1 = 0.601 +- 0.199 (in-sample avg dev_std = 0.473)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.482
Model XAI F1 of binarized graphs for r=0.8 =  0.12161625000000001
Model XAI WIoU of binarized graphs for r=0.8 =  0.2801425
len(reference) = 800
Effective ratio: 0.802 +- 0.002
Model Accuracy over intervened graphs for r=0.8 =  0.425
SUFF++ for r=0.8 class 0 = 0.582 +- 0.315 (in-sample avg dev_std = 0.442)
SUFF++ for r=0.8 class 1 = 0.551 +- 0.315 (in-sample avg dev_std = 0.442)
SUFF++ for r=0.8 class 2 = 0.579 +- 0.315 (in-sample avg dev_std = 0.442)
SUFF++ for r=0.8 all KL = 0.528 +- 0.315 (in-sample avg dev_std = 0.442)
SUFF++ for r=0.8 all L1 = 0.57 +- 0.162 (in-sample avg dev_std = 0.442)


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.9
Model XAI F1 of binarized graphs for r=0.8 =  0.5014237500000001
Model XAI WIoU of binarized graphs for r=0.8 =  0.49398
len(reference) = 800
Effective ratio: 0.813 +- 0.011
Model Accuracy over intervened graphs for r=0.8 =  0.462
NEC for r=0.8 class 0 = 0.579 +- 0.254 (in-sample avg dev_std = 0.685)
NEC for r=0.8 class 1 = 0.596 +- 0.254 (in-sample avg dev_std = 0.685)
NEC for r=0.8 class 2 = 0.589 +- 0.254 (in-sample avg dev_std = 0.685)
NEC for r=0.8 all KL = 0.75 +- 0.254 (in-sample avg dev_std = 0.685)
NEC for r=0.8 all L1 = 0.588 +- 0.175 (in-sample avg dev_std = 0.685)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.712
Model XAI F1 of binarized graphs for r=0.8 =  0.25975750000000003
Model XAI WIoU of binarized graphs for r=0.8 =  0.36365250000000005
len(reference) = 800
Effective ratio: 0.806 +- 0.005
Model Accuracy over intervened graphs for r=0.8 =  0.431
NEC for r=0.8 class 0 = 0.497 +- 0.304 (in-sample avg dev_std = 0.416)
NEC for r=0.8 class 1 = 0.455 +- 0.304 (in-sample avg dev_std = 0.416)
NEC for r=0.8 class 2 = 0.545 +- 0.304 (in-sample avg dev_std = 0.416)
NEC for r=0.8 all KL = 0.472 +- 0.304 (in-sample avg dev_std = 0.416)
NEC for r=0.8 all L1 = 0.498 +- 0.218 (in-sample avg dev_std = 0.416)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.482
Model XAI F1 of binarized graphs for r=0.8 =  0.12161625000000001
Model XAI WIoU of binarized graphs for r=0.8 =  0.2801425
len(reference) = 800
Effective ratio: 0.802 +- 0.002
Model Accuracy over intervened graphs for r=0.8 =  0.387
NEC for r=0.8 class 0 = 0.406 +- 0.318 (in-sample avg dev_std = 0.238)
NEC for r=0.8 class 1 = 0.341 +- 0.318 (in-sample avg dev_std = 0.238)
NEC for r=0.8 class 2 = 0.365 +- 0.318 (in-sample avg dev_std = 0.238)
NEC for r=0.8 all KL = 0.31 +- 0.318 (in-sample avg dev_std = 0.238)
NEC for r=0.8 all L1 = 0.371 +- 0.256 (in-sample avg dev_std = 0.238)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 21:13:22 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/22/2024 09:13:22 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 09:13:33 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 09:13:35 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 09:13:37 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 09:13:41 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 09:13:47 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 09:13:47 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 09:13:47 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/22/2024 09:13:47 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 09:13:47 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:13:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:13:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:13:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:13:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:13:47 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/22/2024 09:13:47 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:13:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:13:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:13:47 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/22/2024 09:13:47 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 64...
[0m[1;37mINFO[0m: [1mCheckpoint 64: 
-----------------------------------
Train ACCURACY: 0.8937
Train Loss: 0.5698
ID Validation ACCURACY: 0.9000
ID Validation Loss: 0.5288
ID Test ACCURACY: 0.8943
ID Test Loss: 0.5798
OOD Validation ACCURACY: 0.6730
OOD Validation Loss: 1.3851
OOD Test ACCURACY: 0.4563
OOD Test Loss: 4.4608

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 20...
[0m[1;37mINFO[0m: [1mCheckpoint 20: 
-----------------------------------
Train ACCURACY: 0.8583
Train Loss: 0.7164
ID Validation ACCURACY: 0.8650
ID Validation Loss: 0.6880
ID Test ACCURACY: 0.8517
ID Test Loss: 0.7220
OOD Validation ACCURACY: 0.7457
OOD Validation Loss: 1.4504
OOD Test ACCURACY: 0.4083
OOD Test Loss: 6.2487

[0m[1;37mINFO[0m: [1mChartInfo 0.8943 0.4563 0.8517 0.4083 0.8650 0.7457[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.8 = 0.516
WIoU for r=0.8 = 0.501
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.8 = 0.260
WIoU for r=0.8 = 0.365
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.8 = 0.121
WIoU for r=0.8 = 0.280


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.905
Model XAI F1 of binarized graphs for r=0.8 =  0.51631
Model XAI WIoU of binarized graphs for r=0.8 =  0.5010162499999999
len(reference) = 800
Effective ratio: 0.813 +- 0.011
Model Accuracy over intervened graphs for r=0.8 =  0.704
SUFF++ for r=0.8 class 0 = 0.542 +- 0.369 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.8 class 1 = 0.755 +- 0.369 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.8 class 2 = 0.816 +- 0.369 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.8 all KL = 0.637 +- 0.369 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.8 all L1 = 0.703 +- 0.291 (in-sample avg dev_std = 0.444)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.68
Model XAI F1 of binarized graphs for r=0.8 =  0.260275
Model XAI WIoU of binarized graphs for r=0.8 =  0.36496375000000003
len(reference) = 800
Effective ratio: 0.806 +- 0.005
Model Accuracy over intervened graphs for r=0.8 =  0.623
SUFF++ for r=0.8 class 0 = 0.582 +- 0.322 (in-sample avg dev_std = 0.491)
SUFF++ for r=0.8 class 1 = 0.63 +- 0.322 (in-sample avg dev_std = 0.491)
SUFF++ for r=0.8 class 2 = 0.691 +- 0.322 (in-sample avg dev_std = 0.491)
SUFF++ for r=0.8 all KL = 0.615 +- 0.322 (in-sample avg dev_std = 0.491)
SUFF++ for r=0.8 all L1 = 0.633 +- 0.216 (in-sample avg dev_std = 0.491)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.461
Model XAI F1 of binarized graphs for r=0.8 =  0.1209375
Model XAI WIoU of binarized graphs for r=0.8 =  0.280265
len(reference) = 800
Effective ratio: 0.802 +- 0.002
Model Accuracy over intervened graphs for r=0.8 =  0.432
SUFF++ for r=0.8 class 0 = 0.491 +- 0.311 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.8 class 1 = 0.48 +- 0.311 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.8 class 2 = 0.511 +- 0.311 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.8 all KL = 0.473 +- 0.311 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.8 all L1 = 0.493 +- 0.182 (in-sample avg dev_std = 0.472)


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.905
Model XAI F1 of binarized graphs for r=0.8 =  0.51631
Model XAI WIoU of binarized graphs for r=0.8 =  0.5010162499999999
len(reference) = 800
Effective ratio: 0.813 +- 0.011
Model Accuracy over intervened graphs for r=0.8 =  0.443
NEC for r=0.8 class 0 = 0.589 +- 0.239 (in-sample avg dev_std = 0.716)
NEC for r=0.8 class 1 = 0.621 +- 0.239 (in-sample avg dev_std = 0.716)
NEC for r=0.8 class 2 = 0.622 +- 0.239 (in-sample avg dev_std = 0.716)
NEC for r=0.8 all KL = 0.796 +- 0.239 (in-sample avg dev_std = 0.716)
NEC for r=0.8 all L1 = 0.611 +- 0.178 (in-sample avg dev_std = 0.716)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.68
Model XAI F1 of binarized graphs for r=0.8 =  0.260275
Model XAI WIoU of binarized graphs for r=0.8 =  0.36496375000000003
len(reference) = 800
Effective ratio: 0.806 +- 0.005
Model Accuracy over intervened graphs for r=0.8 =  0.426
NEC for r=0.8 class 0 = 0.436 +- 0.351 (in-sample avg dev_std = 0.437)
NEC for r=0.8 class 1 = 0.486 +- 0.351 (in-sample avg dev_std = 0.437)
NEC for r=0.8 class 2 = 0.489 +- 0.351 (in-sample avg dev_std = 0.437)
NEC for r=0.8 all KL = 0.477 +- 0.351 (in-sample avg dev_std = 0.437)
NEC for r=0.8 all L1 = 0.47 +- 0.272 (in-sample avg dev_std = 0.437)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.461
Model XAI F1 of binarized graphs for r=0.8 =  0.1209375
Model XAI WIoU of binarized graphs for r=0.8 =  0.280265
len(reference) = 800
Effective ratio: 0.802 +- 0.002
Model Accuracy over intervened graphs for r=0.8 =  0.385
NEC for r=0.8 class 0 = 0.484 +- 0.362 (in-sample avg dev_std = 0.266)
NEC for r=0.8 class 1 = 0.44 +- 0.362 (in-sample avg dev_std = 0.266)
NEC for r=0.8 class 2 = 0.46 +- 0.362 (in-sample avg dev_std = 0.266)
NEC for r=0.8 all KL = 0.441 +- 0.362 (in-sample avg dev_std = 0.266)
NEC for r=0.8 all L1 = 0.461 +- 0.286 (in-sample avg dev_std = 0.266)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 21:15:35 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/22/2024 09:15:35 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 09:15:46 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 09:15:48 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 09:15:50 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 09:15:53 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 09:15:59 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 09:15:59 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 09:15:59 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/22/2024 09:15:59 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 09:15:59 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:15:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:15:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:15:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:15:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:15:59 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/22/2024 09:15:59 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:15:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:15:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:15:59 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/22/2024 09:15:59 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 27...
[0m[1;37mINFO[0m: [1mCheckpoint 27: 
-----------------------------------
Train ACCURACY: 0.8753
Train Loss: 0.5158
ID Validation ACCURACY: 0.8807
ID Validation Loss: 0.4789
ID Test ACCURACY: 0.8773
ID Test Loss: 0.5165
OOD Validation ACCURACY: 0.6493
OOD Validation Loss: 1.1427
OOD Test ACCURACY: 0.4040
OOD Test Loss: 2.8675

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 51...
[0m[1;37mINFO[0m: [1mCheckpoint 51: 
-----------------------------------
Train ACCURACY: 0.8559
Train Loss: 0.5232
ID Validation ACCURACY: 0.8650
ID Validation Loss: 0.4809
ID Test ACCURACY: 0.8633
ID Test Loss: 0.5159
OOD Validation ACCURACY: 0.7123
OOD Validation Loss: 0.8312
OOD Test ACCURACY: 0.3543
OOD Test Loss: 8.7485

[0m[1;37mINFO[0m: [1mChartInfo 0.8773 0.4040 0.8633 0.3543 0.8650 0.7123[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.8 = 0.539
WIoU for r=0.8 = 0.564
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.8 = 0.280
WIoU for r=0.8 = 0.418
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.8 = 0.136
WIoU for r=0.8 = 0.483


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.87
Model XAI F1 of binarized graphs for r=0.8 =  0.53904875
Model XAI WIoU of binarized graphs for r=0.8 =  0.56376375
len(reference) = 800
Effective ratio: 0.813 +- 0.011
Model Accuracy over intervened graphs for r=0.8 =  0.738
SUFF++ for r=0.8 class 0 = 0.67 +- 0.295 (in-sample avg dev_std = 0.395)
SUFF++ for r=0.8 class 1 = 0.579 +- 0.295 (in-sample avg dev_std = 0.395)
SUFF++ for r=0.8 class 2 = 0.874 +- 0.295 (in-sample avg dev_std = 0.395)
SUFF++ for r=0.8 all KL = 0.712 +- 0.295 (in-sample avg dev_std = 0.395)
SUFF++ for r=0.8 all L1 = 0.709 +- 0.246 (in-sample avg dev_std = 0.395)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.647
Model XAI F1 of binarized graphs for r=0.8 =  0.28031
Model XAI WIoU of binarized graphs for r=0.8 =  0.41801125
len(reference) = 800
Effective ratio: 0.806 +- 0.005
Model Accuracy over intervened graphs for r=0.8 =  0.6
SUFF++ for r=0.8 class 0 = 0.57 +- 0.299 (in-sample avg dev_std = 0.464)
SUFF++ for r=0.8 class 1 = 0.561 +- 0.299 (in-sample avg dev_std = 0.464)
SUFF++ for r=0.8 class 2 = 0.655 +- 0.299 (in-sample avg dev_std = 0.464)
SUFF++ for r=0.8 all KL = 0.638 +- 0.299 (in-sample avg dev_std = 0.464)
SUFF++ for r=0.8 all L1 = 0.595 +- 0.220 (in-sample avg dev_std = 0.464)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.393
Model XAI F1 of binarized graphs for r=0.8 =  0.13596125
Model XAI WIoU of binarized graphs for r=0.8 =  0.48281875
len(reference) = 800
Effective ratio: 0.802 +- 0.002
Model Accuracy over intervened graphs for r=0.8 =  0.431
SUFF++ for r=0.8 class 0 = 0.591 +- 0.300 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.8 class 1 = 0.645 +- 0.300 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.8 class 2 = 0.597 +- 0.300 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.8 all KL = 0.552 +- 0.300 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.8 all L1 = 0.611 +- 0.149 (in-sample avg dev_std = 0.506)


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.87
Model XAI F1 of binarized graphs for r=0.8 =  0.53904875
Model XAI WIoU of binarized graphs for r=0.8 =  0.56376375
len(reference) = 800
Effective ratio: 0.813 +- 0.011
Model Accuracy over intervened graphs for r=0.8 =  0.427
NEC for r=0.8 class 0 = 0.612 +- 0.259 (in-sample avg dev_std = 0.617)
NEC for r=0.8 class 1 = 0.583 +- 0.259 (in-sample avg dev_std = 0.617)
NEC for r=0.8 class 2 = 0.609 +- 0.259 (in-sample avg dev_std = 0.617)
NEC for r=0.8 all KL = 0.698 +- 0.259 (in-sample avg dev_std = 0.617)
NEC for r=0.8 all L1 = 0.602 +- 0.162 (in-sample avg dev_std = 0.617)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.647
Model XAI F1 of binarized graphs for r=0.8 =  0.28031
Model XAI WIoU of binarized graphs for r=0.8 =  0.41801125
len(reference) = 800
Effective ratio: 0.806 +- 0.005
Model Accuracy over intervened graphs for r=0.8 =  0.402
NEC for r=0.8 class 0 = 0.426 +- 0.269 (in-sample avg dev_std = 0.389)
NEC for r=0.8 class 1 = 0.453 +- 0.269 (in-sample avg dev_std = 0.389)
NEC for r=0.8 class 2 = 0.506 +- 0.269 (in-sample avg dev_std = 0.389)
NEC for r=0.8 all KL = 0.4 +- 0.269 (in-sample avg dev_std = 0.389)
NEC for r=0.8 all L1 = 0.461 +- 0.214 (in-sample avg dev_std = 0.389)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.393
Model XAI F1 of binarized graphs for r=0.8 =  0.13596125
Model XAI WIoU of binarized graphs for r=0.8 =  0.48281875
len(reference) = 800
Effective ratio: 0.802 +- 0.002
Model Accuracy over intervened graphs for r=0.8 =  0.355
NEC for r=0.8 class 0 = 0.309 +- 0.284 (in-sample avg dev_std = 0.252)
NEC for r=0.8 class 1 = 0.318 +- 0.284 (in-sample avg dev_std = 0.252)
NEC for r=0.8 class 2 = 0.337 +- 0.284 (in-sample avg dev_std = 0.252)
NEC for r=0.8 all KL = 0.27 +- 0.284 (in-sample avg dev_std = 0.252)
NEC for r=0.8 all L1 = 0.321 +- 0.265 (in-sample avg dev_std = 0.252)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 21:17:48 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/22/2024 09:17:48 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 09:18:00 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 09:18:02 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 09:18:04 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 09:18:07 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 09:18:13 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 09:18:13 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 09:18:13 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/22/2024 09:18:13 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 09:18:13 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:18:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:18:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:18:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:18:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:18:13 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/22/2024 09:18:13 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:18:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:18:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:18:13 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/22/2024 09:18:13 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 37...
[0m[1;37mINFO[0m: [1mCheckpoint 37: 
-----------------------------------
Train ACCURACY: 0.8598
Train Loss: 0.5187
ID Validation ACCURACY: 0.8710
ID Validation Loss: 0.4867
ID Test ACCURACY: 0.8650
ID Test Loss: 0.5182
OOD Validation ACCURACY: 0.6850
OOD Validation Loss: 0.7691
OOD Test ACCURACY: 0.3613
OOD Test Loss: 3.5062

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 48...
[0m[1;37mINFO[0m: [1mCheckpoint 48: 
-----------------------------------
Train ACCURACY: 0.8180
Train Loss: 0.7026
ID Validation ACCURACY: 0.8267
ID Validation Loss: 0.6541
ID Test ACCURACY: 0.8193
ID Test Loss: 0.6900
OOD Validation ACCURACY: 0.8000
OOD Validation Loss: 0.6826
OOD Test ACCURACY: 0.4330
OOD Test Loss: 1.3960

[0m[1;37mINFO[0m: [1mChartInfo 0.8650 0.3613 0.8193 0.4330 0.8267 0.8000[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.8 = 0.560
WIoU for r=0.8 = 0.704
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.8 = 0.285
WIoU for r=0.8 = 0.591
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.8 = 0.138
WIoU for r=0.8 = 0.357


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.869
Model XAI F1 of binarized graphs for r=0.8 =  0.55982
Model XAI WIoU of binarized graphs for r=0.8 =  0.70378625
len(reference) = 800
Effective ratio: 0.813 +- 0.011
Model Accuracy over intervened graphs for r=0.8 =  0.776
SUFF++ for r=0.8 class 0 = 0.743 +- 0.233 (in-sample avg dev_std = 0.309)
SUFF++ for r=0.8 class 1 = 0.735 +- 0.233 (in-sample avg dev_std = 0.309)
SUFF++ for r=0.8 class 2 = 0.841 +- 0.233 (in-sample avg dev_std = 0.309)
SUFF++ for r=0.8 all KL = 0.826 +- 0.233 (in-sample avg dev_std = 0.309)
SUFF++ for r=0.8 all L1 = 0.773 +- 0.212 (in-sample avg dev_std = 0.309)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.692
Model XAI F1 of binarized graphs for r=0.8 =  0.28490125
Model XAI WIoU of binarized graphs for r=0.8 =  0.59116
len(reference) = 800
Effective ratio: 0.806 +- 0.005
Model Accuracy over intervened graphs for r=0.8 =  0.585
SUFF++ for r=0.8 class 0 = 0.637 +- 0.176 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.8 class 1 = 0.658 +- 0.176 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.8 class 2 = 0.672 +- 0.176 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.8 all KL = 0.781 +- 0.176 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.8 all L1 = 0.655 +- 0.168 (in-sample avg dev_std = 0.353)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.364
Model XAI F1 of binarized graphs for r=0.8 =  0.13843
Model XAI WIoU of binarized graphs for r=0.8 =  0.35728499999999996
len(reference) = 800
Effective ratio: 0.802 +- 0.002
Model Accuracy over intervened graphs for r=0.8 =  0.41
SUFF++ for r=0.8 class 0 = 0.601 +- 0.327 (in-sample avg dev_std = 0.529)
SUFF++ for r=0.8 class 1 = 0.596 +- 0.327 (in-sample avg dev_std = 0.529)
SUFF++ for r=0.8 class 2 = 0.589 +- 0.327 (in-sample avg dev_std = 0.529)
SUFF++ for r=0.8 all KL = 0.562 +- 0.327 (in-sample avg dev_std = 0.529)
SUFF++ for r=0.8 all L1 = 0.596 +- 0.181 (in-sample avg dev_std = 0.529)


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.869
Model XAI F1 of binarized graphs for r=0.8 =  0.55982
Model XAI WIoU of binarized graphs for r=0.8 =  0.70378625
len(reference) = 800
Effective ratio: 0.813 +- 0.011
Model Accuracy over intervened graphs for r=0.8 =  0.468
NEC for r=0.8 class 0 = 0.622 +- 0.328 (in-sample avg dev_std = 0.536)
NEC for r=0.8 class 1 = 0.369 +- 0.328 (in-sample avg dev_std = 0.536)
NEC for r=0.8 class 2 = 0.624 +- 0.328 (in-sample avg dev_std = 0.536)
NEC for r=0.8 all KL = 0.582 +- 0.328 (in-sample avg dev_std = 0.536)
NEC for r=0.8 all L1 = 0.541 +- 0.232 (in-sample avg dev_std = 0.536)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.692
Model XAI F1 of binarized graphs for r=0.8 =  0.28490125
Model XAI WIoU of binarized graphs for r=0.8 =  0.59116
len(reference) = 800
Effective ratio: 0.806 +- 0.005
Model Accuracy over intervened graphs for r=0.8 =  0.457
NEC for r=0.8 class 0 = 0.572 +- 0.312 (in-sample avg dev_std = 0.350)
NEC for r=0.8 class 1 = 0.421 +- 0.312 (in-sample avg dev_std = 0.350)
NEC for r=0.8 class 2 = 0.599 +- 0.312 (in-sample avg dev_std = 0.350)
NEC for r=0.8 all KL = 0.451 +- 0.312 (in-sample avg dev_std = 0.350)
NEC for r=0.8 all L1 = 0.53 +- 0.228 (in-sample avg dev_std = 0.350)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.364
Model XAI F1 of binarized graphs for r=0.8 =  0.13843
Model XAI WIoU of binarized graphs for r=0.8 =  0.35728499999999996
len(reference) = 800
Effective ratio: 0.802 +- 0.002
Model Accuracy over intervened graphs for r=0.8 =  0.352
NEC for r=0.8 class 0 = 0.453 +- 0.390 (in-sample avg dev_std = 0.211)
NEC for r=0.8 class 1 = 0.438 +- 0.390 (in-sample avg dev_std = 0.211)
NEC for r=0.8 class 2 = 0.465 +- 0.390 (in-sample avg dev_std = 0.211)
NEC for r=0.8 all KL = 0.372 +- 0.390 (in-sample avg dev_std = 0.211)
NEC for r=0.8 all L1 = 0.451 +- 0.289 (in-sample avg dev_std = 0.211)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.618], 'all_L1': [0.681]}), defaultdict(<class 'list'>, {'all_KL': [0.581], 'all_L1': [0.653]}), defaultdict(<class 'list'>, {'all_KL': [0.637], 'all_L1': [0.703]}), defaultdict(<class 'list'>, {'all_KL': [0.712], 'all_L1': [0.709]}), defaultdict(<class 'list'>, {'all_KL': [0.826], 'all_L1': [0.773]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.755], 'all_L1': [0.601]}), defaultdict(<class 'list'>, {'all_KL': [0.75], 'all_L1': [0.588]}), defaultdict(<class 'list'>, {'all_KL': [0.796], 'all_L1': [0.611]}), defaultdict(<class 'list'>, {'all_KL': [0.698], 'all_L1': [0.602]}), defaultdict(<class 'list'>, {'all_KL': [0.582], 'all_L1': [0.541]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.597], 'all_L1': [0.59]}), defaultdict(<class 'list'>, {'all_KL': [0.638], 'all_L1': [0.601]}), defaultdict(<class 'list'>, {'all_KL': [0.615], 'all_L1': [0.633]}), defaultdict(<class 'list'>, {'all_KL': [0.638], 'all_L1': [0.595]}), defaultdict(<class 'list'>, {'all_KL': [0.781], 'all_L1': [0.655]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.397], 'all_L1': [0.438]}), defaultdict(<class 'list'>, {'all_KL': [0.472], 'all_L1': [0.498]}), defaultdict(<class 'list'>, {'all_KL': [0.477], 'all_L1': [0.47]}), defaultdict(<class 'list'>, {'all_KL': [0.4], 'all_L1': [0.461]}), defaultdict(<class 'list'>, {'all_KL': [0.451], 'all_L1': [0.53]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.383], 'all_L1': [0.482]}), defaultdict(<class 'list'>, {'all_KL': [0.528], 'all_L1': [0.57]}), defaultdict(<class 'list'>, {'all_KL': [0.473], 'all_L1': [0.493]}), defaultdict(<class 'list'>, {'all_KL': [0.552], 'all_L1': [0.611]}), defaultdict(<class 'list'>, {'all_KL': [0.562], 'all_L1': [0.596]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.339], 'all_L1': [0.375]}), defaultdict(<class 'list'>, {'all_KL': [0.31], 'all_L1': [0.371]}), defaultdict(<class 'list'>, {'all_KL': [0.441], 'all_L1': [0.461]}), defaultdict(<class 'list'>, {'all_KL': [0.27], 'all_L1': [0.321]}), defaultdict(<class 'list'>, {'all_KL': [0.372], 'all_L1': [0.451]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.704 +- 0.040
suff++ class all_KL  =  0.675 +- 0.087
suff++_acc_int  =  0.721 +- 0.034
nec class all_L1  =  0.589 +- 0.025
nec class all_KL  =  0.716 +- 0.074
nec_acc_int  =  0.449 +- 0.015

Eval split val
suff++ class all_L1  =  0.615 +- 0.025
suff++ class all_KL  =  0.654 +- 0.065
suff++_acc_int  =  0.604 +- 0.016
nec class all_L1  =  0.479 +- 0.032
nec class all_KL  =  0.439 +- 0.035
nec_acc_int  =  0.428 +- 0.018

Eval split test
suff++ class all_L1  =  0.550 +- 0.053
suff++ class all_KL  =  0.500 +- 0.066
suff++_acc_int  =  0.418 +- 0.015
nec class all_L1  =  0.396 +- 0.053
nec class all_KL  =  0.346 +- 0.058
nec_acc_int  =  0.374 +- 0.016


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.646 +- 0.014
Faith. Armon (L1)= 		  =  0.640 +- 0.012
Faith. GMean (L1)= 	  =  0.643 +- 0.013
Faith. Aritm (KL)= 		  =  0.696 +- 0.018
Faith. Armon (KL)= 		  =  0.686 +- 0.019
Faith. GMean (KL)= 	  =  0.691 +- 0.018

Eval split val
Faith. Aritm (L1)= 		  =  0.547 +- 0.027
Faith. Armon (L1)= 		  =  0.538 +- 0.028
Faith. GMean (L1)= 	  =  0.543 +- 0.027
Faith. Aritm (KL)= 		  =  0.547 +- 0.040
Faith. Armon (KL)= 		  =  0.524 +- 0.035
Faith. GMean (KL)= 	  =  0.535 +- 0.037

Eval split test
Faith. Aritm (L1)= 		  =  0.473 +- 0.030
Faith. Armon (L1)= 		  =  0.456 +- 0.035
Faith. GMean (L1)= 	  =  0.465 +- 0.032
Faith. Aritm (KL)= 		  =  0.423 +- 0.038
Faith. Armon (KL)= 		  =  0.403 +- 0.041
Faith. GMean (KL)= 	  =  0.413 +- 0.039
Computed for split load_split = id



Completed in  0:11:11.826273  for CIGAGIN GOODMotif/size



DONE CIGA GOODMotif/size

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 21:20:16 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/22/2024 09:20:16 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 09:20:28 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 09:20:30 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 09:20:32 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 09:20:35 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 09:20:41 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 09:20:41 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 09:20:41 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:20:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:20:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:20:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:20:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:20:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:20:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:20:41 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 146...
[0m[1;37mINFO[0m: [1mCheckpoint 146: 
-----------------------------------
Train ACCURACY: 0.9274
Train Loss: 0.3249
ID Validation ACCURACY: 0.9343
ID Validation Loss: 0.3005
ID Test ACCURACY: 0.9283
ID Test Loss: 0.3247
OOD Validation ACCURACY: 0.9017
OOD Validation Loss: 0.4865
OOD Test ACCURACY: 0.4907
OOD Test Loss: 2.1636

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 84...
[0m[1;37mINFO[0m: [1mCheckpoint 84: 
-----------------------------------
Train ACCURACY: 0.9263
Train Loss: 0.3304
ID Validation ACCURACY: 0.9323
ID Validation Loss: 0.3044
ID Test ACCURACY: 0.9280
ID Test Loss: 0.3315
OOD Validation ACCURACY: 0.9040
OOD Validation Loss: 0.4661
OOD Test ACCURACY: 0.5197
OOD Test Loss: 1.7017

[0m[1;37mINFO[0m: [1mChartInfo 0.9283 0.4907 0.9280 0.5197 0.9323 0.9040[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.735
WIoU for r=0.3 = 0.622
F1 for r=0.6 = 0.650
WIoU for r=0.6 = 0.535
F1 for r=0.9 = 0.517
WIoU for r=0.9 = 0.399
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.377
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.572
WIoU for r=0.3 = 0.441
F1 for r=0.6 = 0.360
WIoU for r=0.6 = 0.245
F1 for r=0.9 = 0.259
WIoU for r=0.9 = 0.171
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.156
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.320
WIoU for r=0.3 = 0.204
F1 for r=0.6 = 0.180
WIoU for r=0.6 = 0.109
F1 for r=0.9 = 0.124
WIoU for r=0.9 = 0.075
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.068


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.488
Model XAI F1 of binarized graphs for r=0.3 =  0.73505
Model XAI WIoU of binarized graphs for r=0.3 =  0.62152
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.418
SUFF++ for r=0.3 class 0 = 0.474 +- 0.288 (in-sample avg dev_std = 0.514)
SUFF++ for r=0.3 class 1 = 0.583 +- 0.288 (in-sample avg dev_std = 0.514)
SUFF++ for r=0.3 class 2 = 0.566 +- 0.288 (in-sample avg dev_std = 0.514)
SUFF++ for r=0.3 all KL = 0.554 +- 0.288 (in-sample avg dev_std = 0.514)
SUFF++ for r=0.3 all L1 = 0.541 +- 0.161 (in-sample avg dev_std = 0.514)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.805
Model XAI F1 of binarized graphs for r=0.6 =  0.64967
Model XAI WIoU of binarized graphs for r=0.6 =  0.535
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.725
SUFF++ for r=0.6 class 0 = 0.615 +- 0.269 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.6 class 1 = 0.644 +- 0.269 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.6 class 2 = 0.721 +- 0.269 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.6 all KL = 0.682 +- 0.269 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.6 all L1 = 0.66 +- 0.212 (in-sample avg dev_std = 0.412)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.918
Model XAI F1 of binarized graphs for r=0.9 =  0.51714375
Model XAI WIoU of binarized graphs for r=0.9 =  0.398635
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.881
SUFF++ for r=0.9 class 0 = 0.814 +- 0.176 (in-sample avg dev_std = 0.224)
SUFF++ for r=0.9 class 1 = 0.864 +- 0.176 (in-sample avg dev_std = 0.224)
SUFF++ for r=0.9 class 2 = 0.878 +- 0.176 (in-sample avg dev_std = 0.224)
SUFF++ for r=0.9 all KL = 0.894 +- 0.176 (in-sample avg dev_std = 0.224)
SUFF++ for r=0.9 all L1 = 0.851 +- 0.160 (in-sample avg dev_std = 0.224)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.765
Model XAI F1 of binarized graphs for r=0.3 =  0.57153625
Model XAI WIoU of binarized graphs for r=0.3 =  0.44075374999999994
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.652
SUFF++ for r=0.3 class 0 = 0.562 +- 0.254 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.3 class 1 = 0.558 +- 0.254 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.3 class 2 = 0.632 +- 0.254 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.3 all KL = 0.634 +- 0.254 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.3 all L1 = 0.583 +- 0.169 (in-sample avg dev_std = 0.437)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.707
Model XAI F1 of binarized graphs for r=0.6 =  0.36021125
Model XAI WIoU of binarized graphs for r=0.6 =  0.24484750000000002
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.694
SUFF++ for r=0.6 class 0 = 0.553 +- 0.231 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.6 class 1 = 0.633 +- 0.231 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.6 class 2 = 0.649 +- 0.231 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.6 all KL = 0.676 +- 0.231 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.6 all L1 = 0.611 +- 0.166 (in-sample avg dev_std = 0.385)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.897
Model XAI F1 of binarized graphs for r=0.9 =  0.2593275
Model XAI WIoU of binarized graphs for r=0.9 =  0.17061374999999998
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.842
SUFF++ for r=0.9 class 0 = 0.758 +- 0.100 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.9 class 1 = 0.794 +- 0.100 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.9 class 2 = 0.789 +- 0.100 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.9 all KL = 0.905 +- 0.100 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.9 all L1 = 0.78 +- 0.133 (in-sample avg dev_std = 0.204)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.605
Model XAI F1 of binarized graphs for r=0.3 =  0.3196725
Model XAI WIoU of binarized graphs for r=0.3 =  0.2043725
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.556
SUFF++ for r=0.3 class 0 = 0.585 +- 0.151 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.3 class 1 = 0.607 +- 0.151 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.3 class 2 = 0.649 +- 0.151 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.3 all KL = 0.761 +- 0.151 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.3 all L1 = 0.613 +- 0.123 (in-sample avg dev_std = 0.360)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.678
Model XAI F1 of binarized graphs for r=0.6 =  0.17980000000000002
Model XAI WIoU of binarized graphs for r=0.6 =  0.10896999999999998
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.604
SUFF++ for r=0.6 class 0 = 0.597 +- 0.224 (in-sample avg dev_std = 0.369)
SUFF++ for r=0.6 class 1 = 0.652 +- 0.224 (in-sample avg dev_std = 0.369)
SUFF++ for r=0.6 class 2 = 0.6 +- 0.224 (in-sample avg dev_std = 0.369)
SUFF++ for r=0.6 all KL = 0.714 +- 0.224 (in-sample avg dev_std = 0.369)
SUFF++ for r=0.6 all L1 = 0.617 +- 0.130 (in-sample avg dev_std = 0.369)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.584
Model XAI F1 of binarized graphs for r=0.9 =  0.12446125000000002
Model XAI WIoU of binarized graphs for r=0.9 =  0.07521749999999999
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.546
SUFF++ for r=0.9 class 0 = 0.766 +- 0.207 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.9 class 1 = 0.692 +- 0.207 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.9 class 2 = 0.724 +- 0.207 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.9 all KL = 0.819 +- 0.207 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.9 all L1 = 0.727 +- 0.154 (in-sample avg dev_std = 0.223)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.488
Model XAI F1 of binarized graphs for r=0.3 =  0.73505
Model XAI WIoU of binarized graphs for r=0.3 =  0.62152
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.329
NEC for r=0.3 class 0 = 0.577 +- 0.345 (in-sample avg dev_std = 0.357)
NEC for r=0.3 class 1 = 0.482 +- 0.345 (in-sample avg dev_std = 0.357)
NEC for r=0.3 class 2 = 0.559 +- 0.345 (in-sample avg dev_std = 0.357)
NEC for r=0.3 all KL = 0.506 +- 0.345 (in-sample avg dev_std = 0.357)
NEC for r=0.3 all L1 = 0.54 +- 0.209 (in-sample avg dev_std = 0.357)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.806
Model XAI F1 of binarized graphs for r=0.6 =  0.64967
Model XAI WIoU of binarized graphs for r=0.6 =  0.535
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.386
NEC for r=0.6 class 0 = 0.604 +- 0.284 (in-sample avg dev_std = 0.492)
NEC for r=0.6 class 1 = 0.546 +- 0.284 (in-sample avg dev_std = 0.492)
NEC for r=0.6 class 2 = 0.669 +- 0.284 (in-sample avg dev_std = 0.492)
NEC for r=0.6 all KL = 0.65 +- 0.284 (in-sample avg dev_std = 0.492)
NEC for r=0.6 all L1 = 0.607 +- 0.166 (in-sample avg dev_std = 0.492)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.92
Model XAI F1 of binarized graphs for r=0.9 =  0.51714375
Model XAI WIoU of binarized graphs for r=0.9 =  0.398635
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.483
NEC for r=0.9 class 0 = 0.596 +- 0.252 (in-sample avg dev_std = 0.572)
NEC for r=0.9 class 1 = 0.509 +- 0.252 (in-sample avg dev_std = 0.572)
NEC for r=0.9 class 2 = 0.6 +- 0.252 (in-sample avg dev_std = 0.572)
NEC for r=0.9 all KL = 0.62 +- 0.252 (in-sample avg dev_std = 0.572)
NEC for r=0.9 all L1 = 0.569 +- 0.167 (in-sample avg dev_std = 0.572)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.935
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.3773075
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.528
NEC for r=1.0 class 0 = 0.571 +- 0.248 (in-sample avg dev_std = 0.622)
NEC for r=1.0 class 1 = 0.472 +- 0.248 (in-sample avg dev_std = 0.622)
NEC for r=1.0 class 2 = 0.59 +- 0.248 (in-sample avg dev_std = 0.622)
NEC for r=1.0 all KL = 0.622 +- 0.248 (in-sample avg dev_std = 0.622)
NEC for r=1.0 all L1 = 0.546 +- 0.174 (in-sample avg dev_std = 0.622)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.761
Model XAI F1 of binarized graphs for r=0.3 =  0.57153625
Model XAI WIoU of binarized graphs for r=0.3 =  0.44075374999999994
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.341
NEC for r=0.3 class 0 = 0.597 +- 0.278 (in-sample avg dev_std = 0.308)
NEC for r=0.3 class 1 = 0.499 +- 0.278 (in-sample avg dev_std = 0.308)
NEC for r=0.3 class 2 = 0.633 +- 0.278 (in-sample avg dev_std = 0.308)
NEC for r=0.3 all KL = 0.546 +- 0.278 (in-sample avg dev_std = 0.308)
NEC for r=0.3 all L1 = 0.575 +- 0.153 (in-sample avg dev_std = 0.308)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.705
Model XAI F1 of binarized graphs for r=0.6 =  0.36021125
Model XAI WIoU of binarized graphs for r=0.6 =  0.24484750000000002
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.417
NEC for r=0.6 class 0 = 0.532 +- 0.239 (in-sample avg dev_std = 0.378)
NEC for r=0.6 class 1 = 0.418 +- 0.239 (in-sample avg dev_std = 0.378)
NEC for r=0.6 class 2 = 0.564 +- 0.239 (in-sample avg dev_std = 0.378)
NEC for r=0.6 all KL = 0.444 +- 0.239 (in-sample avg dev_std = 0.378)
NEC for r=0.6 all L1 = 0.504 +- 0.160 (in-sample avg dev_std = 0.378)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.895
Model XAI F1 of binarized graphs for r=0.9 =  0.2593275
Model XAI WIoU of binarized graphs for r=0.9 =  0.17061374999999998
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.506
NEC for r=0.9 class 0 = 0.505 +- 0.206 (in-sample avg dev_std = 0.381)
NEC for r=0.9 class 1 = 0.38 +- 0.206 (in-sample avg dev_std = 0.381)
NEC for r=0.9 class 2 = 0.518 +- 0.206 (in-sample avg dev_std = 0.381)
NEC for r=0.9 all KL = 0.347 +- 0.206 (in-sample avg dev_std = 0.381)
NEC for r=0.9 all L1 = 0.467 +- 0.151 (in-sample avg dev_std = 0.381)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.923
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.15606124999999998
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.564
NEC for r=1.0 class 0 = 0.485 +- 0.186 (in-sample avg dev_std = 0.410)
NEC for r=1.0 class 1 = 0.422 +- 0.186 (in-sample avg dev_std = 0.410)
NEC for r=1.0 class 2 = 0.519 +- 0.186 (in-sample avg dev_std = 0.410)
NEC for r=1.0 all KL = 0.371 +- 0.186 (in-sample avg dev_std = 0.410)
NEC for r=1.0 all L1 = 0.475 +- 0.128 (in-sample avg dev_std = 0.410)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.606
Model XAI F1 of binarized graphs for r=0.3 =  0.3196725
Model XAI WIoU of binarized graphs for r=0.3 =  0.2043725
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.34
NEC for r=0.3 class 0 = 0.456 +- 0.200 (in-sample avg dev_std = 0.211)
NEC for r=0.3 class 1 = 0.479 +- 0.200 (in-sample avg dev_std = 0.211)
NEC for r=0.3 class 2 = 0.495 +- 0.200 (in-sample avg dev_std = 0.211)
NEC for r=0.3 all KL = 0.321 +- 0.200 (in-sample avg dev_std = 0.211)
NEC for r=0.3 all L1 = 0.476 +- 0.154 (in-sample avg dev_std = 0.211)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.679
Model XAI F1 of binarized graphs for r=0.6 =  0.17980000000000002
Model XAI WIoU of binarized graphs for r=0.6 =  0.10896999999999998
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.396
NEC for r=0.6 class 0 = 0.388 +- 0.147 (in-sample avg dev_std = 0.257)
NEC for r=0.6 class 1 = 0.327 +- 0.147 (in-sample avg dev_std = 0.257)
NEC for r=0.6 class 2 = 0.43 +- 0.147 (in-sample avg dev_std = 0.257)
NEC for r=0.6 all KL = 0.24 +- 0.147 (in-sample avg dev_std = 0.257)
NEC for r=0.6 all L1 = 0.381 +- 0.145 (in-sample avg dev_std = 0.257)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.586
Model XAI F1 of binarized graphs for r=0.9 =  0.12446125000000002
Model XAI WIoU of binarized graphs for r=0.9 =  0.07521749999999999
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.407
NEC for r=0.9 class 0 = 0.295 +- 0.207 (in-sample avg dev_std = 0.252)
NEC for r=0.9 class 1 = 0.336 +- 0.207 (in-sample avg dev_std = 0.252)
NEC for r=0.9 class 2 = 0.325 +- 0.207 (in-sample avg dev_std = 0.252)
NEC for r=0.9 all KL = 0.199 +- 0.207 (in-sample avg dev_std = 0.252)
NEC for r=0.9 all L1 = 0.319 +- 0.167 (in-sample avg dev_std = 0.252)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.501
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.06840625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.41
NEC for r=1.0 class 0 = 0.21 +- 0.212 (in-sample avg dev_std = 0.170)
NEC for r=1.0 class 1 = 0.261 +- 0.212 (in-sample avg dev_std = 0.170)
NEC for r=1.0 class 2 = 0.224 +- 0.212 (in-sample avg dev_std = 0.170)
NEC for r=1.0 all KL = 0.138 +- 0.212 (in-sample avg dev_std = 0.170)
NEC for r=1.0 all L1 = 0.232 +- 0.208 (in-sample avg dev_std = 0.170)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 21:27:01 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/22/2024 09:27:01 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 09:27:12 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 09:27:14 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 09:27:16 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 09:27:19 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 09:27:25 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 09:27:25 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 09:27:25 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:27:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:27:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:27:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:27:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:27:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:27:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:27:25 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 122...
[0m[1;37mINFO[0m: [1mCheckpoint 122: 
-----------------------------------
Train ACCURACY: 0.9269
Train Loss: 0.3371
ID Validation ACCURACY: 0.9333
ID Validation Loss: 0.3138
ID Test ACCURACY: 0.9290
ID Test Loss: 0.3425
OOD Validation ACCURACY: 0.8697
OOD Validation Loss: 0.5698
OOD Test ACCURACY: 0.5503
OOD Test Loss: 1.5812

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 139...
[0m[1;37mINFO[0m: [1mCheckpoint 139: 
-----------------------------------
Train ACCURACY: 0.9264
Train Loss: 0.3343
ID Validation ACCURACY: 0.9327
ID Validation Loss: 0.3132
ID Test ACCURACY: 0.9273
ID Test Loss: 0.3387
OOD Validation ACCURACY: 0.9030
OOD Validation Loss: 0.4750
OOD Test ACCURACY: 0.5800
OOD Test Loss: 2.8730

[0m[1;37mINFO[0m: [1mChartInfo 0.9290 0.5503 0.9273 0.5800 0.9327 0.9030[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.716
WIoU for r=0.3 = 0.598
F1 for r=0.6 = 0.638
WIoU for r=0.6 = 0.516
F1 for r=0.9 = 0.513
WIoU for r=0.9 = 0.387
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.369
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.561
WIoU for r=0.3 = 0.429
F1 for r=0.6 = 0.355
WIoU for r=0.6 = 0.238
F1 for r=0.9 = 0.258
WIoU for r=0.9 = 0.167
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.153
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.316
WIoU for r=0.3 = 0.202
F1 for r=0.6 = 0.179
WIoU for r=0.6 = 0.108
F1 for r=0.9 = 0.124
WIoU for r=0.9 = 0.075
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.068


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.499
Model XAI F1 of binarized graphs for r=0.3 =  0.71578125
Model XAI WIoU of binarized graphs for r=0.3 =  0.59757125
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.432
SUFF++ for r=0.3 class 0 = 0.51 +- 0.272 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.3 class 1 = 0.599 +- 0.272 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.3 class 2 = 0.578 +- 0.272 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.3 all KL = 0.598 +- 0.272 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.3 all L1 = 0.561 +- 0.171 (in-sample avg dev_std = 0.488)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.779
Model XAI F1 of binarized graphs for r=0.6 =  0.6384375
Model XAI WIoU of binarized graphs for r=0.6 =  0.5161250000000001
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.684
SUFF++ for r=0.6 class 0 = 0.579 +- 0.243 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.6 class 1 = 0.63 +- 0.243 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.6 class 2 = 0.725 +- 0.243 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.6 all KL = 0.7 +- 0.243 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.6 all L1 = 0.645 +- 0.195 (in-sample avg dev_std = 0.414)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.913
Model XAI F1 of binarized graphs for r=0.9 =  0.51302
Model XAI WIoU of binarized graphs for r=0.9 =  0.38695125
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.831
SUFF++ for r=0.9 class 0 = 0.723 +- 0.181 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 1 = 0.801 +- 0.181 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 2 = 0.883 +- 0.181 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 all KL = 0.872 +- 0.181 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 all L1 = 0.802 +- 0.182 (in-sample avg dev_std = 0.243)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.723
Model XAI F1 of binarized graphs for r=0.3 =  0.56096375
Model XAI WIoU of binarized graphs for r=0.3 =  0.42936499999999994
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.664
SUFF++ for r=0.3 class 0 = 0.649 +- 0.224 (in-sample avg dev_std = 0.395)
SUFF++ for r=0.3 class 1 = 0.62 +- 0.224 (in-sample avg dev_std = 0.395)
SUFF++ for r=0.3 class 2 = 0.657 +- 0.224 (in-sample avg dev_std = 0.395)
SUFF++ for r=0.3 all KL = 0.729 +- 0.224 (in-sample avg dev_std = 0.395)
SUFF++ for r=0.3 all L1 = 0.642 +- 0.166 (in-sample avg dev_std = 0.395)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.738
Model XAI F1 of binarized graphs for r=0.6 =  0.35532874999999997
Model XAI WIoU of binarized graphs for r=0.6 =  0.2382025
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.737
SUFF++ for r=0.6 class 0 = 0.623 +- 0.217 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 class 1 = 0.636 +- 0.217 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 class 2 = 0.671 +- 0.217 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 all KL = 0.749 +- 0.217 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 all L1 = 0.643 +- 0.165 (in-sample avg dev_std = 0.348)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.877
Model XAI F1 of binarized graphs for r=0.9 =  0.25843499999999997
Model XAI WIoU of binarized graphs for r=0.9 =  0.16659500000000002
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.834
SUFF++ for r=0.9 class 0 = 0.758 +- 0.111 (in-sample avg dev_std = 0.200)
SUFF++ for r=0.9 class 1 = 0.734 +- 0.111 (in-sample avg dev_std = 0.200)
SUFF++ for r=0.9 class 2 = 0.793 +- 0.111 (in-sample avg dev_std = 0.200)
SUFF++ for r=0.9 all KL = 0.894 +- 0.111 (in-sample avg dev_std = 0.200)
SUFF++ for r=0.9 all L1 = 0.761 +- 0.150 (in-sample avg dev_std = 0.200)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.647
Model XAI F1 of binarized graphs for r=0.3 =  0.315925
Model XAI WIoU of binarized graphs for r=0.3 =  0.201755
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.608
SUFF++ for r=0.3 class 0 = 0.693 +- 0.119 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.3 class 1 = 0.677 +- 0.119 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.3 class 2 = 0.686 +- 0.119 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.3 all KL = 0.85 +- 0.119 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.3 all L1 = 0.685 +- 0.113 (in-sample avg dev_std = 0.269)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.645
Model XAI F1 of binarized graphs for r=0.6 =  0.17896125
Model XAI WIoU of binarized graphs for r=0.6 =  0.10806874999999999
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.596
SUFF++ for r=0.6 class 0 = 0.65 +- 0.208 (in-sample avg dev_std = 0.386)
SUFF++ for r=0.6 class 1 = 0.649 +- 0.208 (in-sample avg dev_std = 0.386)
SUFF++ for r=0.6 class 2 = 0.632 +- 0.208 (in-sample avg dev_std = 0.386)
SUFF++ for r=0.6 all KL = 0.76 +- 0.208 (in-sample avg dev_std = 0.386)
SUFF++ for r=0.6 all L1 = 0.644 +- 0.120 (in-sample avg dev_std = 0.386)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.555
Model XAI F1 of binarized graphs for r=0.9 =  0.12400375000000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.0747075
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.507
SUFF++ for r=0.9 class 0 = 0.764 +- 0.090 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.9 class 1 = 0.739 +- 0.090 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.9 class 2 = 0.744 +- 0.090 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.9 all KL = 0.895 +- 0.090 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.9 all L1 = 0.749 +- 0.109 (in-sample avg dev_std = 0.198)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.498
Model XAI F1 of binarized graphs for r=0.3 =  0.71578125
Model XAI WIoU of binarized graphs for r=0.3 =  0.59757125
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.332
NEC for r=0.3 class 0 = 0.559 +- 0.337 (in-sample avg dev_std = 0.340)
NEC for r=0.3 class 1 = 0.415 +- 0.337 (in-sample avg dev_std = 0.340)
NEC for r=0.3 class 2 = 0.561 +- 0.337 (in-sample avg dev_std = 0.340)
NEC for r=0.3 all KL = 0.463 +- 0.337 (in-sample avg dev_std = 0.340)
NEC for r=0.3 all L1 = 0.513 +- 0.230 (in-sample avg dev_std = 0.340)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.777
Model XAI F1 of binarized graphs for r=0.6 =  0.6384375
Model XAI WIoU of binarized graphs for r=0.6 =  0.5161250000000001
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.392
NEC for r=0.6 class 0 = 0.572 +- 0.281 (in-sample avg dev_std = 0.486)
NEC for r=0.6 class 1 = 0.503 +- 0.281 (in-sample avg dev_std = 0.486)
NEC for r=0.6 class 2 = 0.654 +- 0.281 (in-sample avg dev_std = 0.486)
NEC for r=0.6 all KL = 0.565 +- 0.281 (in-sample avg dev_std = 0.486)
NEC for r=0.6 all L1 = 0.577 +- 0.168 (in-sample avg dev_std = 0.486)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.913
Model XAI F1 of binarized graphs for r=0.9 =  0.51302
Model XAI WIoU of binarized graphs for r=0.9 =  0.38695125
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.475
NEC for r=0.9 class 0 = 0.54 +- 0.258 (in-sample avg dev_std = 0.547)
NEC for r=0.9 class 1 = 0.522 +- 0.258 (in-sample avg dev_std = 0.547)
NEC for r=0.9 class 2 = 0.579 +- 0.258 (in-sample avg dev_std = 0.547)
NEC for r=0.9 all KL = 0.551 +- 0.258 (in-sample avg dev_std = 0.547)
NEC for r=0.9 all L1 = 0.547 +- 0.168 (in-sample avg dev_std = 0.547)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.933
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.36938125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.511
NEC for r=1.0 class 0 = 0.551 +- 0.260 (in-sample avg dev_std = 0.587)
NEC for r=1.0 class 1 = 0.487 +- 0.260 (in-sample avg dev_std = 0.587)
NEC for r=1.0 class 2 = 0.585 +- 0.260 (in-sample avg dev_std = 0.587)
NEC for r=1.0 all KL = 0.572 +- 0.260 (in-sample avg dev_std = 0.587)
NEC for r=1.0 all L1 = 0.542 +- 0.174 (in-sample avg dev_std = 0.587)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.723
Model XAI F1 of binarized graphs for r=0.3 =  0.56096375
Model XAI WIoU of binarized graphs for r=0.3 =  0.42936499999999994
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.343
NEC for r=0.3 class 0 = 0.47 +- 0.302 (in-sample avg dev_std = 0.279)
NEC for r=0.3 class 1 = 0.513 +- 0.302 (in-sample avg dev_std = 0.279)
NEC for r=0.3 class 2 = 0.651 +- 0.302 (in-sample avg dev_std = 0.279)
NEC for r=0.3 all KL = 0.471 +- 0.302 (in-sample avg dev_std = 0.279)
NEC for r=0.3 all L1 = 0.543 +- 0.185 (in-sample avg dev_std = 0.279)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.739
Model XAI F1 of binarized graphs for r=0.6 =  0.35532874999999997
Model XAI WIoU of binarized graphs for r=0.6 =  0.2382025
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.422
NEC for r=0.6 class 0 = 0.483 +- 0.223 (in-sample avg dev_std = 0.393)
NEC for r=0.6 class 1 = 0.454 +- 0.223 (in-sample avg dev_std = 0.393)
NEC for r=0.6 class 2 = 0.579 +- 0.223 (in-sample avg dev_std = 0.393)
NEC for r=0.6 all KL = 0.406 +- 0.223 (in-sample avg dev_std = 0.393)
NEC for r=0.6 all L1 = 0.504 +- 0.148 (in-sample avg dev_std = 0.393)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.88
Model XAI F1 of binarized graphs for r=0.9 =  0.25843499999999997
Model XAI WIoU of binarized graphs for r=0.9 =  0.16659500000000002
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.511
NEC for r=0.9 class 0 = 0.457 +- 0.179 (in-sample avg dev_std = 0.360)
NEC for r=0.9 class 1 = 0.441 +- 0.179 (in-sample avg dev_std = 0.360)
NEC for r=0.9 class 2 = 0.497 +- 0.179 (in-sample avg dev_std = 0.360)
NEC for r=0.9 all KL = 0.321 +- 0.179 (in-sample avg dev_std = 0.360)
NEC for r=0.9 all L1 = 0.464 +- 0.127 (in-sample avg dev_std = 0.360)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.887
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.15252625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.548
NEC for r=1.0 class 0 = 0.412 +- 0.178 (in-sample avg dev_std = 0.371)
NEC for r=1.0 class 1 = 0.415 +- 0.178 (in-sample avg dev_std = 0.371)
NEC for r=1.0 class 2 = 0.476 +- 0.178 (in-sample avg dev_std = 0.371)
NEC for r=1.0 all KL = 0.306 +- 0.178 (in-sample avg dev_std = 0.371)
NEC for r=1.0 all L1 = 0.434 +- 0.131 (in-sample avg dev_std = 0.371)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.647
Model XAI F1 of binarized graphs for r=0.3 =  0.315925
Model XAI WIoU of binarized graphs for r=0.3 =  0.201755
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.365
NEC for r=0.3 class 0 = 0.392 +- 0.187 (in-sample avg dev_std = 0.196)
NEC for r=0.3 class 1 = 0.443 +- 0.187 (in-sample avg dev_std = 0.196)
NEC for r=0.3 class 2 = 0.507 +- 0.187 (in-sample avg dev_std = 0.196)
NEC for r=0.3 all KL = 0.265 +- 0.187 (in-sample avg dev_std = 0.196)
NEC for r=0.3 all L1 = 0.446 +- 0.152 (in-sample avg dev_std = 0.196)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.651
Model XAI F1 of binarized graphs for r=0.6 =  0.17896125
Model XAI WIoU of binarized graphs for r=0.6 =  0.10806874999999999
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.394
NEC for r=0.6 class 0 = 0.387 +- 0.151 (in-sample avg dev_std = 0.261)
NEC for r=0.6 class 1 = 0.34 +- 0.151 (in-sample avg dev_std = 0.261)
NEC for r=0.6 class 2 = 0.426 +- 0.151 (in-sample avg dev_std = 0.261)
NEC for r=0.6 all KL = 0.232 +- 0.151 (in-sample avg dev_std = 0.261)
NEC for r=0.6 all L1 = 0.383 +- 0.135 (in-sample avg dev_std = 0.261)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.555
Model XAI F1 of binarized graphs for r=0.9 =  0.12400375000000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.0747075
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.401
NEC for r=0.9 class 0 = 0.307 +- 0.120 (in-sample avg dev_std = 0.196)
NEC for r=0.9 class 1 = 0.327 +- 0.120 (in-sample avg dev_std = 0.196)
NEC for r=0.9 class 2 = 0.329 +- 0.120 (in-sample avg dev_std = 0.196)
NEC for r=0.9 all KL = 0.147 +- 0.120 (in-sample avg dev_std = 0.196)
NEC for r=0.9 all L1 = 0.321 +- 0.150 (in-sample avg dev_std = 0.196)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.56
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.06815125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.406
NEC for r=1.0 class 0 = 0.247 +- 0.114 (in-sample avg dev_std = 0.186)
NEC for r=1.0 class 1 = 0.282 +- 0.114 (in-sample avg dev_std = 0.186)
NEC for r=1.0 class 2 = 0.27 +- 0.114 (in-sample avg dev_std = 0.186)
NEC for r=1.0 all KL = 0.115 +- 0.114 (in-sample avg dev_std = 0.186)
NEC for r=1.0 all L1 = 0.267 +- 0.164 (in-sample avg dev_std = 0.186)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 21:33:39 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/22/2024 09:33:39 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 09:33:51 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 09:33:53 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 09:33:55 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 09:33:58 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 09:34:04 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 09:34:04 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 09:34:04 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:34:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:34:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:34:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:34:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:34:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:34:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:34:04 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 109...
[0m[1;37mINFO[0m: [1mCheckpoint 109: 
-----------------------------------
Train ACCURACY: 0.9266
Train Loss: 0.3328
ID Validation ACCURACY: 0.9347
ID Validation Loss: 0.3080
ID Test ACCURACY: 0.9293
ID Test Loss: 0.3378
OOD Validation ACCURACY: 0.8910
OOD Validation Loss: 0.5238
OOD Test ACCURACY: 0.4787
OOD Test Loss: 2.2870

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 68...
[0m[1;37mINFO[0m: [1mCheckpoint 68: 
-----------------------------------
Train ACCURACY: 0.9253
Train Loss: 0.3400
ID Validation ACCURACY: 0.9327
ID Validation Loss: 0.3125
ID Test ACCURACY: 0.9237
ID Test Loss: 0.3418
OOD Validation ACCURACY: 0.9017
OOD Validation Loss: 0.4991
OOD Test ACCURACY: 0.6000
OOD Test Loss: 1.5258

[0m[1;37mINFO[0m: [1mChartInfo 0.9293 0.4787 0.9237 0.6000 0.9327 0.9017[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.732
WIoU for r=0.3 = 0.613
F1 for r=0.6 = 0.655
WIoU for r=0.6 = 0.535
F1 for r=0.9 = 0.521
WIoU for r=0.9 = 0.400
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.375
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.572
WIoU for r=0.3 = 0.441
F1 for r=0.6 = 0.360
WIoU for r=0.6 = 0.243
F1 for r=0.9 = 0.259
WIoU for r=0.9 = 0.169
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.154
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.319
WIoU for r=0.3 = 0.204
F1 for r=0.6 = 0.180
WIoU for r=0.6 = 0.109
F1 for r=0.9 = 0.124
WIoU for r=0.9 = 0.075
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.068


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.481
Model XAI F1 of binarized graphs for r=0.3 =  0.7318787499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.6125512500000001
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.429
SUFF++ for r=0.3 class 0 = 0.474 +- 0.266 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.3 class 1 = 0.615 +- 0.266 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.3 class 2 = 0.564 +- 0.266 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.3 all KL = 0.579 +- 0.266 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.3 all L1 = 0.55 +- 0.179 (in-sample avg dev_std = 0.486)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.786
Model XAI F1 of binarized graphs for r=0.6 =  0.6545425
Model XAI WIoU of binarized graphs for r=0.6 =  0.5354675
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.717
SUFF++ for r=0.6 class 0 = 0.639 +- 0.235 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 class 1 = 0.593 +- 0.235 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 class 2 = 0.738 +- 0.235 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 all KL = 0.715 +- 0.235 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 all L1 = 0.657 +- 0.201 (in-sample avg dev_std = 0.392)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.913
Model XAI F1 of binarized graphs for r=0.9 =  0.52122
Model XAI WIoU of binarized graphs for r=0.9 =  0.39978499999999995
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.866
SUFF++ for r=0.9 class 0 = 0.802 +- 0.161 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 class 1 = 0.797 +- 0.161 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 class 2 = 0.871 +- 0.161 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 all KL = 0.893 +- 0.161 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 all L1 = 0.824 +- 0.163 (in-sample avg dev_std = 0.239)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.712
Model XAI F1 of binarized graphs for r=0.3 =  0.572055
Model XAI WIoU of binarized graphs for r=0.3 =  0.44129999999999997
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.65
SUFF++ for r=0.3 class 0 = 0.636 +- 0.221 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.3 class 1 = 0.585 +- 0.221 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.3 class 2 = 0.635 +- 0.221 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.3 all KL = 0.69 +- 0.221 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.3 all L1 = 0.618 +- 0.156 (in-sample avg dev_std = 0.396)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.771
Model XAI F1 of binarized graphs for r=0.6 =  0.359595
Model XAI WIoU of binarized graphs for r=0.6 =  0.24309125
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.68
SUFF++ for r=0.6 class 0 = 0.669 +- 0.134 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.6 class 1 = 0.626 +- 0.134 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.6 class 2 = 0.685 +- 0.134 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.6 all KL = 0.807 +- 0.134 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.6 all L1 = 0.66 +- 0.127 (in-sample avg dev_std = 0.310)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.876
Model XAI F1 of binarized graphs for r=0.9 =  0.2593275
Model XAI WIoU of binarized graphs for r=0.9 =  0.16858249999999997
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.818
SUFF++ for r=0.9 class 0 = 0.769 +- 0.088 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.9 class 1 = 0.793 +- 0.088 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.9 class 2 = 0.802 +- 0.088 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.9 all KL = 0.92 +- 0.088 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.9 all L1 = 0.788 +- 0.126 (in-sample avg dev_std = 0.184)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.506
Model XAI F1 of binarized graphs for r=0.3 =  0.31880749999999997
Model XAI WIoU of binarized graphs for r=0.3 =  0.20374875
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.5
SUFF++ for r=0.3 class 0 = 0.688 +- 0.159 (in-sample avg dev_std = 0.349)
SUFF++ for r=0.3 class 1 = 0.671 +- 0.159 (in-sample avg dev_std = 0.349)
SUFF++ for r=0.3 class 2 = 0.683 +- 0.159 (in-sample avg dev_std = 0.349)
SUFF++ for r=0.3 all KL = 0.808 +- 0.159 (in-sample avg dev_std = 0.349)
SUFF++ for r=0.3 all L1 = 0.681 +- 0.119 (in-sample avg dev_std = 0.349)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.589
Model XAI F1 of binarized graphs for r=0.6 =  0.17981124999999998
Model XAI WIoU of binarized graphs for r=0.6 =  0.108675
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.558
SUFF++ for r=0.6 class 0 = 0.64 +- 0.183 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.6 class 1 = 0.62 +- 0.183 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.6 class 2 = 0.629 +- 0.183 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.6 all KL = 0.754 +- 0.183 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.6 all L1 = 0.63 +- 0.126 (in-sample avg dev_std = 0.382)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.5
Model XAI F1 of binarized graphs for r=0.9 =  0.12449875000000002
Model XAI WIoU of binarized graphs for r=0.9 =  0.07502500000000001
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.471
SUFF++ for r=0.9 class 0 = 0.728 +- 0.198 (in-sample avg dev_std = 0.225)
SUFF++ for r=0.9 class 1 = 0.709 +- 0.198 (in-sample avg dev_std = 0.225)
SUFF++ for r=0.9 class 2 = 0.759 +- 0.198 (in-sample avg dev_std = 0.225)
SUFF++ for r=0.9 all KL = 0.828 +- 0.198 (in-sample avg dev_std = 0.225)
SUFF++ for r=0.9 all L1 = 0.732 +- 0.135 (in-sample avg dev_std = 0.225)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.482
Model XAI F1 of binarized graphs for r=0.3 =  0.7318787499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.6125512500000001
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.333
NEC for r=0.3 class 0 = 0.544 +- 0.319 (in-sample avg dev_std = 0.360)
NEC for r=0.3 class 1 = 0.473 +- 0.319 (in-sample avg dev_std = 0.360)
NEC for r=0.3 class 2 = 0.593 +- 0.319 (in-sample avg dev_std = 0.360)
NEC for r=0.3 all KL = 0.499 +- 0.319 (in-sample avg dev_std = 0.360)
NEC for r=0.3 all L1 = 0.538 +- 0.215 (in-sample avg dev_std = 0.360)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.785
Model XAI F1 of binarized graphs for r=0.6 =  0.6545425
Model XAI WIoU of binarized graphs for r=0.6 =  0.5354675
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.387
NEC for r=0.6 class 0 = 0.551 +- 0.261 (in-sample avg dev_std = 0.474)
NEC for r=0.6 class 1 = 0.547 +- 0.261 (in-sample avg dev_std = 0.474)
NEC for r=0.6 class 2 = 0.651 +- 0.261 (in-sample avg dev_std = 0.474)
NEC for r=0.6 all KL = 0.581 +- 0.261 (in-sample avg dev_std = 0.474)
NEC for r=0.6 all L1 = 0.584 +- 0.161 (in-sample avg dev_std = 0.474)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.91
Model XAI F1 of binarized graphs for r=0.9 =  0.52122
Model XAI WIoU of binarized graphs for r=0.9 =  0.39978499999999995
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.478
NEC for r=0.9 class 0 = 0.524 +- 0.236 (in-sample avg dev_std = 0.530)
NEC for r=0.9 class 1 = 0.531 +- 0.236 (in-sample avg dev_std = 0.530)
NEC for r=0.9 class 2 = 0.585 +- 0.236 (in-sample avg dev_std = 0.530)
NEC for r=0.9 all KL = 0.535 +- 0.236 (in-sample avg dev_std = 0.530)
NEC for r=0.9 all L1 = 0.547 +- 0.160 (in-sample avg dev_std = 0.530)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.934
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.37454499999999996
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.511
NEC for r=1.0 class 0 = 0.525 +- 0.247 (in-sample avg dev_std = 0.566)
NEC for r=1.0 class 1 = 0.521 +- 0.247 (in-sample avg dev_std = 0.566)
NEC for r=1.0 class 2 = 0.577 +- 0.247 (in-sample avg dev_std = 0.566)
NEC for r=1.0 all KL = 0.557 +- 0.247 (in-sample avg dev_std = 0.566)
NEC for r=1.0 all L1 = 0.541 +- 0.171 (in-sample avg dev_std = 0.566)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.712
Model XAI F1 of binarized graphs for r=0.3 =  0.572055
Model XAI WIoU of binarized graphs for r=0.3 =  0.44129999999999997
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.333
NEC for r=0.3 class 0 = 0.481 +- 0.284 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 1 = 0.525 +- 0.284 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 2 = 0.622 +- 0.284 (in-sample avg dev_std = 0.293)
NEC for r=0.3 all KL = 0.492 +- 0.284 (in-sample avg dev_std = 0.293)
NEC for r=0.3 all L1 = 0.541 +- 0.182 (in-sample avg dev_std = 0.293)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.769
Model XAI F1 of binarized graphs for r=0.6 =  0.359595
Model XAI WIoU of binarized graphs for r=0.6 =  0.24309125
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.405
NEC for r=0.6 class 0 = 0.426 +- 0.211 (in-sample avg dev_std = 0.318)
NEC for r=0.6 class 1 = 0.46 +- 0.211 (in-sample avg dev_std = 0.318)
NEC for r=0.6 class 2 = 0.531 +- 0.211 (in-sample avg dev_std = 0.318)
NEC for r=0.6 all KL = 0.339 +- 0.211 (in-sample avg dev_std = 0.318)
NEC for r=0.6 all L1 = 0.471 +- 0.155 (in-sample avg dev_std = 0.318)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.877
Model XAI F1 of binarized graphs for r=0.9 =  0.2593275
Model XAI WIoU of binarized graphs for r=0.9 =  0.16858249999999997
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.469
NEC for r=0.9 class 0 = 0.45 +- 0.164 (in-sample avg dev_std = 0.337)
NEC for r=0.9 class 1 = 0.407 +- 0.164 (in-sample avg dev_std = 0.337)
NEC for r=0.9 class 2 = 0.482 +- 0.164 (in-sample avg dev_std = 0.337)
NEC for r=0.9 all KL = 0.288 +- 0.164 (in-sample avg dev_std = 0.337)
NEC for r=0.9 all L1 = 0.446 +- 0.136 (in-sample avg dev_std = 0.337)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.916
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.1539425
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.538
NEC for r=1.0 class 0 = 0.413 +- 0.201 (in-sample avg dev_std = 0.347)
NEC for r=1.0 class 1 = 0.43 +- 0.201 (in-sample avg dev_std = 0.347)
NEC for r=1.0 class 2 = 0.486 +- 0.201 (in-sample avg dev_std = 0.347)
NEC for r=1.0 all KL = 0.307 +- 0.201 (in-sample avg dev_std = 0.347)
NEC for r=1.0 all L1 = 0.442 +- 0.136 (in-sample avg dev_std = 0.347)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.505
Model XAI F1 of binarized graphs for r=0.3 =  0.31880749999999997
Model XAI WIoU of binarized graphs for r=0.3 =  0.20374875
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.34
NEC for r=0.3 class 0 = 0.306 +- 0.193 (in-sample avg dev_std = 0.165)
NEC for r=0.3 class 1 = 0.34 +- 0.193 (in-sample avg dev_std = 0.165)
NEC for r=0.3 class 2 = 0.392 +- 0.193 (in-sample avg dev_std = 0.165)
NEC for r=0.3 all KL = 0.207 +- 0.193 (in-sample avg dev_std = 0.165)
NEC for r=0.3 all L1 = 0.345 +- 0.187 (in-sample avg dev_std = 0.165)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.59
Model XAI F1 of binarized graphs for r=0.6 =  0.17981124999999998
Model XAI WIoU of binarized graphs for r=0.6 =  0.108675
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.378
NEC for r=0.6 class 0 = 0.289 +- 0.123 (in-sample avg dev_std = 0.193)
NEC for r=0.6 class 1 = 0.319 +- 0.123 (in-sample avg dev_std = 0.193)
NEC for r=0.6 class 2 = 0.354 +- 0.123 (in-sample avg dev_std = 0.193)
NEC for r=0.6 all KL = 0.152 +- 0.123 (in-sample avg dev_std = 0.193)
NEC for r=0.6 all L1 = 0.32 +- 0.150 (in-sample avg dev_std = 0.193)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.499
Model XAI F1 of binarized graphs for r=0.9 =  0.12449875000000002
Model XAI WIoU of binarized graphs for r=0.9 =  0.07502500000000001
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.35
NEC for r=0.9 class 0 = 0.271 +- 0.131 (in-sample avg dev_std = 0.172)
NEC for r=0.9 class 1 = 0.336 +- 0.131 (in-sample avg dev_std = 0.172)
NEC for r=0.9 class 2 = 0.284 +- 0.131 (in-sample avg dev_std = 0.172)
NEC for r=0.9 all KL = 0.149 +- 0.131 (in-sample avg dev_std = 0.172)
NEC for r=0.9 all L1 = 0.297 +- 0.152 (in-sample avg dev_std = 0.172)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.48
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.06820999999999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.365
NEC for r=1.0 class 0 = 0.236 +- 0.142 (in-sample avg dev_std = 0.154)
NEC for r=1.0 class 1 = 0.306 +- 0.142 (in-sample avg dev_std = 0.154)
NEC for r=1.0 class 2 = 0.268 +- 0.142 (in-sample avg dev_std = 0.154)
NEC for r=1.0 all KL = 0.143 +- 0.142 (in-sample avg dev_std = 0.154)
NEC for r=1.0 all L1 = 0.271 +- 0.172 (in-sample avg dev_std = 0.154)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 21:40:14 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/22/2024 09:40:14 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 09:40:26 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 09:40:27 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 09:40:29 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 09:40:32 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 09:40:39 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 09:40:39 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 09:40:39 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:40:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:40:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:40:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:40:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:40:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:40:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:40:39 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 135...
[0m[1;37mINFO[0m: [1mCheckpoint 135: 
-----------------------------------
Train ACCURACY: 0.9276
Train Loss: 0.3309
ID Validation ACCURACY: 0.9337
ID Validation Loss: 0.3021
ID Test ACCURACY: 0.9290
ID Test Loss: 0.3333
OOD Validation ACCURACY: 0.9093
OOD Validation Loss: 0.4749
OOD Test ACCURACY: 0.5283
OOD Test Loss: 1.2733

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 135...
[0m[1;37mINFO[0m: [1mCheckpoint 135: 
-----------------------------------
Train ACCURACY: 0.9276
Train Loss: 0.3309
ID Validation ACCURACY: 0.9337
ID Validation Loss: 0.3021
ID Test ACCURACY: 0.9290
ID Test Loss: 0.3333
OOD Validation ACCURACY: 0.9093
OOD Validation Loss: 0.4749
OOD Test ACCURACY: 0.5283
OOD Test Loss: 1.2733

[0m[1;37mINFO[0m: [1mChartInfo 0.9290 0.5283 0.9290 0.5283 0.9337 0.9093[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.728
WIoU for r=0.3 = 0.610
F1 for r=0.6 = 0.638
WIoU for r=0.6 = 0.517
F1 for r=0.9 = 0.517
WIoU for r=0.9 = 0.394
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.373
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.574
WIoU for r=0.3 = 0.444
F1 for r=0.6 = 0.359
WIoU for r=0.6 = 0.244
F1 for r=0.9 = 0.259
WIoU for r=0.9 = 0.169
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.155
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.319
WIoU for r=0.3 = 0.206
F1 for r=0.6 = 0.180
WIoU for r=0.6 = 0.110
F1 for r=0.9 = 0.124
WIoU for r=0.9 = 0.076
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.069


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.49
Model XAI F1 of binarized graphs for r=0.3 =  0.7275212500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.6101287500000001
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.394
SUFF++ for r=0.3 class 0 = 0.488 +- 0.258 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.3 class 1 = 0.621 +- 0.258 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.3 class 2 = 0.563 +- 0.258 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.3 all KL = 0.602 +- 0.258 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.3 all L1 = 0.556 +- 0.152 (in-sample avg dev_std = 0.438)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.785
Model XAI F1 of binarized graphs for r=0.6 =  0.6379625
Model XAI WIoU of binarized graphs for r=0.6 =  0.51734875
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.69
SUFF++ for r=0.6 class 0 = 0.614 +- 0.220 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.6 class 1 = 0.613 +- 0.220 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.6 class 2 = 0.72 +- 0.220 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.6 all KL = 0.718 +- 0.220 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.6 all L1 = 0.649 +- 0.186 (in-sample avg dev_std = 0.375)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.92
Model XAI F1 of binarized graphs for r=0.9 =  0.51672
Model XAI WIoU of binarized graphs for r=0.9 =  0.39370875
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.869
SUFF++ for r=0.9 class 0 = 0.783 +- 0.181 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.9 class 1 = 0.838 +- 0.181 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.9 class 2 = 0.866 +- 0.181 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.9 all KL = 0.889 +- 0.181 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.9 all L1 = 0.828 +- 0.170 (in-sample avg dev_std = 0.227)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.793
Model XAI F1 of binarized graphs for r=0.3 =  0.573545
Model XAI WIoU of binarized graphs for r=0.3 =  0.4435225
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.678
SUFF++ for r=0.3 class 0 = 0.588 +- 0.206 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.3 class 1 = 0.632 +- 0.206 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.3 class 2 = 0.653 +- 0.206 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.3 all KL = 0.709 +- 0.206 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.3 all L1 = 0.624 +- 0.154 (in-sample avg dev_std = 0.383)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.765
Model XAI F1 of binarized graphs for r=0.6 =  0.35940124999999995
Model XAI WIoU of binarized graphs for r=0.6 =  0.24441499999999997
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.72
SUFF++ for r=0.6 class 0 = 0.606 +- 0.172 (in-sample avg dev_std = 0.335)
SUFF++ for r=0.6 class 1 = 0.685 +- 0.172 (in-sample avg dev_std = 0.335)
SUFF++ for r=0.6 class 2 = 0.688 +- 0.172 (in-sample avg dev_std = 0.335)
SUFF++ for r=0.6 all KL = 0.785 +- 0.172 (in-sample avg dev_std = 0.335)
SUFF++ for r=0.6 all L1 = 0.659 +- 0.145 (in-sample avg dev_std = 0.335)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.91
Model XAI F1 of binarized graphs for r=0.9 =  0.25910249999999996
Model XAI WIoU of binarized graphs for r=0.9 =  0.16903750000000003
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.878
SUFF++ for r=0.9 class 0 = 0.789 +- 0.109 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.9 class 1 = 0.816 +- 0.109 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.9 class 2 = 0.788 +- 0.109 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.9 all KL = 0.913 +- 0.109 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.9 all L1 = 0.798 +- 0.136 (in-sample avg dev_std = 0.191)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.581
Model XAI F1 of binarized graphs for r=0.3 =  0.31944
Model XAI WIoU of binarized graphs for r=0.3 =  0.20648125
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.577
SUFF++ for r=0.3 class 0 = 0.608 +- 0.152 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.3 class 1 = 0.619 +- 0.152 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.3 class 2 = 0.642 +- 0.152 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.3 all KL = 0.761 +- 0.152 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.3 all L1 = 0.623 +- 0.120 (in-sample avg dev_std = 0.392)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.664
Model XAI F1 of binarized graphs for r=0.6 =  0.17954499999999995
Model XAI WIoU of binarized graphs for r=0.6 =  0.11019125
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.576
SUFF++ for r=0.6 class 0 = 0.627 +- 0.146 (in-sample avg dev_std = 0.325)
SUFF++ for r=0.6 class 1 = 0.666 +- 0.146 (in-sample avg dev_std = 0.325)
SUFF++ for r=0.6 class 2 = 0.668 +- 0.146 (in-sample avg dev_std = 0.325)
SUFF++ for r=0.6 all KL = 0.799 +- 0.146 (in-sample avg dev_std = 0.325)
SUFF++ for r=0.6 all L1 = 0.653 +- 0.117 (in-sample avg dev_std = 0.325)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.59
Model XAI F1 of binarized graphs for r=0.9 =  0.12430625000000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.07582375
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.61
SUFF++ for r=0.9 class 0 = 0.731 +- 0.159 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.9 class 1 = 0.72 +- 0.159 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.9 class 2 = 0.728 +- 0.159 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.9 all KL = 0.867 +- 0.159 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.9 all L1 = 0.726 +- 0.157 (in-sample avg dev_std = 0.234)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.493
Model XAI F1 of binarized graphs for r=0.3 =  0.7275212500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.6101287500000001
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.334
NEC for r=0.3 class 0 = 0.57 +- 0.314 (in-sample avg dev_std = 0.310)
NEC for r=0.3 class 1 = 0.43 +- 0.314 (in-sample avg dev_std = 0.310)
NEC for r=0.3 class 2 = 0.559 +- 0.314 (in-sample avg dev_std = 0.310)
NEC for r=0.3 all KL = 0.478 +- 0.314 (in-sample avg dev_std = 0.310)
NEC for r=0.3 all L1 = 0.521 +- 0.193 (in-sample avg dev_std = 0.310)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.785
Model XAI F1 of binarized graphs for r=0.6 =  0.6379625
Model XAI WIoU of binarized graphs for r=0.6 =  0.51734875
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.381
NEC for r=0.6 class 0 = 0.604 +- 0.262 (in-sample avg dev_std = 0.436)
NEC for r=0.6 class 1 = 0.516 +- 0.262 (in-sample avg dev_std = 0.436)
NEC for r=0.6 class 2 = 0.627 +- 0.262 (in-sample avg dev_std = 0.436)
NEC for r=0.6 all KL = 0.57 +- 0.262 (in-sample avg dev_std = 0.436)
NEC for r=0.6 all L1 = 0.583 +- 0.150 (in-sample avg dev_std = 0.436)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.92
Model XAI F1 of binarized graphs for r=0.9 =  0.51672
Model XAI WIoU of binarized graphs for r=0.9 =  0.39370875
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.489
NEC for r=0.9 class 0 = 0.588 +- 0.242 (in-sample avg dev_std = 0.526)
NEC for r=0.9 class 1 = 0.512 +- 0.242 (in-sample avg dev_std = 0.526)
NEC for r=0.9 class 2 = 0.58 +- 0.242 (in-sample avg dev_std = 0.526)
NEC for r=0.9 all KL = 0.565 +- 0.242 (in-sample avg dev_std = 0.526)
NEC for r=0.9 all L1 = 0.561 +- 0.156 (in-sample avg dev_std = 0.526)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.934
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.3726525
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.501
NEC for r=1.0 class 0 = 0.577 +- 0.254 (in-sample avg dev_std = 0.584)
NEC for r=1.0 class 1 = 0.512 +- 0.254 (in-sample avg dev_std = 0.584)
NEC for r=1.0 class 2 = 0.595 +- 0.254 (in-sample avg dev_std = 0.584)
NEC for r=1.0 all KL = 0.609 +- 0.254 (in-sample avg dev_std = 0.584)
NEC for r=1.0 all L1 = 0.562 +- 0.167 (in-sample avg dev_std = 0.584)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.79
Model XAI F1 of binarized graphs for r=0.3 =  0.573545
Model XAI WIoU of binarized graphs for r=0.3 =  0.4435225
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.325
NEC for r=0.3 class 0 = 0.596 +- 0.262 (in-sample avg dev_std = 0.269)
NEC for r=0.3 class 1 = 0.516 +- 0.262 (in-sample avg dev_std = 0.269)
NEC for r=0.3 class 2 = 0.598 +- 0.262 (in-sample avg dev_std = 0.269)
NEC for r=0.3 all KL = 0.517 +- 0.262 (in-sample avg dev_std = 0.269)
NEC for r=0.3 all L1 = 0.57 +- 0.147 (in-sample avg dev_std = 0.269)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.765
Model XAI F1 of binarized graphs for r=0.6 =  0.35940124999999995
Model XAI WIoU of binarized graphs for r=0.6 =  0.24441499999999997
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.396
NEC for r=0.6 class 0 = 0.499 +- 0.226 (in-sample avg dev_std = 0.310)
NEC for r=0.6 class 1 = 0.416 +- 0.226 (in-sample avg dev_std = 0.310)
NEC for r=0.6 class 2 = 0.539 +- 0.226 (in-sample avg dev_std = 0.310)
NEC for r=0.6 all KL = 0.355 +- 0.226 (in-sample avg dev_std = 0.310)
NEC for r=0.6 all L1 = 0.484 +- 0.156 (in-sample avg dev_std = 0.310)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.911
Model XAI F1 of binarized graphs for r=0.9 =  0.25910249999999996
Model XAI WIoU of binarized graphs for r=0.9 =  0.16903750000000003
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.507
NEC for r=0.9 class 0 = 0.555 +- 0.201 (in-sample avg dev_std = 0.359)
NEC for r=0.9 class 1 = 0.405 +- 0.201 (in-sample avg dev_std = 0.359)
NEC for r=0.9 class 2 = 0.49 +- 0.201 (in-sample avg dev_std = 0.359)
NEC for r=0.9 all KL = 0.351 +- 0.201 (in-sample avg dev_std = 0.359)
NEC for r=0.9 all L1 = 0.484 +- 0.141 (in-sample avg dev_std = 0.359)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.933
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.15456875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.549
NEC for r=1.0 class 0 = 0.479 +- 0.181 (in-sample avg dev_std = 0.386)
NEC for r=1.0 class 1 = 0.413 +- 0.181 (in-sample avg dev_std = 0.386)
NEC for r=1.0 class 2 = 0.488 +- 0.181 (in-sample avg dev_std = 0.386)
NEC for r=1.0 all KL = 0.338 +- 0.181 (in-sample avg dev_std = 0.386)
NEC for r=1.0 all L1 = 0.46 +- 0.130 (in-sample avg dev_std = 0.386)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.582
Model XAI F1 of binarized graphs for r=0.3 =  0.31944
Model XAI WIoU of binarized graphs for r=0.3 =  0.20648125
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.336
NEC for r=0.3 class 0 = 0.461 +- 0.196 (in-sample avg dev_std = 0.215)
NEC for r=0.3 class 1 = 0.373 +- 0.196 (in-sample avg dev_std = 0.215)
NEC for r=0.3 class 2 = 0.431 +- 0.196 (in-sample avg dev_std = 0.215)
NEC for r=0.3 all KL = 0.264 +- 0.196 (in-sample avg dev_std = 0.215)
NEC for r=0.3 all L1 = 0.421 +- 0.158 (in-sample avg dev_std = 0.215)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.66
Model XAI F1 of binarized graphs for r=0.6 =  0.17954499999999995
Model XAI WIoU of binarized graphs for r=0.6 =  0.11019125
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.388
NEC for r=0.6 class 0 = 0.445 +- 0.156 (in-sample avg dev_std = 0.209)
NEC for r=0.6 class 1 = 0.31 +- 0.156 (in-sample avg dev_std = 0.209)
NEC for r=0.6 class 2 = 0.385 +- 0.156 (in-sample avg dev_std = 0.209)
NEC for r=0.6 all KL = 0.205 +- 0.156 (in-sample avg dev_std = 0.209)
NEC for r=0.6 all L1 = 0.38 +- 0.152 (in-sample avg dev_std = 0.209)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.589
Model XAI F1 of binarized graphs for r=0.9 =  0.12430625000000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.07582375
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.413
NEC for r=0.9 class 0 = 0.425 +- 0.229 (in-sample avg dev_std = 0.276)
NEC for r=0.9 class 1 = 0.408 +- 0.229 (in-sample avg dev_std = 0.276)
NEC for r=0.9 class 2 = 0.389 +- 0.229 (in-sample avg dev_std = 0.276)
NEC for r=0.9 all KL = 0.249 +- 0.229 (in-sample avg dev_std = 0.276)
NEC for r=0.9 all L1 = 0.408 +- 0.176 (in-sample avg dev_std = 0.276)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.538
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.06909
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.435
NEC for r=1.0 class 0 = 0.327 +- 0.186 (in-sample avg dev_std = 0.231)
NEC for r=1.0 class 1 = 0.392 +- 0.186 (in-sample avg dev_std = 0.231)
NEC for r=1.0 class 2 = 0.348 +- 0.186 (in-sample avg dev_std = 0.231)
NEC for r=1.0 all KL = 0.209 +- 0.186 (in-sample avg dev_std = 0.231)
NEC for r=1.0 all L1 = 0.356 +- 0.162 (in-sample avg dev_std = 0.231)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 21:46:48 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 03/22/2024 09:46:48 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 09:47:00 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 09:47:02 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 09:47:03 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 09:47:07 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 09:47:13 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 09:47:13 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 09:47:13 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:47:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:47:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:47:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:47:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:47:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:47:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:47:13 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 109...
[0m[1;37mINFO[0m: [1mCheckpoint 109: 
-----------------------------------
Train ACCURACY: 0.9269
Train Loss: 0.3330
ID Validation ACCURACY: 0.9337
ID Validation Loss: 0.3044
ID Test ACCURACY: 0.9297
ID Test Loss: 0.3362
OOD Validation ACCURACY: 0.9000
OOD Validation Loss: 0.4896
OOD Test ACCURACY: 0.5230
OOD Test Loss: 2.0987

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 67...
[0m[1;37mINFO[0m: [1mCheckpoint 67: 
-----------------------------------
Train ACCURACY: 0.9253
Train Loss: 0.3396
ID Validation ACCURACY: 0.9320
ID Validation Loss: 0.3109
ID Test ACCURACY: 0.9260
ID Test Loss: 0.3440
OOD Validation ACCURACY: 0.9000
OOD Validation Loss: 0.4703
OOD Test ACCURACY: 0.5683
OOD Test Loss: 1.1198

[0m[1;37mINFO[0m: [1mChartInfo 0.9297 0.5230 0.9260 0.5683 0.9320 0.9000[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.715
WIoU for r=0.3 = 0.597
F1 for r=0.6 = 0.645
WIoU for r=0.6 = 0.527
F1 for r=0.9 = 0.518
WIoU for r=0.9 = 0.394
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.372
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.566
WIoU for r=0.3 = 0.435
F1 for r=0.6 = 0.359
WIoU for r=0.6 = 0.242
F1 for r=0.9 = 0.259
WIoU for r=0.9 = 0.168
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.153
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.317
WIoU for r=0.3 = 0.201
F1 for r=0.6 = 0.180
WIoU for r=0.6 = 0.108
F1 for r=0.9 = 0.124
WIoU for r=0.9 = 0.074
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.067


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.521
Model XAI F1 of binarized graphs for r=0.3 =  0.7145112499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.5965125
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.418
SUFF++ for r=0.3 class 0 = 0.474 +- 0.272 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.3 class 1 = 0.557 +- 0.272 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.3 class 2 = 0.543 +- 0.272 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.3 all KL = 0.541 +- 0.272 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.3 all L1 = 0.524 +- 0.170 (in-sample avg dev_std = 0.519)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.775
Model XAI F1 of binarized graphs for r=0.6 =  0.6454875
Model XAI WIoU of binarized graphs for r=0.6 =  0.527225
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.693
SUFF++ for r=0.6 class 0 = 0.59 +- 0.283 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 class 1 = 0.549 +- 0.283 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 class 2 = 0.771 +- 0.283 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 all KL = 0.653 +- 0.283 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 all L1 = 0.638 +- 0.230 (in-sample avg dev_std = 0.444)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.909
Model XAI F1 of binarized graphs for r=0.9 =  0.51755375
Model XAI WIoU of binarized graphs for r=0.9 =  0.39430750000000003
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.862
SUFF++ for r=0.9 class 0 = 0.773 +- 0.183 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.9 class 1 = 0.81 +- 0.183 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.9 class 2 = 0.905 +- 0.183 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.9 all KL = 0.886 +- 0.183 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.9 all L1 = 0.829 +- 0.178 (in-sample avg dev_std = 0.213)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.692
Model XAI F1 of binarized graphs for r=0.3 =  0.5658249999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.43451999999999996
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.673
SUFF++ for r=0.3 class 0 = 0.566 +- 0.244 (in-sample avg dev_std = 0.418)
SUFF++ for r=0.3 class 1 = 0.559 +- 0.244 (in-sample avg dev_std = 0.418)
SUFF++ for r=0.3 class 2 = 0.695 +- 0.244 (in-sample avg dev_std = 0.418)
SUFF++ for r=0.3 all KL = 0.661 +- 0.244 (in-sample avg dev_std = 0.418)
SUFF++ for r=0.3 all L1 = 0.605 +- 0.183 (in-sample avg dev_std = 0.418)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.755
Model XAI F1 of binarized graphs for r=0.6 =  0.3592825
Model XAI WIoU of binarized graphs for r=0.6 =  0.241615
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.709
SUFF++ for r=0.6 class 0 = 0.569 +- 0.227 (in-sample avg dev_std = 0.368)
SUFF++ for r=0.6 class 1 = 0.605 +- 0.227 (in-sample avg dev_std = 0.368)
SUFF++ for r=0.6 class 2 = 0.737 +- 0.227 (in-sample avg dev_std = 0.368)
SUFF++ for r=0.6 all KL = 0.726 +- 0.227 (in-sample avg dev_std = 0.368)
SUFF++ for r=0.6 all L1 = 0.636 +- 0.176 (in-sample avg dev_std = 0.368)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.897
Model XAI F1 of binarized graphs for r=0.9 =  0.2592425
Model XAI WIoU of binarized graphs for r=0.9 =  0.16756124999999997
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.84
SUFF++ for r=0.9 class 0 = 0.745 +- 0.111 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.9 class 1 = 0.805 +- 0.111 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.9 class 2 = 0.835 +- 0.111 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.9 all KL = 0.911 +- 0.111 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.9 all L1 = 0.794 +- 0.141 (in-sample avg dev_std = 0.192)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.566
Model XAI F1 of binarized graphs for r=0.3 =  0.3172825
Model XAI WIoU of binarized graphs for r=0.3 =  0.20112000000000002
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.574
SUFF++ for r=0.3 class 0 = 0.626 +- 0.236 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.3 class 1 = 0.616 +- 0.236 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.3 class 2 = 0.672 +- 0.236 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.3 all KL = 0.741 +- 0.236 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.3 all L1 = 0.637 +- 0.121 (in-sample avg dev_std = 0.393)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.646
Model XAI F1 of binarized graphs for r=0.6 =  0.17977875
Model XAI WIoU of binarized graphs for r=0.6 =  0.10751874999999998
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.564
SUFF++ for r=0.6 class 0 = 0.589 +- 0.252 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.6 class 1 = 0.605 +- 0.252 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.6 class 2 = 0.623 +- 0.252 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.6 all KL = 0.683 +- 0.252 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.6 all L1 = 0.605 +- 0.125 (in-sample avg dev_std = 0.405)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.586
Model XAI F1 of binarized graphs for r=0.9 =  0.12446375
Model XAI WIoU of binarized graphs for r=0.9 =  0.07420875
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.488
SUFF++ for r=0.9 class 0 = 0.718 +- 0.136 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 class 1 = 0.719 +- 0.136 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 class 2 = 0.756 +- 0.136 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 all KL = 0.852 +- 0.136 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 all L1 = 0.73 +- 0.135 (in-sample avg dev_std = 0.231)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.517
Model XAI F1 of binarized graphs for r=0.3 =  0.7145112499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.5965125
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.323
NEC for r=0.3 class 0 = 0.582 +- 0.317 (in-sample avg dev_std = 0.381)
NEC for r=0.3 class 1 = 0.504 +- 0.317 (in-sample avg dev_std = 0.381)
NEC for r=0.3 class 2 = 0.629 +- 0.317 (in-sample avg dev_std = 0.381)
NEC for r=0.3 all KL = 0.543 +- 0.317 (in-sample avg dev_std = 0.381)
NEC for r=0.3 all L1 = 0.573 +- 0.194 (in-sample avg dev_std = 0.381)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.772
Model XAI F1 of binarized graphs for r=0.6 =  0.6454875
Model XAI WIoU of binarized graphs for r=0.6 =  0.527225
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.394
NEC for r=0.6 class 0 = 0.592 +- 0.269 (in-sample avg dev_std = 0.511)
NEC for r=0.6 class 1 = 0.562 +- 0.269 (in-sample avg dev_std = 0.511)
NEC for r=0.6 class 2 = 0.625 +- 0.269 (in-sample avg dev_std = 0.511)
NEC for r=0.6 all KL = 0.642 +- 0.269 (in-sample avg dev_std = 0.511)
NEC for r=0.6 all L1 = 0.593 +- 0.165 (in-sample avg dev_std = 0.511)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.909
Model XAI F1 of binarized graphs for r=0.9 =  0.51755375
Model XAI WIoU of binarized graphs for r=0.9 =  0.39430750000000003
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.471
NEC for r=0.9 class 0 = 0.581 +- 0.249 (in-sample avg dev_std = 0.577)
NEC for r=0.9 class 1 = 0.53 +- 0.249 (in-sample avg dev_std = 0.577)
NEC for r=0.9 class 2 = 0.567 +- 0.249 (in-sample avg dev_std = 0.577)
NEC for r=0.9 all KL = 0.592 +- 0.249 (in-sample avg dev_std = 0.577)
NEC for r=0.9 all L1 = 0.559 +- 0.161 (in-sample avg dev_std = 0.577)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.935
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.37213000000000007
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.518
NEC for r=1.0 class 0 = 0.565 +- 0.251 (in-sample avg dev_std = 0.612)
NEC for r=1.0 class 1 = 0.496 +- 0.251 (in-sample avg dev_std = 0.612)
NEC for r=1.0 class 2 = 0.587 +- 0.251 (in-sample avg dev_std = 0.612)
NEC for r=1.0 all KL = 0.608 +- 0.251 (in-sample avg dev_std = 0.612)
NEC for r=1.0 all L1 = 0.55 +- 0.170 (in-sample avg dev_std = 0.612)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.695
Model XAI F1 of binarized graphs for r=0.3 =  0.5658249999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.43451999999999996
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.347
NEC for r=0.3 class 0 = 0.507 +- 0.302 (in-sample avg dev_std = 0.325)
NEC for r=0.3 class 1 = 0.509 +- 0.302 (in-sample avg dev_std = 0.325)
NEC for r=0.3 class 2 = 0.568 +- 0.302 (in-sample avg dev_std = 0.325)
NEC for r=0.3 all KL = 0.496 +- 0.302 (in-sample avg dev_std = 0.325)
NEC for r=0.3 all L1 = 0.528 +- 0.193 (in-sample avg dev_std = 0.325)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.752
Model XAI F1 of binarized graphs for r=0.6 =  0.3592825
Model XAI WIoU of binarized graphs for r=0.6 =  0.241615
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.412
NEC for r=0.6 class 0 = 0.472 +- 0.239 (in-sample avg dev_std = 0.384)
NEC for r=0.6 class 1 = 0.44 +- 0.239 (in-sample avg dev_std = 0.384)
NEC for r=0.6 class 2 = 0.552 +- 0.239 (in-sample avg dev_std = 0.384)
NEC for r=0.6 all KL = 0.408 +- 0.239 (in-sample avg dev_std = 0.384)
NEC for r=0.6 all L1 = 0.487 +- 0.174 (in-sample avg dev_std = 0.384)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.895
Model XAI F1 of binarized graphs for r=0.9 =  0.2592425
Model XAI WIoU of binarized graphs for r=0.9 =  0.16756124999999997
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.515
NEC for r=0.9 class 0 = 0.475 +- 0.186 (in-sample avg dev_std = 0.391)
NEC for r=0.9 class 1 = 0.431 +- 0.186 (in-sample avg dev_std = 0.391)
NEC for r=0.9 class 2 = 0.469 +- 0.186 (in-sample avg dev_std = 0.391)
NEC for r=0.9 all KL = 0.33 +- 0.186 (in-sample avg dev_std = 0.391)
NEC for r=0.9 all L1 = 0.458 +- 0.134 (in-sample avg dev_std = 0.391)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.921
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.15301625000000002
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.557
NEC for r=1.0 class 0 = 0.464 +- 0.202 (in-sample avg dev_std = 0.419)
NEC for r=1.0 class 1 = 0.411 +- 0.202 (in-sample avg dev_std = 0.419)
NEC for r=1.0 class 2 = 0.488 +- 0.202 (in-sample avg dev_std = 0.419)
NEC for r=1.0 all KL = 0.357 +- 0.202 (in-sample avg dev_std = 0.419)
NEC for r=1.0 all L1 = 0.454 +- 0.133 (in-sample avg dev_std = 0.419)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.565
Model XAI F1 of binarized graphs for r=0.3 =  0.3172825
Model XAI WIoU of binarized graphs for r=0.3 =  0.20112000000000002
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.326
NEC for r=0.3 class 0 = 0.385 +- 0.230 (in-sample avg dev_std = 0.202)
NEC for r=0.3 class 1 = 0.43 +- 0.230 (in-sample avg dev_std = 0.202)
NEC for r=0.3 class 2 = 0.421 +- 0.230 (in-sample avg dev_std = 0.202)
NEC for r=0.3 all KL = 0.278 +- 0.230 (in-sample avg dev_std = 0.202)
NEC for r=0.3 all L1 = 0.411 +- 0.213 (in-sample avg dev_std = 0.202)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.646
Model XAI F1 of binarized graphs for r=0.6 =  0.17977875
Model XAI WIoU of binarized graphs for r=0.6 =  0.10751874999999998
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.393
NEC for r=0.6 class 0 = 0.378 +- 0.194 (in-sample avg dev_std = 0.270)
NEC for r=0.6 class 1 = 0.358 +- 0.194 (in-sample avg dev_std = 0.270)
NEC for r=0.6 class 2 = 0.429 +- 0.194 (in-sample avg dev_std = 0.270)
NEC for r=0.6 all KL = 0.264 +- 0.194 (in-sample avg dev_std = 0.270)
NEC for r=0.6 all L1 = 0.387 +- 0.134 (in-sample avg dev_std = 0.270)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.589
Model XAI F1 of binarized graphs for r=0.9 =  0.12446375
Model XAI WIoU of binarized graphs for r=0.9 =  0.07420875
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.389
NEC for r=0.9 class 0 = 0.339 +- 0.135 (in-sample avg dev_std = 0.221)
NEC for r=0.9 class 1 = 0.327 +- 0.135 (in-sample avg dev_std = 0.221)
NEC for r=0.9 class 2 = 0.322 +- 0.135 (in-sample avg dev_std = 0.221)
NEC for r=0.9 all KL = 0.182 +- 0.135 (in-sample avg dev_std = 0.221)
NEC for r=0.9 all L1 = 0.329 +- 0.157 (in-sample avg dev_std = 0.221)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.519
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.067485
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.379
NEC for r=1.0 class 0 = 0.242 +- 0.146 (in-sample avg dev_std = 0.177)
NEC for r=1.0 class 1 = 0.269 +- 0.146 (in-sample avg dev_std = 0.177)
NEC for r=1.0 class 2 = 0.245 +- 0.146 (in-sample avg dev_std = 0.177)
NEC for r=1.0 all KL = 0.13 +- 0.146 (in-sample avg dev_std = 0.177)
NEC for r=1.0 all L1 = 0.252 +- 0.177 (in-sample avg dev_std = 0.177)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.554, 0.682, 0.894, 1.0], 'all_L1': [0.541, 0.66, 0.851, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.598, 0.7, 0.872, 1.0], 'all_L1': [0.561, 0.645, 0.802, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.579, 0.715, 0.893, 1.0], 'all_L1': [0.55, 0.657, 0.824, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.602, 0.718, 0.889, 1.0], 'all_L1': [0.556, 0.649, 0.828, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.541, 0.653, 0.886, 1.0], 'all_L1': [0.524, 0.638, 0.829, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.506, 0.65, 0.62, 0.622], 'all_L1': [0.54, 0.607, 0.569, 0.546]}), defaultdict(<class 'list'>, {'all_KL': [0.463, 0.565, 0.551, 0.572], 'all_L1': [0.513, 0.577, 0.547, 0.542]}), defaultdict(<class 'list'>, {'all_KL': [0.499, 0.581, 0.535, 0.557], 'all_L1': [0.538, 0.584, 0.547, 0.541]}), defaultdict(<class 'list'>, {'all_KL': [0.478, 0.57, 0.565, 0.609], 'all_L1': [0.521, 0.583, 0.561, 0.562]}), defaultdict(<class 'list'>, {'all_KL': [0.543, 0.642, 0.592, 0.608], 'all_L1': [0.573, 0.593, 0.559, 0.55]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.634, 0.676, 0.905, 1.0], 'all_L1': [0.583, 0.611, 0.78, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.729, 0.749, 0.894, 1.0], 'all_L1': [0.642, 0.643, 0.761, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.69, 0.807, 0.92, 1.0], 'all_L1': [0.618, 0.66, 0.788, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.709, 0.785, 0.913, 1.0], 'all_L1': [0.624, 0.659, 0.798, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.661, 0.726, 0.911, 1.0], 'all_L1': [0.605, 0.636, 0.794, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.546, 0.444, 0.347, 0.371], 'all_L1': [0.575, 0.504, 0.467, 0.475]}), defaultdict(<class 'list'>, {'all_KL': [0.471, 0.406, 0.321, 0.306], 'all_L1': [0.543, 0.504, 0.464, 0.434]}), defaultdict(<class 'list'>, {'all_KL': [0.492, 0.339, 0.288, 0.307], 'all_L1': [0.541, 0.471, 0.446, 0.442]}), defaultdict(<class 'list'>, {'all_KL': [0.517, 0.355, 0.351, 0.338], 'all_L1': [0.57, 0.484, 0.484, 0.46]}), defaultdict(<class 'list'>, {'all_KL': [0.496, 0.408, 0.33, 0.357], 'all_L1': [0.528, 0.487, 0.458, 0.454]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.761, 0.714, 0.819, 1.0], 'all_L1': [0.613, 0.617, 0.727, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.85, 0.76, 0.895, 1.0], 'all_L1': [0.685, 0.644, 0.749, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.808, 0.754, 0.828, 1.0], 'all_L1': [0.681, 0.63, 0.732, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.761, 0.799, 0.867, 1.0], 'all_L1': [0.623, 0.653, 0.726, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.741, 0.683, 0.852, 1.0], 'all_L1': [0.637, 0.605, 0.73, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.321, 0.24, 0.199, 0.138], 'all_L1': [0.476, 0.381, 0.319, 0.232]}), defaultdict(<class 'list'>, {'all_KL': [0.265, 0.232, 0.147, 0.115], 'all_L1': [0.446, 0.383, 0.321, 0.267]}), defaultdict(<class 'list'>, {'all_KL': [0.207, 0.152, 0.149, 0.143], 'all_L1': [0.345, 0.32, 0.297, 0.271]}), defaultdict(<class 'list'>, {'all_KL': [0.264, 0.205, 0.249, 0.209], 'all_L1': [0.421, 0.38, 0.408, 0.356]}), defaultdict(<class 'list'>, {'all_KL': [0.278, 0.264, 0.182, 0.13], 'all_L1': [0.411, 0.387, 0.329, 0.252]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.546 +- 0.013, 0.650 +- 0.008, 0.827 +- 0.016, 1.000 +- 0.000
suff++ class all_KL  =  0.575 +- 0.024, 0.694 +- 0.024, 0.887 +- 0.008, 1.000 +- 0.000
suff++_acc_int  =  0.418 +- 0.013, 0.702 +- 0.016, 0.862 +- 0.016
nec class all_L1  =  0.537 +- 0.021, 0.589 +- 0.010, 0.557 +- 0.009, 0.548 +- 0.008
nec class all_KL  =  0.498 +- 0.027, 0.602 +- 0.037, 0.573 +- 0.030, 0.594 +- 0.025
nec_acc_int  =  0.330 +- 0.004, 0.388 +- 0.004, 0.479 +- 0.006, 0.514 +- 0.009

Eval split val
suff++ class all_L1  =  0.614 +- 0.020, 0.642 +- 0.018, 0.784 +- 0.013, 1.000 +- 0.000
suff++ class all_KL  =  0.685 +- 0.034, 0.749 +- 0.046, 0.909 +- 0.009, 1.000 +- 0.000
suff++_acc_int  =  0.663 +- 0.011, 0.708 +- 0.020, 0.842 +- 0.020
nec class all_L1  =  0.551 +- 0.018, 0.490 +- 0.013, 0.464 +- 0.012, 0.453 +- 0.014
nec class all_KL  =  0.504 +- 0.025, 0.390 +- 0.038, 0.327 +- 0.023, 0.336 +- 0.026
nec_acc_int  =  0.338 +- 0.008, 0.410 +- 0.009, 0.502 +- 0.017, 0.551 +- 0.009

Eval split test
suff++ class all_L1  =  0.648 +- 0.030, 0.630 +- 0.017, 0.733 +- 0.008, 1.000 +- 0.000
suff++ class all_KL  =  0.784 +- 0.040, 0.742 +- 0.040, 0.852 +- 0.027, 1.000 +- 0.000
suff++_acc_int  =  0.563 +- 0.036, 0.580 +- 0.018, 0.524 +- 0.050
nec class all_L1  =  0.420 +- 0.044, 0.370 +- 0.025, 0.335 +- 0.038, 0.276 +- 0.042
nec class all_KL  =  0.267 +- 0.036, 0.219 +- 0.038, 0.185 +- 0.038, 0.147 +- 0.032
nec_acc_int  =  0.342 +- 0.013, 0.390 +- 0.007, 0.392 +- 0.022, 0.399 +- 0.025


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.542 +- 0.004, 0.619 +- 0.008, 0.692 +- 0.012, 0.774 +- 0.004
Faith. Armon (L1)= 		  =  0.541 +- 0.004, 0.618 +- 0.008, 0.665 +- 0.011, 0.708 +- 0.006
Faith. GMean (L1)= 	  =  0.541 +- 0.004, 0.619 +- 0.008, 0.678 +- 0.011, 0.740 +- 0.005
Faith. Aritm (KL)= 		  =  0.536 +- 0.005, 0.648 +- 0.011, 0.730 +- 0.017, 0.797 +- 0.012
Faith. Armon (KL)= 		  =  0.532 +- 0.007, 0.643 +- 0.013, 0.695 +- 0.023, 0.745 +- 0.020
Faith. GMean (KL)= 	  =  0.534 +- 0.006, 0.645 +- 0.012, 0.712 +- 0.020, 0.770 +- 0.016

Eval split val
Faith. Aritm (L1)= 		  =  0.583 +- 0.011, 0.566 +- 0.006, 0.624 +- 0.010, 0.726 +- 0.007
Faith. Armon (L1)= 		  =  0.581 +- 0.011, 0.555 +- 0.006, 0.583 +- 0.011, 0.623 +- 0.013
Faith. GMean (L1)= 	  =  0.582 +- 0.011, 0.561 +- 0.005, 0.603 +- 0.010, 0.673 +- 0.011
Faith. Aritm (KL)= 		  =  0.595 +- 0.011, 0.569 +- 0.006, 0.618 +- 0.011, 0.668 +- 0.013
Faith. Armon (KL)= 		  =  0.580 +- 0.011, 0.510 +- 0.023, 0.481 +- 0.024, 0.502 +- 0.029
Faith. GMean (KL)= 	  =  0.587 +- 0.011, 0.539 +- 0.011, 0.545 +- 0.018, 0.579 +- 0.023

Eval split test
Faith. Aritm (L1)= 		  =  0.534 +- 0.019, 0.500 +- 0.015, 0.534 +- 0.018, 0.638 +- 0.021
Faith. Armon (L1)= 		  =  0.507 +- 0.030, 0.466 +- 0.021, 0.458 +- 0.034, 0.430 +- 0.050
Faith. GMean (L1)= 	  =  0.520 +- 0.024, 0.482 +- 0.018, 0.494 +- 0.026, 0.524 +- 0.039
Faith. Aritm (KL)= 		  =  0.526 +- 0.020, 0.480 +- 0.017, 0.519 +- 0.023, 0.574 +- 0.016
Faith. Armon (KL)= 		  =  0.396 +- 0.039, 0.335 +- 0.045, 0.302 +- 0.050, 0.255 +- 0.048
Faith. GMean (KL)= 	  =  0.456 +- 0.029, 0.400 +- 0.032, 0.395 +- 0.040, 0.381 +- 0.040
Computed for split load_split = id



Completed in  0:33:15.357293  for GSATGIN GOODMotif/size



DONE GSAT GOODMotif/size

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 21:53:48 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 09:53:49 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 166...
[0m[1;37mINFO[0m: [1mCheckpoint 166: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0002
ID Validation ACCURACY: 0.9210
ID Validation Loss: 0.4334
ID Test ACCURACY: 0.9151
ID Test Loss: 0.4930
OOD Validation ACCURACY: 0.8823
OOD Validation Loss: 0.6328
OOD Test ACCURACY: 0.8311
OOD Test Loss: 1.1309

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 162...
[0m[1;37mINFO[0m: [1mCheckpoint 162: 
-----------------------------------
Train ACCURACY: 0.9999
Train Loss: 0.0004
ID Validation ACCURACY: 0.9172
ID Validation Loss: 0.4056
ID Test ACCURACY: 0.9130
ID Test Loss: 0.4650
OOD Validation ACCURACY: 0.8837
OOD Validation Loss: 0.6111
OOD Test ACCURACY: 0.8308
OOD Test Loss: 1.1121

[0m[1;37mINFO[0m: [1mChartInfo 0.9151 0.8311 0.9130 0.8308 0.9172 0.8837[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 03/22/2024 09:53:50 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.9
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 571
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.843
SUFF++ for r=0.6 class 0.0 = 0.806 +- 0.357 (in-sample avg dev_std = 0.493)
SUFF++ for r=0.6 class 1.0 = 0.862 +- 0.357 (in-sample avg dev_std = 0.493)
SUFF++ for r=0.6 all KL = 0.649 +- 0.357 (in-sample avg dev_std = 0.493)
SUFF++ for r=0.6 all L1 = 0.84 +- 0.177 (in-sample avg dev_std = 0.493)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.878
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.872
SUFF++ for r=0.9 class 0.0 = 0.964 +- 0.114 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.9 class 1.0 = 0.988 +- 0.114 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.9 all KL = 0.98 +- 0.114 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.9 all L1 = 0.977 +- 0.099 (in-sample avg dev_std = 0.112)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.83
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.749
SUFF++ for r=0.3 class 0.0 = 0.707 +- 0.337 (in-sample avg dev_std = 0.639)
SUFF++ for r=0.3 class 1.0 = 0.731 +- 0.337 (in-sample avg dev_std = 0.639)
SUFF++ for r=0.3 all KL = 0.465 +- 0.337 (in-sample avg dev_std = 0.639)
SUFF++ for r=0.3 all L1 = 0.72 +- 0.197 (in-sample avg dev_std = 0.639)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.871
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.836
SUFF++ for r=0.6 class 0.0 = 0.833 +- 0.317 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.6 class 1.0 = 0.865 +- 0.317 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.6 all KL = 0.722 +- 0.317 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.6 all L1 = 0.85 +- 0.187 (in-sample avg dev_std = 0.445)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.891
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.885
SUFF++ for r=0.9 class 0.0 = 0.94 +- 0.149 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.9 class 1.0 = 0.954 +- 0.149 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.9 all KL = 0.928 +- 0.149 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.9 all L1 = 0.947 +- 0.105 (in-sample avg dev_std = 0.241)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.8
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.747
SUFF++ for r=0.3 class 0.0 = 0.739 +- 0.355 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.3 class 1.0 = 0.788 +- 0.355 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.3 all KL = 0.545 +- 0.355 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.3 all L1 = 0.764 +- 0.212 (in-sample avg dev_std = 0.577)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.826
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.805
SUFF++ for r=0.6 class 0.0 = 0.834 +- 0.313 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 class 1.0 = 0.878 +- 0.313 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 all KL = 0.748 +- 0.313 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 all L1 = 0.857 +- 0.193 (in-sample avg dev_std = 0.415)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.858
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.846
SUFF++ for r=0.9 class 0.0 = 0.935 +- 0.154 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.9 class 1.0 = 0.957 +- 0.154 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.9 all KL = 0.931 +- 0.154 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.9 all L1 = 0.946 +- 0.120 (in-sample avg dev_std = 0.236)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.9
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 571
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.894
NEC for r=0.6 class 0.0 = 0.094 +- 0.231 (in-sample avg dev_std = 0.129)
NEC for r=0.6 class 1.0 = 0.048 +- 0.231 (in-sample avg dev_std = 0.129)
NEC for r=0.6 all KL = 0.084 +- 0.231 (in-sample avg dev_std = 0.129)
NEC for r=0.6 all L1 = 0.066 +- 0.178 (in-sample avg dev_std = 0.129)


ratio=0.9


tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
tensor([], size=(2, 0), dtype=torch.int64)
0
[1;31mERROR[0m: 03/22/2024 09:55:53 PM - utils.py - line 87 : [1mTraceback (most recent call last):
  File "/mnt/cimec-storage6/users/steve.azzolin/venv/leci/bin/goodtg", line 33, in <module>
    sys.exit(load_entry_point('graph-ood', 'console_scripts', 'goodtg')())
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/kernel/main.py", line 552, in goodtg
    main()
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/kernel/main.py", line 490, in main
    evaluate_metric(args)
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/kernel/main.py", line 304, in evaluate_metric
    score, acc_int, results = pipeline.compute_metric_ratio(
  File "/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/kernel/pipelines/basic_pipeline.py", line 908, in compute_metric_ratio
    int_dataset = CustomDataset("", eval_samples, belonging)
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/kernel/pipelines/basic_pipeline.py", line 58, in __init__
    raise ValueError("Empty intervened graph")
ValueError: Empty intervened graph
[0m
[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 22:02:10 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:12 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:02:12 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 166...
[0m[1;37mINFO[0m: [1mCheckpoint 166: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0002
ID Validation ACCURACY: 0.9210
ID Validation Loss: 0.4334
ID Test ACCURACY: 0.9151
ID Test Loss: 0.4930
OOD Validation ACCURACY: 0.8823
OOD Validation Loss: 0.6328
OOD Test ACCURACY: 0.8311
OOD Test Loss: 1.1309

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 162...
[0m[1;37mINFO[0m: [1mCheckpoint 162: 
-----------------------------------
Train ACCURACY: 0.9999
Train Loss: 0.0004
ID Validation ACCURACY: 0.9172
ID Validation Loss: 0.4056
ID Test ACCURACY: 0.9130
ID Test Loss: 0.4650
OOD Validation ACCURACY: 0.8837
OOD Validation Loss: 0.6111
OOD Test ACCURACY: 0.8308
OOD Test Loss: 1.1121

[0m[1;37mINFO[0m: [1mChartInfo 0.9151 0.8311 0.9130 0.8308 0.9172 0.8837[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 03/22/2024 10:02:13 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.838
SUFF++ for r=0.6 class 0.0 = 0.811 +- 0.337 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.6 class 1.0 = 0.864 +- 0.337 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.6 all KL = 0.692 +- 0.337 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.6 all L1 = 0.842 +- 0.192 (in-sample avg dev_std = 0.470)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.878
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.872
SUFF++ for r=0.9 class 0.0 = 0.964 +- 0.114 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.9 class 1.0 = 0.988 +- 0.114 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.9 all KL = 0.98 +- 0.114 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.9 all L1 = 0.977 +- 0.099 (in-sample avg dev_std = 0.112)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.83
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.749
SUFF++ for r=0.3 class 0.0 = 0.707 +- 0.337 (in-sample avg dev_std = 0.639)
SUFF++ for r=0.3 class 1.0 = 0.731 +- 0.337 (in-sample avg dev_std = 0.639)
SUFF++ for r=0.3 all KL = 0.465 +- 0.337 (in-sample avg dev_std = 0.639)
SUFF++ for r=0.3 all L1 = 0.72 +- 0.197 (in-sample avg dev_std = 0.639)


ratio=0.6


Computing with masking

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 22:03:48 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:03:49 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 166...
[0m[1;37mINFO[0m: [1mCheckpoint 166: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0002
ID Validation ACCURACY: 0.9210
ID Validation Loss: 0.4334
ID Test ACCURACY: 0.9151
ID Test Loss: 0.4930
OOD Validation ACCURACY: 0.8823
OOD Validation Loss: 0.6328
OOD Test ACCURACY: 0.8311
OOD Test Loss: 1.1309

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 162...
[0m[1;37mINFO[0m: [1mCheckpoint 162: 
-----------------------------------
Train ACCURACY: 0.9999
Train Loss: 0.0004
ID Validation ACCURACY: 0.9172
ID Validation Loss: 0.4056
ID Test ACCURACY: 0.9130
ID Test Loss: 0.4650
OOD Validation ACCURACY: 0.8837
OOD Validation Loss: 0.6111
OOD Test ACCURACY: 0.8308
OOD Test Loss: 1.1121

[0m[1;37mINFO[0m: [1mChartInfo 0.9151 0.8311 0.9130 0.8308 0.9172 0.8837[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 03/22/2024 10:03:50 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.838
SUFF++ for r=0.6 class 0.0 = 0.811 +- 0.337 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.6 class 1.0 = 0.864 +- 0.337 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.6 all KL = 0.692 +- 0.337 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.6 all L1 = 0.842 +- 0.192 (in-sample avg dev_std = 0.470)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.878
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.872
SUFF++ for r=0.9 class 0.0 = 0.964 +- 0.114 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.9 class 1.0 = 0.988 +- 0.114 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.9 all KL = 0.98 +- 0.114 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.9 all L1 = 0.977 +- 0.099 (in-sample avg dev_std = 0.112)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.83
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.749
SUFF++ for r=0.3 class 0.0 = 0.707 +- 0.337 (in-sample avg dev_std = 0.639)
SUFF++ for r=0.3 class 1.0 = 0.731 +- 0.337 (in-sample avg dev_std = 0.639)
SUFF++ for r=0.3 all KL = 0.465 +- 0.337 (in-sample avg dev_std = 0.639)
SUFF++ for r=0.3 all L1 = 0.72 +- 0.197 (in-sample avg dev_std = 0.639)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.871
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.836
SUFF++ for r=0.6 class 0.0 = 0.833 +- 0.317 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.6 class 1.0 = 0.865 +- 0.317 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.6 all KL = 0.722 +- 0.317 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.6 all L1 = 0.85 +- 0.187 (in-sample avg dev_std = 0.445)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.891
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.885
SUFF++ for r=0.9 class 0.0 = 0.94 +- 0.149 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.9 class 1.0 = 0.954 +- 0.149 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.9 all KL = 0.928 +- 0.149 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.9 all L1 = 0.947 +- 0.105 (in-sample avg dev_std = 0.241)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.8
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.747
SUFF++ for r=0.3 class 0.0 = 0.739 +- 0.355 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.3 class 1.0 = 0.788 +- 0.355 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.3 all KL = 0.545 +- 0.355 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.3 all L1 = 0.764 +- 0.212 (in-sample avg dev_std = 0.577)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.826
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.805
SUFF++ for r=0.6 class 0.0 = 0.834 +- 0.313 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 class 1.0 = 0.878 +- 0.313 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 all KL = 0.748 +- 0.313 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 all L1 = 0.857 +- 0.193 (in-sample avg dev_std = 0.415)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.858
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.846
SUFF++ for r=0.9 class 0.0 = 0.935 +- 0.154 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.9 class 1.0 = 0.957 +- 0.154 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.9 all KL = 0.931 +- 0.154 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.9 all L1 = 0.946 +- 0.120 (in-sample avg dev_std = 0.236)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.867
NEC for r=0.6 class 0.0 = 0.1 +- 0.240 (in-sample avg dev_std = 0.205)
NEC for r=0.6 class 1.0 = 0.058 +- 0.240 (in-sample avg dev_std = 0.205)
NEC for r=0.6 all KL = 0.096 +- 0.240 (in-sample avg dev_std = 0.205)
NEC for r=0.6 all L1 = 0.075 +- 0.178 (in-sample avg dev_std = 0.205)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.888
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.877
NEC for r=0.9 class 0.0 = 0.037 +- 0.110 (in-sample avg dev_std = 0.096)
NEC for r=0.9 class 1.0 = 0.016 +- 0.110 (in-sample avg dev_std = 0.096)
NEC for r=0.9 all KL = 0.021 +- 0.110 (in-sample avg dev_std = 0.096)
NEC for r=0.9 all L1 = 0.025 +- 0.100 (in-sample avg dev_std = 0.096)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.888
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.877
NEC for r=1.0 class 0.0 = 0.037 +- 0.110 (in-sample avg dev_std = 0.096)
NEC for r=1.0 class 1.0 = 0.016 +- 0.110 (in-sample avg dev_std = 0.096)
NEC for r=1.0 all KL = 0.021 +- 0.110 (in-sample avg dev_std = 0.096)
NEC for r=1.0 all L1 = 0.025 +- 0.100 (in-sample avg dev_std = 0.096)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.83
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.824
NEC for r=0.3 class 0.0 = 0.181 +- 0.310 (in-sample avg dev_std = 0.286)
NEC for r=0.3 class 1.0 = 0.113 +- 0.310 (in-sample avg dev_std = 0.286)
NEC for r=0.3 all KL = 0.179 +- 0.310 (in-sample avg dev_std = 0.286)
NEC for r=0.3 all L1 = 0.146 +- 0.239 (in-sample avg dev_std = 0.286)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.871
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.87
NEC for r=0.6 class 0.0 = 0.088 +- 0.220 (in-sample avg dev_std = 0.215)
NEC for r=0.6 class 1.0 = 0.062 +- 0.220 (in-sample avg dev_std = 0.215)
NEC for r=0.6 all KL = 0.086 +- 0.220 (in-sample avg dev_std = 0.215)
NEC for r=0.6 all L1 = 0.074 +- 0.174 (in-sample avg dev_std = 0.215)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.891
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.886
NEC for r=0.9 class 0.0 = 0.026 +- 0.102 (in-sample avg dev_std = 0.094)
NEC for r=0.9 class 1.0 = 0.019 +- 0.102 (in-sample avg dev_std = 0.094)
NEC for r=0.9 all KL = 0.018 +- 0.102 (in-sample avg dev_std = 0.094)
NEC for r=0.9 all L1 = 0.022 +- 0.092 (in-sample avg dev_std = 0.094)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.892
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.886
NEC for r=1.0 class 0.0 = 0.022 +- 0.083 (in-sample avg dev_std = 0.070)
NEC for r=1.0 class 1.0 = 0.015 +- 0.083 (in-sample avg dev_std = 0.070)
NEC for r=1.0 all KL = 0.013 +- 0.083 (in-sample avg dev_std = 0.070)
NEC for r=1.0 all L1 = 0.018 +- 0.083 (in-sample avg dev_std = 0.070)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.8
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.788
NEC for r=0.3 class 0.0 = 0.171 +- 0.313 (in-sample avg dev_std = 0.291)
NEC for r=0.3 class 1.0 = 0.116 +- 0.313 (in-sample avg dev_std = 0.291)
NEC for r=0.3 all KL = 0.182 +- 0.313 (in-sample avg dev_std = 0.291)
NEC for r=0.3 all L1 = 0.143 +- 0.245 (in-sample avg dev_std = 0.291)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.826
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.828
NEC for r=0.6 class 0.0 = 0.098 +- 0.217 (in-sample avg dev_std = 0.241)
NEC for r=0.6 class 1.0 = 0.062 +- 0.217 (in-sample avg dev_std = 0.241)
NEC for r=0.6 all KL = 0.091 +- 0.217 (in-sample avg dev_std = 0.241)
NEC for r=0.6 all L1 = 0.079 +- 0.174 (in-sample avg dev_std = 0.241)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.858
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.849
NEC for r=0.9 class 0.0 = 0.042 +- 0.109 (in-sample avg dev_std = 0.127)
NEC for r=0.9 class 1.0 = 0.022 +- 0.109 (in-sample avg dev_std = 0.127)
NEC for r=0.9 all KL = 0.025 +- 0.109 (in-sample avg dev_std = 0.127)
NEC for r=0.9 all L1 = 0.032 +- 0.105 (in-sample avg dev_std = 0.127)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.856
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.85
NEC for r=1.0 class 0.0 = 0.027 +- 0.084 (in-sample avg dev_std = 0.103)
NEC for r=1.0 class 1.0 = 0.019 +- 0.084 (in-sample avg dev_std = 0.103)
NEC for r=1.0 all KL = 0.017 +- 0.084 (in-sample avg dev_std = 0.103)
NEC for r=1.0 all L1 = 0.023 +- 0.082 (in-sample avg dev_std = 0.103)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 22:07:04 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 158...
[0m[1;37mINFO[0m: [1mCheckpoint 158: 
-----------------------------------
Train ACCURACY: 0.9999
Train Loss: 0.0004
ID Validation ACCURACY: 0.9219
ID Validation Loss: 0.4149
ID Test ACCURACY: 0.9153
ID Test Loss: 0.4712
OOD Validation ACCURACY: 0.8844
OOD Validation Loss: 0.6335
OOD Test ACCURACY: 0.8226
OOD Test Loss: 1.5522

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 198...
[0m[1;37mINFO[0m: [1mCheckpoint 198: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0002
ID Validation ACCURACY: 0.9206
ID Validation Loss: 0.4566
ID Test ACCURACY: 0.9164
ID Test Loss: 0.5199
OOD Validation ACCURACY: 0.8857
OOD Validation Loss: 0.7013
OOD Test ACCURACY: 0.8256
OOD Test Loss: 1.5657

[0m[1;37mINFO[0m: [1mChartInfo 0.9153 0.8226 0.9164 0.8256 0.9206 0.8857[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 03/22/2024 10:07:05 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.836
SUFF++ for r=0.6 class 0.0 = 0.81 +- 0.305 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.6 class 1.0 = 0.9 +- 0.305 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.6 all KL = 0.749 +- 0.305 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.6 all L1 = 0.863 +- 0.182 (in-sample avg dev_std = 0.401)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.894
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.878
SUFF++ for r=0.9 class 0.0 = 0.959 +- 0.121 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.9 class 1.0 = 0.983 +- 0.121 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.9 all KL = 0.978 +- 0.121 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.9 all L1 = 0.973 +- 0.106 (in-sample avg dev_std = 0.112)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.79
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 799
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.767
SUFF++ for r=0.3 class 0.0 = 0.751 +- 0.313 (in-sample avg dev_std = 0.493)
SUFF++ for r=0.3 class 1.0 = 0.824 +- 0.313 (in-sample avg dev_std = 0.493)
SUFF++ for r=0.3 all KL = 0.656 +- 0.313 (in-sample avg dev_std = 0.493)
SUFF++ for r=0.3 all L1 = 0.789 +- 0.209 (in-sample avg dev_std = 0.493)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.874
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.838
SUFF++ for r=0.6 class 0.0 = 0.828 +- 0.277 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 class 1.0 = 0.893 +- 0.277 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 all KL = 0.773 +- 0.277 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 all L1 = 0.862 +- 0.181 (in-sample avg dev_std = 0.392)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.887
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.875
SUFF++ for r=0.9 class 0.0 = 0.926 +- 0.162 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.9 class 1.0 = 0.952 +- 0.162 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.9 all KL = 0.914 +- 0.162 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.9 all L1 = 0.94 +- 0.106 (in-sample avg dev_std = 0.262)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.781
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.749
SUFF++ for r=0.3 class 0.0 = 0.741 +- 0.319 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 class 1.0 = 0.859 +- 0.319 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 all KL = 0.672 +- 0.319 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 all L1 = 0.802 +- 0.211 (in-sample avg dev_std = 0.475)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.822
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.798
SUFF++ for r=0.6 class 0.0 = 0.826 +- 0.296 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.6 class 1.0 = 0.901 +- 0.296 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.6 all KL = 0.783 +- 0.296 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.6 all L1 = 0.865 +- 0.198 (in-sample avg dev_std = 0.390)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.839
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.83
SUFF++ for r=0.9 class 0.0 = 0.939 +- 0.154 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.9 class 1.0 = 0.963 +- 0.154 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.9 all KL = 0.936 +- 0.154 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.9 all L1 = 0.952 +- 0.113 (in-sample avg dev_std = 0.229)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.859
NEC for r=0.6 class 0.0 = 0.087 +- 0.203 (in-sample avg dev_std = 0.139)
NEC for r=0.6 class 1.0 = 0.041 +- 0.203 (in-sample avg dev_std = 0.139)
NEC for r=0.6 all KL = 0.067 +- 0.203 (in-sample avg dev_std = 0.139)
NEC for r=0.6 all L1 = 0.06 +- 0.156 (in-sample avg dev_std = 0.139)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.884
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.866
NEC for r=0.9 class 0.0 = 0.041 +- 0.137 (in-sample avg dev_std = 0.099)
NEC for r=0.9 class 1.0 = 0.019 +- 0.137 (in-sample avg dev_std = 0.099)
NEC for r=0.9 all KL = 0.027 +- 0.137 (in-sample avg dev_std = 0.099)
NEC for r=0.9 all L1 = 0.028 +- 0.115 (in-sample avg dev_std = 0.099)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.884
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.866
NEC for r=1.0 class 0.0 = 0.041 +- 0.137 (in-sample avg dev_std = 0.099)
NEC for r=1.0 class 1.0 = 0.019 +- 0.137 (in-sample avg dev_std = 0.099)
NEC for r=1.0 all KL = 0.027 +- 0.137 (in-sample avg dev_std = 0.099)
NEC for r=1.0 all L1 = 0.028 +- 0.115 (in-sample avg dev_std = 0.099)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.79
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.792
NEC for r=0.3 class 0.0 = 0.166 +- 0.268 (in-sample avg dev_std = 0.258)
NEC for r=0.3 class 1.0 = 0.093 +- 0.268 (in-sample avg dev_std = 0.258)
NEC for r=0.3 all KL = 0.142 +- 0.268 (in-sample avg dev_std = 0.258)
NEC for r=0.3 all L1 = 0.128 +- 0.220 (in-sample avg dev_std = 0.258)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.874
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.864
NEC for r=0.6 class 0.0 = 0.082 +- 0.161 (in-sample avg dev_std = 0.152)
NEC for r=0.6 class 1.0 = 0.043 +- 0.161 (in-sample avg dev_std = 0.152)
NEC for r=0.6 all KL = 0.059 +- 0.161 (in-sample avg dev_std = 0.152)
NEC for r=0.6 all L1 = 0.062 +- 0.150 (in-sample avg dev_std = 0.152)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.887
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.875
NEC for r=0.9 class 0.0 = 0.032 +- 0.093 (in-sample avg dev_std = 0.088)
NEC for r=0.9 class 1.0 = 0.017 +- 0.093 (in-sample avg dev_std = 0.088)
NEC for r=0.9 all KL = 0.017 +- 0.093 (in-sample avg dev_std = 0.088)
NEC for r=0.9 all L1 = 0.024 +- 0.094 (in-sample avg dev_std = 0.088)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.887
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.878
NEC for r=1.0 class 0.0 = 0.027 +- 0.091 (in-sample avg dev_std = 0.085)
NEC for r=1.0 class 1.0 = 0.016 +- 0.091 (in-sample avg dev_std = 0.085)
NEC for r=1.0 all KL = 0.016 +- 0.091 (in-sample avg dev_std = 0.085)
NEC for r=1.0 all L1 = 0.022 +- 0.088 (in-sample avg dev_std = 0.085)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.781
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.768
NEC for r=0.3 class 0.0 = 0.183 +- 0.287 (in-sample avg dev_std = 0.298)
NEC for r=0.3 class 1.0 = 0.094 +- 0.287 (in-sample avg dev_std = 0.298)
NEC for r=0.3 all KL = 0.167 +- 0.287 (in-sample avg dev_std = 0.298)
NEC for r=0.3 all L1 = 0.137 +- 0.222 (in-sample avg dev_std = 0.298)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.824
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.819
NEC for r=0.6 class 0.0 = 0.098 +- 0.191 (in-sample avg dev_std = 0.211)
NEC for r=0.6 class 1.0 = 0.048 +- 0.191 (in-sample avg dev_std = 0.211)
NEC for r=0.6 all KL = 0.077 +- 0.191 (in-sample avg dev_std = 0.211)
NEC for r=0.6 all L1 = 0.073 +- 0.161 (in-sample avg dev_std = 0.211)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.839
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.836
NEC for r=0.9 class 0.0 = 0.04 +- 0.101 (in-sample avg dev_std = 0.114)
NEC for r=0.9 class 1.0 = 0.023 +- 0.101 (in-sample avg dev_std = 0.114)
NEC for r=0.9 all KL = 0.024 +- 0.101 (in-sample avg dev_std = 0.114)
NEC for r=0.9 all L1 = 0.031 +- 0.106 (in-sample avg dev_std = 0.114)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.84
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.84
NEC for r=1.0 class 0.0 = 0.033 +- 0.095 (in-sample avg dev_std = 0.111)
NEC for r=1.0 class 1.0 = 0.023 +- 0.095 (in-sample avg dev_std = 0.111)
NEC for r=1.0 all KL = 0.021 +- 0.095 (in-sample avg dev_std = 0.111)
NEC for r=1.0 all L1 = 0.027 +- 0.094 (in-sample avg dev_std = 0.111)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 22:10:29 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:10:30 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 176...
[0m[1;37mINFO[0m: [1mCheckpoint 176: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0002
ID Validation ACCURACY: 0.9217
ID Validation Loss: 0.4089
ID Test ACCURACY: 0.9170
ID Test Loss: 0.4793
OOD Validation ACCURACY: 0.8800
OOD Validation Loss: 0.6717
OOD Test ACCURACY: 0.8278
OOD Test Loss: 1.4934

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 109...
[0m[1;37mINFO[0m: [1mCheckpoint 109: 
-----------------------------------
Train ACCURACY: 0.9996
Train Loss: 0.0032
ID Validation ACCURACY: 0.9189
ID Validation Loss: 0.3261
ID Test ACCURACY: 0.9128
ID Test Loss: 0.3801
OOD Validation ACCURACY: 0.8837
OOD Validation Loss: 0.5452
OOD Test ACCURACY: 0.8331
OOD Test Loss: 1.2119

[0m[1;37mINFO[0m: [1mChartInfo 0.9170 0.8278 0.9128 0.8331 0.9189 0.8837[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 03/22/2024 10:10:31 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.888
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.848
SUFF++ for r=0.6 class 0.0 = 0.823 +- 0.317 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.6 class 1.0 = 0.884 +- 0.317 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.6 all KL = 0.71 +- 0.317 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.6 all L1 = 0.859 +- 0.173 (in-sample avg dev_std = 0.426)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.883
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.869
SUFF++ for r=0.9 class 0.0 = 0.964 +- 0.119 (in-sample avg dev_std = 0.095)
SUFF++ for r=0.9 class 1.0 = 0.984 +- 0.119 (in-sample avg dev_std = 0.095)
SUFF++ for r=0.9 all KL = 0.977 +- 0.119 (in-sample avg dev_std = 0.095)
SUFF++ for r=0.9 all L1 = 0.975 +- 0.099 (in-sample avg dev_std = 0.095)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.824
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.777
SUFF++ for r=0.3 class 0.0 = 0.767 +- 0.321 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.3 class 1.0 = 0.81 +- 0.321 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.3 all KL = 0.652 +- 0.321 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.3 all L1 = 0.789 +- 0.204 (in-sample avg dev_std = 0.500)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.877
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.836
SUFF++ for r=0.6 class 0.0 = 0.84 +- 0.295 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.6 class 1.0 = 0.872 +- 0.295 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.6 all KL = 0.743 +- 0.295 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.6 all L1 = 0.857 +- 0.175 (in-sample avg dev_std = 0.412)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.887
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.871
SUFF++ for r=0.9 class 0.0 = 0.917 +- 0.171 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.9 class 1.0 = 0.953 +- 0.171 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.9 all KL = 0.904 +- 0.171 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.9 all L1 = 0.936 +- 0.113 (in-sample avg dev_std = 0.280)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.78
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.74
SUFF++ for r=0.3 class 0.0 = 0.751 +- 0.323 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.3 class 1.0 = 0.815 +- 0.323 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.3 all KL = 0.642 +- 0.323 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.3 all L1 = 0.784 +- 0.214 (in-sample avg dev_std = 0.495)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.814
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.792
SUFF++ for r=0.6 class 0.0 = 0.84 +- 0.308 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.6 class 1.0 = 0.873 +- 0.308 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.6 all KL = 0.747 +- 0.308 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.6 all L1 = 0.857 +- 0.193 (in-sample avg dev_std = 0.416)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.84
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.832
SUFF++ for r=0.9 class 0.0 = 0.935 +- 0.170 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 class 1.0 = 0.962 +- 0.170 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 all KL = 0.921 +- 0.170 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 all L1 = 0.949 +- 0.107 (in-sample avg dev_std = 0.248)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.87
NEC for r=0.6 class 0.0 = 0.103 +- 0.206 (in-sample avg dev_std = 0.123)
NEC for r=0.6 class 1.0 = 0.041 +- 0.206 (in-sample avg dev_std = 0.123)
NEC for r=0.6 all KL = 0.072 +- 0.206 (in-sample avg dev_std = 0.123)
NEC for r=0.6 all L1 = 0.067 +- 0.175 (in-sample avg dev_std = 0.123)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.891
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.871
NEC for r=0.9 class 0.0 = 0.048 +- 0.141 (in-sample avg dev_std = 0.115)
NEC for r=0.9 class 1.0 = 0.017 +- 0.141 (in-sample avg dev_std = 0.115)
NEC for r=0.9 all KL = 0.029 +- 0.141 (in-sample avg dev_std = 0.115)
NEC for r=0.9 all L1 = 0.03 +- 0.117 (in-sample avg dev_std = 0.115)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.891
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.871
NEC for r=1.0 class 0.0 = 0.048 +- 0.141 (in-sample avg dev_std = 0.115)
NEC for r=1.0 class 1.0 = 0.017 +- 0.141 (in-sample avg dev_std = 0.115)
NEC for r=1.0 all KL = 0.029 +- 0.141 (in-sample avg dev_std = 0.115)
NEC for r=1.0 all L1 = 0.03 +- 0.117 (in-sample avg dev_std = 0.115)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.824
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.819
NEC for r=0.3 class 0.0 = 0.157 +- 0.265 (in-sample avg dev_std = 0.242)
NEC for r=0.3 class 1.0 = 0.107 +- 0.265 (in-sample avg dev_std = 0.242)
NEC for r=0.3 all KL = 0.143 +- 0.265 (in-sample avg dev_std = 0.242)
NEC for r=0.3 all L1 = 0.131 +- 0.219 (in-sample avg dev_std = 0.242)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.876
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.873
NEC for r=0.6 class 0.0 = 0.069 +- 0.168 (in-sample avg dev_std = 0.158)
NEC for r=0.6 class 1.0 = 0.055 +- 0.168 (in-sample avg dev_std = 0.158)
NEC for r=0.6 all KL = 0.057 +- 0.168 (in-sample avg dev_std = 0.158)
NEC for r=0.6 all L1 = 0.061 +- 0.155 (in-sample avg dev_std = 0.158)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.887
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.883
NEC for r=0.9 class 0.0 = 0.027 +- 0.091 (in-sample avg dev_std = 0.086)
NEC for r=0.9 class 1.0 = 0.013 +- 0.091 (in-sample avg dev_std = 0.086)
NEC for r=0.9 all KL = 0.015 +- 0.091 (in-sample avg dev_std = 0.086)
NEC for r=0.9 all L1 = 0.02 +- 0.089 (in-sample avg dev_std = 0.086)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.887
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.885
NEC for r=1.0 class 0.0 = 0.023 +- 0.085 (in-sample avg dev_std = 0.092)
NEC for r=1.0 class 1.0 = 0.014 +- 0.085 (in-sample avg dev_std = 0.092)
NEC for r=1.0 all KL = 0.014 +- 0.085 (in-sample avg dev_std = 0.092)
NEC for r=1.0 all L1 = 0.018 +- 0.084 (in-sample avg dev_std = 0.092)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.779
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.779
NEC for r=0.3 class 0.0 = 0.185 +- 0.284 (in-sample avg dev_std = 0.301)
NEC for r=0.3 class 1.0 = 0.113 +- 0.284 (in-sample avg dev_std = 0.301)
NEC for r=0.3 all KL = 0.178 +- 0.284 (in-sample avg dev_std = 0.301)
NEC for r=0.3 all L1 = 0.148 +- 0.229 (in-sample avg dev_std = 0.301)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.814
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.82
NEC for r=0.6 class 0.0 = 0.085 +- 0.179 (in-sample avg dev_std = 0.192)
NEC for r=0.6 class 1.0 = 0.047 +- 0.179 (in-sample avg dev_std = 0.192)
NEC for r=0.6 all KL = 0.068 +- 0.179 (in-sample avg dev_std = 0.192)
NEC for r=0.6 all L1 = 0.065 +- 0.159 (in-sample avg dev_std = 0.192)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.84
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.833
NEC for r=0.9 class 0.0 = 0.026 +- 0.099 (in-sample avg dev_std = 0.097)
NEC for r=0.9 class 1.0 = 0.018 +- 0.099 (in-sample avg dev_std = 0.097)
NEC for r=0.9 all KL = 0.018 +- 0.099 (in-sample avg dev_std = 0.097)
NEC for r=0.9 all L1 = 0.022 +- 0.092 (in-sample avg dev_std = 0.097)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.84
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.834
NEC for r=1.0 class 0.0 = 0.026 +- 0.098 (in-sample avg dev_std = 0.107)
NEC for r=1.0 class 1.0 = 0.017 +- 0.098 (in-sample avg dev_std = 0.107)
NEC for r=1.0 all KL = 0.017 +- 0.098 (in-sample avg dev_std = 0.107)
NEC for r=1.0 all L1 = 0.021 +- 0.090 (in-sample avg dev_std = 0.107)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 22:13:47 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 180...
[0m[1;37mINFO[0m: [1mCheckpoint 180: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0002
ID Validation ACCURACY: 0.9225
ID Validation Loss: 0.4107
ID Test ACCURACY: 0.9176
ID Test Loss: 0.4755
OOD Validation ACCURACY: 0.8817
OOD Validation Loss: 0.6167
OOD Test ACCURACY: 0.8206
OOD Test Loss: 1.3282

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 193...
[0m[1;37mINFO[0m: [1mCheckpoint 193: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0002
ID Validation ACCURACY: 0.9204
ID Validation Loss: 0.4402
ID Test ACCURACY: 0.9183
ID Test Loss: 0.5109
OOD Validation ACCURACY: 0.8846
OOD Validation Loss: 0.6529
OOD Test ACCURACY: 0.8255
OOD Test Loss: 1.3708

[0m[1;37mINFO[0m: [1mChartInfo 0.9176 0.8206 0.9183 0.8255 0.9204 0.8846[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 03/22/2024 10:13:48 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.814
SUFF++ for r=0.6 class 0.0 = 0.764 +- 0.339 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.6 class 1.0 = 0.845 +- 0.339 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.6 all KL = 0.645 +- 0.339 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.6 all L1 = 0.811 +- 0.204 (in-sample avg dev_std = 0.494)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.911
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.891
SUFF++ for r=0.9 class 0.0 = 0.946 +- 0.144 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.9 class 1.0 = 0.978 +- 0.144 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.9 all KL = 0.967 +- 0.144 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.9 all L1 = 0.964 +- 0.121 (in-sample avg dev_std = 0.133)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.82
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.738
SUFF++ for r=0.3 class 0.0 = 0.677 +- 0.323 (in-sample avg dev_std = 0.646)
SUFF++ for r=0.3 class 1.0 = 0.713 +- 0.323 (in-sample avg dev_std = 0.646)
SUFF++ for r=0.3 all KL = 0.472 +- 0.323 (in-sample avg dev_std = 0.646)
SUFF++ for r=0.3 all L1 = 0.696 +- 0.197 (in-sample avg dev_std = 0.646)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.869
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.818
SUFF++ for r=0.6 class 0.0 = 0.805 +- 0.321 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.6 class 1.0 = 0.833 +- 0.321 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.6 all KL = 0.665 +- 0.321 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.6 all L1 = 0.82 +- 0.189 (in-sample avg dev_std = 0.475)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.882
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.868
SUFF++ for r=0.9 class 0.0 = 0.926 +- 0.171 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 class 1.0 = 0.944 +- 0.171 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 all KL = 0.905 +- 0.171 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 all L1 = 0.935 +- 0.113 (in-sample avg dev_std = 0.271)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.785
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.708
SUFF++ for r=0.3 class 0.0 = 0.653 +- 0.324 (in-sample avg dev_std = 0.619)
SUFF++ for r=0.3 class 1.0 = 0.747 +- 0.324 (in-sample avg dev_std = 0.619)
SUFF++ for r=0.3 all KL = 0.488 +- 0.324 (in-sample avg dev_std = 0.619)
SUFF++ for r=0.3 all L1 = 0.702 +- 0.212 (in-sample avg dev_std = 0.619)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.82
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.777
SUFF++ for r=0.6 class 0.0 = 0.787 +- 0.330 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.6 class 1.0 = 0.865 +- 0.330 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.6 all KL = 0.686 +- 0.330 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.6 all L1 = 0.827 +- 0.197 (in-sample avg dev_std = 0.459)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.826
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.821
SUFF++ for r=0.9 class 0.0 = 0.933 +- 0.153 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.9 class 1.0 = 0.958 +- 0.153 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.9 all KL = 0.928 +- 0.153 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.9 all L1 = 0.946 +- 0.109 (in-sample avg dev_std = 0.236)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.875
NEC for r=0.6 class 0.0 = 0.118 +- 0.253 (in-sample avg dev_std = 0.186)
NEC for r=0.6 class 1.0 = 0.069 +- 0.253 (in-sample avg dev_std = 0.186)
NEC for r=0.6 all KL = 0.1 +- 0.253 (in-sample avg dev_std = 0.186)
NEC for r=0.6 all L1 = 0.089 +- 0.208 (in-sample avg dev_std = 0.186)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.905
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.88
NEC for r=0.9 class 0.0 = 0.057 +- 0.161 (in-sample avg dev_std = 0.107)
NEC for r=0.9 class 1.0 = 0.024 +- 0.161 (in-sample avg dev_std = 0.107)
NEC for r=0.9 all KL = 0.036 +- 0.161 (in-sample avg dev_std = 0.107)
NEC for r=0.9 all L1 = 0.038 +- 0.137 (in-sample avg dev_std = 0.107)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.905
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.88
NEC for r=1.0 class 0.0 = 0.057 +- 0.161 (in-sample avg dev_std = 0.107)
NEC for r=1.0 class 1.0 = 0.024 +- 0.161 (in-sample avg dev_std = 0.107)
NEC for r=1.0 all KL = 0.036 +- 0.161 (in-sample avg dev_std = 0.107)
NEC for r=1.0 all L1 = 0.038 +- 0.137 (in-sample avg dev_std = 0.107)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.82
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.809
NEC for r=0.3 class 0.0 = 0.204 +- 0.317 (in-sample avg dev_std = 0.294)
NEC for r=0.3 class 1.0 = 0.143 +- 0.317 (in-sample avg dev_std = 0.294)
NEC for r=0.3 all KL = 0.193 +- 0.317 (in-sample avg dev_std = 0.294)
NEC for r=0.3 all L1 = 0.172 +- 0.258 (in-sample avg dev_std = 0.294)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.869
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.859
NEC for r=0.6 class 0.0 = 0.097 +- 0.199 (in-sample avg dev_std = 0.202)
NEC for r=0.6 class 1.0 = 0.058 +- 0.199 (in-sample avg dev_std = 0.202)
NEC for r=0.6 all KL = 0.079 +- 0.199 (in-sample avg dev_std = 0.202)
NEC for r=0.6 all L1 = 0.076 +- 0.170 (in-sample avg dev_std = 0.202)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.882
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.876
NEC for r=0.9 class 0.0 = 0.022 +- 0.085 (in-sample avg dev_std = 0.085)
NEC for r=0.9 class 1.0 = 0.019 +- 0.085 (in-sample avg dev_std = 0.085)
NEC for r=0.9 all KL = 0.015 +- 0.085 (in-sample avg dev_std = 0.085)
NEC for r=0.9 all L1 = 0.02 +- 0.081 (in-sample avg dev_std = 0.085)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.88
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.876
NEC for r=1.0 class 0.0 = 0.019 +- 0.069 (in-sample avg dev_std = 0.070)
NEC for r=1.0 class 1.0 = 0.012 +- 0.069 (in-sample avg dev_std = 0.070)
NEC for r=1.0 all KL = 0.009 +- 0.069 (in-sample avg dev_std = 0.070)
NEC for r=1.0 all L1 = 0.015 +- 0.067 (in-sample avg dev_std = 0.070)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.785
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.768
NEC for r=0.3 class 0.0 = 0.228 +- 0.328 (in-sample avg dev_std = 0.333)
NEC for r=0.3 class 1.0 = 0.151 +- 0.328 (in-sample avg dev_std = 0.333)
NEC for r=0.3 all KL = 0.226 +- 0.328 (in-sample avg dev_std = 0.333)
NEC for r=0.3 all L1 = 0.188 +- 0.261 (in-sample avg dev_std = 0.333)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.82
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.813
NEC for r=0.6 class 0.0 = 0.104 +- 0.213 (in-sample avg dev_std = 0.227)
NEC for r=0.6 class 1.0 = 0.073 +- 0.213 (in-sample avg dev_std = 0.227)
NEC for r=0.6 all KL = 0.096 +- 0.213 (in-sample avg dev_std = 0.227)
NEC for r=0.6 all L1 = 0.088 +- 0.179 (in-sample avg dev_std = 0.227)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.826
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.824
NEC for r=0.9 class 0.0 = 0.036 +- 0.084 (in-sample avg dev_std = 0.106)
NEC for r=0.9 class 1.0 = 0.022 +- 0.084 (in-sample avg dev_std = 0.106)
NEC for r=0.9 all KL = 0.021 +- 0.084 (in-sample avg dev_std = 0.106)
NEC for r=0.9 all L1 = 0.029 +- 0.095 (in-sample avg dev_std = 0.106)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.825
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.825
NEC for r=1.0 class 0.0 = 0.024 +- 0.067 (in-sample avg dev_std = 0.083)
NEC for r=1.0 class 1.0 = 0.019 +- 0.067 (in-sample avg dev_std = 0.083)
NEC for r=1.0 all KL = 0.013 +- 0.067 (in-sample avg dev_std = 0.083)
NEC for r=1.0 all L1 = 0.021 +- 0.077 (in-sample avg dev_std = 0.083)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 22:17:09 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:10 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:10 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:10 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 175...
[0m[1;37mINFO[0m: [1mCheckpoint 175: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0002
ID Validation ACCURACY: 0.9208
ID Validation Loss: 0.4313
ID Test ACCURACY: 0.9178
ID Test Loss: 0.4948
OOD Validation ACCURACY: 0.8829
OOD Validation Loss: 0.6848
OOD Test ACCURACY: 0.8338
OOD Test Loss: 1.5415

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 183...
[0m[1;37mINFO[0m: [1mCheckpoint 183: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0002
ID Validation ACCURACY: 0.9178
ID Validation Loss: 0.4301
ID Test ACCURACY: 0.9166
ID Test Loss: 0.4923
OOD Validation ACCURACY: 0.8847
OOD Validation Loss: 0.6580
OOD Test ACCURACY: 0.8312
OOD Test Loss: 1.4830

[0m[1;37mINFO[0m: [1mChartInfo 0.9178 0.8338 0.9166 0.8312 0.9178 0.8847[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 03/22/2024 10:17:11 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.867
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.83
SUFF++ for r=0.6 class 0.0 = 0.84 +- 0.328 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.6 class 1.0 = 0.871 +- 0.328 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.6 all KL = 0.704 +- 0.328 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.6 all L1 = 0.858 +- 0.175 (in-sample avg dev_std = 0.450)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.878
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.859
SUFF++ for r=0.9 class 0.0 = 0.952 +- 0.141 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.9 class 1.0 = 0.978 +- 0.141 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.9 all KL = 0.97 +- 0.141 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.9 all L1 = 0.966 +- 0.120 (in-sample avg dev_std = 0.119)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.842
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.761
SUFF++ for r=0.3 class 0.0 = 0.779 +- 0.351 (in-sample avg dev_std = 0.608)
SUFF++ for r=0.3 class 1.0 = 0.73 +- 0.351 (in-sample avg dev_std = 0.608)
SUFF++ for r=0.3 all KL = 0.511 +- 0.351 (in-sample avg dev_std = 0.608)
SUFF++ for r=0.3 all L1 = 0.753 +- 0.199 (in-sample avg dev_std = 0.608)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.875
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.826
SUFF++ for r=0.6 class 0.0 = 0.819 +- 0.336 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.6 class 1.0 = 0.864 +- 0.336 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.6 all KL = 0.676 +- 0.336 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.6 all L1 = 0.843 +- 0.180 (in-sample avg dev_std = 0.461)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.884
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.874
SUFF++ for r=0.9 class 0.0 = 0.932 +- 0.159 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.9 class 1.0 = 0.964 +- 0.159 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.9 all KL = 0.926 +- 0.159 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.9 all L1 = 0.949 +- 0.111 (in-sample avg dev_std = 0.228)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.791
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.722
SUFF++ for r=0.3 class 0.0 = 0.714 +- 0.340 (in-sample avg dev_std = 0.588)
SUFF++ for r=0.3 class 1.0 = 0.723 +- 0.340 (in-sample avg dev_std = 0.588)
SUFF++ for r=0.3 all KL = 0.495 +- 0.340 (in-sample avg dev_std = 0.588)
SUFF++ for r=0.3 all L1 = 0.718 +- 0.217 (in-sample avg dev_std = 0.588)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.825
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.798
SUFF++ for r=0.6 class 0.0 = 0.809 +- 0.339 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.6 class 1.0 = 0.849 +- 0.339 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.6 all KL = 0.682 +- 0.339 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.6 all L1 = 0.829 +- 0.204 (in-sample avg dev_std = 0.446)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.85
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.843
SUFF++ for r=0.9 class 0.0 = 0.939 +- 0.159 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 class 1.0 = 0.961 +- 0.159 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 all KL = 0.93 +- 0.159 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 all L1 = 0.95 +- 0.106 (in-sample avg dev_std = 0.222)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.867
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.853
NEC for r=0.6 class 0.0 = 0.088 +- 0.223 (in-sample avg dev_std = 0.181)
NEC for r=0.6 class 1.0 = 0.058 +- 0.223 (in-sample avg dev_std = 0.181)
NEC for r=0.6 all KL = 0.083 +- 0.223 (in-sample avg dev_std = 0.181)
NEC for r=0.6 all L1 = 0.07 +- 0.178 (in-sample avg dev_std = 0.181)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.881
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.864
NEC for r=0.9 class 0.0 = 0.044 +- 0.147 (in-sample avg dev_std = 0.105)
NEC for r=0.9 class 1.0 = 0.03 +- 0.147 (in-sample avg dev_std = 0.105)
NEC for r=0.9 all KL = 0.032 +- 0.147 (in-sample avg dev_std = 0.105)
NEC for r=0.9 all L1 = 0.036 +- 0.128 (in-sample avg dev_std = 0.105)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.881
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.864
NEC for r=1.0 class 0.0 = 0.044 +- 0.147 (in-sample avg dev_std = 0.105)
NEC for r=1.0 class 1.0 = 0.03 +- 0.147 (in-sample avg dev_std = 0.105)
NEC for r=1.0 all KL = 0.032 +- 0.147 (in-sample avg dev_std = 0.105)
NEC for r=1.0 all L1 = 0.036 +- 0.128 (in-sample avg dev_std = 0.105)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.842
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.837
NEC for r=0.3 class 0.0 = 0.123 +- 0.289 (in-sample avg dev_std = 0.282)
NEC for r=0.3 class 1.0 = 0.112 +- 0.289 (in-sample avg dev_std = 0.282)
NEC for r=0.3 all KL = 0.147 +- 0.289 (in-sample avg dev_std = 0.282)
NEC for r=0.3 all L1 = 0.117 +- 0.217 (in-sample avg dev_std = 0.282)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.875
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.873
NEC for r=0.6 class 0.0 = 0.085 +- 0.213 (in-sample avg dev_std = 0.202)
NEC for r=0.6 class 1.0 = 0.058 +- 0.213 (in-sample avg dev_std = 0.202)
NEC for r=0.6 all KL = 0.08 +- 0.213 (in-sample avg dev_std = 0.202)
NEC for r=0.6 all L1 = 0.071 +- 0.174 (in-sample avg dev_std = 0.202)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.884
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.882
NEC for r=0.9 class 0.0 = 0.028 +- 0.091 (in-sample avg dev_std = 0.091)
NEC for r=0.9 class 1.0 = 0.014 +- 0.091 (in-sample avg dev_std = 0.091)
NEC for r=0.9 all KL = 0.018 +- 0.091 (in-sample avg dev_std = 0.091)
NEC for r=0.9 all L1 = 0.02 +- 0.084 (in-sample avg dev_std = 0.091)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.884
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.884
NEC for r=1.0 class 0.0 = 0.019 +- 0.065 (in-sample avg dev_std = 0.066)
NEC for r=1.0 class 1.0 = 0.011 +- 0.065 (in-sample avg dev_std = 0.066)
NEC for r=1.0 all KL = 0.011 +- 0.065 (in-sample avg dev_std = 0.066)
NEC for r=1.0 all L1 = 0.015 +- 0.071 (in-sample avg dev_std = 0.066)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.791
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.786
NEC for r=0.3 class 0.0 = 0.204 +- 0.312 (in-sample avg dev_std = 0.313)
NEC for r=0.3 class 1.0 = 0.138 +- 0.312 (in-sample avg dev_std = 0.313)
NEC for r=0.3 all KL = 0.204 +- 0.312 (in-sample avg dev_std = 0.313)
NEC for r=0.3 all L1 = 0.17 +- 0.249 (in-sample avg dev_std = 0.313)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.825
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.829
NEC for r=0.6 class 0.0 = 0.108 +- 0.225 (in-sample avg dev_std = 0.242)
NEC for r=0.6 class 1.0 = 0.074 +- 0.225 (in-sample avg dev_std = 0.242)
NEC for r=0.6 all KL = 0.106 +- 0.225 (in-sample avg dev_std = 0.242)
NEC for r=0.6 all L1 = 0.091 +- 0.183 (in-sample avg dev_std = 0.242)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.85
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.848
NEC for r=0.9 class 0.0 = 0.033 +- 0.082 (in-sample avg dev_std = 0.108)
NEC for r=0.9 class 1.0 = 0.022 +- 0.082 (in-sample avg dev_std = 0.108)
NEC for r=0.9 all KL = 0.02 +- 0.082 (in-sample avg dev_std = 0.108)
NEC for r=0.9 all L1 = 0.027 +- 0.086 (in-sample avg dev_std = 0.108)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.849
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.847
NEC for r=1.0 class 0.0 = 0.022 +- 0.059 (in-sample avg dev_std = 0.079)
NEC for r=1.0 class 1.0 = 0.015 +- 0.059 (in-sample avg dev_std = 0.079)
NEC for r=1.0 all KL = 0.011 +- 0.059 (in-sample avg dev_std = 0.079)
NEC for r=1.0 all L1 = 0.018 +- 0.067 (in-sample avg dev_std = 0.079)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.692, 0.98, 1.0], 'all_L1': [0.842, 0.977, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.749, 0.978, 1.0], 'all_L1': [0.863, 0.973, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.71, 0.977, 1.0], 'all_L1': [0.859, 0.975, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.645, 0.967, 1.0], 'all_L1': [0.811, 0.964, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.704, 0.97, 1.0], 'all_L1': [0.858, 0.966, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.096, 0.021, 0.021], 'all_L1': [0.075, 0.025, 0.025]}), defaultdict(<class 'list'>, {'all_KL': [0.067, 0.027, 0.027], 'all_L1': [0.06, 0.028, 0.028]}), defaultdict(<class 'list'>, {'all_KL': [0.072, 0.029, 0.029], 'all_L1': [0.067, 0.03, 0.03]}), defaultdict(<class 'list'>, {'all_KL': [0.1, 0.036, 0.036], 'all_L1': [0.089, 0.038, 0.038]}), defaultdict(<class 'list'>, {'all_KL': [0.083, 0.032, 0.032], 'all_L1': [0.07, 0.036, 0.036]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.465, 0.722, 0.928, 1.0], 'all_L1': [0.72, 0.85, 0.947, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.656, 0.773, 0.914, 1.0], 'all_L1': [0.789, 0.862, 0.94, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.652, 0.743, 0.904, 1.0], 'all_L1': [0.789, 0.857, 0.936, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.472, 0.665, 0.905, 1.0], 'all_L1': [0.696, 0.82, 0.935, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.511, 0.676, 0.926, 1.0], 'all_L1': [0.753, 0.843, 0.949, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.179, 0.086, 0.018, 0.013], 'all_L1': [0.146, 0.074, 0.022, 0.018]}), defaultdict(<class 'list'>, {'all_KL': [0.142, 0.059, 0.017, 0.016], 'all_L1': [0.128, 0.062, 0.024, 0.022]}), defaultdict(<class 'list'>, {'all_KL': [0.143, 0.057, 0.015, 0.014], 'all_L1': [0.131, 0.061, 0.02, 0.018]}), defaultdict(<class 'list'>, {'all_KL': [0.193, 0.079, 0.015, 0.009], 'all_L1': [0.172, 0.076, 0.02, 0.015]}), defaultdict(<class 'list'>, {'all_KL': [0.147, 0.08, 0.018, 0.011], 'all_L1': [0.117, 0.071, 0.02, 0.015]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.545, 0.748, 0.931, 1.0], 'all_L1': [0.764, 0.857, 0.946, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.672, 0.783, 0.936, 1.0], 'all_L1': [0.802, 0.865, 0.952, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.642, 0.747, 0.921, 1.0], 'all_L1': [0.784, 0.857, 0.949, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.488, 0.686, 0.928, 1.0], 'all_L1': [0.702, 0.827, 0.946, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.495, 0.682, 0.93, 1.0], 'all_L1': [0.718, 0.829, 0.95, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.182, 0.091, 0.025, 0.017], 'all_L1': [0.143, 0.079, 0.032, 0.023]}), defaultdict(<class 'list'>, {'all_KL': [0.167, 0.077, 0.024, 0.021], 'all_L1': [0.137, 0.073, 0.031, 0.027]}), defaultdict(<class 'list'>, {'all_KL': [0.178, 0.068, 0.018, 0.017], 'all_L1': [0.148, 0.065, 0.022, 0.021]}), defaultdict(<class 'list'>, {'all_KL': [0.226, 0.096, 0.021, 0.013], 'all_L1': [0.188, 0.088, 0.029, 0.021]}), defaultdict(<class 'list'>, {'all_KL': [0.204, 0.106, 0.02, 0.011], 'all_L1': [0.17, 0.091, 0.027, 0.018]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.847 +- 0.019, 0.971 +- 0.005, 1.000 +- 0.000
suff++ class all_KL  =  0.700 +- 0.033, 0.974 +- 0.005, 1.000 +- 0.000
suff++_acc_int  =  0.833 +- 0.011, 0.874 +- 0.011
nec class all_L1  =  0.072 +- 0.010, 0.031 +- 0.005, 0.031 +- 0.005
nec class all_KL  =  0.084 +- 0.013, 0.029 +- 0.005, 0.029 +- 0.005
nec_acc_int  =  0.865 +- 0.008, 0.872 +- 0.006, 0.872 +- 0.006

Eval split val
suff++ class all_L1  =  0.749 +- 0.037, 0.846 +- 0.015, 0.941 +- 0.006, 1.000 +- 0.000
suff++ class all_KL  =  0.551 +- 0.085, 0.716 +- 0.041, 0.915 +- 0.010, 1.000 +- 0.000
suff++_acc_int  =  0.759 +- 0.014, 0.831 +- 0.008, 0.875 +- 0.005
nec class all_L1  =  0.139 +- 0.019, 0.069 +- 0.006, 0.021 +- 0.002, 0.018 +- 0.003
nec class all_KL  =  0.161 +- 0.021, 0.072 +- 0.012, 0.017 +- 0.001, 0.013 +- 0.002
nec_acc_int  =  0.816 +- 0.015, 0.868 +- 0.005, 0.881 +- 0.004, 0.882 +- 0.004

Eval split test
suff++ class all_L1  =  0.754 +- 0.038, 0.847 +- 0.016, 0.949 +- 0.002, 1.000 +- 0.000
suff++ class all_KL  =  0.568 +- 0.076, 0.729 +- 0.039, 0.929 +- 0.005, 1.000 +- 0.000
suff++_acc_int  =  0.733 +- 0.016, 0.794 +- 0.009, 0.834 +- 0.009
nec class all_L1  =  0.157 +- 0.019, 0.079 +- 0.010, 0.028 +- 0.004, 0.022 +- 0.003
nec class all_KL  =  0.191 +- 0.021, 0.088 +- 0.014, 0.022 +- 0.003, 0.016 +- 0.003
nec_acc_int  =  0.778 +- 0.009, 0.822 +- 0.006, 0.838 +- 0.009, 0.839 +- 0.009


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.459 +- 0.005, 0.501 +- 0.001, 0.516 +- 0.002
Faith. Armon (L1)= 		  =  0.133 +- 0.016, 0.061 +- 0.009, 0.061 +- 0.009
Faith. GMean (L1)= 	  =  0.246 +- 0.014, 0.174 +- 0.013, 0.177 +- 0.014
Faith. Aritm (KL)= 		  =  0.392 +- 0.011, 0.502 +- 0.001, 0.515 +- 0.003
Faith. Armon (KL)= 		  =  0.149 +- 0.020, 0.056 +- 0.009, 0.056 +- 0.009
Faith. GMean (KL)= 	  =  0.241 +- 0.014, 0.167 +- 0.014, 0.170 +- 0.015

Eval split val
Faith. Aritm (L1)= 		  =  0.444 +- 0.012, 0.458 +- 0.005, 0.481 +- 0.003, 0.509 +- 0.001
Faith. Armon (L1)= 		  =  0.233 +- 0.025, 0.127 +- 0.010, 0.041 +- 0.003, 0.035 +- 0.005
Faith. GMean (L1)= 	  =  0.321 +- 0.016, 0.241 +- 0.009, 0.141 +- 0.005, 0.132 +- 0.010
Faith. Aritm (KL)= 		  =  0.356 +- 0.035, 0.394 +- 0.016, 0.466 +- 0.006, 0.506 +- 0.001
Faith. Armon (KL)= 		  =  0.246 +- 0.018, 0.131 +- 0.019, 0.033 +- 0.003, 0.025 +- 0.005
Faith. GMean (KL)= 	  =  0.295 +- 0.012, 0.226 +- 0.015, 0.123 +- 0.006, 0.112 +- 0.011

Eval split test
Faith. Aritm (L1)= 		  =  0.456 +- 0.011, 0.463 +- 0.005, 0.488 +- 0.002, 0.511 +- 0.001
Faith. Armon (L1)= 		  =  0.259 +- 0.023, 0.145 +- 0.016, 0.055 +- 0.007, 0.043 +- 0.006
Faith. GMean (L1)= 	  =  0.343 +- 0.012, 0.258 +- 0.014, 0.163 +- 0.011, 0.148 +- 0.010
Faith. Aritm (KL)= 		  =  0.380 +- 0.029, 0.408 +- 0.015, 0.475 +- 0.004, 0.508 +- 0.002
Faith. Armon (KL)= 		  =  0.283 +- 0.015, 0.156 +- 0.021, 0.042 +- 0.005, 0.031 +- 0.007
Faith. GMean (KL)= 	  =  0.328 +- 0.009, 0.251 +- 0.015, 0.141 +- 0.009, 0.125 +- 0.014
Computed for split load_split = id



Completed in  0:16:52.216808  for LECIvGIN GOODSST2/length



DONE LECI GOODSST2/length

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 22:20:52 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 03/22/2024 10:20:53 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 10:20:53 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 10:20:53 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/22/2024 10:20:53 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 10:20:53 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:20:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:20:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:20:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:20:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:20:53 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/22/2024 10:20:53 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:20:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:20:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:20:53 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/22/2024 10:20:53 PM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 03/22/2024 10:20:53 PM : [1mInit Backbone:  3
[0m[1;34mDEBUG[0m: 03/22/2024 10:20:53 PM : [1mCreating vGINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 10:20:53 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:20:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:20:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:20:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:20:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:20:53 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:20:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:20:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:20:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:20:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:20:53 PM : [1mInit CLF:  3
[0m[1;34mDEBUG[0m: 03/22/2024 10:20:53 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:20:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:20:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:20:53 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:20:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:20:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:20:53 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 148...
[0m[1;37mINFO[0m: [1mCheckpoint 148: 
-----------------------------------
Train ACCURACY: 0.9479
Train Loss: 0.0807
ID Validation ACCURACY: 0.8570
ID Validation Loss: 0.6526
ID Test ACCURACY: 0.8504
ID Test Loss: 0.7123
OOD Validation ACCURACY: 0.8377
OOD Validation Loss: 0.8949
OOD Test ACCURACY: 0.7398
OOD Test Loss: 1.5170

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 71...
[0m[1;37mINFO[0m: [1mCheckpoint 71: 
-----------------------------------
Train ACCURACY: 0.9165
Train Loss: 0.1472
ID Validation ACCURACY: 0.8142
ID Validation Loss: 0.7736
ID Test ACCURACY: 0.8114
ID Test Loss: 0.8563
OOD Validation ACCURACY: 0.8439
OOD Validation Loss: 0.7952
OOD Test ACCURACY: 0.8108
OOD Test Loss: 0.9714

[0m[1;37mINFO[0m: [1mChartInfo 0.8504 0.7398 0.8114 0.8108 0.8142 0.8439[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 03/22/2024 10:20:54 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.8 = nan
WIoU for r=0.8 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.8 = nan
WIoU for r=0.8 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.8 = nan
WIoU for r=0.8 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.867
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 285
Effective ratio: 0.796 +- 0.301
Model Accuracy over intervened graphs for r=0.8 =  0.841
SUFF++ for r=0.8 class 0.0 = 0.839 +- 0.217 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.8 class 1.0 = 0.936 +- 0.217 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.8 all KL = 0.866 +- 0.217 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.8 all L1 = 0.895 +- 0.165 (in-sample avg dev_std = 0.281)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.841
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.824 +- 0.019
Model Accuracy over intervened graphs for r=0.8 =  0.813
SUFF++ for r=0.8 class 0.0 = 0.814 +- 0.196 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.8 class 1.0 = 0.943 +- 0.196 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.8 all KL = 0.871 +- 0.196 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.8 all L1 = 0.881 +- 0.176 (in-sample avg dev_std = 0.262)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.741
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.810 +- 0.008
Model Accuracy over intervened graphs for r=0.8 =  0.693
SUFF++ for r=0.8 class 0.0 = 0.776 +- 0.195 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.8 class 1.0 = 0.963 +- 0.195 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.8 all KL = 0.879 +- 0.195 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.8 all L1 = 0.872 +- 0.189 (in-sample avg dev_std = 0.249)


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.867
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 285
Effective ratio: 0.796 +- 0.301
Model Accuracy over intervened graphs for r=0.8 =  0.862
NEC for r=0.8 class 0.0 = 0.118 +- 0.172 (in-sample avg dev_std = 0.155)
NEC for r=0.8 class 1.0 = 0.05 +- 0.172 (in-sample avg dev_std = 0.155)
NEC for r=0.8 all KL = 0.071 +- 0.172 (in-sample avg dev_std = 0.155)
NEC for r=0.8 all L1 = 0.078 +- 0.156 (in-sample avg dev_std = 0.155)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.841
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.824 +- 0.019
Model Accuracy over intervened graphs for r=0.8 =  0.817
NEC for r=0.8 class 0.0 = 0.125 +- 0.139 (in-sample avg dev_std = 0.169)
NEC for r=0.8 class 1.0 = 0.038 +- 0.139 (in-sample avg dev_std = 0.169)
NEC for r=0.8 all KL = 0.061 +- 0.139 (in-sample avg dev_std = 0.169)
NEC for r=0.8 all L1 = 0.079 +- 0.149 (in-sample avg dev_std = 0.169)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.741
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.810 +- 0.008
Model Accuracy over intervened graphs for r=0.8 =  0.722
NEC for r=0.8 class 0.0 = 0.165 +- 0.149 (in-sample avg dev_std = 0.182)
NEC for r=0.8 class 1.0 = 0.03 +- 0.149 (in-sample avg dev_std = 0.182)
NEC for r=0.8 all KL = 0.071 +- 0.149 (in-sample avg dev_std = 0.182)
NEC for r=0.8 all L1 = 0.096 +- 0.163 (in-sample avg dev_std = 0.182)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 22:22:02 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 03/22/2024 10:22:04 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 10:22:04 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 10:22:04 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/22/2024 10:22:04 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 10:22:04 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:22:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:22:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:22:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:22:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:22:04 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/22/2024 10:22:04 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:22:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:22:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:22:04 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/22/2024 10:22:04 PM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 03/22/2024 10:22:04 PM : [1mInit Backbone:  3
[0m[1;34mDEBUG[0m: 03/22/2024 10:22:04 PM : [1mCreating vGINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 10:22:04 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:22:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:22:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:22:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:22:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:22:04 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:22:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:22:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:22:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:22:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:22:04 PM : [1mInit CLF:  3
[0m[1;34mDEBUG[0m: 03/22/2024 10:22:04 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:22:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:22:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:22:04 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:22:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:22:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:22:04 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 160...
[0m[1;37mINFO[0m: [1mCheckpoint 160: 
-----------------------------------
Train ACCURACY: 0.9487
Train Loss: 0.0768
ID Validation ACCURACY: 0.8587
ID Validation Loss: 0.7200
ID Test ACCURACY: 0.8551
ID Test Loss: 0.8849
OOD Validation ACCURACY: 0.8472
OOD Validation Loss: 1.0741
OOD Test ACCURACY: 0.7967
OOD Test Loss: 1.3148

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 162...
[0m[1;37mINFO[0m: [1mCheckpoint 162: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0760
ID Validation ACCURACY: 0.8581
ID Validation Loss: 0.7569
ID Test ACCURACY: 0.8551
ID Test Loss: 0.9395
OOD Validation ACCURACY: 0.8551
OOD Validation Loss: 1.0513
OOD Test ACCURACY: 0.8051
OOD Test Loss: 1.2667

[0m[1;37mINFO[0m: [1mChartInfo 0.8551 0.7967 0.8551 0.8051 0.8581 0.8551[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 03/22/2024 10:22:04 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.8 = nan
WIoU for r=0.8 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.8 = nan
WIoU for r=0.8 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.8 = nan
WIoU for r=0.8 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.867
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 285
Effective ratio: 0.796 +- 0.301
Model Accuracy over intervened graphs for r=0.8 =  0.85
SUFF++ for r=0.8 class 0.0 = 0.931 +- 0.223 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.8 class 1.0 = 0.884 +- 0.223 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.8 all KL = 0.866 +- 0.223 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.8 all L1 = 0.903 +- 0.173 (in-sample avg dev_std = 0.269)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.86
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.824 +- 0.019
Model Accuracy over intervened graphs for r=0.8 =  0.834
SUFF++ for r=0.8 class 0.0 = 0.944 +- 0.191 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.8 class 1.0 = 0.859 +- 0.191 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.8 all KL = 0.887 +- 0.191 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.8 all L1 = 0.9 +- 0.166 (in-sample avg dev_std = 0.241)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.811
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.810 +- 0.008
Model Accuracy over intervened graphs for r=0.8 =  0.793
SUFF++ for r=0.8 class 0.0 = 0.919 +- 0.179 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.8 class 1.0 = 0.83 +- 0.179 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.8 all KL = 0.883 +- 0.179 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.8 all L1 = 0.873 +- 0.186 (in-sample avg dev_std = 0.247)


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.867
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 285
Effective ratio: 0.796 +- 0.301
Model Accuracy over intervened graphs for r=0.8 =  0.84
NEC for r=0.8 class 0.0 = 0.06 +- 0.212 (in-sample avg dev_std = 0.198)
NEC for r=0.8 class 1.0 = 0.115 +- 0.212 (in-sample avg dev_std = 0.198)
NEC for r=0.8 all KL = 0.098 +- 0.212 (in-sample avg dev_std = 0.198)
NEC for r=0.8 all L1 = 0.092 +- 0.188 (in-sample avg dev_std = 0.198)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.86
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.824 +- 0.019
Model Accuracy over intervened graphs for r=0.8 =  0.849
NEC for r=0.8 class 0.0 = 0.049 +- 0.155 (in-sample avg dev_std = 0.164)
NEC for r=0.8 class 1.0 = 0.101 +- 0.155 (in-sample avg dev_std = 0.164)
NEC for r=0.8 all KL = 0.066 +- 0.155 (in-sample avg dev_std = 0.164)
NEC for r=0.8 all L1 = 0.076 +- 0.154 (in-sample avg dev_std = 0.164)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.811
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.810 +- 0.008
Model Accuracy over intervened graphs for r=0.8 =  0.802
NEC for r=0.8 class 0.0 = 0.072 +- 0.176 (in-sample avg dev_std = 0.201)
NEC for r=0.8 class 1.0 = 0.138 +- 0.176 (in-sample avg dev_std = 0.201)
NEC for r=0.8 all KL = 0.087 +- 0.176 (in-sample avg dev_std = 0.201)
NEC for r=0.8 all L1 = 0.106 +- 0.181 (in-sample avg dev_std = 0.201)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 22:23:12 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 03/22/2024 10:23:13 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 10:23:13 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 10:23:13 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/22/2024 10:23:13 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 10:23:13 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:23:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:23:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:23:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:23:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:23:13 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/22/2024 10:23:13 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:23:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:23:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:23:13 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/22/2024 10:23:13 PM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 03/22/2024 10:23:13 PM : [1mInit Backbone:  3
[0m[1;34mDEBUG[0m: 03/22/2024 10:23:13 PM : [1mCreating vGINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 10:23:13 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:23:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:23:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:23:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:23:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:23:13 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:23:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:23:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:23:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:23:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:23:13 PM : [1mInit CLF:  3
[0m[1;34mDEBUG[0m: 03/22/2024 10:23:13 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:23:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:23:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:23:13 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:23:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:23:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:23:14 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 149...
[0m[1;37mINFO[0m: [1mCheckpoint 149: 
-----------------------------------
Train ACCURACY: 0.9479
Train Loss: 0.0798
ID Validation ACCURACY: 0.8600
ID Validation Loss: 0.6948
ID Test ACCURACY: 0.8576
ID Test Loss: 0.7845
OOD Validation ACCURACY: 0.8474
OOD Validation Loss: 1.0437
OOD Test ACCURACY: 0.8045
OOD Test Loss: 1.1397

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 140...
[0m[1;37mINFO[0m: [1mCheckpoint 140: 
-----------------------------------
Train ACCURACY: 0.9461
Train Loss: 0.0840
ID Validation ACCURACY: 0.8459
ID Validation Loss: 0.7816
ID Test ACCURACY: 0.8498
ID Test Loss: 0.8524
OOD Validation ACCURACY: 0.8581
OOD Validation Loss: 0.9137
OOD Test ACCURACY: 0.8097
OOD Test Loss: 1.0383

[0m[1;37mINFO[0m: [1mChartInfo 0.8576 0.8045 0.8498 0.8097 0.8459 0.8581[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 03/22/2024 10:23:14 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.8 = nan
WIoU for r=0.8 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.8 = nan
WIoU for r=0.8 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.8 = nan
WIoU for r=0.8 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.867
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 285
Effective ratio: 0.796 +- 0.301
Model Accuracy over intervened graphs for r=0.8 =  0.846
SUFF++ for r=0.8 class 0.0 = 0.933 +- 0.251 (in-sample avg dev_std = 0.306)
SUFF++ for r=0.8 class 1.0 = 0.869 +- 0.251 (in-sample avg dev_std = 0.306)
SUFF++ for r=0.8 all KL = 0.84 +- 0.251 (in-sample avg dev_std = 0.306)
SUFF++ for r=0.8 all L1 = 0.896 +- 0.173 (in-sample avg dev_std = 0.306)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.849
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.824 +- 0.019
Model Accuracy over intervened graphs for r=0.8 =  0.836
SUFF++ for r=0.8 class 0.0 = 0.94 +- 0.191 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.8 class 1.0 = 0.861 +- 0.191 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.8 all KL = 0.885 +- 0.191 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.8 all L1 = 0.899 +- 0.172 (in-sample avg dev_std = 0.249)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.821
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.810 +- 0.008
Model Accuracy over intervened graphs for r=0.8 =  0.794
SUFF++ for r=0.8 class 0.0 = 0.922 +- 0.173 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.8 class 1.0 = 0.836 +- 0.173 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.8 all KL = 0.891 +- 0.173 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.8 all L1 = 0.878 +- 0.183 (in-sample avg dev_std = 0.227)


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.867
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 285
Effective ratio: 0.796 +- 0.301
Model Accuracy over intervened graphs for r=0.8 =  0.86
NEC for r=0.8 class 0.0 = 0.065 +- 0.186 (in-sample avg dev_std = 0.193)
NEC for r=0.8 class 1.0 = 0.077 +- 0.186 (in-sample avg dev_std = 0.193)
NEC for r=0.8 all KL = 0.078 +- 0.186 (in-sample avg dev_std = 0.193)
NEC for r=0.8 all L1 = 0.072 +- 0.156 (in-sample avg dev_std = 0.193)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.849
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.824 +- 0.019
Model Accuracy over intervened graphs for r=0.8 =  0.849
NEC for r=0.8 class 0.0 = 0.051 +- 0.156 (in-sample avg dev_std = 0.177)
NEC for r=0.8 class 1.0 = 0.089 +- 0.156 (in-sample avg dev_std = 0.177)
NEC for r=0.8 all KL = 0.062 +- 0.156 (in-sample avg dev_std = 0.177)
NEC for r=0.8 all L1 = 0.07 +- 0.148 (in-sample avg dev_std = 0.177)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.821
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.810 +- 0.008
Model Accuracy over intervened graphs for r=0.8 =  0.811
NEC for r=0.8 class 0.0 = 0.072 +- 0.169 (in-sample avg dev_std = 0.200)
NEC for r=0.8 class 1.0 = 0.134 +- 0.169 (in-sample avg dev_std = 0.200)
NEC for r=0.8 all KL = 0.085 +- 0.169 (in-sample avg dev_std = 0.200)
NEC for r=0.8 all L1 = 0.104 +- 0.172 (in-sample avg dev_std = 0.200)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 22:24:25 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 03/22/2024 10:24:26 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 10:24:26 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 10:24:26 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/22/2024 10:24:26 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 10:24:26 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:24:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:24:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:24:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:24:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:24:26 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/22/2024 10:24:26 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:24:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:24:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:24:26 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/22/2024 10:24:26 PM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 03/22/2024 10:24:26 PM : [1mInit Backbone:  3
[0m[1;34mDEBUG[0m: 03/22/2024 10:24:26 PM : [1mCreating vGINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 10:24:26 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:24:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:24:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:24:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:24:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:24:26 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:24:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:24:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:24:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:24:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:24:26 PM : [1mInit CLF:  3
[0m[1;34mDEBUG[0m: 03/22/2024 10:24:26 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:24:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:24:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:24:26 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:24:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:24:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:24:26 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 113...
[0m[1;37mINFO[0m: [1mCheckpoint 113: 
-----------------------------------
Train ACCURACY: 0.9483
Train Loss: 0.0792
ID Validation ACCURACY: 0.8604
ID Validation Loss: 0.6685
ID Test ACCURACY: 0.8570
ID Test Loss: 0.7609
OOD Validation ACCURACY: 0.8537
OOD Validation Loss: 0.9443
OOD Test ACCURACY: 0.8069
OOD Test Loss: 1.0629

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 114...
[0m[1;37mINFO[0m: [1mCheckpoint 114: 
-----------------------------------
Train ACCURACY: 0.9462
Train Loss: 0.0915
ID Validation ACCURACY: 0.8478
ID Validation Loss: 0.6421
ID Test ACCURACY: 0.8480
ID Test Loss: 0.7499
OOD Validation ACCURACY: 0.8555
OOD Validation Loss: 0.7389
OOD Test ACCURACY: 0.8109
OOD Test Loss: 0.7657

[0m[1;37mINFO[0m: [1mChartInfo 0.8570 0.8069 0.8480 0.8109 0.8478 0.8555[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 03/22/2024 10:24:27 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.8 = nan
WIoU for r=0.8 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.8 = nan
WIoU for r=0.8 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.8 = nan
WIoU for r=0.8 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.874
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 285
Effective ratio: 0.796 +- 0.301
Model Accuracy over intervened graphs for r=0.8 =  0.847
SUFF++ for r=0.8 class 0.0 = 0.94 +- 0.178 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.8 class 1.0 = 0.895 +- 0.178 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.8 all KL = 0.908 +- 0.178 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.8 all L1 = 0.914 +- 0.156 (in-sample avg dev_std = 0.239)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.86
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.824 +- 0.019
Model Accuracy over intervened graphs for r=0.8 =  0.842
SUFF++ for r=0.8 class 0.0 = 0.943 +- 0.144 (in-sample avg dev_std = 0.199)
SUFF++ for r=0.8 class 1.0 = 0.893 +- 0.144 (in-sample avg dev_std = 0.199)
SUFF++ for r=0.8 all KL = 0.928 +- 0.144 (in-sample avg dev_std = 0.199)
SUFF++ for r=0.8 all L1 = 0.917 +- 0.148 (in-sample avg dev_std = 0.199)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.824
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.810 +- 0.008
Model Accuracy over intervened graphs for r=0.8 =  0.814
SUFF++ for r=0.8 class 0.0 = 0.932 +- 0.129 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.8 class 1.0 = 0.874 +- 0.129 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.8 all KL = 0.93 +- 0.129 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.8 all L1 = 0.902 +- 0.148 (in-sample avg dev_std = 0.191)


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.874
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 285
Effective ratio: 0.796 +- 0.301
Model Accuracy over intervened graphs for r=0.8 =  0.846
NEC for r=0.8 class 0.0 = 0.066 +- 0.190 (in-sample avg dev_std = 0.175)
NEC for r=0.8 class 1.0 = 0.105 +- 0.190 (in-sample avg dev_std = 0.175)
NEC for r=0.8 all KL = 0.081 +- 0.190 (in-sample avg dev_std = 0.175)
NEC for r=0.8 all L1 = 0.089 +- 0.174 (in-sample avg dev_std = 0.175)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.86
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.824 +- 0.019
Model Accuracy over intervened graphs for r=0.8 =  0.852
NEC for r=0.8 class 0.0 = 0.058 +- 0.138 (in-sample avg dev_std = 0.166)
NEC for r=0.8 class 1.0 = 0.079 +- 0.138 (in-sample avg dev_std = 0.166)
NEC for r=0.8 all KL = 0.053 +- 0.138 (in-sample avg dev_std = 0.166)
NEC for r=0.8 all L1 = 0.069 +- 0.144 (in-sample avg dev_std = 0.166)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.824
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.810 +- 0.008
Model Accuracy over intervened graphs for r=0.8 =  0.825
NEC for r=0.8 class 0.0 = 0.08 +- 0.154 (in-sample avg dev_std = 0.188)
NEC for r=0.8 class 1.0 = 0.117 +- 0.154 (in-sample avg dev_std = 0.188)
NEC for r=0.8 all KL = 0.073 +- 0.154 (in-sample avg dev_std = 0.188)
NEC for r=0.8 all L1 = 0.099 +- 0.164 (in-sample avg dev_std = 0.188)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 22:25:38 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 03/22/2024 10:25:39 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 10:25:39 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 10:25:39 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/22/2024 10:25:39 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 10:25:39 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:25:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:25:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:25:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:25:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:25:39 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/22/2024 10:25:39 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:25:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:25:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:25:39 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/22/2024 10:25:39 PM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 03/22/2024 10:25:39 PM : [1mInit Backbone:  3
[0m[1;34mDEBUG[0m: 03/22/2024 10:25:39 PM : [1mCreating vGINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 10:25:39 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:25:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:25:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:25:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:25:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:25:39 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:25:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:25:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:25:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:25:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:25:39 PM : [1mInit CLF:  3
[0m[1;34mDEBUG[0m: 03/22/2024 10:25:39 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:25:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:25:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:25:39 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:25:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:25:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:25:39 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 144...
[0m[1;37mINFO[0m: [1mCheckpoint 144: 
-----------------------------------
Train ACCURACY: 0.9443
Train Loss: 0.0872
ID Validation ACCURACY: 0.8447
ID Validation Loss: 0.7583
ID Test ACCURACY: 0.8393
ID Test Loss: 0.8682
OOD Validation ACCURACY: 0.7661
OOD Validation Loss: 1.6477
OOD Test ACCURACY: 0.6583
OOD Test Loss: 3.1226

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 92...
[0m[1;37mINFO[0m: [1mCheckpoint 92: 
-----------------------------------
Train ACCURACY: 0.9332
Train Loss: 0.1117
ID Validation ACCURACY: 0.8306
ID Validation Loss: 0.6694
ID Test ACCURACY: 0.8312
ID Test Loss: 0.7076
OOD Validation ACCURACY: 0.8233
OOD Validation Loss: 0.9547
OOD Test ACCURACY: 0.7755
OOD Test Loss: 1.3760

[0m[1;37mINFO[0m: [1mChartInfo 0.8393 0.6583 0.8312 0.7755 0.8306 0.8233[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 03/22/2024 10:25:39 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.8 = nan
WIoU for r=0.8 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.8 = nan
WIoU for r=0.8 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.8 = nan
WIoU for r=0.8 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.842
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 285
Effective ratio: 0.796 +- 0.301
Model Accuracy over intervened graphs for r=0.8 =  0.814
SUFF++ for r=0.8 class 0.0 = 0.753 +- 0.304 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.8 class 1.0 = 0.95 +- 0.304 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.8 all KL = 0.786 +- 0.304 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.8 all L1 = 0.868 +- 0.204 (in-sample avg dev_std = 0.366)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.772
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.824 +- 0.019
Model Accuracy over intervened graphs for r=0.8 =  0.716
SUFF++ for r=0.8 class 0.0 = 0.741 +- 0.282 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.8 class 1.0 = 0.97 +- 0.282 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.8 all KL = 0.818 +- 0.282 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.8 all L1 = 0.861 +- 0.222 (in-sample avg dev_std = 0.300)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.67
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.810 +- 0.008
Model Accuracy over intervened graphs for r=0.8 =  0.617
SUFF++ for r=0.8 class 0.0 = 0.781 +- 0.254 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.8 class 1.0 = 0.979 +- 0.254 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.8 all KL = 0.864 +- 0.254 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.8 all L1 = 0.883 +- 0.212 (in-sample avg dev_std = 0.251)


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.842
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 285
Effective ratio: 0.796 +- 0.301
Model Accuracy over intervened graphs for r=0.8 =  0.825
NEC for r=0.8 class 0.0 = 0.174 +- 0.227 (in-sample avg dev_std = 0.199)
NEC for r=0.8 class 1.0 = 0.029 +- 0.227 (in-sample avg dev_std = 0.199)
NEC for r=0.8 all KL = 0.095 +- 0.227 (in-sample avg dev_std = 0.199)
NEC for r=0.8 all L1 = 0.09 +- 0.195 (in-sample avg dev_std = 0.199)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.772
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.824 +- 0.019
Model Accuracy over intervened graphs for r=0.8 =  0.768
NEC for r=0.8 class 0.0 = 0.137 +- 0.160 (in-sample avg dev_std = 0.186)
NEC for r=0.8 class 1.0 = 0.016 +- 0.160 (in-sample avg dev_std = 0.186)
NEC for r=0.8 all KL = 0.065 +- 0.160 (in-sample avg dev_std = 0.186)
NEC for r=0.8 all L1 = 0.074 +- 0.157 (in-sample avg dev_std = 0.186)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.67
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.810 +- 0.008
Model Accuracy over intervened graphs for r=0.8 =  0.659
NEC for r=0.8 class 0.0 = 0.161 +- 0.189 (in-sample avg dev_std = 0.189)
NEC for r=0.8 class 1.0 = 0.013 +- 0.189 (in-sample avg dev_std = 0.189)
NEC for r=0.8 all KL = 0.08 +- 0.189 (in-sample avg dev_std = 0.189)
NEC for r=0.8 all L1 = 0.084 +- 0.175 (in-sample avg dev_std = 0.189)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.866], 'all_L1': [0.895]}), defaultdict(<class 'list'>, {'all_KL': [0.866], 'all_L1': [0.903]}), defaultdict(<class 'list'>, {'all_KL': [0.84], 'all_L1': [0.896]}), defaultdict(<class 'list'>, {'all_KL': [0.908], 'all_L1': [0.914]}), defaultdict(<class 'list'>, {'all_KL': [0.786], 'all_L1': [0.868]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.071], 'all_L1': [0.078]}), defaultdict(<class 'list'>, {'all_KL': [0.098], 'all_L1': [0.092]}), defaultdict(<class 'list'>, {'all_KL': [0.078], 'all_L1': [0.072]}), defaultdict(<class 'list'>, {'all_KL': [0.081], 'all_L1': [0.089]}), defaultdict(<class 'list'>, {'all_KL': [0.095], 'all_L1': [0.09]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.871], 'all_L1': [0.881]}), defaultdict(<class 'list'>, {'all_KL': [0.887], 'all_L1': [0.9]}), defaultdict(<class 'list'>, {'all_KL': [0.885], 'all_L1': [0.899]}), defaultdict(<class 'list'>, {'all_KL': [0.928], 'all_L1': [0.917]}), defaultdict(<class 'list'>, {'all_KL': [0.818], 'all_L1': [0.861]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.061], 'all_L1': [0.079]}), defaultdict(<class 'list'>, {'all_KL': [0.066], 'all_L1': [0.076]}), defaultdict(<class 'list'>, {'all_KL': [0.062], 'all_L1': [0.07]}), defaultdict(<class 'list'>, {'all_KL': [0.053], 'all_L1': [0.069]}), defaultdict(<class 'list'>, {'all_KL': [0.065], 'all_L1': [0.074]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.879], 'all_L1': [0.872]}), defaultdict(<class 'list'>, {'all_KL': [0.883], 'all_L1': [0.873]}), defaultdict(<class 'list'>, {'all_KL': [0.891], 'all_L1': [0.878]}), defaultdict(<class 'list'>, {'all_KL': [0.93], 'all_L1': [0.902]}), defaultdict(<class 'list'>, {'all_KL': [0.864], 'all_L1': [0.883]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.071], 'all_L1': [0.096]}), defaultdict(<class 'list'>, {'all_KL': [0.087], 'all_L1': [0.106]}), defaultdict(<class 'list'>, {'all_KL': [0.085], 'all_L1': [0.104]}), defaultdict(<class 'list'>, {'all_KL': [0.073], 'all_L1': [0.099]}), defaultdict(<class 'list'>, {'all_KL': [0.08], 'all_L1': [0.084]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.895 +- 0.015
suff++ class all_KL  =  0.853 +- 0.040
suff++_acc_int  =  0.840 +- 0.013
nec class all_L1  =  0.084 +- 0.008
nec class all_KL  =  0.085 +- 0.010
nec_acc_int  =  0.847 +- 0.014

Eval split val
suff++ class all_L1  =  0.892 +- 0.019
suff++ class all_KL  =  0.878 +- 0.035
suff++_acc_int  =  0.808 +- 0.047
nec class all_L1  =  0.074 +- 0.004
nec class all_KL  =  0.061 +- 0.005
nec_acc_int  =  0.827 +- 0.032

Eval split test
suff++ class all_L1  =  0.882 +- 0.011
suff++ class all_KL  =  0.889 +- 0.022
suff++_acc_int  =  0.742 +- 0.076
nec class all_L1  =  0.098 +- 0.008
nec class all_KL  =  0.079 +- 0.006
nec_acc_int  =  0.764 +- 0.063


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.490 +- 0.008
Faith. Armon (L1)= 		  =  0.154 +- 0.013
Faith. GMean (L1)= 	  =  0.274 +- 0.013
Faith. Aritm (KL)= 		  =  0.469 +- 0.019
Faith. Armon (KL)= 		  =  0.154 +- 0.017
Faith. GMean (KL)= 	  =  0.268 +- 0.015

Eval split val
Faith. Aritm (L1)= 		  =  0.483 +- 0.009
Faith. Armon (L1)= 		  =  0.136 +- 0.006
Faith. GMean (L1)= 	  =  0.256 +- 0.005
Faith. Aritm (KL)= 		  =  0.470 +- 0.016
Faith. Armon (KL)= 		  =  0.115 +- 0.008
Faith. GMean (KL)= 	  =  0.232 +- 0.007

Eval split test
Faith. Aritm (L1)= 		  =  0.490 +- 0.006
Faith. Armon (L1)= 		  =  0.176 +- 0.013
Faith. GMean (L1)= 	  =  0.293 +- 0.012
Faith. Aritm (KL)= 		  =  0.484 +- 0.010
Faith. Armon (KL)= 		  =  0.145 +- 0.011
Faith. GMean (KL)= 	  =  0.265 +- 0.010
Computed for split load_split = id



Completed in  0:06:04.888329  for CIGAvGIN GOODSST2/length



DONE CIGA GOODSST2/length

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 22:27:07 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 03/22/2024 10:27:08 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 10:27:08 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 10:27:08 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:27:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:27:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:27:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:27:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:27:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:27:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:27:08 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:27:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:27:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:27:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:27:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:27:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:27:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:27:08 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:27:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:27:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:27:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:27:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:27:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:27:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:27:08 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 109...
[0m[1;37mINFO[0m: [1mCheckpoint 109: 
-----------------------------------
Train ACCURACY: 0.9994
Train Loss: 0.0025
ID Validation ACCURACY: 0.9106
ID Validation Loss: 0.5101
ID Test ACCURACY: 0.8987
ID Test Loss: 0.6337
OOD Validation ACCURACY: 0.8501
OOD Validation Loss: 1.2162
OOD Test ACCURACY: 0.7241
OOD Test Loss: 5.9794

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 92...
[0m[1;37mINFO[0m: [1mCheckpoint 92: 
-----------------------------------
Train ACCURACY: 0.9918
Train Loss: 0.0210
ID Validation ACCURACY: 0.9013
ID Validation Loss: 0.3950
ID Test ACCURACY: 0.8921
ID Test Loss: 0.4835
OOD Validation ACCURACY: 0.8680
OOD Validation Loss: 0.6745
OOD Test ACCURACY: 0.7971
OOD Test Loss: 1.9556

[0m[1;37mINFO[0m: [1mChartInfo 0.8987 0.7241 0.8921 0.7971 0.9013 0.8680[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 03/22/2024 10:27:09 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.821
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.764
SUFF++ for r=0.6 class 0.0 = 0.703 +- 0.321 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.6 class 1.0 = 0.899 +- 0.321 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.6 all KL = 0.708 +- 0.321 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.6 all L1 = 0.817 +- 0.212 (in-sample avg dev_std = 0.461)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.85
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.855
SUFF++ for r=0.9 class 0.0 = 0.91 +- 0.174 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.9 class 1.0 = 0.954 +- 0.174 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.9 all KL = 0.937 +- 0.174 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.9 all L1 = 0.934 +- 0.158 (in-sample avg dev_std = 0.158)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.692
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.65
SUFF++ for r=0.3 class 0.0 = 0.7 +- 0.293 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 class 1.0 = 0.85 +- 0.293 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 all KL = 0.69 +- 0.293 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 all L1 = 0.778 +- 0.196 (in-sample avg dev_std = 0.456)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.769
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.729
SUFF++ for r=0.6 class 0.0 = 0.719 +- 0.297 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.6 class 1.0 = 0.897 +- 0.297 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.6 all KL = 0.706 +- 0.297 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.6 all L1 = 0.812 +- 0.196 (in-sample avg dev_std = 0.423)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.845
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.826
SUFF++ for r=0.9 class 0.0 = 0.857 +- 0.234 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 class 1.0 = 0.949 +- 0.234 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 all KL = 0.851 +- 0.234 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 all L1 = 0.905 +- 0.154 (in-sample avg dev_std = 0.316)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.665
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.615
SUFF++ for r=0.3 class 0.0 = 0.676 +- 0.304 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 class 1.0 = 0.879 +- 0.304 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 all KL = 0.691 +- 0.304 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 all L1 = 0.781 +- 0.217 (in-sample avg dev_std = 0.441)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.705
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.659
SUFF++ for r=0.6 class 0.0 = 0.701 +- 0.314 (in-sample avg dev_std = 0.410)
SUFF++ for r=0.6 class 1.0 = 0.94 +- 0.314 (in-sample avg dev_std = 0.410)
SUFF++ for r=0.6 all KL = 0.751 +- 0.314 (in-sample avg dev_std = 0.410)
SUFF++ for r=0.6 all L1 = 0.824 +- 0.225 (in-sample avg dev_std = 0.410)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.74
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.717
SUFF++ for r=0.9 class 0.0 = 0.841 +- 0.243 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.9 class 1.0 = 0.982 +- 0.243 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.9 all KL = 0.874 +- 0.243 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.9 all L1 = 0.914 +- 0.167 (in-sample avg dev_std = 0.280)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.821
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.821
NEC for r=0.6 class 0.0 = 0.169 +- 0.227 (in-sample avg dev_std = 0.202)
NEC for r=0.6 class 1.0 = 0.044 +- 0.227 (in-sample avg dev_std = 0.202)
NEC for r=0.6 all KL = 0.099 +- 0.227 (in-sample avg dev_std = 0.202)
NEC for r=0.6 all L1 = 0.096 +- 0.193 (in-sample avg dev_std = 0.202)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.849
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.853
NEC for r=0.9 class 0.0 = 0.069 +- 0.138 (in-sample avg dev_std = 0.131)
NEC for r=0.9 class 1.0 = 0.031 +- 0.138 (in-sample avg dev_std = 0.131)
NEC for r=0.9 all KL = 0.044 +- 0.138 (in-sample avg dev_std = 0.131)
NEC for r=0.9 all L1 = 0.047 +- 0.127 (in-sample avg dev_std = 0.131)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.853
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.852
NEC for r=1.0 class 0.0 = 0.061 +- 0.127 (in-sample avg dev_std = 0.125)
NEC for r=1.0 class 1.0 = 0.028 +- 0.127 (in-sample avg dev_std = 0.125)
NEC for r=1.0 all KL = 0.037 +- 0.127 (in-sample avg dev_std = 0.125)
NEC for r=1.0 all L1 = 0.042 +- 0.116 (in-sample avg dev_std = 0.125)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.692
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.705
NEC for r=0.3 class 0.0 = 0.223 +- 0.231 (in-sample avg dev_std = 0.236)
NEC for r=0.3 class 1.0 = 0.094 +- 0.231 (in-sample avg dev_std = 0.236)
NEC for r=0.3 all KL = 0.136 +- 0.231 (in-sample avg dev_std = 0.236)
NEC for r=0.3 all L1 = 0.156 +- 0.216 (in-sample avg dev_std = 0.236)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.769
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.784
NEC for r=0.6 class 0.0 = 0.171 +- 0.197 (in-sample avg dev_std = 0.205)
NEC for r=0.6 class 1.0 = 0.054 +- 0.197 (in-sample avg dev_std = 0.205)
NEC for r=0.6 all KL = 0.096 +- 0.197 (in-sample avg dev_std = 0.205)
NEC for r=0.6 all L1 = 0.11 +- 0.186 (in-sample avg dev_std = 0.205)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.845
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.845
NEC for r=0.9 class 0.0 = 0.088 +- 0.142 (in-sample avg dev_std = 0.151)
NEC for r=0.9 class 1.0 = 0.025 +- 0.142 (in-sample avg dev_std = 0.151)
NEC for r=0.9 all KL = 0.049 +- 0.142 (in-sample avg dev_std = 0.151)
NEC for r=0.9 all L1 = 0.055 +- 0.133 (in-sample avg dev_std = 0.151)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.86
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.855
NEC for r=1.0 class 0.0 = 0.076 +- 0.125 (in-sample avg dev_std = 0.154)
NEC for r=1.0 class 1.0 = 0.026 +- 0.125 (in-sample avg dev_std = 0.154)
NEC for r=1.0 all KL = 0.04 +- 0.125 (in-sample avg dev_std = 0.154)
NEC for r=1.0 all L1 = 0.05 +- 0.125 (in-sample avg dev_std = 0.154)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.665
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.667
NEC for r=0.3 class 0.0 = 0.249 +- 0.228 (in-sample avg dev_std = 0.266)
NEC for r=0.3 class 1.0 = 0.074 +- 0.228 (in-sample avg dev_std = 0.266)
NEC for r=0.3 all KL = 0.149 +- 0.228 (in-sample avg dev_std = 0.266)
NEC for r=0.3 all L1 = 0.159 +- 0.217 (in-sample avg dev_std = 0.266)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.705
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.715
NEC for r=0.6 class 0.0 = 0.207 +- 0.223 (in-sample avg dev_std = 0.258)
NEC for r=0.6 class 1.0 = 0.041 +- 0.223 (in-sample avg dev_std = 0.258)
NEC for r=0.6 all KL = 0.125 +- 0.223 (in-sample avg dev_std = 0.258)
NEC for r=0.6 all L1 = 0.122 +- 0.203 (in-sample avg dev_std = 0.258)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.74
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.739
NEC for r=0.9 class 0.0 = 0.119 +- 0.188 (in-sample avg dev_std = 0.191)
NEC for r=0.9 class 1.0 = 0.019 +- 0.188 (in-sample avg dev_std = 0.191)
NEC for r=0.9 all KL = 0.075 +- 0.188 (in-sample avg dev_std = 0.191)
NEC for r=0.9 all L1 = 0.068 +- 0.158 (in-sample avg dev_std = 0.191)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.755
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.745
NEC for r=1.0 class 0.0 = 0.095 +- 0.174 (in-sample avg dev_std = 0.183)
NEC for r=1.0 class 1.0 = 0.023 +- 0.174 (in-sample avg dev_std = 0.183)
NEC for r=1.0 all KL = 0.061 +- 0.174 (in-sample avg dev_std = 0.183)
NEC for r=1.0 all L1 = 0.057 +- 0.145 (in-sample avg dev_std = 0.183)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 22:30:24 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 03/22/2024 10:30:25 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 10:30:25 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 10:30:25 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:30:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:30:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:30:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:30:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:30:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:30:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:30:25 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:30:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:30:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:30:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:30:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:30:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:30:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:30:25 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:30:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:30:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:30:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:30:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:30:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:30:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:30:26 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 197...
[0m[1;37mINFO[0m: [1mCheckpoint 197: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.9113
ID Validation Loss: 0.7707
ID Test ACCURACY: 0.9036
ID Test Loss: 0.8911
OOD Validation ACCURACY: 0.8742
OOD Validation Loss: 0.9645
OOD Test ACCURACY: 0.8288
OOD Test Loss: 1.5437

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 198...
[0m[1;37mINFO[0m: [1mCheckpoint 198: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.9087
ID Validation Loss: 0.6769
ID Test ACCURACY: 0.9010
ID Test Loss: 0.7782
OOD Validation ACCURACY: 0.8751
OOD Validation Loss: 0.7905
OOD Test ACCURACY: 0.8313
OOD Test Loss: 1.1097

[0m[1;37mINFO[0m: [1mChartInfo 0.9036 0.8288 0.9010 0.8313 0.9087 0.8751[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 03/22/2024 10:30:26 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.814
SUFF++ for r=0.6 class 0.0 = 0.703 +- 0.398 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.6 class 1.0 = 0.878 +- 0.398 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.6 all KL = 0.598 +- 0.398 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.6 all L1 = 0.805 +- 0.225 (in-sample avg dev_std = 0.516)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.872
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.87
SUFF++ for r=0.9 class 0.0 = 0.967 +- 0.068 (in-sample avg dev_std = 0.088)
SUFF++ for r=0.9 class 1.0 = 0.977 +- 0.068 (in-sample avg dev_std = 0.088)
SUFF++ for r=0.9 all KL = 0.981 +- 0.068 (in-sample avg dev_std = 0.088)
SUFF++ for r=0.9 all L1 = 0.972 +- 0.094 (in-sample avg dev_std = 0.088)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.809
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.728
SUFF++ for r=0.3 class 0.0 = 0.611 +- 0.393 (in-sample avg dev_std = 0.614)
SUFF++ for r=0.3 class 1.0 = 0.865 +- 0.393 (in-sample avg dev_std = 0.614)
SUFF++ for r=0.3 all KL = 0.507 +- 0.393 (in-sample avg dev_std = 0.614)
SUFF++ for r=0.3 all L1 = 0.744 +- 0.232 (in-sample avg dev_std = 0.614)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.848
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.803
SUFF++ for r=0.6 class 0.0 = 0.747 +- 0.358 (in-sample avg dev_std = 0.479)
SUFF++ for r=0.6 class 1.0 = 0.893 +- 0.358 (in-sample avg dev_std = 0.479)
SUFF++ for r=0.6 all KL = 0.659 +- 0.358 (in-sample avg dev_std = 0.479)
SUFF++ for r=0.6 all L1 = 0.823 +- 0.214 (in-sample avg dev_std = 0.479)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.87
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.865
SUFF++ for r=0.9 class 0.0 = 0.928 +- 0.209 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.9 class 1.0 = 0.94 +- 0.209 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.9 all KL = 0.9 +- 0.209 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.9 all L1 = 0.935 +- 0.140 (in-sample avg dev_std = 0.258)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.767
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.683
SUFF++ for r=0.3 class 0.0 = 0.639 +- 0.385 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.3 class 1.0 = 0.9 +- 0.385 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.3 all KL = 0.56 +- 0.385 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.3 all L1 = 0.774 +- 0.232 (in-sample avg dev_std = 0.558)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.836
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.779
SUFF++ for r=0.6 class 0.0 = 0.742 +- 0.349 (in-sample avg dev_std = 0.473)
SUFF++ for r=0.6 class 1.0 = 0.884 +- 0.349 (in-sample avg dev_std = 0.473)
SUFF++ for r=0.6 all KL = 0.647 +- 0.349 (in-sample avg dev_std = 0.473)
SUFF++ for r=0.6 all L1 = 0.815 +- 0.212 (in-sample avg dev_std = 0.473)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.851
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.85
SUFF++ for r=0.9 class 0.0 = 0.93 +- 0.192 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.9 class 1.0 = 0.926 +- 0.192 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.9 all KL = 0.906 +- 0.192 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.9 all L1 = 0.928 +- 0.145 (in-sample avg dev_std = 0.238)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.861
NEC for r=0.6 class 0.0 = 0.149 +- 0.284 (in-sample avg dev_std = 0.244)
NEC for r=0.6 class 1.0 = 0.062 +- 0.284 (in-sample avg dev_std = 0.244)
NEC for r=0.6 all KL = 0.13 +- 0.284 (in-sample avg dev_std = 0.244)
NEC for r=0.6 all L1 = 0.098 +- 0.212 (in-sample avg dev_std = 0.244)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.877
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.879
NEC for r=0.9 class 0.0 = 0.028 +- 0.098 (in-sample avg dev_std = 0.094)
NEC for r=0.9 class 1.0 = 0.032 +- 0.098 (in-sample avg dev_std = 0.094)
NEC for r=0.9 all KL = 0.025 +- 0.098 (in-sample avg dev_std = 0.094)
NEC for r=0.9 all L1 = 0.03 +- 0.112 (in-sample avg dev_std = 0.094)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.881
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.876
NEC for r=1.0 class 0.0 = 0.025 +- 0.100 (in-sample avg dev_std = 0.092)
NEC for r=1.0 class 1.0 = 0.032 +- 0.100 (in-sample avg dev_std = 0.092)
NEC for r=1.0 all KL = 0.024 +- 0.100 (in-sample avg dev_std = 0.092)
NEC for r=1.0 all L1 = 0.029 +- 0.111 (in-sample avg dev_std = 0.092)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.809
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.795
NEC for r=0.3 class 0.0 = 0.214 +- 0.313 (in-sample avg dev_std = 0.288)
NEC for r=0.3 class 1.0 = 0.055 +- 0.313 (in-sample avg dev_std = 0.288)
NEC for r=0.3 all KL = 0.17 +- 0.313 (in-sample avg dev_std = 0.288)
NEC for r=0.3 all L1 = 0.131 +- 0.240 (in-sample avg dev_std = 0.288)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.848
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.845
NEC for r=0.6 class 0.0 = 0.143 +- 0.250 (in-sample avg dev_std = 0.252)
NEC for r=0.6 class 1.0 = 0.046 +- 0.250 (in-sample avg dev_std = 0.252)
NEC for r=0.6 all KL = 0.112 +- 0.250 (in-sample avg dev_std = 0.252)
NEC for r=0.6 all L1 = 0.093 +- 0.202 (in-sample avg dev_std = 0.252)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.87
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.863
NEC for r=0.9 class 0.0 = 0.051 +- 0.152 (in-sample avg dev_std = 0.157)
NEC for r=0.9 class 1.0 = 0.046 +- 0.152 (in-sample avg dev_std = 0.157)
NEC for r=0.9 all KL = 0.047 +- 0.152 (in-sample avg dev_std = 0.157)
NEC for r=0.9 all L1 = 0.048 +- 0.134 (in-sample avg dev_std = 0.157)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.87
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.866
NEC for r=1.0 class 0.0 = 0.043 +- 0.131 (in-sample avg dev_std = 0.141)
NEC for r=1.0 class 1.0 = 0.039 +- 0.131 (in-sample avg dev_std = 0.141)
NEC for r=1.0 all KL = 0.036 +- 0.131 (in-sample avg dev_std = 0.141)
NEC for r=1.0 all L1 = 0.041 +- 0.125 (in-sample avg dev_std = 0.141)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.767
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.752
NEC for r=0.3 class 0.0 = 0.216 +- 0.307 (in-sample avg dev_std = 0.309)
NEC for r=0.3 class 1.0 = 0.049 +- 0.307 (in-sample avg dev_std = 0.309)
NEC for r=0.3 all KL = 0.177 +- 0.307 (in-sample avg dev_std = 0.309)
NEC for r=0.3 all L1 = 0.13 +- 0.230 (in-sample avg dev_std = 0.309)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.836
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.823
NEC for r=0.6 class 0.0 = 0.167 +- 0.263 (in-sample avg dev_std = 0.271)
NEC for r=0.6 class 1.0 = 0.063 +- 0.263 (in-sample avg dev_std = 0.271)
NEC for r=0.6 all KL = 0.14 +- 0.263 (in-sample avg dev_std = 0.271)
NEC for r=0.6 all L1 = 0.113 +- 0.212 (in-sample avg dev_std = 0.271)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.851
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.848
NEC for r=0.9 class 0.0 = 0.072 +- 0.175 (in-sample avg dev_std = 0.195)
NEC for r=0.9 class 1.0 = 0.061 +- 0.175 (in-sample avg dev_std = 0.195)
NEC for r=0.9 all KL = 0.066 +- 0.175 (in-sample avg dev_std = 0.195)
NEC for r=0.9 all L1 = 0.067 +- 0.157 (in-sample avg dev_std = 0.195)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.863
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.851
NEC for r=1.0 class 0.0 = 0.055 +- 0.149 (in-sample avg dev_std = 0.159)
NEC for r=1.0 class 1.0 = 0.056 +- 0.149 (in-sample avg dev_std = 0.159)
NEC for r=1.0 all KL = 0.048 +- 0.149 (in-sample avg dev_std = 0.159)
NEC for r=1.0 all L1 = 0.055 +- 0.144 (in-sample avg dev_std = 0.159)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 22:33:52 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 03/22/2024 10:33:53 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 10:33:53 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 10:33:53 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:33:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:33:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:33:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:33:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:33:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:33:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:33:53 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:33:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:33:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:33:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:33:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:33:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:33:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:33:53 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:33:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:33:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:33:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:33:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:33:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:33:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:33:53 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 176...
[0m[1;37mINFO[0m: [1mCheckpoint 176: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0002
ID Validation ACCURACY: 0.9070
ID Validation Loss: 0.6761
ID Test ACCURACY: 0.9085
ID Test Loss: 0.7858
OOD Validation ACCURACY: 0.8698
OOD Validation Loss: 0.7126
OOD Test ACCURACY: 0.8129
OOD Test Loss: 0.9194

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 176...
[0m[1;37mINFO[0m: [1mCheckpoint 176: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0002
ID Validation ACCURACY: 0.9070
ID Validation Loss: 0.6761
ID Test ACCURACY: 0.9085
ID Test Loss: 0.7858
OOD Validation ACCURACY: 0.8698
OOD Validation Loss: 0.7126
OOD Test ACCURACY: 0.8129
OOD Test Loss: 0.9194

[0m[1;37mINFO[0m: [1mChartInfo 0.9085 0.8129 0.9085 0.8129 0.9070 0.8698[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 03/22/2024 10:33:54 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.867
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.817
SUFF++ for r=0.6 class 0.0 = 0.916 +- 0.360 (in-sample avg dev_std = 0.400)
SUFF++ for r=0.6 class 1.0 = 0.83 +- 0.360 (in-sample avg dev_std = 0.400)
SUFF++ for r=0.6 all KL = 0.716 +- 0.360 (in-sample avg dev_std = 0.400)
SUFF++ for r=0.6 all L1 = 0.866 +- 0.192 (in-sample avg dev_std = 0.400)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.856
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.858
SUFF++ for r=0.9 class 0.0 = 0.966 +- 0.103 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 class 1.0 = 0.959 +- 0.103 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 all KL = 0.97 +- 0.103 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 all L1 = 0.962 +- 0.117 (in-sample avg dev_std = 0.107)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.791
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.723
SUFF++ for r=0.3 class 0.0 = 0.941 +- 0.381 (in-sample avg dev_std = 0.517)
SUFF++ for r=0.3 class 1.0 = 0.694 +- 0.381 (in-sample avg dev_std = 0.517)
SUFF++ for r=0.3 all KL = 0.673 +- 0.381 (in-sample avg dev_std = 0.517)
SUFF++ for r=0.3 all L1 = 0.812 +- 0.219 (in-sample avg dev_std = 0.517)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.849
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.813
SUFF++ for r=0.6 class 0.0 = 0.932 +- 0.297 (in-sample avg dev_std = 0.377)
SUFF++ for r=0.6 class 1.0 = 0.833 +- 0.297 (in-sample avg dev_std = 0.377)
SUFF++ for r=0.6 all KL = 0.782 +- 0.297 (in-sample avg dev_std = 0.377)
SUFF++ for r=0.6 all L1 = 0.88 +- 0.168 (in-sample avg dev_std = 0.377)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.864
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.859
SUFF++ for r=0.9 class 0.0 = 0.942 +- 0.120 (in-sample avg dev_std = 0.189)
SUFF++ for r=0.9 class 1.0 = 0.943 +- 0.120 (in-sample avg dev_std = 0.189)
SUFF++ for r=0.9 all KL = 0.946 +- 0.120 (in-sample avg dev_std = 0.189)
SUFF++ for r=0.9 all L1 = 0.943 +- 0.122 (in-sample avg dev_std = 0.189)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.74
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.667
SUFF++ for r=0.3 class 0.0 = 0.947 +- 0.354 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.3 class 1.0 = 0.716 +- 0.354 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.3 all KL = 0.729 +- 0.354 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.3 all L1 = 0.828 +- 0.221 (in-sample avg dev_std = 0.452)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.783
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.751
SUFF++ for r=0.6 class 0.0 = 0.911 +- 0.278 (in-sample avg dev_std = 0.359)
SUFF++ for r=0.6 class 1.0 = 0.809 +- 0.278 (in-sample avg dev_std = 0.359)
SUFF++ for r=0.6 all KL = 0.785 +- 0.278 (in-sample avg dev_std = 0.359)
SUFF++ for r=0.6 all L1 = 0.859 +- 0.175 (in-sample avg dev_std = 0.359)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.815
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.81
SUFF++ for r=0.9 class 0.0 = 0.922 +- 0.123 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.9 class 1.0 = 0.909 +- 0.123 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.9 all KL = 0.94 +- 0.123 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.9 all L1 = 0.915 +- 0.146 (in-sample avg dev_std = 0.183)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.867
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.843
NEC for r=0.6 class 0.0 = 0.075 +- 0.222 (in-sample avg dev_std = 0.171)
NEC for r=0.6 class 1.0 = 0.073 +- 0.222 (in-sample avg dev_std = 0.171)
NEC for r=0.6 all KL = 0.085 +- 0.222 (in-sample avg dev_std = 0.171)
NEC for r=0.6 all L1 = 0.074 +- 0.185 (in-sample avg dev_std = 0.171)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.849
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.86
NEC for r=0.9 class 0.0 = 0.041 +- 0.120 (in-sample avg dev_std = 0.109)
NEC for r=0.9 class 1.0 = 0.042 +- 0.120 (in-sample avg dev_std = 0.109)
NEC for r=0.9 all KL = 0.034 +- 0.120 (in-sample avg dev_std = 0.109)
NEC for r=0.9 all L1 = 0.042 +- 0.126 (in-sample avg dev_std = 0.109)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.86
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.861
NEC for r=1.0 class 0.0 = 0.047 +- 0.129 (in-sample avg dev_std = 0.104)
NEC for r=1.0 class 1.0 = 0.043 +- 0.129 (in-sample avg dev_std = 0.104)
NEC for r=1.0 all KL = 0.037 +- 0.129 (in-sample avg dev_std = 0.104)
NEC for r=1.0 all L1 = 0.045 +- 0.134 (in-sample avg dev_std = 0.104)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.791
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.805
NEC for r=0.3 class 0.0 = 0.046 +- 0.232 (in-sample avg dev_std = 0.188)
NEC for r=0.3 class 1.0 = 0.133 +- 0.232 (in-sample avg dev_std = 0.188)
NEC for r=0.3 all KL = 0.1 +- 0.232 (in-sample avg dev_std = 0.188)
NEC for r=0.3 all L1 = 0.092 +- 0.194 (in-sample avg dev_std = 0.188)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.849
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.845
NEC for r=0.6 class 0.0 = 0.044 +- 0.154 (in-sample avg dev_std = 0.156)
NEC for r=0.6 class 1.0 = 0.076 +- 0.154 (in-sample avg dev_std = 0.156)
NEC for r=0.6 all KL = 0.056 +- 0.154 (in-sample avg dev_std = 0.156)
NEC for r=0.6 all L1 = 0.061 +- 0.149 (in-sample avg dev_std = 0.156)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.864
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.861
NEC for r=0.9 class 0.0 = 0.05 +- 0.110 (in-sample avg dev_std = 0.130)
NEC for r=0.9 class 1.0 = 0.049 +- 0.110 (in-sample avg dev_std = 0.130)
NEC for r=0.9 all KL = 0.035 +- 0.110 (in-sample avg dev_std = 0.130)
NEC for r=0.9 all L1 = 0.049 +- 0.126 (in-sample avg dev_std = 0.130)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.865
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.865
NEC for r=1.0 class 0.0 = 0.043 +- 0.096 (in-sample avg dev_std = 0.116)
NEC for r=1.0 class 1.0 = 0.04 +- 0.096 (in-sample avg dev_std = 0.116)
NEC for r=1.0 all KL = 0.027 +- 0.096 (in-sample avg dev_std = 0.116)
NEC for r=1.0 all L1 = 0.042 +- 0.112 (in-sample avg dev_std = 0.116)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.74
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.73
NEC for r=0.3 class 0.0 = 0.05 +- 0.216 (in-sample avg dev_std = 0.209)
NEC for r=0.3 class 1.0 = 0.141 +- 0.216 (in-sample avg dev_std = 0.209)
NEC for r=0.3 all KL = 0.105 +- 0.216 (in-sample avg dev_std = 0.209)
NEC for r=0.3 all L1 = 0.097 +- 0.188 (in-sample avg dev_std = 0.209)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.783
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.781
NEC for r=0.6 class 0.0 = 0.057 +- 0.160 (in-sample avg dev_std = 0.186)
NEC for r=0.6 class 1.0 = 0.117 +- 0.160 (in-sample avg dev_std = 0.186)
NEC for r=0.6 all KL = 0.073 +- 0.160 (in-sample avg dev_std = 0.186)
NEC for r=0.6 all L1 = 0.088 +- 0.165 (in-sample avg dev_std = 0.186)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.815
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.817
NEC for r=0.9 class 0.0 = 0.072 +- 0.133 (in-sample avg dev_std = 0.163)
NEC for r=0.9 class 1.0 = 0.091 +- 0.133 (in-sample avg dev_std = 0.163)
NEC for r=0.9 all KL = 0.056 +- 0.133 (in-sample avg dev_std = 0.163)
NEC for r=0.9 all L1 = 0.082 +- 0.149 (in-sample avg dev_std = 0.163)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.83
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.826
NEC for r=1.0 class 0.0 = 0.07 +- 0.102 (in-sample avg dev_std = 0.141)
NEC for r=1.0 class 1.0 = 0.079 +- 0.102 (in-sample avg dev_std = 0.141)
NEC for r=1.0 all KL = 0.041 +- 0.102 (in-sample avg dev_std = 0.141)
NEC for r=1.0 all L1 = 0.075 +- 0.133 (in-sample avg dev_std = 0.141)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 22:37:18 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 03/22/2024 10:37:20 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 10:37:20 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 10:37:20 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:37:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:37:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:37:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:37:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:37:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:37:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:37:20 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:37:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:37:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:37:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:37:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:37:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:37:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:37:20 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:37:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:37:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:37:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:37:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:37:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:37:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:37:20 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 186...
[0m[1;37mINFO[0m: [1mCheckpoint 186: 
-----------------------------------
Train ACCURACY: 0.9999
Train Loss: 0.0001
ID Validation ACCURACY: 0.9147
ID Validation Loss: 0.6881
ID Test ACCURACY: 0.9072
ID Test Loss: 0.8292
OOD Validation ACCURACY: 0.8620
OOD Validation Loss: 1.4572
OOD Test ACCURACY: 0.8092
OOD Test Loss: 3.9476

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 194...
[0m[1;37mINFO[0m: [1mCheckpoint 194: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.9128
ID Validation Loss: 0.7432
ID Test ACCURACY: 0.9068
ID Test Loss: 0.8946
OOD Validation ACCURACY: 0.8693
OOD Validation Loss: 1.4169
OOD Test ACCURACY: 0.8193
OOD Test Loss: 3.6034

[0m[1;37mINFO[0m: [1mChartInfo 0.9072 0.8092 0.9068 0.8193 0.9128 0.8693[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 03/22/2024 10:37:20 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.849
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.789
SUFF++ for r=0.6 class 0.0 = 0.697 +- 0.389 (in-sample avg dev_std = 0.464)
SUFF++ for r=0.6 class 1.0 = 0.942 +- 0.389 (in-sample avg dev_std = 0.464)
SUFF++ for r=0.6 all KL = 0.688 +- 0.389 (in-sample avg dev_std = 0.464)
SUFF++ for r=0.6 all L1 = 0.84 +- 0.224 (in-sample avg dev_std = 0.464)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.9
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.867
SUFF++ for r=0.9 class 0.0 = 0.921 +- 0.179 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.9 class 1.0 = 0.976 +- 0.179 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.9 all KL = 0.949 +- 0.179 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.9 all L1 = 0.952 +- 0.157 (in-sample avg dev_std = 0.144)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.734
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.672
SUFF++ for r=0.3 class 0.0 = 0.677 +- 0.375 (in-sample avg dev_std = 0.496)
SUFF++ for r=0.3 class 1.0 = 0.906 +- 0.375 (in-sample avg dev_std = 0.496)
SUFF++ for r=0.3 all KL = 0.66 +- 0.375 (in-sample avg dev_std = 0.496)
SUFF++ for r=0.3 all L1 = 0.797 +- 0.244 (in-sample avg dev_std = 0.496)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.819
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.752
SUFF++ for r=0.6 class 0.0 = 0.703 +- 0.369 (in-sample avg dev_std = 0.485)
SUFF++ for r=0.6 class 1.0 = 0.926 +- 0.369 (in-sample avg dev_std = 0.485)
SUFF++ for r=0.6 all KL = 0.665 +- 0.369 (in-sample avg dev_std = 0.485)
SUFF++ for r=0.6 all L1 = 0.819 +- 0.224 (in-sample avg dev_std = 0.485)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.849
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.845
SUFF++ for r=0.9 class 0.0 = 0.895 +- 0.231 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.9 class 1.0 = 0.941 +- 0.231 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.9 all KL = 0.869 +- 0.231 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.9 all L1 = 0.919 +- 0.153 (in-sample avg dev_std = 0.295)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.686
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.622
SUFF++ for r=0.3 class 0.0 = 0.674 +- 0.366 (in-sample avg dev_std = 0.523)
SUFF++ for r=0.3 class 1.0 = 0.871 +- 0.366 (in-sample avg dev_std = 0.523)
SUFF++ for r=0.3 all KL = 0.6 +- 0.366 (in-sample avg dev_std = 0.523)
SUFF++ for r=0.3 all L1 = 0.776 +- 0.242 (in-sample avg dev_std = 0.523)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.754
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.698
SUFF++ for r=0.6 class 0.0 = 0.724 +- 0.378 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.6 class 1.0 = 0.936 +- 0.378 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.6 all KL = 0.665 +- 0.378 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.6 all L1 = 0.833 +- 0.209 (in-sample avg dev_std = 0.467)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.829
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.827
SUFF++ for r=0.9 class 0.0 = 0.9 +- 0.228 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 class 1.0 = 0.954 +- 0.228 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 all KL = 0.889 +- 0.228 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 all L1 = 0.928 +- 0.155 (in-sample avg dev_std = 0.249)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.849
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.839
NEC for r=0.6 class 0.0 = 0.171 +- 0.271 (in-sample avg dev_std = 0.250)
NEC for r=0.6 class 1.0 = 0.032 +- 0.271 (in-sample avg dev_std = 0.250)
NEC for r=0.6 all KL = 0.112 +- 0.271 (in-sample avg dev_std = 0.250)
NEC for r=0.6 all L1 = 0.09 +- 0.212 (in-sample avg dev_std = 0.250)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.888
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.867
NEC for r=0.9 class 0.0 = 0.076 +- 0.172 (in-sample avg dev_std = 0.137)
NEC for r=0.9 class 1.0 = 0.019 +- 0.172 (in-sample avg dev_std = 0.137)
NEC for r=0.9 all KL = 0.045 +- 0.172 (in-sample avg dev_std = 0.137)
NEC for r=0.9 all L1 = 0.043 +- 0.149 (in-sample avg dev_std = 0.137)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.888
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.874
NEC for r=1.0 class 0.0 = 0.06 +- 0.158 (in-sample avg dev_std = 0.132)
NEC for r=1.0 class 1.0 = 0.018 +- 0.158 (in-sample avg dev_std = 0.132)
NEC for r=1.0 all KL = 0.037 +- 0.158 (in-sample avg dev_std = 0.132)
NEC for r=1.0 all L1 = 0.036 +- 0.134 (in-sample avg dev_std = 0.132)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.734
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.745
NEC for r=0.3 class 0.0 = 0.198 +- 0.296 (in-sample avg dev_std = 0.268)
NEC for r=0.3 class 1.0 = 0.065 +- 0.296 (in-sample avg dev_std = 0.268)
NEC for r=0.3 all KL = 0.156 +- 0.296 (in-sample avg dev_std = 0.268)
NEC for r=0.3 all L1 = 0.129 +- 0.239 (in-sample avg dev_std = 0.268)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.819
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.821
NEC for r=0.6 class 0.0 = 0.132 +- 0.220 (in-sample avg dev_std = 0.216)
NEC for r=0.6 class 1.0 = 0.035 +- 0.220 (in-sample avg dev_std = 0.216)
NEC for r=0.6 all KL = 0.093 +- 0.220 (in-sample avg dev_std = 0.216)
NEC for r=0.6 all L1 = 0.082 +- 0.185 (in-sample avg dev_std = 0.216)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.849
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.856
NEC for r=0.9 class 0.0 = 0.066 +- 0.150 (in-sample avg dev_std = 0.171)
NEC for r=0.9 class 1.0 = 0.032 +- 0.150 (in-sample avg dev_std = 0.171)
NEC for r=0.9 all KL = 0.047 +- 0.150 (in-sample avg dev_std = 0.171)
NEC for r=0.9 all L1 = 0.048 +- 0.130 (in-sample avg dev_std = 0.171)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.856
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.862
NEC for r=1.0 class 0.0 = 0.058 +- 0.133 (in-sample avg dev_std = 0.151)
NEC for r=1.0 class 1.0 = 0.03 +- 0.133 (in-sample avg dev_std = 0.151)
NEC for r=1.0 all KL = 0.04 +- 0.133 (in-sample avg dev_std = 0.151)
NEC for r=1.0 all L1 = 0.044 +- 0.125 (in-sample avg dev_std = 0.151)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.686
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.688
NEC for r=0.3 class 0.0 = 0.21 +- 0.329 (in-sample avg dev_std = 0.344)
NEC for r=0.3 class 1.0 = 0.098 +- 0.329 (in-sample avg dev_std = 0.344)
NEC for r=0.3 all KL = 0.211 +- 0.329 (in-sample avg dev_std = 0.344)
NEC for r=0.3 all L1 = 0.152 +- 0.244 (in-sample avg dev_std = 0.344)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.754
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.764
NEC for r=0.6 class 0.0 = 0.15 +- 0.245 (in-sample avg dev_std = 0.232)
NEC for r=0.6 class 1.0 = 0.029 +- 0.245 (in-sample avg dev_std = 0.232)
NEC for r=0.6 all KL = 0.117 +- 0.245 (in-sample avg dev_std = 0.232)
NEC for r=0.6 all L1 = 0.088 +- 0.184 (in-sample avg dev_std = 0.232)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.829
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.824
NEC for r=0.9 class 0.0 = 0.086 +- 0.174 (in-sample avg dev_std = 0.165)
NEC for r=0.9 class 1.0 = 0.029 +- 0.174 (in-sample avg dev_std = 0.165)
NEC for r=0.9 all KL = 0.06 +- 0.174 (in-sample avg dev_std = 0.165)
NEC for r=0.9 all L1 = 0.057 +- 0.153 (in-sample avg dev_std = 0.165)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.83
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.83
NEC for r=1.0 class 0.0 = 0.068 +- 0.169 (in-sample avg dev_std = 0.161)
NEC for r=1.0 class 1.0 = 0.032 +- 0.169 (in-sample avg dev_std = 0.161)
NEC for r=1.0 all KL = 0.057 +- 0.169 (in-sample avg dev_std = 0.161)
NEC for r=1.0 all L1 = 0.05 +- 0.140 (in-sample avg dev_std = 0.161)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 22:40:44 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 03/22/2024 10:40:45 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 10:40:45 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 10:40:45 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:40:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:40:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:40:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:40:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:40:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:40:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:40:45 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:40:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:40:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:40:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:40:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:40:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:40:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:40:45 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:40:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:40:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:40:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:40:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:40:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:40:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:40:46 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 196...
[0m[1;37mINFO[0m: [1mCheckpoint 196: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.9085
ID Validation Loss: 0.7434
ID Test ACCURACY: 0.9083
ID Test Loss: 0.7942
OOD Validation ACCURACY: 0.8622
OOD Validation Loss: 1.0214
OOD Test ACCURACY: 0.7831
OOD Test Loss: 1.9072

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 198...
[0m[1;37mINFO[0m: [1mCheckpoint 198: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.9062
ID Validation Loss: 0.7432
ID Test ACCURACY: 0.9059
ID Test Loss: 0.8164
OOD Validation ACCURACY: 0.8689
OOD Validation Loss: 0.9364
OOD Test ACCURACY: 0.8087
OOD Test Loss: 1.4925

[0m[1;37mINFO[0m: [1mChartInfo 0.9083 0.7831 0.9059 0.8087 0.9062 0.8689[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 03/22/2024 10:40:46 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.849
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.804
SUFF++ for r=0.6 class 0.0 = 0.784 +- 0.362 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.6 class 1.0 = 0.911 +- 0.362 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.6 all KL = 0.716 +- 0.362 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.6 all L1 = 0.858 +- 0.210 (in-sample avg dev_std = 0.437)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.861
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.856
SUFF++ for r=0.9 class 0.0 = 0.915 +- 0.171 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 class 1.0 = 0.961 +- 0.171 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 all KL = 0.946 +- 0.171 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 all L1 = 0.94 +- 0.162 (in-sample avg dev_std = 0.152)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.799
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.746
SUFF++ for r=0.3 class 0.0 = 0.672 +- 0.399 (in-sample avg dev_std = 0.524)
SUFF++ for r=0.3 class 1.0 = 0.941 +- 0.399 (in-sample avg dev_std = 0.524)
SUFF++ for r=0.3 all KL = 0.654 +- 0.399 (in-sample avg dev_std = 0.524)
SUFF++ for r=0.3 all L1 = 0.812 +- 0.237 (in-sample avg dev_std = 0.524)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.846
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.815
SUFF++ for r=0.6 class 0.0 = 0.776 +- 0.319 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 class 1.0 = 0.939 +- 0.319 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 all KL = 0.757 +- 0.319 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 all L1 = 0.861 +- 0.197 (in-sample avg dev_std = 0.396)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.879
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.868
SUFF++ for r=0.9 class 0.0 = 0.929 +- 0.142 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.9 class 1.0 = 0.962 +- 0.142 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.9 all KL = 0.941 +- 0.142 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.9 all L1 = 0.946 +- 0.118 (in-sample avg dev_std = 0.205)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.719
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.667
SUFF++ for r=0.3 class 0.0 = 0.728 +- 0.371 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.3 class 1.0 = 0.971 +- 0.371 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.3 all KL = 0.744 +- 0.371 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.3 all L1 = 0.854 +- 0.230 (in-sample avg dev_std = 0.446)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.762
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.737
SUFF++ for r=0.6 class 0.0 = 0.772 +- 0.302 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.6 class 1.0 = 0.967 +- 0.302 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.6 all KL = 0.802 +- 0.302 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.6 all L1 = 0.873 +- 0.194 (in-sample avg dev_std = 0.360)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.803
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.794
SUFF++ for r=0.9 class 0.0 = 0.902 +- 0.123 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.9 class 1.0 = 0.976 +- 0.123 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.9 all KL = 0.951 +- 0.123 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.9 all L1 = 0.94 +- 0.129 (in-sample avg dev_std = 0.163)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.849
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.846
NEC for r=0.6 class 0.0 = 0.127 +- 0.260 (in-sample avg dev_std = 0.220)
NEC for r=0.6 class 1.0 = 0.051 +- 0.260 (in-sample avg dev_std = 0.220)
NEC for r=0.6 all KL = 0.1 +- 0.260 (in-sample avg dev_std = 0.220)
NEC for r=0.6 all L1 = 0.083 +- 0.210 (in-sample avg dev_std = 0.220)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.86
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.85
NEC for r=0.9 class 0.0 = 0.081 +- 0.180 (in-sample avg dev_std = 0.149)
NEC for r=0.9 class 1.0 = 0.036 +- 0.180 (in-sample avg dev_std = 0.149)
NEC for r=0.9 all KL = 0.054 +- 0.180 (in-sample avg dev_std = 0.149)
NEC for r=0.9 all L1 = 0.055 +- 0.164 (in-sample avg dev_std = 0.149)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.874
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.853
NEC for r=1.0 class 0.0 = 0.076 +- 0.186 (in-sample avg dev_std = 0.156)
NEC for r=1.0 class 1.0 = 0.04 +- 0.186 (in-sample avg dev_std = 0.156)
NEC for r=1.0 all KL = 0.057 +- 0.186 (in-sample avg dev_std = 0.156)
NEC for r=1.0 all L1 = 0.055 +- 0.167 (in-sample avg dev_std = 0.156)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.799
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.786
NEC for r=0.3 class 0.0 = 0.197 +- 0.298 (in-sample avg dev_std = 0.292)
NEC for r=0.3 class 1.0 = 0.029 +- 0.298 (in-sample avg dev_std = 0.292)
NEC for r=0.3 all KL = 0.146 +- 0.298 (in-sample avg dev_std = 0.292)
NEC for r=0.3 all L1 = 0.109 +- 0.222 (in-sample avg dev_std = 0.292)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.846
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.836
NEC for r=0.6 class 0.0 = 0.148 +- 0.234 (in-sample avg dev_std = 0.248)
NEC for r=0.6 class 1.0 = 0.041 +- 0.234 (in-sample avg dev_std = 0.248)
NEC for r=0.6 all KL = 0.107 +- 0.234 (in-sample avg dev_std = 0.248)
NEC for r=0.6 all L1 = 0.093 +- 0.190 (in-sample avg dev_std = 0.248)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.879
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.867
NEC for r=0.9 class 0.0 = 0.075 +- 0.139 (in-sample avg dev_std = 0.156)
NEC for r=0.9 class 1.0 = 0.033 +- 0.139 (in-sample avg dev_std = 0.156)
NEC for r=0.9 all KL = 0.047 +- 0.139 (in-sample avg dev_std = 0.156)
NEC for r=0.9 all L1 = 0.053 +- 0.135 (in-sample avg dev_std = 0.156)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.875
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.867
NEC for r=1.0 class 0.0 = 0.066 +- 0.136 (in-sample avg dev_std = 0.152)
NEC for r=1.0 class 1.0 = 0.031 +- 0.136 (in-sample avg dev_std = 0.152)
NEC for r=1.0 all KL = 0.042 +- 0.136 (in-sample avg dev_std = 0.152)
NEC for r=1.0 all L1 = 0.048 +- 0.133 (in-sample avg dev_std = 0.152)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.719
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.72
NEC for r=0.3 class 0.0 = 0.187 +- 0.294 (in-sample avg dev_std = 0.292)
NEC for r=0.3 class 1.0 = 0.019 +- 0.294 (in-sample avg dev_std = 0.292)
NEC for r=0.3 all KL = 0.144 +- 0.294 (in-sample avg dev_std = 0.292)
NEC for r=0.3 all L1 = 0.1 +- 0.214 (in-sample avg dev_std = 0.292)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.762
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.766
NEC for r=0.6 class 0.0 = 0.151 +- 0.198 (in-sample avg dev_std = 0.218)
NEC for r=0.6 class 1.0 = 0.025 +- 0.198 (in-sample avg dev_std = 0.218)
NEC for r=0.6 all KL = 0.09 +- 0.198 (in-sample avg dev_std = 0.218)
NEC for r=0.6 all L1 = 0.086 +- 0.178 (in-sample avg dev_std = 0.218)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.803
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.798
NEC for r=0.9 class 0.0 = 0.103 +- 0.130 (in-sample avg dev_std = 0.154)
NEC for r=0.9 class 1.0 = 0.024 +- 0.130 (in-sample avg dev_std = 0.154)
NEC for r=0.9 all KL = 0.05 +- 0.130 (in-sample avg dev_std = 0.154)
NEC for r=0.9 all L1 = 0.062 +- 0.139 (in-sample avg dev_std = 0.154)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.804
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.804
NEC for r=1.0 class 0.0 = 0.095 +- 0.125 (in-sample avg dev_std = 0.144)
NEC for r=1.0 class 1.0 = 0.022 +- 0.125 (in-sample avg dev_std = 0.144)
NEC for r=1.0 all KL = 0.044 +- 0.125 (in-sample avg dev_std = 0.144)
NEC for r=1.0 all L1 = 0.058 +- 0.137 (in-sample avg dev_std = 0.144)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.708, 0.937, 1.0], 'all_L1': [0.817, 0.934, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.598, 0.981, 1.0], 'all_L1': [0.805, 0.972, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.716, 0.97, 1.0], 'all_L1': [0.866, 0.962, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.688, 0.949, 1.0], 'all_L1': [0.84, 0.952, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.716, 0.946, 1.0], 'all_L1': [0.858, 0.94, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.099, 0.044, 0.037], 'all_L1': [0.096, 0.047, 0.042]}), defaultdict(<class 'list'>, {'all_KL': [0.13, 0.025, 0.024], 'all_L1': [0.098, 0.03, 0.029]}), defaultdict(<class 'list'>, {'all_KL': [0.085, 0.034, 0.037], 'all_L1': [0.074, 0.042, 0.045]}), defaultdict(<class 'list'>, {'all_KL': [0.112, 0.045, 0.037], 'all_L1': [0.09, 0.043, 0.036]}), defaultdict(<class 'list'>, {'all_KL': [0.1, 0.054, 0.057], 'all_L1': [0.083, 0.055, 0.055]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.69, 0.706, 0.851, 1.0], 'all_L1': [0.778, 0.812, 0.905, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.507, 0.659, 0.9, 1.0], 'all_L1': [0.744, 0.823, 0.935, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.673, 0.782, 0.946, 1.0], 'all_L1': [0.812, 0.88, 0.943, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.66, 0.665, 0.869, 1.0], 'all_L1': [0.797, 0.819, 0.919, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.654, 0.757, 0.941, 1.0], 'all_L1': [0.812, 0.861, 0.946, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.136, 0.096, 0.049, 0.04], 'all_L1': [0.156, 0.11, 0.055, 0.05]}), defaultdict(<class 'list'>, {'all_KL': [0.17, 0.112, 0.047, 0.036], 'all_L1': [0.131, 0.093, 0.048, 0.041]}), defaultdict(<class 'list'>, {'all_KL': [0.1, 0.056, 0.035, 0.027], 'all_L1': [0.092, 0.061, 0.049, 0.042]}), defaultdict(<class 'list'>, {'all_KL': [0.156, 0.093, 0.047, 0.04], 'all_L1': [0.129, 0.082, 0.048, 0.044]}), defaultdict(<class 'list'>, {'all_KL': [0.146, 0.107, 0.047, 0.042], 'all_L1': [0.109, 0.093, 0.053, 0.048]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.691, 0.751, 0.874, 1.0], 'all_L1': [0.781, 0.824, 0.914, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.56, 0.647, 0.906, 1.0], 'all_L1': [0.774, 0.815, 0.928, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.729, 0.785, 0.94, 1.0], 'all_L1': [0.828, 0.859, 0.915, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.6, 0.665, 0.889, 1.0], 'all_L1': [0.776, 0.833, 0.928, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.744, 0.802, 0.951, 1.0], 'all_L1': [0.854, 0.873, 0.94, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.149, 0.125, 0.075, 0.061], 'all_L1': [0.159, 0.122, 0.068, 0.057]}), defaultdict(<class 'list'>, {'all_KL': [0.177, 0.14, 0.066, 0.048], 'all_L1': [0.13, 0.113, 0.067, 0.055]}), defaultdict(<class 'list'>, {'all_KL': [0.105, 0.073, 0.056, 0.041], 'all_L1': [0.097, 0.088, 0.082, 0.075]}), defaultdict(<class 'list'>, {'all_KL': [0.211, 0.117, 0.06, 0.057], 'all_L1': [0.152, 0.088, 0.057, 0.05]}), defaultdict(<class 'list'>, {'all_KL': [0.144, 0.09, 0.05, 0.044], 'all_L1': [0.1, 0.086, 0.062, 0.058]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.837 +- 0.023, 0.952 +- 0.014, 1.000 +- 0.000
suff++ class all_KL  =  0.685 +- 0.045, 0.957 +- 0.016, 1.000 +- 0.000
suff++_acc_int  =  0.797 +- 0.019, 0.861 +- 0.006
nec class all_L1  =  0.088 +- 0.009, 0.043 +- 0.008, 0.041 +- 0.009
nec class all_KL  =  0.105 +- 0.015, 0.040 +- 0.010, 0.038 +- 0.011
nec_acc_int  =  0.842 +- 0.013, 0.862 +- 0.010, 0.863 +- 0.010

Eval split val
suff++ class all_L1  =  0.789 +- 0.026, 0.839 +- 0.027, 0.930 +- 0.015, 1.000 +- 0.000
suff++ class all_KL  =  0.637 +- 0.066, 0.714 +- 0.049, 0.901 +- 0.038, 1.000 +- 0.000
suff++_acc_int  =  0.704 +- 0.037, 0.782 +- 0.035, 0.852 +- 0.015
nec class all_L1  =  0.123 +- 0.022, 0.088 +- 0.016, 0.051 +- 0.003, 0.045 +- 0.003
nec class all_KL  =  0.142 +- 0.024, 0.093 +- 0.020, 0.045 +- 0.005, 0.037 +- 0.005
nec_acc_int  =  0.767 +- 0.037, 0.826 +- 0.023, 0.858 +- 0.008, 0.863 +- 0.005

Eval split test
suff++ class all_L1  =  0.803 +- 0.032, 0.841 +- 0.022, 0.925 +- 0.010, 1.000 +- 0.000
suff++ class all_KL  =  0.665 +- 0.072, 0.730 +- 0.063, 0.912 +- 0.029, 1.000 +- 0.000
suff++_acc_int  =  0.651 +- 0.027, 0.725 +- 0.042, 0.799 +- 0.045
nec class all_L1  =  0.128 +- 0.026, 0.099 +- 0.015, 0.067 +- 0.008, 0.059 +- 0.008
nec class all_KL  =  0.157 +- 0.035, 0.109 +- 0.024, 0.061 +- 0.009, 0.050 +- 0.008
nec_acc_int  =  0.712 +- 0.030, 0.770 +- 0.035, 0.805 +- 0.037, 0.811 +- 0.036


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.463 +- 0.008, 0.498 +- 0.004, 0.521 +- 0.004
Faith. Armon (L1)= 		  =  0.159 +- 0.014, 0.083 +- 0.015, 0.079 +- 0.016
Faith. GMean (L1)= 	  =  0.271 +- 0.010, 0.202 +- 0.018, 0.202 +- 0.022
Faith. Aritm (KL)= 		  =  0.395 +- 0.016, 0.499 +- 0.004, 0.519 +- 0.005
Faith. Armon (KL)= 		  =  0.181 +- 0.021, 0.077 +- 0.018, 0.074 +- 0.020
Faith. GMean (KL)= 	  =  0.267 +- 0.012, 0.195 +- 0.024, 0.194 +- 0.027

Eval split val
Faith. Aritm (L1)= 		  =  0.456 +- 0.010, 0.463 +- 0.009, 0.490 +- 0.007, 0.522 +- 0.002
Faith. Armon (L1)= 		  =  0.212 +- 0.032, 0.158 +- 0.026, 0.096 +- 0.005, 0.086 +- 0.006
Faith. GMean (L1)= 	  =  0.310 +- 0.025, 0.270 +- 0.023, 0.217 +- 0.006, 0.212 +- 0.008
Faith. Aritm (KL)= 		  =  0.389 +- 0.027, 0.403 +- 0.020, 0.473 +- 0.017, 0.518 +- 0.003
Faith. Armon (KL)= 		  =  0.229 +- 0.029, 0.163 +- 0.031, 0.086 +- 0.009, 0.071 +- 0.010
Faith. GMean (KL)= 	  =  0.298 +- 0.021, 0.255 +- 0.026, 0.201 +- 0.010, 0.192 +- 0.015

Eval split test
Faith. Aritm (L1)= 		  =  0.465 +- 0.008, 0.470 +- 0.007, 0.496 +- 0.004, 0.530 +- 0.004
Faith. Armon (L1)= 		  =  0.219 +- 0.037, 0.177 +- 0.023, 0.125 +- 0.014, 0.111 +- 0.015
Faith. GMean (L1)= 	  =  0.318 +- 0.027, 0.288 +- 0.019, 0.249 +- 0.014, 0.242 +- 0.017
Faith. Aritm (KL)= 		  =  0.411 +- 0.025, 0.419 +- 0.023, 0.487 +- 0.011, 0.525 +- 0.004
Faith. Armon (KL)= 		  =  0.250 +- 0.042, 0.188 +- 0.035, 0.115 +- 0.015, 0.096 +- 0.014
Faith. GMean (KL)= 	  =  0.319 +- 0.025, 0.279 +- 0.024, 0.236 +- 0.013, 0.223 +- 0.017
Computed for split load_split = id



Completed in  0:17:01.688668  for GSATvGIN GOODSST2/length



DONE GSAT GOODSST2/length

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 22:44:21 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:21 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:24 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:24 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:24 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:26 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:44:28 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 35...
[0m[1;37mINFO[0m: [1mCheckpoint 35: 
-----------------------------------
Train ACCURACY: 0.9819
Train Loss: 0.0593
ID Validation ACCURACY: 0.6877
ID Validation Loss: 1.6620
ID Test ACCURACY: 0.6462
ID Test Loss: 1.7034
OOD Validation ACCURACY: 0.5798
OOD Validation Loss: 2.5076
OOD Test ACCURACY: 0.5333
OOD Test Loss: 3.8144

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 7...
[0m[1;37mINFO[0m: [1mCheckpoint 7: 
-----------------------------------
Train ACCURACY: 0.7409
Train Loss: 0.6367
ID Validation ACCURACY: 0.6643
ID Validation Loss: 0.8006
ID Test ACCURACY: 0.6841
ID Test Loss: 0.7824
OOD Validation ACCURACY: 0.6213
OOD Validation Loss: 0.9502
OOD Test ACCURACY: 0.5765
OOD Test Loss: 1.1552

[0m[1;37mINFO[0m: [1mChartInfo 0.6462 0.5333 0.6841 0.5765 0.6643 0.6213[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.613
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.564
SUFF++ for r=0.3 class 0 = 0.594 +- 0.248 (in-sample avg dev_std = 0.545)
SUFF++ for r=0.3 class 1 = 0.674 +- 0.248 (in-sample avg dev_std = 0.545)
SUFF++ for r=0.3 class 2 = 0.665 +- 0.248 (in-sample avg dev_std = 0.545)
SUFF++ for r=0.3 all KL = 0.582 +- 0.248 (in-sample avg dev_std = 0.545)
SUFF++ for r=0.3 all L1 = 0.652 +- 0.185 (in-sample avg dev_std = 0.545)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.646
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.625
SUFF++ for r=0.6 class 0 = 0.719 +- 0.230 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.6 class 1 = 0.795 +- 0.230 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.6 class 2 = 0.788 +- 0.230 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.6 all KL = 0.768 +- 0.230 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.6 all L1 = 0.775 +- 0.191 (in-sample avg dev_std = 0.387)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.682
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.663
SUFF++ for r=0.9 class 0 = 0.868 +- 0.123 (in-sample avg dev_std = 0.212)
SUFF++ for r=0.9 class 1 = 0.887 +- 0.123 (in-sample avg dev_std = 0.212)
SUFF++ for r=0.9 class 2 = 0.894 +- 0.123 (in-sample avg dev_std = 0.212)
SUFF++ for r=0.9 all KL = 0.928 +- 0.123 (in-sample avg dev_std = 0.212)
SUFF++ for r=0.9 all L1 = 0.884 +- 0.142 (in-sample avg dev_std = 0.212)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.546
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.52
SUFF++ for r=0.3 class 0 = 0.587 +- 0.230 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.3 class 1 = 0.601 +- 0.230 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.3 class 2 = 0.611 +- 0.230 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.3 all KL = 0.542 +- 0.230 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.3 all L1 = 0.599 +- 0.181 (in-sample avg dev_std = 0.534)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.544
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.55
SUFF++ for r=0.6 class 0 = 0.729 +- 0.232 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.6 class 1 = 0.697 +- 0.232 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.6 class 2 = 0.716 +- 0.232 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.6 all KL = 0.698 +- 0.232 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.6 all L1 = 0.709 +- 0.198 (in-sample avg dev_std = 0.414)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.571
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.567
SUFF++ for r=0.9 class 0 = 0.858 +- 0.138 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.9 class 1 = 0.84 +- 0.138 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.9 class 2 = 0.865 +- 0.138 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.9 all KL = 0.909 +- 0.138 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.9 all L1 = 0.85 +- 0.167 (in-sample avg dev_std = 0.203)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.506
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.487
SUFF++ for r=0.3 class 0 = 0.599 +- 0.229 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.3 class 1 = 0.586 +- 0.229 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.3 class 2 = 0.643 +- 0.229 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.3 all KL = 0.559 +- 0.229 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.3 all L1 = 0.603 +- 0.182 (in-sample avg dev_std = 0.503)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.515
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.5
SUFF++ for r=0.6 class 0 = 0.734 +- 0.211 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 class 1 = 0.703 +- 0.211 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 class 2 = 0.764 +- 0.211 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 all KL = 0.739 +- 0.211 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 all L1 = 0.726 +- 0.196 (in-sample avg dev_std = 0.379)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.531
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.521
SUFF++ for r=0.9 class 0 = 0.89 +- 0.096 (in-sample avg dev_std = 0.175)
SUFF++ for r=0.9 class 1 = 0.867 +- 0.096 (in-sample avg dev_std = 0.175)
SUFF++ for r=0.9 class 2 = 0.89 +- 0.096 (in-sample avg dev_std = 0.175)
SUFF++ for r=0.9 all KL = 0.938 +- 0.096 (in-sample avg dev_std = 0.175)
SUFF++ for r=0.9 all L1 = 0.879 +- 0.135 (in-sample avg dev_std = 0.175)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.613
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.606
NEC for r=0.3 class 0 = 0.348 +- 0.259 (in-sample avg dev_std = 0.329)
NEC for r=0.3 class 1 = 0.238 +- 0.259 (in-sample avg dev_std = 0.329)
NEC for r=0.3 class 2 = 0.264 +- 0.259 (in-sample avg dev_std = 0.329)
NEC for r=0.3 all KL = 0.243 +- 0.259 (in-sample avg dev_std = 0.329)
NEC for r=0.3 all L1 = 0.272 +- 0.227 (in-sample avg dev_std = 0.329)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.646
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.628
NEC for r=0.6 class 0 = 0.243 +- 0.217 (in-sample avg dev_std = 0.284)
NEC for r=0.6 class 1 = 0.192 +- 0.217 (in-sample avg dev_std = 0.284)
NEC for r=0.6 class 2 = 0.175 +- 0.217 (in-sample avg dev_std = 0.284)
NEC for r=0.6 all KL = 0.164 +- 0.217 (in-sample avg dev_std = 0.284)
NEC for r=0.6 all L1 = 0.199 +- 0.203 (in-sample avg dev_std = 0.284)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.682
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.66
NEC for r=0.9 class 0 = 0.157 +- 0.135 (in-sample avg dev_std = 0.190)
NEC for r=0.9 class 1 = 0.121 +- 0.135 (in-sample avg dev_std = 0.190)
NEC for r=0.9 class 2 = 0.111 +- 0.135 (in-sample avg dev_std = 0.190)
NEC for r=0.9 all KL = 0.077 +- 0.135 (in-sample avg dev_std = 0.190)
NEC for r=0.9 all L1 = 0.127 +- 0.160 (in-sample avg dev_std = 0.190)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.684
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.667
NEC for r=1.0 class 0 = 0.137 +- 0.107 (in-sample avg dev_std = 0.165)
NEC for r=1.0 class 1 = 0.096 +- 0.107 (in-sample avg dev_std = 0.165)
NEC for r=1.0 class 2 = 0.085 +- 0.107 (in-sample avg dev_std = 0.165)
NEC for r=1.0 all KL = 0.053 +- 0.107 (in-sample avg dev_std = 0.165)
NEC for r=1.0 all L1 = 0.103 +- 0.140 (in-sample avg dev_std = 0.165)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.546
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.54
NEC for r=0.3 class 0 = 0.363 +- 0.278 (in-sample avg dev_std = 0.390)
NEC for r=0.3 class 1 = 0.333 +- 0.278 (in-sample avg dev_std = 0.390)
NEC for r=0.3 class 2 = 0.304 +- 0.278 (in-sample avg dev_std = 0.390)
NEC for r=0.3 all KL = 0.321 +- 0.278 (in-sample avg dev_std = 0.390)
NEC for r=0.3 all L1 = 0.334 +- 0.231 (in-sample avg dev_std = 0.390)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.544
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.561
NEC for r=0.6 class 0 = 0.242 +- 0.238 (in-sample avg dev_std = 0.311)
NEC for r=0.6 class 1 = 0.257 +- 0.238 (in-sample avg dev_std = 0.311)
NEC for r=0.6 class 2 = 0.214 +- 0.238 (in-sample avg dev_std = 0.311)
NEC for r=0.6 all KL = 0.212 +- 0.238 (in-sample avg dev_std = 0.311)
NEC for r=0.6 all L1 = 0.244 +- 0.215 (in-sample avg dev_std = 0.311)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.571
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.567
NEC for r=0.9 class 0 = 0.176 +- 0.167 (in-sample avg dev_std = 0.216)
NEC for r=0.9 class 1 = 0.17 +- 0.167 (in-sample avg dev_std = 0.216)
NEC for r=0.9 class 2 = 0.156 +- 0.167 (in-sample avg dev_std = 0.216)
NEC for r=0.9 all KL = 0.113 +- 0.167 (in-sample avg dev_std = 0.216)
NEC for r=0.9 all L1 = 0.169 +- 0.186 (in-sample avg dev_std = 0.216)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.574
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.571
NEC for r=1.0 class 0 = 0.152 +- 0.143 (in-sample avg dev_std = 0.189)
NEC for r=1.0 class 1 = 0.144 +- 0.143 (in-sample avg dev_std = 0.189)
NEC for r=1.0 class 2 = 0.13 +- 0.143 (in-sample avg dev_std = 0.189)
NEC for r=1.0 all KL = 0.087 +- 0.143 (in-sample avg dev_std = 0.189)
NEC for r=1.0 all L1 = 0.143 +- 0.166 (in-sample avg dev_std = 0.189)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.506
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.528
NEC for r=0.3 class 0 = 0.318 +- 0.252 (in-sample avg dev_std = 0.330)
NEC for r=0.3 class 1 = 0.312 +- 0.252 (in-sample avg dev_std = 0.330)
NEC for r=0.3 class 2 = 0.269 +- 0.252 (in-sample avg dev_std = 0.330)
NEC for r=0.3 all KL = 0.27 +- 0.252 (in-sample avg dev_std = 0.330)
NEC for r=0.3 all L1 = 0.303 +- 0.218 (in-sample avg dev_std = 0.330)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.515
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.518
NEC for r=0.6 class 0 = 0.215 +- 0.198 (in-sample avg dev_std = 0.256)
NEC for r=0.6 class 1 = 0.227 +- 0.198 (in-sample avg dev_std = 0.256)
NEC for r=0.6 class 2 = 0.183 +- 0.198 (in-sample avg dev_std = 0.256)
NEC for r=0.6 all KL = 0.163 +- 0.198 (in-sample avg dev_std = 0.256)
NEC for r=0.6 all L1 = 0.213 +- 0.199 (in-sample avg dev_std = 0.256)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.531
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.53
NEC for r=0.9 class 0 = 0.13 +- 0.127 (in-sample avg dev_std = 0.171)
NEC for r=0.9 class 1 = 0.15 +- 0.127 (in-sample avg dev_std = 0.171)
NEC for r=0.9 class 2 = 0.109 +- 0.127 (in-sample avg dev_std = 0.171)
NEC for r=0.9 all KL = 0.077 +- 0.127 (in-sample avg dev_std = 0.171)
NEC for r=0.9 all L1 = 0.135 +- 0.157 (in-sample avg dev_std = 0.171)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.533
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.535
NEC for r=1.0 class 0 = 0.124 +- 0.130 (in-sample avg dev_std = 0.183)
NEC for r=1.0 class 1 = 0.137 +- 0.130 (in-sample avg dev_std = 0.183)
NEC for r=1.0 class 2 = 0.113 +- 0.130 (in-sample avg dev_std = 0.183)
NEC for r=1.0 all KL = 0.076 +- 0.130 (in-sample avg dev_std = 0.183)
NEC for r=1.0 all L1 = 0.128 +- 0.158 (in-sample avg dev_std = 0.183)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 22:49:43 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:43 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:45 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:45 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:46 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:47 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:49:50 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 32...
[0m[1;37mINFO[0m: [1mCheckpoint 32: 
-----------------------------------
Train ACCURACY: 0.9873
Train Loss: 0.0557
ID Validation ACCURACY: 0.7040
ID Validation Loss: 1.2333
ID Test ACCURACY: 0.6751
ID Test Loss: 1.2914
OOD Validation ACCURACY: 0.6235
OOD Validation Loss: 1.5984
OOD Test ACCURACY: 0.5710
OOD Test Loss: 2.1738

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 10...
[0m[1;37mINFO[0m: [1mCheckpoint 10: 
-----------------------------------
Train ACCURACY: 0.8039
Train Loss: 0.4968
ID Validation ACCURACY: 0.6949
ID Validation Loss: 0.7512
ID Test ACCURACY: 0.6931
ID Test Loss: 0.7845
OOD Validation ACCURACY: 0.6476
OOD Validation Loss: 0.9328
OOD Test ACCURACY: 0.5779
OOD Test Loss: 1.2430

[0m[1;37mINFO[0m: [1mChartInfo 0.6751 0.5710 0.6931 0.5779 0.6949 0.6476[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.617
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.599
SUFF++ for r=0.3 class 0 = 0.589 +- 0.220 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 class 1 = 0.662 +- 0.220 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 class 2 = 0.728 +- 0.220 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 all KL = 0.668 +- 0.220 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 all L1 = 0.662 +- 0.176 (in-sample avg dev_std = 0.462)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.67
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.651
SUFF++ for r=0.6 class 0 = 0.718 +- 0.202 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.6 class 1 = 0.765 +- 0.202 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.6 class 2 = 0.783 +- 0.202 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.6 all KL = 0.79 +- 0.202 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.6 all L1 = 0.759 +- 0.184 (in-sample avg dev_std = 0.350)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.688
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.686
SUFF++ for r=0.9 class 0 = 0.883 +- 0.100 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.9 class 1 = 0.883 +- 0.100 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.9 class 2 = 0.878 +- 0.100 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.9 all KL = 0.941 +- 0.100 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.9 all L1 = 0.881 +- 0.133 (in-sample avg dev_std = 0.182)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.6
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.577
SUFF++ for r=0.3 class 0 = 0.686 +- 0.173 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.3 class 1 = 0.721 +- 0.173 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.3 class 2 = 0.688 +- 0.173 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.3 all KL = 0.793 +- 0.173 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.3 all L1 = 0.705 +- 0.158 (in-sample avg dev_std = 0.332)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.621
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.611
SUFF++ for r=0.6 class 0 = 0.771 +- 0.134 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.6 class 1 = 0.798 +- 0.134 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.6 class 2 = 0.749 +- 0.134 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.6 all KL = 0.863 +- 0.134 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.6 all L1 = 0.781 +- 0.157 (in-sample avg dev_std = 0.266)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.63
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.627
SUFF++ for r=0.9 class 0 = 0.892 +- 0.060 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.9 class 1 = 0.895 +- 0.060 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.9 class 2 = 0.874 +- 0.060 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.9 all KL = 0.958 +- 0.060 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.9 all L1 = 0.89 +- 0.113 (in-sample avg dev_std = 0.145)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.55
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.526
SUFF++ for r=0.3 class 0 = 0.69 +- 0.165 (in-sample avg dev_std = 0.345)
SUFF++ for r=0.3 class 1 = 0.726 +- 0.165 (in-sample avg dev_std = 0.345)
SUFF++ for r=0.3 class 2 = 0.689 +- 0.165 (in-sample avg dev_std = 0.345)
SUFF++ for r=0.3 all KL = 0.791 +- 0.165 (in-sample avg dev_std = 0.345)
SUFF++ for r=0.3 all L1 = 0.707 +- 0.148 (in-sample avg dev_std = 0.345)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.545
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.528
SUFF++ for r=0.6 class 0 = 0.788 +- 0.139 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.6 class 1 = 0.769 +- 0.139 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.6 class 2 = 0.737 +- 0.139 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.6 all KL = 0.837 +- 0.139 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.6 all L1 = 0.766 +- 0.155 (in-sample avg dev_std = 0.311)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.556
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.549
SUFF++ for r=0.9 class 0 = 0.918 +- 0.051 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.9 class 1 = 0.904 +- 0.051 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.9 class 2 = 0.89 +- 0.051 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.9 all KL = 0.965 +- 0.051 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.9 all L1 = 0.904 +- 0.102 (in-sample avg dev_std = 0.148)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.617
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.635
NEC for r=0.3 class 0 = 0.294 +- 0.206 (in-sample avg dev_std = 0.276)
NEC for r=0.3 class 1 = 0.245 +- 0.206 (in-sample avg dev_std = 0.276)
NEC for r=0.3 class 2 = 0.218 +- 0.206 (in-sample avg dev_std = 0.276)
NEC for r=0.3 all KL = 0.176 +- 0.206 (in-sample avg dev_std = 0.276)
NEC for r=0.3 all L1 = 0.25 +- 0.200 (in-sample avg dev_std = 0.276)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.67
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.66
NEC for r=0.6 class 0 = 0.207 +- 0.169 (in-sample avg dev_std = 0.233)
NEC for r=0.6 class 1 = 0.169 +- 0.169 (in-sample avg dev_std = 0.233)
NEC for r=0.6 class 2 = 0.169 +- 0.169 (in-sample avg dev_std = 0.233)
NEC for r=0.6 all KL = 0.114 +- 0.169 (in-sample avg dev_std = 0.233)
NEC for r=0.6 all L1 = 0.178 +- 0.178 (in-sample avg dev_std = 0.233)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.688
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.682
NEC for r=0.9 class 0 = 0.138 +- 0.122 (in-sample avg dev_std = 0.176)
NEC for r=0.9 class 1 = 0.114 +- 0.122 (in-sample avg dev_std = 0.176)
NEC for r=0.9 class 2 = 0.139 +- 0.122 (in-sample avg dev_std = 0.176)
NEC for r=0.9 all KL = 0.064 +- 0.122 (in-sample avg dev_std = 0.176)
NEC for r=0.9 all L1 = 0.127 +- 0.148 (in-sample avg dev_std = 0.176)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.701
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.682
NEC for r=1.0 class 0 = 0.12 +- 0.129 (in-sample avg dev_std = 0.180)
NEC for r=1.0 class 1 = 0.101 +- 0.129 (in-sample avg dev_std = 0.180)
NEC for r=1.0 class 2 = 0.128 +- 0.129 (in-sample avg dev_std = 0.180)
NEC for r=1.0 all KL = 0.06 +- 0.129 (in-sample avg dev_std = 0.180)
NEC for r=1.0 all L1 = 0.113 +- 0.145 (in-sample avg dev_std = 0.180)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.6
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.597
NEC for r=0.3 class 0 = 0.294 +- 0.182 (in-sample avg dev_std = 0.259)
NEC for r=0.3 class 1 = 0.263 +- 0.182 (in-sample avg dev_std = 0.259)
NEC for r=0.3 class 2 = 0.283 +- 0.182 (in-sample avg dev_std = 0.259)
NEC for r=0.3 all KL = 0.176 +- 0.182 (in-sample avg dev_std = 0.259)
NEC for r=0.3 all L1 = 0.275 +- 0.179 (in-sample avg dev_std = 0.259)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.621
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.622
NEC for r=0.6 class 0 = 0.213 +- 0.143 (in-sample avg dev_std = 0.204)
NEC for r=0.6 class 1 = 0.179 +- 0.143 (in-sample avg dev_std = 0.204)
NEC for r=0.6 class 2 = 0.218 +- 0.143 (in-sample avg dev_std = 0.204)
NEC for r=0.6 all KL = 0.108 +- 0.143 (in-sample avg dev_std = 0.204)
NEC for r=0.6 all L1 = 0.196 +- 0.169 (in-sample avg dev_std = 0.204)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.63
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.625
NEC for r=0.9 class 0 = 0.146 +- 0.106 (in-sample avg dev_std = 0.149)
NEC for r=0.9 class 1 = 0.126 +- 0.106 (in-sample avg dev_std = 0.149)
NEC for r=0.9 class 2 = 0.149 +- 0.106 (in-sample avg dev_std = 0.149)
NEC for r=0.9 all KL = 0.064 +- 0.106 (in-sample avg dev_std = 0.149)
NEC for r=0.9 all L1 = 0.136 +- 0.152 (in-sample avg dev_std = 0.149)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.629
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.627
NEC for r=1.0 class 0 = 0.144 +- 0.123 (in-sample avg dev_std = 0.172)
NEC for r=1.0 class 1 = 0.116 +- 0.123 (in-sample avg dev_std = 0.172)
NEC for r=1.0 class 2 = 0.155 +- 0.123 (in-sample avg dev_std = 0.172)
NEC for r=1.0 all KL = 0.07 +- 0.123 (in-sample avg dev_std = 0.172)
NEC for r=1.0 all L1 = 0.131 +- 0.152 (in-sample avg dev_std = 0.172)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.55
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.546
NEC for r=0.3 class 0 = 0.276 +- 0.178 (in-sample avg dev_std = 0.248)
NEC for r=0.3 class 1 = 0.252 +- 0.178 (in-sample avg dev_std = 0.248)
NEC for r=0.3 class 2 = 0.314 +- 0.178 (in-sample avg dev_std = 0.248)
NEC for r=0.3 all KL = 0.17 +- 0.178 (in-sample avg dev_std = 0.248)
NEC for r=0.3 all L1 = 0.273 +- 0.179 (in-sample avg dev_std = 0.248)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.545
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.548
NEC for r=0.6 class 0 = 0.179 +- 0.145 (in-sample avg dev_std = 0.189)
NEC for r=0.6 class 1 = 0.177 +- 0.145 (in-sample avg dev_std = 0.189)
NEC for r=0.6 class 2 = 0.207 +- 0.145 (in-sample avg dev_std = 0.189)
NEC for r=0.6 all KL = 0.101 +- 0.145 (in-sample avg dev_std = 0.189)
NEC for r=0.6 all L1 = 0.185 +- 0.171 (in-sample avg dev_std = 0.189)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.556
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.557
NEC for r=0.9 class 0 = 0.118 +- 0.115 (in-sample avg dev_std = 0.148)
NEC for r=0.9 class 1 = 0.119 +- 0.115 (in-sample avg dev_std = 0.148)
NEC for r=0.9 class 2 = 0.144 +- 0.115 (in-sample avg dev_std = 0.148)
NEC for r=0.9 all KL = 0.062 +- 0.115 (in-sample avg dev_std = 0.148)
NEC for r=0.9 all L1 = 0.125 +- 0.150 (in-sample avg dev_std = 0.148)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.554
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.555
NEC for r=1.0 class 0 = 0.118 +- 0.129 (in-sample avg dev_std = 0.170)
NEC for r=1.0 class 1 = 0.117 +- 0.129 (in-sample avg dev_std = 0.170)
NEC for r=1.0 class 2 = 0.151 +- 0.129 (in-sample avg dev_std = 0.170)
NEC for r=1.0 all KL = 0.07 +- 0.129 (in-sample avg dev_std = 0.170)
NEC for r=1.0 all L1 = 0.126 +- 0.158 (in-sample avg dev_std = 0.170)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 22:55:00 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:00 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:02 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:03 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:03 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:05 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 10:55:07 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 26...
[0m[1;37mINFO[0m: [1mCheckpoint 26: 
-----------------------------------
Train ACCURACY: 0.9622
Train Loss: 0.1169
ID Validation ACCURACY: 0.7058
ID Validation Loss: 1.0059
ID Test ACCURACY: 0.6588
ID Test Loss: 1.1823
OOD Validation ACCURACY: 0.6319
OOD Validation Loss: 1.4492
OOD Test ACCURACY: 0.5635
OOD Test Loss: 2.1363

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 11...
[0m[1;37mINFO[0m: [1mCheckpoint 11: 
-----------------------------------
Train ACCURACY: 0.8077
Train Loss: 0.4721
ID Validation ACCURACY: 0.7004
ID Validation Loss: 0.7735
ID Test ACCURACY: 0.6895
ID Test Loss: 0.8005
OOD Validation ACCURACY: 0.6420
OOD Validation Loss: 0.9580
OOD Test ACCURACY: 0.5964
OOD Test Loss: 1.2456

[0m[1;37mINFO[0m: [1mChartInfo 0.6588 0.5635 0.6895 0.5964 0.7004 0.6420[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.631
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.583
SUFF++ for r=0.3 class 0 = 0.66 +- 0.183 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 class 1 = 0.707 +- 0.183 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 class 2 = 0.624 +- 0.183 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 all KL = 0.738 +- 0.183 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 all L1 = 0.672 +- 0.158 (in-sample avg dev_std = 0.415)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.668
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.65
SUFF++ for r=0.6 class 0 = 0.723 +- 0.164 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.6 class 1 = 0.793 +- 0.164 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.6 class 2 = 0.731 +- 0.164 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.6 all KL = 0.823 +- 0.164 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.6 all L1 = 0.759 +- 0.164 (in-sample avg dev_std = 0.332)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.691
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.699
SUFF++ for r=0.9 class 0 = 0.879 +- 0.078 (in-sample avg dev_std = 0.173)
SUFF++ for r=0.9 class 1 = 0.895 +- 0.078 (in-sample avg dev_std = 0.173)
SUFF++ for r=0.9 class 2 = 0.874 +- 0.078 (in-sample avg dev_std = 0.173)
SUFF++ for r=0.9 all KL = 0.951 +- 0.078 (in-sample avg dev_std = 0.173)
SUFF++ for r=0.9 all L1 = 0.885 +- 0.120 (in-sample avg dev_std = 0.173)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.601
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.598
SUFF++ for r=0.3 class 0 = 0.693 +- 0.136 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.3 class 1 = 0.771 +- 0.136 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.3 class 2 = 0.704 +- 0.136 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.3 all KL = 0.85 +- 0.136 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.3 all L1 = 0.737 +- 0.150 (in-sample avg dev_std = 0.280)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.62
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.616
SUFF++ for r=0.6 class 0 = 0.763 +- 0.120 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.6 class 1 = 0.819 +- 0.120 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.6 class 2 = 0.752 +- 0.120 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.6 all KL = 0.881 +- 0.120 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.6 all L1 = 0.79 +- 0.155 (in-sample avg dev_std = 0.248)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.64
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.631
SUFF++ for r=0.9 class 0 = 0.878 +- 0.060 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.9 class 1 = 0.89 +- 0.060 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.9 class 2 = 0.852 +- 0.060 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.9 all KL = 0.952 +- 0.060 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.9 all L1 = 0.879 +- 0.116 (in-sample avg dev_std = 0.159)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.541
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.539
SUFF++ for r=0.3 class 0 = 0.737 +- 0.115 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.3 class 1 = 0.77 +- 0.115 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.3 class 2 = 0.73 +- 0.115 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.3 all KL = 0.869 +- 0.115 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.3 all L1 = 0.752 +- 0.137 (in-sample avg dev_std = 0.259)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.556
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.541
SUFF++ for r=0.6 class 0 = 0.809 +- 0.124 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.6 class 1 = 0.797 +- 0.124 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.6 class 2 = 0.761 +- 0.124 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.6 all KL = 0.879 +- 0.124 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.6 all L1 = 0.791 +- 0.161 (in-sample avg dev_std = 0.255)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.565
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.555
SUFF++ for r=0.9 class 0 = 0.896 +- 0.080 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.9 class 1 = 0.866 +- 0.080 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.9 class 2 = 0.857 +- 0.080 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.9 all KL = 0.944 +- 0.080 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.9 all L1 = 0.872 +- 0.131 (in-sample avg dev_std = 0.172)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.631
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.617
NEC for r=0.3 class 0 = 0.274 +- 0.185 (in-sample avg dev_std = 0.248)
NEC for r=0.3 class 1 = 0.24 +- 0.185 (in-sample avg dev_std = 0.248)
NEC for r=0.3 class 2 = 0.313 +- 0.185 (in-sample avg dev_std = 0.248)
NEC for r=0.3 all KL = 0.161 +- 0.185 (in-sample avg dev_std = 0.248)
NEC for r=0.3 all L1 = 0.268 +- 0.191 (in-sample avg dev_std = 0.248)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.668
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.67
NEC for r=0.6 class 0 = 0.183 +- 0.126 (in-sample avg dev_std = 0.203)
NEC for r=0.6 class 1 = 0.162 +- 0.126 (in-sample avg dev_std = 0.203)
NEC for r=0.6 class 2 = 0.201 +- 0.126 (in-sample avg dev_std = 0.203)
NEC for r=0.6 all KL = 0.091 +- 0.126 (in-sample avg dev_std = 0.203)
NEC for r=0.6 all L1 = 0.178 +- 0.157 (in-sample avg dev_std = 0.203)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.692
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.684
NEC for r=0.9 class 0 = 0.123 +- 0.083 (in-sample avg dev_std = 0.155)
NEC for r=0.9 class 1 = 0.108 +- 0.083 (in-sample avg dev_std = 0.155)
NEC for r=0.9 class 2 = 0.138 +- 0.083 (in-sample avg dev_std = 0.155)
NEC for r=0.9 all KL = 0.05 +- 0.083 (in-sample avg dev_std = 0.155)
NEC for r=0.9 all L1 = 0.12 +- 0.126 (in-sample avg dev_std = 0.155)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.703
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.685
NEC for r=1.0 class 0 = 0.118 +- 0.090 (in-sample avg dev_std = 0.153)
NEC for r=1.0 class 1 = 0.098 +- 0.090 (in-sample avg dev_std = 0.153)
NEC for r=1.0 class 2 = 0.119 +- 0.090 (in-sample avg dev_std = 0.153)
NEC for r=1.0 all KL = 0.047 +- 0.090 (in-sample avg dev_std = 0.153)
NEC for r=1.0 all L1 = 0.109 +- 0.124 (in-sample avg dev_std = 0.153)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.601
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.609
NEC for r=0.3 class 0 = 0.294 +- 0.151 (in-sample avg dev_std = 0.229)
NEC for r=0.3 class 1 = 0.225 +- 0.151 (in-sample avg dev_std = 0.229)
NEC for r=0.3 class 2 = 0.278 +- 0.151 (in-sample avg dev_std = 0.229)
NEC for r=0.3 all KL = 0.137 +- 0.151 (in-sample avg dev_std = 0.229)
NEC for r=0.3 all L1 = 0.254 +- 0.166 (in-sample avg dev_std = 0.229)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.62
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.63
NEC for r=0.6 class 0 = 0.209 +- 0.110 (in-sample avg dev_std = 0.182)
NEC for r=0.6 class 1 = 0.153 +- 0.110 (in-sample avg dev_std = 0.182)
NEC for r=0.6 class 2 = 0.217 +- 0.110 (in-sample avg dev_std = 0.182)
NEC for r=0.6 all KL = 0.086 +- 0.110 (in-sample avg dev_std = 0.182)
NEC for r=0.6 all L1 = 0.181 +- 0.152 (in-sample avg dev_std = 0.182)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.64
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.63
NEC for r=0.9 class 0 = 0.13 +- 0.080 (in-sample avg dev_std = 0.132)
NEC for r=0.9 class 1 = 0.11 +- 0.080 (in-sample avg dev_std = 0.132)
NEC for r=0.9 class 2 = 0.149 +- 0.080 (in-sample avg dev_std = 0.132)
NEC for r=0.9 all KL = 0.049 +- 0.080 (in-sample avg dev_std = 0.132)
NEC for r=0.9 all L1 = 0.124 +- 0.132 (in-sample avg dev_std = 0.132)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.631
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.629
NEC for r=1.0 class 0 = 0.129 +- 0.098 (in-sample avg dev_std = 0.145)
NEC for r=1.0 class 1 = 0.112 +- 0.098 (in-sample avg dev_std = 0.145)
NEC for r=1.0 class 2 = 0.15 +- 0.098 (in-sample avg dev_std = 0.145)
NEC for r=1.0 all KL = 0.057 +- 0.098 (in-sample avg dev_std = 0.145)
NEC for r=1.0 all L1 = 0.124 +- 0.143 (in-sample avg dev_std = 0.145)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.541
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.542
NEC for r=0.3 class 0 = 0.259 +- 0.139 (in-sample avg dev_std = 0.217)
NEC for r=0.3 class 1 = 0.229 +- 0.139 (in-sample avg dev_std = 0.217)
NEC for r=0.3 class 2 = 0.263 +- 0.139 (in-sample avg dev_std = 0.217)
NEC for r=0.3 all KL = 0.126 +- 0.139 (in-sample avg dev_std = 0.217)
NEC for r=0.3 all L1 = 0.245 +- 0.161 (in-sample avg dev_std = 0.217)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.556
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.553
NEC for r=0.6 class 0 = 0.175 +- 0.120 (in-sample avg dev_std = 0.199)
NEC for r=0.6 class 1 = 0.178 +- 0.120 (in-sample avg dev_std = 0.199)
NEC for r=0.6 class 2 = 0.199 +- 0.120 (in-sample avg dev_std = 0.199)
NEC for r=0.6 all KL = 0.091 +- 0.120 (in-sample avg dev_std = 0.199)
NEC for r=0.6 all L1 = 0.182 +- 0.161 (in-sample avg dev_std = 0.199)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.565
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.566
NEC for r=0.9 class 0 = 0.117 +- 0.088 (in-sample avg dev_std = 0.150)
NEC for r=0.9 class 1 = 0.123 +- 0.088 (in-sample avg dev_std = 0.150)
NEC for r=0.9 class 2 = 0.156 +- 0.088 (in-sample avg dev_std = 0.150)
NEC for r=0.9 all KL = 0.055 +- 0.088 (in-sample avg dev_std = 0.150)
NEC for r=0.9 all L1 = 0.129 +- 0.141 (in-sample avg dev_std = 0.150)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.561
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.561
NEC for r=1.0 class 0 = 0.116 +- 0.106 (in-sample avg dev_std = 0.163)
NEC for r=1.0 class 1 = 0.123 +- 0.106 (in-sample avg dev_std = 0.163)
NEC for r=1.0 class 2 = 0.156 +- 0.106 (in-sample avg dev_std = 0.163)
NEC for r=1.0 all KL = 0.062 +- 0.106 (in-sample avg dev_std = 0.163)
NEC for r=1.0 all L1 = 0.129 +- 0.150 (in-sample avg dev_std = 0.163)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 23:00:21 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:21 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:23 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:24 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:24 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:26 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:00:27 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 163...
[0m[1;37mINFO[0m: [1mCheckpoint 163: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.7076
ID Validation Loss: 2.3068
ID Test ACCURACY: 0.6697
ID Test Loss: 2.5476
OOD Validation ACCURACY: 0.6118
OOD Validation Loss: 2.8631
OOD Test ACCURACY: 0.5559
OOD Test Loss: 3.9096

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 9...
[0m[1;37mINFO[0m: [1mCheckpoint 9: 
-----------------------------------
Train ACCURACY: 0.7730
Train Loss: 0.5461
ID Validation ACCURACY: 0.6877
ID Validation Loss: 0.7610
ID Test ACCURACY: 0.6841
ID Test Loss: 0.7794
OOD Validation ACCURACY: 0.6431
OOD Validation Loss: 0.8959
OOD Test ACCURACY: 0.5944
OOD Test Loss: 1.0740

[0m[1;37mINFO[0m: [1mChartInfo 0.6697 0.5559 0.6841 0.5944 0.6877 0.6431[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.65
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.582
SUFF++ for r=0.3 class 0 = 0.616 +- 0.337 (in-sample avg dev_std = 0.623)
SUFF++ for r=0.3 class 1 = 0.706 +- 0.337 (in-sample avg dev_std = 0.623)
SUFF++ for r=0.3 class 2 = 0.586 +- 0.337 (in-sample avg dev_std = 0.623)
SUFF++ for r=0.3 all KL = 0.419 +- 0.337 (in-sample avg dev_std = 0.623)
SUFF++ for r=0.3 all L1 = 0.651 +- 0.232 (in-sample avg dev_std = 0.623)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.688
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.641
SUFF++ for r=0.6 class 0 = 0.728 +- 0.331 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.6 class 1 = 0.794 +- 0.331 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.6 class 2 = 0.692 +- 0.331 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.6 all KL = 0.61 +- 0.331 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.6 all L1 = 0.749 +- 0.219 (in-sample avg dev_std = 0.482)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.699
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.687
SUFF++ for r=0.9 class 0 = 0.879 +- 0.173 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 class 1 = 0.895 +- 0.173 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 class 2 = 0.87 +- 0.173 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 all KL = 0.895 +- 0.173 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 all L1 = 0.884 +- 0.164 (in-sample avg dev_std = 0.268)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.591
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.567
SUFF++ for r=0.3 class 0 = 0.648 +- 0.315 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 class 1 = 0.689 +- 0.315 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 class 2 = 0.65 +- 0.315 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 all KL = 0.504 +- 0.315 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 all L1 = 0.67 +- 0.220 (in-sample avg dev_std = 0.563)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.611
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.595
SUFF++ for r=0.6 class 0 = 0.749 +- 0.272 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 class 1 = 0.786 +- 0.272 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 class 2 = 0.734 +- 0.272 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 all KL = 0.693 +- 0.272 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 all L1 = 0.766 +- 0.205 (in-sample avg dev_std = 0.417)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.609
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.609
SUFF++ for r=0.9 class 0 = 0.898 +- 0.113 (in-sample avg dev_std = 0.206)
SUFF++ for r=0.9 class 1 = 0.889 +- 0.113 (in-sample avg dev_std = 0.206)
SUFF++ for r=0.9 class 2 = 0.888 +- 0.113 (in-sample avg dev_std = 0.206)
SUFF++ for r=0.9 all KL = 0.926 +- 0.113 (in-sample avg dev_std = 0.206)
SUFF++ for r=0.9 all L1 = 0.891 +- 0.141 (in-sample avg dev_std = 0.206)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.54
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.513
SUFF++ for r=0.3 class 0 = 0.661 +- 0.292 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.3 class 1 = 0.659 +- 0.292 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.3 class 2 = 0.623 +- 0.292 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.3 all KL = 0.49 +- 0.292 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.3 all L1 = 0.651 +- 0.212 (in-sample avg dev_std = 0.557)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.531
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.515
SUFF++ for r=0.6 class 0 = 0.772 +- 0.271 (in-sample avg dev_std = 0.435)
SUFF++ for r=0.6 class 1 = 0.755 +- 0.271 (in-sample avg dev_std = 0.435)
SUFF++ for r=0.6 class 2 = 0.71 +- 0.271 (in-sample avg dev_std = 0.435)
SUFF++ for r=0.6 all KL = 0.667 +- 0.271 (in-sample avg dev_std = 0.435)
SUFF++ for r=0.6 all L1 = 0.749 +- 0.206 (in-sample avg dev_std = 0.435)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.543
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.543
SUFF++ for r=0.9 class 0 = 0.892 +- 0.100 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.9 class 1 = 0.886 +- 0.100 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.9 class 2 = 0.882 +- 0.100 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.9 all KL = 0.926 +- 0.100 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.9 all L1 = 0.887 +- 0.136 (in-sample avg dev_std = 0.197)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.65
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.637
NEC for r=0.3 class 0 = 0.277 +- 0.336 (in-sample avg dev_std = 0.368)
NEC for r=0.3 class 1 = 0.209 +- 0.336 (in-sample avg dev_std = 0.368)
NEC for r=0.3 class 2 = 0.256 +- 0.336 (in-sample avg dev_std = 0.368)
NEC for r=0.3 all KL = 0.286 +- 0.336 (in-sample avg dev_std = 0.368)
NEC for r=0.3 all L1 = 0.238 +- 0.271 (in-sample avg dev_std = 0.368)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.688
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.672
NEC for r=0.6 class 0 = 0.193 +- 0.265 (in-sample avg dev_std = 0.299)
NEC for r=0.6 class 1 = 0.135 +- 0.265 (in-sample avg dev_std = 0.299)
NEC for r=0.6 class 2 = 0.184 +- 0.265 (in-sample avg dev_std = 0.299)
NEC for r=0.6 all KL = 0.169 +- 0.265 (in-sample avg dev_std = 0.299)
NEC for r=0.6 all L1 = 0.163 +- 0.215 (in-sample avg dev_std = 0.299)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.699
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.689
NEC for r=0.9 class 0 = 0.111 +- 0.150 (in-sample avg dev_std = 0.183)
NEC for r=0.9 class 1 = 0.08 +- 0.150 (in-sample avg dev_std = 0.183)
NEC for r=0.9 class 2 = 0.106 +- 0.150 (in-sample avg dev_std = 0.183)
NEC for r=0.9 all KL = 0.069 +- 0.150 (in-sample avg dev_std = 0.183)
NEC for r=0.9 all L1 = 0.095 +- 0.154 (in-sample avg dev_std = 0.183)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.704
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.687
NEC for r=1.0 class 0 = 0.099 +- 0.138 (in-sample avg dev_std = 0.174)
NEC for r=1.0 class 1 = 0.072 +- 0.138 (in-sample avg dev_std = 0.174)
NEC for r=1.0 class 2 = 0.09 +- 0.138 (in-sample avg dev_std = 0.174)
NEC for r=1.0 all KL = 0.059 +- 0.138 (in-sample avg dev_std = 0.174)
NEC for r=1.0 all L1 = 0.084 +- 0.142 (in-sample avg dev_std = 0.174)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.591
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.59
NEC for r=0.3 class 0 = 0.271 +- 0.332 (in-sample avg dev_std = 0.410)
NEC for r=0.3 class 1 = 0.267 +- 0.332 (in-sample avg dev_std = 0.410)
NEC for r=0.3 class 2 = 0.29 +- 0.332 (in-sample avg dev_std = 0.410)
NEC for r=0.3 all KL = 0.335 +- 0.332 (in-sample avg dev_std = 0.410)
NEC for r=0.3 all L1 = 0.273 +- 0.261 (in-sample avg dev_std = 0.410)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.611
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.605
NEC for r=0.6 class 0 = 0.18 +- 0.244 (in-sample avg dev_std = 0.286)
NEC for r=0.6 class 1 = 0.179 +- 0.244 (in-sample avg dev_std = 0.286)
NEC for r=0.6 class 2 = 0.188 +- 0.244 (in-sample avg dev_std = 0.286)
NEC for r=0.6 all KL = 0.177 +- 0.244 (in-sample avg dev_std = 0.286)
NEC for r=0.6 all L1 = 0.181 +- 0.215 (in-sample avg dev_std = 0.286)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.609
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.612
NEC for r=0.9 class 0 = 0.116 +- 0.138 (in-sample avg dev_std = 0.166)
NEC for r=0.9 class 1 = 0.11 +- 0.138 (in-sample avg dev_std = 0.166)
NEC for r=0.9 class 2 = 0.123 +- 0.138 (in-sample avg dev_std = 0.166)
NEC for r=0.9 all KL = 0.072 +- 0.138 (in-sample avg dev_std = 0.166)
NEC for r=0.9 all L1 = 0.114 +- 0.160 (in-sample avg dev_std = 0.166)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.613
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.612
NEC for r=1.0 class 0 = 0.103 +- 0.131 (in-sample avg dev_std = 0.159)
NEC for r=1.0 class 1 = 0.101 +- 0.131 (in-sample avg dev_std = 0.159)
NEC for r=1.0 class 2 = 0.122 +- 0.131 (in-sample avg dev_std = 0.159)
NEC for r=1.0 all KL = 0.065 +- 0.131 (in-sample avg dev_std = 0.159)
NEC for r=1.0 all L1 = 0.106 +- 0.153 (in-sample avg dev_std = 0.159)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.54
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.531
NEC for r=0.3 class 0 = 0.273 +- 0.315 (in-sample avg dev_std = 0.400)
NEC for r=0.3 class 1 = 0.269 +- 0.315 (in-sample avg dev_std = 0.400)
NEC for r=0.3 class 2 = 0.303 +- 0.315 (in-sample avg dev_std = 0.400)
NEC for r=0.3 all KL = 0.324 +- 0.315 (in-sample avg dev_std = 0.400)
NEC for r=0.3 all L1 = 0.279 +- 0.250 (in-sample avg dev_std = 0.400)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.531
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.546
NEC for r=0.6 class 0 = 0.176 +- 0.236 (in-sample avg dev_std = 0.263)
NEC for r=0.6 class 1 = 0.183 +- 0.236 (in-sample avg dev_std = 0.263)
NEC for r=0.6 class 2 = 0.197 +- 0.236 (in-sample avg dev_std = 0.263)
NEC for r=0.6 all KL = 0.178 +- 0.236 (in-sample avg dev_std = 0.263)
NEC for r=0.6 all L1 = 0.184 +- 0.212 (in-sample avg dev_std = 0.263)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.543
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.55
NEC for r=0.9 class 0 = 0.103 +- 0.121 (in-sample avg dev_std = 0.162)
NEC for r=0.9 class 1 = 0.111 +- 0.121 (in-sample avg dev_std = 0.162)
NEC for r=0.9 class 2 = 0.116 +- 0.121 (in-sample avg dev_std = 0.162)
NEC for r=0.9 all KL = 0.065 +- 0.121 (in-sample avg dev_std = 0.162)
NEC for r=0.9 all L1 = 0.11 +- 0.152 (in-sample avg dev_std = 0.162)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.543
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.546
NEC for r=1.0 class 0 = 0.092 +- 0.116 (in-sample avg dev_std = 0.155)
NEC for r=1.0 class 1 = 0.1 +- 0.116 (in-sample avg dev_std = 0.155)
NEC for r=1.0 class 2 = 0.117 +- 0.116 (in-sample avg dev_std = 0.155)
NEC for r=1.0 all KL = 0.059 +- 0.116 (in-sample avg dev_std = 0.155)
NEC for r=1.0 all L1 = 0.102 +- 0.146 (in-sample avg dev_std = 0.155)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 23:05:41 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:41 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:43 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:44 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:44 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:46 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:05:48 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 65...
[0m[1;37mINFO[0m: [1mCheckpoint 65: 
-----------------------------------
Train ACCURACY: 0.9988
Train Loss: 0.0094
ID Validation ACCURACY: 0.7040
ID Validation Loss: 1.7565
ID Test ACCURACY: 0.6643
ID Test Loss: 2.0819
OOD Validation ACCURACY: 0.6084
OOD Validation Loss: 2.4105
OOD Test ACCURACY: 0.5450
OOD Test Loss: 3.1833

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 22...
[0m[1;37mINFO[0m: [1mCheckpoint 22: 
-----------------------------------
Train ACCURACY: 0.9317
Train Loss: 0.2018
ID Validation ACCURACY: 0.6859
ID Validation Loss: 0.9593
ID Test ACCURACY: 0.6769
ID Test Loss: 1.0846
OOD Validation ACCURACY: 0.6476
OOD Validation Loss: 1.2904
OOD Test ACCURACY: 0.6026
OOD Test Loss: 1.8131

[0m[1;37mINFO[0m: [1mChartInfo 0.6643 0.5450 0.6769 0.6026 0.6859 0.6476[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.642
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.581
SUFF++ for r=0.3 class 0 = 0.642 +- 0.271 (in-sample avg dev_std = 0.547)
SUFF++ for r=0.3 class 1 = 0.696 +- 0.271 (in-sample avg dev_std = 0.547)
SUFF++ for r=0.3 class 2 = 0.567 +- 0.271 (in-sample avg dev_std = 0.547)
SUFF++ for r=0.3 all KL = 0.542 +- 0.271 (in-sample avg dev_std = 0.547)
SUFF++ for r=0.3 all L1 = 0.647 +- 0.193 (in-sample avg dev_std = 0.547)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.666
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.633
SUFF++ for r=0.6 class 0 = 0.759 +- 0.272 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.6 class 1 = 0.764 +- 0.272 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.6 class 2 = 0.663 +- 0.272 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.6 all KL = 0.678 +- 0.272 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.6 all L1 = 0.735 +- 0.205 (in-sample avg dev_std = 0.432)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.691
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.682
SUFF++ for r=0.9 class 0 = 0.893 +- 0.148 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 1 = 0.884 +- 0.148 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 2 = 0.823 +- 0.148 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 all KL = 0.898 +- 0.148 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 all L1 = 0.869 +- 0.163 (in-sample avg dev_std = 0.243)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.571
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.562
SUFF++ for r=0.3 class 0 = 0.704 +- 0.236 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.3 class 1 = 0.716 +- 0.236 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.3 class 2 = 0.648 +- 0.236 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.3 all KL = 0.681 +- 0.236 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.3 all L1 = 0.699 +- 0.196 (in-sample avg dev_std = 0.426)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.587
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.587
SUFF++ for r=0.6 class 0 = 0.781 +- 0.215 (in-sample avg dev_std = 0.343)
SUFF++ for r=0.6 class 1 = 0.789 +- 0.215 (in-sample avg dev_std = 0.343)
SUFF++ for r=0.6 class 2 = 0.725 +- 0.215 (in-sample avg dev_std = 0.343)
SUFF++ for r=0.6 all KL = 0.785 +- 0.215 (in-sample avg dev_std = 0.343)
SUFF++ for r=0.6 all L1 = 0.774 +- 0.194 (in-sample avg dev_std = 0.343)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.618
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.609
SUFF++ for r=0.9 class 0 = 0.899 +- 0.104 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.9 class 1 = 0.895 +- 0.104 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.9 class 2 = 0.849 +- 0.104 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.9 all KL = 0.93 +- 0.104 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.9 all L1 = 0.886 +- 0.139 (in-sample avg dev_std = 0.184)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.514
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.504
SUFF++ for r=0.3 class 0 = 0.724 +- 0.234 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.3 class 1 = 0.721 +- 0.234 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.3 class 2 = 0.673 +- 0.234 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.3 all KL = 0.7 +- 0.234 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.3 all L1 = 0.71 +- 0.196 (in-sample avg dev_std = 0.409)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.535
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.52
SUFF++ for r=0.6 class 0 = 0.787 +- 0.213 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.6 class 1 = 0.796 +- 0.213 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.6 class 2 = 0.74 +- 0.213 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.6 all KL = 0.793 +- 0.213 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.6 all L1 = 0.78 +- 0.191 (in-sample avg dev_std = 0.332)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.535
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.531
SUFF++ for r=0.9 class 0 = 0.896 +- 0.094 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.9 class 1 = 0.887 +- 0.094 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.9 class 2 = 0.881 +- 0.094 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.9 all KL = 0.937 +- 0.094 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.9 all L1 = 0.888 +- 0.139 (in-sample avg dev_std = 0.182)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.642
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.631
NEC for r=0.3 class 0 = 0.268 +- 0.284 (in-sample avg dev_std = 0.359)
NEC for r=0.3 class 1 = 0.247 +- 0.284 (in-sample avg dev_std = 0.359)
NEC for r=0.3 class 2 = 0.318 +- 0.284 (in-sample avg dev_std = 0.359)
NEC for r=0.3 all KL = 0.263 +- 0.284 (in-sample avg dev_std = 0.359)
NEC for r=0.3 all L1 = 0.272 +- 0.238 (in-sample avg dev_std = 0.359)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.666
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.651
NEC for r=0.6 class 0 = 0.156 +- 0.222 (in-sample avg dev_std = 0.281)
NEC for r=0.6 class 1 = 0.159 +- 0.222 (in-sample avg dev_std = 0.281)
NEC for r=0.6 class 2 = 0.242 +- 0.222 (in-sample avg dev_std = 0.281)
NEC for r=0.6 all KL = 0.156 +- 0.222 (in-sample avg dev_std = 0.281)
NEC for r=0.6 all L1 = 0.181 +- 0.204 (in-sample avg dev_std = 0.281)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.692
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.675
NEC for r=0.9 class 0 = 0.119 +- 0.148 (in-sample avg dev_std = 0.192)
NEC for r=0.9 class 1 = 0.108 +- 0.148 (in-sample avg dev_std = 0.192)
NEC for r=0.9 class 2 = 0.14 +- 0.148 (in-sample avg dev_std = 0.192)
NEC for r=0.9 all KL = 0.08 +- 0.148 (in-sample avg dev_std = 0.192)
NEC for r=0.9 all L1 = 0.12 +- 0.163 (in-sample avg dev_std = 0.192)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.701
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.675
NEC for r=1.0 class 0 = 0.103 +- 0.142 (in-sample avg dev_std = 0.186)
NEC for r=1.0 class 1 = 0.091 +- 0.142 (in-sample avg dev_std = 0.186)
NEC for r=1.0 class 2 = 0.132 +- 0.142 (in-sample avg dev_std = 0.186)
NEC for r=1.0 all KL = 0.069 +- 0.142 (in-sample avg dev_std = 0.186)
NEC for r=1.0 all L1 = 0.105 +- 0.154 (in-sample avg dev_std = 0.186)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.571
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.585
NEC for r=0.3 class 0 = 0.273 +- 0.268 (in-sample avg dev_std = 0.340)
NEC for r=0.3 class 1 = 0.287 +- 0.268 (in-sample avg dev_std = 0.340)
NEC for r=0.3 class 2 = 0.339 +- 0.268 (in-sample avg dev_std = 0.340)
NEC for r=0.3 all KL = 0.278 +- 0.268 (in-sample avg dev_std = 0.340)
NEC for r=0.3 all L1 = 0.294 +- 0.237 (in-sample avg dev_std = 0.340)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.587
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.605
NEC for r=0.6 class 0 = 0.173 +- 0.193 (in-sample avg dev_std = 0.255)
NEC for r=0.6 class 1 = 0.178 +- 0.193 (in-sample avg dev_std = 0.255)
NEC for r=0.6 class 2 = 0.238 +- 0.193 (in-sample avg dev_std = 0.255)
NEC for r=0.6 all KL = 0.147 +- 0.193 (in-sample avg dev_std = 0.255)
NEC for r=0.6 all L1 = 0.189 +- 0.198 (in-sample avg dev_std = 0.255)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.618
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.614
NEC for r=0.9 class 0 = 0.105 +- 0.116 (in-sample avg dev_std = 0.156)
NEC for r=0.9 class 1 = 0.106 +- 0.116 (in-sample avg dev_std = 0.156)
NEC for r=0.9 class 2 = 0.148 +- 0.116 (in-sample avg dev_std = 0.156)
NEC for r=0.9 all KL = 0.066 +- 0.116 (in-sample avg dev_std = 0.156)
NEC for r=0.9 all L1 = 0.115 +- 0.150 (in-sample avg dev_std = 0.156)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.613
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.615
NEC for r=1.0 class 0 = 0.104 +- 0.125 (in-sample avg dev_std = 0.169)
NEC for r=1.0 class 1 = 0.101 +- 0.125 (in-sample avg dev_std = 0.169)
NEC for r=1.0 class 2 = 0.14 +- 0.125 (in-sample avg dev_std = 0.169)
NEC for r=1.0 all KL = 0.069 +- 0.125 (in-sample avg dev_std = 0.169)
NEC for r=1.0 all L1 = 0.11 +- 0.150 (in-sample avg dev_std = 0.169)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.514
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.514
NEC for r=0.3 class 0 = 0.247 +- 0.246 (in-sample avg dev_std = 0.312)
NEC for r=0.3 class 1 = 0.26 +- 0.246 (in-sample avg dev_std = 0.312)
NEC for r=0.3 class 2 = 0.302 +- 0.246 (in-sample avg dev_std = 0.312)
NEC for r=0.3 all KL = 0.241 +- 0.246 (in-sample avg dev_std = 0.312)
NEC for r=0.3 all L1 = 0.267 +- 0.226 (in-sample avg dev_std = 0.312)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.535
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.526
NEC for r=0.6 class 0 = 0.159 +- 0.184 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 1 = 0.176 +- 0.184 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 2 = 0.207 +- 0.184 (in-sample avg dev_std = 0.237)
NEC for r=0.6 all KL = 0.132 +- 0.184 (in-sample avg dev_std = 0.237)
NEC for r=0.6 all L1 = 0.179 +- 0.195 (in-sample avg dev_std = 0.237)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.535
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.538
NEC for r=0.9 class 0 = 0.109 +- 0.112 (in-sample avg dev_std = 0.158)
NEC for r=0.9 class 1 = 0.113 +- 0.112 (in-sample avg dev_std = 0.158)
NEC for r=0.9 class 2 = 0.126 +- 0.112 (in-sample avg dev_std = 0.158)
NEC for r=0.9 all KL = 0.064 +- 0.112 (in-sample avg dev_std = 0.158)
NEC for r=0.9 all L1 = 0.115 +- 0.154 (in-sample avg dev_std = 0.158)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.533
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.536
NEC for r=1.0 class 0 = 0.102 +- 0.127 (in-sample avg dev_std = 0.170)
NEC for r=1.0 class 1 = 0.113 +- 0.127 (in-sample avg dev_std = 0.170)
NEC for r=1.0 class 2 = 0.123 +- 0.127 (in-sample avg dev_std = 0.170)
NEC for r=1.0 all KL = 0.068 +- 0.127 (in-sample avg dev_std = 0.170)
NEC for r=1.0 all L1 = 0.113 +- 0.159 (in-sample avg dev_std = 0.170)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.582, 0.768, 0.928, 1.0], 'all_L1': [0.652, 0.775, 0.884, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.668, 0.79, 0.941, 1.0], 'all_L1': [0.662, 0.759, 0.881, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.738, 0.823, 0.951, 1.0], 'all_L1': [0.672, 0.759, 0.885, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.419, 0.61, 0.895, 1.0], 'all_L1': [0.651, 0.749, 0.884, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.542, 0.678, 0.898, 1.0], 'all_L1': [0.647, 0.735, 0.869, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.243, 0.164, 0.077, 0.053], 'all_L1': [0.272, 0.199, 0.127, 0.103]}), defaultdict(<class 'list'>, {'all_KL': [0.176, 0.114, 0.064, 0.06], 'all_L1': [0.25, 0.178, 0.127, 0.113]}), defaultdict(<class 'list'>, {'all_KL': [0.161, 0.091, 0.05, 0.047], 'all_L1': [0.268, 0.178, 0.12, 0.109]}), defaultdict(<class 'list'>, {'all_KL': [0.286, 0.169, 0.069, 0.059], 'all_L1': [0.238, 0.163, 0.095, 0.084]}), defaultdict(<class 'list'>, {'all_KL': [0.263, 0.156, 0.08, 0.069], 'all_L1': [0.272, 0.181, 0.12, 0.105]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.542, 0.698, 0.909, 1.0], 'all_L1': [0.599, 0.709, 0.85, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.793, 0.863, 0.958, 1.0], 'all_L1': [0.705, 0.781, 0.89, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.85, 0.881, 0.952, 1.0], 'all_L1': [0.737, 0.79, 0.879, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.504, 0.693, 0.926, 1.0], 'all_L1': [0.67, 0.766, 0.891, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.681, 0.785, 0.93, 1.0], 'all_L1': [0.699, 0.774, 0.886, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.321, 0.212, 0.113, 0.087], 'all_L1': [0.334, 0.244, 0.169, 0.143]}), defaultdict(<class 'list'>, {'all_KL': [0.176, 0.108, 0.064, 0.07], 'all_L1': [0.275, 0.196, 0.136, 0.131]}), defaultdict(<class 'list'>, {'all_KL': [0.137, 0.086, 0.049, 0.057], 'all_L1': [0.254, 0.181, 0.124, 0.124]}), defaultdict(<class 'list'>, {'all_KL': [0.335, 0.177, 0.072, 0.065], 'all_L1': [0.273, 0.181, 0.114, 0.106]}), defaultdict(<class 'list'>, {'all_KL': [0.278, 0.147, 0.066, 0.069], 'all_L1': [0.294, 0.189, 0.115, 0.11]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.559, 0.739, 0.938, 1.0], 'all_L1': [0.603, 0.726, 0.879, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.791, 0.837, 0.965, 1.0], 'all_L1': [0.707, 0.766, 0.904, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.869, 0.879, 0.944, 1.0], 'all_L1': [0.752, 0.791, 0.872, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.49, 0.667, 0.926, 1.0], 'all_L1': [0.651, 0.749, 0.887, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.7, 0.793, 0.937, 1.0], 'all_L1': [0.71, 0.78, 0.888, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.27, 0.163, 0.077, 0.076], 'all_L1': [0.303, 0.213, 0.135, 0.128]}), defaultdict(<class 'list'>, {'all_KL': [0.17, 0.101, 0.062, 0.07], 'all_L1': [0.273, 0.185, 0.125, 0.126]}), defaultdict(<class 'list'>, {'all_KL': [0.126, 0.091, 0.055, 0.062], 'all_L1': [0.245, 0.182, 0.129, 0.129]}), defaultdict(<class 'list'>, {'all_KL': [0.324, 0.178, 0.065, 0.059], 'all_L1': [0.279, 0.184, 0.11, 0.102]}), defaultdict(<class 'list'>, {'all_KL': [0.241, 0.132, 0.064, 0.068], 'all_L1': [0.267, 0.179, 0.115, 0.113]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.657 +- 0.009, 0.755 +- 0.013, 0.881 +- 0.006, 1.000 +- 0.000
suff++ class all_KL  =  0.590 +- 0.109, 0.734 +- 0.078, 0.923 +- 0.023, 1.000 +- 0.000
suff++_acc_int  =  0.582 +- 0.011, 0.640 +- 0.010, 0.683 +- 0.011
nec class all_L1  =  0.260 +- 0.014, 0.180 +- 0.011, 0.118 +- 0.012, 0.103 +- 0.010
nec class all_KL  =  0.226 +- 0.049, 0.139 +- 0.031, 0.068 +- 0.011, 0.058 +- 0.007
nec_acc_int  =  0.625 +- 0.012, 0.657 +- 0.016, 0.678 +- 0.010, 0.679 +- 0.007

Eval split val
suff++ class all_L1  =  0.682 +- 0.047, 0.764 +- 0.029, 0.879 +- 0.015, 1.000 +- 0.000
suff++ class all_KL  =  0.674 +- 0.135, 0.784 +- 0.079, 0.935 +- 0.018, 1.000 +- 0.000
suff++_acc_int  =  0.565 +- 0.025, 0.592 +- 0.023, 0.609 +- 0.022
nec class all_L1  =  0.286 +- 0.027, 0.198 +- 0.024, 0.132 +- 0.020, 0.123 +- 0.014
nec class all_KL  =  0.249 +- 0.079, 0.146 +- 0.046, 0.073 +- 0.021, 0.070 +- 0.010
nec_acc_int  =  0.584 +- 0.023, 0.605 +- 0.024, 0.610 +- 0.022, 0.611 +- 0.021

Eval split test
suff++ class all_L1  =  0.685 +- 0.052, 0.762 +- 0.023, 0.886 +- 0.011, 1.000 +- 0.000
suff++ class all_KL  =  0.682 +- 0.141, 0.783 +- 0.074, 0.942 +- 0.013, 1.000 +- 0.000
suff++_acc_int  =  0.514 +- 0.018, 0.521 +- 0.014, 0.540 +- 0.012
nec class all_L1  =  0.273 +- 0.019, 0.189 +- 0.012, 0.123 +- 0.009, 0.120 +- 0.011
nec class all_KL  =  0.226 +- 0.071, 0.133 +- 0.034, 0.065 +- 0.007, 0.067 +- 0.006
nec_acc_int  =  0.532 +- 0.011, 0.538 +- 0.014, 0.548 +- 0.013, 0.546 +- 0.010


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.458 +- 0.008, 0.468 +- 0.011, 0.499 +- 0.006, 0.551 +- 0.005
Faith. Armon (L1)= 		  =  0.372 +- 0.014, 0.290 +- 0.016, 0.208 +- 0.019, 0.186 +- 0.017
Faith. GMean (L1)= 	  =  0.413 +- 0.011, 0.368 +- 0.014, 0.322 +- 0.017, 0.320 +- 0.016
Faith. Aritm (KL)= 		  =  0.408 +- 0.032, 0.436 +- 0.029, 0.495 +- 0.008, 0.529 +- 0.004
Faith. Armon (KL)= 		  =  0.316 +- 0.037, 0.230 +- 0.042, 0.126 +- 0.018, 0.109 +- 0.013
Faith. GMean (KL)= 	  =  0.357 +- 0.016, 0.315 +- 0.027, 0.249 +- 0.018, 0.240 +- 0.015

Eval split val
Faith. Aritm (L1)= 		  =  0.484 +- 0.013, 0.481 +- 0.006, 0.505 +- 0.005, 0.561 +- 0.007
Faith. Armon (L1)= 		  =  0.401 +- 0.018, 0.314 +- 0.026, 0.228 +- 0.030, 0.218 +- 0.022
Faith. GMean (L1)= 	  =  0.440 +- 0.009, 0.388 +- 0.015, 0.339 +- 0.023, 0.350 +- 0.019
Faith. Aritm (KL)= 		  =  0.462 +- 0.030, 0.465 +- 0.019, 0.504 +- 0.006, 0.535 +- 0.005
Faith. Armon (KL)= 		  =  0.345 +- 0.070, 0.241 +- 0.061, 0.134 +- 0.036, 0.130 +- 0.017
Faith. GMean (KL)= 	  =  0.396 +- 0.034, 0.331 +- 0.038, 0.258 +- 0.034, 0.263 +- 0.018

Eval split test
Faith. Aritm (L1)= 		  =  0.479 +- 0.017, 0.476 +- 0.007, 0.504 +- 0.006, 0.560 +- 0.005
Faith. Armon (L1)= 		  =  0.389 +- 0.011, 0.302 +- 0.014, 0.216 +- 0.014, 0.213 +- 0.017
Faith. GMean (L1)= 	  =  0.432 +- 0.005, 0.379 +- 0.008, 0.330 +- 0.012, 0.345 +- 0.015
Faith. Aritm (KL)= 		  =  0.454 +- 0.036, 0.458 +- 0.021, 0.503 +- 0.006, 0.534 +- 0.003
Faith. Armon (KL)= 		  =  0.323 +- 0.063, 0.224 +- 0.046, 0.121 +- 0.012, 0.126 +- 0.011
Faith. GMean (KL)= 	  =  0.379 +- 0.028, 0.318 +- 0.027, 0.246 +- 0.013, 0.259 +- 0.012
Computed for split load_split = id



Completed in  0:26:26.037689  for LECIvGIN GOODTwitter/length



DONE LECI GOODTwitter/length

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 23:11:00 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:00 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:02 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:02 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:03 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:05 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:06 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:06 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:06 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:06 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:06 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:06 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:06 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:06 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:06 PM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:06 PM : [1mInit Backbone:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:06 PM : [1mCreating vGINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:06 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:06 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:06 PM : [1mInit CLF:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:06 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:06 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:11:06 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 67...
[0m[1;37mINFO[0m: [1mCheckpoint 67: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.7004
ID Validation Loss: 1.4395
ID Test ACCURACY: 0.6498
ID Test Loss: 1.7556
OOD Validation ACCURACY: 0.6269
OOD Validation Loss: 1.7485
OOD Test ACCURACY: 0.5676
OOD Test Loss: 2.4674

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 144...
[0m[1;37mINFO[0m: [1mCheckpoint 144: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0000
ID Validation ACCURACY: 0.6931
ID Validation Loss: 1.6611
ID Test ACCURACY: 0.6588
ID Test Loss: 1.9403
OOD Validation ACCURACY: 0.6409
OOD Validation Loss: 2.1076
OOD Test ACCURACY: 0.5813
OOD Test Loss: 2.4255

[0m[1;37mINFO[0m: [1mChartInfo 0.6498 0.5676 0.6588 0.5813 0.6931 0.6409[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.699
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.658
SUFF++ for r=0.6 class 0 = 0.758 +- 0.255 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.6 class 1 = 0.81 +- 0.255 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.6 class 2 = 0.754 +- 0.255 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.6 all KL = 0.708 +- 0.255 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.6 all L1 = 0.782 +- 0.176 (in-sample avg dev_std = 0.433)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.629
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.627
SUFF++ for r=0.6 class 0 = 0.792 +- 0.193 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.6 class 1 = 0.814 +- 0.193 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.6 class 2 = 0.766 +- 0.193 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.6 all KL = 0.8 +- 0.193 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.6 all L1 = 0.798 +- 0.182 (in-sample avg dev_std = 0.341)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.57
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.553
SUFF++ for r=0.6 class 0 = 0.817 +- 0.190 (in-sample avg dev_std = 0.344)
SUFF++ for r=0.6 class 1 = 0.804 +- 0.190 (in-sample avg dev_std = 0.344)
SUFF++ for r=0.6 class 2 = 0.76 +- 0.190 (in-sample avg dev_std = 0.344)
SUFF++ for r=0.6 all KL = 0.804 +- 0.190 (in-sample avg dev_std = 0.344)
SUFF++ for r=0.6 all L1 = 0.796 +- 0.178 (in-sample avg dev_std = 0.344)


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.699
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.683
NEC for r=0.6 class 0 = 0.145 +- 0.186 (in-sample avg dev_std = 0.208)
NEC for r=0.6 class 1 = 0.116 +- 0.186 (in-sample avg dev_std = 0.208)
NEC for r=0.6 class 2 = 0.176 +- 0.186 (in-sample avg dev_std = 0.208)
NEC for r=0.6 all KL = 0.107 +- 0.186 (in-sample avg dev_std = 0.208)
NEC for r=0.6 all L1 = 0.14 +- 0.192 (in-sample avg dev_std = 0.208)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.629
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.634
NEC for r=0.6 class 0 = 0.198 +- 0.225 (in-sample avg dev_std = 0.241)
NEC for r=0.6 class 1 = 0.181 +- 0.225 (in-sample avg dev_std = 0.241)
NEC for r=0.6 class 2 = 0.213 +- 0.225 (in-sample avg dev_std = 0.241)
NEC for r=0.6 all KL = 0.159 +- 0.225 (in-sample avg dev_std = 0.241)
NEC for r=0.6 all L1 = 0.192 +- 0.219 (in-sample avg dev_std = 0.241)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.57
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.571
NEC for r=0.6 class 0 = 0.179 +- 0.209 (in-sample avg dev_std = 0.231)
NEC for r=0.6 class 1 = 0.172 +- 0.209 (in-sample avg dev_std = 0.231)
NEC for r=0.6 class 2 = 0.219 +- 0.209 (in-sample avg dev_std = 0.231)
NEC for r=0.6 all KL = 0.145 +- 0.209 (in-sample avg dev_std = 0.231)
NEC for r=0.6 all L1 = 0.186 +- 0.213 (in-sample avg dev_std = 0.231)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 23:12:49 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:49 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:51 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:51 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:51 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:53 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:54 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:54 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:54 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:54 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:54 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:54 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:54 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:54 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:54 PM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:54 PM : [1mInit Backbone:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:54 PM : [1mCreating vGINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:54 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:54 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:54 PM : [1mInit CLF:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:54 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:54 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:12:54 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 190...
[0m[1;37mINFO[0m: [1mCheckpoint 190: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0000
ID Validation ACCURACY: 0.6968
ID Validation Loss: 1.8803
ID Test ACCURACY: 0.6552
ID Test Loss: 2.0303
OOD Validation ACCURACY: 0.6415
OOD Validation Loss: 2.1364
OOD Test ACCURACY: 0.5580
OOD Test Loss: 2.5377

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 195...
[0m[1;37mINFO[0m: [1mCheckpoint 195: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0000
ID Validation ACCURACY: 0.6895
ID Validation Loss: 1.7708
ID Test ACCURACY: 0.6625
ID Test Loss: 1.9030
OOD Validation ACCURACY: 0.6471
OOD Validation Loss: 2.0345
OOD Test ACCURACY: 0.5553
OOD Test Loss: 2.4157

[0m[1;37mINFO[0m: [1mChartInfo 0.6552 0.5580 0.6625 0.5553 0.6895 0.6471[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.693
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.635
SUFF++ for r=0.6 class 0 = 0.723 +- 0.305 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.6 class 1 = 0.868 +- 0.305 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.6 class 2 = 0.72 +- 0.305 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.6 all KL = 0.712 +- 0.305 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.6 all L1 = 0.791 +- 0.208 (in-sample avg dev_std = 0.432)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.645
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.625
SUFF++ for r=0.6 class 0 = 0.76 +- 0.243 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.6 class 1 = 0.873 +- 0.243 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.6 class 2 = 0.78 +- 0.243 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.6 all KL = 0.811 +- 0.243 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.6 all L1 = 0.824 +- 0.202 (in-sample avg dev_std = 0.332)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.566
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.547
SUFF++ for r=0.6 class 0 = 0.767 +- 0.215 (in-sample avg dev_std = 0.345)
SUFF++ for r=0.6 class 1 = 0.845 +- 0.215 (in-sample avg dev_std = 0.345)
SUFF++ for r=0.6 class 2 = 0.748 +- 0.215 (in-sample avg dev_std = 0.345)
SUFF++ for r=0.6 all KL = 0.8 +- 0.215 (in-sample avg dev_std = 0.345)
SUFF++ for r=0.6 all L1 = 0.801 +- 0.195 (in-sample avg dev_std = 0.345)


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.693
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.663
NEC for r=0.6 class 0 = 0.162 +- 0.202 (in-sample avg dev_std = 0.207)
NEC for r=0.6 class 1 = 0.104 +- 0.202 (in-sample avg dev_std = 0.207)
NEC for r=0.6 class 2 = 0.155 +- 0.202 (in-sample avg dev_std = 0.207)
NEC for r=0.6 all KL = 0.113 +- 0.202 (in-sample avg dev_std = 0.207)
NEC for r=0.6 all L1 = 0.133 +- 0.196 (in-sample avg dev_std = 0.207)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.645
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.656
NEC for r=0.6 class 0 = 0.203 +- 0.213 (in-sample avg dev_std = 0.213)
NEC for r=0.6 class 1 = 0.124 +- 0.213 (in-sample avg dev_std = 0.213)
NEC for r=0.6 class 2 = 0.167 +- 0.213 (in-sample avg dev_std = 0.213)
NEC for r=0.6 all KL = 0.129 +- 0.213 (in-sample avg dev_std = 0.213)
NEC for r=0.6 all L1 = 0.153 +- 0.208 (in-sample avg dev_std = 0.213)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.566
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.56
NEC for r=0.6 class 0 = 0.211 +- 0.213 (in-sample avg dev_std = 0.231)
NEC for r=0.6 class 1 = 0.141 +- 0.213 (in-sample avg dev_std = 0.231)
NEC for r=0.6 class 2 = 0.205 +- 0.213 (in-sample avg dev_std = 0.231)
NEC for r=0.6 all KL = 0.142 +- 0.213 (in-sample avg dev_std = 0.231)
NEC for r=0.6 all L1 = 0.175 +- 0.213 (in-sample avg dev_std = 0.231)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 23:14:36 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:36 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:37 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:38 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:38 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:40 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:41 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:41 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:41 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:41 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:41 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:41 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:41 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:41 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:41 PM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:41 PM : [1mInit Backbone:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:41 PM : [1mCreating vGINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:41 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:41 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:41 PM : [1mInit CLF:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:41 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:41 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:14:41 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 127...
[0m[1;37mINFO[0m: [1mCheckpoint 127: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.7004
ID Validation Loss: 2.4023
ID Test ACCURACY: 0.6282
ID Test Loss: 2.7740
OOD Validation ACCURACY: 0.6246
OOD Validation Loss: 2.7762
OOD Test ACCURACY: 0.5635
OOD Test Loss: 3.1692

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 193...
[0m[1;37mINFO[0m: [1mCheckpoint 193: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0000
ID Validation ACCURACY: 0.6679
ID Validation Loss: 2.4808
ID Test ACCURACY: 0.6462
ID Test Loss: 2.5342
OOD Validation ACCURACY: 0.6431
OOD Validation Loss: 2.6516
OOD Test ACCURACY: 0.5765
OOD Test Loss: 2.9538

[0m[1;37mINFO[0m: [1mChartInfo 0.6282 0.5635 0.6462 0.5765 0.6679 0.6431[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.699
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.651
SUFF++ for r=0.6 class 0 = 0.804 +- 0.281 (in-sample avg dev_std = 0.413)
SUFF++ for r=0.6 class 1 = 0.818 +- 0.281 (in-sample avg dev_std = 0.413)
SUFF++ for r=0.6 class 2 = 0.744 +- 0.281 (in-sample avg dev_std = 0.413)
SUFF++ for r=0.6 all KL = 0.729 +- 0.281 (in-sample avg dev_std = 0.413)
SUFF++ for r=0.6 all L1 = 0.794 +- 0.215 (in-sample avg dev_std = 0.413)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.639
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.612
SUFF++ for r=0.6 class 0 = 0.801 +- 0.266 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.6 class 1 = 0.808 +- 0.266 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.6 class 2 = 0.771 +- 0.266 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.6 all KL = 0.759 +- 0.266 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.6 all L1 = 0.798 +- 0.221 (in-sample avg dev_std = 0.382)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.56
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.536
SUFF++ for r=0.6 class 0 = 0.795 +- 0.245 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.6 class 1 = 0.793 +- 0.245 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.6 class 2 = 0.752 +- 0.245 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.6 all KL = 0.759 +- 0.245 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.6 all L1 = 0.784 +- 0.216 (in-sample avg dev_std = 0.371)


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.699
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.668
NEC for r=0.6 class 0 = 0.156 +- 0.230 (in-sample avg dev_std = 0.287)
NEC for r=0.6 class 1 = 0.128 +- 0.230 (in-sample avg dev_std = 0.287)
NEC for r=0.6 class 2 = 0.179 +- 0.230 (in-sample avg dev_std = 0.287)
NEC for r=0.6 all KL = 0.146 +- 0.230 (in-sample avg dev_std = 0.287)
NEC for r=0.6 all L1 = 0.149 +- 0.205 (in-sample avg dev_std = 0.287)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.639
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.62
NEC for r=0.6 class 0 = 0.177 +- 0.244 (in-sample avg dev_std = 0.304)
NEC for r=0.6 class 1 = 0.165 +- 0.244 (in-sample avg dev_std = 0.304)
NEC for r=0.6 class 2 = 0.17 +- 0.244 (in-sample avg dev_std = 0.304)
NEC for r=0.6 all KL = 0.176 +- 0.244 (in-sample avg dev_std = 0.304)
NEC for r=0.6 all L1 = 0.169 +- 0.217 (in-sample avg dev_std = 0.304)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.56
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.546
NEC for r=0.6 class 0 = 0.18 +- 0.230 (in-sample avg dev_std = 0.288)
NEC for r=0.6 class 1 = 0.16 +- 0.230 (in-sample avg dev_std = 0.288)
NEC for r=0.6 class 2 = 0.189 +- 0.230 (in-sample avg dev_std = 0.288)
NEC for r=0.6 all KL = 0.161 +- 0.230 (in-sample avg dev_std = 0.288)
NEC for r=0.6 all L1 = 0.172 +- 0.210 (in-sample avg dev_std = 0.288)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 23:16:13 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:13 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:15 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:15 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:16 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:17 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:19 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:19 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:19 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:19 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:19 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:19 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:19 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:19 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:19 PM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:19 PM : [1mInit Backbone:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:19 PM : [1mCreating vGINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:19 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:19 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:19 PM : [1mInit CLF:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:19 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:19 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:16:19 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 30...
[0m[1;37mINFO[0m: [1mCheckpoint 30: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0000
ID Validation ACCURACY: 0.7040
ID Validation Loss: 1.6780
ID Test ACCURACY: 0.6408
ID Test Loss: 1.9436
OOD Validation ACCURACY: 0.6353
OOD Validation Loss: 1.9583
OOD Test ACCURACY: 0.5662
OOD Test Loss: 2.4517

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 72...
[0m[1;37mINFO[0m: [1mCheckpoint 72: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0000
ID Validation ACCURACY: 0.6715
ID Validation Loss: 2.2080
ID Test ACCURACY: 0.6462
ID Test Loss: 2.5187
OOD Validation ACCURACY: 0.6465
OOD Validation Loss: 2.4911
OOD Test ACCURACY: 0.5779
OOD Test Loss: 2.9096

[0m[1;37mINFO[0m: [1mChartInfo 0.6408 0.5662 0.6462 0.5779 0.6715 0.6465[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.704
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.664
SUFF++ for r=0.6 class 0 = 0.765 +- 0.258 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 class 1 = 0.803 +- 0.258 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 class 2 = 0.787 +- 0.258 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 all KL = 0.749 +- 0.258 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 all L1 = 0.789 +- 0.220 (in-sample avg dev_std = 0.379)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.646
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.628
SUFF++ for r=0.6 class 0 = 0.746 +- 0.251 (in-sample avg dev_std = 0.376)
SUFF++ for r=0.6 class 1 = 0.807 +- 0.251 (in-sample avg dev_std = 0.376)
SUFF++ for r=0.6 class 2 = 0.724 +- 0.251 (in-sample avg dev_std = 0.376)
SUFF++ for r=0.6 all KL = 0.754 +- 0.251 (in-sample avg dev_std = 0.376)
SUFF++ for r=0.6 all L1 = 0.774 +- 0.224 (in-sample avg dev_std = 0.376)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.572
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.548
SUFF++ for r=0.6 class 0 = 0.788 +- 0.234 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.6 class 1 = 0.778 +- 0.234 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.6 class 2 = 0.729 +- 0.234 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.6 all KL = 0.757 +- 0.234 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.6 all L1 = 0.768 +- 0.212 (in-sample avg dev_std = 0.378)


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.704
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.68
NEC for r=0.6 class 0 = 0.144 +- 0.159 (in-sample avg dev_std = 0.231)
NEC for r=0.6 class 1 = 0.123 +- 0.159 (in-sample avg dev_std = 0.231)
NEC for r=0.6 class 2 = 0.131 +- 0.159 (in-sample avg dev_std = 0.231)
NEC for r=0.6 all KL = 0.099 +- 0.159 (in-sample avg dev_std = 0.231)
NEC for r=0.6 all L1 = 0.131 +- 0.178 (in-sample avg dev_std = 0.231)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.646
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.635
NEC for r=0.6 class 0 = 0.176 +- 0.205 (in-sample avg dev_std = 0.278)
NEC for r=0.6 class 1 = 0.145 +- 0.205 (in-sample avg dev_std = 0.278)
NEC for r=0.6 class 2 = 0.213 +- 0.205 (in-sample avg dev_std = 0.278)
NEC for r=0.6 all KL = 0.142 +- 0.205 (in-sample avg dev_std = 0.278)
NEC for r=0.6 all L1 = 0.167 +- 0.204 (in-sample avg dev_std = 0.278)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.572
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.569
NEC for r=0.6 class 0 = 0.156 +- 0.198 (in-sample avg dev_std = 0.271)
NEC for r=0.6 class 1 = 0.152 +- 0.198 (in-sample avg dev_std = 0.271)
NEC for r=0.6 class 2 = 0.193 +- 0.198 (in-sample avg dev_std = 0.271)
NEC for r=0.6 all KL = 0.133 +- 0.198 (in-sample avg dev_std = 0.271)
NEC for r=0.6 all L1 = 0.163 +- 0.190 (in-sample avg dev_std = 0.271)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 23:17:48 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:48 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:50 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:50 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:51 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:52 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:54 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:54 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:54 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:54 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:54 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:54 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:54 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:54 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:54 PM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:54 PM : [1mInit Backbone:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:54 PM : [1mCreating vGINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:54 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:54 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:54 PM : [1mInit CLF:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:54 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:54 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:17:54 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 131...
[0m[1;37mINFO[0m: [1mCheckpoint 131: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0000
ID Validation ACCURACY: 0.6841
ID Validation Loss: 2.1540
ID Test ACCURACY: 0.6462
ID Test Loss: 2.4067
OOD Validation ACCURACY: 0.6123
OOD Validation Loss: 2.5559
OOD Test ACCURACY: 0.5511
OOD Test Loss: 3.1148

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 190...
[0m[1;37mINFO[0m: [1mCheckpoint 190: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0000
ID Validation ACCURACY: 0.6643
ID Validation Loss: 2.4438
ID Test ACCURACY: 0.6408
ID Test Loss: 2.7934
OOD Validation ACCURACY: 0.6359
OOD Validation Loss: 2.7242
OOD Test ACCURACY: 0.5704
OOD Test Loss: 3.1535

[0m[1;37mINFO[0m: [1mChartInfo 0.6462 0.5511 0.6408 0.5704 0.6643 0.6359[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.681
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.646
SUFF++ for r=0.6 class 0 = 0.795 +- 0.293 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.6 class 1 = 0.817 +- 0.293 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.6 class 2 = 0.754 +- 0.293 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.6 all KL = 0.72 +- 0.293 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.6 all L1 = 0.794 +- 0.224 (in-sample avg dev_std = 0.393)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.611
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.594
SUFF++ for r=0.6 class 0 = 0.773 +- 0.259 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.6 class 1 = 0.777 +- 0.259 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.6 class 2 = 0.739 +- 0.259 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.6 all KL = 0.732 +- 0.259 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.6 all L1 = 0.768 +- 0.223 (in-sample avg dev_std = 0.399)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.534
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.531
SUFF++ for r=0.6 class 0 = 0.791 +- 0.250 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 class 1 = 0.759 +- 0.250 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 class 2 = 0.744 +- 0.250 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 all KL = 0.734 +- 0.250 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 all L1 = 0.764 +- 0.216 (in-sample avg dev_std = 0.392)


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.681
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.664
NEC for r=0.6 class 0 = 0.148 +- 0.219 (in-sample avg dev_std = 0.266)
NEC for r=0.6 class 1 = 0.12 +- 0.219 (in-sample avg dev_std = 0.266)
NEC for r=0.6 class 2 = 0.164 +- 0.219 (in-sample avg dev_std = 0.266)
NEC for r=0.6 all KL = 0.135 +- 0.219 (in-sample avg dev_std = 0.266)
NEC for r=0.6 all L1 = 0.139 +- 0.193 (in-sample avg dev_std = 0.266)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.611
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.598
NEC for r=0.6 class 0 = 0.175 +- 0.235 (in-sample avg dev_std = 0.312)
NEC for r=0.6 class 1 = 0.183 +- 0.235 (in-sample avg dev_std = 0.312)
NEC for r=0.6 class 2 = 0.211 +- 0.235 (in-sample avg dev_std = 0.312)
NEC for r=0.6 all KL = 0.179 +- 0.235 (in-sample avg dev_std = 0.312)
NEC for r=0.6 all L1 = 0.187 +- 0.214 (in-sample avg dev_std = 0.312)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.534
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.527
NEC for r=0.6 class 0 = 0.146 +- 0.219 (in-sample avg dev_std = 0.290)
NEC for r=0.6 class 1 = 0.187 +- 0.219 (in-sample avg dev_std = 0.290)
NEC for r=0.6 class 2 = 0.196 +- 0.219 (in-sample avg dev_std = 0.290)
NEC for r=0.6 all KL = 0.162 +- 0.219 (in-sample avg dev_std = 0.290)
NEC for r=0.6 all L1 = 0.179 +- 0.200 (in-sample avg dev_std = 0.290)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.708], 'all_L1': [0.782]}), defaultdict(<class 'list'>, {'all_KL': [0.712], 'all_L1': [0.791]}), defaultdict(<class 'list'>, {'all_KL': [0.729], 'all_L1': [0.794]}), defaultdict(<class 'list'>, {'all_KL': [0.749], 'all_L1': [0.789]}), defaultdict(<class 'list'>, {'all_KL': [0.72], 'all_L1': [0.794]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.107], 'all_L1': [0.14]}), defaultdict(<class 'list'>, {'all_KL': [0.113], 'all_L1': [0.133]}), defaultdict(<class 'list'>, {'all_KL': [0.146], 'all_L1': [0.149]}), defaultdict(<class 'list'>, {'all_KL': [0.099], 'all_L1': [0.131]}), defaultdict(<class 'list'>, {'all_KL': [0.135], 'all_L1': [0.139]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.8], 'all_L1': [0.798]}), defaultdict(<class 'list'>, {'all_KL': [0.811], 'all_L1': [0.824]}), defaultdict(<class 'list'>, {'all_KL': [0.759], 'all_L1': [0.798]}), defaultdict(<class 'list'>, {'all_KL': [0.754], 'all_L1': [0.774]}), defaultdict(<class 'list'>, {'all_KL': [0.732], 'all_L1': [0.768]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.159], 'all_L1': [0.192]}), defaultdict(<class 'list'>, {'all_KL': [0.129], 'all_L1': [0.153]}), defaultdict(<class 'list'>, {'all_KL': [0.176], 'all_L1': [0.169]}), defaultdict(<class 'list'>, {'all_KL': [0.142], 'all_L1': [0.167]}), defaultdict(<class 'list'>, {'all_KL': [0.179], 'all_L1': [0.187]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.804], 'all_L1': [0.796]}), defaultdict(<class 'list'>, {'all_KL': [0.8], 'all_L1': [0.801]}), defaultdict(<class 'list'>, {'all_KL': [0.759], 'all_L1': [0.784]}), defaultdict(<class 'list'>, {'all_KL': [0.757], 'all_L1': [0.768]}), defaultdict(<class 'list'>, {'all_KL': [0.734], 'all_L1': [0.764]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.145], 'all_L1': [0.186]}), defaultdict(<class 'list'>, {'all_KL': [0.142], 'all_L1': [0.175]}), defaultdict(<class 'list'>, {'all_KL': [0.161], 'all_L1': [0.172]}), defaultdict(<class 'list'>, {'all_KL': [0.133], 'all_L1': [0.163]}), defaultdict(<class 'list'>, {'all_KL': [0.162], 'all_L1': [0.179]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.790 +- 0.004
suff++ class all_KL  =  0.724 +- 0.015
suff++_acc_int  =  0.651 +- 0.010
nec class all_L1  =  0.138 +- 0.006
nec class all_KL  =  0.120 +- 0.018
nec_acc_int  =  0.672 +- 0.008

Eval split val
suff++ class all_L1  =  0.792 +- 0.020
suff++ class all_KL  =  0.771 +- 0.030
suff++_acc_int  =  0.617 +- 0.013
nec class all_L1  =  0.174 +- 0.014
nec class all_KL  =  0.157 +- 0.019
nec_acc_int  =  0.629 +- 0.019

Eval split test
suff++ class all_L1  =  0.783 +- 0.015
suff++ class all_KL  =  0.771 +- 0.027
suff++_acc_int  =  0.543 +- 0.008
nec class all_L1  =  0.175 +- 0.008
nec class all_KL  =  0.149 +- 0.011
nec_acc_int  =  0.555 +- 0.017


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.464 +- 0.004
Faith. Armon (L1)= 		  =  0.235 +- 0.009
Faith. GMean (L1)= 	  =  0.331 +- 0.008
Faith. Aritm (KL)= 		  =  0.422 +- 0.011
Faith. Armon (KL)= 		  =  0.205 +- 0.026
Faith. GMean (KL)= 	  =  0.294 +- 0.021

Eval split val
Faith. Aritm (L1)= 		  =  0.483 +- 0.008
Faith. Armon (L1)= 		  =  0.284 +- 0.019
Faith. GMean (L1)= 	  =  0.370 +- 0.013
Faith. Aritm (KL)= 		  =  0.464 +- 0.011
Faith. Armon (KL)= 		  =  0.260 +- 0.026
Faith. GMean (KL)= 	  =  0.347 +- 0.018

Eval split test
Faith. Aritm (L1)= 		  =  0.479 +- 0.010
Faith. Armon (L1)= 		  =  0.286 +- 0.011
Faith. GMean (L1)= 	  =  0.370 +- 0.010
Faith. Aritm (KL)= 		  =  0.460 +- 0.012
Faith. Armon (KL)= 		  =  0.249 +- 0.015
Faith. GMean (KL)= 	  =  0.338 +- 0.011
Computed for split load_split = id



Completed in  0:08:27.775092  for CIGAvGIN GOODTwitter/length



DONE CIGA GOODTwitter/length

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 23:19:36 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 03/22/2024 11:19:36 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 11:19:38 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 11:19:38 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 11:19:38 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 11:19:40 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 11:19:42 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 11:19:42 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 11:19:42 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:19:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:19:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:19:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:19:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:19:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:19:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:19:42 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:19:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:19:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:19:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:19:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:19:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:19:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:19:42 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:19:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:19:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:19:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:19:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:19:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:19:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:19:42 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 39...
[0m[1;37mINFO[0m: [1mCheckpoint 39: 
-----------------------------------
Train ACCURACY: 0.9965
Train Loss: 0.0177
ID Validation ACCURACY: 0.6931
ID Validation Loss: 1.6171
ID Test ACCURACY: 0.6318
ID Test Loss: 1.8774
OOD Validation ACCURACY: 0.6011
OOD Validation Loss: 2.2998
OOD Test ACCURACY: 0.5319
OOD Test Loss: 3.2275

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 91...
[0m[1;37mINFO[0m: [1mCheckpoint 91: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0007
ID Validation ACCURACY: 0.6715
ID Validation Loss: 2.2483
ID Test ACCURACY: 0.6498
ID Test Loss: 2.4645
OOD Validation ACCURACY: 0.6353
OOD Validation Loss: 2.6045
OOD Test ACCURACY: 0.5765
OOD Test Loss: 3.1984

[0m[1;37mINFO[0m: [1mChartInfo 0.6318 0.5319 0.6498 0.5765 0.6715 0.6353[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.604
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.547
SUFF++ for r=0.3 class 0 = 0.662 +- 0.274 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.3 class 1 = 0.734 +- 0.274 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.3 class 2 = 0.589 +- 0.274 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.3 all KL = 0.6 +- 0.274 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.3 all L1 = 0.676 +- 0.205 (in-sample avg dev_std = 0.520)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.648
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.618
SUFF++ for r=0.6 class 0 = 0.791 +- 0.259 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.6 class 1 = 0.808 +- 0.259 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.6 class 2 = 0.713 +- 0.259 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.6 all KL = 0.74 +- 0.259 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.6 all L1 = 0.777 +- 0.204 (in-sample avg dev_std = 0.409)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.699
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.673
SUFF++ for r=0.9 class 0 = 0.897 +- 0.135 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.9 class 1 = 0.889 +- 0.135 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.9 class 2 = 0.883 +- 0.135 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.9 all KL = 0.917 +- 0.135 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.9 all L1 = 0.889 +- 0.141 (in-sample avg dev_std = 0.233)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.586
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.563
SUFF++ for r=0.3 class 0 = 0.677 +- 0.276 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.3 class 1 = 0.741 +- 0.276 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.3 class 2 = 0.674 +- 0.276 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.3 all KL = 0.646 +- 0.276 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.3 all L1 = 0.71 +- 0.212 (in-sample avg dev_std = 0.494)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.595
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.586
SUFF++ for r=0.6 class 0 = 0.783 +- 0.235 (in-sample avg dev_std = 0.376)
SUFF++ for r=0.6 class 1 = 0.82 +- 0.235 (in-sample avg dev_std = 0.376)
SUFF++ for r=0.6 class 2 = 0.735 +- 0.235 (in-sample avg dev_std = 0.376)
SUFF++ for r=0.6 all KL = 0.782 +- 0.235 (in-sample avg dev_std = 0.376)
SUFF++ for r=0.6 all L1 = 0.793 +- 0.195 (in-sample avg dev_std = 0.376)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.601
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.601
SUFF++ for r=0.9 class 0 = 0.863 +- 0.151 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.9 class 1 = 0.891 +- 0.151 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.9 class 2 = 0.845 +- 0.151 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.9 all KL = 0.917 +- 0.151 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.9 all L1 = 0.874 +- 0.165 (in-sample avg dev_std = 0.207)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.536
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.515
SUFF++ for r=0.3 class 0 = 0.668 +- 0.276 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.3 class 1 = 0.733 +- 0.276 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.3 class 2 = 0.654 +- 0.276 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.3 all KL = 0.629 +- 0.276 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.3 all L1 = 0.697 +- 0.216 (in-sample avg dev_std = 0.501)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.536
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.526
SUFF++ for r=0.6 class 0 = 0.784 +- 0.242 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.6 class 1 = 0.818 +- 0.242 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.6 class 2 = 0.741 +- 0.242 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.6 all KL = 0.775 +- 0.242 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.6 all L1 = 0.79 +- 0.198 (in-sample avg dev_std = 0.382)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.544
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.538
SUFF++ for r=0.9 class 0 = 0.89 +- 0.124 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.9 class 1 = 0.896 +- 0.124 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.9 class 2 = 0.862 +- 0.124 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.9 all KL = 0.928 +- 0.124 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.9 all L1 = 0.886 +- 0.155 (in-sample avg dev_std = 0.195)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.604
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.61
NEC for r=0.3 class 0 = 0.263 +- 0.248 (in-sample avg dev_std = 0.305)
NEC for r=0.3 class 1 = 0.192 +- 0.248 (in-sample avg dev_std = 0.305)
NEC for r=0.3 class 2 = 0.263 +- 0.248 (in-sample avg dev_std = 0.305)
NEC for r=0.3 all KL = 0.2 +- 0.248 (in-sample avg dev_std = 0.305)
NEC for r=0.3 all L1 = 0.229 +- 0.229 (in-sample avg dev_std = 0.305)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.648
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.638
NEC for r=0.6 class 0 = 0.187 +- 0.206 (in-sample avg dev_std = 0.264)
NEC for r=0.6 class 1 = 0.147 +- 0.206 (in-sample avg dev_std = 0.264)
NEC for r=0.6 class 2 = 0.18 +- 0.206 (in-sample avg dev_std = 0.264)
NEC for r=0.6 all KL = 0.137 +- 0.206 (in-sample avg dev_std = 0.264)
NEC for r=0.6 all L1 = 0.166 +- 0.201 (in-sample avg dev_std = 0.264)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.699
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.672
NEC for r=0.9 class 0 = 0.12 +- 0.170 (in-sample avg dev_std = 0.229)
NEC for r=0.9 class 1 = 0.117 +- 0.170 (in-sample avg dev_std = 0.229)
NEC for r=0.9 class 2 = 0.137 +- 0.170 (in-sample avg dev_std = 0.229)
NEC for r=0.9 all KL = 0.093 +- 0.170 (in-sample avg dev_std = 0.229)
NEC for r=0.9 all L1 = 0.123 +- 0.170 (in-sample avg dev_std = 0.229)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.695
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.672
NEC for r=1.0 class 0 = 0.111 +- 0.156 (in-sample avg dev_std = 0.215)
NEC for r=1.0 class 1 = 0.117 +- 0.156 (in-sample avg dev_std = 0.215)
NEC for r=1.0 class 2 = 0.123 +- 0.156 (in-sample avg dev_std = 0.215)
NEC for r=1.0 all KL = 0.083 +- 0.156 (in-sample avg dev_std = 0.215)
NEC for r=1.0 all L1 = 0.117 +- 0.163 (in-sample avg dev_std = 0.215)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.586
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.59
NEC for r=0.3 class 0 = 0.291 +- 0.262 (in-sample avg dev_std = 0.338)
NEC for r=0.3 class 1 = 0.202 +- 0.262 (in-sample avg dev_std = 0.338)
NEC for r=0.3 class 2 = 0.225 +- 0.262 (in-sample avg dev_std = 0.338)
NEC for r=0.3 all KL = 0.22 +- 0.262 (in-sample avg dev_std = 0.338)
NEC for r=0.3 all L1 = 0.229 +- 0.234 (in-sample avg dev_std = 0.338)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.595
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.608
NEC for r=0.6 class 0 = 0.22 +- 0.222 (in-sample avg dev_std = 0.286)
NEC for r=0.6 class 1 = 0.156 +- 0.222 (in-sample avg dev_std = 0.286)
NEC for r=0.6 class 2 = 0.209 +- 0.222 (in-sample avg dev_std = 0.286)
NEC for r=0.6 all KL = 0.158 +- 0.222 (in-sample avg dev_std = 0.286)
NEC for r=0.6 all L1 = 0.183 +- 0.212 (in-sample avg dev_std = 0.286)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.601
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.614
NEC for r=0.9 class 0 = 0.161 +- 0.164 (in-sample avg dev_std = 0.212)
NEC for r=0.9 class 1 = 0.127 +- 0.164 (in-sample avg dev_std = 0.212)
NEC for r=0.9 class 2 = 0.174 +- 0.164 (in-sample avg dev_std = 0.212)
NEC for r=0.9 all KL = 0.104 +- 0.164 (in-sample avg dev_std = 0.212)
NEC for r=0.9 all L1 = 0.145 +- 0.182 (in-sample avg dev_std = 0.212)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.611
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.609
NEC for r=1.0 class 0 = 0.142 +- 0.157 (in-sample avg dev_std = 0.204)
NEC for r=1.0 class 1 = 0.133 +- 0.157 (in-sample avg dev_std = 0.204)
NEC for r=1.0 class 2 = 0.158 +- 0.157 (in-sample avg dev_std = 0.204)
NEC for r=1.0 all KL = 0.097 +- 0.157 (in-sample avg dev_std = 0.204)
NEC for r=1.0 all L1 = 0.14 +- 0.176 (in-sample avg dev_std = 0.204)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.536
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.531
NEC for r=0.3 class 0 = 0.261 +- 0.247 (in-sample avg dev_std = 0.330)
NEC for r=0.3 class 1 = 0.194 +- 0.247 (in-sample avg dev_std = 0.330)
NEC for r=0.3 class 2 = 0.242 +- 0.247 (in-sample avg dev_std = 0.330)
NEC for r=0.3 all KL = 0.211 +- 0.247 (in-sample avg dev_std = 0.330)
NEC for r=0.3 all L1 = 0.223 +- 0.221 (in-sample avg dev_std = 0.330)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.536
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.534
NEC for r=0.6 class 0 = 0.184 +- 0.214 (in-sample avg dev_std = 0.275)
NEC for r=0.6 class 1 = 0.155 +- 0.214 (in-sample avg dev_std = 0.275)
NEC for r=0.6 class 2 = 0.193 +- 0.214 (in-sample avg dev_std = 0.275)
NEC for r=0.6 all KL = 0.145 +- 0.214 (in-sample avg dev_std = 0.275)
NEC for r=0.6 all L1 = 0.172 +- 0.205 (in-sample avg dev_std = 0.275)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.544
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.541
NEC for r=0.9 class 0 = 0.137 +- 0.153 (in-sample avg dev_std = 0.203)
NEC for r=0.9 class 1 = 0.118 +- 0.153 (in-sample avg dev_std = 0.203)
NEC for r=0.9 class 2 = 0.157 +- 0.153 (in-sample avg dev_std = 0.203)
NEC for r=0.9 all KL = 0.093 +- 0.153 (in-sample avg dev_std = 0.203)
NEC for r=0.9 all L1 = 0.133 +- 0.173 (in-sample avg dev_std = 0.203)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.543
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.541
NEC for r=1.0 class 0 = 0.124 +- 0.155 (in-sample avg dev_std = 0.204)
NEC for r=1.0 class 1 = 0.114 +- 0.155 (in-sample avg dev_std = 0.204)
NEC for r=1.0 class 2 = 0.148 +- 0.155 (in-sample avg dev_std = 0.204)
NEC for r=1.0 all KL = 0.087 +- 0.155 (in-sample avg dev_std = 0.204)
NEC for r=1.0 all L1 = 0.125 +- 0.172 (in-sample avg dev_std = 0.204)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 23:24:26 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 03/22/2024 11:24:26 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 11:24:28 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 11:24:28 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 11:24:29 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 11:24:31 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 11:24:32 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 11:24:32 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 11:24:32 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:24:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:24:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:24:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:24:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:24:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:24:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:24:32 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:24:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:24:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:24:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:24:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:24:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:24:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:24:32 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:24:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:24:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:24:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:24:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:24:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:24:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:24:32 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 115...
[0m[1;37mINFO[0m: [1mCheckpoint 115: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0007
ID Validation ACCURACY: 0.7004
ID Validation Loss: 2.0560
ID Test ACCURACY: 0.6715
ID Test Loss: 2.3868
OOD Validation ACCURACY: 0.6331
OOD Validation Loss: 2.6110
OOD Test ACCURACY: 0.5518
OOD Test Loss: 3.4085

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 115...
[0m[1;37mINFO[0m: [1mCheckpoint 115: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0007
ID Validation ACCURACY: 0.7004
ID Validation Loss: 2.0560
ID Test ACCURACY: 0.6715
ID Test Loss: 2.3868
OOD Validation ACCURACY: 0.6331
OOD Validation Loss: 2.6110
OOD Test ACCURACY: 0.5518
OOD Test Loss: 3.4085

[0m[1;37mINFO[0m: [1mChartInfo 0.6715 0.5518 0.6715 0.5518 0.7004 0.6331[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.661
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.573
SUFF++ for r=0.3 class 0 = 0.59 +- 0.307 (in-sample avg dev_std = 0.666)
SUFF++ for r=0.3 class 1 = 0.682 +- 0.307 (in-sample avg dev_std = 0.666)
SUFF++ for r=0.3 class 2 = 0.576 +- 0.307 (in-sample avg dev_std = 0.666)
SUFF++ for r=0.3 all KL = 0.377 +- 0.307 (in-sample avg dev_std = 0.666)
SUFF++ for r=0.3 all L1 = 0.63 +- 0.212 (in-sample avg dev_std = 0.666)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.646
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.636
SUFF++ for r=0.6 class 0 = 0.785 +- 0.335 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 class 1 = 0.805 +- 0.335 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 class 2 = 0.725 +- 0.335 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 all KL = 0.647 +- 0.335 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 all L1 = 0.778 +- 0.229 (in-sample avg dev_std = 0.483)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.682
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.67
SUFF++ for r=0.9 class 0 = 0.894 +- 0.176 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 class 1 = 0.906 +- 0.176 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 class 2 = 0.887 +- 0.176 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 all KL = 0.906 +- 0.176 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 all L1 = 0.898 +- 0.158 (in-sample avg dev_std = 0.239)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.629
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.585
SUFF++ for r=0.3 class 0 = 0.642 +- 0.339 (in-sample avg dev_std = 0.600)
SUFF++ for r=0.3 class 1 = 0.727 +- 0.339 (in-sample avg dev_std = 0.600)
SUFF++ for r=0.3 class 2 = 0.618 +- 0.339 (in-sample avg dev_std = 0.600)
SUFF++ for r=0.3 all KL = 0.467 +- 0.339 (in-sample avg dev_std = 0.600)
SUFF++ for r=0.3 all L1 = 0.682 +- 0.232 (in-sample avg dev_std = 0.600)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.634
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.62
SUFF++ for r=0.6 class 0 = 0.823 +- 0.290 (in-sample avg dev_std = 0.389)
SUFF++ for r=0.6 class 1 = 0.847 +- 0.290 (in-sample avg dev_std = 0.389)
SUFF++ for r=0.6 class 2 = 0.759 +- 0.290 (in-sample avg dev_std = 0.389)
SUFF++ for r=0.6 all KL = 0.758 +- 0.290 (in-sample avg dev_std = 0.389)
SUFF++ for r=0.6 all L1 = 0.822 +- 0.214 (in-sample avg dev_std = 0.389)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.641
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.635
SUFF++ for r=0.9 class 0 = 0.89 +- 0.187 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.9 class 1 = 0.903 +- 0.187 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.9 class 2 = 0.861 +- 0.187 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.9 all KL = 0.911 +- 0.187 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.9 all L1 = 0.891 +- 0.171 (in-sample avg dev_std = 0.233)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.545
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.519
SUFF++ for r=0.3 class 0 = 0.666 +- 0.320 (in-sample avg dev_std = 0.614)
SUFF++ for r=0.3 class 1 = 0.689 +- 0.320 (in-sample avg dev_std = 0.614)
SUFF++ for r=0.3 class 2 = 0.641 +- 0.320 (in-sample avg dev_std = 0.614)
SUFF++ for r=0.3 all KL = 0.443 +- 0.320 (in-sample avg dev_std = 0.614)
SUFF++ for r=0.3 all L1 = 0.671 +- 0.222 (in-sample avg dev_std = 0.614)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.551
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 799
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.543
SUFF++ for r=0.6 class 0 = 0.821 +- 0.279 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.6 class 1 = 0.839 +- 0.279 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.6 class 2 = 0.788 +- 0.279 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.6 all KL = 0.763 +- 0.279 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.6 all L1 = 0.822 +- 0.203 (in-sample avg dev_std = 0.383)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.541
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.545
SUFF++ for r=0.9 class 0 = 0.872 +- 0.168 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 class 1 = 0.906 +- 0.168 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 class 2 = 0.859 +- 0.168 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 all KL = 0.913 +- 0.168 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 all L1 = 0.886 +- 0.165 (in-sample avg dev_std = 0.222)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.661
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.649
NEC for r=0.3 class 0 = 0.253 +- 0.306 (in-sample avg dev_std = 0.337)
NEC for r=0.3 class 1 = 0.165 +- 0.306 (in-sample avg dev_std = 0.337)
NEC for r=0.3 class 2 = 0.22 +- 0.306 (in-sample avg dev_std = 0.337)
NEC for r=0.3 all KL = 0.235 +- 0.306 (in-sample avg dev_std = 0.337)
NEC for r=0.3 all L1 = 0.202 +- 0.245 (in-sample avg dev_std = 0.337)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.646
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.648
NEC for r=0.6 class 0 = 0.164 +- 0.285 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 1 = 0.133 +- 0.285 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 2 = 0.188 +- 0.285 (in-sample avg dev_std = 0.328)
NEC for r=0.6 all KL = 0.183 +- 0.285 (in-sample avg dev_std = 0.328)
NEC for r=0.6 all L1 = 0.156 +- 0.223 (in-sample avg dev_std = 0.328)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.682
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.67
NEC for r=0.9 class 0 = 0.129 +- 0.216 (in-sample avg dev_std = 0.252)
NEC for r=0.9 class 1 = 0.11 +- 0.216 (in-sample avg dev_std = 0.252)
NEC for r=0.9 class 2 = 0.139 +- 0.216 (in-sample avg dev_std = 0.252)
NEC for r=0.9 all KL = 0.116 +- 0.216 (in-sample avg dev_std = 0.252)
NEC for r=0.9 all L1 = 0.123 +- 0.185 (in-sample avg dev_std = 0.252)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.701
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.67
NEC for r=1.0 class 0 = 0.121 +- 0.197 (in-sample avg dev_std = 0.240)
NEC for r=1.0 class 1 = 0.096 +- 0.197 (in-sample avg dev_std = 0.240)
NEC for r=1.0 class 2 = 0.136 +- 0.197 (in-sample avg dev_std = 0.240)
NEC for r=1.0 all KL = 0.098 +- 0.197 (in-sample avg dev_std = 0.240)
NEC for r=1.0 all L1 = 0.113 +- 0.178 (in-sample avg dev_std = 0.240)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.629
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.631
NEC for r=0.3 class 0 = 0.228 +- 0.310 (in-sample avg dev_std = 0.349)
NEC for r=0.3 class 1 = 0.168 +- 0.310 (in-sample avg dev_std = 0.349)
NEC for r=0.3 class 2 = 0.249 +- 0.310 (in-sample avg dev_std = 0.349)
NEC for r=0.3 all KL = 0.251 +- 0.310 (in-sample avg dev_std = 0.349)
NEC for r=0.3 all L1 = 0.201 +- 0.246 (in-sample avg dev_std = 0.349)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.634
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.628
NEC for r=0.6 class 0 = 0.167 +- 0.269 (in-sample avg dev_std = 0.305)
NEC for r=0.6 class 1 = 0.138 +- 0.269 (in-sample avg dev_std = 0.305)
NEC for r=0.6 class 2 = 0.198 +- 0.269 (in-sample avg dev_std = 0.305)
NEC for r=0.6 all KL = 0.18 +- 0.269 (in-sample avg dev_std = 0.305)
NEC for r=0.6 all L1 = 0.158 +- 0.225 (in-sample avg dev_std = 0.305)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.641
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.632
NEC for r=0.9 class 0 = 0.14 +- 0.207 (in-sample avg dev_std = 0.243)
NEC for r=0.9 class 1 = 0.116 +- 0.207 (in-sample avg dev_std = 0.243)
NEC for r=0.9 class 2 = 0.172 +- 0.207 (in-sample avg dev_std = 0.243)
NEC for r=0.9 all KL = 0.119 +- 0.207 (in-sample avg dev_std = 0.243)
NEC for r=0.9 all L1 = 0.134 +- 0.194 (in-sample avg dev_std = 0.243)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.644
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.642
NEC for r=1.0 class 0 = 0.127 +- 0.159 (in-sample avg dev_std = 0.196)
NEC for r=1.0 class 1 = 0.098 +- 0.159 (in-sample avg dev_std = 0.196)
NEC for r=1.0 class 2 = 0.147 +- 0.159 (in-sample avg dev_std = 0.196)
NEC for r=1.0 all KL = 0.085 +- 0.159 (in-sample avg dev_std = 0.196)
NEC for r=1.0 all L1 = 0.115 +- 0.167 (in-sample avg dev_std = 0.196)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.545
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.554
NEC for r=0.3 class 0 = 0.24 +- 0.318 (in-sample avg dev_std = 0.375)
NEC for r=0.3 class 1 = 0.173 +- 0.318 (in-sample avg dev_std = 0.375)
NEC for r=0.3 class 2 = 0.228 +- 0.318 (in-sample avg dev_std = 0.375)
NEC for r=0.3 all KL = 0.263 +- 0.318 (in-sample avg dev_std = 0.375)
NEC for r=0.3 all L1 = 0.204 +- 0.242 (in-sample avg dev_std = 0.375)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.55
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.542
NEC for r=0.6 class 0 = 0.193 +- 0.291 (in-sample avg dev_std = 0.330)
NEC for r=0.6 class 1 = 0.147 +- 0.291 (in-sample avg dev_std = 0.330)
NEC for r=0.6 class 2 = 0.204 +- 0.291 (in-sample avg dev_std = 0.330)
NEC for r=0.6 all KL = 0.205 +- 0.291 (in-sample avg dev_std = 0.330)
NEC for r=0.6 all L1 = 0.173 +- 0.226 (in-sample avg dev_std = 0.330)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.541
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.539
NEC for r=0.9 class 0 = 0.161 +- 0.191 (in-sample avg dev_std = 0.240)
NEC for r=0.9 class 1 = 0.122 +- 0.191 (in-sample avg dev_std = 0.240)
NEC for r=0.9 class 2 = 0.164 +- 0.191 (in-sample avg dev_std = 0.240)
NEC for r=0.9 all KL = 0.119 +- 0.191 (in-sample avg dev_std = 0.240)
NEC for r=0.9 all L1 = 0.142 +- 0.193 (in-sample avg dev_std = 0.240)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.546
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.542
NEC for r=1.0 class 0 = 0.148 +- 0.167 (in-sample avg dev_std = 0.213)
NEC for r=1.0 class 1 = 0.112 +- 0.167 (in-sample avg dev_std = 0.213)
NEC for r=1.0 class 2 = 0.152 +- 0.167 (in-sample avg dev_std = 0.213)
NEC for r=1.0 all KL = 0.097 +- 0.167 (in-sample avg dev_std = 0.213)
NEC for r=1.0 all L1 = 0.131 +- 0.176 (in-sample avg dev_std = 0.213)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 23:29:23 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 03/22/2024 11:29:23 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 11:29:25 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 11:29:26 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 11:29:26 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 11:29:28 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 11:29:29 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 11:29:29 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 11:29:29 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:29:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:29:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:29:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:29:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:29:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:29:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:29:29 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:29:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:29:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:29:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:29:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:29:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:29:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:29:29 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:29:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:29:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:29:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:29:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:29:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:29:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:29:29 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 25...
[0m[1;37mINFO[0m: [1mCheckpoint 25: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0031
ID Validation ACCURACY: 0.7058
ID Validation Loss: 1.5079
ID Test ACCURACY: 0.6426
ID Test Loss: 1.8561
OOD Validation ACCURACY: 0.6101
OOD Validation Loss: 2.2219
OOD Test ACCURACY: 0.5333
OOD Test Loss: 3.4476

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 36...
[0m[1;37mINFO[0m: [1mCheckpoint 36: 
-----------------------------------
Train ACCURACY: 0.9981
Train Loss: 0.0050
ID Validation ACCURACY: 0.6733
ID Validation Loss: 1.7091
ID Test ACCURACY: 0.6552
ID Test Loss: 1.9976
OOD Validation ACCURACY: 0.6403
OOD Validation Loss: 2.0926
OOD Test ACCURACY: 0.5690
OOD Test Loss: 2.7705

[0m[1;37mINFO[0m: [1mChartInfo 0.6426 0.5333 0.6552 0.5690 0.6733 0.6403[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.611
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.577
SUFF++ for r=0.3 class 0 = 0.709 +- 0.279 (in-sample avg dev_std = 0.560)
SUFF++ for r=0.3 class 1 = 0.688 +- 0.279 (in-sample avg dev_std = 0.560)
SUFF++ for r=0.3 class 2 = 0.584 +- 0.279 (in-sample avg dev_std = 0.560)
SUFF++ for r=0.3 all KL = 0.556 +- 0.279 (in-sample avg dev_std = 0.560)
SUFF++ for r=0.3 all L1 = 0.664 +- 0.206 (in-sample avg dev_std = 0.560)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.668
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.626
SUFF++ for r=0.6 class 0 = 0.818 +- 0.258 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.6 class 1 = 0.803 +- 0.258 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.6 class 2 = 0.713 +- 0.258 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.6 all KL = 0.739 +- 0.258 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.6 all L1 = 0.782 +- 0.206 (in-sample avg dev_std = 0.414)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.695
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.676
SUFF++ for r=0.9 class 0 = 0.886 +- 0.168 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 class 1 = 0.886 +- 0.168 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 class 2 = 0.858 +- 0.168 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 all KL = 0.905 +- 0.168 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 all L1 = 0.878 +- 0.171 (in-sample avg dev_std = 0.246)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.576
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.534
SUFF++ for r=0.3 class 0 = 0.759 +- 0.300 (in-sample avg dev_std = 0.559)
SUFF++ for r=0.3 class 1 = 0.666 +- 0.300 (in-sample avg dev_std = 0.559)
SUFF++ for r=0.3 class 2 = 0.611 +- 0.300 (in-sample avg dev_std = 0.559)
SUFF++ for r=0.3 all KL = 0.561 +- 0.300 (in-sample avg dev_std = 0.559)
SUFF++ for r=0.3 all L1 = 0.678 +- 0.218 (in-sample avg dev_std = 0.559)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.584
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.567
SUFF++ for r=0.6 class 0 = 0.841 +- 0.260 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.6 class 1 = 0.794 +- 0.260 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.6 class 2 = 0.762 +- 0.260 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.6 all KL = 0.766 +- 0.260 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.6 all L1 = 0.799 +- 0.205 (in-sample avg dev_std = 0.397)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.596
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.595
SUFF++ for r=0.9 class 0 = 0.859 +- 0.184 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 class 1 = 0.872 +- 0.184 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 class 2 = 0.841 +- 0.184 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 all KL = 0.896 +- 0.184 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 all L1 = 0.862 +- 0.186 (in-sample avg dev_std = 0.252)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.493
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.455
SUFF++ for r=0.3 class 0 = 0.777 +- 0.320 (in-sample avg dev_std = 0.551)
SUFF++ for r=0.3 class 1 = 0.676 +- 0.320 (in-sample avg dev_std = 0.551)
SUFF++ for r=0.3 class 2 = 0.598 +- 0.320 (in-sample avg dev_std = 0.551)
SUFF++ for r=0.3 all KL = 0.574 +- 0.320 (in-sample avg dev_std = 0.551)
SUFF++ for r=0.3 all L1 = 0.683 +- 0.232 (in-sample avg dev_std = 0.551)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.509
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.49
SUFF++ for r=0.6 class 0 = 0.83 +- 0.260 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 class 1 = 0.799 +- 0.260 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 class 2 = 0.742 +- 0.260 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 all KL = 0.759 +- 0.260 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 all L1 = 0.793 +- 0.211 (in-sample avg dev_std = 0.396)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.533
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.516
SUFF++ for r=0.9 class 0 = 0.879 +- 0.177 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.9 class 1 = 0.862 +- 0.177 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.9 class 2 = 0.848 +- 0.177 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.9 all KL = 0.893 +- 0.177 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.9 all L1 = 0.863 +- 0.182 (in-sample avg dev_std = 0.259)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.611
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.624
NEC for r=0.3 class 0 = 0.215 +- 0.263 (in-sample avg dev_std = 0.316)
NEC for r=0.3 class 1 = 0.187 +- 0.263 (in-sample avg dev_std = 0.316)
NEC for r=0.3 class 2 = 0.285 +- 0.263 (in-sample avg dev_std = 0.316)
NEC for r=0.3 all KL = 0.21 +- 0.263 (in-sample avg dev_std = 0.316)
NEC for r=0.3 all L1 = 0.221 +- 0.226 (in-sample avg dev_std = 0.316)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.668
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.643
NEC for r=0.6 class 0 = 0.159 +- 0.241 (in-sample avg dev_std = 0.298)
NEC for r=0.6 class 1 = 0.164 +- 0.241 (in-sample avg dev_std = 0.298)
NEC for r=0.6 class 2 = 0.219 +- 0.241 (in-sample avg dev_std = 0.298)
NEC for r=0.6 all KL = 0.171 +- 0.241 (in-sample avg dev_std = 0.298)
NEC for r=0.6 all L1 = 0.178 +- 0.213 (in-sample avg dev_std = 0.298)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.695
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.675
NEC for r=0.9 class 0 = 0.145 +- 0.184 (in-sample avg dev_std = 0.260)
NEC for r=0.9 class 1 = 0.129 +- 0.184 (in-sample avg dev_std = 0.260)
NEC for r=0.9 class 2 = 0.153 +- 0.184 (in-sample avg dev_std = 0.260)
NEC for r=0.9 all KL = 0.112 +- 0.184 (in-sample avg dev_std = 0.260)
NEC for r=0.9 all L1 = 0.14 +- 0.184 (in-sample avg dev_std = 0.260)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.704
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.683
NEC for r=1.0 class 0 = 0.154 +- 0.185 (in-sample avg dev_std = 0.246)
NEC for r=1.0 class 1 = 0.117 +- 0.185 (in-sample avg dev_std = 0.246)
NEC for r=1.0 class 2 = 0.15 +- 0.185 (in-sample avg dev_std = 0.246)
NEC for r=1.0 all KL = 0.104 +- 0.185 (in-sample avg dev_std = 0.246)
NEC for r=1.0 all L1 = 0.135 +- 0.181 (in-sample avg dev_std = 0.246)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.576
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.574
NEC for r=0.3 class 0 = 0.202 +- 0.293 (in-sample avg dev_std = 0.368)
NEC for r=0.3 class 1 = 0.244 +- 0.293 (in-sample avg dev_std = 0.368)
NEC for r=0.3 class 2 = 0.281 +- 0.293 (in-sample avg dev_std = 0.368)
NEC for r=0.3 all KL = 0.266 +- 0.293 (in-sample avg dev_std = 0.368)
NEC for r=0.3 all L1 = 0.241 +- 0.239 (in-sample avg dev_std = 0.368)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.584
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.576
NEC for r=0.6 class 0 = 0.159 +- 0.256 (in-sample avg dev_std = 0.317)
NEC for r=0.6 class 1 = 0.193 +- 0.256 (in-sample avg dev_std = 0.317)
NEC for r=0.6 class 2 = 0.213 +- 0.256 (in-sample avg dev_std = 0.317)
NEC for r=0.6 all KL = 0.195 +- 0.256 (in-sample avg dev_std = 0.317)
NEC for r=0.6 all L1 = 0.188 +- 0.221 (in-sample avg dev_std = 0.317)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.596
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.59
NEC for r=0.9 class 0 = 0.152 +- 0.207 (in-sample avg dev_std = 0.266)
NEC for r=0.9 class 1 = 0.168 +- 0.207 (in-sample avg dev_std = 0.266)
NEC for r=0.9 class 2 = 0.182 +- 0.207 (in-sample avg dev_std = 0.266)
NEC for r=0.9 all KL = 0.14 +- 0.207 (in-sample avg dev_std = 0.266)
NEC for r=0.9 all L1 = 0.167 +- 0.208 (in-sample avg dev_std = 0.266)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.604
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.595
NEC for r=1.0 class 0 = 0.157 +- 0.191 (in-sample avg dev_std = 0.246)
NEC for r=1.0 class 1 = 0.15 +- 0.191 (in-sample avg dev_std = 0.246)
NEC for r=1.0 class 2 = 0.174 +- 0.191 (in-sample avg dev_std = 0.246)
NEC for r=1.0 all KL = 0.122 +- 0.191 (in-sample avg dev_std = 0.246)
NEC for r=1.0 all L1 = 0.157 +- 0.200 (in-sample avg dev_std = 0.246)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.493
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.5
NEC for r=0.3 class 0 = 0.192 +- 0.284 (in-sample avg dev_std = 0.350)
NEC for r=0.3 class 1 = 0.219 +- 0.284 (in-sample avg dev_std = 0.350)
NEC for r=0.3 class 2 = 0.27 +- 0.284 (in-sample avg dev_std = 0.350)
NEC for r=0.3 all KL = 0.247 +- 0.284 (in-sample avg dev_std = 0.350)
NEC for r=0.3 all L1 = 0.225 +- 0.233 (in-sample avg dev_std = 0.350)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.509
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.507
NEC for r=0.6 class 0 = 0.144 +- 0.241 (in-sample avg dev_std = 0.307)
NEC for r=0.6 class 1 = 0.169 +- 0.241 (in-sample avg dev_std = 0.307)
NEC for r=0.6 class 2 = 0.216 +- 0.241 (in-sample avg dev_std = 0.307)
NEC for r=0.6 all KL = 0.173 +- 0.241 (in-sample avg dev_std = 0.307)
NEC for r=0.6 all L1 = 0.174 +- 0.214 (in-sample avg dev_std = 0.307)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.533
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.522
NEC for r=0.9 class 0 = 0.143 +- 0.201 (in-sample avg dev_std = 0.259)
NEC for r=0.9 class 1 = 0.149 +- 0.201 (in-sample avg dev_std = 0.259)
NEC for r=0.9 class 2 = 0.187 +- 0.201 (in-sample avg dev_std = 0.259)
NEC for r=0.9 all KL = 0.131 +- 0.201 (in-sample avg dev_std = 0.259)
NEC for r=0.9 all L1 = 0.157 +- 0.199 (in-sample avg dev_std = 0.259)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.531
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.523
NEC for r=1.0 class 0 = 0.136 +- 0.198 (in-sample avg dev_std = 0.246)
NEC for r=1.0 class 1 = 0.147 +- 0.198 (in-sample avg dev_std = 0.246)
NEC for r=1.0 class 2 = 0.178 +- 0.198 (in-sample avg dev_std = 0.246)
NEC for r=1.0 all KL = 0.124 +- 0.198 (in-sample avg dev_std = 0.246)
NEC for r=1.0 all L1 = 0.152 +- 0.197 (in-sample avg dev_std = 0.246)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 23:34:35 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 03/22/2024 11:34:35 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 11:34:37 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 11:34:37 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 11:34:38 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 11:34:39 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 11:34:41 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 11:34:41 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 11:34:41 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:34:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:34:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:34:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:34:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:34:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:34:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:34:41 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:34:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:34:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:34:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:34:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:34:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:34:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:34:41 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:34:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:34:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:34:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:34:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:34:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:34:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:34:41 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 68...
[0m[1;37mINFO[0m: [1mCheckpoint 68: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0013
ID Validation ACCURACY: 0.7004
ID Validation Loss: 1.8103
ID Test ACCURACY: 0.6444
ID Test Loss: 2.1469
OOD Validation ACCURACY: 0.6280
OOD Validation Loss: 2.2065
OOD Test ACCURACY: 0.5436
OOD Test Loss: 2.9759

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 145...
[0m[1;37mINFO[0m: [1mCheckpoint 145: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0004
ID Validation ACCURACY: 0.6877
ID Validation Loss: 2.1026
ID Test ACCURACY: 0.6101
ID Test Loss: 2.4334
OOD Validation ACCURACY: 0.6336
OOD Validation Loss: 2.6554
OOD Test ACCURACY: 0.5642
OOD Test Loss: 3.4042

[0m[1;37mINFO[0m: [1mChartInfo 0.6444 0.5436 0.6101 0.5642 0.6877 0.6336[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.659
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.577
SUFF++ for r=0.3 class 0 = 0.57 +- 0.308 (in-sample avg dev_std = 0.584)
SUFF++ for r=0.3 class 1 = 0.743 +- 0.308 (in-sample avg dev_std = 0.584)
SUFF++ for r=0.3 class 2 = 0.622 +- 0.308 (in-sample avg dev_std = 0.584)
SUFF++ for r=0.3 all KL = 0.503 +- 0.308 (in-sample avg dev_std = 0.584)
SUFF++ for r=0.3 all L1 = 0.667 +- 0.224 (in-sample avg dev_std = 0.584)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.695
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.636
SUFF++ for r=0.6 class 0 = 0.704 +- 0.294 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.6 class 1 = 0.812 +- 0.294 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.6 class 2 = 0.774 +- 0.294 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.6 all KL = 0.675 +- 0.294 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.6 all L1 = 0.775 +- 0.211 (in-sample avg dev_std = 0.463)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.7
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.679
SUFF++ for r=0.9 class 0 = 0.861 +- 0.147 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.9 class 1 = 0.907 +- 0.147 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.9 class 2 = 0.897 +- 0.147 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.9 all KL = 0.915 +- 0.147 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.9 all L1 = 0.893 +- 0.156 (in-sample avg dev_std = 0.230)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.624
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.568
SUFF++ for r=0.3 class 0 = 0.587 +- 0.296 (in-sample avg dev_std = 0.584)
SUFF++ for r=0.3 class 1 = 0.699 +- 0.296 (in-sample avg dev_std = 0.584)
SUFF++ for r=0.3 class 2 = 0.622 +- 0.296 (in-sample avg dev_std = 0.584)
SUFF++ for r=0.3 all KL = 0.49 +- 0.296 (in-sample avg dev_std = 0.584)
SUFF++ for r=0.3 all L1 = 0.655 +- 0.219 (in-sample avg dev_std = 0.584)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.621
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.596
SUFF++ for r=0.6 class 0 = 0.782 +- 0.274 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.6 class 1 = 0.769 +- 0.274 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.6 class 2 = 0.753 +- 0.274 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.6 all KL = 0.705 +- 0.274 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.6 all L1 = 0.769 +- 0.211 (in-sample avg dev_std = 0.428)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.626
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.618
SUFF++ for r=0.9 class 0 = 0.873 +- 0.181 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 class 1 = 0.873 +- 0.181 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 class 2 = 0.853 +- 0.181 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 all KL = 0.901 +- 0.181 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 all L1 = 0.869 +- 0.177 (in-sample avg dev_std = 0.235)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.556
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.498
SUFF++ for r=0.3 class 0 = 0.604 +- 0.260 (in-sample avg dev_std = 0.621)
SUFF++ for r=0.3 class 1 = 0.631 +- 0.260 (in-sample avg dev_std = 0.621)
SUFF++ for r=0.3 class 2 = 0.58 +- 0.260 (in-sample avg dev_std = 0.621)
SUFF++ for r=0.3 all KL = 0.432 +- 0.260 (in-sample avg dev_std = 0.621)
SUFF++ for r=0.3 all L1 = 0.611 +- 0.197 (in-sample avg dev_std = 0.621)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.545
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.52
SUFF++ for r=0.6 class 0 = 0.765 +- 0.256 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.6 class 1 = 0.748 +- 0.256 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.6 class 2 = 0.727 +- 0.256 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.6 all KL = 0.69 +- 0.256 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.6 all L1 = 0.747 +- 0.204 (in-sample avg dev_std = 0.433)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.556
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.54
SUFF++ for r=0.9 class 0 = 0.867 +- 0.168 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 class 1 = 0.849 +- 0.168 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 class 2 = 0.844 +- 0.168 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 all KL = 0.892 +- 0.168 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 all L1 = 0.852 +- 0.180 (in-sample avg dev_std = 0.255)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.659
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.638
NEC for r=0.3 class 0 = 0.281 +- 0.261 (in-sample avg dev_std = 0.291)
NEC for r=0.3 class 1 = 0.134 +- 0.261 (in-sample avg dev_std = 0.291)
NEC for r=0.3 class 2 = 0.202 +- 0.261 (in-sample avg dev_std = 0.291)
NEC for r=0.3 all KL = 0.185 +- 0.261 (in-sample avg dev_std = 0.291)
NEC for r=0.3 all L1 = 0.189 +- 0.230 (in-sample avg dev_std = 0.291)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.695
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.664
NEC for r=0.6 class 0 = 0.23 +- 0.247 (in-sample avg dev_std = 0.295)
NEC for r=0.6 class 1 = 0.125 +- 0.247 (in-sample avg dev_std = 0.295)
NEC for r=0.6 class 2 = 0.164 +- 0.247 (in-sample avg dev_std = 0.295)
NEC for r=0.6 all KL = 0.164 +- 0.247 (in-sample avg dev_std = 0.295)
NEC for r=0.6 all L1 = 0.162 +- 0.217 (in-sample avg dev_std = 0.295)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.701
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.68
NEC for r=0.9 class 0 = 0.173 +- 0.200 (in-sample avg dev_std = 0.247)
NEC for r=0.9 class 1 = 0.109 +- 0.200 (in-sample avg dev_std = 0.247)
NEC for r=0.9 class 2 = 0.13 +- 0.200 (in-sample avg dev_std = 0.247)
NEC for r=0.9 all KL = 0.116 +- 0.200 (in-sample avg dev_std = 0.247)
NEC for r=0.9 all L1 = 0.13 +- 0.187 (in-sample avg dev_std = 0.247)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.697
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.679
NEC for r=1.0 class 0 = 0.14 +- 0.166 (in-sample avg dev_std = 0.209)
NEC for r=1.0 class 1 = 0.099 +- 0.166 (in-sample avg dev_std = 0.209)
NEC for r=1.0 class 2 = 0.118 +- 0.166 (in-sample avg dev_std = 0.209)
NEC for r=1.0 all KL = 0.088 +- 0.166 (in-sample avg dev_std = 0.209)
NEC for r=1.0 all L1 = 0.114 +- 0.168 (in-sample avg dev_std = 0.209)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.624
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.613
NEC for r=0.3 class 0 = 0.295 +- 0.293 (in-sample avg dev_std = 0.352)
NEC for r=0.3 class 1 = 0.198 +- 0.293 (in-sample avg dev_std = 0.352)
NEC for r=0.3 class 2 = 0.235 +- 0.293 (in-sample avg dev_std = 0.352)
NEC for r=0.3 all KL = 0.248 +- 0.293 (in-sample avg dev_std = 0.352)
NEC for r=0.3 all L1 = 0.23 +- 0.246 (in-sample avg dev_std = 0.352)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.621
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.616
NEC for r=0.6 class 0 = 0.205 +- 0.281 (in-sample avg dev_std = 0.331)
NEC for r=0.6 class 1 = 0.198 +- 0.281 (in-sample avg dev_std = 0.331)
NEC for r=0.6 class 2 = 0.213 +- 0.281 (in-sample avg dev_std = 0.331)
NEC for r=0.6 all KL = 0.213 +- 0.281 (in-sample avg dev_std = 0.331)
NEC for r=0.6 all L1 = 0.203 +- 0.238 (in-sample avg dev_std = 0.331)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.626
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.615
NEC for r=0.9 class 0 = 0.146 +- 0.217 (in-sample avg dev_std = 0.258)
NEC for r=0.9 class 1 = 0.163 +- 0.217 (in-sample avg dev_std = 0.258)
NEC for r=0.9 class 2 = 0.183 +- 0.217 (in-sample avg dev_std = 0.258)
NEC for r=0.9 all KL = 0.139 +- 0.217 (in-sample avg dev_std = 0.258)
NEC for r=0.9 all L1 = 0.163 +- 0.206 (in-sample avg dev_std = 0.258)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.626
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.614
NEC for r=1.0 class 0 = 0.136 +- 0.176 (in-sample avg dev_std = 0.224)
NEC for r=1.0 class 1 = 0.143 +- 0.176 (in-sample avg dev_std = 0.224)
NEC for r=1.0 class 2 = 0.165 +- 0.176 (in-sample avg dev_std = 0.224)
NEC for r=1.0 all KL = 0.106 +- 0.176 (in-sample avg dev_std = 0.224)
NEC for r=1.0 all L1 = 0.146 +- 0.186 (in-sample avg dev_std = 0.224)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.556
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.547
NEC for r=0.3 class 0 = 0.287 +- 0.278 (in-sample avg dev_std = 0.364)
NEC for r=0.3 class 1 = 0.218 +- 0.278 (in-sample avg dev_std = 0.364)
NEC for r=0.3 class 2 = 0.245 +- 0.278 (in-sample avg dev_std = 0.364)
NEC for r=0.3 all KL = 0.252 +- 0.278 (in-sample avg dev_std = 0.364)
NEC for r=0.3 all L1 = 0.243 +- 0.237 (in-sample avg dev_std = 0.364)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.545
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.537
NEC for r=0.6 class 0 = 0.207 +- 0.252 (in-sample avg dev_std = 0.331)
NEC for r=0.6 class 1 = 0.215 +- 0.252 (in-sample avg dev_std = 0.331)
NEC for r=0.6 class 2 = 0.21 +- 0.252 (in-sample avg dev_std = 0.331)
NEC for r=0.6 all KL = 0.213 +- 0.252 (in-sample avg dev_std = 0.331)
NEC for r=0.6 all L1 = 0.212 +- 0.218 (in-sample avg dev_std = 0.331)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.556
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.535
NEC for r=0.9 class 0 = 0.149 +- 0.211 (in-sample avg dev_std = 0.255)
NEC for r=0.9 class 1 = 0.19 +- 0.211 (in-sample avg dev_std = 0.255)
NEC for r=0.9 class 2 = 0.188 +- 0.211 (in-sample avg dev_std = 0.255)
NEC for r=0.9 all KL = 0.148 +- 0.211 (in-sample avg dev_std = 0.255)
NEC for r=0.9 all L1 = 0.179 +- 0.211 (in-sample avg dev_std = 0.255)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.538
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.54
NEC for r=1.0 class 0 = 0.132 +- 0.174 (in-sample avg dev_std = 0.229)
NEC for r=1.0 class 1 = 0.155 +- 0.174 (in-sample avg dev_std = 0.229)
NEC for r=1.0 class 2 = 0.177 +- 0.174 (in-sample avg dev_std = 0.229)
NEC for r=1.0 all KL = 0.109 +- 0.174 (in-sample avg dev_std = 0.229)
NEC for r=1.0 all L1 = 0.154 +- 0.188 (in-sample avg dev_std = 0.229)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 23:39:58 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 03/22/2024 11:39:58 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/22/2024 11:39:59 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 11:40:00 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 11:40:01 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 11:40:02 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 11:40:04 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/22/2024 11:40:04 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 11:40:04 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:40:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:40:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:40:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:40:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:40:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:40:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:40:04 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:40:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:40:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:40:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:40:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:40:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:40:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:40:04 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:40:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:40:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:40:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:40:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:40:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/22/2024 11:40:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/22/2024 11:40:04 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 5...
[0m[1;37mINFO[0m: [1mCheckpoint 5: 
-----------------------------------
Train ACCURACY: 0.9208
Train Loss: 0.2372
ID Validation ACCURACY: 0.6949
ID Validation Loss: 0.8254
ID Test ACCURACY: 0.6480
ID Test Loss: 0.9897
OOD Validation ACCURACY: 0.6174
OOD Validation Loss: 1.2560
OOD Test ACCURACY: 0.5669
OOD Test Loss: 1.6424

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 103...
[0m[1;37mINFO[0m: [1mCheckpoint 103: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0004
ID Validation ACCURACY: 0.6823
ID Validation Loss: 2.1377
ID Test ACCURACY: 0.6588
ID Test Loss: 2.5118
OOD Validation ACCURACY: 0.6336
OOD Validation Loss: 2.6032
OOD Test ACCURACY: 0.5745
OOD Test Loss: 3.2801

[0m[1;37mINFO[0m: [1mChartInfo 0.6480 0.5669 0.6588 0.5745 0.6823 0.6336[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.584
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.56
SUFF++ for r=0.3 class 0 = 0.7 +- 0.117 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.3 class 1 = 0.801 +- 0.117 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.3 class 2 = 0.722 +- 0.117 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.3 all KL = 0.884 +- 0.117 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.3 all L1 = 0.754 +- 0.128 (in-sample avg dev_std = 0.263)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.646
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.619
SUFF++ for r=0.6 class 0 = 0.697 +- 0.125 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.6 class 1 = 0.799 +- 0.125 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.6 class 2 = 0.738 +- 0.125 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.6 all KL = 0.873 +- 0.125 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.6 all L1 = 0.757 +- 0.127 (in-sample avg dev_std = 0.263)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.686
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.687
SUFF++ for r=0.9 class 0 = 0.837 +- 0.059 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.9 class 1 = 0.871 +- 0.059 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.9 class 2 = 0.862 +- 0.059 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.9 all KL = 0.95 +- 0.059 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.9 all L1 = 0.86 +- 0.103 (in-sample avg dev_std = 0.172)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.592
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.581
SUFF++ for r=0.3 class 0 = 0.688 +- 0.127 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.3 class 1 = 0.748 +- 0.127 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.3 class 2 = 0.708 +- 0.127 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.3 all KL = 0.854 +- 0.127 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.3 all L1 = 0.724 +- 0.127 (in-sample avg dev_std = 0.289)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.596
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.583
SUFF++ for r=0.6 class 0 = 0.704 +- 0.119 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.6 class 1 = 0.74 +- 0.119 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.6 class 2 = 0.728 +- 0.119 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.6 all KL = 0.847 +- 0.119 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.6 all L1 = 0.728 +- 0.133 (in-sample avg dev_std = 0.296)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.598
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.595
SUFF++ for r=0.9 class 0 = 0.809 +- 0.083 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.9 class 1 = 0.837 +- 0.083 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.9 class 2 = 0.833 +- 0.083 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.9 all KL = 0.936 +- 0.083 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.9 all L1 = 0.829 +- 0.128 (in-sample avg dev_std = 0.165)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.562
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.525
SUFF++ for r=0.3 class 0 = 0.666 +- 0.124 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.3 class 1 = 0.714 +- 0.124 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.3 class 2 = 0.673 +- 0.124 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.3 all KL = 0.826 +- 0.124 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.3 all L1 = 0.692 +- 0.118 (in-sample avg dev_std = 0.316)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.555
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.535
SUFF++ for r=0.6 class 0 = 0.699 +- 0.132 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.6 class 1 = 0.71 +- 0.132 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.6 class 2 = 0.69 +- 0.132 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.6 all KL = 0.819 +- 0.132 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.6 all L1 = 0.702 +- 0.142 (in-sample avg dev_std = 0.319)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.566
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.558
SUFF++ for r=0.9 class 0 = 0.82 +- 0.104 (in-sample avg dev_std = 0.189)
SUFF++ for r=0.9 class 1 = 0.805 +- 0.104 (in-sample avg dev_std = 0.189)
SUFF++ for r=0.9 class 2 = 0.812 +- 0.104 (in-sample avg dev_std = 0.189)
SUFF++ for r=0.9 all KL = 0.919 +- 0.104 (in-sample avg dev_std = 0.189)
SUFF++ for r=0.9 all L1 = 0.81 +- 0.146 (in-sample avg dev_std = 0.189)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.584
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.579
NEC for r=0.3 class 0 = 0.251 +- 0.084 (in-sample avg dev_std = 0.157)
NEC for r=0.3 class 1 = 0.153 +- 0.084 (in-sample avg dev_std = 0.157)
NEC for r=0.3 class 2 = 0.202 +- 0.084 (in-sample avg dev_std = 0.157)
NEC for r=0.3 all KL = 0.064 +- 0.084 (in-sample avg dev_std = 0.157)
NEC for r=0.3 all L1 = 0.19 +- 0.127 (in-sample avg dev_std = 0.157)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.646
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.638
NEC for r=0.6 class 0 = 0.238 +- 0.090 (in-sample avg dev_std = 0.167)
NEC for r=0.6 class 1 = 0.155 +- 0.090 (in-sample avg dev_std = 0.167)
NEC for r=0.6 class 2 = 0.192 +- 0.090 (in-sample avg dev_std = 0.167)
NEC for r=0.6 all KL = 0.069 +- 0.090 (in-sample avg dev_std = 0.167)
NEC for r=0.6 all L1 = 0.185 +- 0.127 (in-sample avg dev_std = 0.167)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.688
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.682
NEC for r=0.9 class 0 = 0.174 +- 0.077 (in-sample avg dev_std = 0.141)
NEC for r=0.9 class 1 = 0.13 +- 0.077 (in-sample avg dev_std = 0.141)
NEC for r=0.9 class 2 = 0.158 +- 0.077 (in-sample avg dev_std = 0.141)
NEC for r=0.9 all KL = 0.051 +- 0.077 (in-sample avg dev_std = 0.141)
NEC for r=0.9 all L1 = 0.148 +- 0.120 (in-sample avg dev_std = 0.141)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.692
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.684
NEC for r=1.0 class 0 = 0.144 +- 0.081 (in-sample avg dev_std = 0.142)
NEC for r=1.0 class 1 = 0.118 +- 0.081 (in-sample avg dev_std = 0.142)
NEC for r=1.0 class 2 = 0.135 +- 0.081 (in-sample avg dev_std = 0.142)
NEC for r=1.0 all KL = 0.045 +- 0.081 (in-sample avg dev_std = 0.142)
NEC for r=1.0 all L1 = 0.129 +- 0.115 (in-sample avg dev_std = 0.142)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.592
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.597
NEC for r=0.3 class 0 = 0.264 +- 0.104 (in-sample avg dev_std = 0.181)
NEC for r=0.3 class 1 = 0.196 +- 0.104 (in-sample avg dev_std = 0.181)
NEC for r=0.3 class 2 = 0.241 +- 0.104 (in-sample avg dev_std = 0.181)
NEC for r=0.3 all KL = 0.09 +- 0.104 (in-sample avg dev_std = 0.181)
NEC for r=0.3 all L1 = 0.223 +- 0.133 (in-sample avg dev_std = 0.181)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.596
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.605
NEC for r=0.6 class 0 = 0.241 +- 0.097 (in-sample avg dev_std = 0.182)
NEC for r=0.6 class 1 = 0.191 +- 0.097 (in-sample avg dev_std = 0.182)
NEC for r=0.6 class 2 = 0.212 +- 0.097 (in-sample avg dev_std = 0.182)
NEC for r=0.6 all KL = 0.086 +- 0.097 (in-sample avg dev_std = 0.182)
NEC for r=0.6 all L1 = 0.208 +- 0.136 (in-sample avg dev_std = 0.182)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.598
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.594
NEC for r=0.9 class 0 = 0.203 +- 0.090 (in-sample avg dev_std = 0.166)
NEC for r=0.9 class 1 = 0.172 +- 0.090 (in-sample avg dev_std = 0.166)
NEC for r=0.9 class 2 = 0.174 +- 0.090 (in-sample avg dev_std = 0.166)
NEC for r=0.9 all KL = 0.072 +- 0.090 (in-sample avg dev_std = 0.166)
NEC for r=0.9 all L1 = 0.181 +- 0.138 (in-sample avg dev_std = 0.166)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.613
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.592
NEC for r=1.0 class 0 = 0.19 +- 0.094 (in-sample avg dev_std = 0.168)
NEC for r=1.0 class 1 = 0.162 +- 0.094 (in-sample avg dev_std = 0.168)
NEC for r=1.0 class 2 = 0.155 +- 0.094 (in-sample avg dev_std = 0.168)
NEC for r=1.0 all KL = 0.069 +- 0.094 (in-sample avg dev_std = 0.168)
NEC for r=1.0 all L1 = 0.168 +- 0.140 (in-sample avg dev_std = 0.168)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.562
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.561
NEC for r=0.3 class 0 = 0.262 +- 0.106 (in-sample avg dev_std = 0.198)
NEC for r=0.3 class 1 = 0.222 +- 0.106 (in-sample avg dev_std = 0.198)
NEC for r=0.3 class 2 = 0.255 +- 0.106 (in-sample avg dev_std = 0.198)
NEC for r=0.3 all KL = 0.1 +- 0.106 (in-sample avg dev_std = 0.198)
NEC for r=0.3 all L1 = 0.241 +- 0.133 (in-sample avg dev_std = 0.198)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.555
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.562
NEC for r=0.6 class 0 = 0.23 +- 0.111 (in-sample avg dev_std = 0.204)
NEC for r=0.6 class 1 = 0.218 +- 0.111 (in-sample avg dev_std = 0.204)
NEC for r=0.6 class 2 = 0.239 +- 0.111 (in-sample avg dev_std = 0.204)
NEC for r=0.6 all KL = 0.101 +- 0.111 (in-sample avg dev_std = 0.204)
NEC for r=0.6 all L1 = 0.226 +- 0.148 (in-sample avg dev_std = 0.204)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.566
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.563
NEC for r=0.9 class 0 = 0.192 +- 0.108 (in-sample avg dev_std = 0.184)
NEC for r=0.9 class 1 = 0.196 +- 0.108 (in-sample avg dev_std = 0.184)
NEC for r=0.9 class 2 = 0.187 +- 0.108 (in-sample avg dev_std = 0.184)
NEC for r=0.9 all KL = 0.085 +- 0.108 (in-sample avg dev_std = 0.184)
NEC for r=0.9 all L1 = 0.193 +- 0.150 (in-sample avg dev_std = 0.184)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.574
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.57
NEC for r=1.0 class 0 = 0.172 +- 0.102 (in-sample avg dev_std = 0.173)
NEC for r=1.0 class 1 = 0.176 +- 0.102 (in-sample avg dev_std = 0.173)
NEC for r=1.0 class 2 = 0.173 +- 0.102 (in-sample avg dev_std = 0.173)
NEC for r=1.0 all KL = 0.075 +- 0.102 (in-sample avg dev_std = 0.173)
NEC for r=1.0 all L1 = 0.174 +- 0.146 (in-sample avg dev_std = 0.173)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.6, 0.74, 0.917, 1.0], 'all_L1': [0.676, 0.777, 0.889, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.377, 0.647, 0.906, 1.0], 'all_L1': [0.63, 0.778, 0.898, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.556, 0.739, 0.905, 1.0], 'all_L1': [0.664, 0.782, 0.878, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.503, 0.675, 0.915, 1.0], 'all_L1': [0.667, 0.775, 0.893, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.884, 0.873, 0.95, 1.0], 'all_L1': [0.754, 0.757, 0.86, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.2, 0.137, 0.093, 0.083], 'all_L1': [0.229, 0.166, 0.123, 0.117]}), defaultdict(<class 'list'>, {'all_KL': [0.235, 0.183, 0.116, 0.098], 'all_L1': [0.202, 0.156, 0.123, 0.113]}), defaultdict(<class 'list'>, {'all_KL': [0.21, 0.171, 0.112, 0.104], 'all_L1': [0.221, 0.178, 0.14, 0.135]}), defaultdict(<class 'list'>, {'all_KL': [0.185, 0.164, 0.116, 0.088], 'all_L1': [0.189, 0.162, 0.13, 0.114]}), defaultdict(<class 'list'>, {'all_KL': [0.064, 0.069, 0.051, 0.045], 'all_L1': [0.19, 0.185, 0.148, 0.129]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.646, 0.782, 0.917, 1.0], 'all_L1': [0.71, 0.793, 0.874, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.467, 0.758, 0.911, 1.0], 'all_L1': [0.682, 0.822, 0.891, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.561, 0.766, 0.896, 1.0], 'all_L1': [0.678, 0.799, 0.862, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.49, 0.705, 0.901, 1.0], 'all_L1': [0.655, 0.769, 0.869, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.854, 0.847, 0.936, 1.0], 'all_L1': [0.724, 0.728, 0.829, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.22, 0.158, 0.104, 0.097], 'all_L1': [0.229, 0.183, 0.145, 0.14]}), defaultdict(<class 'list'>, {'all_KL': [0.251, 0.18, 0.119, 0.085], 'all_L1': [0.201, 0.158, 0.134, 0.115]}), defaultdict(<class 'list'>, {'all_KL': [0.266, 0.195, 0.14, 0.122], 'all_L1': [0.241, 0.188, 0.167, 0.157]}), defaultdict(<class 'list'>, {'all_KL': [0.248, 0.213, 0.139, 0.106], 'all_L1': [0.23, 0.203, 0.163, 0.146]}), defaultdict(<class 'list'>, {'all_KL': [0.09, 0.086, 0.072, 0.069], 'all_L1': [0.223, 0.208, 0.181, 0.168]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.629, 0.775, 0.928, 1.0], 'all_L1': [0.697, 0.79, 0.886, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.443, 0.763, 0.913, 1.0], 'all_L1': [0.671, 0.822, 0.886, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.574, 0.759, 0.893, 1.0], 'all_L1': [0.683, 0.793, 0.863, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.432, 0.69, 0.892, 1.0], 'all_L1': [0.611, 0.747, 0.852, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.826, 0.819, 0.919, 1.0], 'all_L1': [0.692, 0.702, 0.81, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.211, 0.145, 0.093, 0.087], 'all_L1': [0.223, 0.172, 0.133, 0.125]}), defaultdict(<class 'list'>, {'all_KL': [0.263, 0.205, 0.119, 0.097], 'all_L1': [0.204, 0.173, 0.142, 0.131]}), defaultdict(<class 'list'>, {'all_KL': [0.247, 0.173, 0.131, 0.124], 'all_L1': [0.225, 0.174, 0.157, 0.152]}), defaultdict(<class 'list'>, {'all_KL': [0.252, 0.213, 0.148, 0.109], 'all_L1': [0.243, 0.212, 0.179, 0.154]}), defaultdict(<class 'list'>, {'all_KL': [0.1, 0.101, 0.085, 0.075], 'all_L1': [0.241, 0.226, 0.193, 0.174]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.678 +- 0.041, 0.774 +- 0.009, 0.884 +- 0.014, 1.000 +- 0.000
suff++ class all_KL  =  0.584 +- 0.168, 0.735 +- 0.078, 0.919 +- 0.016, 1.000 +- 0.000
suff++_acc_int  =  0.567 +- 0.012, 0.627 +- 0.008, 0.677 +- 0.006
nec class all_L1  =  0.206 +- 0.016, 0.169 +- 0.011, 0.133 +- 0.010, 0.122 +- 0.009
nec class all_KL  =  0.179 +- 0.060, 0.145 +- 0.041, 0.098 +- 0.025, 0.084 +- 0.021
nec_acc_int  =  0.620 +- 0.024, 0.646 +- 0.010, 0.676 +- 0.004, 0.678 +- 0.006

Eval split val
suff++ class all_L1  =  0.690 +- 0.024, 0.782 +- 0.032, 0.865 +- 0.020, 1.000 +- 0.000
suff++ class all_KL  =  0.604 +- 0.140, 0.772 +- 0.046, 0.912 +- 0.014, 1.000 +- 0.000
suff++_acc_int  =  0.566 +- 0.018, 0.590 +- 0.017, 0.609 +- 0.016
nec class all_L1  =  0.225 +- 0.013, 0.188 +- 0.018, 0.158 +- 0.017, 0.145 +- 0.018
nec class all_KL  =  0.215 +- 0.064, 0.166 +- 0.044, 0.115 +- 0.025, 0.096 +- 0.018
nec_acc_int  =  0.601 +- 0.020, 0.606 +- 0.017, 0.609 +- 0.015, 0.610 +- 0.018

Eval split test
suff++ class all_L1  =  0.671 +- 0.031, 0.771 +- 0.042, 0.859 +- 0.028, 1.000 +- 0.000
suff++ class all_KL  =  0.581 +- 0.144, 0.761 +- 0.041, 0.909 +- 0.014, 1.000 +- 0.000
suff++_acc_int  =  0.502 +- 0.026, 0.523 +- 0.018, 0.540 +- 0.013
nec class all_L1  =  0.227 +- 0.014, 0.191 +- 0.023, 0.161 +- 0.022, 0.147 +- 0.018
nec class all_KL  =  0.215 +- 0.060, 0.167 +- 0.041, 0.115 +- 0.023, 0.098 +- 0.017
nec_acc_int  =  0.538 +- 0.022, 0.536 +- 0.018, 0.540 +- 0.013, 0.543 +- 0.015


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.442 +- 0.019, 0.472 +- 0.005, 0.508 +- 0.003, 0.561 +- 0.004
Faith. Armon (L1)= 		  =  0.316 +- 0.018, 0.278 +- 0.014, 0.231 +- 0.014, 0.217 +- 0.014
Faith. GMean (L1)= 	  =  0.373 +- 0.015, 0.362 +- 0.010, 0.342 +- 0.010, 0.348 +- 0.013
Faith. Aritm (KL)= 		  =  0.381 +- 0.057, 0.440 +- 0.021, 0.508 +- 0.005, 0.542 +- 0.010
Faith. Armon (KL)= 		  =  0.257 +- 0.070, 0.237 +- 0.058, 0.175 +- 0.042, 0.154 +- 0.036
Faith. GMean (KL)= 	  =  0.306 +- 0.039, 0.319 +- 0.039, 0.296 +- 0.040, 0.286 +- 0.039

Eval split val
Faith. Aritm (L1)= 		  =  0.457 +- 0.013, 0.485 +- 0.009, 0.512 +- 0.004, 0.573 +- 0.009
Faith. Armon (L1)= 		  =  0.339 +- 0.015, 0.302 +- 0.021, 0.267 +- 0.023, 0.253 +- 0.027
Faith. GMean (L1)= 	  =  0.394 +- 0.013, 0.383 +- 0.012, 0.369 +- 0.016, 0.380 +- 0.024
Faith. Aritm (KL)= 		  =  0.409 +- 0.042, 0.469 +- 0.007, 0.513 +- 0.006, 0.548 +- 0.009
Faith. Armon (KL)= 		  =  0.302 +- 0.071, 0.270 +- 0.061, 0.203 +- 0.040, 0.174 +- 0.030
Faith. GMean (KL)= 	  =  0.346 +- 0.038, 0.353 +- 0.044, 0.321 +- 0.035, 0.308 +- 0.029

Eval split test
Faith. Aritm (L1)= 		  =  0.449 +- 0.015, 0.481 +- 0.011, 0.510 +- 0.005, 0.574 +- 0.009
Faith. Armon (L1)= 		  =  0.339 +- 0.015, 0.305 +- 0.026, 0.270 +- 0.030, 0.256 +- 0.027
Faith. GMean (L1)= 	  =  0.390 +- 0.013, 0.383 +- 0.013, 0.370 +- 0.020, 0.383 +- 0.023
Faith. Aritm (KL)= 		  =  0.398 +- 0.045, 0.464 +- 0.011, 0.512 +- 0.006, 0.549 +- 0.009
Faith. Armon (KL)= 		  =  0.298 +- 0.061, 0.271 +- 0.054, 0.204 +- 0.037, 0.179 +- 0.028
Faith. GMean (KL)= 	  =  0.340 +- 0.031, 0.353 +- 0.038, 0.322 +- 0.031, 0.313 +- 0.027
Computed for split load_split = id



Completed in  0:25:37.190760  for GSATvGIN GOODTwitter/length



DONE GSAT GOODTwitter/length

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 23:45:25 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:25 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:28 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:32 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:35 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:38 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:38 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0mUsing feature sampling := feat
self.EF = 0.1
[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:45:54 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 145...
[0m[1;37mINFO[0m: [1mCheckpoint 145: 
-----------------------------------
Train ROC-AUC: 0.9716
Train Loss: 0.0653
ID Validation ROC-AUC: 0.8412
ID Validation Loss: 0.1394
ID Test ROC-AUC: 0.7964
ID Test Loss: 0.1371
OOD Validation ROC-AUC: 0.7570
OOD Validation Loss: 0.1376
OOD Test ROC-AUC: 0.7331
OOD Test Loss: 0.0930

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 51...
[0m[1;37mINFO[0m: [1mCheckpoint 51: 
-----------------------------------
Train ROC-AUC: 0.8810
Train Loss: 0.1019
ID Validation ROC-AUC: 0.8118
ID Validation Loss: 0.1338
ID Test ROC-AUC: 0.8103
ID Test Loss: 0.1133
OOD Validation ROC-AUC: 0.7797
OOD Validation Loss: 0.1199
OOD Test ROC-AUC: 0.7043
OOD Test Loss: 0.0856

[0m[1;37mINFO[0m: [1mChartInfo 0.7964 0.7331 0.8103 0.7043 0.8118 0.7797[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 03/22/2024 11:45:55 PM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 03/22/2024 11:45:58 PM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 03/22/2024 11:45:59 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.707
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 340
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.609
SUFF++ for r=0.3 class 0.0 = 0.944 +- 0.071 (in-sample avg dev_std = 0.146)
SUFF++ for r=0.3 class 1.0 = 0.866 +- 0.071 (in-sample avg dev_std = 0.146)
SUFF++ for r=0.3 all KL = 0.953 +- 0.071 (in-sample avg dev_std = 0.146)
SUFF++ for r=0.3 all L1 = 0.905 +- 0.109 (in-sample avg dev_std = 0.146)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.812
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.75
SUFF++ for r=0.6 class 0.0 = 0.951 +- 0.138 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.6 class 1.0 = 0.804 +- 0.138 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.6 all KL = 0.93 +- 0.138 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.6 all L1 = 0.878 +- 0.163 (in-sample avg dev_std = 0.198)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.855
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.843
SUFF++ for r=0.9 class 0.0 = 0.988 +- 0.075 (in-sample avg dev_std = 0.130)
SUFF++ for r=0.9 class 1.0 = 0.924 +- 0.075 (in-sample avg dev_std = 0.130)
SUFF++ for r=0.9 all KL = 0.977 +- 0.075 (in-sample avg dev_std = 0.130)
SUFF++ for r=0.9 all L1 = 0.956 +- 0.091 (in-sample avg dev_std = 0.130)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.635
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 243
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.618
SUFF++ for r=0.3 class 0.0 = 0.942 +- 0.062 (in-sample avg dev_std = 0.115)
SUFF++ for r=0.3 class 1.0 = 0.881 +- 0.062 (in-sample avg dev_std = 0.115)
SUFF++ for r=0.3 all KL = 0.961 +- 0.062 (in-sample avg dev_std = 0.115)
SUFF++ for r=0.3 all L1 = 0.911 +- 0.101 (in-sample avg dev_std = 0.115)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.695
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.653
SUFF++ for r=0.6 class 0.0 = 0.954 +- 0.119 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.6 class 1.0 = 0.846 +- 0.119 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.6 all KL = 0.947 +- 0.119 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.6 all L1 = 0.9 +- 0.145 (in-sample avg dev_std = 0.181)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.741
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.732
SUFF++ for r=0.9 class 0.0 = 0.984 +- 0.050 (in-sample avg dev_std = 0.102)
SUFF++ for r=0.9 class 1.0 = 0.94 +- 0.050 (in-sample avg dev_std = 0.102)
SUFF++ for r=0.9 all KL = 0.984 +- 0.050 (in-sample avg dev_std = 0.102)
SUFF++ for r=0.9 all L1 = 0.962 +- 0.082 (in-sample avg dev_std = 0.102)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.619
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 147
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.577
SUFF++ for r=0.3 class 0.0 = 0.935 +- 0.087 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.3 class 1.0 = 0.885 +- 0.087 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.3 all KL = 0.955 +- 0.087 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.3 all L1 = 0.911 +- 0.124 (in-sample avg dev_std = 0.128)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.712
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.651
SUFF++ for r=0.6 class 0.0 = 0.948 +- 0.142 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.6 class 1.0 = 0.839 +- 0.142 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.6 all KL = 0.933 +- 0.142 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.6 all L1 = 0.894 +- 0.151 (in-sample avg dev_std = 0.213)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.717
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.706
SUFF++ for r=0.9 class 0.0 = 0.983 +- 0.070 (in-sample avg dev_std = 0.100)
SUFF++ for r=0.9 class 1.0 = 0.944 +- 0.070 (in-sample avg dev_std = 0.100)
SUFF++ for r=0.9 all KL = 0.981 +- 0.070 (in-sample avg dev_std = 0.100)
SUFF++ for r=0.9 all L1 = 0.964 +- 0.078 (in-sample avg dev_std = 0.100)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.71
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.68
NEC for r=0.3 class 0.0 = 0.045 +- 0.044 (in-sample avg dev_std = 0.097)
NEC for r=0.3 class 1.0 = 0.102 +- 0.044 (in-sample avg dev_std = 0.097)
NEC for r=0.3 all KL = 0.026 +- 0.044 (in-sample avg dev_std = 0.097)
NEC for r=0.3 all L1 = 0.074 +- 0.084 (in-sample avg dev_std = 0.097)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.812
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.776
NEC for r=0.6 class 0.0 = 0.046 +- 0.129 (in-sample avg dev_std = 0.196)
NEC for r=0.6 class 1.0 = 0.192 +- 0.129 (in-sample avg dev_std = 0.196)
NEC for r=0.6 all KL = 0.067 +- 0.129 (in-sample avg dev_std = 0.196)
NEC for r=0.6 all L1 = 0.119 +- 0.159 (in-sample avg dev_std = 0.196)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.855
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.793
NEC for r=0.9 class 0.0 = 0.04 +- 0.217 (in-sample avg dev_std = 0.268)
NEC for r=0.9 class 1.0 = 0.229 +- 0.217 (in-sample avg dev_std = 0.268)
NEC for r=0.9 all KL = 0.119 +- 0.217 (in-sample avg dev_std = 0.268)
NEC for r=0.9 all L1 = 0.135 +- 0.189 (in-sample avg dev_std = 0.268)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.861
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.806
NEC for r=1.0 class 0.0 = 0.037 +- 0.241 (in-sample avg dev_std = 0.282)
NEC for r=1.0 class 1.0 = 0.235 +- 0.241 (in-sample avg dev_std = 0.282)
NEC for r=1.0 all KL = 0.134 +- 0.241 (in-sample avg dev_std = 0.282)
NEC for r=1.0 all L1 = 0.136 +- 0.199 (in-sample avg dev_std = 0.282)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.637
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.662
NEC for r=0.3 class 0.0 = 0.051 +- 0.056 (in-sample avg dev_std = 0.091)
NEC for r=0.3 class 1.0 = 0.099 +- 0.056 (in-sample avg dev_std = 0.091)
NEC for r=0.3 all KL = 0.027 +- 0.056 (in-sample avg dev_std = 0.091)
NEC for r=0.3 all L1 = 0.075 +- 0.085 (in-sample avg dev_std = 0.091)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.695
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.709
NEC for r=0.6 class 0.0 = 0.053 +- 0.083 (in-sample avg dev_std = 0.148)
NEC for r=0.6 class 1.0 = 0.143 +- 0.083 (in-sample avg dev_std = 0.148)
NEC for r=0.6 all KL = 0.047 +- 0.083 (in-sample avg dev_std = 0.148)
NEC for r=0.6 all L1 = 0.098 +- 0.122 (in-sample avg dev_std = 0.148)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.741
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.73
NEC for r=0.9 class 0.0 = 0.043 +- 0.113 (in-sample avg dev_std = 0.165)
NEC for r=0.9 class 1.0 = 0.144 +- 0.113 (in-sample avg dev_std = 0.165)
NEC for r=0.9 all KL = 0.064 +- 0.113 (in-sample avg dev_std = 0.165)
NEC for r=0.9 all L1 = 0.094 +- 0.131 (in-sample avg dev_std = 0.165)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.747
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.734
NEC for r=1.0 class 0.0 = 0.042 +- 0.152 (in-sample avg dev_std = 0.182)
NEC for r=1.0 class 1.0 = 0.145 +- 0.152 (in-sample avg dev_std = 0.182)
NEC for r=1.0 all KL = 0.076 +- 0.152 (in-sample avg dev_std = 0.182)
NEC for r=1.0 all L1 = 0.093 +- 0.142 (in-sample avg dev_std = 0.182)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.624
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.596
NEC for r=0.3 class 0.0 = 0.064 +- 0.068 (in-sample avg dev_std = 0.121)
NEC for r=0.3 class 1.0 = 0.108 +- 0.068 (in-sample avg dev_std = 0.121)
NEC for r=0.3 all KL = 0.037 +- 0.068 (in-sample avg dev_std = 0.121)
NEC for r=0.3 all L1 = 0.086 +- 0.108 (in-sample avg dev_std = 0.121)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.712
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.672
NEC for r=0.6 class 0.0 = 0.049 +- 0.114 (in-sample avg dev_std = 0.161)
NEC for r=0.6 class 1.0 = 0.126 +- 0.114 (in-sample avg dev_std = 0.161)
NEC for r=0.6 all KL = 0.046 +- 0.114 (in-sample avg dev_std = 0.161)
NEC for r=0.6 all L1 = 0.088 +- 0.120 (in-sample avg dev_std = 0.161)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.717
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.694
NEC for r=0.9 class 0.0 = 0.032 +- 0.126 (in-sample avg dev_std = 0.177)
NEC for r=0.9 class 1.0 = 0.135 +- 0.126 (in-sample avg dev_std = 0.177)
NEC for r=0.9 all KL = 0.06 +- 0.126 (in-sample avg dev_std = 0.177)
NEC for r=0.9 all L1 = 0.083 +- 0.128 (in-sample avg dev_std = 0.177)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.736
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.715
NEC for r=1.0 class 0.0 = 0.025 +- 0.161 (in-sample avg dev_std = 0.198)
NEC for r=1.0 class 1.0 = 0.148 +- 0.161 (in-sample avg dev_std = 0.198)
NEC for r=1.0 all KL = 0.073 +- 0.161 (in-sample avg dev_std = 0.198)
NEC for r=1.0 all L1 = 0.086 +- 0.147 (in-sample avg dev_std = 0.198)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 23:47:15 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:15 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:19 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:23 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:27 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:30 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:30 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:49 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0mUsing feature sampling := feat
self.EF = 0.1
[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 198...
[0m[1;37mINFO[0m: [1mCheckpoint 198: 
-----------------------------------
Train ROC-AUC: 0.9881
Train Loss: 0.0502
ID Validation ROC-AUC: 0.8421
ID Validation Loss: 0.1583
ID Test ROC-AUC: 0.7976
ID Test Loss: 0.1471
OOD Validation ROC-AUC: 0.7386
OOD Validation Loss: 0.1672
OOD Test ROC-AUC: 0.7071
OOD Test Loss: 0.1073

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 77...
[0m[1;37mINFO[0m: [1mCheckpoint 77: 
-----------------------------------
Train ROC-AUC: 0.9117
Train Loss: 0.0938
ID Validation ROC-AUC: 0.8079
ID Validation Loss: 0.1347
ID Test ROC-AUC: 0.7889
ID Test Loss: 0.1161
OOD Validation ROC-AUC: 0.7802
OOD Validation Loss: 0.1159
OOD Test ROC-AUC: 0.6996
OOD Test Loss: 0.0890

[0m[1;37mINFO[0m: [1mChartInfo 0.7976 0.7071 0.7889 0.6996 0.8079 0.7802[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 03/22/2024 11:47:50 PM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 03/22/2024 11:47:52 PM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 03/22/2024 11:47:54 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.741
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 339
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.628
SUFF++ for r=0.3 class 0.0 = 0.946 +- 0.110 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.3 class 1.0 = 0.829 +- 0.110 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.3 all KL = 0.931 +- 0.110 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.3 all L1 = 0.887 +- 0.146 (in-sample avg dev_std = 0.181)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.806
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.752
SUFF++ for r=0.6 class 0.0 = 0.957 +- 0.190 (in-sample avg dev_std = 0.225)
SUFF++ for r=0.6 class 1.0 = 0.783 +- 0.190 (in-sample avg dev_std = 0.225)
SUFF++ for r=0.6 all KL = 0.902 +- 0.190 (in-sample avg dev_std = 0.225)
SUFF++ for r=0.6 all L1 = 0.87 +- 0.196 (in-sample avg dev_std = 0.225)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.849
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.835
SUFF++ for r=0.9 class 0.0 = 0.988 +- 0.137 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.9 class 1.0 = 0.906 +- 0.137 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.9 all KL = 0.956 +- 0.137 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.9 all L1 = 0.947 +- 0.126 (in-sample avg dev_std = 0.183)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.62
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 245
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.555
SUFF++ for r=0.3 class 0.0 = 0.934 +- 0.104 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.3 class 1.0 = 0.849 +- 0.104 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.3 all KL = 0.936 +- 0.104 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.3 all L1 = 0.891 +- 0.143 (in-sample avg dev_std = 0.174)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.727
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.659
SUFF++ for r=0.6 class 0.0 = 0.951 +- 0.181 (in-sample avg dev_std = 0.224)
SUFF++ for r=0.6 class 1.0 = 0.815 +- 0.181 (in-sample avg dev_std = 0.224)
SUFF++ for r=0.6 all KL = 0.914 +- 0.181 (in-sample avg dev_std = 0.224)
SUFF++ for r=0.6 all L1 = 0.883 +- 0.182 (in-sample avg dev_std = 0.224)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.737
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.724
SUFF++ for r=0.9 class 0.0 = 0.989 +- 0.138 (in-sample avg dev_std = 0.173)
SUFF++ for r=0.9 class 1.0 = 0.924 +- 0.138 (in-sample avg dev_std = 0.173)
SUFF++ for r=0.9 all KL = 0.963 +- 0.138 (in-sample avg dev_std = 0.173)
SUFF++ for r=0.9 all L1 = 0.956 +- 0.112 (in-sample avg dev_std = 0.173)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.718
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 149
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.621
SUFF++ for r=0.3 class 0.0 = 0.955 +- 0.103 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.3 class 1.0 = 0.896 +- 0.103 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.3 all KL = 0.952 +- 0.103 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.3 all L1 = 0.926 +- 0.114 (in-sample avg dev_std = 0.148)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.72
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.653
SUFF++ for r=0.6 class 0.0 = 0.97 +- 0.167 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 class 1.0 = 0.833 +- 0.167 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 all KL = 0.929 +- 0.167 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 all L1 = 0.902 +- 0.184 (in-sample avg dev_std = 0.184)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.72
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.712
SUFF++ for r=0.9 class 0.0 = 0.993 +- 0.086 (in-sample avg dev_std = 0.142)
SUFF++ for r=0.9 class 1.0 = 0.934 +- 0.086 (in-sample avg dev_std = 0.142)
SUFF++ for r=0.9 all KL = 0.976 +- 0.086 (in-sample avg dev_std = 0.142)
SUFF++ for r=0.9 all L1 = 0.964 +- 0.088 (in-sample avg dev_std = 0.142)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.741
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.683
NEC for r=0.3 class 0.0 = 0.055 +- 0.090 (in-sample avg dev_std = 0.143)
NEC for r=0.3 class 1.0 = 0.144 +- 0.090 (in-sample avg dev_std = 0.143)
NEC for r=0.3 all KL = 0.052 +- 0.090 (in-sample avg dev_std = 0.143)
NEC for r=0.3 all L1 = 0.1 +- 0.127 (in-sample avg dev_std = 0.143)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.806
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.775
NEC for r=0.6 class 0.0 = 0.045 +- 0.181 (in-sample avg dev_std = 0.236)
NEC for r=0.6 class 1.0 = 0.207 +- 0.181 (in-sample avg dev_std = 0.236)
NEC for r=0.6 all KL = 0.1 +- 0.181 (in-sample avg dev_std = 0.236)
NEC for r=0.6 all L1 = 0.126 +- 0.181 (in-sample avg dev_std = 0.236)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.849
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.808
NEC for r=0.9 class 0.0 = 0.046 +- 0.277 (in-sample avg dev_std = 0.309)
NEC for r=0.9 class 1.0 = 0.243 +- 0.277 (in-sample avg dev_std = 0.309)
NEC for r=0.9 all KL = 0.173 +- 0.277 (in-sample avg dev_std = 0.309)
NEC for r=0.9 all L1 = 0.145 +- 0.211 (in-sample avg dev_std = 0.309)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.865
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.809
NEC for r=1.0 class 0.0 = 0.051 +- 0.299 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 1.0 = 0.255 +- 0.299 (in-sample avg dev_std = 0.345)
NEC for r=1.0 all KL = 0.197 +- 0.299 (in-sample avg dev_std = 0.345)
NEC for r=1.0 all L1 = 0.153 +- 0.222 (in-sample avg dev_std = 0.345)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.612
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.613
NEC for r=0.3 class 0.0 = 0.067 +- 0.096 (in-sample avg dev_std = 0.147)
NEC for r=0.3 class 1.0 = 0.14 +- 0.096 (in-sample avg dev_std = 0.147)
NEC for r=0.3 all KL = 0.055 +- 0.096 (in-sample avg dev_std = 0.147)
NEC for r=0.3 all L1 = 0.103 +- 0.121 (in-sample avg dev_std = 0.147)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.727
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.699
NEC for r=0.6 class 0.0 = 0.048 +- 0.177 (in-sample avg dev_std = 0.206)
NEC for r=0.6 class 1.0 = 0.19 +- 0.177 (in-sample avg dev_std = 0.206)
NEC for r=0.6 all KL = 0.094 +- 0.177 (in-sample avg dev_std = 0.206)
NEC for r=0.6 all L1 = 0.119 +- 0.175 (in-sample avg dev_std = 0.206)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.737
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.724
NEC for r=0.9 class 0.0 = 0.048 +- 0.236 (in-sample avg dev_std = 0.244)
NEC for r=0.9 class 1.0 = 0.179 +- 0.236 (in-sample avg dev_std = 0.244)
NEC for r=0.9 all KL = 0.125 +- 0.236 (in-sample avg dev_std = 0.244)
NEC for r=0.9 all L1 = 0.113 +- 0.189 (in-sample avg dev_std = 0.244)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.741
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.735
NEC for r=1.0 class 0.0 = 0.038 +- 0.230 (in-sample avg dev_std = 0.234)
NEC for r=1.0 class 1.0 = 0.18 +- 0.230 (in-sample avg dev_std = 0.234)
NEC for r=1.0 all KL = 0.128 +- 0.230 (in-sample avg dev_std = 0.234)
NEC for r=1.0 all L1 = 0.109 +- 0.186 (in-sample avg dev_std = 0.234)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.713
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.669
NEC for r=0.3 class 0.0 = 0.036 +- 0.074 (in-sample avg dev_std = 0.112)
NEC for r=0.3 class 1.0 = 0.092 +- 0.074 (in-sample avg dev_std = 0.112)
NEC for r=0.3 all KL = 0.033 +- 0.074 (in-sample avg dev_std = 0.112)
NEC for r=0.3 all L1 = 0.064 +- 0.097 (in-sample avg dev_std = 0.112)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.72
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.646
NEC for r=0.6 class 0.0 = 0.04 +- 0.162 (in-sample avg dev_std = 0.185)
NEC for r=0.6 class 1.0 = 0.165 +- 0.162 (in-sample avg dev_std = 0.185)
NEC for r=0.6 all KL = 0.075 +- 0.162 (in-sample avg dev_std = 0.185)
NEC for r=0.6 all L1 = 0.102 +- 0.175 (in-sample avg dev_std = 0.185)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.72
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.694
NEC for r=0.9 class 0.0 = 0.022 +- 0.217 (in-sample avg dev_std = 0.235)
NEC for r=0.9 class 1.0 = 0.163 +- 0.217 (in-sample avg dev_std = 0.235)
NEC for r=0.9 all KL = 0.097 +- 0.217 (in-sample avg dev_std = 0.235)
NEC for r=0.9 all L1 = 0.093 +- 0.170 (in-sample avg dev_std = 0.235)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.737
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.697
NEC for r=1.0 class 0.0 = 0.02 +- 0.245 (in-sample avg dev_std = 0.270)
NEC for r=1.0 class 1.0 = 0.185 +- 0.245 (in-sample avg dev_std = 0.270)
NEC for r=1.0 all KL = 0.113 +- 0.245 (in-sample avg dev_std = 0.270)
NEC for r=1.0 all L1 = 0.102 +- 0.191 (in-sample avg dev_std = 0.270)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 23:49:14 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:14 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:18 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:22 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:25 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:28 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:28 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:45 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:45 PM : [1mUsing no mitigation None
[0mUsing feature sampling := feat
self.EF = 0.1
[1;34mDEBUG[0m: 03/22/2024 11:49:45 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 156...
[0m[1;37mINFO[0m: [1mCheckpoint 156: 
-----------------------------------
Train ROC-AUC: 0.9869
Train Loss: 0.0538
ID Validation ROC-AUC: 0.8431
ID Validation Loss: 0.1490
ID Test ROC-AUC: 0.8115
ID Test Loss: 0.1338
OOD Validation ROC-AUC: 0.7762
OOD Validation Loss: 0.1394
OOD Test ROC-AUC: 0.7383
OOD Test Loss: 0.0997

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 149...
[0m[1;37mINFO[0m: [1mCheckpoint 149: 
-----------------------------------
Train ROC-AUC: 0.9764
Train Loss: 0.0628
ID Validation ROC-AUC: 0.8350
ID Validation Loss: 0.1429
ID Test ROC-AUC: 0.8089
ID Test Loss: 0.1287
OOD Validation ROC-AUC: 0.7881
OOD Validation Loss: 0.1266
OOD Test ROC-AUC: 0.7471
OOD Test Loss: 0.0945

[0m[1;37mINFO[0m: [1mChartInfo 0.8115 0.7383 0.8089 0.7471 0.8350 0.7881[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 03/22/2024 11:49:46 PM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 03/22/2024 11:49:48 PM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 03/22/2024 11:49:49 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.726
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 339
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.625
SUFF++ for r=0.3 class 0.0 = 0.929 +- 0.106 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.3 class 1.0 = 0.805 +- 0.106 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.3 all KL = 0.922 +- 0.106 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.3 all L1 = 0.865 +- 0.144 (in-sample avg dev_std = 0.207)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.811
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.76
SUFF++ for r=0.6 class 0.0 = 0.936 +- 0.138 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.6 class 1.0 = 0.811 +- 0.138 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.6 all KL = 0.92 +- 0.138 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.6 all L1 = 0.873 +- 0.154 (in-sample avg dev_std = 0.214)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.858
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.847
SUFF++ for r=0.9 class 0.0 = 0.981 +- 0.103 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.9 class 1.0 = 0.916 +- 0.103 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.9 all KL = 0.966 +- 0.103 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.9 all L1 = 0.948 +- 0.108 (in-sample avg dev_std = 0.159)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.724
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 239
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.623
SUFF++ for r=0.3 class 0.0 = 0.924 +- 0.132 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.3 class 1.0 = 0.788 +- 0.132 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.3 all KL = 0.913 +- 0.132 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.3 all L1 = 0.856 +- 0.164 (in-sample avg dev_std = 0.229)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.743
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.684
SUFF++ for r=0.6 class 0.0 = 0.929 +- 0.134 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.6 class 1.0 = 0.791 +- 0.134 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.6 all KL = 0.918 +- 0.134 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.6 all L1 = 0.86 +- 0.164 (in-sample avg dev_std = 0.216)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.759
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.75
SUFF++ for r=0.9 class 0.0 = 0.978 +- 0.085 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.9 class 1.0 = 0.92 +- 0.085 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.9 all KL = 0.973 +- 0.085 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.9 all L1 = 0.949 +- 0.102 (in-sample avg dev_std = 0.145)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.616
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 148
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.568
SUFF++ for r=0.3 class 0.0 = 0.939 +- 0.092 (in-sample avg dev_std = 0.153)
SUFF++ for r=0.3 class 1.0 = 0.868 +- 0.092 (in-sample avg dev_std = 0.153)
SUFF++ for r=0.3 all KL = 0.951 +- 0.092 (in-sample avg dev_std = 0.153)
SUFF++ for r=0.3 all L1 = 0.904 +- 0.133 (in-sample avg dev_std = 0.153)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.708
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.653
SUFF++ for r=0.6 class 0.0 = 0.941 +- 0.168 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.6 class 1.0 = 0.823 +- 0.168 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.6 all KL = 0.92 +- 0.168 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.6 all L1 = 0.882 +- 0.178 (in-sample avg dev_std = 0.213)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.742
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 161
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.744
SUFF++ for r=0.9 class 0.0 = 0.984 +- 0.123 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.9 class 1.0 = 0.907 +- 0.123 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.9 all KL = 0.958 +- 0.123 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.9 all L1 = 0.945 +- 0.113 (in-sample avg dev_std = 0.181)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.718
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.678
NEC for r=0.3 class 0.0 = 0.065 +- 0.089 (in-sample avg dev_std = 0.135)
NEC for r=0.3 class 1.0 = 0.163 +- 0.089 (in-sample avg dev_std = 0.135)
NEC for r=0.3 all KL = 0.053 +- 0.089 (in-sample avg dev_std = 0.135)
NEC for r=0.3 all L1 = 0.114 +- 0.127 (in-sample avg dev_std = 0.135)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.811
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.769
NEC for r=0.6 class 0.0 = 0.065 +- 0.155 (in-sample avg dev_std = 0.215)
NEC for r=0.6 class 1.0 = 0.194 +- 0.155 (in-sample avg dev_std = 0.215)
NEC for r=0.6 all KL = 0.086 +- 0.155 (in-sample avg dev_std = 0.215)
NEC for r=0.6 all L1 = 0.129 +- 0.162 (in-sample avg dev_std = 0.215)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.858
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.803
NEC for r=0.9 class 0.0 = 0.059 +- 0.230 (in-sample avg dev_std = 0.282)
NEC for r=0.9 class 1.0 = 0.23 +- 0.230 (in-sample avg dev_std = 0.282)
NEC for r=0.9 all KL = 0.14 +- 0.230 (in-sample avg dev_std = 0.282)
NEC for r=0.9 all L1 = 0.144 +- 0.202 (in-sample avg dev_std = 0.282)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.863
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.809
NEC for r=1.0 class 0.0 = 0.055 +- 0.256 (in-sample avg dev_std = 0.307)
NEC for r=1.0 class 1.0 = 0.243 +- 0.256 (in-sample avg dev_std = 0.307)
NEC for r=1.0 all KL = 0.162 +- 0.256 (in-sample avg dev_std = 0.307)
NEC for r=1.0 all L1 = 0.149 +- 0.213 (in-sample avg dev_std = 0.307)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.718
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.673
NEC for r=0.3 class 0.0 = 0.074 +- 0.067 (in-sample avg dev_std = 0.130)
NEC for r=0.3 class 1.0 = 0.147 +- 0.067 (in-sample avg dev_std = 0.130)
NEC for r=0.3 all KL = 0.045 +- 0.067 (in-sample avg dev_std = 0.130)
NEC for r=0.3 all L1 = 0.111 +- 0.108 (in-sample avg dev_std = 0.130)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.743
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.742
NEC for r=0.6 class 0.0 = 0.066 +- 0.110 (in-sample avg dev_std = 0.197)
NEC for r=0.6 class 1.0 = 0.19 +- 0.110 (in-sample avg dev_std = 0.197)
NEC for r=0.6 all KL = 0.073 +- 0.110 (in-sample avg dev_std = 0.197)
NEC for r=0.6 all L1 = 0.128 +- 0.139 (in-sample avg dev_std = 0.197)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.759
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.742
NEC for r=0.9 class 0.0 = 0.063 +- 0.196 (in-sample avg dev_std = 0.248)
NEC for r=0.9 class 1.0 = 0.208 +- 0.196 (in-sample avg dev_std = 0.248)
NEC for r=0.9 all KL = 0.118 +- 0.196 (in-sample avg dev_std = 0.248)
NEC for r=0.9 all L1 = 0.136 +- 0.180 (in-sample avg dev_std = 0.248)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.77
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.749
NEC for r=1.0 class 0.0 = 0.065 +- 0.223 (in-sample avg dev_std = 0.257)
NEC for r=1.0 class 1.0 = 0.218 +- 0.223 (in-sample avg dev_std = 0.257)
NEC for r=1.0 all KL = 0.14 +- 0.223 (in-sample avg dev_std = 0.257)
NEC for r=1.0 all L1 = 0.141 +- 0.194 (in-sample avg dev_std = 0.257)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.599
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.622
NEC for r=0.3 class 0.0 = 0.054 +- 0.072 (in-sample avg dev_std = 0.123)
NEC for r=0.3 class 1.0 = 0.129 +- 0.072 (in-sample avg dev_std = 0.123)
NEC for r=0.3 all KL = 0.041 +- 0.072 (in-sample avg dev_std = 0.123)
NEC for r=0.3 all L1 = 0.091 +- 0.113 (in-sample avg dev_std = 0.123)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.708
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.681
NEC for r=0.6 class 0.0 = 0.066 +- 0.150 (in-sample avg dev_std = 0.203)
NEC for r=0.6 class 1.0 = 0.16 +- 0.150 (in-sample avg dev_std = 0.203)
NEC for r=0.6 all KL = 0.081 +- 0.150 (in-sample avg dev_std = 0.203)
NEC for r=0.6 all L1 = 0.113 +- 0.152 (in-sample avg dev_std = 0.203)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.745
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.708
NEC for r=0.9 class 0.0 = 0.054 +- 0.217 (in-sample avg dev_std = 0.251)
NEC for r=0.9 class 1.0 = 0.198 +- 0.217 (in-sample avg dev_std = 0.251)
NEC for r=0.9 all KL = 0.119 +- 0.217 (in-sample avg dev_std = 0.251)
NEC for r=0.9 all L1 = 0.126 +- 0.189 (in-sample avg dev_std = 0.251)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.74
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.703
NEC for r=1.0 class 0.0 = 0.043 +- 0.244 (in-sample avg dev_std = 0.267)
NEC for r=1.0 class 1.0 = 0.22 +- 0.244 (in-sample avg dev_std = 0.267)
NEC for r=1.0 all KL = 0.135 +- 0.244 (in-sample avg dev_std = 0.267)
NEC for r=1.0 all L1 = 0.132 +- 0.204 (in-sample avg dev_std = 0.267)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 23:51:05 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:05 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:08 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:12 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:16 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:19 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:19 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0mUsing feature sampling := feat
self.EF = 0.1
[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 140...
[0m[1;37mINFO[0m: [1mCheckpoint 140: 
-----------------------------------
Train ROC-AUC: 0.9788
Train Loss: 0.0657
ID Validation ROC-AUC: 0.8378
ID Validation Loss: 0.1396
ID Test ROC-AUC: 0.8109
ID Test Loss: 0.1227
OOD Validation ROC-AUC: 0.7665
OOD Validation Loss: 0.1310
OOD Test ROC-AUC: 0.7331
OOD Test Loss: 0.0936

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 139...
[0m[1;37mINFO[0m: [1mCheckpoint 139: 
-----------------------------------
Train ROC-AUC: 0.9723
Train Loss: 0.0782
ID Validation ROC-AUC: 0.8167
ID Validation Loss: 0.1530
ID Test ROC-AUC: 0.8037
ID Test Loss: 0.1332
OOD Validation ROC-AUC: 0.7875
OOD Validation Loss: 0.1295
OOD Test ROC-AUC: 0.6782
OOD Test Loss: 0.1101

[0m[1;37mINFO[0m: [1mChartInfo 0.8109 0.7331 0.8037 0.6782 0.8167 0.7875[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 03/22/2024 11:51:35 PM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 03/22/2024 11:51:37 PM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 03/22/2024 11:51:38 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.716
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 339
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.627
SUFF++ for r=0.3 class 0.0 = 0.966 +- 0.050 (in-sample avg dev_std = 0.091)
SUFF++ for r=0.3 class 1.0 = 0.903 +- 0.050 (in-sample avg dev_std = 0.091)
SUFF++ for r=0.3 all KL = 0.971 +- 0.050 (in-sample avg dev_std = 0.091)
SUFF++ for r=0.3 all L1 = 0.934 +- 0.092 (in-sample avg dev_std = 0.091)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.822
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.772
SUFF++ for r=0.6 class 0.0 = 0.974 +- 0.077 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.6 class 1.0 = 0.852 +- 0.077 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.6 all KL = 0.962 +- 0.077 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.6 all L1 = 0.913 +- 0.128 (in-sample avg dev_std = 0.132)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.856
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.849
SUFF++ for r=0.9 class 0.0 = 0.989 +- 0.085 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.9 class 1.0 = 0.919 +- 0.085 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.9 all KL = 0.975 +- 0.085 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.9 all L1 = 0.954 +- 0.096 (in-sample avg dev_std = 0.144)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.633
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 244
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.572
SUFF++ for r=0.3 class 0.0 = 0.969 +- 0.046 (in-sample avg dev_std = 0.083)
SUFF++ for r=0.3 class 1.0 = 0.917 +- 0.046 (in-sample avg dev_std = 0.083)
SUFF++ for r=0.3 all KL = 0.977 +- 0.046 (in-sample avg dev_std = 0.083)
SUFF++ for r=0.3 all L1 = 0.942 +- 0.086 (in-sample avg dev_std = 0.083)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.693
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.644
SUFF++ for r=0.6 class 0.0 = 0.967 +- 0.092 (in-sample avg dev_std = 0.142)
SUFF++ for r=0.6 class 1.0 = 0.863 +- 0.092 (in-sample avg dev_std = 0.142)
SUFF++ for r=0.6 all KL = 0.959 +- 0.092 (in-sample avg dev_std = 0.142)
SUFF++ for r=0.6 all L1 = 0.915 +- 0.139 (in-sample avg dev_std = 0.142)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.767
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.759
SUFF++ for r=0.9 class 0.0 = 0.99 +- 0.085 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.9 class 1.0 = 0.928 +- 0.085 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.9 all KL = 0.979 +- 0.085 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.9 all L1 = 0.959 +- 0.096 (in-sample avg dev_std = 0.128)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.655
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 153
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.582
SUFF++ for r=0.3 class 0.0 = 0.976 +- 0.038 (in-sample avg dev_std = 0.072)
SUFF++ for r=0.3 class 1.0 = 0.935 +- 0.038 (in-sample avg dev_std = 0.072)
SUFF++ for r=0.3 all KL = 0.981 +- 0.038 (in-sample avg dev_std = 0.072)
SUFF++ for r=0.3 all L1 = 0.955 +- 0.067 (in-sample avg dev_std = 0.072)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.699
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.68
SUFF++ for r=0.6 class 0.0 = 0.981 +- 0.100 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.6 class 1.0 = 0.888 +- 0.100 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.6 all KL = 0.965 +- 0.100 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.6 all L1 = 0.934 +- 0.128 (in-sample avg dev_std = 0.118)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.761
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.764
SUFF++ for r=0.9 class 0.0 = 0.994 +- 0.067 (in-sample avg dev_std = 0.103)
SUFF++ for r=0.9 class 1.0 = 0.946 +- 0.067 (in-sample avg dev_std = 0.103)
SUFF++ for r=0.9 all KL = 0.987 +- 0.067 (in-sample avg dev_std = 0.103)
SUFF++ for r=0.9 all L1 = 0.97 +- 0.068 (in-sample avg dev_std = 0.103)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.714
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.708
NEC for r=0.3 class 0.0 = 0.028 +- 0.042 (in-sample avg dev_std = 0.066)
NEC for r=0.3 class 1.0 = 0.081 +- 0.042 (in-sample avg dev_std = 0.066)
NEC for r=0.3 all KL = 0.019 +- 0.042 (in-sample avg dev_std = 0.066)
NEC for r=0.3 all L1 = 0.054 +- 0.078 (in-sample avg dev_std = 0.066)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.822
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.778
NEC for r=0.6 class 0.0 = 0.025 +- 0.112 (in-sample avg dev_std = 0.153)
NEC for r=0.6 class 1.0 = 0.16 +- 0.112 (in-sample avg dev_std = 0.153)
NEC for r=0.6 all KL = 0.048 +- 0.112 (in-sample avg dev_std = 0.153)
NEC for r=0.6 all L1 = 0.093 +- 0.148 (in-sample avg dev_std = 0.153)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.856
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.81
NEC for r=0.9 class 0.0 = 0.032 +- 0.219 (in-sample avg dev_std = 0.260)
NEC for r=0.9 class 1.0 = 0.255 +- 0.219 (in-sample avg dev_std = 0.260)
NEC for r=0.9 all KL = 0.122 +- 0.219 (in-sample avg dev_std = 0.260)
NEC for r=0.9 all L1 = 0.144 +- 0.209 (in-sample avg dev_std = 0.260)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.856
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.806
NEC for r=1.0 class 0.0 = 0.034 +- 0.261 (in-sample avg dev_std = 0.284)
NEC for r=1.0 class 1.0 = 0.278 +- 0.261 (in-sample avg dev_std = 0.284)
NEC for r=1.0 all KL = 0.153 +- 0.261 (in-sample avg dev_std = 0.284)
NEC for r=1.0 all L1 = 0.156 +- 0.225 (in-sample avg dev_std = 0.284)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.635
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.661
NEC for r=0.3 class 0.0 = 0.029 +- 0.029 (in-sample avg dev_std = 0.070)
NEC for r=0.3 class 1.0 = 0.065 +- 0.029 (in-sample avg dev_std = 0.070)
NEC for r=0.3 all KL = 0.016 +- 0.029 (in-sample avg dev_std = 0.070)
NEC for r=0.3 all L1 = 0.047 +- 0.061 (in-sample avg dev_std = 0.070)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.693
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.702
NEC for r=0.6 class 0.0 = 0.035 +- 0.088 (in-sample avg dev_std = 0.131)
NEC for r=0.6 class 1.0 = 0.135 +- 0.088 (in-sample avg dev_std = 0.131)
NEC for r=0.6 all KL = 0.042 +- 0.088 (in-sample avg dev_std = 0.131)
NEC for r=0.6 all L1 = 0.085 +- 0.130 (in-sample avg dev_std = 0.131)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.767
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.746
NEC for r=0.9 class 0.0 = 0.045 +- 0.175 (in-sample avg dev_std = 0.205)
NEC for r=0.9 class 1.0 = 0.179 +- 0.175 (in-sample avg dev_std = 0.205)
NEC for r=0.9 all KL = 0.091 +- 0.175 (in-sample avg dev_std = 0.205)
NEC for r=0.9 all L1 = 0.112 +- 0.165 (in-sample avg dev_std = 0.205)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.751
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.727
NEC for r=1.0 class 0.0 = 0.046 +- 0.221 (in-sample avg dev_std = 0.244)
NEC for r=1.0 class 1.0 = 0.208 +- 0.221 (in-sample avg dev_std = 0.244)
NEC for r=1.0 all KL = 0.124 +- 0.221 (in-sample avg dev_std = 0.244)
NEC for r=1.0 all L1 = 0.127 +- 0.190 (in-sample avg dev_std = 0.244)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.647
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.641
NEC for r=0.3 class 0.0 = 0.021 +- 0.044 (in-sample avg dev_std = 0.065)
NEC for r=0.3 class 1.0 = 0.055 +- 0.044 (in-sample avg dev_std = 0.065)
NEC for r=0.3 all KL = 0.015 +- 0.044 (in-sample avg dev_std = 0.065)
NEC for r=0.3 all L1 = 0.038 +- 0.062 (in-sample avg dev_std = 0.065)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.699
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.703
NEC for r=0.6 class 0.0 = 0.017 +- 0.107 (in-sample avg dev_std = 0.134)
NEC for r=0.6 class 1.0 = 0.124 +- 0.107 (in-sample avg dev_std = 0.134)
NEC for r=0.6 all KL = 0.039 +- 0.107 (in-sample avg dev_std = 0.134)
NEC for r=0.6 all L1 = 0.071 +- 0.137 (in-sample avg dev_std = 0.134)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.761
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.742
NEC for r=0.9 class 0.0 = 0.013 +- 0.147 (in-sample avg dev_std = 0.192)
NEC for r=0.9 class 1.0 = 0.137 +- 0.147 (in-sample avg dev_std = 0.192)
NEC for r=0.9 all KL = 0.054 +- 0.147 (in-sample avg dev_std = 0.192)
NEC for r=0.9 all L1 = 0.075 +- 0.141 (in-sample avg dev_std = 0.192)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.785
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.752
NEC for r=1.0 class 0.0 = 0.011 +- 0.147 (in-sample avg dev_std = 0.190)
NEC for r=1.0 class 1.0 = 0.128 +- 0.147 (in-sample avg dev_std = 0.190)
NEC for r=1.0 all KL = 0.051 +- 0.147 (in-sample avg dev_std = 0.190)
NEC for r=1.0 all L1 = 0.07 +- 0.133 (in-sample avg dev_std = 0.190)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 23:52:52 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 03/22/2024 11:52:52 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 11:52:56 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 11:52:59 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:03 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:06 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:06 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0mUsing feature sampling := feat
self.EF = 0.1
[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:53:23 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 178...
[0m[1;37mINFO[0m: [1mCheckpoint 178: 
-----------------------------------
Train ROC-AUC: 0.9928
Train Loss: 0.0421
ID Validation ROC-AUC: 0.8460
ID Validation Loss: 0.1580
ID Test ROC-AUC: 0.8091
ID Test Loss: 0.1489
OOD Validation ROC-AUC: 0.7496
OOD Validation Loss: 0.1650
OOD Test ROC-AUC: 0.7077
OOD Test Loss: 0.1190

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 141...
[0m[1;37mINFO[0m: [1mCheckpoint 141: 
-----------------------------------
Train ROC-AUC: 0.9781
Train Loss: 0.0600
ID Validation ROC-AUC: 0.8358
ID Validation Loss: 0.1409
ID Test ROC-AUC: 0.8118
ID Test Loss: 0.1303
OOD Validation ROC-AUC: 0.7903
OOD Validation Loss: 0.1230
OOD Test ROC-AUC: 0.7362
OOD Test Loss: 0.0936

[0m[1;37mINFO[0m: [1mChartInfo 0.8091 0.7077 0.8118 0.7362 0.8358 0.7903[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 03/22/2024 11:53:24 PM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 03/22/2024 11:53:26 PM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 03/22/2024 11:53:27 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.713
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 339
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.613
SUFF++ for r=0.3 class 0.0 = 0.949 +- 0.137 (in-sample avg dev_std = 0.189)
SUFF++ for r=0.3 class 1.0 = 0.83 +- 0.137 (in-sample avg dev_std = 0.189)
SUFF++ for r=0.3 all KL = 0.925 +- 0.137 (in-sample avg dev_std = 0.189)
SUFF++ for r=0.3 all L1 = 0.89 +- 0.167 (in-sample avg dev_std = 0.189)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.83
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.779
SUFF++ for r=0.6 class 0.0 = 0.958 +- 0.180 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.6 class 1.0 = 0.786 +- 0.180 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.6 all KL = 0.905 +- 0.180 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.6 all L1 = 0.872 +- 0.177 (in-sample avg dev_std = 0.241)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.858
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.842
SUFF++ for r=0.9 class 0.0 = 0.985 +- 0.134 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.9 class 1.0 = 0.909 +- 0.134 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.9 all KL = 0.958 +- 0.134 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.9 all L1 = 0.947 +- 0.119 (in-sample avg dev_std = 0.174)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.642
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 243
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.562
SUFF++ for r=0.3 class 0.0 = 0.959 +- 0.110 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.3 class 1.0 = 0.853 +- 0.110 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.3 all KL = 0.942 +- 0.110 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.3 all L1 = 0.905 +- 0.151 (in-sample avg dev_std = 0.164)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.697
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.654
SUFF++ for r=0.6 class 0.0 = 0.958 +- 0.156 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.6 class 1.0 = 0.836 +- 0.156 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.6 all KL = 0.921 +- 0.156 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.6 all L1 = 0.897 +- 0.164 (in-sample avg dev_std = 0.218)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.743
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.736
SUFF++ for r=0.9 class 0.0 = 0.985 +- 0.057 (in-sample avg dev_std = 0.110)
SUFF++ for r=0.9 class 1.0 = 0.938 +- 0.057 (in-sample avg dev_std = 0.110)
SUFF++ for r=0.9 all KL = 0.98 +- 0.057 (in-sample avg dev_std = 0.110)
SUFF++ for r=0.9 all L1 = 0.962 +- 0.078 (in-sample avg dev_std = 0.110)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.672
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 144
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.604
SUFF++ for r=0.3 class 0.0 = 0.964 +- 0.092 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.3 class 1.0 = 0.897 +- 0.092 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.3 all KL = 0.958 +- 0.092 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.3 all L1 = 0.93 +- 0.134 (in-sample avg dev_std = 0.124)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.691
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.686
SUFF++ for r=0.6 class 0.0 = 0.967 +- 0.166 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.6 class 1.0 = 0.844 +- 0.166 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.6 all KL = 0.932 +- 0.166 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.6 all L1 = 0.906 +- 0.174 (in-sample avg dev_std = 0.192)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.704
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.708
SUFF++ for r=0.9 class 0.0 = 0.991 +- 0.056 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.9 class 1.0 = 0.946 +- 0.056 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.9 all KL = 0.983 +- 0.056 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.9 all L1 = 0.968 +- 0.072 (in-sample avg dev_std = 0.112)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.713
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.695
NEC for r=0.3 class 0.0 = 0.045 +- 0.094 (in-sample avg dev_std = 0.134)
NEC for r=0.3 class 1.0 = 0.131 +- 0.094 (in-sample avg dev_std = 0.134)
NEC for r=0.3 all KL = 0.044 +- 0.094 (in-sample avg dev_std = 0.134)
NEC for r=0.3 all L1 = 0.088 +- 0.134 (in-sample avg dev_std = 0.134)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.83
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.788
NEC for r=0.6 class 0.0 = 0.039 +- 0.174 (in-sample avg dev_std = 0.215)
NEC for r=0.6 class 1.0 = 0.203 +- 0.174 (in-sample avg dev_std = 0.215)
NEC for r=0.6 all KL = 0.089 +- 0.174 (in-sample avg dev_std = 0.215)
NEC for r=0.6 all L1 = 0.121 +- 0.172 (in-sample avg dev_std = 0.215)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.858
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.806
NEC for r=0.9 class 0.0 = 0.041 +- 0.269 (in-sample avg dev_std = 0.305)
NEC for r=0.9 class 1.0 = 0.252 +- 0.269 (in-sample avg dev_std = 0.305)
NEC for r=0.9 all KL = 0.162 +- 0.269 (in-sample avg dev_std = 0.305)
NEC for r=0.9 all L1 = 0.146 +- 0.209 (in-sample avg dev_std = 0.305)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.867
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.818
NEC for r=1.0 class 0.0 = 0.05 +- 0.287 (in-sample avg dev_std = 0.331)
NEC for r=1.0 class 1.0 = 0.259 +- 0.287 (in-sample avg dev_std = 0.331)
NEC for r=1.0 all KL = 0.183 +- 0.287 (in-sample avg dev_std = 0.331)
NEC for r=1.0 all L1 = 0.155 +- 0.216 (in-sample avg dev_std = 0.331)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.642
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.661
NEC for r=0.3 class 0.0 = 0.04 +- 0.059 (in-sample avg dev_std = 0.098)
NEC for r=0.3 class 1.0 = 0.112 +- 0.059 (in-sample avg dev_std = 0.098)
NEC for r=0.3 all KL = 0.033 +- 0.059 (in-sample avg dev_std = 0.098)
NEC for r=0.3 all L1 = 0.076 +- 0.113 (in-sample avg dev_std = 0.098)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.697
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.688
NEC for r=0.6 class 0.0 = 0.044 +- 0.128 (in-sample avg dev_std = 0.164)
NEC for r=0.6 class 1.0 = 0.137 +- 0.128 (in-sample avg dev_std = 0.164)
NEC for r=0.6 all KL = 0.061 +- 0.128 (in-sample avg dev_std = 0.164)
NEC for r=0.6 all L1 = 0.091 +- 0.148 (in-sample avg dev_std = 0.164)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.743
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.735
NEC for r=0.9 class 0.0 = 0.041 +- 0.174 (in-sample avg dev_std = 0.209)
NEC for r=0.9 class 1.0 = 0.172 +- 0.174 (in-sample avg dev_std = 0.209)
NEC for r=0.9 all KL = 0.094 +- 0.174 (in-sample avg dev_std = 0.209)
NEC for r=0.9 all L1 = 0.106 +- 0.161 (in-sample avg dev_std = 0.209)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.749
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.728
NEC for r=1.0 class 0.0 = 0.05 +- 0.202 (in-sample avg dev_std = 0.232)
NEC for r=1.0 class 1.0 = 0.176 +- 0.202 (in-sample avg dev_std = 0.232)
NEC for r=1.0 all KL = 0.106 +- 0.202 (in-sample avg dev_std = 0.232)
NEC for r=1.0 all L1 = 0.113 +- 0.171 (in-sample avg dev_std = 0.232)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.66
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.634
NEC for r=0.3 class 0.0 = 0.027 +- 0.083 (in-sample avg dev_std = 0.117)
NEC for r=0.3 class 1.0 = 0.094 +- 0.083 (in-sample avg dev_std = 0.117)
NEC for r=0.3 all KL = 0.03 +- 0.083 (in-sample avg dev_std = 0.117)
NEC for r=0.3 all L1 = 0.06 +- 0.117 (in-sample avg dev_std = 0.117)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.691
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.659
NEC for r=0.6 class 0.0 = 0.036 +- 0.150 (in-sample avg dev_std = 0.181)
NEC for r=0.6 class 1.0 = 0.138 +- 0.150 (in-sample avg dev_std = 0.181)
NEC for r=0.6 all KL = 0.06 +- 0.150 (in-sample avg dev_std = 0.181)
NEC for r=0.6 all L1 = 0.087 +- 0.159 (in-sample avg dev_std = 0.181)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.704
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.678
NEC for r=0.9 class 0.0 = 0.025 +- 0.203 (in-sample avg dev_std = 0.232)
NEC for r=0.9 class 1.0 = 0.162 +- 0.203 (in-sample avg dev_std = 0.232)
NEC for r=0.9 all KL = 0.083 +- 0.203 (in-sample avg dev_std = 0.232)
NEC for r=0.9 all L1 = 0.094 +- 0.172 (in-sample avg dev_std = 0.232)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.73
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.673
NEC for r=1.0 class 0.0 = 0.021 +- 0.190 (in-sample avg dev_std = 0.214)
NEC for r=1.0 class 1.0 = 0.154 +- 0.190 (in-sample avg dev_std = 0.214)
NEC for r=1.0 all KL = 0.079 +- 0.190 (in-sample avg dev_std = 0.214)
NEC for r=1.0 all L1 = 0.087 +- 0.158 (in-sample avg dev_std = 0.214)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.953, 0.93, 0.977, 1.0], 'all_L1': [0.905, 0.878, 0.956, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.931, 0.902, 0.956, 1.0], 'all_L1': [0.887, 0.87, 0.947, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.922, 0.92, 0.966, 1.0], 'all_L1': [0.865, 0.873, 0.948, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.971, 0.962, 0.975, 1.0], 'all_L1': [0.934, 0.913, 0.954, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.925, 0.905, 0.958, 1.0], 'all_L1': [0.89, 0.872, 0.947, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.026, 0.067, 0.119, 0.134], 'all_L1': [0.074, 0.119, 0.135, 0.136]}), defaultdict(<class 'list'>, {'all_KL': [0.052, 0.1, 0.173, 0.197], 'all_L1': [0.1, 0.126, 0.145, 0.153]}), defaultdict(<class 'list'>, {'all_KL': [0.053, 0.086, 0.14, 0.162], 'all_L1': [0.114, 0.129, 0.144, 0.149]}), defaultdict(<class 'list'>, {'all_KL': [0.019, 0.048, 0.122, 0.153], 'all_L1': [0.054, 0.093, 0.144, 0.156]}), defaultdict(<class 'list'>, {'all_KL': [0.044, 0.089, 0.162, 0.183], 'all_L1': [0.088, 0.121, 0.146, 0.155]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.961, 0.947, 0.984, 1.0], 'all_L1': [0.911, 0.9, 0.962, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.936, 0.914, 0.963, 1.0], 'all_L1': [0.891, 0.883, 0.956, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.913, 0.918, 0.973, 1.0], 'all_L1': [0.856, 0.86, 0.949, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.977, 0.959, 0.979, 1.0], 'all_L1': [0.942, 0.915, 0.959, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.942, 0.921, 0.98, 1.0], 'all_L1': [0.905, 0.897, 0.962, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.027, 0.047, 0.064, 0.076], 'all_L1': [0.075, 0.098, 0.094, 0.093]}), defaultdict(<class 'list'>, {'all_KL': [0.055, 0.094, 0.125, 0.128], 'all_L1': [0.103, 0.119, 0.113, 0.109]}), defaultdict(<class 'list'>, {'all_KL': [0.045, 0.073, 0.118, 0.14], 'all_L1': [0.111, 0.128, 0.136, 0.141]}), defaultdict(<class 'list'>, {'all_KL': [0.016, 0.042, 0.091, 0.124], 'all_L1': [0.047, 0.085, 0.112, 0.127]}), defaultdict(<class 'list'>, {'all_KL': [0.033, 0.061, 0.094, 0.106], 'all_L1': [0.076, 0.091, 0.106, 0.113]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.955, 0.933, 0.981, 1.0], 'all_L1': [0.911, 0.894, 0.964, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.952, 0.929, 0.976, 1.0], 'all_L1': [0.926, 0.902, 0.964, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.951, 0.92, 0.958, 1.0], 'all_L1': [0.904, 0.882, 0.945, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.981, 0.965, 0.987, 1.0], 'all_L1': [0.955, 0.934, 0.97, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.958, 0.932, 0.983, 1.0], 'all_L1': [0.93, 0.906, 0.968, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.037, 0.046, 0.06, 0.073], 'all_L1': [0.086, 0.088, 0.083, 0.086]}), defaultdict(<class 'list'>, {'all_KL': [0.033, 0.075, 0.097, 0.113], 'all_L1': [0.064, 0.102, 0.093, 0.102]}), defaultdict(<class 'list'>, {'all_KL': [0.041, 0.081, 0.119, 0.135], 'all_L1': [0.091, 0.113, 0.126, 0.132]}), defaultdict(<class 'list'>, {'all_KL': [0.015, 0.039, 0.054, 0.051], 'all_L1': [0.038, 0.071, 0.075, 0.07]}), defaultdict(<class 'list'>, {'all_KL': [0.03, 0.06, 0.083, 0.079], 'all_L1': [0.06, 0.087, 0.094, 0.087]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.896 +- 0.023, 0.881 +- 0.016, 0.950 +- 0.004, 1.000 +- 0.000
suff++ class all_KL  =  0.940 +- 0.019, 0.924 +- 0.022, 0.966 +- 0.009, 1.000 +- 0.000
suff++_acc_int  =  0.621 +- 0.008, 0.763 +- 0.011, 0.843 +- 0.005
nec class all_L1  =  0.086 +- 0.021, 0.118 +- 0.013, 0.143 +- 0.004, 0.150 +- 0.007
nec class all_KL  =  0.039 +- 0.014, 0.078 +- 0.018, 0.143 +- 0.021, 0.166 +- 0.022
nec_acc_int  =  0.689 +- 0.011, 0.777 +- 0.006, 0.804 +- 0.006, 0.809 +- 0.004

Eval split val
suff++ class all_L1  =  0.901 +- 0.028, 0.891 +- 0.019, 0.958 +- 0.005, 1.000 +- 0.000
suff++ class all_KL  =  0.946 +- 0.022, 0.932 +- 0.018, 0.976 +- 0.007, 1.000 +- 0.000
suff++_acc_int  =  0.586 +- 0.029, 0.659 +- 0.013, 0.740 +- 0.013
nec class all_L1  =  0.082 +- 0.023, 0.104 +- 0.017, 0.112 +- 0.014, 0.117 +- 0.016
nec class all_KL  =  0.035 +- 0.014, 0.063 +- 0.019, 0.098 +- 0.022, 0.115 +- 0.022
nec_acc_int  =  0.654 +- 0.021, 0.708 +- 0.018, 0.735 +- 0.008, 0.735 +- 0.008

Eval split test
suff++ class all_L1  =  0.925 +- 0.018, 0.904 +- 0.017, 0.962 +- 0.009, 1.000 +- 0.000
suff++ class all_KL  =  0.959 +- 0.011, 0.936 +- 0.015, 0.977 +- 0.010, 1.000 +- 0.000
suff++_acc_int  =  0.590 +- 0.019, 0.665 +- 0.015, 0.727 +- 0.023
nec class all_L1  =  0.068 +- 0.019, 0.092 +- 0.014, 0.094 +- 0.017, 0.095 +- 0.021
nec class all_KL  =  0.031 +- 0.009, 0.060 +- 0.016, 0.083 +- 0.024, 0.090 +- 0.030
nec_acc_int  =  0.632 +- 0.024, 0.672 +- 0.019, 0.703 +- 0.022, 0.708 +- 0.026


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.491 +- 0.002, 0.499 +- 0.002, 0.547 +- 0.001, 0.575 +- 0.004
Faith. Armon (L1)= 		  =  0.156 +- 0.034, 0.207 +- 0.020, 0.248 +- 0.006, 0.260 +- 0.011
Faith. GMean (L1)= 	  =  0.275 +- 0.031, 0.321 +- 0.016, 0.368 +- 0.005, 0.387 +- 0.010
Faith. Aritm (KL)= 		  =  0.490 +- 0.004, 0.501 +- 0.003, 0.555 +- 0.006, 0.583 +- 0.011
Faith. Armon (KL)= 		  =  0.074 +- 0.026, 0.143 +- 0.031, 0.249 +- 0.032, 0.284 +- 0.033
Faith. GMean (KL)= 	  =  0.187 +- 0.035, 0.266 +- 0.030, 0.371 +- 0.026, 0.406 +- 0.027

Eval split val
Faith. Aritm (L1)= 		  =  0.492 +- 0.005, 0.498 +- 0.003, 0.535 +- 0.005, 0.558 +- 0.008
Faith. Armon (L1)= 		  =  0.150 +- 0.038, 0.186 +- 0.026, 0.201 +- 0.022, 0.208 +- 0.026
Faith. GMean (L1)= 	  =  0.269 +- 0.035, 0.304 +- 0.021, 0.327 +- 0.019, 0.341 +- 0.024
Faith. Aritm (KL)= 		  =  0.491 +- 0.007, 0.498 +- 0.004, 0.537 +- 0.008, 0.557 +- 0.011
Faith. Armon (KL)= 		  =  0.067 +- 0.025, 0.118 +- 0.032, 0.178 +- 0.036, 0.205 +- 0.036
Faith. GMean (KL)= 	  =  0.178 +- 0.035, 0.240 +- 0.033, 0.308 +- 0.034, 0.337 +- 0.034

Eval split test
Faith. Aritm (L1)= 		  =  0.497 +- 0.001, 0.498 +- 0.004, 0.528 +- 0.005, 0.548 +- 0.010
Faith. Armon (L1)= 		  =  0.126 +- 0.033, 0.167 +- 0.023, 0.171 +- 0.028, 0.174 +- 0.034
Faith. GMean (L1)= 	  =  0.247 +- 0.035, 0.288 +- 0.020, 0.300 +- 0.025, 0.307 +- 0.033
Faith. Aritm (KL)= 		  =  0.495 +- 0.002, 0.498 +- 0.005, 0.530 +- 0.008, 0.545 +- 0.015
Faith. Armon (KL)= 		  =  0.060 +- 0.017, 0.113 +- 0.028, 0.151 +- 0.040, 0.164 +- 0.050
Faith. GMean (KL)= 	  =  0.171 +- 0.026, 0.235 +- 0.031, 0.281 +- 0.040, 0.296 +- 0.050
Computed for split load_split = id



Completed in  0:09:24.222004  for LECIvGIN GOODHIV/scaffold



DONE LECI GOODHIV/scaffold

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 23:55:01 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 03/22/2024 11:55:02 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 11:55:05 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 11:55:09 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 11:55:12 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 11:55:15 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 03/22/2024 11:55:15 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 11:55:32 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/22/2024 11:55:32 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:55:32 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:55:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:55:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:55:32 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/22/2024 11:55:32 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:55:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:55:32 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/22/2024 11:55:32 PM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 03/22/2024 11:55:32 PM : [1mInit Backbone:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:55:32 PM : [1mCreating vGINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:55:32 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:55:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:55:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:55:32 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:55:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:55:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:55:32 PM : [1mInit CLF:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:55:32 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:55:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:55:32 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:55:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:55:32 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 78...
[0m[1;37mINFO[0m: [1mCheckpoint 78: 
-----------------------------------
Train ROC-AUC: 0.9940
Train Loss: 0.0391
ID Validation ROC-AUC: 0.8450
ID Validation Loss: 0.1821
ID Test ROC-AUC: 0.8077
ID Test Loss: 0.1679
OOD Validation ROC-AUC: 0.6969
OOD Validation Loss: 0.2009
OOD Test ROC-AUC: 0.6673
OOD Test Loss: 0.1473

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 67...
[0m[1;37mINFO[0m: [1mCheckpoint 67: 
-----------------------------------
Train ROC-AUC: 0.9930
Train Loss: 0.0404
ID Validation ROC-AUC: 0.8284
ID Validation Loss: 0.1766
ID Test ROC-AUC: 0.8100
ID Test Loss: 0.1597
OOD Validation ROC-AUC: 0.7746
OOD Validation Loss: 0.1708
OOD Test ROC-AUC: 0.6410
OOD Test Loss: 0.1507

[0m[1;37mINFO[0m: [1mChartInfo 0.8077 0.6673 0.8100 0.6410 0.8284 0.7746[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 03/22/2024 11:55:33 PM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.8 = nan
WIoU for r=0.8 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 03/22/2024 11:55:37 PM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.8 = nan
WIoU for r=0.8 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 03/22/2024 11:55:39 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.8 = nan
WIoU for r=0.8 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.742
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 352
Effective ratio: 0.807 +- 0.006
Model ROC-AUC over intervened graphs for r=0.8 =  0.54
SUFF++ for r=0.8 class 0.0 = 0.703 +- 0.299 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.8 class 1.0 = 0.62 +- 0.299 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.8 all KL = 0.543 +- 0.299 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.8 all L1 = 0.662 +- 0.222 (in-sample avg dev_std = 0.530)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.637
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 252
Effective ratio: 0.807 +- 0.006
Model ROC-AUC over intervened graphs for r=0.8 =  0.571
SUFF++ for r=0.8 class 0.0 = 0.775 +- 0.285 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.8 class 1.0 = 0.722 +- 0.285 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.8 all KL = 0.683 +- 0.285 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.8 all L1 = 0.749 +- 0.225 (in-sample avg dev_std = 0.450)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.579
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 161
Effective ratio: 0.810 +- 0.010
Model ROC-AUC over intervened graphs for r=0.8 =  0.49
SUFF++ for r=0.8 class 0.0 = 0.789 +- 0.287 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.8 class 1.0 = 0.761 +- 0.287 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.8 all KL = 0.725 +- 0.287 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.8 all L1 = 0.775 +- 0.228 (in-sample avg dev_std = 0.394)


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.742
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 352
Effective ratio: 0.807 +- 0.006
Model ROC-AUC over intervened graphs for r=0.8 =  0.636
NEC for r=0.8 class 0.0 = 0.247 +- 0.314 (in-sample avg dev_std = 0.298)
NEC for r=0.8 class 1.0 = 0.29 +- 0.314 (in-sample avg dev_std = 0.298)
NEC for r=0.8 all KL = 0.302 +- 0.314 (in-sample avg dev_std = 0.298)
NEC for r=0.8 all L1 = 0.269 +- 0.258 (in-sample avg dev_std = 0.298)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.637
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 252
Effective ratio: 0.807 +- 0.006
Model ROC-AUC over intervened graphs for r=0.8 =  0.608
NEC for r=0.8 class 0.0 = 0.181 +- 0.262 (in-sample avg dev_std = 0.234)
NEC for r=0.8 class 1.0 = 0.188 +- 0.262 (in-sample avg dev_std = 0.234)
NEC for r=0.8 all KL = 0.184 +- 0.262 (in-sample avg dev_std = 0.234)
NEC for r=0.8 all L1 = 0.184 +- 0.227 (in-sample avg dev_std = 0.234)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.572
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 162
Effective ratio: 0.810 +- 0.010
Model ROC-AUC over intervened graphs for r=0.8 =  0.481
NEC for r=0.8 class 0.0 = 0.223 +- 0.315 (in-sample avg dev_std = 0.303)
NEC for r=0.8 class 1.0 = 0.245 +- 0.315 (in-sample avg dev_std = 0.303)
NEC for r=0.8 all KL = 0.264 +- 0.315 (in-sample avg dev_std = 0.303)
NEC for r=0.8 all L1 = 0.234 +- 0.265 (in-sample avg dev_std = 0.303)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 23:56:02 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 03/22/2024 11:56:02 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 11:56:06 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 11:56:09 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 11:56:12 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 11:56:15 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 03/22/2024 11:56:15 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 11:56:31 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/22/2024 11:56:31 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:56:31 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:56:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:56:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:56:31 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/22/2024 11:56:31 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:56:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:56:31 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/22/2024 11:56:31 PM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 03/22/2024 11:56:31 PM : [1mInit Backbone:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:56:31 PM : [1mCreating vGINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:56:31 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:56:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:56:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:56:31 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:56:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:56:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:56:31 PM : [1mInit CLF:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:56:31 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:56:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:56:31 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:56:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:56:31 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 129...
[0m[1;37mINFO[0m: [1mCheckpoint 129: 
-----------------------------------
Train ROC-AUC: 0.9987
Train Loss: 0.0183
ID Validation ROC-AUC: 0.8436
ID Validation Loss: 0.1867
ID Test ROC-AUC: 0.7972
ID Test Loss: 0.1808
OOD Validation ROC-AUC: 0.7113
OOD Validation Loss: 0.2083
OOD Test ROC-AUC: 0.6616
OOD Test Loss: 0.1540

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 11...
[0m[1;37mINFO[0m: [1mCheckpoint 11: 
-----------------------------------
Train ROC-AUC: 0.8665
Train Loss: 0.1133
ID Validation ROC-AUC: 0.8073
ID Validation Loss: 0.1400
ID Test ROC-AUC: 0.8000
ID Test Loss: 0.1208
OOD Validation ROC-AUC: 0.7821
OOD Validation Loss: 0.1218
OOD Test ROC-AUC: 0.6412
OOD Test Loss: 0.0947

[0m[1;37mINFO[0m: [1mChartInfo 0.7972 0.6616 0.8000 0.6412 0.8073 0.7821[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 03/22/2024 11:56:31 PM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.8 = nan
WIoU for r=0.8 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 03/22/2024 11:56:35 PM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.8 = nan
WIoU for r=0.8 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 03/22/2024 11:56:37 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.8 = nan
WIoU for r=0.8 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.696
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 352
Effective ratio: 0.807 +- 0.006
Model ROC-AUC over intervened graphs for r=0.8 =  0.593
SUFF++ for r=0.8 class 0.0 = 0.932 +- 0.233 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.8 class 1.0 = 0.819 +- 0.233 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.8 all KL = 0.863 +- 0.233 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.8 all L1 = 0.876 +- 0.211 (in-sample avg dev_std = 0.228)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.542
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 252
Effective ratio: 0.807 +- 0.006
Model ROC-AUC over intervened graphs for r=0.8 =  0.57
SUFF++ for r=0.8 class 0.0 = 0.89 +- 0.255 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.8 class 1.0 = 0.818 +- 0.255 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.8 all KL = 0.83 +- 0.255 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.8 all L1 = 0.854 +- 0.224 (in-sample avg dev_std = 0.278)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.561
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 161
Effective ratio: 0.810 +- 0.010
Model ROC-AUC over intervened graphs for r=0.8 =  0.555
SUFF++ for r=0.8 class 0.0 = 0.885 +- 0.254 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.8 class 1.0 = 0.821 +- 0.254 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.8 all KL = 0.831 +- 0.254 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.8 all L1 = 0.853 +- 0.228 (in-sample avg dev_std = 0.263)


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.696
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 352
Effective ratio: 0.807 +- 0.006
Model ROC-AUC over intervened graphs for r=0.8 =  0.647
NEC for r=0.8 class 0.0 = 0.116 +- 0.297 (in-sample avg dev_std = 0.285)
NEC for r=0.8 class 1.0 = 0.231 +- 0.297 (in-sample avg dev_std = 0.285)
NEC for r=0.8 all KL = 0.207 +- 0.297 (in-sample avg dev_std = 0.285)
NEC for r=0.8 all L1 = 0.174 +- 0.244 (in-sample avg dev_std = 0.285)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.542
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 252
Effective ratio: 0.807 +- 0.006
Model ROC-AUC over intervened graphs for r=0.8 =  0.542
NEC for r=0.8 class 0.0 = 0.224 +- 0.333 (in-sample avg dev_std = 0.340)
NEC for r=0.8 class 1.0 = 0.22 +- 0.333 (in-sample avg dev_std = 0.340)
NEC for r=0.8 all KL = 0.271 +- 0.333 (in-sample avg dev_std = 0.340)
NEC for r=0.8 all L1 = 0.222 +- 0.266 (in-sample avg dev_std = 0.340)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.558
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 162
Effective ratio: 0.810 +- 0.010
Model ROC-AUC over intervened graphs for r=0.8 =  0.569
NEC for r=0.8 class 0.0 = 0.09 +- 0.210 (in-sample avg dev_std = 0.268)
NEC for r=0.8 class 1.0 = 0.17 +- 0.210 (in-sample avg dev_std = 0.268)
NEC for r=0.8 all KL = 0.135 +- 0.210 (in-sample avg dev_std = 0.268)
NEC for r=0.8 all L1 = 0.13 +- 0.190 (in-sample avg dev_std = 0.268)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 23:56:59 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 03/22/2024 11:56:59 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 11:57:02 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 11:57:05 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 11:57:08 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 11:57:11 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 03/22/2024 11:57:11 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 11:57:26 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/22/2024 11:57:26 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:57:26 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:57:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:57:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:57:26 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/22/2024 11:57:26 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:57:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:57:26 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/22/2024 11:57:26 PM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 03/22/2024 11:57:26 PM : [1mInit Backbone:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:57:26 PM : [1mCreating vGINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:57:26 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:57:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:57:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:57:27 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:57:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:57:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:57:27 PM : [1mInit CLF:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:57:27 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:57:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:57:27 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:57:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:57:27 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 32...
[0m[1;37mINFO[0m: [1mCheckpoint 32: 
-----------------------------------
Train ROC-AUC: 0.9615
Train Loss: 0.0758
ID Validation ROC-AUC: 0.8439
ID Validation Loss: 0.1249
ID Test ROC-AUC: 0.7995
ID Test Loss: 0.1163
OOD Validation ROC-AUC: 0.7437
OOD Validation Loss: 0.1234
OOD Test ROC-AUC: 0.6739
OOD Test Loss: 0.0957

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 13...
[0m[1;37mINFO[0m: [1mCheckpoint 13: 
-----------------------------------
Train ROC-AUC: 0.8809
Train Loss: 0.1125
ID Validation ROC-AUC: 0.8182
ID Validation Loss: 0.1392
ID Test ROC-AUC: 0.7843
ID Test Loss: 0.1272
OOD Validation ROC-AUC: 0.7800
OOD Validation Loss: 0.1249
OOD Test ROC-AUC: 0.6692
OOD Test Loss: 0.0917

[0m[1;37mINFO[0m: [1mChartInfo 0.7995 0.6739 0.7843 0.6692 0.8182 0.7800[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 03/22/2024 11:57:27 PM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.8 = nan
WIoU for r=0.8 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 03/22/2024 11:57:30 PM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.8 = nan
WIoU for r=0.8 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 03/22/2024 11:57:33 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.8 = nan
WIoU for r=0.8 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.736
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 352
Effective ratio: 0.807 +- 0.006
Model ROC-AUC over intervened graphs for r=0.8 =  0.634
SUFF++ for r=0.8 class 0.0 = 0.935 +- 0.098 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.8 class 1.0 = 0.864 +- 0.098 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.8 all KL = 0.929 +- 0.098 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.8 all L1 = 0.9 +- 0.113 (in-sample avg dev_std = 0.152)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.722
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 252
Effective ratio: 0.807 +- 0.006
Model ROC-AUC over intervened graphs for r=0.8 =  0.663
SUFF++ for r=0.8 class 0.0 = 0.931 +- 0.075 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.8 class 1.0 = 0.883 +- 0.075 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.8 all KL = 0.939 +- 0.075 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.8 all L1 = 0.907 +- 0.073 (in-sample avg dev_std = 0.127)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.625
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 162
Effective ratio: 0.810 +- 0.010
Model ROC-AUC over intervened graphs for r=0.8 =  0.567
SUFF++ for r=0.8 class 0.0 = 0.955 +- 0.041 (in-sample avg dev_std = 0.078)
SUFF++ for r=0.8 class 1.0 = 0.91 +- 0.041 (in-sample avg dev_std = 0.078)
SUFF++ for r=0.8 all KL = 0.968 +- 0.041 (in-sample avg dev_std = 0.078)
SUFF++ for r=0.8 all L1 = 0.933 +- 0.076 (in-sample avg dev_std = 0.078)


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.736
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 352
Effective ratio: 0.807 +- 0.006
Model ROC-AUC over intervened graphs for r=0.8 =  0.686
NEC for r=0.8 class 0.0 = 0.049 +- 0.062 (in-sample avg dev_std = 0.081)
NEC for r=0.8 class 1.0 = 0.101 +- 0.062 (in-sample avg dev_std = 0.081)
NEC for r=0.8 all KL = 0.036 +- 0.062 (in-sample avg dev_std = 0.081)
NEC for r=0.8 all L1 = 0.075 +- 0.094 (in-sample avg dev_std = 0.081)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.722
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 252
Effective ratio: 0.807 +- 0.006
Model ROC-AUC over intervened graphs for r=0.8 =  0.713
NEC for r=0.8 class 0.0 = 0.05 +- 0.064 (in-sample avg dev_std = 0.074)
NEC for r=0.8 class 1.0 = 0.099 +- 0.064 (in-sample avg dev_std = 0.074)
NEC for r=0.8 all KL = 0.033 +- 0.064 (in-sample avg dev_std = 0.074)
NEC for r=0.8 all L1 = 0.075 +- 0.083 (in-sample avg dev_std = 0.074)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.625
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 162
Effective ratio: 0.810 +- 0.010
Model ROC-AUC over intervened graphs for r=0.8 =  0.624
NEC for r=0.8 class 0.0 = 0.037 +- 0.025 (in-sample avg dev_std = 0.057)
NEC for r=0.8 class 1.0 = 0.069 +- 0.025 (in-sample avg dev_std = 0.057)
NEC for r=0.8 all KL = 0.019 +- 0.025 (in-sample avg dev_std = 0.057)
NEC for r=0.8 all L1 = 0.053 +- 0.060 (in-sample avg dev_std = 0.057)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 23:57:55 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 03/22/2024 11:57:55 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 11:57:58 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 11:58:01 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 11:58:05 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 11:58:07 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 03/22/2024 11:58:07 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 11:58:23 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/22/2024 11:58:23 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:58:23 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:58:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:58:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:58:23 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/22/2024 11:58:23 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:58:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:58:23 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/22/2024 11:58:23 PM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 03/22/2024 11:58:23 PM : [1mInit Backbone:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:58:23 PM : [1mCreating vGINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:58:23 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:58:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:58:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:58:23 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:58:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:58:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:58:23 PM : [1mInit CLF:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:58:23 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:58:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:58:23 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:58:23 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:58:23 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 143...
[0m[1;37mINFO[0m: [1mCheckpoint 143: 
-----------------------------------
Train ROC-AUC: 0.9983
Train Loss: 0.0242
ID Validation ROC-AUC: 0.8431
ID Validation Loss: 0.1834
ID Test ROC-AUC: 0.8028
ID Test Loss: 0.1734
OOD Validation ROC-AUC: 0.7364
OOD Validation Loss: 0.2070
OOD Test ROC-AUC: 0.6626
OOD Test Loss: 0.1633

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 38...
[0m[1;37mINFO[0m: [1mCheckpoint 38: 
-----------------------------------
Train ROC-AUC: 0.9560
Train Loss: 0.0779
ID Validation ROC-AUC: 0.8151
ID Validation Loss: 0.1518
ID Test ROC-AUC: 0.7777
ID Test Loss: 0.1370
OOD Validation ROC-AUC: 0.7910
OOD Validation Loss: 0.1230
OOD Test ROC-AUC: 0.6634
OOD Test Loss: 0.1055

[0m[1;37mINFO[0m: [1mChartInfo 0.8028 0.6626 0.7777 0.6634 0.8151 0.7910[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 03/22/2024 11:58:23 PM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.8 = nan
WIoU for r=0.8 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 03/22/2024 11:58:27 PM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.8 = nan
WIoU for r=0.8 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 03/22/2024 11:58:29 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.8 = nan
WIoU for r=0.8 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.669
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 352
Effective ratio: 0.807 +- 0.006
Model ROC-AUC over intervened graphs for r=0.8 =  0.588
SUFF++ for r=0.8 class 0.0 = 0.815 +- 0.308 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.8 class 1.0 = 0.705 +- 0.308 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.8 all KL = 0.64 +- 0.308 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.8 all L1 = 0.76 +- 0.222 (in-sample avg dev_std = 0.489)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.711
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 252
Effective ratio: 0.807 +- 0.006
Model ROC-AUC over intervened graphs for r=0.8 =  0.637
SUFF++ for r=0.8 class 0.0 = 0.868 +- 0.310 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.8 class 1.0 = 0.715 +- 0.310 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.8 all KL = 0.684 +- 0.310 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.8 all L1 = 0.792 +- 0.227 (in-sample avg dev_std = 0.450)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.53
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 161
Effective ratio: 0.810 +- 0.010
Model ROC-AUC over intervened graphs for r=0.8 =  0.53
SUFF++ for r=0.8 class 0.0 = 0.907 +- 0.242 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.8 class 1.0 = 0.871 +- 0.242 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.8 all KL = 0.837 +- 0.242 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.8 all L1 = 0.889 +- 0.167 (in-sample avg dev_std = 0.300)


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.669
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 352
Effective ratio: 0.807 +- 0.006
Model ROC-AUC over intervened graphs for r=0.8 =  0.681
NEC for r=0.8 class 0.0 = 0.117 +- 0.258 (in-sample avg dev_std = 0.274)
NEC for r=0.8 class 1.0 = 0.165 +- 0.258 (in-sample avg dev_std = 0.274)
NEC for r=0.8 all KL = 0.173 +- 0.258 (in-sample avg dev_std = 0.274)
NEC for r=0.8 all L1 = 0.141 +- 0.198 (in-sample avg dev_std = 0.274)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.711
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 252
Effective ratio: 0.807 +- 0.006
Model ROC-AUC over intervened graphs for r=0.8 =  0.721
NEC for r=0.8 class 0.0 = 0.085 +- 0.260 (in-sample avg dev_std = 0.249)
NEC for r=0.8 class 1.0 = 0.172 +- 0.260 (in-sample avg dev_std = 0.249)
NEC for r=0.8 all KL = 0.154 +- 0.260 (in-sample avg dev_std = 0.249)
NEC for r=0.8 all L1 = 0.128 +- 0.210 (in-sample avg dev_std = 0.249)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.528
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 162
Effective ratio: 0.810 +- 0.010
Model ROC-AUC over intervened graphs for r=0.8 =  0.572
NEC for r=0.8 class 0.0 = 0.09 +- 0.199 (in-sample avg dev_std = 0.195)
NEC for r=0.8 class 1.0 = 0.095 +- 0.199 (in-sample avg dev_std = 0.195)
NEC for r=0.8 all KL = 0.111 +- 0.199 (in-sample avg dev_std = 0.195)
NEC for r=0.8 all L1 = 0.092 +- 0.168 (in-sample avg dev_std = 0.195)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri Mar 22 23:58:51 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 03/22/2024 11:58:51 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/22/2024 11:58:54 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/22/2024 11:58:58 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/22/2024 11:59:01 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/22/2024 11:59:04 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 03/22/2024 11:59:04 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/22/2024 11:59:19 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/22/2024 11:59:19 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:59:19 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:59:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:59:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:59:19 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/22/2024 11:59:19 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:59:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:59:19 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/22/2024 11:59:19 PM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 03/22/2024 11:59:19 PM : [1mInit Backbone:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:59:19 PM : [1mCreating vGINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:59:19 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:59:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:59:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:59:19 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:59:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:59:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:59:19 PM : [1mInit CLF:  3
[0m[1;34mDEBUG[0m: 03/22/2024 11:59:19 PM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:59:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:59:19 PM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/22/2024 11:59:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/22/2024 11:59:20 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 42...
[0m[1;37mINFO[0m: [1mCheckpoint 42: 
-----------------------------------
Train ROC-AUC: 0.9711
Train Loss: 0.0868
ID Validation ROC-AUC: 0.8464
ID Validation Loss: 0.1631
ID Test ROC-AUC: 0.8070
ID Test Loss: 0.1620
OOD Validation ROC-AUC: 0.7678
OOD Validation Loss: 0.1715
OOD Test ROC-AUC: 0.7207
OOD Test Loss: 0.1109

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 8...
[0m[1;37mINFO[0m: [1mCheckpoint 8: 
-----------------------------------
Train ROC-AUC: 0.8237
Train Loss: 0.1344
ID Validation ROC-AUC: 0.7836
ID Validation Loss: 0.1594
ID Test ROC-AUC: 0.7505
ID Test Loss: 0.1407
OOD Validation ROC-AUC: 0.7881
OOD Validation Loss: 0.1099
OOD Test ROC-AUC: 0.7056
OOD Test Loss: 0.1049

[0m[1;37mINFO[0m: [1mChartInfo 0.8070 0.7207 0.7505 0.7056 0.7836 0.7881[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 03/22/2024 11:59:20 PM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.8 = nan
WIoU for r=0.8 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 03/22/2024 11:59:23 PM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.8 = nan
WIoU for r=0.8 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 03/22/2024 11:59:26 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.8 = nan
WIoU for r=0.8 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.715
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 352
Effective ratio: 0.807 +- 0.006
Model ROC-AUC over intervened graphs for r=0.8 =  0.66
SUFF++ for r=0.8 class 0.0 = 0.712 +- 0.191 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.8 class 1.0 = 0.715 +- 0.191 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.8 all KL = 0.778 +- 0.191 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.8 all L1 = 0.714 +- 0.186 (in-sample avg dev_std = 0.355)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.695
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 252
Effective ratio: 0.807 +- 0.006
Model ROC-AUC over intervened graphs for r=0.8 =  0.698
SUFF++ for r=0.8 class 0.0 = 0.622 +- 0.196 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.8 class 1.0 = 0.791 +- 0.196 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.8 all KL = 0.799 +- 0.196 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.8 all L1 = 0.706 +- 0.196 (in-sample avg dev_std = 0.360)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.666
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 160
Effective ratio: 0.810 +- 0.010
Model ROC-AUC over intervened graphs for r=0.8 =  0.626
SUFF++ for r=0.8 class 0.0 = 0.757 +- 0.181 (in-sample avg dev_std = 0.325)
SUFF++ for r=0.8 class 1.0 = 0.694 +- 0.181 (in-sample avg dev_std = 0.325)
SUFF++ for r=0.8 all KL = 0.817 +- 0.181 (in-sample avg dev_std = 0.325)
SUFF++ for r=0.8 all L1 = 0.725 +- 0.185 (in-sample avg dev_std = 0.325)


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.715
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 352
Effective ratio: 0.807 +- 0.006
Model ROC-AUC over intervened graphs for r=0.8 =  0.684
NEC for r=0.8 class 0.0 = 0.215 +- 0.156 (in-sample avg dev_std = 0.222)
NEC for r=0.8 class 1.0 = 0.194 +- 0.156 (in-sample avg dev_std = 0.222)
NEC for r=0.8 all KL = 0.123 +- 0.156 (in-sample avg dev_std = 0.222)
NEC for r=0.8 all L1 = 0.205 +- 0.180 (in-sample avg dev_std = 0.222)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.695
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 252
Effective ratio: 0.807 +- 0.006
Model ROC-AUC over intervened graphs for r=0.8 =  0.687
NEC for r=0.8 class 0.0 = 0.317 +- 0.176 (in-sample avg dev_std = 0.230)
NEC for r=0.8 class 1.0 = 0.206 +- 0.176 (in-sample avg dev_std = 0.230)
NEC for r=0.8 all KL = 0.153 +- 0.176 (in-sample avg dev_std = 0.230)
NEC for r=0.8 all L1 = 0.262 +- 0.206 (in-sample avg dev_std = 0.230)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.667
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 162
Effective ratio: 0.810 +- 0.010
Model ROC-AUC over intervened graphs for r=0.8 =  0.62
NEC for r=0.8 class 0.0 = 0.19 +- 0.154 (in-sample avg dev_std = 0.186)
NEC for r=0.8 class 1.0 = 0.269 +- 0.154 (in-sample avg dev_std = 0.186)
NEC for r=0.8 all KL = 0.118 +- 0.154 (in-sample avg dev_std = 0.186)
NEC for r=0.8 all L1 = 0.23 +- 0.189 (in-sample avg dev_std = 0.186)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.543], 'all_L1': [0.662]}), defaultdict(<class 'list'>, {'all_KL': [0.863], 'all_L1': [0.876]}), defaultdict(<class 'list'>, {'all_KL': [0.929], 'all_L1': [0.9]}), defaultdict(<class 'list'>, {'all_KL': [0.64], 'all_L1': [0.76]}), defaultdict(<class 'list'>, {'all_KL': [0.778], 'all_L1': [0.714]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.302], 'all_L1': [0.269]}), defaultdict(<class 'list'>, {'all_KL': [0.207], 'all_L1': [0.174]}), defaultdict(<class 'list'>, {'all_KL': [0.036], 'all_L1': [0.075]}), defaultdict(<class 'list'>, {'all_KL': [0.173], 'all_L1': [0.141]}), defaultdict(<class 'list'>, {'all_KL': [0.123], 'all_L1': [0.205]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.683], 'all_L1': [0.749]}), defaultdict(<class 'list'>, {'all_KL': [0.83], 'all_L1': [0.854]}), defaultdict(<class 'list'>, {'all_KL': [0.939], 'all_L1': [0.907]}), defaultdict(<class 'list'>, {'all_KL': [0.684], 'all_L1': [0.792]}), defaultdict(<class 'list'>, {'all_KL': [0.799], 'all_L1': [0.706]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.184], 'all_L1': [0.184]}), defaultdict(<class 'list'>, {'all_KL': [0.271], 'all_L1': [0.222]}), defaultdict(<class 'list'>, {'all_KL': [0.033], 'all_L1': [0.075]}), defaultdict(<class 'list'>, {'all_KL': [0.154], 'all_L1': [0.128]}), defaultdict(<class 'list'>, {'all_KL': [0.153], 'all_L1': [0.262]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.725], 'all_L1': [0.775]}), defaultdict(<class 'list'>, {'all_KL': [0.831], 'all_L1': [0.853]}), defaultdict(<class 'list'>, {'all_KL': [0.968], 'all_L1': [0.933]}), defaultdict(<class 'list'>, {'all_KL': [0.837], 'all_L1': [0.889]}), defaultdict(<class 'list'>, {'all_KL': [0.817], 'all_L1': [0.725]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.264], 'all_L1': [0.234]}), defaultdict(<class 'list'>, {'all_KL': [0.135], 'all_L1': [0.13]}), defaultdict(<class 'list'>, {'all_KL': [0.019], 'all_L1': [0.053]}), defaultdict(<class 'list'>, {'all_KL': [0.111], 'all_L1': [0.092]}), defaultdict(<class 'list'>, {'all_KL': [0.118], 'all_L1': [0.23]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.782 +- 0.092
suff++ class all_KL  =  0.751 +- 0.142
suff++_acc_int  =  0.603 +- 0.041
nec class all_L1  =  0.173 +- 0.065
nec class all_KL  =  0.168 +- 0.088
nec_acc_int  =  0.667 +- 0.021

Eval split val
suff++ class all_L1  =  0.802 +- 0.072
suff++ class all_KL  =  0.787 +- 0.096
suff++_acc_int  =  0.628 +- 0.051
nec class all_L1  =  0.174 +- 0.066
nec class all_KL  =  0.159 +- 0.076
nec_acc_int  =  0.654 +- 0.069

Eval split test
suff++ class all_L1  =  0.835 +- 0.076
suff++ class all_KL  =  0.836 +- 0.078
suff++_acc_int  =  0.554 +- 0.045
nec class all_L1  =  0.148 +- 0.073
nec class all_KL  =  0.129 +- 0.078
nec_acc_int  =  0.573 +- 0.051


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.478 +- 0.027
Faith. Armon (L1)= 		  =  0.274 +- 0.082
Faith. GMean (L1)= 	  =  0.356 +- 0.057
Faith. Aritm (KL)= 		  =  0.459 +- 0.046
Faith. Armon (KL)= 		  =  0.255 +- 0.110
Faith. GMean (KL)= 	  =  0.331 +- 0.085

Eval split val
Faith. Aritm (L1)= 		  =  0.488 +- 0.027
Faith. Armon (L1)= 		  =  0.278 +- 0.089
Faith. GMean (L1)= 	  =  0.363 +- 0.067
Faith. Aritm (KL)= 		  =  0.473 +- 0.046
Faith. Armon (KL)= 		  =  0.254 +- 0.111
Faith. GMean (KL)= 	  =  0.336 +- 0.095

Eval split test
Faith. Aritm (L1)= 		  =  0.491 +- 0.009
Faith. Armon (L1)= 		  =  0.240 +- 0.101
Faith. GMean (L1)= 	  =  0.335 +- 0.076
Faith. Aritm (KL)= 		  =  0.482 +- 0.011
Faith. Armon (KL)= 		  =  0.212 +- 0.111
Faith. GMean (KL)= 	  =  0.305 +- 0.097
Computed for split load_split = id



Completed in  0:04:48.955933  for CIGAvGIN GOODHIV/scaffold



DONE CIGA GOODHIV/scaffold

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Mar 23 00:00:03 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 03/23/2024 12:00:03 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/23/2024 12:00:06 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/23/2024 12:00:09 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/23/2024 12:00:12 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/23/2024 12:00:15 AM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 03/23/2024 12:00:15 AM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/23/2024 12:00:30 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:00:30 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:00:30 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:00:30 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:00:30 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:00:30 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:00:30 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:00:30 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:00:30 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:00:30 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:00:30 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:00:30 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:00:30 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 57...
[0m[1;37mINFO[0m: [1mCheckpoint 57: 
-----------------------------------
Train ROC-AUC: 0.9090
Train Loss: 0.0950
ID Validation ROC-AUC: 0.8455
ID Validation Loss: 0.1252
ID Test ROC-AUC: 0.8217
ID Test Loss: 0.1090
OOD Validation ROC-AUC: 0.7404
OOD Validation Loss: 0.1137
OOD Test ROC-AUC: 0.6988
OOD Test Loss: 0.0867

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 26...
[0m[1;37mINFO[0m: [1mCheckpoint 26: 
-----------------------------------
Train ROC-AUC: 0.8446
Train Loss: 0.1135
ID Validation ROC-AUC: 0.8042
ID Validation Loss: 0.1337
ID Test ROC-AUC: 0.8042
ID Test Loss: 0.1156
OOD Validation ROC-AUC: 0.7833
OOD Validation Loss: 0.1126
OOD Test ROC-AUC: 0.6912
OOD Test Loss: 0.0970

[0m[1;37mINFO[0m: [1mChartInfo 0.8217 0.6988 0.8042 0.6912 0.8042 0.7833[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 03/23/2024 12:00:31 AM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 03/23/2024 12:00:33 AM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 03/23/2024 12:00:34 AM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.544
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.516
SUFF++ for r=0.3 class 0.0 = 0.986 +- 0.016 (in-sample avg dev_std = 0.036)
SUFF++ for r=0.3 class 1.0 = 0.979 +- 0.016 (in-sample avg dev_std = 0.036)
SUFF++ for r=0.3 all KL = 0.993 +- 0.016 (in-sample avg dev_std = 0.036)
SUFF++ for r=0.3 all L1 = 0.982 +- 0.021 (in-sample avg dev_std = 0.036)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.612
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.6
SUFF++ for r=0.6 class 0.0 = 0.987 +- 0.029 (in-sample avg dev_std = 0.048)
SUFF++ for r=0.6 class 1.0 = 0.964 +- 0.029 (in-sample avg dev_std = 0.048)
SUFF++ for r=0.6 all KL = 0.989 +- 0.029 (in-sample avg dev_std = 0.048)
SUFF++ for r=0.6 all L1 = 0.976 +- 0.046 (in-sample avg dev_std = 0.048)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.674
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.672
SUFF++ for r=0.9 class 0.0 = 0.989 +- 0.024 (in-sample avg dev_std = 0.051)
SUFF++ for r=0.9 class 1.0 = 0.967 +- 0.024 (in-sample avg dev_std = 0.051)
SUFF++ for r=0.9 all KL = 0.993 +- 0.024 (in-sample avg dev_std = 0.051)
SUFF++ for r=0.9 all L1 = 0.978 +- 0.045 (in-sample avg dev_std = 0.051)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.635
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.533
SUFF++ for r=0.3 class 0.0 = 0.985 +- 0.012 (in-sample avg dev_std = 0.027)
SUFF++ for r=0.3 class 1.0 = 0.969 +- 0.012 (in-sample avg dev_std = 0.027)
SUFF++ for r=0.3 all KL = 0.993 +- 0.012 (in-sample avg dev_std = 0.027)
SUFF++ for r=0.3 all L1 = 0.977 +- 0.026 (in-sample avg dev_std = 0.027)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.608
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.575
SUFF++ for r=0.6 class 0.0 = 0.981 +- 0.012 (in-sample avg dev_std = 0.031)
SUFF++ for r=0.6 class 1.0 = 0.973 +- 0.012 (in-sample avg dev_std = 0.031)
SUFF++ for r=0.6 all KL = 0.992 +- 0.012 (in-sample avg dev_std = 0.031)
SUFF++ for r=0.6 all L1 = 0.977 +- 0.027 (in-sample avg dev_std = 0.031)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.65
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.622
SUFF++ for r=0.9 class 0.0 = 0.985 +- 0.009 (in-sample avg dev_std = 0.025)
SUFF++ for r=0.9 class 1.0 = 0.973 +- 0.009 (in-sample avg dev_std = 0.025)
SUFF++ for r=0.9 all KL = 0.995 +- 0.009 (in-sample avg dev_std = 0.025)
SUFF++ for r=0.9 all L1 = 0.979 +- 0.029 (in-sample avg dev_std = 0.025)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.565
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.552
SUFF++ for r=0.3 class 0.0 = 0.989 +- 0.013 (in-sample avg dev_std = 0.031)
SUFF++ for r=0.3 class 1.0 = 0.978 +- 0.013 (in-sample avg dev_std = 0.031)
SUFF++ for r=0.3 all KL = 0.994 +- 0.013 (in-sample avg dev_std = 0.031)
SUFF++ for r=0.3 all L1 = 0.983 +- 0.021 (in-sample avg dev_std = 0.031)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.57
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.532
SUFF++ for r=0.6 class 0.0 = 0.984 +- 0.020 (in-sample avg dev_std = 0.032)
SUFF++ for r=0.6 class 1.0 = 0.969 +- 0.020 (in-sample avg dev_std = 0.032)
SUFF++ for r=0.6 all KL = 0.992 +- 0.020 (in-sample avg dev_std = 0.032)
SUFF++ for r=0.6 all L1 = 0.977 +- 0.039 (in-sample avg dev_std = 0.032)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.626
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.594
SUFF++ for r=0.9 class 0.0 = 0.983 +- 0.014 (in-sample avg dev_std = 0.032)
SUFF++ for r=0.9 class 1.0 = 0.977 +- 0.014 (in-sample avg dev_std = 0.032)
SUFF++ for r=0.9 all KL = 0.995 +- 0.014 (in-sample avg dev_std = 0.032)
SUFF++ for r=0.9 all L1 = 0.98 +- 0.036 (in-sample avg dev_std = 0.032)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.546
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.534
NEC for r=0.3 class 0.0 = 0.011 +- 0.026 (in-sample avg dev_std = 0.029)
NEC for r=0.3 class 1.0 = 0.021 +- 0.026 (in-sample avg dev_std = 0.029)
NEC for r=0.3 all KL = 0.006 +- 0.026 (in-sample avg dev_std = 0.029)
NEC for r=0.3 all L1 = 0.016 +- 0.028 (in-sample avg dev_std = 0.029)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.612
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.608
NEC for r=0.6 class 0.0 = 0.009 +- 0.025 (in-sample avg dev_std = 0.035)
NEC for r=0.6 class 1.0 = 0.034 +- 0.025 (in-sample avg dev_std = 0.035)
NEC for r=0.6 all KL = 0.008 +- 0.025 (in-sample avg dev_std = 0.035)
NEC for r=0.6 all L1 = 0.022 +- 0.043 (in-sample avg dev_std = 0.035)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.674
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.664
NEC for r=0.9 class 0.0 = 0.01 +- 0.016 (in-sample avg dev_std = 0.044)
NEC for r=0.9 class 1.0 = 0.034 +- 0.016 (in-sample avg dev_std = 0.044)
NEC for r=0.9 all KL = 0.006 +- 0.016 (in-sample avg dev_std = 0.044)
NEC for r=0.9 all L1 = 0.022 +- 0.043 (in-sample avg dev_std = 0.044)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.682
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.687
NEC for r=1.0 class 0.0 = 0.011 +- 0.017 (in-sample avg dev_std = 0.039)
NEC for r=1.0 class 1.0 = 0.035 +- 0.017 (in-sample avg dev_std = 0.039)
NEC for r=1.0 all KL = 0.006 +- 0.017 (in-sample avg dev_std = 0.039)
NEC for r=1.0 all L1 = 0.023 +- 0.047 (in-sample avg dev_std = 0.039)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.634
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.526
NEC for r=0.3 class 0.0 = 0.013 +- 0.013 (in-sample avg dev_std = 0.025)
NEC for r=0.3 class 1.0 = 0.028 +- 0.013 (in-sample avg dev_std = 0.025)
NEC for r=0.3 all KL = 0.006 +- 0.013 (in-sample avg dev_std = 0.025)
NEC for r=0.3 all L1 = 0.02 +- 0.026 (in-sample avg dev_std = 0.025)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.607
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.552
NEC for r=0.6 class 0.0 = 0.015 +- 0.010 (in-sample avg dev_std = 0.027)
NEC for r=0.6 class 1.0 = 0.027 +- 0.010 (in-sample avg dev_std = 0.027)
NEC for r=0.6 all KL = 0.007 +- 0.010 (in-sample avg dev_std = 0.027)
NEC for r=0.6 all L1 = 0.021 +- 0.023 (in-sample avg dev_std = 0.027)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.65
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.634
NEC for r=0.9 class 0.0 = 0.018 +- 0.010 (in-sample avg dev_std = 0.025)
NEC for r=0.9 class 1.0 = 0.028 +- 0.010 (in-sample avg dev_std = 0.025)
NEC for r=0.9 all KL = 0.006 +- 0.010 (in-sample avg dev_std = 0.025)
NEC for r=0.9 all L1 = 0.023 +- 0.029 (in-sample avg dev_std = 0.025)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.647
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.64
NEC for r=1.0 class 0.0 = 0.017 +- 0.008 (in-sample avg dev_std = 0.027)
NEC for r=1.0 class 1.0 = 0.025 +- 0.008 (in-sample avg dev_std = 0.027)
NEC for r=1.0 all KL = 0.004 +- 0.008 (in-sample avg dev_std = 0.027)
NEC for r=1.0 all L1 = 0.021 +- 0.025 (in-sample avg dev_std = 0.027)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.565
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.548
NEC for r=0.3 class 0.0 = 0.009 +- 0.009 (in-sample avg dev_std = 0.017)
NEC for r=0.3 class 1.0 = 0.019 +- 0.009 (in-sample avg dev_std = 0.017)
NEC for r=0.3 all KL = 0.004 +- 0.009 (in-sample avg dev_std = 0.017)
NEC for r=0.3 all L1 = 0.014 +- 0.021 (in-sample avg dev_std = 0.017)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.57
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.586
NEC for r=0.6 class 0.0 = 0.013 +- 0.023 (in-sample avg dev_std = 0.027)
NEC for r=0.6 class 1.0 = 0.03 +- 0.023 (in-sample avg dev_std = 0.027)
NEC for r=0.6 all KL = 0.007 +- 0.023 (in-sample avg dev_std = 0.027)
NEC for r=0.6 all L1 = 0.021 +- 0.041 (in-sample avg dev_std = 0.027)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.625
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.624
NEC for r=0.9 class 0.0 = 0.018 +- 0.012 (in-sample avg dev_std = 0.031)
NEC for r=0.9 class 1.0 = 0.026 +- 0.012 (in-sample avg dev_std = 0.031)
NEC for r=0.9 all KL = 0.005 +- 0.012 (in-sample avg dev_std = 0.031)
NEC for r=0.9 all L1 = 0.022 +- 0.035 (in-sample avg dev_std = 0.031)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.607
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.601
NEC for r=1.0 class 0.0 = 0.018 +- 0.013 (in-sample avg dev_std = 0.030)
NEC for r=1.0 class 1.0 = 0.03 +- 0.013 (in-sample avg dev_std = 0.030)
NEC for r=1.0 all KL = 0.005 +- 0.013 (in-sample avg dev_std = 0.030)
NEC for r=1.0 all L1 = 0.024 +- 0.036 (in-sample avg dev_std = 0.030)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Mar 23 00:01:48 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 03/23/2024 12:01:48 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/23/2024 12:01:52 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/23/2024 12:01:55 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/23/2024 12:01:58 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/23/2024 12:02:00 AM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 03/23/2024 12:02:00 AM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/23/2024 12:02:15 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:02:15 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:02:15 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:02:15 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:02:15 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:02:15 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:02:15 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:02:15 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:02:15 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:02:15 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:02:15 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:02:15 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:02:15 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 87...
[0m[1;37mINFO[0m: [1mCheckpoint 87: 
-----------------------------------
Train ROC-AUC: 0.9193
Train Loss: 0.0894
ID Validation ROC-AUC: 0.8354
ID Validation Loss: 0.1257
ID Test ROC-AUC: 0.8084
ID Test Loss: 0.1109
OOD Validation ROC-AUC: 0.7601
OOD Validation Loss: 0.1176
OOD Test ROC-AUC: 0.7290
OOD Test Loss: 0.0872

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 35...
[0m[1;37mINFO[0m: [1mCheckpoint 35: 
-----------------------------------
Train ROC-AUC: 0.8677
Train Loss: 0.1098
ID Validation ROC-AUC: 0.8315
ID Validation Loss: 0.1337
ID Test ROC-AUC: 0.8039
ID Test Loss: 0.1138
OOD Validation ROC-AUC: 0.7858
OOD Validation Loss: 0.1065
OOD Test ROC-AUC: 0.7517
OOD Test Loss: 0.0875

[0m[1;37mINFO[0m: [1mChartInfo 0.8084 0.7290 0.8039 0.7517 0.8315 0.7858[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 03/23/2024 12:02:15 AM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 03/23/2024 12:02:17 AM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 03/23/2024 12:02:19 AM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.497
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.494
SUFF++ for r=0.3 class 0.0 = 0.976 +- 0.050 (in-sample avg dev_std = 0.077)
SUFF++ for r=0.3 class 1.0 = 0.97 +- 0.050 (in-sample avg dev_std = 0.077)
SUFF++ for r=0.3 all KL = 0.979 +- 0.050 (in-sample avg dev_std = 0.077)
SUFF++ for r=0.3 all L1 = 0.973 +- 0.047 (in-sample avg dev_std = 0.077)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.572
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.566
SUFF++ for r=0.6 class 0.0 = 0.974 +- 0.103 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.6 class 1.0 = 0.917 +- 0.103 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.6 all KL = 0.956 +- 0.103 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.6 all L1 = 0.946 +- 0.107 (in-sample avg dev_std = 0.133)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.605
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.608
SUFF++ for r=0.9 class 0.0 = 0.987 +- 0.068 (in-sample avg dev_std = 0.079)
SUFF++ for r=0.9 class 1.0 = 0.941 +- 0.068 (in-sample avg dev_std = 0.079)
SUFF++ for r=0.9 all KL = 0.978 +- 0.068 (in-sample avg dev_std = 0.079)
SUFF++ for r=0.9 all L1 = 0.964 +- 0.089 (in-sample avg dev_std = 0.079)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.551
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.548
SUFF++ for r=0.3 class 0.0 = 0.979 +- 0.063 (in-sample avg dev_std = 0.094)
SUFF++ for r=0.3 class 1.0 = 0.96 +- 0.063 (in-sample avg dev_std = 0.094)
SUFF++ for r=0.3 all KL = 0.973 +- 0.063 (in-sample avg dev_std = 0.094)
SUFF++ for r=0.3 all L1 = 0.97 +- 0.044 (in-sample avg dev_std = 0.094)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.525
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.557
SUFF++ for r=0.6 class 0.0 = 0.969 +- 0.096 (in-sample avg dev_std = 0.116)
SUFF++ for r=0.6 class 1.0 = 0.932 +- 0.096 (in-sample avg dev_std = 0.116)
SUFF++ for r=0.6 all KL = 0.952 +- 0.096 (in-sample avg dev_std = 0.116)
SUFF++ for r=0.6 all L1 = 0.951 +- 0.076 (in-sample avg dev_std = 0.116)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.569
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.572
SUFF++ for r=0.9 class 0.0 = 0.985 +- 0.070 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.9 class 1.0 = 0.959 +- 0.070 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.9 all KL = 0.977 +- 0.070 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.9 all L1 = 0.972 +- 0.056 (in-sample avg dev_std = 0.089)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.492
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.521
SUFF++ for r=0.3 class 0.0 = 0.978 +- 0.042 (in-sample avg dev_std = 0.061)
SUFF++ for r=0.3 class 1.0 = 0.974 +- 0.042 (in-sample avg dev_std = 0.061)
SUFF++ for r=0.3 all KL = 0.983 +- 0.042 (in-sample avg dev_std = 0.061)
SUFF++ for r=0.3 all L1 = 0.976 +- 0.033 (in-sample avg dev_std = 0.061)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.532
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.572
SUFF++ for r=0.6 class 0.0 = 0.975 +- 0.068 (in-sample avg dev_std = 0.110)
SUFF++ for r=0.6 class 1.0 = 0.939 +- 0.068 (in-sample avg dev_std = 0.110)
SUFF++ for r=0.6 all KL = 0.968 +- 0.068 (in-sample avg dev_std = 0.110)
SUFF++ for r=0.6 all L1 = 0.957 +- 0.072 (in-sample avg dev_std = 0.110)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.626
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.612
SUFF++ for r=0.9 class 0.0 = 0.988 +- 0.077 (in-sample avg dev_std = 0.101)
SUFF++ for r=0.9 class 1.0 = 0.943 +- 0.077 (in-sample avg dev_std = 0.101)
SUFF++ for r=0.9 all KL = 0.972 +- 0.077 (in-sample avg dev_std = 0.101)
SUFF++ for r=0.9 all L1 = 0.966 +- 0.074 (in-sample avg dev_std = 0.101)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.499
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.501
NEC for r=0.3 class 0.0 = 0.018 +- 0.066 (in-sample avg dev_std = 0.082)
NEC for r=0.3 class 1.0 = 0.036 +- 0.066 (in-sample avg dev_std = 0.082)
NEC for r=0.3 all KL = 0.019 +- 0.066 (in-sample avg dev_std = 0.082)
NEC for r=0.3 all L1 = 0.027 +- 0.065 (in-sample avg dev_std = 0.082)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.572
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.591
NEC for r=0.6 class 0.0 = 0.017 +- 0.077 (in-sample avg dev_std = 0.098)
NEC for r=0.6 class 1.0 = 0.071 +- 0.077 (in-sample avg dev_std = 0.098)
NEC for r=0.6 all KL = 0.029 +- 0.077 (in-sample avg dev_std = 0.098)
NEC for r=0.6 all L1 = 0.044 +- 0.094 (in-sample avg dev_std = 0.098)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.604
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.629
NEC for r=0.9 class 0.0 = 0.015 +- 0.068 (in-sample avg dev_std = 0.088)
NEC for r=0.9 class 1.0 = 0.06 +- 0.068 (in-sample avg dev_std = 0.088)
NEC for r=0.9 all KL = 0.021 +- 0.068 (in-sample avg dev_std = 0.088)
NEC for r=0.9 all L1 = 0.037 +- 0.082 (in-sample avg dev_std = 0.088)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.579
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.615
NEC for r=1.0 class 0.0 = 0.01 +- 0.037 (in-sample avg dev_std = 0.071)
NEC for r=1.0 class 1.0 = 0.044 +- 0.037 (in-sample avg dev_std = 0.071)
NEC for r=1.0 all KL = 0.013 +- 0.037 (in-sample avg dev_std = 0.071)
NEC for r=1.0 all L1 = 0.027 +- 0.062 (in-sample avg dev_std = 0.071)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.55
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.557
NEC for r=0.3 class 0.0 = 0.016 +- 0.052 (in-sample avg dev_std = 0.064)
NEC for r=0.3 class 1.0 = 0.026 +- 0.052 (in-sample avg dev_std = 0.064)
NEC for r=0.3 all KL = 0.014 +- 0.052 (in-sample avg dev_std = 0.064)
NEC for r=0.3 all L1 = 0.021 +- 0.037 (in-sample avg dev_std = 0.064)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.524
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.571
NEC for r=0.6 class 0.0 = 0.026 +- 0.081 (in-sample avg dev_std = 0.096)
NEC for r=0.6 class 1.0 = 0.062 +- 0.081 (in-sample avg dev_std = 0.096)
NEC for r=0.6 all KL = 0.036 +- 0.081 (in-sample avg dev_std = 0.096)
NEC for r=0.6 all L1 = 0.044 +- 0.075 (in-sample avg dev_std = 0.096)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.568
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.591
NEC for r=0.9 class 0.0 = 0.024 +- 0.091 (in-sample avg dev_std = 0.097)
NEC for r=0.9 class 1.0 = 0.054 +- 0.091 (in-sample avg dev_std = 0.097)
NEC for r=0.9 all KL = 0.034 +- 0.091 (in-sample avg dev_std = 0.097)
NEC for r=0.9 all L1 = 0.039 +- 0.078 (in-sample avg dev_std = 0.097)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.548
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.594
NEC for r=1.0 class 0.0 = 0.016 +- 0.073 (in-sample avg dev_std = 0.084)
NEC for r=1.0 class 1.0 = 0.041 +- 0.073 (in-sample avg dev_std = 0.084)
NEC for r=1.0 all KL = 0.023 +- 0.073 (in-sample avg dev_std = 0.084)
NEC for r=1.0 all L1 = 0.028 +- 0.065 (in-sample avg dev_std = 0.084)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.495
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.517
NEC for r=0.3 class 0.0 = 0.018 +- 0.085 (in-sample avg dev_std = 0.046)
NEC for r=0.3 class 1.0 = 0.035 +- 0.085 (in-sample avg dev_std = 0.046)
NEC for r=0.3 all KL = 0.021 +- 0.085 (in-sample avg dev_std = 0.046)
NEC for r=0.3 all L1 = 0.026 +- 0.070 (in-sample avg dev_std = 0.046)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.531
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.602
NEC for r=0.6 class 0.0 = 0.021 +- 0.067 (in-sample avg dev_std = 0.080)
NEC for r=0.6 class 1.0 = 0.055 +- 0.067 (in-sample avg dev_std = 0.080)
NEC for r=0.6 all KL = 0.024 +- 0.067 (in-sample avg dev_std = 0.080)
NEC for r=0.6 all L1 = 0.038 +- 0.069 (in-sample avg dev_std = 0.080)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.628
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.652
NEC for r=0.9 class 0.0 = 0.014 +- 0.081 (in-sample avg dev_std = 0.077)
NEC for r=0.9 class 1.0 = 0.059 +- 0.081 (in-sample avg dev_std = 0.077)
NEC for r=0.9 all KL = 0.026 +- 0.081 (in-sample avg dev_std = 0.077)
NEC for r=0.9 all L1 = 0.036 +- 0.077 (in-sample avg dev_std = 0.077)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.605
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.637
NEC for r=1.0 class 0.0 = 0.011 +- 0.051 (in-sample avg dev_std = 0.067)
NEC for r=1.0 class 1.0 = 0.046 +- 0.051 (in-sample avg dev_std = 0.067)
NEC for r=1.0 all KL = 0.016 +- 0.051 (in-sample avg dev_std = 0.067)
NEC for r=1.0 all L1 = 0.028 +- 0.064 (in-sample avg dev_std = 0.067)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Mar 23 00:03:33 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 03/23/2024 12:03:33 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/23/2024 12:03:36 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/23/2024 12:03:39 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/23/2024 12:03:43 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/23/2024 12:03:45 AM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 03/23/2024 12:03:45 AM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/23/2024 12:04:00 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:04:00 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:04:00 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:04:00 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:04:00 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:04:00 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:04:00 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:04:00 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:04:00 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:04:00 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:04:00 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:04:00 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:04:00 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 105...
[0m[1;37mINFO[0m: [1mCheckpoint 105: 
-----------------------------------
Train ROC-AUC: 0.9408
Train Loss: 0.0845
ID Validation ROC-AUC: 0.8353
ID Validation Loss: 0.1363
ID Test ROC-AUC: 0.8180
ID Test Loss: 0.1216
OOD Validation ROC-AUC: 0.7710
OOD Validation Loss: 0.1283
OOD Test ROC-AUC: 0.7279
OOD Test Loss: 0.0901

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 107...
[0m[1;37mINFO[0m: [1mCheckpoint 107: 
-----------------------------------
Train ROC-AUC: 0.9312
Train Loss: 0.0842
ID Validation ROC-AUC: 0.8199
ID Validation Loss: 0.1342
ID Test ROC-AUC: 0.7980
ID Test Loss: 0.1163
OOD Validation ROC-AUC: 0.7737
OOD Validation Loss: 0.1243
OOD Test ROC-AUC: 0.7203
OOD Test Loss: 0.0949

[0m[1;37mINFO[0m: [1mChartInfo 0.8180 0.7279 0.7980 0.7203 0.8199 0.7737[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 03/23/2024 12:04:00 AM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 03/23/2024 12:04:02 AM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 03/23/2024 12:04:03 AM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.659
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.606
SUFF++ for r=0.3 class 0.0 = 0.88 +- 0.142 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.3 class 1.0 = 0.804 +- 0.142 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.3 all KL = 0.861 +- 0.142 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.3 all L1 = 0.842 +- 0.138 (in-sample avg dev_std = 0.245)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.648
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.593
SUFF++ for r=0.6 class 0.0 = 0.912 +- 0.133 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.6 class 1.0 = 0.829 +- 0.133 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.6 all KL = 0.907 +- 0.133 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.6 all L1 = 0.87 +- 0.156 (in-sample avg dev_std = 0.203)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.655
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.62
SUFF++ for r=0.9 class 0.0 = 0.97 +- 0.061 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 class 1.0 = 0.931 +- 0.061 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 all KL = 0.974 +- 0.061 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 all L1 = 0.951 +- 0.094 (in-sample avg dev_std = 0.107)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.547
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.529
SUFF++ for r=0.3 class 0.0 = 0.851 +- 0.120 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.3 class 1.0 = 0.814 +- 0.120 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.3 all KL = 0.864 +- 0.120 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.3 all L1 = 0.833 +- 0.121 (in-sample avg dev_std = 0.222)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.513
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.492
SUFF++ for r=0.6 class 0.0 = 0.856 +- 0.124 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.6 class 1.0 = 0.836 +- 0.124 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.6 all KL = 0.89 +- 0.124 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.6 all L1 = 0.846 +- 0.137 (in-sample avg dev_std = 0.203)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.517
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 251
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.516
SUFF++ for r=0.9 class 0.0 = 0.944 +- 0.083 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 class 1.0 = 0.926 +- 0.083 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 all KL = 0.967 +- 0.083 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 all L1 = 0.935 +- 0.100 (in-sample avg dev_std = 0.107)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.578
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.552
SUFF++ for r=0.3 class 0.0 = 0.931 +- 0.108 (in-sample avg dev_std = 0.200)
SUFF++ for r=0.3 class 1.0 = 0.871 +- 0.108 (in-sample avg dev_std = 0.200)
SUFF++ for r=0.3 all KL = 0.905 +- 0.108 (in-sample avg dev_std = 0.200)
SUFF++ for r=0.3 all L1 = 0.901 +- 0.101 (in-sample avg dev_std = 0.200)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.638
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.617
SUFF++ for r=0.6 class 0.0 = 0.939 +- 0.122 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.6 class 1.0 = 0.85 +- 0.122 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.6 all KL = 0.907 +- 0.122 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.6 all L1 = 0.894 +- 0.124 (in-sample avg dev_std = 0.194)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.659
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.638
SUFF++ for r=0.9 class 0.0 = 0.972 +- 0.068 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.9 class 1.0 = 0.922 +- 0.068 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.9 all KL = 0.97 +- 0.068 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.9 all L1 = 0.947 +- 0.099 (in-sample avg dev_std = 0.108)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.661
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.643
NEC for r=0.3 class 0.0 = 0.09 +- 0.131 (in-sample avg dev_std = 0.182)
NEC for r=0.3 class 1.0 = 0.159 +- 0.131 (in-sample avg dev_std = 0.182)
NEC for r=0.3 all KL = 0.089 +- 0.131 (in-sample avg dev_std = 0.182)
NEC for r=0.3 all L1 = 0.125 +- 0.137 (in-sample avg dev_std = 0.182)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.648
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.635
NEC for r=0.6 class 0.0 = 0.076 +- 0.128 (in-sample avg dev_std = 0.187)
NEC for r=0.6 class 1.0 = 0.169 +- 0.128 (in-sample avg dev_std = 0.187)
NEC for r=0.6 all KL = 0.081 +- 0.128 (in-sample avg dev_std = 0.187)
NEC for r=0.6 all L1 = 0.122 +- 0.152 (in-sample avg dev_std = 0.187)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.655
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.625
NEC for r=0.9 class 0.0 = 0.036 +- 0.079 (in-sample avg dev_std = 0.115)
NEC for r=0.9 class 1.0 = 0.076 +- 0.079 (in-sample avg dev_std = 0.115)
NEC for r=0.9 all KL = 0.033 +- 0.079 (in-sample avg dev_std = 0.115)
NEC for r=0.9 all L1 = 0.056 +- 0.097 (in-sample avg dev_std = 0.115)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.663
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.635
NEC for r=1.0 class 0.0 = 0.022 +- 0.060 (in-sample avg dev_std = 0.095)
NEC for r=1.0 class 1.0 = 0.056 +- 0.060 (in-sample avg dev_std = 0.095)
NEC for r=1.0 all KL = 0.02 +- 0.060 (in-sample avg dev_std = 0.095)
NEC for r=1.0 all L1 = 0.039 +- 0.081 (in-sample avg dev_std = 0.095)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.544
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.611
NEC for r=0.3 class 0.0 = 0.1 +- 0.144 (in-sample avg dev_std = 0.193)
NEC for r=0.3 class 1.0 = 0.203 +- 0.144 (in-sample avg dev_std = 0.193)
NEC for r=0.3 all KL = 0.113 +- 0.144 (in-sample avg dev_std = 0.193)
NEC for r=0.3 all L1 = 0.152 +- 0.145 (in-sample avg dev_std = 0.193)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.512
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.527
NEC for r=0.6 class 0.0 = 0.117 +- 0.126 (in-sample avg dev_std = 0.171)
NEC for r=0.6 class 1.0 = 0.158 +- 0.126 (in-sample avg dev_std = 0.171)
NEC for r=0.6 all KL = 0.089 +- 0.126 (in-sample avg dev_std = 0.171)
NEC for r=0.6 all L1 = 0.138 +- 0.136 (in-sample avg dev_std = 0.171)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.519
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.523
NEC for r=0.9 class 0.0 = 0.068 +- 0.093 (in-sample avg dev_std = 0.131)
NEC for r=0.9 class 1.0 = 0.082 +- 0.093 (in-sample avg dev_std = 0.131)
NEC for r=0.9 all KL = 0.044 +- 0.093 (in-sample avg dev_std = 0.131)
NEC for r=0.9 all L1 = 0.075 +- 0.096 (in-sample avg dev_std = 0.131)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.52
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.524
NEC for r=1.0 class 0.0 = 0.055 +- 0.060 (in-sample avg dev_std = 0.094)
NEC for r=1.0 class 1.0 = 0.061 +- 0.060 (in-sample avg dev_std = 0.094)
NEC for r=1.0 all KL = 0.029 +- 0.060 (in-sample avg dev_std = 0.094)
NEC for r=1.0 all L1 = 0.058 +- 0.081 (in-sample avg dev_std = 0.094)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.579
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.612
NEC for r=0.3 class 0.0 = 0.039 +- 0.117 (in-sample avg dev_std = 0.121)
NEC for r=0.3 class 1.0 = 0.101 +- 0.117 (in-sample avg dev_std = 0.121)
NEC for r=0.3 all KL = 0.051 +- 0.117 (in-sample avg dev_std = 0.121)
NEC for r=0.3 all L1 = 0.07 +- 0.114 (in-sample avg dev_std = 0.121)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.636
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.657
NEC for r=0.6 class 0.0 = 0.028 +- 0.099 (in-sample avg dev_std = 0.104)
NEC for r=0.6 class 1.0 = 0.116 +- 0.099 (in-sample avg dev_std = 0.104)
NEC for r=0.6 all KL = 0.046 +- 0.099 (in-sample avg dev_std = 0.104)
NEC for r=0.6 all L1 = 0.072 +- 0.119 (in-sample avg dev_std = 0.104)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.658
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.674
NEC for r=0.9 class 0.0 = 0.025 +- 0.088 (in-sample avg dev_std = 0.113)
NEC for r=0.9 class 1.0 = 0.081 +- 0.088 (in-sample avg dev_std = 0.113)
NEC for r=0.9 all KL = 0.032 +- 0.088 (in-sample avg dev_std = 0.113)
NEC for r=0.9 all L1 = 0.053 +- 0.095 (in-sample avg dev_std = 0.113)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.652
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.665
NEC for r=1.0 class 0.0 = 0.018 +- 0.044 (in-sample avg dev_std = 0.082)
NEC for r=1.0 class 1.0 = 0.058 +- 0.044 (in-sample avg dev_std = 0.082)
NEC for r=1.0 all KL = 0.019 +- 0.044 (in-sample avg dev_std = 0.082)
NEC for r=1.0 all L1 = 0.038 +- 0.069 (in-sample avg dev_std = 0.082)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Mar 23 00:05:20 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 03/23/2024 12:05:20 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/23/2024 12:05:24 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/23/2024 12:05:27 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/23/2024 12:05:30 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/23/2024 12:05:33 AM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 03/23/2024 12:05:33 AM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/23/2024 12:05:47 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:05:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:05:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:05:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:05:47 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:05:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:05:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:05:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:05:47 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:05:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:05:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:05:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:05:47 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 143...
[0m[1;37mINFO[0m: [1mCheckpoint 143: 
-----------------------------------
Train ROC-AUC: 0.9672
Train Loss: 0.0711
ID Validation ROC-AUC: 0.8273
ID Validation Loss: 0.1308
ID Test ROC-AUC: 0.8111
ID Test Loss: 0.1127
OOD Validation ROC-AUC: 0.7208
OOD Validation Loss: 0.1246
OOD Test ROC-AUC: 0.6528
OOD Test Loss: 0.0969

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 38...
[0m[1;37mINFO[0m: [1mCheckpoint 38: 
-----------------------------------
Train ROC-AUC: 0.8696
Train Loss: 0.1264
ID Validation ROC-AUC: 0.8184
ID Validation Loss: 0.1532
ID Test ROC-AUC: 0.8196
ID Test Loss: 0.1278
OOD Validation ROC-AUC: 0.7775
OOD Validation Loss: 0.1197
OOD Test ROC-AUC: 0.7122
OOD Test Loss: 0.1159

[0m[1;37mINFO[0m: [1mChartInfo 0.8111 0.6528 0.8196 0.7122 0.8184 0.7775[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 03/23/2024 12:05:48 AM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 03/23/2024 12:05:49 AM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 03/23/2024 12:05:51 AM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.708
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.639
SUFF++ for r=0.3 class 0.0 = 0.831 +- 0.205 (in-sample avg dev_std = 0.349)
SUFF++ for r=0.3 class 1.0 = 0.73 +- 0.205 (in-sample avg dev_std = 0.349)
SUFF++ for r=0.3 all KL = 0.769 +- 0.205 (in-sample avg dev_std = 0.349)
SUFF++ for r=0.3 all L1 = 0.78 +- 0.174 (in-sample avg dev_std = 0.349)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.726
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.665
SUFF++ for r=0.6 class 0.0 = 0.855 +- 0.173 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.6 class 1.0 = 0.765 +- 0.173 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.6 all KL = 0.852 +- 0.173 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.6 all L1 = 0.81 +- 0.164 (in-sample avg dev_std = 0.274)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.725
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.715
SUFF++ for r=0.9 class 0.0 = 0.926 +- 0.084 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.9 class 1.0 = 0.86 +- 0.084 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.9 all KL = 0.951 +- 0.084 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.9 all L1 = 0.893 +- 0.125 (in-sample avg dev_std = 0.158)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.77
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.702
SUFF++ for r=0.3 class 0.0 = 0.801 +- 0.186 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 class 1.0 = 0.682 +- 0.186 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 all KL = 0.738 +- 0.186 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 all L1 = 0.741 +- 0.149 (in-sample avg dev_std = 0.372)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.767
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.735
SUFF++ for r=0.6 class 0.0 = 0.818 +- 0.138 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.6 class 1.0 = 0.742 +- 0.138 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.6 all KL = 0.855 +- 0.138 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.6 all L1 = 0.78 +- 0.137 (in-sample avg dev_std = 0.273)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.767
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.734
SUFF++ for r=0.9 class 0.0 = 0.903 +- 0.079 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.9 class 1.0 = 0.833 +- 0.079 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.9 all KL = 0.944 +- 0.079 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.9 all L1 = 0.868 +- 0.113 (in-sample avg dev_std = 0.162)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.596
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.582
SUFF++ for r=0.3 class 0.0 = 0.921 +- 0.133 (in-sample avg dev_std = 0.224)
SUFF++ for r=0.3 class 1.0 = 0.88 +- 0.133 (in-sample avg dev_std = 0.224)
SUFF++ for r=0.3 all KL = 0.887 +- 0.133 (in-sample avg dev_std = 0.224)
SUFF++ for r=0.3 all L1 = 0.901 +- 0.117 (in-sample avg dev_std = 0.224)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.567
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.583
SUFF++ for r=0.6 class 0.0 = 0.891 +- 0.172 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.6 class 1.0 = 0.85 +- 0.172 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.6 all KL = 0.86 +- 0.172 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.6 all L1 = 0.871 +- 0.128 (in-sample avg dev_std = 0.250)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.62
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.612
SUFF++ for r=0.9 class 0.0 = 0.948 +- 0.082 (in-sample avg dev_std = 0.142)
SUFF++ for r=0.9 class 1.0 = 0.912 +- 0.082 (in-sample avg dev_std = 0.142)
SUFF++ for r=0.9 all KL = 0.955 +- 0.082 (in-sample avg dev_std = 0.142)
SUFF++ for r=0.9 all L1 = 0.93 +- 0.096 (in-sample avg dev_std = 0.142)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.707
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.671
NEC for r=0.3 class 0.0 = 0.099 +- 0.171 (in-sample avg dev_std = 0.211)
NEC for r=0.3 class 1.0 = 0.231 +- 0.171 (in-sample avg dev_std = 0.211)
NEC for r=0.3 all KL = 0.12 +- 0.171 (in-sample avg dev_std = 0.211)
NEC for r=0.3 all L1 = 0.165 +- 0.195 (in-sample avg dev_std = 0.211)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.726
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.678
NEC for r=0.6 class 0.0 = 0.122 +- 0.143 (in-sample avg dev_std = 0.229)
NEC for r=0.6 class 1.0 = 0.219 +- 0.143 (in-sample avg dev_std = 0.229)
NEC for r=0.6 all KL = 0.106 +- 0.143 (in-sample avg dev_std = 0.229)
NEC for r=0.6 all L1 = 0.17 +- 0.174 (in-sample avg dev_std = 0.229)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.725
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.695
NEC for r=0.9 class 0.0 = 0.089 +- 0.108 (in-sample avg dev_std = 0.178)
NEC for r=0.9 class 1.0 = 0.166 +- 0.108 (in-sample avg dev_std = 0.178)
NEC for r=0.9 all KL = 0.067 +- 0.108 (in-sample avg dev_std = 0.178)
NEC for r=0.9 all L1 = 0.127 +- 0.146 (in-sample avg dev_std = 0.178)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.726
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.697
NEC for r=1.0 class 0.0 = 0.068 +- 0.091 (in-sample avg dev_std = 0.152)
NEC for r=1.0 class 1.0 = 0.147 +- 0.091 (in-sample avg dev_std = 0.152)
NEC for r=1.0 all KL = 0.052 +- 0.091 (in-sample avg dev_std = 0.152)
NEC for r=1.0 all L1 = 0.107 +- 0.133 (in-sample avg dev_std = 0.152)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.77
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.726
NEC for r=0.3 class 0.0 = 0.116 +- 0.168 (in-sample avg dev_std = 0.223)
NEC for r=0.3 class 1.0 = 0.258 +- 0.168 (in-sample avg dev_std = 0.223)
NEC for r=0.3 all KL = 0.126 +- 0.168 (in-sample avg dev_std = 0.223)
NEC for r=0.3 all L1 = 0.187 +- 0.196 (in-sample avg dev_std = 0.223)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.767
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.73
NEC for r=0.6 class 0.0 = 0.152 +- 0.123 (in-sample avg dev_std = 0.235)
NEC for r=0.6 class 1.0 = 0.262 +- 0.123 (in-sample avg dev_std = 0.235)
NEC for r=0.6 all KL = 0.116 +- 0.123 (in-sample avg dev_std = 0.235)
NEC for r=0.6 all L1 = 0.207 +- 0.160 (in-sample avg dev_std = 0.235)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.768
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.727
NEC for r=0.9 class 0.0 = 0.107 +- 0.077 (in-sample avg dev_std = 0.187)
NEC for r=0.9 class 1.0 = 0.201 +- 0.077 (in-sample avg dev_std = 0.187)
NEC for r=0.9 all KL = 0.065 +- 0.077 (in-sample avg dev_std = 0.187)
NEC for r=0.9 all L1 = 0.154 +- 0.126 (in-sample avg dev_std = 0.187)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.768
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.732
NEC for r=1.0 class 0.0 = 0.092 +- 0.087 (in-sample avg dev_std = 0.176)
NEC for r=1.0 class 1.0 = 0.192 +- 0.087 (in-sample avg dev_std = 0.176)
NEC for r=1.0 all KL = 0.063 +- 0.087 (in-sample avg dev_std = 0.176)
NEC for r=1.0 all L1 = 0.142 +- 0.128 (in-sample avg dev_std = 0.176)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.597
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.583
NEC for r=0.3 class 0.0 = 0.068 +- 0.126 (in-sample avg dev_std = 0.132)
NEC for r=0.3 class 1.0 = 0.085 +- 0.126 (in-sample avg dev_std = 0.132)
NEC for r=0.3 all KL = 0.056 +- 0.126 (in-sample avg dev_std = 0.132)
NEC for r=0.3 all L1 = 0.077 +- 0.147 (in-sample avg dev_std = 0.132)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.567
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.592
NEC for r=0.6 class 0.0 = 0.073 +- 0.124 (in-sample avg dev_std = 0.144)
NEC for r=0.6 class 1.0 = 0.091 +- 0.124 (in-sample avg dev_std = 0.144)
NEC for r=0.6 all KL = 0.062 +- 0.124 (in-sample avg dev_std = 0.144)
NEC for r=0.6 all L1 = 0.082 +- 0.121 (in-sample avg dev_std = 0.144)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.621
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.595
NEC for r=0.9 class 0.0 = 0.052 +- 0.081 (in-sample avg dev_std = 0.098)
NEC for r=0.9 class 1.0 = 0.073 +- 0.081 (in-sample avg dev_std = 0.098)
NEC for r=0.9 all KL = 0.036 +- 0.081 (in-sample avg dev_std = 0.098)
NEC for r=0.9 all L1 = 0.062 +- 0.099 (in-sample avg dev_std = 0.098)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.63
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.61
NEC for r=1.0 class 0.0 = 0.044 +- 0.073 (in-sample avg dev_std = 0.101)
NEC for r=1.0 class 1.0 = 0.074 +- 0.073 (in-sample avg dev_std = 0.101)
NEC for r=1.0 all KL = 0.032 +- 0.073 (in-sample avg dev_std = 0.101)
NEC for r=1.0 all L1 = 0.059 +- 0.095 (in-sample avg dev_std = 0.101)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Mar 23 00:07:06 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 03/23/2024 12:07:06 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/23/2024 12:07:09 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/23/2024 12:07:12 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/23/2024 12:07:15 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/23/2024 12:07:18 AM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 03/23/2024 12:07:18 AM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/23/2024 12:07:33 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:07:33 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:07:33 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:07:33 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:07:33 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:07:33 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:07:33 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:07:33 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:07:33 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:07:33 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:07:33 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:07:33 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:07:33 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 61...
[0m[1;37mINFO[0m: [1mCheckpoint 61: 
-----------------------------------
Train ROC-AUC: 0.9084
Train Loss: 0.0957
ID Validation ROC-AUC: 0.8316
ID Validation Loss: 0.1288
ID Test ROC-AUC: 0.8079
ID Test Loss: 0.1132
OOD Validation ROC-AUC: 0.7393
OOD Validation Loss: 0.1117
OOD Test ROC-AUC: 0.7327
OOD Test Loss: 0.0860

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 130...
[0m[1;37mINFO[0m: [1mCheckpoint 130: 
-----------------------------------
Train ROC-AUC: 0.9676
Train Loss: 0.0823
ID Validation ROC-AUC: 0.8098
ID Validation Loss: 0.1356
ID Test ROC-AUC: 0.8105
ID Test Loss: 0.1148
OOD Validation ROC-AUC: 0.7817
OOD Validation Loss: 0.1135
OOD Test ROC-AUC: 0.7377
OOD Test Loss: 0.0885

[0m[1;37mINFO[0m: [1mChartInfo 0.8079 0.7327 0.8105 0.7377 0.8098 0.7817[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 03/23/2024 12:07:33 AM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 03/23/2024 12:07:35 AM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 03/23/2024 12:07:36 AM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.731
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.659
SUFF++ for r=0.3 class 0.0 = 0.854 +- 0.125 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 class 1.0 = 0.754 +- 0.125 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 all KL = 0.85 +- 0.125 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 all L1 = 0.804 +- 0.131 (in-sample avg dev_std = 0.279)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.778
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.721
SUFF++ for r=0.6 class 0.0 = 0.798 +- 0.167 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.6 class 1.0 = 0.746 +- 0.167 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.6 all KL = 0.823 +- 0.167 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.6 all L1 = 0.772 +- 0.145 (in-sample avg dev_std = 0.336)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.812
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.77
SUFF++ for r=0.9 class 0.0 = 0.868 +- 0.122 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.9 class 1.0 = 0.852 +- 0.122 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.9 all KL = 0.914 +- 0.122 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.9 all L1 = 0.86 +- 0.124 (in-sample avg dev_std = 0.220)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.635
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.64
SUFF++ for r=0.3 class 0.0 = 0.797 +- 0.116 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.3 class 1.0 = 0.745 +- 0.116 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.3 all KL = 0.842 +- 0.116 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.3 all L1 = 0.771 +- 0.118 (in-sample avg dev_std = 0.280)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.689
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.67
SUFF++ for r=0.6 class 0.0 = 0.767 +- 0.139 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.6 class 1.0 = 0.744 +- 0.139 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.6 all KL = 0.843 +- 0.139 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.6 all L1 = 0.755 +- 0.128 (in-sample avg dev_std = 0.320)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.724
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 251
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.706
SUFF++ for r=0.9 class 0.0 = 0.862 +- 0.090 (in-sample avg dev_std = 0.212)
SUFF++ for r=0.9 class 1.0 = 0.856 +- 0.090 (in-sample avg dev_std = 0.212)
SUFF++ for r=0.9 all KL = 0.933 +- 0.090 (in-sample avg dev_std = 0.212)
SUFF++ for r=0.9 all L1 = 0.859 +- 0.116 (in-sample avg dev_std = 0.212)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.601
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.588
SUFF++ for r=0.3 class 0.0 = 0.861 +- 0.116 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.3 class 1.0 = 0.821 +- 0.116 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.3 all KL = 0.882 +- 0.116 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.3 all L1 = 0.841 +- 0.122 (in-sample avg dev_std = 0.226)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.632
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.615
SUFF++ for r=0.6 class 0.0 = 0.859 +- 0.105 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.6 class 1.0 = 0.816 +- 0.105 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.6 all KL = 0.905 +- 0.105 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.6 all L1 = 0.838 +- 0.127 (in-sample avg dev_std = 0.223)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.656
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.643
SUFF++ for r=0.9 class 0.0 = 0.905 +- 0.059 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.9 class 1.0 = 0.88 +- 0.059 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.9 all KL = 0.957 +- 0.059 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.9 all L1 = 0.893 +- 0.094 (in-sample avg dev_std = 0.160)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.731
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.731
NEC for r=0.3 class 0.0 = 0.093 +- 0.142 (in-sample avg dev_std = 0.184)
NEC for r=0.3 class 1.0 = 0.23 +- 0.142 (in-sample avg dev_std = 0.184)
NEC for r=0.3 all KL = 0.1 +- 0.142 (in-sample avg dev_std = 0.184)
NEC for r=0.3 all L1 = 0.162 +- 0.164 (in-sample avg dev_std = 0.184)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.778
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.771
NEC for r=0.6 class 0.0 = 0.106 +- 0.134 (in-sample avg dev_std = 0.204)
NEC for r=0.6 class 1.0 = 0.213 +- 0.134 (in-sample avg dev_std = 0.204)
NEC for r=0.6 all KL = 0.09 +- 0.134 (in-sample avg dev_std = 0.204)
NEC for r=0.6 all L1 = 0.16 +- 0.155 (in-sample avg dev_std = 0.204)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.812
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.779
NEC for r=0.9 class 0.0 = 0.116 +- 0.126 (in-sample avg dev_std = 0.201)
NEC for r=0.9 class 1.0 = 0.164 +- 0.126 (in-sample avg dev_std = 0.201)
NEC for r=0.9 all KL = 0.079 +- 0.126 (in-sample avg dev_std = 0.201)
NEC for r=0.9 all L1 = 0.14 +- 0.142 (in-sample avg dev_std = 0.201)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.812
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.789
NEC for r=1.0 class 0.0 = 0.098 +- 0.115 (in-sample avg dev_std = 0.185)
NEC for r=1.0 class 1.0 = 0.154 +- 0.115 (in-sample avg dev_std = 0.185)
NEC for r=1.0 all KL = 0.068 +- 0.115 (in-sample avg dev_std = 0.185)
NEC for r=1.0 all L1 = 0.126 +- 0.140 (in-sample avg dev_std = 0.185)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.635
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.696
NEC for r=0.3 class 0.0 = 0.129 +- 0.133 (in-sample avg dev_std = 0.195)
NEC for r=0.3 class 1.0 = 0.244 +- 0.133 (in-sample avg dev_std = 0.195)
NEC for r=0.3 all KL = 0.105 +- 0.133 (in-sample avg dev_std = 0.195)
NEC for r=0.3 all L1 = 0.187 +- 0.158 (in-sample avg dev_std = 0.195)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.689
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.704
NEC for r=0.6 class 0.0 = 0.143 +- 0.093 (in-sample avg dev_std = 0.188)
NEC for r=0.6 class 1.0 = 0.214 +- 0.093 (in-sample avg dev_std = 0.188)
NEC for r=0.6 all KL = 0.079 +- 0.093 (in-sample avg dev_std = 0.188)
NEC for r=0.6 all L1 = 0.178 +- 0.130 (in-sample avg dev_std = 0.188)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.726
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.723
NEC for r=0.9 class 0.0 = 0.137 +- 0.093 (in-sample avg dev_std = 0.175)
NEC for r=0.9 class 1.0 = 0.16 +- 0.093 (in-sample avg dev_std = 0.175)
NEC for r=0.9 all KL = 0.065 +- 0.093 (in-sample avg dev_std = 0.175)
NEC for r=0.9 all L1 = 0.148 +- 0.126 (in-sample avg dev_std = 0.175)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.745
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.735
NEC for r=1.0 class 0.0 = 0.112 +- 0.086 (in-sample avg dev_std = 0.167)
NEC for r=1.0 class 1.0 = 0.15 +- 0.086 (in-sample avg dev_std = 0.167)
NEC for r=1.0 all KL = 0.056 +- 0.086 (in-sample avg dev_std = 0.167)
NEC for r=1.0 all L1 = 0.131 +- 0.124 (in-sample avg dev_std = 0.167)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.602
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.6
NEC for r=0.3 class 0.0 = 0.103 +- 0.116 (in-sample avg dev_std = 0.166)
NEC for r=0.3 class 1.0 = 0.16 +- 0.116 (in-sample avg dev_std = 0.166)
NEC for r=0.3 all KL = 0.08 +- 0.116 (in-sample avg dev_std = 0.166)
NEC for r=0.3 all L1 = 0.132 +- 0.138 (in-sample avg dev_std = 0.166)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.632
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.633
NEC for r=0.6 class 0.0 = 0.097 +- 0.081 (in-sample avg dev_std = 0.154)
NEC for r=0.6 class 1.0 = 0.156 +- 0.081 (in-sample avg dev_std = 0.154)
NEC for r=0.6 all KL = 0.055 +- 0.081 (in-sample avg dev_std = 0.154)
NEC for r=0.6 all L1 = 0.126 +- 0.123 (in-sample avg dev_std = 0.154)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.656
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.636
NEC for r=0.9 class 0.0 = 0.105 +- 0.081 (in-sample avg dev_std = 0.175)
NEC for r=0.9 class 1.0 = 0.138 +- 0.081 (in-sample avg dev_std = 0.175)
NEC for r=0.9 all KL = 0.053 +- 0.081 (in-sample avg dev_std = 0.175)
NEC for r=0.9 all L1 = 0.122 +- 0.113 (in-sample avg dev_std = 0.175)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.67
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.635
NEC for r=1.0 class 0.0 = 0.092 +- 0.090 (in-sample avg dev_std = 0.177)
NEC for r=1.0 class 1.0 = 0.12 +- 0.090 (in-sample avg dev_std = 0.177)
NEC for r=1.0 all KL = 0.048 +- 0.090 (in-sample avg dev_std = 0.177)
NEC for r=1.0 all L1 = 0.106 +- 0.111 (in-sample avg dev_std = 0.177)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.993, 0.989, 0.993, 1.0], 'all_L1': [0.982, 0.976, 0.978, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.979, 0.956, 0.978, 1.0], 'all_L1': [0.973, 0.946, 0.964, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.861, 0.907, 0.974, 1.0], 'all_L1': [0.842, 0.87, 0.951, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.769, 0.852, 0.951, 1.0], 'all_L1': [0.78, 0.81, 0.893, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.85, 0.823, 0.914, 1.0], 'all_L1': [0.804, 0.772, 0.86, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.006, 0.008, 0.006, 0.006], 'all_L1': [0.016, 0.022, 0.022, 0.023]}), defaultdict(<class 'list'>, {'all_KL': [0.019, 0.029, 0.021, 0.013], 'all_L1': [0.027, 0.044, 0.037, 0.027]}), defaultdict(<class 'list'>, {'all_KL': [0.089, 0.081, 0.033, 0.02], 'all_L1': [0.125, 0.122, 0.056, 0.039]}), defaultdict(<class 'list'>, {'all_KL': [0.12, 0.106, 0.067, 0.052], 'all_L1': [0.165, 0.17, 0.127, 0.107]}), defaultdict(<class 'list'>, {'all_KL': [0.1, 0.09, 0.079, 0.068], 'all_L1': [0.162, 0.16, 0.14, 0.126]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.993, 0.992, 0.995, 1.0], 'all_L1': [0.977, 0.977, 0.979, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.973, 0.952, 0.977, 1.0], 'all_L1': [0.97, 0.951, 0.972, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.864, 0.89, 0.967, 1.0], 'all_L1': [0.833, 0.846, 0.935, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.738, 0.855, 0.944, 1.0], 'all_L1': [0.741, 0.78, 0.868, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.842, 0.843, 0.933, 1.0], 'all_L1': [0.771, 0.755, 0.859, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.006, 0.007, 0.006, 0.004], 'all_L1': [0.02, 0.021, 0.023, 0.021]}), defaultdict(<class 'list'>, {'all_KL': [0.014, 0.036, 0.034, 0.023], 'all_L1': [0.021, 0.044, 0.039, 0.028]}), defaultdict(<class 'list'>, {'all_KL': [0.113, 0.089, 0.044, 0.029], 'all_L1': [0.152, 0.138, 0.075, 0.058]}), defaultdict(<class 'list'>, {'all_KL': [0.126, 0.116, 0.065, 0.063], 'all_L1': [0.187, 0.207, 0.154, 0.142]}), defaultdict(<class 'list'>, {'all_KL': [0.105, 0.079, 0.065, 0.056], 'all_L1': [0.187, 0.178, 0.148, 0.131]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.994, 0.992, 0.995, 1.0], 'all_L1': [0.983, 0.977, 0.98, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.983, 0.968, 0.972, 1.0], 'all_L1': [0.976, 0.957, 0.966, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.905, 0.907, 0.97, 1.0], 'all_L1': [0.901, 0.894, 0.947, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.887, 0.86, 0.955, 1.0], 'all_L1': [0.901, 0.871, 0.93, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.882, 0.905, 0.957, 1.0], 'all_L1': [0.841, 0.838, 0.893, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.004, 0.007, 0.005, 0.005], 'all_L1': [0.014, 0.021, 0.022, 0.024]}), defaultdict(<class 'list'>, {'all_KL': [0.021, 0.024, 0.026, 0.016], 'all_L1': [0.026, 0.038, 0.036, 0.028]}), defaultdict(<class 'list'>, {'all_KL': [0.051, 0.046, 0.032, 0.019], 'all_L1': [0.07, 0.072, 0.053, 0.038]}), defaultdict(<class 'list'>, {'all_KL': [0.056, 0.062, 0.036, 0.032], 'all_L1': [0.077, 0.082, 0.062, 0.059]}), defaultdict(<class 'list'>, {'all_KL': [0.08, 0.055, 0.053, 0.048], 'all_L1': [0.132, 0.126, 0.122, 0.106]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.876 +- 0.085, 0.875 +- 0.078, 0.929 +- 0.045, 1.000 +- 0.000
suff++ class all_KL  =  0.890 +- 0.084, 0.905 +- 0.062, 0.962 +- 0.028, 1.000 +- 0.000
suff++_acc_int  =  0.583 +- 0.066, 0.629 +- 0.056, 0.677 +- 0.060
nec class all_L1  =  0.099 +- 0.065, 0.104 +- 0.060, 0.076 +- 0.048, 0.064 +- 0.043
nec class all_KL  =  0.067 +- 0.046, 0.063 +- 0.038, 0.041 +- 0.028, 0.032 +- 0.024
nec_acc_int  =  0.616 +- 0.086, 0.657 +- 0.064, 0.678 +- 0.056, 0.684 +- 0.060

Eval split val
suff++ class all_L1  =  0.858 +- 0.099, 0.862 +- 0.089, 0.923 +- 0.051, 1.000 +- 0.000
suff++ class all_KL  =  0.882 +- 0.093, 0.906 +- 0.057, 0.963 +- 0.022, 1.000 +- 0.000
suff++_acc_int  =  0.590 +- 0.069, 0.606 +- 0.086, 0.630 +- 0.081
nec class all_L1  =  0.113 +- 0.077, 0.118 +- 0.073, 0.088 +- 0.054, 0.076 +- 0.051
nec class all_KL  =  0.073 +- 0.052, 0.065 +- 0.039, 0.043 +- 0.022, 0.035 +- 0.022
nec_acc_int  =  0.623 +- 0.077, 0.617 +- 0.084, 0.640 +- 0.078, 0.645 +- 0.081

Eval split test
suff++ class all_L1  =  0.920 +- 0.053, 0.907 +- 0.052, 0.943 +- 0.030, 1.000 +- 0.000
suff++ class all_KL  =  0.930 +- 0.048, 0.926 +- 0.047, 0.970 +- 0.014, 1.000 +- 0.000
suff++_acc_int  =  0.559 +- 0.024, 0.584 +- 0.031, 0.620 +- 0.018
nec class all_L1  =  0.064 +- 0.042, 0.068 +- 0.037, 0.059 +- 0.034, 0.051 +- 0.030
nec class all_KL  =  0.042 +- 0.027, 0.039 +- 0.020, 0.030 +- 0.016, 0.024 +- 0.015
nec_acc_int  =  0.572 +- 0.035, 0.614 +- 0.027, 0.636 +- 0.026, 0.630 +- 0.023


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.488 +- 0.010, 0.489 +- 0.012, 0.503 +- 0.004, 0.532 +- 0.022
Faith. Armon (L1)= 		  =  0.169 +- 0.106, 0.177 +- 0.096, 0.137 +- 0.080, 0.118 +- 0.075
Faith. GMean (L1)= 	  =  0.266 +- 0.102, 0.280 +- 0.088, 0.250 +- 0.080, 0.239 +- 0.085
Faith. Aritm (KL)= 		  =  0.479 +- 0.020, 0.484 +- 0.015, 0.502 +- 0.004, 0.516 +- 0.012
Faith. Armon (KL)= 		  =  0.119 +- 0.079, 0.114 +- 0.066, 0.077 +- 0.050, 0.061 +- 0.045
Faith. GMean (KL)= 	  =  0.217 +- 0.092, 0.220 +- 0.080, 0.184 +- 0.071, 0.164 +- 0.069

Eval split val
Faith. Aritm (L1)= 		  =  0.486 +- 0.013, 0.490 +- 0.012, 0.505 +- 0.003, 0.538 +- 0.026
Faith. Armon (L1)= 		  =  0.187 +- 0.121, 0.196 +- 0.113, 0.155 +- 0.089, 0.137 +- 0.087
Faith. GMean (L1)= 	  =  0.278 +- 0.112, 0.292 +- 0.100, 0.266 +- 0.086, 0.258 +- 0.096
Faith. Aritm (KL)= 		  =  0.477 +- 0.024, 0.486 +- 0.013, 0.503 +- 0.003, 0.518 +- 0.011
Faith. Armon (KL)= 		  =  0.128 +- 0.089, 0.119 +- 0.068, 0.081 +- 0.041, 0.067 +- 0.041
Faith. GMean (KL)= 	  =  0.222 +- 0.103, 0.225 +- 0.082, 0.192 +- 0.062, 0.175 +- 0.067

Eval split test
Faith. Aritm (L1)= 		  =  0.492 +- 0.006, 0.488 +- 0.009, 0.501 +- 0.004, 0.525 +- 0.015
Faith. Armon (L1)= 		  =  0.116 +- 0.071, 0.123 +- 0.062, 0.109 +- 0.059, 0.096 +- 0.053
Faith. GMean (L1)= 	  =  0.225 +- 0.077, 0.236 +- 0.063, 0.226 +- 0.061, 0.217 +- 0.062
Faith. Aritm (KL)= 		  =  0.486 +- 0.012, 0.483 +- 0.014, 0.500 +- 0.003, 0.512 +- 0.007
Faith. Armon (KL)= 		  =  0.080 +- 0.049, 0.074 +- 0.038, 0.058 +- 0.029, 0.046 +- 0.028
Faith. GMean (KL)= 	  =  0.182 +- 0.071, 0.179 +- 0.055, 0.163 +- 0.051, 0.147 +- 0.050
Computed for split load_split = id



Completed in  0:08:50.331288  for GSATvGIN GOODHIV/scaffold



DONE GSAT GOODHIV/scaffold

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Mar 23 00:09:10 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 03/23/2024 12:09:10 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/23/2024 12:09:41 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/23/2024 12:09:51 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/23/2024 12:10:02 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/23/2024 12:10:18 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/23/2024 12:10:33 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 03/23/2024 12:10:33 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:46 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0mUsing feature sampling := feat
self.EF = 0.1
[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:11:47 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 174...
[0m[1;37mINFO[0m: [1mCheckpoint 174: 
-----------------------------------
Train ROC-AUC: 0.9747
Train Loss: 0.1592
ID Validation ROC-AUC: 0.9216
ID Validation Loss: 0.3096
ID Test ROC-AUC: 0.9242
ID Test Loss: 0.3130
OOD Validation ROC-AUC: 0.6625
OOD Validation Loss: 0.4639
OOD Test ROC-AUC: 0.7200
OOD Test Loss: 0.6879

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 29...
[0m[1;37mINFO[0m: [1mCheckpoint 29: 
-----------------------------------
Train ROC-AUC: 0.9117
Train Loss: 0.2596
ID Validation ROC-AUC: 0.8990
ID Validation Loss: 0.2737
ID Test ROC-AUC: 0.9017
ID Test Loss: 0.2762
OOD Validation ROC-AUC: 0.6935
OOD Validation Loss: 0.2996
OOD Test ROC-AUC: 0.7346
OOD Test Loss: 0.4781

[0m[1;37mINFO[0m: [1mChartInfo 0.9242 0.7200 0.9017 0.7346 0.8990 0.6935[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 03/23/2024 12:11:48 AM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 03/23/2024 12:11:53 AM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 03/23/2024 12:11:57 AM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.637
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.65
SUFF++ for r=0.3 class 0.0 = 0.695 +- 0.146 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.3 class 1.0 = 0.667 +- 0.146 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.3 all KL = 0.814 +- 0.146 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.3 all L1 = 0.67 +- 0.135 (in-sample avg dev_std = 0.336)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.807
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.779
SUFF++ for r=0.6 class 0.0 = 0.706 +- 0.175 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.6 class 1.0 = 0.79 +- 0.175 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.6 all KL = 0.841 +- 0.175 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.6 all L1 = 0.78 +- 0.191 (in-sample avg dev_std = 0.313)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.904
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.886
SUFF++ for r=0.9 class 0.0 = 0.846 +- 0.104 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.9 class 1.0 = 0.933 +- 0.104 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.9 all KL = 0.953 +- 0.104 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.9 all L1 = 0.923 +- 0.128 (in-sample avg dev_std = 0.182)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.561
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 799
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.558
SUFF++ for r=0.3 class 0.0 = 0.679 +- 0.140 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.3 class 1.0 = 0.665 +- 0.140 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.3 all KL = 0.822 +- 0.140 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.3 all L1 = 0.666 +- 0.124 (in-sample avg dev_std = 0.341)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.622
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.596
SUFF++ for r=0.6 class 0.0 = 0.697 +- 0.192 (in-sample avg dev_std = 0.359)
SUFF++ for r=0.6 class 1.0 = 0.718 +- 0.192 (in-sample avg dev_std = 0.359)
SUFF++ for r=0.6 all KL = 0.8 +- 0.192 (in-sample avg dev_std = 0.359)
SUFF++ for r=0.6 all L1 = 0.716 +- 0.191 (in-sample avg dev_std = 0.359)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.639
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.654
SUFF++ for r=0.9 class 0.0 = 0.841 +- 0.135 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.9 class 1.0 = 0.862 +- 0.135 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.9 all KL = 0.916 +- 0.135 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.9 all L1 = 0.861 +- 0.162 (in-sample avg dev_std = 0.230)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.598
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.587
SUFF++ for r=0.3 class 0.0 = 0.683 +- 0.152 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.3 class 1.0 = 0.662 +- 0.152 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.3 all KL = 0.816 +- 0.152 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.3 all L1 = 0.666 +- 0.132 (in-sample avg dev_std = 0.341)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.67
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.662
SUFF++ for r=0.6 class 0.0 = 0.698 +- 0.182 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 class 1.0 = 0.725 +- 0.182 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 all KL = 0.81 +- 0.182 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 all L1 = 0.721 +- 0.182 (in-sample avg dev_std = 0.353)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.699
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.7
SUFF++ for r=0.9 class 0.0 = 0.831 +- 0.147 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 class 1.0 = 0.873 +- 0.147 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 all KL = 0.913 +- 0.147 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 all L1 = 0.866 +- 0.160 (in-sample avg dev_std = 0.245)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.637
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.603
NEC for r=0.3 class 0.0 = 0.276 +- 0.142 (in-sample avg dev_std = 0.277)
NEC for r=0.3 class 1.0 = 0.293 +- 0.142 (in-sample avg dev_std = 0.277)
NEC for r=0.3 all KL = 0.145 +- 0.142 (in-sample avg dev_std = 0.277)
NEC for r=0.3 all L1 = 0.291 +- 0.147 (in-sample avg dev_std = 0.277)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.807
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.769
NEC for r=0.6 class 0.0 = 0.27 +- 0.157 (in-sample avg dev_std = 0.279)
NEC for r=0.6 class 1.0 = 0.187 +- 0.157 (in-sample avg dev_std = 0.279)
NEC for r=0.6 all KL = 0.132 +- 0.157 (in-sample avg dev_std = 0.279)
NEC for r=0.6 all L1 = 0.197 +- 0.173 (in-sample avg dev_std = 0.279)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.904
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.844
NEC for r=0.9 class 0.0 = 0.279 +- 0.174 (in-sample avg dev_std = 0.258)
NEC for r=0.9 class 1.0 = 0.108 +- 0.174 (in-sample avg dev_std = 0.258)
NEC for r=0.9 all KL = 0.105 +- 0.174 (in-sample avg dev_std = 0.258)
NEC for r=0.9 all L1 = 0.128 +- 0.175 (in-sample avg dev_std = 0.258)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.923
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.861
NEC for r=1.0 class 0.0 = 0.316 +- 0.203 (in-sample avg dev_std = 0.282)
NEC for r=1.0 class 1.0 = 0.098 +- 0.203 (in-sample avg dev_std = 0.282)
NEC for r=1.0 all KL = 0.115 +- 0.203 (in-sample avg dev_std = 0.282)
NEC for r=1.0 all L1 = 0.124 +- 0.181 (in-sample avg dev_std = 0.282)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.561
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.507
NEC for r=0.3 class 0.0 = 0.311 +- 0.140 (in-sample avg dev_std = 0.271)
NEC for r=0.3 class 1.0 = 0.296 +- 0.140 (in-sample avg dev_std = 0.271)
NEC for r=0.3 all KL = 0.142 +- 0.140 (in-sample avg dev_std = 0.271)
NEC for r=0.3 all L1 = 0.297 +- 0.146 (in-sample avg dev_std = 0.271)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.622
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.583
NEC for r=0.6 class 0.0 = 0.306 +- 0.170 (in-sample avg dev_std = 0.315)
NEC for r=0.6 class 1.0 = 0.246 +- 0.170 (in-sample avg dev_std = 0.315)
NEC for r=0.6 all KL = 0.162 +- 0.170 (in-sample avg dev_std = 0.315)
NEC for r=0.6 all L1 = 0.251 +- 0.175 (in-sample avg dev_std = 0.315)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.639
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.645
NEC for r=0.9 class 0.0 = 0.271 +- 0.204 (in-sample avg dev_std = 0.342)
NEC for r=0.9 class 1.0 = 0.213 +- 0.204 (in-sample avg dev_std = 0.342)
NEC for r=0.9 all KL = 0.17 +- 0.204 (in-sample avg dev_std = 0.342)
NEC for r=0.9 all L1 = 0.218 +- 0.201 (in-sample avg dev_std = 0.342)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.647
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.647
NEC for r=1.0 class 0.0 = 0.265 +- 0.208 (in-sample avg dev_std = 0.347)
NEC for r=1.0 class 1.0 = 0.204 +- 0.208 (in-sample avg dev_std = 0.347)
NEC for r=1.0 all KL = 0.168 +- 0.208 (in-sample avg dev_std = 0.347)
NEC for r=1.0 all L1 = 0.209 +- 0.207 (in-sample avg dev_std = 0.347)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.598
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.58
NEC for r=0.3 class 0.0 = 0.292 +- 0.140 (in-sample avg dev_std = 0.274)
NEC for r=0.3 class 1.0 = 0.297 +- 0.140 (in-sample avg dev_std = 0.274)
NEC for r=0.3 all KL = 0.145 +- 0.140 (in-sample avg dev_std = 0.274)
NEC for r=0.3 all L1 = 0.296 +- 0.142 (in-sample avg dev_std = 0.274)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.67
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.678
NEC for r=0.6 class 0.0 = 0.259 +- 0.170 (in-sample avg dev_std = 0.323)
NEC for r=0.6 class 1.0 = 0.257 +- 0.170 (in-sample avg dev_std = 0.323)
NEC for r=0.6 all KL = 0.166 +- 0.170 (in-sample avg dev_std = 0.323)
NEC for r=0.6 all L1 = 0.258 +- 0.170 (in-sample avg dev_std = 0.323)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.699
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.695
NEC for r=0.9 class 0.0 = 0.271 +- 0.214 (in-sample avg dev_std = 0.347)
NEC for r=0.9 class 1.0 = 0.207 +- 0.214 (in-sample avg dev_std = 0.347)
NEC for r=0.9 all KL = 0.18 +- 0.214 (in-sample avg dev_std = 0.347)
NEC for r=0.9 all L1 = 0.218 +- 0.200 (in-sample avg dev_std = 0.347)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.719
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.71
NEC for r=1.0 class 0.0 = 0.269 +- 0.227 (in-sample avg dev_std = 0.349)
NEC for r=1.0 class 1.0 = 0.197 +- 0.227 (in-sample avg dev_std = 0.349)
NEC for r=1.0 all KL = 0.184 +- 0.227 (in-sample avg dev_std = 0.349)
NEC for r=1.0 all L1 = 0.209 +- 0.210 (in-sample avg dev_std = 0.349)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Mar 23 00:16:16 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 03/23/2024 12:16:16 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/23/2024 12:16:48 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/23/2024 12:16:58 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/23/2024 12:17:09 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/23/2024 12:17:24 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/23/2024 12:17:40 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 03/23/2024 12:17:40 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0mUsing feature sampling := feat
self.EF = 0.1
[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:18:53 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 167...
[0m[1;37mINFO[0m: [1mCheckpoint 167: 
-----------------------------------
Train ROC-AUC: 0.9783
Train Loss: 0.1269
ID Validation ROC-AUC: 0.9244
ID Validation Loss: 0.2658
ID Test ROC-AUC: 0.9267
ID Test Loss: 0.2679
OOD Validation ROC-AUC: 0.6593
OOD Validation Loss: 0.4783
OOD Test ROC-AUC: 0.7128
OOD Test Loss: 0.6262

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 30...
[0m[1;37mINFO[0m: [1mCheckpoint 30: 
-----------------------------------
Train ROC-AUC: 0.9086
Train Loss: 0.2436
ID Validation ROC-AUC: 0.8959
ID Validation Loss: 0.2566
ID Test ROC-AUC: 0.8988
ID Test Loss: 0.2585
OOD Validation ROC-AUC: 0.6869
OOD Validation Loss: 0.2916
OOD Test ROC-AUC: 0.7309
OOD Test Loss: 0.4531

[0m[1;37mINFO[0m: [1mChartInfo 0.9267 0.7128 0.8988 0.7309 0.8959 0.6869[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 03/23/2024 12:18:54 AM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 03/23/2024 12:18:58 AM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 03/23/2024 12:19:03 AM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.609
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 786
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.534
SUFF++ for r=0.3 class 0.0 = 0.778 +- 0.109 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.3 class 1.0 = 0.769 +- 0.109 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.3 all KL = 0.901 +- 0.109 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.3 all L1 = 0.77 +- 0.099 (in-sample avg dev_std = 0.255)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.832
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.756
SUFF++ for r=0.6 class 0.0 = 0.792 +- 0.152 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.6 class 1.0 = 0.804 +- 0.152 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.6 all KL = 0.877 +- 0.152 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.6 all L1 = 0.803 +- 0.144 (in-sample avg dev_std = 0.240)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.91
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.895
SUFF++ for r=0.9 class 0.0 = 0.907 +- 0.049 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.9 class 1.0 = 0.957 +- 0.049 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.9 all KL = 0.982 +- 0.049 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.9 all L1 = 0.951 +- 0.076 (in-sample avg dev_std = 0.118)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.56
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 775
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.534
SUFF++ for r=0.3 class 0.0 = 0.79 +- 0.109 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.3 class 1.0 = 0.758 +- 0.109 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.3 all KL = 0.895 +- 0.109 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.3 all L1 = 0.76 +- 0.103 (in-sample avg dev_std = 0.259)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.644
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.607
SUFF++ for r=0.6 class 0.0 = 0.795 +- 0.149 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.6 class 1.0 = 0.782 +- 0.149 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.6 all KL = 0.882 +- 0.149 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.6 all L1 = 0.783 +- 0.140 (in-sample avg dev_std = 0.242)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.644
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.63
SUFF++ for r=0.9 class 0.0 = 0.901 +- 0.059 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.9 class 1.0 = 0.924 +- 0.059 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.9 all KL = 0.972 +- 0.059 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.9 all L1 = 0.922 +- 0.092 (in-sample avg dev_std = 0.155)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.567
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 783
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.555
SUFF++ for r=0.3 class 0.0 = 0.768 +- 0.104 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.3 class 1.0 = 0.763 +- 0.104 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.3 all KL = 0.905 +- 0.104 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.3 all L1 = 0.764 +- 0.102 (in-sample avg dev_std = 0.262)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.627
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.616
SUFF++ for r=0.6 class 0.0 = 0.788 +- 0.125 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.6 class 1.0 = 0.783 +- 0.125 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.6 all KL = 0.896 +- 0.125 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.6 all L1 = 0.784 +- 0.130 (in-sample avg dev_std = 0.234)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.708
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.702
SUFF++ for r=0.9 class 0.0 = 0.898 +- 0.060 (in-sample avg dev_std = 0.161)
SUFF++ for r=0.9 class 1.0 = 0.916 +- 0.060 (in-sample avg dev_std = 0.161)
SUFF++ for r=0.9 all KL = 0.969 +- 0.060 (in-sample avg dev_std = 0.161)
SUFF++ for r=0.9 all L1 = 0.913 +- 0.094 (in-sample avg dev_std = 0.161)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.613
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.593
NEC for r=0.3 class 0.0 = 0.193 +- 0.091 (in-sample avg dev_std = 0.209)
NEC for r=0.3 class 1.0 = 0.207 +- 0.091 (in-sample avg dev_std = 0.209)
NEC for r=0.3 all KL = 0.076 +- 0.091 (in-sample avg dev_std = 0.209)
NEC for r=0.3 all L1 = 0.205 +- 0.111 (in-sample avg dev_std = 0.209)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.832
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.793
NEC for r=0.6 class 0.0 = 0.197 +- 0.116 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 1.0 = 0.165 +- 0.116 (in-sample avg dev_std = 0.237)
NEC for r=0.6 all KL = 0.09 +- 0.116 (in-sample avg dev_std = 0.237)
NEC for r=0.6 all L1 = 0.169 +- 0.134 (in-sample avg dev_std = 0.237)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.91
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.861
NEC for r=0.9 class 0.0 = 0.255 +- 0.141 (in-sample avg dev_std = 0.235)
NEC for r=0.9 class 1.0 = 0.122 +- 0.141 (in-sample avg dev_std = 0.235)
NEC for r=0.9 all KL = 0.093 +- 0.141 (in-sample avg dev_std = 0.235)
NEC for r=0.9 all L1 = 0.138 +- 0.156 (in-sample avg dev_std = 0.235)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.919
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.862
NEC for r=1.0 class 0.0 = 0.296 +- 0.163 (in-sample avg dev_std = 0.244)
NEC for r=1.0 class 1.0 = 0.109 +- 0.163 (in-sample avg dev_std = 0.244)
NEC for r=1.0 all KL = 0.098 +- 0.163 (in-sample avg dev_std = 0.244)
NEC for r=1.0 all L1 = 0.13 +- 0.164 (in-sample avg dev_std = 0.244)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.561
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.544
NEC for r=0.3 class 0.0 = 0.196 +- 0.101 (in-sample avg dev_std = 0.217)
NEC for r=0.3 class 1.0 = 0.213 +- 0.101 (in-sample avg dev_std = 0.217)
NEC for r=0.3 all KL = 0.08 +- 0.101 (in-sample avg dev_std = 0.217)
NEC for r=0.3 all L1 = 0.211 +- 0.112 (in-sample avg dev_std = 0.217)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.644
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.622
NEC for r=0.6 class 0.0 = 0.213 +- 0.119 (in-sample avg dev_std = 0.257)
NEC for r=0.6 class 1.0 = 0.195 +- 0.119 (in-sample avg dev_std = 0.257)
NEC for r=0.6 all KL = 0.097 +- 0.119 (in-sample avg dev_std = 0.257)
NEC for r=0.6 all L1 = 0.197 +- 0.137 (in-sample avg dev_std = 0.257)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.644
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.631
NEC for r=0.9 class 0.0 = 0.27 +- 0.159 (in-sample avg dev_std = 0.298)
NEC for r=0.9 class 1.0 = 0.199 +- 0.159 (in-sample avg dev_std = 0.298)
NEC for r=0.9 all KL = 0.128 +- 0.159 (in-sample avg dev_std = 0.298)
NEC for r=0.9 all L1 = 0.205 +- 0.171 (in-sample avg dev_std = 0.298)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.662
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.651
NEC for r=1.0 class 0.0 = 0.286 +- 0.168 (in-sample avg dev_std = 0.303)
NEC for r=1.0 class 1.0 = 0.198 +- 0.168 (in-sample avg dev_std = 0.303)
NEC for r=1.0 all KL = 0.133 +- 0.168 (in-sample avg dev_std = 0.303)
NEC for r=1.0 all L1 = 0.206 +- 0.179 (in-sample avg dev_std = 0.303)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.57
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.565
NEC for r=0.3 class 0.0 = 0.195 +- 0.087 (in-sample avg dev_std = 0.211)
NEC for r=0.3 class 1.0 = 0.211 +- 0.087 (in-sample avg dev_std = 0.211)
NEC for r=0.3 all KL = 0.072 +- 0.087 (in-sample avg dev_std = 0.211)
NEC for r=0.3 all L1 = 0.208 +- 0.110 (in-sample avg dev_std = 0.211)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.627
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.615
NEC for r=0.6 class 0.0 = 0.213 +- 0.118 (in-sample avg dev_std = 0.254)
NEC for r=0.6 class 1.0 = 0.206 +- 0.118 (in-sample avg dev_std = 0.254)
NEC for r=0.6 all KL = 0.097 +- 0.118 (in-sample avg dev_std = 0.254)
NEC for r=0.6 all L1 = 0.207 +- 0.132 (in-sample avg dev_std = 0.254)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.708
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.688
NEC for r=0.9 class 0.0 = 0.275 +- 0.169 (in-sample avg dev_std = 0.311)
NEC for r=0.9 class 1.0 = 0.211 +- 0.169 (in-sample avg dev_std = 0.311)
NEC for r=0.9 all KL = 0.14 +- 0.169 (in-sample avg dev_std = 0.311)
NEC for r=0.9 all L1 = 0.222 +- 0.171 (in-sample avg dev_std = 0.311)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.72
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.692
NEC for r=1.0 class 0.0 = 0.279 +- 0.181 (in-sample avg dev_std = 0.322)
NEC for r=1.0 class 1.0 = 0.212 +- 0.181 (in-sample avg dev_std = 0.322)
NEC for r=1.0 all KL = 0.152 +- 0.181 (in-sample avg dev_std = 0.322)
NEC for r=1.0 all L1 = 0.223 +- 0.183 (in-sample avg dev_std = 0.322)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Mar 23 00:23:13 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 03/23/2024 12:23:13 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/23/2024 12:23:44 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/23/2024 12:23:54 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/23/2024 12:24:04 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/23/2024 12:24:20 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/23/2024 12:24:36 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 03/23/2024 12:24:36 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0mUsing feature sampling := feat
self.EF = 0.1
[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:51 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:51 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:25:51 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 119...
[0m[1;37mINFO[0m: [1mCheckpoint 119: 
-----------------------------------
Train ROC-AUC: 0.9586
Train Loss: 0.1793
ID Validation ROC-AUC: 0.9217
ID Validation Loss: 0.2533
ID Test ROC-AUC: 0.9244
ID Test Loss: 0.2525
OOD Validation ROC-AUC: 0.6759
OOD Validation Loss: 0.3745
OOD Test ROC-AUC: 0.7109
OOD Test Loss: 0.5685

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 97...
[0m[1;37mINFO[0m: [1mCheckpoint 97: 
-----------------------------------
Train ROC-AUC: 0.9479
Train Loss: 0.1985
ID Validation ROC-AUC: 0.9155
ID Validation Loss: 0.2618
ID Test ROC-AUC: 0.9197
ID Test Loss: 0.2606
OOD Validation ROC-AUC: 0.6885
OOD Validation Loss: 0.3598
OOD Test ROC-AUC: 0.7250
OOD Test Loss: 0.5469

[0m[1;37mINFO[0m: [1mChartInfo 0.9244 0.7109 0.9197 0.7250 0.9155 0.6885[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 03/23/2024 12:25:51 AM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 03/23/2024 12:25:56 AM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 03/23/2024 12:26:00 AM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.706
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.645
SUFF++ for r=0.3 class 0.0 = 0.717 +- 0.094 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.3 class 1.0 = 0.713 +- 0.094 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.3 all KL = 0.876 +- 0.094 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.3 all L1 = 0.714 +- 0.109 (in-sample avg dev_std = 0.269)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.828
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.781
SUFF++ for r=0.6 class 0.0 = 0.704 +- 0.096 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.6 class 1.0 = 0.838 +- 0.096 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.6 all KL = 0.905 +- 0.096 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.6 all L1 = 0.822 +- 0.148 (in-sample avg dev_std = 0.229)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.878
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.863
SUFF++ for r=0.9 class 0.0 = 0.806 +- 0.069 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 class 1.0 = 0.923 +- 0.069 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 all KL = 0.962 +- 0.069 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 all L1 = 0.91 +- 0.118 (in-sample avg dev_std = 0.152)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.576
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.57
SUFF++ for r=0.3 class 0.0 = 0.747 +- 0.080 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.3 class 1.0 = 0.722 +- 0.080 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.3 all KL = 0.896 +- 0.080 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.3 all L1 = 0.724 +- 0.098 (in-sample avg dev_std = 0.261)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.648
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.627
SUFF++ for r=0.6 class 0.0 = 0.713 +- 0.104 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.6 class 1.0 = 0.778 +- 0.104 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.6 all KL = 0.888 +- 0.104 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.6 all L1 = 0.772 +- 0.142 (in-sample avg dev_std = 0.251)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.64
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.635
SUFF++ for r=0.9 class 0.0 = 0.826 +- 0.074 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.9 class 1.0 = 0.862 +- 0.074 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.9 all KL = 0.945 +- 0.074 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.9 all L1 = 0.859 +- 0.129 (in-sample avg dev_std = 0.179)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.678
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.606
SUFF++ for r=0.3 class 0.0 = 0.723 +- 0.088 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.3 class 1.0 = 0.72 +- 0.088 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.3 all KL = 0.888 +- 0.088 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.3 all L1 = 0.721 +- 0.104 (in-sample avg dev_std = 0.270)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.699
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.66
SUFF++ for r=0.6 class 0.0 = 0.708 +- 0.104 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.6 class 1.0 = 0.775 +- 0.104 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.6 all KL = 0.88 +- 0.104 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.6 all L1 = 0.764 +- 0.142 (in-sample avg dev_std = 0.268)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.717
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.693
SUFF++ for r=0.9 class 0.0 = 0.822 +- 0.074 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.9 class 1.0 = 0.877 +- 0.074 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.9 all KL = 0.948 +- 0.074 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.9 all L1 = 0.868 +- 0.121 (in-sample avg dev_std = 0.188)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.706
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.717
NEC for r=0.3 class 0.0 = 0.218 +- 0.091 (in-sample avg dev_std = 0.207)
NEC for r=0.3 class 1.0 = 0.265 +- 0.091 (in-sample avg dev_std = 0.207)
NEC for r=0.3 all KL = 0.098 +- 0.091 (in-sample avg dev_std = 0.207)
NEC for r=0.3 all L1 = 0.259 +- 0.121 (in-sample avg dev_std = 0.207)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.828
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.808
NEC for r=0.6 class 0.0 = 0.25 +- 0.099 (in-sample avg dev_std = 0.188)
NEC for r=0.6 class 1.0 = 0.154 +- 0.099 (in-sample avg dev_std = 0.188)
NEC for r=0.6 all KL = 0.081 +- 0.099 (in-sample avg dev_std = 0.188)
NEC for r=0.6 all L1 = 0.165 +- 0.136 (in-sample avg dev_std = 0.188)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.878
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.851
NEC for r=0.9 class 0.0 = 0.242 +- 0.096 (in-sample avg dev_std = 0.168)
NEC for r=0.9 class 1.0 = 0.095 +- 0.096 (in-sample avg dev_std = 0.168)
NEC for r=0.9 all KL = 0.058 +- 0.096 (in-sample avg dev_std = 0.168)
NEC for r=0.9 all L1 = 0.112 +- 0.132 (in-sample avg dev_std = 0.168)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.912
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.87
NEC for r=1.0 class 0.0 = 0.258 +- 0.108 (in-sample avg dev_std = 0.184)
NEC for r=1.0 class 1.0 = 0.093 +- 0.108 (in-sample avg dev_std = 0.184)
NEC for r=1.0 all KL = 0.063 +- 0.108 (in-sample avg dev_std = 0.184)
NEC for r=1.0 all L1 = 0.112 +- 0.136 (in-sample avg dev_std = 0.184)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.576
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.603
NEC for r=0.3 class 0.0 = 0.262 +- 0.083 (in-sample avg dev_std = 0.207)
NEC for r=0.3 class 1.0 = 0.26 +- 0.083 (in-sample avg dev_std = 0.207)
NEC for r=0.3 all KL = 0.089 +- 0.083 (in-sample avg dev_std = 0.207)
NEC for r=0.3 all L1 = 0.26 +- 0.115 (in-sample avg dev_std = 0.207)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.648
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.607
NEC for r=0.6 class 0.0 = 0.232 +- 0.096 (in-sample avg dev_std = 0.209)
NEC for r=0.6 class 1.0 = 0.203 +- 0.096 (in-sample avg dev_std = 0.209)
NEC for r=0.6 all KL = 0.089 +- 0.096 (in-sample avg dev_std = 0.209)
NEC for r=0.6 all L1 = 0.205 +- 0.129 (in-sample avg dev_std = 0.209)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.64
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.63
NEC for r=0.9 class 0.0 = 0.207 +- 0.103 (in-sample avg dev_std = 0.217)
NEC for r=0.9 class 1.0 = 0.172 +- 0.103 (in-sample avg dev_std = 0.217)
NEC for r=0.9 all KL = 0.084 +- 0.103 (in-sample avg dev_std = 0.217)
NEC for r=0.9 all L1 = 0.175 +- 0.143 (in-sample avg dev_std = 0.217)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.623
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.629
NEC for r=1.0 class 0.0 = 0.185 +- 0.103 (in-sample avg dev_std = 0.220)
NEC for r=1.0 class 1.0 = 0.173 +- 0.103 (in-sample avg dev_std = 0.220)
NEC for r=1.0 all KL = 0.081 +- 0.103 (in-sample avg dev_std = 0.220)
NEC for r=1.0 all L1 = 0.174 +- 0.144 (in-sample avg dev_std = 0.220)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.678
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.621
NEC for r=0.3 class 0.0 = 0.251 +- 0.095 (in-sample avg dev_std = 0.199)
NEC for r=0.3 class 1.0 = 0.256 +- 0.095 (in-sample avg dev_std = 0.199)
NEC for r=0.3 all KL = 0.091 +- 0.095 (in-sample avg dev_std = 0.199)
NEC for r=0.3 all L1 = 0.255 +- 0.125 (in-sample avg dev_std = 0.199)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.699
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.694
NEC for r=0.6 class 0.0 = 0.233 +- 0.096 (in-sample avg dev_std = 0.205)
NEC for r=0.6 class 1.0 = 0.203 +- 0.096 (in-sample avg dev_std = 0.205)
NEC for r=0.6 all KL = 0.091 +- 0.096 (in-sample avg dev_std = 0.205)
NEC for r=0.6 all L1 = 0.208 +- 0.134 (in-sample avg dev_std = 0.205)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.717
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.692
NEC for r=0.9 class 0.0 = 0.214 +- 0.108 (in-sample avg dev_std = 0.208)
NEC for r=0.9 class 1.0 = 0.161 +- 0.108 (in-sample avg dev_std = 0.208)
NEC for r=0.9 all KL = 0.084 +- 0.108 (in-sample avg dev_std = 0.208)
NEC for r=0.9 all L1 = 0.17 +- 0.141 (in-sample avg dev_std = 0.208)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.717
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.689
NEC for r=1.0 class 0.0 = 0.224 +- 0.098 (in-sample avg dev_std = 0.217)
NEC for r=1.0 class 1.0 = 0.156 +- 0.098 (in-sample avg dev_std = 0.217)
NEC for r=1.0 all KL = 0.078 +- 0.098 (in-sample avg dev_std = 0.217)
NEC for r=1.0 all L1 = 0.167 +- 0.141 (in-sample avg dev_std = 0.217)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Mar 23 00:30:35 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 03/23/2024 12:30:35 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/23/2024 12:31:06 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/23/2024 12:31:16 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/23/2024 12:31:27 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/23/2024 12:31:43 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/23/2024 12:31:58 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 03/23/2024 12:31:58 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:12 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:12 AM : [1mUsing no mitigation None
[0mUsing feature sampling := feat
self.EF = 0.1
[1;34mDEBUG[0m: 03/23/2024 12:33:12 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:12 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:12 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:12 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:12 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:12 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:12 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:12 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:13 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:13 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:13 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:13 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:13 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:13 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:13 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:13 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:13 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:13 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:13 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:13 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:13 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:13 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:13 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:13 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:13 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:13 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:13 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:13 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:13 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:13 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:13 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:13 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:13 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:33:13 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 107...
[0m[1;37mINFO[0m: [1mCheckpoint 107: 
-----------------------------------
Train ROC-AUC: 0.9561
Train Loss: 0.1699
ID Validation ROC-AUC: 0.9223
ID Validation Loss: 0.2340
ID Test ROC-AUC: 0.9235
ID Test Loss: 0.2358
OOD Validation ROC-AUC: 0.6576
OOD Validation Loss: 0.3970
OOD Test ROC-AUC: 0.7067
OOD Test Loss: 0.5494

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 21...
[0m[1;37mINFO[0m: [1mCheckpoint 21: 
-----------------------------------
Train ROC-AUC: 0.9016
Train Loss: 0.2482
ID Validation ROC-AUC: 0.8949
ID Validation Loss: 0.2557
ID Test ROC-AUC: 0.8953
ID Test Loss: 0.2587
OOD Validation ROC-AUC: 0.6908
OOD Validation Loss: 0.2916
OOD Test ROC-AUC: 0.7285
OOD Test Loss: 0.4503

[0m[1;37mINFO[0m: [1mChartInfo 0.9235 0.7067 0.8953 0.7285 0.8949 0.6908[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 03/23/2024 12:33:13 AM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 03/23/2024 12:33:18 AM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 03/23/2024 12:33:22 AM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.552
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.583
SUFF++ for r=0.3 class 0.0 = 0.768 +- 0.070 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.3 class 1.0 = 0.741 +- 0.070 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.3 all KL = 0.913 +- 0.070 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.3 all L1 = 0.744 +- 0.089 (in-sample avg dev_std = 0.246)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.776
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.754
SUFF++ for r=0.6 class 0.0 = 0.749 +- 0.083 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.6 class 1.0 = 0.784 +- 0.083 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.6 all KL = 0.903 +- 0.083 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.6 all L1 = 0.78 +- 0.117 (in-sample avg dev_std = 0.233)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.899
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.877
SUFF++ for r=0.9 class 0.0 = 0.828 +- 0.063 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.9 class 1.0 = 0.912 +- 0.063 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.9 all KL = 0.959 +- 0.063 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.9 all L1 = 0.902 +- 0.102 (in-sample avg dev_std = 0.162)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.531
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.546
SUFF++ for r=0.3 class 0.0 = 0.77 +- 0.058 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.3 class 1.0 = 0.753 +- 0.058 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.3 all KL = 0.924 +- 0.058 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.3 all L1 = 0.755 +- 0.081 (in-sample avg dev_std = 0.236)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.613
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.603
SUFF++ for r=0.6 class 0.0 = 0.74 +- 0.080 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.6 class 1.0 = 0.752 +- 0.080 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.6 all KL = 0.899 +- 0.080 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.6 all L1 = 0.751 +- 0.111 (in-sample avg dev_std = 0.245)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.686
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.671
SUFF++ for r=0.9 class 0.0 = 0.823 +- 0.079 (in-sample avg dev_std = 0.189)
SUFF++ for r=0.9 class 1.0 = 0.85 +- 0.079 (in-sample avg dev_std = 0.189)
SUFF++ for r=0.9 all KL = 0.941 +- 0.079 (in-sample avg dev_std = 0.189)
SUFF++ for r=0.9 all L1 = 0.848 +- 0.124 (in-sample avg dev_std = 0.189)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.529
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.531
SUFF++ for r=0.3 class 0.0 = 0.753 +- 0.067 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.3 class 1.0 = 0.748 +- 0.067 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.3 all KL = 0.917 +- 0.067 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.3 all L1 = 0.749 +- 0.086 (in-sample avg dev_std = 0.245)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.6
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.614
SUFF++ for r=0.6 class 0.0 = 0.743 +- 0.093 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.6 class 1.0 = 0.747 +- 0.093 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.6 all KL = 0.892 +- 0.093 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.6 all L1 = 0.746 +- 0.113 (in-sample avg dev_std = 0.251)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.699
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.691
SUFF++ for r=0.9 class 0.0 = 0.825 +- 0.083 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.9 class 1.0 = 0.856 +- 0.083 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.9 all KL = 0.938 +- 0.083 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.9 all L1 = 0.851 +- 0.120 (in-sample avg dev_std = 0.202)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.552
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.55
NEC for r=0.3 class 0.0 = 0.221 +- 0.081 (in-sample avg dev_std = 0.180)
NEC for r=0.3 class 1.0 = 0.226 +- 0.081 (in-sample avg dev_std = 0.180)
NEC for r=0.3 all KL = 0.067 +- 0.081 (in-sample avg dev_std = 0.180)
NEC for r=0.3 all L1 = 0.225 +- 0.112 (in-sample avg dev_std = 0.180)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.776
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.75
NEC for r=0.6 class 0.0 = 0.229 +- 0.111 (in-sample avg dev_std = 0.221)
NEC for r=0.6 class 1.0 = 0.233 +- 0.111 (in-sample avg dev_std = 0.221)
NEC for r=0.6 all KL = 0.109 +- 0.111 (in-sample avg dev_std = 0.221)
NEC for r=0.6 all L1 = 0.233 +- 0.126 (in-sample avg dev_std = 0.221)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.899
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.857
NEC for r=0.9 class 0.0 = 0.224 +- 0.100 (in-sample avg dev_std = 0.196)
NEC for r=0.9 class 1.0 = 0.134 +- 0.100 (in-sample avg dev_std = 0.196)
NEC for r=0.9 all KL = 0.077 +- 0.100 (in-sample avg dev_std = 0.196)
NEC for r=0.9 all L1 = 0.144 +- 0.125 (in-sample avg dev_std = 0.196)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.919
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.862
NEC for r=1.0 class 0.0 = 0.207 +- 0.108 (in-sample avg dev_std = 0.191)
NEC for r=1.0 class 1.0 = 0.105 +- 0.108 (in-sample avg dev_std = 0.191)
NEC for r=1.0 all KL = 0.066 +- 0.108 (in-sample avg dev_std = 0.191)
NEC for r=1.0 all L1 = 0.117 +- 0.120 (in-sample avg dev_std = 0.191)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.531
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.56
NEC for r=0.3 class 0.0 = 0.217 +- 0.061 (in-sample avg dev_std = 0.180)
NEC for r=0.3 class 1.0 = 0.222 +- 0.061 (in-sample avg dev_std = 0.180)
NEC for r=0.3 all KL = 0.061 +- 0.061 (in-sample avg dev_std = 0.180)
NEC for r=0.3 all L1 = 0.221 +- 0.100 (in-sample avg dev_std = 0.180)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.613
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.607
NEC for r=0.6 class 0.0 = 0.262 +- 0.102 (in-sample avg dev_std = 0.224)
NEC for r=0.6 class 1.0 = 0.251 +- 0.102 (in-sample avg dev_std = 0.224)
NEC for r=0.6 all KL = 0.104 +- 0.102 (in-sample avg dev_std = 0.224)
NEC for r=0.6 all L1 = 0.252 +- 0.120 (in-sample avg dev_std = 0.224)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.686
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.662
NEC for r=0.9 class 0.0 = 0.226 +- 0.102 (in-sample avg dev_std = 0.224)
NEC for r=0.9 class 1.0 = 0.189 +- 0.102 (in-sample avg dev_std = 0.224)
NEC for r=0.9 all KL = 0.088 +- 0.102 (in-sample avg dev_std = 0.224)
NEC for r=0.9 all L1 = 0.192 +- 0.129 (in-sample avg dev_std = 0.224)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.664
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.648
NEC for r=1.0 class 0.0 = 0.228 +- 0.109 (in-sample avg dev_std = 0.233)
NEC for r=1.0 class 1.0 = 0.172 +- 0.109 (in-sample avg dev_std = 0.233)
NEC for r=1.0 all KL = 0.084 +- 0.109 (in-sample avg dev_std = 0.233)
NEC for r=1.0 all L1 = 0.177 +- 0.136 (in-sample avg dev_std = 0.233)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.529
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.534
NEC for r=0.3 class 0.0 = 0.202 +- 0.070 (in-sample avg dev_std = 0.184)
NEC for r=0.3 class 1.0 = 0.233 +- 0.070 (in-sample avg dev_std = 0.184)
NEC for r=0.3 all KL = 0.066 +- 0.070 (in-sample avg dev_std = 0.184)
NEC for r=0.3 all L1 = 0.228 +- 0.106 (in-sample avg dev_std = 0.184)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.6
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.614
NEC for r=0.6 class 0.0 = 0.248 +- 0.109 (in-sample avg dev_std = 0.228)
NEC for r=0.6 class 1.0 = 0.254 +- 0.109 (in-sample avg dev_std = 0.228)
NEC for r=0.6 all KL = 0.107 +- 0.109 (in-sample avg dev_std = 0.228)
NEC for r=0.6 all L1 = 0.253 +- 0.122 (in-sample avg dev_std = 0.228)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.699
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.686
NEC for r=0.9 class 0.0 = 0.207 +- 0.113 (in-sample avg dev_std = 0.227)
NEC for r=0.9 class 1.0 = 0.195 +- 0.113 (in-sample avg dev_std = 0.227)
NEC for r=0.9 all KL = 0.094 +- 0.113 (in-sample avg dev_std = 0.227)
NEC for r=0.9 all L1 = 0.197 +- 0.135 (in-sample avg dev_std = 0.227)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.712
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.688
NEC for r=1.0 class 0.0 = 0.208 +- 0.112 (in-sample avg dev_std = 0.228)
NEC for r=1.0 class 1.0 = 0.167 +- 0.112 (in-sample avg dev_std = 0.228)
NEC for r=1.0 all KL = 0.083 +- 0.112 (in-sample avg dev_std = 0.228)
NEC for r=1.0 all L1 = 0.174 +- 0.132 (in-sample avg dev_std = 0.228)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Mar 23 00:37:49 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 03/23/2024 12:37:49 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/23/2024 12:38:20 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/23/2024 12:38:31 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/23/2024 12:38:42 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/23/2024 12:38:58 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/23/2024 12:39:13 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 03/23/2024 12:39:13 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0mUsing feature sampling := feat
self.EF = 0.1
[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:28 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:28 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:28 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:28 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:28 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:28 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:28 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:28 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:28 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:28 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:40:28 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 117...
[0m[1;37mINFO[0m: [1mCheckpoint 117: 
-----------------------------------
Train ROC-AUC: 0.9604
Train Loss: 0.1577
ID Validation ROC-AUC: 0.9213
ID Validation Loss: 0.2276
ID Test ROC-AUC: 0.9231
ID Test Loss: 0.2288
OOD Validation ROC-AUC: 0.6638
OOD Validation Loss: 0.4052
OOD Test ROC-AUC: 0.7105
OOD Test Loss: 0.5421

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 20...
[0m[1;37mINFO[0m: [1mCheckpoint 20: 
-----------------------------------
Train ROC-AUC: 0.8989
Train Loss: 0.2529
ID Validation ROC-AUC: 0.8912
ID Validation Loss: 0.2608
ID Test ROC-AUC: 0.8911
ID Test Loss: 0.2654
OOD Validation ROC-AUC: 0.6866
OOD Validation Loss: 0.2898
OOD Test ROC-AUC: 0.7229
OOD Test Loss: 0.4564

[0m[1;37mINFO[0m: [1mChartInfo 0.9231 0.7105 0.8911 0.7229 0.8912 0.6866[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 03/23/2024 12:40:28 AM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 03/23/2024 12:40:32 AM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 03/23/2024 12:40:37 AM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.634
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.613
SUFF++ for r=0.3 class 0.0 = 0.754 +- 0.076 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.3 class 1.0 = 0.74 +- 0.076 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.3 all KL = 0.911 +- 0.076 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.3 all L1 = 0.741 +- 0.091 (in-sample avg dev_std = 0.250)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.787
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.709
SUFF++ for r=0.6 class 0.0 = 0.708 +- 0.125 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.6 class 1.0 = 0.732 +- 0.125 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.6 all KL = 0.853 +- 0.125 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.6 all L1 = 0.73 +- 0.113 (in-sample avg dev_std = 0.278)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.918
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.882
SUFF++ for r=0.9 class 0.0 = 0.824 +- 0.100 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.9 class 1.0 = 0.887 +- 0.100 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.9 all KL = 0.942 +- 0.100 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.9 all L1 = 0.88 +- 0.120 (in-sample avg dev_std = 0.176)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.473
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.533
SUFF++ for r=0.3 class 0.0 = 0.758 +- 0.067 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.3 class 1.0 = 0.751 +- 0.067 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.3 all KL = 0.919 +- 0.067 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.3 all L1 = 0.752 +- 0.090 (in-sample avg dev_std = 0.240)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.589
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.576
SUFF++ for r=0.6 class 0.0 = 0.737 +- 0.118 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.6 class 1.0 = 0.721 +- 0.118 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.6 all KL = 0.864 +- 0.118 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.6 all L1 = 0.722 +- 0.109 (in-sample avg dev_std = 0.274)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.65
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.641
SUFF++ for r=0.9 class 0.0 = 0.829 +- 0.095 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.9 class 1.0 = 0.84 +- 0.095 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.9 all KL = 0.935 +- 0.095 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.9 all L1 = 0.839 +- 0.120 (in-sample avg dev_std = 0.191)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.523
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.549
SUFF++ for r=0.3 class 0.0 = 0.753 +- 0.065 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.3 class 1.0 = 0.748 +- 0.065 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.3 all KL = 0.917 +- 0.065 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.3 all L1 = 0.749 +- 0.084 (in-sample avg dev_std = 0.250)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.532
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.581
SUFF++ for r=0.6 class 0.0 = 0.723 +- 0.116 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.6 class 1.0 = 0.717 +- 0.116 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.6 all KL = 0.864 +- 0.116 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.6 all L1 = 0.718 +- 0.114 (in-sample avg dev_std = 0.276)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.672
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.65
SUFF++ for r=0.9 class 0.0 = 0.846 +- 0.101 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.9 class 1.0 = 0.834 +- 0.101 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.9 all KL = 0.931 +- 0.101 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.9 all L1 = 0.836 +- 0.125 (in-sample avg dev_std = 0.207)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.634
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.638
NEC for r=0.3 class 0.0 = 0.241 +- 0.089 (in-sample avg dev_std = 0.203)
NEC for r=0.3 class 1.0 = 0.255 +- 0.089 (in-sample avg dev_std = 0.203)
NEC for r=0.3 all KL = 0.085 +- 0.089 (in-sample avg dev_std = 0.203)
NEC for r=0.3 all L1 = 0.253 +- 0.120 (in-sample avg dev_std = 0.203)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.787
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.758
NEC for r=0.6 class 0.0 = 0.274 +- 0.133 (in-sample avg dev_std = 0.266)
NEC for r=0.6 class 1.0 = 0.273 +- 0.133 (in-sample avg dev_std = 0.266)
NEC for r=0.6 all KL = 0.147 +- 0.133 (in-sample avg dev_std = 0.266)
NEC for r=0.6 all L1 = 0.273 +- 0.121 (in-sample avg dev_std = 0.266)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.918
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.846
NEC for r=0.9 class 0.0 = 0.236 +- 0.148 (in-sample avg dev_std = 0.260)
NEC for r=0.9 class 1.0 = 0.188 +- 0.148 (in-sample avg dev_std = 0.260)
NEC for r=0.9 all KL = 0.131 +- 0.148 (in-sample avg dev_std = 0.260)
NEC for r=0.9 all L1 = 0.193 +- 0.139 (in-sample avg dev_std = 0.260)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.921
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.863
NEC for r=1.0 class 0.0 = 0.224 +- 0.157 (in-sample avg dev_std = 0.249)
NEC for r=1.0 class 1.0 = 0.153 +- 0.157 (in-sample avg dev_std = 0.249)
NEC for r=1.0 all KL = 0.113 +- 0.157 (in-sample avg dev_std = 0.249)
NEC for r=1.0 all L1 = 0.161 +- 0.139 (in-sample avg dev_std = 0.249)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.473
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.541
NEC for r=0.3 class 0.0 = 0.215 +- 0.074 (in-sample avg dev_std = 0.197)
NEC for r=0.3 class 1.0 = 0.246 +- 0.074 (in-sample avg dev_std = 0.197)
NEC for r=0.3 all KL = 0.074 +- 0.074 (in-sample avg dev_std = 0.197)
NEC for r=0.3 all L1 = 0.243 +- 0.106 (in-sample avg dev_std = 0.197)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.589
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.582
NEC for r=0.6 class 0.0 = 0.288 +- 0.142 (in-sample avg dev_std = 0.263)
NEC for r=0.6 class 1.0 = 0.292 +- 0.142 (in-sample avg dev_std = 0.263)
NEC for r=0.6 all KL = 0.149 +- 0.142 (in-sample avg dev_std = 0.263)
NEC for r=0.6 all L1 = 0.292 +- 0.129 (in-sample avg dev_std = 0.263)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.65
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.62
NEC for r=0.9 class 0.0 = 0.245 +- 0.126 (in-sample avg dev_std = 0.255)
NEC for r=0.9 class 1.0 = 0.231 +- 0.126 (in-sample avg dev_std = 0.255)
NEC for r=0.9 all KL = 0.12 +- 0.126 (in-sample avg dev_std = 0.255)
NEC for r=0.9 all L1 = 0.232 +- 0.133 (in-sample avg dev_std = 0.255)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.638
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.615
NEC for r=1.0 class 0.0 = 0.21 +- 0.116 (in-sample avg dev_std = 0.241)
NEC for r=1.0 class 1.0 = 0.197 +- 0.116 (in-sample avg dev_std = 0.241)
NEC for r=1.0 all KL = 0.094 +- 0.116 (in-sample avg dev_std = 0.241)
NEC for r=1.0 all L1 = 0.198 +- 0.129 (in-sample avg dev_std = 0.241)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.523
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.509
NEC for r=0.3 class 0.0 = 0.25 +- 0.092 (in-sample avg dev_std = 0.207)
NEC for r=0.3 class 1.0 = 0.254 +- 0.092 (in-sample avg dev_std = 0.207)
NEC for r=0.3 all KL = 0.085 +- 0.092 (in-sample avg dev_std = 0.207)
NEC for r=0.3 all L1 = 0.254 +- 0.120 (in-sample avg dev_std = 0.207)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.532
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.591
NEC for r=0.6 class 0.0 = 0.295 +- 0.133 (in-sample avg dev_std = 0.260)
NEC for r=0.6 class 1.0 = 0.292 +- 0.133 (in-sample avg dev_std = 0.260)
NEC for r=0.6 all KL = 0.143 +- 0.133 (in-sample avg dev_std = 0.260)
NEC for r=0.6 all L1 = 0.293 +- 0.128 (in-sample avg dev_std = 0.260)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.672
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.644
NEC for r=0.9 class 0.0 = 0.228 +- 0.140 (in-sample avg dev_std = 0.270)
NEC for r=0.9 class 1.0 = 0.241 +- 0.140 (in-sample avg dev_std = 0.270)
NEC for r=0.9 all KL = 0.129 +- 0.140 (in-sample avg dev_std = 0.270)
NEC for r=0.9 all L1 = 0.239 +- 0.136 (in-sample avg dev_std = 0.270)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.704
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.662
NEC for r=1.0 class 0.0 = 0.215 +- 0.146 (in-sample avg dev_std = 0.262)
NEC for r=1.0 class 1.0 = 0.216 +- 0.146 (in-sample avg dev_std = 0.262)
NEC for r=1.0 all KL = 0.117 +- 0.146 (in-sample avg dev_std = 0.262)
NEC for r=1.0 all L1 = 0.216 +- 0.144 (in-sample avg dev_std = 0.262)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.814, 0.841, 0.953, 1.0], 'all_L1': [0.67, 0.78, 0.923, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.901, 0.877, 0.982, 1.0], 'all_L1': [0.77, 0.803, 0.951, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.876, 0.905, 0.962, 1.0], 'all_L1': [0.714, 0.822, 0.91, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.913, 0.903, 0.959, 1.0], 'all_L1': [0.744, 0.78, 0.902, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.911, 0.853, 0.942, 1.0], 'all_L1': [0.741, 0.73, 0.88, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.145, 0.132, 0.105, 0.115], 'all_L1': [0.291, 0.197, 0.128, 0.124]}), defaultdict(<class 'list'>, {'all_KL': [0.076, 0.09, 0.093, 0.098], 'all_L1': [0.205, 0.169, 0.138, 0.13]}), defaultdict(<class 'list'>, {'all_KL': [0.098, 0.081, 0.058, 0.063], 'all_L1': [0.259, 0.165, 0.112, 0.112]}), defaultdict(<class 'list'>, {'all_KL': [0.067, 0.109, 0.077, 0.066], 'all_L1': [0.225, 0.233, 0.144, 0.117]}), defaultdict(<class 'list'>, {'all_KL': [0.085, 0.147, 0.131, 0.113], 'all_L1': [0.253, 0.273, 0.193, 0.161]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.822, 0.8, 0.916, 1.0], 'all_L1': [0.666, 0.716, 0.861, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.895, 0.882, 0.972, 1.0], 'all_L1': [0.76, 0.783, 0.922, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.896, 0.888, 0.945, 1.0], 'all_L1': [0.724, 0.772, 0.859, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.924, 0.899, 0.941, 1.0], 'all_L1': [0.755, 0.751, 0.848, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.919, 0.864, 0.935, 1.0], 'all_L1': [0.752, 0.722, 0.839, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.142, 0.162, 0.17, 0.168], 'all_L1': [0.297, 0.251, 0.218, 0.209]}), defaultdict(<class 'list'>, {'all_KL': [0.08, 0.097, 0.128, 0.133], 'all_L1': [0.211, 0.197, 0.205, 0.206]}), defaultdict(<class 'list'>, {'all_KL': [0.089, 0.089, 0.084, 0.081], 'all_L1': [0.26, 0.205, 0.175, 0.174]}), defaultdict(<class 'list'>, {'all_KL': [0.061, 0.104, 0.088, 0.084], 'all_L1': [0.221, 0.252, 0.192, 0.177]}), defaultdict(<class 'list'>, {'all_KL': [0.074, 0.149, 0.12, 0.094], 'all_L1': [0.243, 0.292, 0.232, 0.198]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.816, 0.81, 0.913, 1.0], 'all_L1': [0.666, 0.721, 0.866, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.905, 0.896, 0.969, 1.0], 'all_L1': [0.764, 0.784, 0.913, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.888, 0.88, 0.948, 1.0], 'all_L1': [0.721, 0.764, 0.868, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.917, 0.892, 0.938, 1.0], 'all_L1': [0.749, 0.746, 0.851, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.917, 0.864, 0.931, 1.0], 'all_L1': [0.749, 0.718, 0.836, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.145, 0.166, 0.18, 0.184], 'all_L1': [0.296, 0.258, 0.218, 0.209]}), defaultdict(<class 'list'>, {'all_KL': [0.072, 0.097, 0.14, 0.152], 'all_L1': [0.208, 0.207, 0.222, 0.223]}), defaultdict(<class 'list'>, {'all_KL': [0.091, 0.091, 0.084, 0.078], 'all_L1': [0.255, 0.208, 0.17, 0.167]}), defaultdict(<class 'list'>, {'all_KL': [0.066, 0.107, 0.094, 0.083], 'all_L1': [0.228, 0.253, 0.197, 0.174]}), defaultdict(<class 'list'>, {'all_KL': [0.085, 0.143, 0.129, 0.117], 'all_L1': [0.254, 0.293, 0.239, 0.216]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.728 +- 0.034, 0.783 +- 0.031, 0.913 +- 0.024, 1.000 +- 0.000
suff++ class all_KL  =  0.883 +- 0.037, 0.876 +- 0.026, 0.960 +- 0.013, 1.000 +- 0.000
suff++_acc_int  =  0.605 +- 0.043, 0.756 +- 0.026, 0.881 +- 0.011
nec class all_L1  =  0.247 +- 0.030, 0.207 +- 0.041, 0.143 +- 0.027, 0.129 +- 0.017
nec class all_KL  =  0.094 +- 0.027, 0.112 +- 0.025, 0.093 +- 0.025, 0.091 +- 0.022
nec_acc_int  =  0.620 +- 0.056, 0.775 +- 0.022, 0.852 +- 0.007, 0.864 +- 0.003

Eval split val
suff++ class all_L1  =  0.731 +- 0.035, 0.749 +- 0.026, 0.866 +- 0.029, 1.000 +- 0.000
suff++ class all_KL  =  0.891 +- 0.037, 0.867 +- 0.035, 0.942 +- 0.018, 1.000 +- 0.000
suff++_acc_int  =  0.548 +- 0.014, 0.602 +- 0.017, 0.646 +- 0.015
nec class all_L1  =  0.246 +- 0.031, 0.239 +- 0.035, 0.204 +- 0.020, 0.193 +- 0.015
nec class all_KL  =  0.089 +- 0.028, 0.120 +- 0.029, 0.118 +- 0.031, 0.112 +- 0.034
nec_acc_int  =  0.551 +- 0.031, 0.600 +- 0.015, 0.638 +- 0.015, 0.638 +- 0.014

Eval split test
suff++ class all_L1  =  0.730 +- 0.035, 0.747 +- 0.025, 0.867 +- 0.026, 1.000 +- 0.000
suff++ class all_KL  =  0.889 +- 0.038, 0.868 +- 0.031, 0.940 +- 0.019, 1.000 +- 0.000
suff++_acc_int  =  0.565 +- 0.027, 0.627 +- 0.031, 0.687 +- 0.019
nec class all_L1  =  0.248 +- 0.030, 0.244 +- 0.033, 0.209 +- 0.024, 0.198 +- 0.023
nec class all_KL  =  0.092 +- 0.028, 0.121 +- 0.029, 0.125 +- 0.034, 0.123 +- 0.041
nec_acc_int  =  0.562 +- 0.038, 0.639 +- 0.040, 0.681 +- 0.019, 0.688 +- 0.015


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.487 +- 0.005, 0.495 +- 0.008, 0.528 +- 0.012, 0.564 +- 0.009
Faith. Armon (L1)= 		  =  0.366 +- 0.029, 0.325 +- 0.047, 0.246 +- 0.039, 0.228 +- 0.027
Faith. GMean (L1)= 	  =  0.422 +- 0.016, 0.400 +- 0.031, 0.360 +- 0.030, 0.358 +- 0.023
Faith. Aritm (KL)= 		  =  0.489 +- 0.006, 0.494 +- 0.008, 0.526 +- 0.011, 0.545 +- 0.011
Faith. Armon (KL)= 		  =  0.169 +- 0.042, 0.197 +- 0.038, 0.168 +- 0.041, 0.166 +- 0.038
Faith. GMean (KL)= 	  =  0.285 +- 0.033, 0.311 +- 0.031, 0.296 +- 0.039, 0.299 +- 0.038

Eval split val
Faith. Aritm (L1)= 		  =  0.489 +- 0.005, 0.494 +- 0.009, 0.535 +- 0.017, 0.596 +- 0.007
Faith. Armon (L1)= 		  =  0.367 +- 0.029, 0.361 +- 0.037, 0.330 +- 0.026, 0.323 +- 0.021
Faith. GMean (L1)= 	  =  0.423 +- 0.016, 0.422 +- 0.024, 0.420 +- 0.021, 0.439 +- 0.017
Faith. Aritm (KL)= 		  =  0.490 +- 0.005, 0.493 +- 0.009, 0.530 +- 0.015, 0.556 +- 0.017
Faith. Armon (KL)= 		  =  0.160 +- 0.044, 0.209 +- 0.044, 0.208 +- 0.048, 0.200 +- 0.053
Faith. GMean (KL)= 	  =  0.278 +- 0.035, 0.320 +- 0.033, 0.330 +- 0.042, 0.331 +- 0.049

Eval split test
Faith. Aritm (L1)= 		  =  0.489 +- 0.007, 0.495 +- 0.007, 0.538 +- 0.017, 0.599 +- 0.011
Faith. Armon (L1)= 		  =  0.369 +- 0.028, 0.366 +- 0.034, 0.336 +- 0.031, 0.330 +- 0.032
Faith. GMean (L1)= 	  =  0.424 +- 0.016, 0.425 +- 0.022, 0.425 +- 0.025, 0.444 +- 0.026
Faith. Aritm (KL)= 		  =  0.490 +- 0.007, 0.495 +- 0.007, 0.533 +- 0.016, 0.561 +- 0.020
Faith. Armon (KL)= 		  =  0.165 +- 0.043, 0.210 +- 0.043, 0.219 +- 0.053, 0.216 +- 0.064
Faith. GMean (KL)= 	  =  0.282 +- 0.034, 0.321 +- 0.033, 0.340 +- 0.045, 0.346 +- 0.058
Computed for split load_split = id



Completed in  0:35:54.723428  for LECIvGIN LBAPcore/assay



DONE LECI LBAPcore/assay

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Mar 23 00:45:18 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 03/23/2024 12:45:18 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/23/2024 12:45:56 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/23/2024 12:46:10 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/23/2024 12:46:23 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/23/2024 12:46:39 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/23/2024 12:46:56 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 03/23/2024 12:46:56 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/23/2024 12:48:17 AM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/23/2024 12:48:17 AM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/23/2024 12:48:17 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:48:17 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:48:17 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:48:17 AM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/23/2024 12:48:17 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:48:17 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:48:17 AM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/23/2024 12:48:17 AM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 03/23/2024 12:48:17 AM : [1mInit Backbone:  3
[0m[1;34mDEBUG[0m: 03/23/2024 12:48:17 AM : [1mCreating vGINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/23/2024 12:48:17 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:48:17 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:48:17 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:48:17 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:48:17 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:48:17 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:48:17 AM : [1mInit CLF:  3
[0m[1;34mDEBUG[0m: 03/23/2024 12:48:17 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:48:17 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:48:17 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:48:17 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:48:17 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 23...
[0m[1;37mINFO[0m: [1mCheckpoint 23: 
-----------------------------------
Train ROC-AUC: 0.9686
Train Loss: 0.1597
ID Validation ROC-AUC: 0.9236
ID Validation Loss: 0.2366
ID Test ROC-AUC: 0.9233
ID Test Loss: 0.2412
OOD Validation ROC-AUC: 0.6572
OOD Validation Loss: 0.3846
OOD Test ROC-AUC: 0.6967
OOD Test Loss: 0.5574

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 1...
[0m[1;37mINFO[0m: [1mCheckpoint 1: 
-----------------------------------
Train ROC-AUC: 0.8713
Train Loss: 0.2869
ID Validation ROC-AUC: 0.8665
ID Validation Loss: 0.2911
ID Test ROC-AUC: 0.8695
ID Test Loss: 0.2927
OOD Validation ROC-AUC: 0.6861
OOD Validation Loss: 0.2792
OOD Test ROC-AUC: 0.7034
OOD Test Loss: 0.4207

[0m[1;37mINFO[0m: [1mChartInfo 0.9233 0.6967 0.8695 0.7034 0.8665 0.6861[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 03/23/2024 12:48:18 AM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.6 = nan
WIoU for r=0.6 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 03/23/2024 12:48:28 AM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.6 = nan
WIoU for r=0.6 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 03/23/2024 12:48:36 AM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.625
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.608
SUFF++ for r=0.6 class 0.0 = 0.839 +- 0.057 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.6 class 1.0 = 0.888 +- 0.057 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.6 all KL = 0.951 +- 0.057 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.6 all L1 = 0.882 +- 0.071 (in-sample avg dev_std = 0.131)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.507
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 799
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.526
SUFF++ for r=0.6 class 0.0 = 0.843 +- 0.062 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.6 class 1.0 = 0.88 +- 0.062 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.6 all KL = 0.949 +- 0.062 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.6 all L1 = 0.877 +- 0.073 (in-sample avg dev_std = 0.135)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.566
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.56
SUFF++ for r=0.6 class 0.0 = 0.848 +- 0.073 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.6 class 1.0 = 0.869 +- 0.073 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.6 all KL = 0.941 +- 0.073 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.6 all L1 = 0.866 +- 0.080 (in-sample avg dev_std = 0.145)


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.625
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.641
NEC for r=0.6 class 0.0 = 0.116 +- 0.043 (in-sample avg dev_std = 0.079)
NEC for r=0.6 class 1.0 = 0.071 +- 0.043 (in-sample avg dev_std = 0.079)
NEC for r=0.6 all KL = 0.021 +- 0.043 (in-sample avg dev_std = 0.079)
NEC for r=0.6 all L1 = 0.076 +- 0.070 (in-sample avg dev_std = 0.079)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.514
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.554
NEC for r=0.6 class 0.0 = 0.123 +- 0.054 (in-sample avg dev_std = 0.090)
NEC for r=0.6 class 1.0 = 0.086 +- 0.054 (in-sample avg dev_std = 0.090)
NEC for r=0.6 all KL = 0.028 +- 0.054 (in-sample avg dev_std = 0.090)
NEC for r=0.6 all L1 = 0.089 +- 0.074 (in-sample avg dev_std = 0.090)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.566
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.583
NEC for r=0.6 class 0.0 = 0.107 +- 0.044 (in-sample avg dev_std = 0.083)
NEC for r=0.6 class 1.0 = 0.089 +- 0.044 (in-sample avg dev_std = 0.083)
NEC for r=0.6 all KL = 0.025 +- 0.044 (in-sample avg dev_std = 0.083)
NEC for r=0.6 all L1 = 0.092 +- 0.077 (in-sample avg dev_std = 0.083)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Mar 23 00:50:04 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 03/23/2024 12:50:04 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/23/2024 12:50:38 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/23/2024 12:50:49 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/23/2024 12:51:02 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/23/2024 12:51:21 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/23/2024 12:51:40 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 03/23/2024 12:51:40 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/23/2024 12:53:02 AM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/23/2024 12:53:02 AM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/23/2024 12:53:02 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:53:02 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:53:02 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:53:02 AM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/23/2024 12:53:02 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:53:02 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:53:02 AM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/23/2024 12:53:02 AM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 03/23/2024 12:53:02 AM : [1mInit Backbone:  3
[0m[1;34mDEBUG[0m: 03/23/2024 12:53:02 AM : [1mCreating vGINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/23/2024 12:53:02 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:53:02 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:53:02 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:53:02 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:53:02 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:53:02 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:53:02 AM : [1mInit CLF:  3
[0m[1;34mDEBUG[0m: 03/23/2024 12:53:02 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:53:02 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:53:02 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:53:02 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:53:02 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 37...
[0m[1;37mINFO[0m: [1mCheckpoint 37: 
-----------------------------------
Train ROC-AUC: 0.9829
Train Loss: 0.1261
ID Validation ROC-AUC: 0.9196
ID Validation Loss: 0.2917
ID Test ROC-AUC: 0.9170
ID Test Loss: 0.3056
OOD Validation ROC-AUC: 0.6433
OOD Validation Loss: 0.4965
OOD Test ROC-AUC: 0.6785
OOD Test Loss: 0.7235

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 3...
[0m[1;37mINFO[0m: [1mCheckpoint 3: 
-----------------------------------
Train ROC-AUC: 0.8825
Train Loss: 0.2710
ID Validation ROC-AUC: 0.8746
ID Validation Loss: 0.2831
ID Test ROC-AUC: 0.8768
ID Test Loss: 0.2841
OOD Validation ROC-AUC: 0.6840
OOD Validation Loss: 0.3139
OOD Test ROC-AUC: 0.7101
OOD Test Loss: 0.4991

[0m[1;37mINFO[0m: [1mChartInfo 0.9170 0.6785 0.8768 0.7101 0.8746 0.6840[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 03/23/2024 12:53:03 AM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.6 = nan
WIoU for r=0.6 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 03/23/2024 12:53:11 AM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.6 = nan
WIoU for r=0.6 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 03/23/2024 12:53:20 AM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.714
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.634
SUFF++ for r=0.6 class 0.0 = 0.747 +- 0.177 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.6 class 1.0 = 0.87 +- 0.177 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.6 all KL = 0.843 +- 0.177 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.6 all L1 = 0.855 +- 0.165 (in-sample avg dev_std = 0.249)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.665
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.614
SUFF++ for r=0.6 class 0.0 = 0.743 +- 0.176 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.6 class 1.0 = 0.828 +- 0.176 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.6 all KL = 0.824 +- 0.176 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.6 all L1 = 0.821 +- 0.172 (in-sample avg dev_std = 0.268)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.598
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.569
SUFF++ for r=0.6 class 0.0 = 0.76 +- 0.181 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.6 class 1.0 = 0.826 +- 0.181 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.6 all KL = 0.806 +- 0.181 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.6 all L1 = 0.815 +- 0.171 (in-sample avg dev_std = 0.272)


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.714
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.71
NEC for r=0.6 class 0.0 = 0.245 +- 0.161 (in-sample avg dev_std = 0.159)
NEC for r=0.6 class 1.0 = 0.122 +- 0.161 (in-sample avg dev_std = 0.159)
NEC for r=0.6 all KL = 0.121 +- 0.161 (in-sample avg dev_std = 0.159)
NEC for r=0.6 all L1 = 0.136 +- 0.178 (in-sample avg dev_std = 0.159)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.665
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.647
NEC for r=0.6 class 0.0 = 0.224 +- 0.173 (in-sample avg dev_std = 0.177)
NEC for r=0.6 class 1.0 = 0.171 +- 0.173 (in-sample avg dev_std = 0.177)
NEC for r=0.6 all KL = 0.148 +- 0.173 (in-sample avg dev_std = 0.177)
NEC for r=0.6 all L1 = 0.175 +- 0.192 (in-sample avg dev_std = 0.177)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.598
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.6
NEC for r=0.6 class 0.0 = 0.218 +- 0.167 (in-sample avg dev_std = 0.170)
NEC for r=0.6 class 1.0 = 0.162 +- 0.167 (in-sample avg dev_std = 0.170)
NEC for r=0.6 all KL = 0.147 +- 0.167 (in-sample avg dev_std = 0.170)
NEC for r=0.6 all L1 = 0.171 +- 0.187 (in-sample avg dev_std = 0.170)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Mar 23 00:54:46 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 03/23/2024 12:54:46 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/23/2024 12:55:20 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/23/2024 12:55:31 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/23/2024 12:55:42 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/23/2024 12:56:00 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/23/2024 12:56:16 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 03/23/2024 12:56:16 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/23/2024 12:57:45 AM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/23/2024 12:57:45 AM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/23/2024 12:57:45 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:57:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:57:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:57:45 AM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/23/2024 12:57:45 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:57:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:57:45 AM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/23/2024 12:57:45 AM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 03/23/2024 12:57:45 AM : [1mInit Backbone:  3
[0m[1;34mDEBUG[0m: 03/23/2024 12:57:45 AM : [1mCreating vGINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/23/2024 12:57:45 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:57:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:57:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:57:45 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:57:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:57:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:57:45 AM : [1mInit CLF:  3
[0m[1;34mDEBUG[0m: 03/23/2024 12:57:45 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:57:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:57:45 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 12:57:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 12:57:46 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 15...
[0m[1;37mINFO[0m: [1mCheckpoint 15: 
-----------------------------------
Train ROC-AUC: 0.9540
Train Loss: 0.1749
ID Validation ROC-AUC: 0.9236
ID Validation Loss: 0.2164
ID Test ROC-AUC: 0.9206
ID Test Loss: 0.2244
OOD Validation ROC-AUC: 0.6596
OOD Validation Loss: 0.3480
OOD Test ROC-AUC: 0.6987
OOD Test Loss: 0.4931

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 3...
[0m[1;37mINFO[0m: [1mCheckpoint 3: 
-----------------------------------
Train ROC-AUC: 0.8972
Train Loss: 0.2438
ID Validation ROC-AUC: 0.8845
ID Validation Loss: 0.2539
ID Test ROC-AUC: 0.8865
ID Test Loss: 0.2549
OOD Validation ROC-AUC: 0.6935
OOD Validation Loss: 0.2839
OOD Test ROC-AUC: 0.7162
OOD Test Loss: 0.4332

[0m[1;37mINFO[0m: [1mChartInfo 0.9206 0.6987 0.8865 0.7162 0.8845 0.6935[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 03/23/2024 12:57:46 AM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.6 = nan
WIoU for r=0.6 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 03/23/2024 12:57:54 AM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.6 = nan
WIoU for r=0.6 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 03/23/2024 12:58:04 AM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.656
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.602
SUFF++ for r=0.6 class 0.0 = 0.868 +- 0.017 (in-sample avg dev_std = 0.109)
SUFF++ for r=0.6 class 1.0 = 0.878 +- 0.017 (in-sample avg dev_std = 0.109)
SUFF++ for r=0.6 all KL = 0.983 +- 0.017 (in-sample avg dev_std = 0.109)
SUFF++ for r=0.6 all L1 = 0.877 +- 0.047 (in-sample avg dev_std = 0.109)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.49
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.47
SUFF++ for r=0.6 class 0.0 = 0.882 +- 0.013 (in-sample avg dev_std = 0.103)
SUFF++ for r=0.6 class 1.0 = 0.875 +- 0.013 (in-sample avg dev_std = 0.103)
SUFF++ for r=0.6 all KL = 0.984 +- 0.013 (in-sample avg dev_std = 0.103)
SUFF++ for r=0.6 all L1 = 0.875 +- 0.045 (in-sample avg dev_std = 0.103)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.558
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.545
SUFF++ for r=0.6 class 0.0 = 0.872 +- 0.015 (in-sample avg dev_std = 0.104)
SUFF++ for r=0.6 class 1.0 = 0.875 +- 0.015 (in-sample avg dev_std = 0.104)
SUFF++ for r=0.6 all KL = 0.983 +- 0.015 (in-sample avg dev_std = 0.104)
SUFF++ for r=0.6 all L1 = 0.874 +- 0.047 (in-sample avg dev_std = 0.104)


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.656
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.604
NEC for r=0.6 class 0.0 = 0.075 +- 0.008 (in-sample avg dev_std = 0.055)
NEC for r=0.6 class 1.0 = 0.07 +- 0.008 (in-sample avg dev_std = 0.055)
NEC for r=0.6 all KL = 0.006 +- 0.008 (in-sample avg dev_std = 0.055)
NEC for r=0.6 all L1 = 0.071 +- 0.034 (in-sample avg dev_std = 0.055)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.49
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.472
NEC for r=0.6 class 0.0 = 0.077 +- 0.006 (in-sample avg dev_std = 0.054)
NEC for r=0.6 class 1.0 = 0.068 +- 0.006 (in-sample avg dev_std = 0.054)
NEC for r=0.6 all KL = 0.005 +- 0.006 (in-sample avg dev_std = 0.054)
NEC for r=0.6 all L1 = 0.069 +- 0.034 (in-sample avg dev_std = 0.054)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.558
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.542
NEC for r=0.6 class 0.0 = 0.073 +- 0.008 (in-sample avg dev_std = 0.058)
NEC for r=0.6 class 1.0 = 0.073 +- 0.008 (in-sample avg dev_std = 0.058)
NEC for r=0.6 all KL = 0.006 +- 0.008 (in-sample avg dev_std = 0.058)
NEC for r=0.6 all L1 = 0.073 +- 0.038 (in-sample avg dev_std = 0.058)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Mar 23 00:59:31 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 03/23/2024 12:59:31 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/23/2024 01:00:06 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/23/2024 01:00:18 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/23/2024 01:00:29 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/23/2024 01:00:46 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/23/2024 01:01:04 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 03/23/2024 01:01:04 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/23/2024 01:02:25 AM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/23/2024 01:02:25 AM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/23/2024 01:02:25 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:02:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:02:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:02:25 AM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/23/2024 01:02:25 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:02:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:02:25 AM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/23/2024 01:02:25 AM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 03/23/2024 01:02:25 AM : [1mInit Backbone:  3
[0m[1;34mDEBUG[0m: 03/23/2024 01:02:25 AM : [1mCreating vGINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/23/2024 01:02:25 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:02:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:02:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:02:26 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:02:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:02:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:02:26 AM : [1mInit CLF:  3
[0m[1;34mDEBUG[0m: 03/23/2024 01:02:26 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:02:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:02:26 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:02:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:02:26 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 31...
[0m[1;37mINFO[0m: [1mCheckpoint 31: 
-----------------------------------
Train ROC-AUC: 0.9785
Train Loss: 0.1297
ID Validation ROC-AUC: 0.9231
ID Validation Loss: 0.2533
ID Test ROC-AUC: 0.9232
ID Test Loss: 0.2591
OOD Validation ROC-AUC: 0.6355
OOD Validation Loss: 0.4365
OOD Test ROC-AUC: 0.6820
OOD Test Loss: 0.6119

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 7...
[0m[1;37mINFO[0m: [1mCheckpoint 7: 
-----------------------------------
Train ROC-AUC: 0.9090
Train Loss: 0.2539
ID Validation ROC-AUC: 0.8928
ID Validation Loss: 0.2745
ID Test ROC-AUC: 0.8905
ID Test Loss: 0.2822
OOD Validation ROC-AUC: 0.6800
OOD Validation Loss: 0.3263
OOD Test ROC-AUC: 0.7103
OOD Test Loss: 0.5223

[0m[1;37mINFO[0m: [1mChartInfo 0.9232 0.6820 0.8905 0.7103 0.8928 0.6800[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 03/23/2024 01:02:26 AM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.6 = nan
WIoU for r=0.6 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 03/23/2024 01:02:36 AM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.6 = nan
WIoU for r=0.6 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 03/23/2024 01:02:45 AM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.611
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.625
SUFF++ for r=0.6 class 0.0 = 0.672 +- 0.227 (in-sample avg dev_std = 0.369)
SUFF++ for r=0.6 class 1.0 = 0.654 +- 0.227 (in-sample avg dev_std = 0.369)
SUFF++ for r=0.6 all KL = 0.771 +- 0.227 (in-sample avg dev_std = 0.369)
SUFF++ for r=0.6 all L1 = 0.656 +- 0.161 (in-sample avg dev_std = 0.369)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.582
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.581
SUFF++ for r=0.6 class 0.0 = 0.659 +- 0.208 (in-sample avg dev_std = 0.349)
SUFF++ for r=0.6 class 1.0 = 0.648 +- 0.208 (in-sample avg dev_std = 0.349)
SUFF++ for r=0.6 all KL = 0.778 +- 0.208 (in-sample avg dev_std = 0.349)
SUFF++ for r=0.6 all L1 = 0.649 +- 0.162 (in-sample avg dev_std = 0.349)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.516
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.55
SUFF++ for r=0.6 class 0.0 = 0.64 +- 0.224 (in-sample avg dev_std = 0.363)
SUFF++ for r=0.6 class 1.0 = 0.649 +- 0.224 (in-sample avg dev_std = 0.363)
SUFF++ for r=0.6 all KL = 0.768 +- 0.224 (in-sample avg dev_std = 0.363)
SUFF++ for r=0.6 all L1 = 0.648 +- 0.164 (in-sample avg dev_std = 0.363)


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.611
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.578
NEC for r=0.6 class 0.0 = 0.203 +- 0.144 (in-sample avg dev_std = 0.230)
NEC for r=0.6 class 1.0 = 0.214 +- 0.144 (in-sample avg dev_std = 0.230)
NEC for r=0.6 all KL = 0.101 +- 0.144 (in-sample avg dev_std = 0.230)
NEC for r=0.6 all L1 = 0.213 +- 0.140 (in-sample avg dev_std = 0.230)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.582
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.555
NEC for r=0.6 class 0.0 = 0.253 +- 0.137 (in-sample avg dev_std = 0.233)
NEC for r=0.6 class 1.0 = 0.231 +- 0.137 (in-sample avg dev_std = 0.233)
NEC for r=0.6 all KL = 0.107 +- 0.137 (in-sample avg dev_std = 0.233)
NEC for r=0.6 all L1 = 0.233 +- 0.145 (in-sample avg dev_std = 0.233)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.516
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.52
NEC for r=0.6 class 0.0 = 0.221 +- 0.141 (in-sample avg dev_std = 0.224)
NEC for r=0.6 class 1.0 = 0.213 +- 0.141 (in-sample avg dev_std = 0.224)
NEC for r=0.6 all KL = 0.099 +- 0.141 (in-sample avg dev_std = 0.224)
NEC for r=0.6 all L1 = 0.214 +- 0.146 (in-sample avg dev_std = 0.224)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Mar 23 01:04:14 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 03/23/2024 01:04:14 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/23/2024 01:04:50 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/23/2024 01:05:01 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/23/2024 01:05:13 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/23/2024 01:05:30 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/23/2024 01:05:48 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 03/23/2024 01:05:48 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/23/2024 01:07:13 AM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/23/2024 01:07:13 AM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/23/2024 01:07:13 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:07:13 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:07:13 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:07:13 AM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 03/23/2024 01:07:13 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:07:13 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:07:13 AM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/23/2024 01:07:13 AM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 03/23/2024 01:07:13 AM : [1mInit Backbone:  3
[0m[1;34mDEBUG[0m: 03/23/2024 01:07:13 AM : [1mCreating vGINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 03/23/2024 01:07:13 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:07:13 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:07:13 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:07:13 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:07:13 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:07:13 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:07:13 AM : [1mInit CLF:  3
[0m[1;34mDEBUG[0m: 03/23/2024 01:07:13 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:07:13 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:07:13 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:07:13 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:07:13 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 24...
[0m[1;37mINFO[0m: [1mCheckpoint 24: 
-----------------------------------
Train ROC-AUC: 0.9685
Train Loss: 0.1653
ID Validation ROC-AUC: 0.9224
ID Validation Loss: 0.2315
ID Test ROC-AUC: 0.9196
ID Test Loss: 0.2391
OOD Validation ROC-AUC: 0.6434
OOD Validation Loss: 0.3691
OOD Test ROC-AUC: 0.6778
OOD Test Loss: 0.5284

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 3...
[0m[1;37mINFO[0m: [1mCheckpoint 3: 
-----------------------------------
Train ROC-AUC: 0.8955
Train Loss: 0.2439
ID Validation ROC-AUC: 0.8855
ID Validation Loss: 0.2541
ID Test ROC-AUC: 0.8869
ID Test Loss: 0.2554
OOD Validation ROC-AUC: 0.6944
OOD Validation Loss: 0.2933
OOD Test ROC-AUC: 0.7180
OOD Test Loss: 0.4561

[0m[1;37mINFO[0m: [1mChartInfo 0.9196 0.6778 0.8869 0.7180 0.8855 0.6944[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 03/23/2024 01:07:13 AM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.6 = nan
WIoU for r=0.6 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 03/23/2024 01:07:24 AM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.6 = nan
WIoU for r=0.6 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 03/23/2024 01:07:33 AM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.317
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.414
SUFF++ for r=0.6 class 0.0 = 0.856 +- 0.017 (in-sample avg dev_std = 0.096)
SUFF++ for r=0.6 class 1.0 = 0.894 +- 0.017 (in-sample avg dev_std = 0.096)
SUFF++ for r=0.6 all KL = 0.986 +- 0.017 (in-sample avg dev_std = 0.096)
SUFF++ for r=0.6 all L1 = 0.89 +- 0.054 (in-sample avg dev_std = 0.096)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.452
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.478
SUFF++ for r=0.6 class 0.0 = 0.873 +- 0.019 (in-sample avg dev_std = 0.100)
SUFF++ for r=0.6 class 1.0 = 0.888 +- 0.019 (in-sample avg dev_std = 0.100)
SUFF++ for r=0.6 all KL = 0.985 +- 0.019 (in-sample avg dev_std = 0.100)
SUFF++ for r=0.6 all L1 = 0.887 +- 0.056 (in-sample avg dev_std = 0.100)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.388
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.431
SUFF++ for r=0.6 class 0.0 = 0.868 +- 0.015 (in-sample avg dev_std = 0.100)
SUFF++ for r=0.6 class 1.0 = 0.89 +- 0.015 (in-sample avg dev_std = 0.100)
SUFF++ for r=0.6 all KL = 0.986 +- 0.015 (in-sample avg dev_std = 0.100)
SUFF++ for r=0.6 all L1 = 0.886 +- 0.054 (in-sample avg dev_std = 0.100)


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.317
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.316
NEC for r=0.6 class 0.0 = 0.067 +- 0.004 (in-sample avg dev_std = 0.043)
NEC for r=0.6 class 1.0 = 0.052 +- 0.004 (in-sample avg dev_std = 0.043)
NEC for r=0.6 all KL = 0.003 +- 0.004 (in-sample avg dev_std = 0.043)
NEC for r=0.6 all L1 = 0.054 +- 0.027 (in-sample avg dev_std = 0.043)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.452
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.419
NEC for r=0.6 class 0.0 = 0.067 +- 0.007 (in-sample avg dev_std = 0.044)
NEC for r=0.6 class 1.0 = 0.056 +- 0.007 (in-sample avg dev_std = 0.044)
NEC for r=0.6 all KL = 0.004 +- 0.007 (in-sample avg dev_std = 0.044)
NEC for r=0.6 all L1 = 0.057 +- 0.034 (in-sample avg dev_std = 0.044)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.388
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.365
NEC for r=0.6 class 0.0 = 0.067 +- 0.005 (in-sample avg dev_std = 0.046)
NEC for r=0.6 class 1.0 = 0.059 +- 0.005 (in-sample avg dev_std = 0.046)
NEC for r=0.6 all KL = 0.004 +- 0.005 (in-sample avg dev_std = 0.046)
NEC for r=0.6 all L1 = 0.06 +- 0.034 (in-sample avg dev_std = 0.046)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.951], 'all_L1': [0.882]}), defaultdict(<class 'list'>, {'all_KL': [0.843], 'all_L1': [0.855]}), defaultdict(<class 'list'>, {'all_KL': [0.983], 'all_L1': [0.877]}), defaultdict(<class 'list'>, {'all_KL': [0.771], 'all_L1': [0.656]}), defaultdict(<class 'list'>, {'all_KL': [0.986], 'all_L1': [0.89]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.021], 'all_L1': [0.076]}), defaultdict(<class 'list'>, {'all_KL': [0.121], 'all_L1': [0.136]}), defaultdict(<class 'list'>, {'all_KL': [0.006], 'all_L1': [0.071]}), defaultdict(<class 'list'>, {'all_KL': [0.101], 'all_L1': [0.213]}), defaultdict(<class 'list'>, {'all_KL': [0.003], 'all_L1': [0.054]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.949], 'all_L1': [0.877]}), defaultdict(<class 'list'>, {'all_KL': [0.824], 'all_L1': [0.821]}), defaultdict(<class 'list'>, {'all_KL': [0.984], 'all_L1': [0.875]}), defaultdict(<class 'list'>, {'all_KL': [0.778], 'all_L1': [0.649]}), defaultdict(<class 'list'>, {'all_KL': [0.985], 'all_L1': [0.887]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.028], 'all_L1': [0.089]}), defaultdict(<class 'list'>, {'all_KL': [0.148], 'all_L1': [0.175]}), defaultdict(<class 'list'>, {'all_KL': [0.005], 'all_L1': [0.069]}), defaultdict(<class 'list'>, {'all_KL': [0.107], 'all_L1': [0.233]}), defaultdict(<class 'list'>, {'all_KL': [0.004], 'all_L1': [0.057]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.941], 'all_L1': [0.866]}), defaultdict(<class 'list'>, {'all_KL': [0.806], 'all_L1': [0.815]}), defaultdict(<class 'list'>, {'all_KL': [0.983], 'all_L1': [0.874]}), defaultdict(<class 'list'>, {'all_KL': [0.768], 'all_L1': [0.648]}), defaultdict(<class 'list'>, {'all_KL': [0.986], 'all_L1': [0.886]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.025], 'all_L1': [0.092]}), defaultdict(<class 'list'>, {'all_KL': [0.147], 'all_L1': [0.171]}), defaultdict(<class 'list'>, {'all_KL': [0.006], 'all_L1': [0.073]}), defaultdict(<class 'list'>, {'all_KL': [0.099], 'all_L1': [0.214]}), defaultdict(<class 'list'>, {'all_KL': [0.004], 'all_L1': [0.06]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.832 +- 0.089
suff++ class all_KL  =  0.907 +- 0.085
suff++_acc_int  =  0.577 +- 0.082
nec class all_L1  =  0.110 +- 0.058
nec class all_KL  =  0.050 +- 0.050
nec_acc_int  =  0.570 +- 0.134

Eval split val
suff++ class all_L1  =  0.822 +- 0.089
suff++ class all_KL  =  0.904 +- 0.086
suff++_acc_int  =  0.534 +- 0.056
nec class all_L1  =  0.125 +- 0.068
nec class all_KL  =  0.058 +- 0.059
nec_acc_int  =  0.529 +- 0.078

Eval split test
suff++ class all_L1  =  0.818 +- 0.088
suff++ class all_KL  =  0.897 +- 0.092
suff++_acc_int  =  0.531 +- 0.051
nec class all_L1  =  0.122 +- 0.060
nec class all_KL  =  0.056 +- 0.057
nec_acc_int  =  0.522 +- 0.083


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.471 +- 0.020
Faith. Armon (L1)= 		  =  0.186 +- 0.081
Faith. GMean (L1)= 	  =  0.288 +- 0.059
Faith. Aritm (KL)= 		  =  0.479 +- 0.022
Faith. Armon (KL)= 		  =  0.090 +- 0.087
Faith. GMean (KL)= 	  =  0.174 +- 0.107

Eval split val
Faith. Aritm (L1)= 		  =  0.473 +- 0.019
Faith. Armon (L1)= 		  =  0.206 +- 0.093
Faith. GMean (L1)= 	  =  0.304 +- 0.068
Faith. Aritm (KL)= 		  =  0.481 +- 0.020
Faith. Armon (KL)= 		  =  0.102 +- 0.099
Faith. GMean (KL)= 	  =  0.187 +- 0.115

Eval split test
Faith. Aritm (L1)= 		  =  0.470 +- 0.021
Faith. Armon (L1)= 		  =  0.204 +- 0.083
Faith. GMean (L1)= 	  =  0.302 +- 0.060
Faith. Aritm (KL)= 		  =  0.477 +- 0.023
Faith. Armon (KL)= 		  =  0.099 +- 0.097
Faith. GMean (KL)= 	  =  0.183 +- 0.111
Computed for split load_split = id



Completed in  0:23:51.216046  for CIGAvGIN LBAPcore/assay



DONE CIGA LBAPcore/assay

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Mar 23 01:09:24 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 03/23/2024 01:09:24 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/23/2024 01:10:00 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/23/2024 01:10:11 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/23/2024 01:10:23 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/23/2024 01:10:42 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/23/2024 01:11:00 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 03/23/2024 01:11:00 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/23/2024 01:12:21 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:12:21 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:12:21 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:12:21 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:12:21 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:12:21 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:12:21 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:12:21 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:12:21 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:12:21 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:12:21 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:12:21 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:12:22 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 187...
[0m[1;37mINFO[0m: [1mCheckpoint 187: 
-----------------------------------
Train ROC-AUC: 0.9769
Train Loss: 0.1241
ID Validation ROC-AUC: 0.9251
ID Validation Loss: 0.2646
ID Test ROC-AUC: 0.9244
ID Test Loss: 0.2693
OOD Validation ROC-AUC: 0.6274
OOD Validation Loss: 0.5719
OOD Test ROC-AUC: 0.7014
OOD Test Loss: 0.7027

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 3...
[0m[1;37mINFO[0m: [1mCheckpoint 3: 
-----------------------------------
Train ROC-AUC: 0.8627
Train Loss: 0.3460
ID Validation ROC-AUC: 0.8591
ID Validation Loss: 0.3495
ID Test ROC-AUC: 0.8621
ID Test Loss: 0.3525
OOD Validation ROC-AUC: 0.7045
OOD Validation Loss: 0.2921
OOD Test ROC-AUC: 0.7135
OOD Test Loss: 0.5263

[0m[1;37mINFO[0m: [1mChartInfo 0.9244 0.7014 0.8621 0.7135 0.8591 0.7045[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 03/23/2024 01:12:23 AM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 03/23/2024 01:12:28 AM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 03/23/2024 01:12:33 AM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.645
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.597
SUFF++ for r=0.3 class 0.0 = 0.657 +- 0.249 (in-sample avg dev_std = 0.619)
SUFF++ for r=0.3 class 1.0 = 0.589 +- 0.249 (in-sample avg dev_std = 0.619)
SUFF++ for r=0.3 all KL = 0.524 +- 0.249 (in-sample avg dev_std = 0.619)
SUFF++ for r=0.3 all L1 = 0.597 +- 0.175 (in-sample avg dev_std = 0.619)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.679
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.623
SUFF++ for r=0.6 class 0.0 = 0.672 +- 0.254 (in-sample avg dev_std = 0.556)
SUFF++ for r=0.6 class 1.0 = 0.633 +- 0.254 (in-sample avg dev_std = 0.556)
SUFF++ for r=0.6 all KL = 0.607 +- 0.254 (in-sample avg dev_std = 0.556)
SUFF++ for r=0.6 all L1 = 0.637 +- 0.191 (in-sample avg dev_std = 0.556)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.692
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.669
SUFF++ for r=0.9 class 0.0 = 0.802 +- 0.198 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.9 class 1.0 = 0.732 +- 0.198 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.9 all KL = 0.814 +- 0.198 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.9 all L1 = 0.74 +- 0.195 (in-sample avg dev_std = 0.338)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.535
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.529
SUFF++ for r=0.3 class 0.0 = 0.592 +- 0.256 (in-sample avg dev_std = 0.626)
SUFF++ for r=0.3 class 1.0 = 0.599 +- 0.256 (in-sample avg dev_std = 0.626)
SUFF++ for r=0.3 all KL = 0.518 +- 0.256 (in-sample avg dev_std = 0.626)
SUFF++ for r=0.3 all L1 = 0.599 +- 0.177 (in-sample avg dev_std = 0.626)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.553
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.58
SUFF++ for r=0.6 class 0.0 = 0.648 +- 0.242 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.6 class 1.0 = 0.621 +- 0.242 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.6 all KL = 0.605 +- 0.242 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.6 all L1 = 0.623 +- 0.186 (in-sample avg dev_std = 0.558)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.58
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.597
SUFF++ for r=0.9 class 0.0 = 0.766 +- 0.186 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.9 class 1.0 = 0.745 +- 0.186 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.9 all KL = 0.832 +- 0.186 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.9 all L1 = 0.747 +- 0.190 (in-sample avg dev_std = 0.317)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.595
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.563
SUFF++ for r=0.3 class 0.0 = 0.638 +- 0.258 (in-sample avg dev_std = 0.625)
SUFF++ for r=0.3 class 1.0 = 0.611 +- 0.258 (in-sample avg dev_std = 0.625)
SUFF++ for r=0.3 all KL = 0.522 +- 0.258 (in-sample avg dev_std = 0.625)
SUFF++ for r=0.3 all L1 = 0.615 +- 0.174 (in-sample avg dev_std = 0.625)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.6
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.586
SUFF++ for r=0.6 class 0.0 = 0.665 +- 0.257 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.6 class 1.0 = 0.642 +- 0.257 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.6 all KL = 0.602 +- 0.257 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.6 all L1 = 0.646 +- 0.187 (in-sample avg dev_std = 0.568)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.62
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.602
SUFF++ for r=0.9 class 0.0 = 0.782 +- 0.198 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 class 1.0 = 0.742 +- 0.198 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 all KL = 0.819 +- 0.198 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 all L1 = 0.749 +- 0.192 (in-sample avg dev_std = 0.346)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.645
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.667
NEC for r=0.3 class 0.0 = 0.238 +- 0.272 (in-sample avg dev_std = 0.381)
NEC for r=0.3 class 1.0 = 0.257 +- 0.272 (in-sample avg dev_std = 0.381)
NEC for r=0.3 all KL = 0.238 +- 0.272 (in-sample avg dev_std = 0.381)
NEC for r=0.3 all L1 = 0.255 +- 0.236 (in-sample avg dev_std = 0.381)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.678
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.689
NEC for r=0.6 class 0.0 = 0.216 +- 0.233 (in-sample avg dev_std = 0.366)
NEC for r=0.6 class 1.0 = 0.234 +- 0.233 (in-sample avg dev_std = 0.366)
NEC for r=0.6 all KL = 0.198 +- 0.233 (in-sample avg dev_std = 0.366)
NEC for r=0.6 all L1 = 0.232 +- 0.210 (in-sample avg dev_std = 0.366)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.692
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.692
NEC for r=0.9 class 0.0 = 0.188 +- 0.167 (in-sample avg dev_std = 0.314)
NEC for r=0.9 class 1.0 = 0.225 +- 0.167 (in-sample avg dev_std = 0.314)
NEC for r=0.9 all KL = 0.144 +- 0.167 (in-sample avg dev_std = 0.314)
NEC for r=0.9 all L1 = 0.221 +- 0.171 (in-sample avg dev_std = 0.314)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.7
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.704
NEC for r=1.0 class 0.0 = 0.18 +- 0.142 (in-sample avg dev_std = 0.276)
NEC for r=1.0 class 1.0 = 0.208 +- 0.142 (in-sample avg dev_std = 0.276)
NEC for r=1.0 all KL = 0.116 +- 0.142 (in-sample avg dev_std = 0.276)
NEC for r=1.0 all L1 = 0.205 +- 0.155 (in-sample avg dev_std = 0.276)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.535
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.563
NEC for r=0.3 class 0.0 = 0.286 +- 0.284 (in-sample avg dev_std = 0.408)
NEC for r=0.3 class 1.0 = 0.263 +- 0.284 (in-sample avg dev_std = 0.408)
NEC for r=0.3 all KL = 0.26 +- 0.284 (in-sample avg dev_std = 0.408)
NEC for r=0.3 all L1 = 0.265 +- 0.240 (in-sample avg dev_std = 0.408)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.553
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.596
NEC for r=0.6 class 0.0 = 0.262 +- 0.236 (in-sample avg dev_std = 0.380)
NEC for r=0.6 class 1.0 = 0.252 +- 0.236 (in-sample avg dev_std = 0.380)
NEC for r=0.6 all KL = 0.213 +- 0.236 (in-sample avg dev_std = 0.380)
NEC for r=0.6 all L1 = 0.253 +- 0.215 (in-sample avg dev_std = 0.380)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.58
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.602
NEC for r=0.9 class 0.0 = 0.242 +- 0.173 (in-sample avg dev_std = 0.309)
NEC for r=0.9 class 1.0 = 0.226 +- 0.173 (in-sample avg dev_std = 0.309)
NEC for r=0.9 all KL = 0.146 +- 0.173 (in-sample avg dev_std = 0.309)
NEC for r=0.9 all L1 = 0.228 +- 0.175 (in-sample avg dev_std = 0.309)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.582
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.593
NEC for r=1.0 class 0.0 = 0.215 +- 0.141 (in-sample avg dev_std = 0.279)
NEC for r=1.0 class 1.0 = 0.205 +- 0.141 (in-sample avg dev_std = 0.279)
NEC for r=1.0 all KL = 0.115 +- 0.141 (in-sample avg dev_std = 0.279)
NEC for r=1.0 all L1 = 0.206 +- 0.153 (in-sample avg dev_std = 0.279)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.595
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.607
NEC for r=0.3 class 0.0 = 0.239 +- 0.291 (in-sample avg dev_std = 0.390)
NEC for r=0.3 class 1.0 = 0.25 +- 0.291 (in-sample avg dev_std = 0.390)
NEC for r=0.3 all KL = 0.242 +- 0.291 (in-sample avg dev_std = 0.390)
NEC for r=0.3 all L1 = 0.248 +- 0.242 (in-sample avg dev_std = 0.390)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.6
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.597
NEC for r=0.6 class 0.0 = 0.215 +- 0.243 (in-sample avg dev_std = 0.357)
NEC for r=0.6 class 1.0 = 0.229 +- 0.243 (in-sample avg dev_std = 0.357)
NEC for r=0.6 all KL = 0.198 +- 0.243 (in-sample avg dev_std = 0.357)
NEC for r=0.6 all L1 = 0.227 +- 0.216 (in-sample avg dev_std = 0.357)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.62
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.602
NEC for r=0.9 class 0.0 = 0.211 +- 0.172 (in-sample avg dev_std = 0.301)
NEC for r=0.9 class 1.0 = 0.22 +- 0.172 (in-sample avg dev_std = 0.301)
NEC for r=0.9 all KL = 0.144 +- 0.172 (in-sample avg dev_std = 0.301)
NEC for r=0.9 all L1 = 0.219 +- 0.176 (in-sample avg dev_std = 0.301)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.615
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.608
NEC for r=1.0 class 0.0 = 0.193 +- 0.155 (in-sample avg dev_std = 0.269)
NEC for r=1.0 class 1.0 = 0.205 +- 0.155 (in-sample avg dev_std = 0.269)
NEC for r=1.0 all KL = 0.119 +- 0.155 (in-sample avg dev_std = 0.269)
NEC for r=1.0 all L1 = 0.203 +- 0.157 (in-sample avg dev_std = 0.269)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Mar 23 01:17:04 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 03/23/2024 01:17:04 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/23/2024 01:17:37 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/23/2024 01:17:48 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/23/2024 01:17:59 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/23/2024 01:18:16 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/23/2024 01:18:32 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 03/23/2024 01:18:32 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/23/2024 01:20:01 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:20:01 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:20:01 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:20:01 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:20:01 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:20:01 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:20:01 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:20:01 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:20:01 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:20:01 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:20:01 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:20:01 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:20:01 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 120...
[0m[1;37mINFO[0m: [1mCheckpoint 120: 
-----------------------------------
Train ROC-AUC: 0.9559
Train Loss: 0.1818
ID Validation ROC-AUC: 0.9207
ID Validation Loss: 0.2309
ID Test ROC-AUC: 0.9188
ID Test Loss: 0.2372
OOD Validation ROC-AUC: 0.6575
OOD Validation Loss: 0.3564
OOD Test ROC-AUC: 0.7045
OOD Test Loss: 0.5081

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 6...
[0m[1;37mINFO[0m: [1mCheckpoint 6: 
-----------------------------------
Train ROC-AUC: 0.8717
Train Loss: 0.3292
ID Validation ROC-AUC: 0.8694
ID Validation Loss: 0.3314
ID Test ROC-AUC: 0.8710
ID Test Loss: 0.3354
OOD Validation ROC-AUC: 0.7102
OOD Validation Loss: 0.2911
OOD Test ROC-AUC: 0.7280
OOD Test Loss: 0.5120

[0m[1;37mINFO[0m: [1mChartInfo 0.9188 0.7045 0.8710 0.7280 0.8694 0.7102[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 03/23/2024 01:20:01 AM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 03/23/2024 01:20:06 AM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 03/23/2024 01:20:10 AM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.728
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.704
SUFF++ for r=0.3 class 0.0 = 0.685 +- 0.114 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.3 class 1.0 = 0.744 +- 0.114 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.3 all KL = 0.859 +- 0.114 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.3 all L1 = 0.737 +- 0.131 (in-sample avg dev_std = 0.321)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.774
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.743
SUFF++ for r=0.6 class 0.0 = 0.699 +- 0.133 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.6 class 1.0 = 0.761 +- 0.133 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.6 all KL = 0.854 +- 0.133 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.6 all L1 = 0.754 +- 0.146 (in-sample avg dev_std = 0.315)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.814
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.784
SUFF++ for r=0.9 class 0.0 = 0.812 +- 0.094 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.9 class 1.0 = 0.861 +- 0.094 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.9 all KL = 0.932 +- 0.094 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.9 all L1 = 0.855 +- 0.128 (in-sample avg dev_std = 0.171)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.548
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.56
SUFF++ for r=0.3 class 0.0 = 0.698 +- 0.123 (in-sample avg dev_std = 0.347)
SUFF++ for r=0.3 class 1.0 = 0.69 +- 0.123 (in-sample avg dev_std = 0.347)
SUFF++ for r=0.3 all KL = 0.834 +- 0.123 (in-sample avg dev_std = 0.347)
SUFF++ for r=0.3 all L1 = 0.691 +- 0.124 (in-sample avg dev_std = 0.347)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.553
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 799
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.573
SUFF++ for r=0.6 class 0.0 = 0.707 +- 0.137 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.6 class 1.0 = 0.707 +- 0.137 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.6 all KL = 0.832 +- 0.137 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.6 all L1 = 0.707 +- 0.143 (in-sample avg dev_std = 0.339)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.604
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.581
SUFF++ for r=0.9 class 0.0 = 0.832 +- 0.106 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.9 class 1.0 = 0.822 +- 0.106 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.9 all KL = 0.924 +- 0.106 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.9 all L1 = 0.823 +- 0.135 (in-sample avg dev_std = 0.194)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.669
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.62
SUFF++ for r=0.3 class 0.0 = 0.683 +- 0.115 (in-sample avg dev_std = 0.345)
SUFF++ for r=0.3 class 1.0 = 0.703 +- 0.115 (in-sample avg dev_std = 0.345)
SUFF++ for r=0.3 all KL = 0.839 +- 0.115 (in-sample avg dev_std = 0.345)
SUFF++ for r=0.3 all L1 = 0.7 +- 0.122 (in-sample avg dev_std = 0.345)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.678
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.627
SUFF++ for r=0.6 class 0.0 = 0.712 +- 0.135 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.6 class 1.0 = 0.729 +- 0.135 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.6 all KL = 0.846 +- 0.135 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.6 all L1 = 0.726 +- 0.143 (in-sample avg dev_std = 0.326)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.691
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.659
SUFF++ for r=0.9 class 0.0 = 0.817 +- 0.096 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.9 class 1.0 = 0.831 +- 0.096 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.9 all KL = 0.929 +- 0.096 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.9 all L1 = 0.829 +- 0.126 (in-sample avg dev_std = 0.185)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.728
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.684
NEC for r=0.3 class 0.0 = 0.266 +- 0.092 (in-sample avg dev_std = 0.207)
NEC for r=0.3 class 1.0 = 0.186 +- 0.092 (in-sample avg dev_std = 0.207)
NEC for r=0.3 all KL = 0.077 +- 0.092 (in-sample avg dev_std = 0.207)
NEC for r=0.3 all L1 = 0.195 +- 0.130 (in-sample avg dev_std = 0.207)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.774
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.76
NEC for r=0.6 class 0.0 = 0.217 +- 0.102 (in-sample avg dev_std = 0.223)
NEC for r=0.6 class 1.0 = 0.18 +- 0.102 (in-sample avg dev_std = 0.223)
NEC for r=0.6 all KL = 0.085 +- 0.102 (in-sample avg dev_std = 0.223)
NEC for r=0.6 all L1 = 0.184 +- 0.128 (in-sample avg dev_std = 0.223)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.814
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.804
NEC for r=0.9 class 0.0 = 0.18 +- 0.069 (in-sample avg dev_std = 0.163)
NEC for r=0.9 class 1.0 = 0.116 +- 0.069 (in-sample avg dev_std = 0.163)
NEC for r=0.9 all KL = 0.05 +- 0.069 (in-sample avg dev_std = 0.163)
NEC for r=0.9 all L1 = 0.123 +- 0.108 (in-sample avg dev_std = 0.163)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.817
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.804
NEC for r=1.0 class 0.0 = 0.148 +- 0.048 (in-sample avg dev_std = 0.127)
NEC for r=1.0 class 1.0 = 0.093 +- 0.048 (in-sample avg dev_std = 0.127)
NEC for r=1.0 all KL = 0.033 +- 0.048 (in-sample avg dev_std = 0.127)
NEC for r=1.0 all L1 = 0.1 +- 0.084 (in-sample avg dev_std = 0.127)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.549
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.547
NEC for r=0.3 class 0.0 = 0.255 +- 0.111 (in-sample avg dev_std = 0.242)
NEC for r=0.3 class 1.0 = 0.24 +- 0.111 (in-sample avg dev_std = 0.242)
NEC for r=0.3 all KL = 0.102 +- 0.111 (in-sample avg dev_std = 0.242)
NEC for r=0.3 all L1 = 0.241 +- 0.141 (in-sample avg dev_std = 0.242)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.558
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.586
NEC for r=0.6 class 0.0 = 0.218 +- 0.112 (in-sample avg dev_std = 0.250)
NEC for r=0.6 class 1.0 = 0.221 +- 0.112 (in-sample avg dev_std = 0.250)
NEC for r=0.6 all KL = 0.099 +- 0.112 (in-sample avg dev_std = 0.250)
NEC for r=0.6 all L1 = 0.221 +- 0.131 (in-sample avg dev_std = 0.250)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.604
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.605
NEC for r=0.9 class 0.0 = 0.186 +- 0.079 (in-sample avg dev_std = 0.193)
NEC for r=0.9 class 1.0 = 0.159 +- 0.079 (in-sample avg dev_std = 0.193)
NEC for r=0.9 all KL = 0.063 +- 0.079 (in-sample avg dev_std = 0.193)
NEC for r=0.9 all L1 = 0.162 +- 0.117 (in-sample avg dev_std = 0.193)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.623
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.619
NEC for r=1.0 class 0.0 = 0.15 +- 0.058 (in-sample avg dev_std = 0.150)
NEC for r=1.0 class 1.0 = 0.126 +- 0.058 (in-sample avg dev_std = 0.150)
NEC for r=1.0 all KL = 0.041 +- 0.058 (in-sample avg dev_std = 0.150)
NEC for r=1.0 all L1 = 0.128 +- 0.095 (in-sample avg dev_std = 0.150)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.668
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.637
NEC for r=0.3 class 0.0 = 0.23 +- 0.105 (in-sample avg dev_std = 0.221)
NEC for r=0.3 class 1.0 = 0.229 +- 0.105 (in-sample avg dev_std = 0.221)
NEC for r=0.3 all KL = 0.094 +- 0.105 (in-sample avg dev_std = 0.221)
NEC for r=0.3 all L1 = 0.229 +- 0.138 (in-sample avg dev_std = 0.221)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.678
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.667
NEC for r=0.6 class 0.0 = 0.197 +- 0.107 (in-sample avg dev_std = 0.227)
NEC for r=0.6 class 1.0 = 0.204 +- 0.107 (in-sample avg dev_std = 0.227)
NEC for r=0.6 all KL = 0.088 +- 0.107 (in-sample avg dev_std = 0.227)
NEC for r=0.6 all L1 = 0.203 +- 0.130 (in-sample avg dev_std = 0.227)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.691
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.685
NEC for r=0.9 class 0.0 = 0.168 +- 0.073 (in-sample avg dev_std = 0.176)
NEC for r=0.9 class 1.0 = 0.15 +- 0.073 (in-sample avg dev_std = 0.176)
NEC for r=0.9 all KL = 0.057 +- 0.073 (in-sample avg dev_std = 0.176)
NEC for r=0.9 all L1 = 0.153 +- 0.112 (in-sample avg dev_std = 0.176)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.693
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.687
NEC for r=1.0 class 0.0 = 0.13 +- 0.049 (in-sample avg dev_std = 0.137)
NEC for r=1.0 class 1.0 = 0.121 +- 0.049 (in-sample avg dev_std = 0.137)
NEC for r=1.0 all KL = 0.036 +- 0.049 (in-sample avg dev_std = 0.137)
NEC for r=1.0 all L1 = 0.122 +- 0.086 (in-sample avg dev_std = 0.137)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Mar 23 01:24:32 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 03/23/2024 01:24:33 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/23/2024 01:25:13 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/23/2024 01:25:24 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/23/2024 01:25:35 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/23/2024 01:25:52 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/23/2024 01:26:08 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 03/23/2024 01:26:08 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/23/2024 01:27:26 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:27:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:27:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:27:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:27:26 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:27:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:27:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:27:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:27:26 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:27:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:27:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:27:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:27:26 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 166...
[0m[1;37mINFO[0m: [1mCheckpoint 166: 
-----------------------------------
Train ROC-AUC: 0.9718
Train Loss: 0.1502
ID Validation ROC-AUC: 0.9222
ID Validation Loss: 0.2869
ID Test ROC-AUC: 0.9201
ID Test Loss: 0.2932
OOD Validation ROC-AUC: 0.6430
OOD Validation Loss: 0.5048
OOD Test ROC-AUC: 0.7020
OOD Test Loss: 0.7112

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 0...
[0m[1;37mINFO[0m: [1mCheckpoint 0: 
-----------------------------------
Train ROC-AUC: 0.8089
Train Loss: 0.4646
ID Validation ROC-AUC: 0.8084
ID Validation Loss: 0.4676
ID Test ROC-AUC: 0.8095
ID Test Loss: 0.4731
OOD Validation ROC-AUC: 0.6927
OOD Validation Loss: 0.3283
OOD Test ROC-AUC: 0.6938
OOD Test Loss: 0.4537

[0m[1;37mINFO[0m: [1mChartInfo 0.9201 0.7020 0.8095 0.6938 0.8084 0.6927[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 03/23/2024 01:27:26 AM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 03/23/2024 01:27:31 AM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 03/23/2024 01:27:35 AM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.585
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.609
SUFF++ for r=0.3 class 0.0 = 0.696 +- 0.265 (in-sample avg dev_std = 0.622)
SUFF++ for r=0.3 class 1.0 = 0.585 +- 0.265 (in-sample avg dev_std = 0.622)
SUFF++ for r=0.3 all KL = 0.529 +- 0.265 (in-sample avg dev_std = 0.622)
SUFF++ for r=0.3 all L1 = 0.598 +- 0.185 (in-sample avg dev_std = 0.622)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.65
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.648
SUFF++ for r=0.6 class 0.0 = 0.703 +- 0.294 (in-sample avg dev_std = 0.598)
SUFF++ for r=0.6 class 1.0 = 0.636 +- 0.294 (in-sample avg dev_std = 0.598)
SUFF++ for r=0.6 all KL = 0.566 +- 0.294 (in-sample avg dev_std = 0.598)
SUFF++ for r=0.6 all L1 = 0.644 +- 0.212 (in-sample avg dev_std = 0.598)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.684
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.669
SUFF++ for r=0.9 class 0.0 = 0.8 +- 0.234 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.9 class 1.0 = 0.728 +- 0.234 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.9 all KL = 0.787 +- 0.234 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.9 all L1 = 0.736 +- 0.203 (in-sample avg dev_std = 0.355)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.553
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.535
SUFF++ for r=0.3 class 0.0 = 0.678 +- 0.257 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.3 class 1.0 = 0.641 +- 0.257 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.3 all KL = 0.611 +- 0.257 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.3 all L1 = 0.644 +- 0.188 (in-sample avg dev_std = 0.564)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.596
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.582
SUFF++ for r=0.6 class 0.0 = 0.713 +- 0.287 (in-sample avg dev_std = 0.581)
SUFF++ for r=0.6 class 1.0 = 0.638 +- 0.287 (in-sample avg dev_std = 0.581)
SUFF++ for r=0.6 all KL = 0.586 +- 0.287 (in-sample avg dev_std = 0.581)
SUFF++ for r=0.6 all L1 = 0.644 +- 0.202 (in-sample avg dev_std = 0.581)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.597
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.592
SUFF++ for r=0.9 class 0.0 = 0.818 +- 0.236 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.9 class 1.0 = 0.74 +- 0.236 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.9 all KL = 0.798 +- 0.236 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.9 all L1 = 0.747 +- 0.199 (in-sample avg dev_std = 0.355)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.511
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.552
SUFF++ for r=0.3 class 0.0 = 0.693 +- 0.263 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.3 class 1.0 = 0.628 +- 0.263 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.3 all KL = 0.598 +- 0.263 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.3 all L1 = 0.639 +- 0.189 (in-sample avg dev_std = 0.576)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.559
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.583
SUFF++ for r=0.6 class 0.0 = 0.698 +- 0.287 (in-sample avg dev_std = 0.571)
SUFF++ for r=0.6 class 1.0 = 0.649 +- 0.287 (in-sample avg dev_std = 0.571)
SUFF++ for r=0.6 all KL = 0.606 +- 0.287 (in-sample avg dev_std = 0.571)
SUFF++ for r=0.6 all L1 = 0.657 +- 0.211 (in-sample avg dev_std = 0.571)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.588
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.572
SUFF++ for r=0.9 class 0.0 = 0.78 +- 0.229 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.9 class 1.0 = 0.751 +- 0.229 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.9 all KL = 0.812 +- 0.229 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.9 all L1 = 0.756 +- 0.205 (in-sample avg dev_std = 0.337)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.585
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.589
NEC for r=0.3 class 0.0 = 0.197 +- 0.266 (in-sample avg dev_std = 0.410)
NEC for r=0.3 class 1.0 = 0.285 +- 0.266 (in-sample avg dev_std = 0.410)
NEC for r=0.3 all KL = 0.268 +- 0.266 (in-sample avg dev_std = 0.410)
NEC for r=0.3 all L1 = 0.275 +- 0.211 (in-sample avg dev_std = 0.410)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.65
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.664
NEC for r=0.6 class 0.0 = 0.214 +- 0.273 (in-sample avg dev_std = 0.430)
NEC for r=0.6 class 1.0 = 0.251 +- 0.273 (in-sample avg dev_std = 0.430)
NEC for r=0.6 all KL = 0.258 +- 0.273 (in-sample avg dev_std = 0.430)
NEC for r=0.6 all L1 = 0.246 +- 0.220 (in-sample avg dev_std = 0.430)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.684
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.691
NEC for r=0.9 class 0.0 = 0.226 +- 0.196 (in-sample avg dev_std = 0.349)
NEC for r=0.9 class 1.0 = 0.249 +- 0.196 (in-sample avg dev_std = 0.349)
NEC for r=0.9 all KL = 0.188 +- 0.196 (in-sample avg dev_std = 0.349)
NEC for r=0.9 all L1 = 0.247 +- 0.186 (in-sample avg dev_std = 0.349)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.691
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.7
NEC for r=1.0 class 0.0 = 0.206 +- 0.159 (in-sample avg dev_std = 0.300)
NEC for r=1.0 class 1.0 = 0.258 +- 0.159 (in-sample avg dev_std = 0.300)
NEC for r=1.0 all KL = 0.158 +- 0.159 (in-sample avg dev_std = 0.300)
NEC for r=1.0 all L1 = 0.252 +- 0.171 (in-sample avg dev_std = 0.300)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.553
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.535
NEC for r=0.3 class 0.0 = 0.241 +- 0.253 (in-sample avg dev_std = 0.383)
NEC for r=0.3 class 1.0 = 0.264 +- 0.253 (in-sample avg dev_std = 0.383)
NEC for r=0.3 all KL = 0.24 +- 0.253 (in-sample avg dev_std = 0.383)
NEC for r=0.3 all L1 = 0.262 +- 0.206 (in-sample avg dev_std = 0.383)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.594
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.593
NEC for r=0.6 class 0.0 = 0.191 +- 0.258 (in-sample avg dev_std = 0.419)
NEC for r=0.6 class 1.0 = 0.245 +- 0.258 (in-sample avg dev_std = 0.419)
NEC for r=0.6 all KL = 0.238 +- 0.258 (in-sample avg dev_std = 0.419)
NEC for r=0.6 all L1 = 0.241 +- 0.207 (in-sample avg dev_std = 0.419)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.597
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.6
NEC for r=0.9 class 0.0 = 0.211 +- 0.211 (in-sample avg dev_std = 0.367)
NEC for r=0.9 class 1.0 = 0.25 +- 0.211 (in-sample avg dev_std = 0.367)
NEC for r=0.9 all KL = 0.196 +- 0.211 (in-sample avg dev_std = 0.367)
NEC for r=0.9 all L1 = 0.247 +- 0.181 (in-sample avg dev_std = 0.367)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.589
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.607
NEC for r=1.0 class 0.0 = 0.2 +- 0.175 (in-sample avg dev_std = 0.312)
NEC for r=1.0 class 1.0 = 0.249 +- 0.175 (in-sample avg dev_std = 0.312)
NEC for r=1.0 all KL = 0.16 +- 0.175 (in-sample avg dev_std = 0.312)
NEC for r=1.0 all L1 = 0.244 +- 0.169 (in-sample avg dev_std = 0.312)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.511
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.547
NEC for r=0.3 class 0.0 = 0.22 +- 0.248 (in-sample avg dev_std = 0.368)
NEC for r=0.3 class 1.0 = 0.268 +- 0.248 (in-sample avg dev_std = 0.368)
NEC for r=0.3 all KL = 0.231 +- 0.248 (in-sample avg dev_std = 0.368)
NEC for r=0.3 all L1 = 0.26 +- 0.214 (in-sample avg dev_std = 0.368)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.559
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.582
NEC for r=0.6 class 0.0 = 0.236 +- 0.261 (in-sample avg dev_std = 0.412)
NEC for r=0.6 class 1.0 = 0.248 +- 0.261 (in-sample avg dev_std = 0.412)
NEC for r=0.6 all KL = 0.242 +- 0.261 (in-sample avg dev_std = 0.412)
NEC for r=0.6 all L1 = 0.246 +- 0.213 (in-sample avg dev_std = 0.412)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.588
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.593
NEC for r=0.9 class 0.0 = 0.231 +- 0.206 (in-sample avg dev_std = 0.346)
NEC for r=0.9 class 1.0 = 0.244 +- 0.206 (in-sample avg dev_std = 0.346)
NEC for r=0.9 all KL = 0.184 +- 0.206 (in-sample avg dev_std = 0.346)
NEC for r=0.9 all L1 = 0.241 +- 0.187 (in-sample avg dev_std = 0.346)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.591
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.595
NEC for r=1.0 class 0.0 = 0.223 +- 0.175 (in-sample avg dev_std = 0.301)
NEC for r=1.0 class 1.0 = 0.245 +- 0.175 (in-sample avg dev_std = 0.301)
NEC for r=1.0 all KL = 0.155 +- 0.175 (in-sample avg dev_std = 0.301)
NEC for r=1.0 all L1 = 0.241 +- 0.173 (in-sample avg dev_std = 0.301)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Mar 23 01:32:08 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 03/23/2024 01:32:09 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/23/2024 01:32:41 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/23/2024 01:32:51 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/23/2024 01:33:03 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/23/2024 01:33:19 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/23/2024 01:33:35 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 03/23/2024 01:33:35 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/23/2024 01:34:53 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:34:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:34:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:34:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:34:53 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:34:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:34:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:34:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:34:53 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:34:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:34:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:34:53 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:34:53 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 127...
[0m[1;37mINFO[0m: [1mCheckpoint 127: 
-----------------------------------
Train ROC-AUC: 0.9605
Train Loss: 0.1572
ID Validation ROC-AUC: 0.9210
ID Validation Loss: 0.2207
ID Test ROC-AUC: 0.9206
ID Test Loss: 0.2229
OOD Validation ROC-AUC: 0.6437
OOD Validation Loss: 0.4343
OOD Test ROC-AUC: 0.7008
OOD Test Loss: 0.5543

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 3...
[0m[1;37mINFO[0m: [1mCheckpoint 3: 
-----------------------------------
Train ROC-AUC: 0.8643
Train Loss: 0.3237
ID Validation ROC-AUC: 0.8622
ID Validation Loss: 0.3271
ID Test ROC-AUC: 0.8643
ID Test Loss: 0.3301
OOD Validation ROC-AUC: 0.7009
OOD Validation Loss: 0.2819
OOD Test ROC-AUC: 0.7289
OOD Test Loss: 0.4908

[0m[1;37mINFO[0m: [1mChartInfo 0.9206 0.7008 0.8643 0.7289 0.8622 0.7009[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 03/23/2024 01:34:53 AM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 03/23/2024 01:34:58 AM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 03/23/2024 01:35:02 AM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.435
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.489
SUFF++ for r=0.3 class 0.0 = 0.72 +- 0.121 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.3 class 1.0 = 0.703 +- 0.121 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.3 all KL = 0.848 +- 0.121 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.3 all L1 = 0.705 +- 0.106 (in-sample avg dev_std = 0.324)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.525
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.539
SUFF++ for r=0.6 class 0.0 = 0.801 +- 0.087 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.6 class 1.0 = 0.773 +- 0.087 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.6 all KL = 0.911 +- 0.087 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.6 all L1 = 0.776 +- 0.097 (in-sample avg dev_std = 0.244)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.57
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.566
SUFF++ for r=0.9 class 0.0 = 0.911 +- 0.031 (in-sample avg dev_std = 0.104)
SUFF++ for r=0.9 class 1.0 = 0.891 +- 0.031 (in-sample avg dev_std = 0.104)
SUFF++ for r=0.9 all KL = 0.98 +- 0.031 (in-sample avg dev_std = 0.104)
SUFF++ for r=0.9 all L1 = 0.894 +- 0.068 (in-sample avg dev_std = 0.104)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.483
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.512
SUFF++ for r=0.3 class 0.0 = 0.733 +- 0.110 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.3 class 1.0 = 0.721 +- 0.110 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.3 all KL = 0.861 +- 0.110 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.3 all L1 = 0.722 +- 0.106 (in-sample avg dev_std = 0.305)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.501
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.537
SUFF++ for r=0.6 class 0.0 = 0.798 +- 0.064 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.6 class 1.0 = 0.799 +- 0.064 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.6 all KL = 0.927 +- 0.064 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.6 all L1 = 0.799 +- 0.087 (in-sample avg dev_std = 0.219)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.576
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.581
SUFF++ for r=0.9 class 0.0 = 0.913 +- 0.018 (in-sample avg dev_std = 0.084)
SUFF++ for r=0.9 class 1.0 = 0.909 +- 0.018 (in-sample avg dev_std = 0.084)
SUFF++ for r=0.9 all KL = 0.986 +- 0.018 (in-sample avg dev_std = 0.084)
SUFF++ for r=0.9 all L1 = 0.91 +- 0.054 (in-sample avg dev_std = 0.084)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.455
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.491
SUFF++ for r=0.3 class 0.0 = 0.742 +- 0.102 (in-sample avg dev_std = 0.308)
SUFF++ for r=0.3 class 1.0 = 0.719 +- 0.102 (in-sample avg dev_std = 0.308)
SUFF++ for r=0.3 all KL = 0.865 +- 0.102 (in-sample avg dev_std = 0.308)
SUFF++ for r=0.3 all L1 = 0.723 +- 0.099 (in-sample avg dev_std = 0.308)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.509
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.51
SUFF++ for r=0.6 class 0.0 = 0.801 +- 0.077 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.6 class 1.0 = 0.795 +- 0.077 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.6 all KL = 0.92 +- 0.077 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.6 all L1 = 0.796 +- 0.094 (in-sample avg dev_std = 0.233)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.531
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.526
SUFF++ for r=0.9 class 0.0 = 0.907 +- 0.021 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.9 class 1.0 = 0.907 +- 0.021 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.9 all KL = 0.984 +- 0.021 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.9 all L1 = 0.907 +- 0.059 (in-sample avg dev_std = 0.089)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.435
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.458
NEC for r=0.3 class 0.0 = 0.265 +- 0.124 (in-sample avg dev_std = 0.257)
NEC for r=0.3 class 1.0 = 0.253 +- 0.124 (in-sample avg dev_std = 0.257)
NEC for r=0.3 all KL = 0.115 +- 0.124 (in-sample avg dev_std = 0.257)
NEC for r=0.3 all L1 = 0.254 +- 0.131 (in-sample avg dev_std = 0.257)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.525
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.537
NEC for r=0.6 class 0.0 = 0.163 +- 0.076 (in-sample avg dev_std = 0.193)
NEC for r=0.6 class 1.0 = 0.18 +- 0.076 (in-sample avg dev_std = 0.193)
NEC for r=0.6 all KL = 0.058 +- 0.076 (in-sample avg dev_std = 0.193)
NEC for r=0.6 all L1 = 0.178 +- 0.101 (in-sample avg dev_std = 0.193)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.57
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.566
NEC for r=0.9 class 0.0 = 0.105 +- 0.035 (in-sample avg dev_std = 0.109)
NEC for r=0.9 class 1.0 = 0.112 +- 0.035 (in-sample avg dev_std = 0.109)
NEC for r=0.9 all KL = 0.021 +- 0.035 (in-sample avg dev_std = 0.109)
NEC for r=0.9 all L1 = 0.111 +- 0.070 (in-sample avg dev_std = 0.109)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.585
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.576
NEC for r=1.0 class 0.0 = 0.093 +- 0.025 (in-sample avg dev_std = 0.085)
NEC for r=1.0 class 1.0 = 0.091 +- 0.025 (in-sample avg dev_std = 0.085)
NEC for r=1.0 all KL = 0.015 +- 0.025 (in-sample avg dev_std = 0.085)
NEC for r=1.0 all L1 = 0.091 +- 0.058 (in-sample avg dev_std = 0.085)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.484
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.513
NEC for r=0.3 class 0.0 = 0.251 +- 0.110 (in-sample avg dev_std = 0.252)
NEC for r=0.3 class 1.0 = 0.253 +- 0.110 (in-sample avg dev_std = 0.252)
NEC for r=0.3 all KL = 0.113 +- 0.110 (in-sample avg dev_std = 0.252)
NEC for r=0.3 all L1 = 0.253 +- 0.127 (in-sample avg dev_std = 0.252)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.501
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.539
NEC for r=0.6 class 0.0 = 0.178 +- 0.061 (in-sample avg dev_std = 0.181)
NEC for r=0.6 class 1.0 = 0.174 +- 0.061 (in-sample avg dev_std = 0.181)
NEC for r=0.6 all KL = 0.056 +- 0.061 (in-sample avg dev_std = 0.181)
NEC for r=0.6 all L1 = 0.174 +- 0.094 (in-sample avg dev_std = 0.181)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.577
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.58
NEC for r=0.9 class 0.0 = 0.115 +- 0.025 (in-sample avg dev_std = 0.102)
NEC for r=0.9 class 1.0 = 0.104 +- 0.025 (in-sample avg dev_std = 0.102)
NEC for r=0.9 all KL = 0.019 +- 0.025 (in-sample avg dev_std = 0.102)
NEC for r=0.9 all L1 = 0.105 +- 0.062 (in-sample avg dev_std = 0.102)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.585
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.581
NEC for r=1.0 class 0.0 = 0.095 +- 0.021 (in-sample avg dev_std = 0.082)
NEC for r=1.0 class 1.0 = 0.087 +- 0.021 (in-sample avg dev_std = 0.082)
NEC for r=1.0 all KL = 0.014 +- 0.021 (in-sample avg dev_std = 0.082)
NEC for r=1.0 all L1 = 0.087 +- 0.054 (in-sample avg dev_std = 0.082)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.451
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.492
NEC for r=0.3 class 0.0 = 0.249 +- 0.114 (in-sample avg dev_std = 0.249)
NEC for r=0.3 class 1.0 = 0.254 +- 0.114 (in-sample avg dev_std = 0.249)
NEC for r=0.3 all KL = 0.111 +- 0.114 (in-sample avg dev_std = 0.249)
NEC for r=0.3 all L1 = 0.254 +- 0.126 (in-sample avg dev_std = 0.249)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.509
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.524
NEC for r=0.6 class 0.0 = 0.172 +- 0.066 (in-sample avg dev_std = 0.185)
NEC for r=0.6 class 1.0 = 0.175 +- 0.066 (in-sample avg dev_std = 0.185)
NEC for r=0.6 all KL = 0.058 +- 0.066 (in-sample avg dev_std = 0.185)
NEC for r=0.6 all L1 = 0.174 +- 0.097 (in-sample avg dev_std = 0.185)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.532
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.544
NEC for r=0.9 class 0.0 = 0.109 +- 0.031 (in-sample avg dev_std = 0.108)
NEC for r=0.9 class 1.0 = 0.108 +- 0.031 (in-sample avg dev_std = 0.108)
NEC for r=0.9 all KL = 0.021 +- 0.031 (in-sample avg dev_std = 0.108)
NEC for r=0.9 all L1 = 0.108 +- 0.065 (in-sample avg dev_std = 0.108)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.54
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.546
NEC for r=1.0 class 0.0 = 0.093 +- 0.022 (in-sample avg dev_std = 0.080)
NEC for r=1.0 class 1.0 = 0.087 +- 0.022 (in-sample avg dev_std = 0.080)
NEC for r=1.0 all KL = 0.014 +- 0.022 (in-sample avg dev_std = 0.080)
NEC for r=1.0 all L1 = 0.088 +- 0.053 (in-sample avg dev_std = 0.080)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Mar 23 01:39:35 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 03/23/2024 01:39:35 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 03/23/2024 01:40:07 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 03/23/2024 01:40:18 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 03/23/2024 01:40:28 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 03/23/2024 01:40:45 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 03/23/2024 01:41:05 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 03/23/2024 01:41:05 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/23/2024 01:42:32 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:42:32 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:42:32 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:42:32 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:42:32 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:42:32 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:42:32 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:42:32 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:42:32 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:42:32 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:42:32 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:42:32 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 03/23/2024 01:42:32 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 172...
[0m[1;37mINFO[0m: [1mCheckpoint 172: 
-----------------------------------
Train ROC-AUC: 0.9755
Train Loss: 0.1331
ID Validation ROC-AUC: 0.9228
ID Validation Loss: 0.2627
ID Test ROC-AUC: 0.9230
ID Test Loss: 0.2676
OOD Validation ROC-AUC: 0.6330
OOD Validation Loss: 0.4920
OOD Test ROC-AUC: 0.6956
OOD Test Loss: 0.6669

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 2...
[0m[1;37mINFO[0m: [1mCheckpoint 2: 
-----------------------------------
Train ROC-AUC: 0.8416
Train Loss: 0.7193
ID Validation ROC-AUC: 0.8417
ID Validation Loss: 0.7258
ID Test ROC-AUC: 0.8407
ID Test Loss: 0.7339
OOD Validation ROC-AUC: 0.7030
OOD Validation Loss: 0.4109
OOD Test ROC-AUC: 0.7172
OOD Test Loss: 0.4958

[0m[1;37mINFO[0m: [1mChartInfo 0.9230 0.6956 0.8407 0.7172 0.8417 0.7030[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 03/23/2024 01:42:32 AM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 03/23/2024 01:42:37 AM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 03/23/2024 01:42:41 AM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.566
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.529
SUFF++ for r=0.3 class 0.0 = 0.835 +- 0.212 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.3 class 1.0 = 0.811 +- 0.212 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.3 all KL = 0.784 +- 0.212 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.3 all L1 = 0.813 +- 0.156 (in-sample avg dev_std = 0.405)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.678
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.595
SUFF++ for r=0.6 class 0.0 = 0.782 +- 0.246 (in-sample avg dev_std = 0.497)
SUFF++ for r=0.6 class 1.0 = 0.716 +- 0.246 (in-sample avg dev_std = 0.497)
SUFF++ for r=0.6 all KL = 0.703 +- 0.246 (in-sample avg dev_std = 0.497)
SUFF++ for r=0.6 all L1 = 0.724 +- 0.192 (in-sample avg dev_std = 0.497)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.688
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.664
SUFF++ for r=0.9 class 0.0 = 0.88 +- 0.208 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.9 class 1.0 = 0.766 +- 0.208 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.9 all KL = 0.835 +- 0.208 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.9 all L1 = 0.779 +- 0.193 (in-sample avg dev_std = 0.324)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.423
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.469
SUFF++ for r=0.3 class 0.0 = 0.86 +- 0.178 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.3 class 1.0 = 0.877 +- 0.178 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.3 all KL = 0.868 +- 0.178 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.3 all L1 = 0.875 +- 0.130 (in-sample avg dev_std = 0.300)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.531
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.495
SUFF++ for r=0.6 class 0.0 = 0.775 +- 0.216 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.6 class 1.0 = 0.78 +- 0.216 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.6 all KL = 0.788 +- 0.216 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.6 all L1 = 0.78 +- 0.183 (in-sample avg dev_std = 0.405)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.527
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.522
SUFF++ for r=0.9 class 0.0 = 0.853 +- 0.156 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 1.0 = 0.826 +- 0.156 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 all KL = 0.892 +- 0.156 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 all L1 = 0.829 +- 0.169 (in-sample avg dev_std = 0.253)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.575
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.533
SUFF++ for r=0.3 class 0.0 = 0.869 +- 0.194 (in-sample avg dev_std = 0.344)
SUFF++ for r=0.3 class 1.0 = 0.856 +- 0.194 (in-sample avg dev_std = 0.344)
SUFF++ for r=0.3 all KL = 0.837 +- 0.194 (in-sample avg dev_std = 0.344)
SUFF++ for r=0.3 all L1 = 0.858 +- 0.135 (in-sample avg dev_std = 0.344)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.593
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.597
SUFF++ for r=0.6 class 0.0 = 0.82 +- 0.232 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.6 class 1.0 = 0.771 +- 0.232 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.6 all KL = 0.768 +- 0.232 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.6 all L1 = 0.779 +- 0.183 (in-sample avg dev_std = 0.427)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.63
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.598
SUFF++ for r=0.9 class 0.0 = 0.88 +- 0.174 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.9 class 1.0 = 0.821 +- 0.174 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.9 all KL = 0.884 +- 0.174 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.9 all L1 = 0.831 +- 0.176 (in-sample avg dev_std = 0.262)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.567
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.576
NEC for r=0.3 class 0.0 = 0.082 +- 0.155 (in-sample avg dev_std = 0.221)
NEC for r=0.3 class 1.0 = 0.114 +- 0.155 (in-sample avg dev_std = 0.221)
NEC for r=0.3 all KL = 0.094 +- 0.155 (in-sample avg dev_std = 0.221)
NEC for r=0.3 all L1 = 0.111 +- 0.135 (in-sample avg dev_std = 0.221)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.678
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.662
NEC for r=0.6 class 0.0 = 0.115 +- 0.195 (in-sample avg dev_std = 0.294)
NEC for r=0.6 class 1.0 = 0.178 +- 0.195 (in-sample avg dev_std = 0.294)
NEC for r=0.6 all KL = 0.137 +- 0.195 (in-sample avg dev_std = 0.294)
NEC for r=0.6 all L1 = 0.171 +- 0.184 (in-sample avg dev_std = 0.294)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.688
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.679
NEC for r=0.9 class 0.0 = 0.117 +- 0.176 (in-sample avg dev_std = 0.295)
NEC for r=0.9 class 1.0 = 0.21 +- 0.176 (in-sample avg dev_std = 0.295)
NEC for r=0.9 all KL = 0.137 +- 0.176 (in-sample avg dev_std = 0.295)
NEC for r=0.9 all L1 = 0.199 +- 0.176 (in-sample avg dev_std = 0.295)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.69
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.691
NEC for r=1.0 class 0.0 = 0.115 +- 0.148 (in-sample avg dev_std = 0.269)
NEC for r=1.0 class 1.0 = 0.211 +- 0.148 (in-sample avg dev_std = 0.269)
NEC for r=1.0 all KL = 0.12 +- 0.148 (in-sample avg dev_std = 0.269)
NEC for r=1.0 all L1 = 0.2 +- 0.163 (in-sample avg dev_std = 0.269)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.413
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.425
NEC for r=0.3 class 0.0 = 0.098 +- 0.142 (in-sample avg dev_std = 0.192)
NEC for r=0.3 class 1.0 = 0.086 +- 0.142 (in-sample avg dev_std = 0.192)
NEC for r=0.3 all KL = 0.075 +- 0.142 (in-sample avg dev_std = 0.192)
NEC for r=0.3 all L1 = 0.087 +- 0.116 (in-sample avg dev_std = 0.192)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.531
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.515
NEC for r=0.6 class 0.0 = 0.143 +- 0.176 (in-sample avg dev_std = 0.275)
NEC for r=0.6 class 1.0 = 0.148 +- 0.176 (in-sample avg dev_std = 0.275)
NEC for r=0.6 all KL = 0.112 +- 0.176 (in-sample avg dev_std = 0.275)
NEC for r=0.6 all L1 = 0.148 +- 0.171 (in-sample avg dev_std = 0.275)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.528
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.513
NEC for r=0.9 class 0.0 = 0.163 +- 0.153 (in-sample avg dev_std = 0.266)
NEC for r=0.9 class 1.0 = 0.179 +- 0.153 (in-sample avg dev_std = 0.266)
NEC for r=0.9 all KL = 0.113 +- 0.153 (in-sample avg dev_std = 0.266)
NEC for r=0.9 all L1 = 0.178 +- 0.165 (in-sample avg dev_std = 0.266)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.509
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.512
NEC for r=1.0 class 0.0 = 0.165 +- 0.129 (in-sample avg dev_std = 0.227)
NEC for r=1.0 class 1.0 = 0.175 +- 0.129 (in-sample avg dev_std = 0.227)
NEC for r=1.0 all KL = 0.096 +- 0.129 (in-sample avg dev_std = 0.227)
NEC for r=1.0 all L1 = 0.174 +- 0.154 (in-sample avg dev_std = 0.227)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.575
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.544
NEC for r=0.3 class 0.0 = 0.087 +- 0.142 (in-sample avg dev_std = 0.183)
NEC for r=0.3 class 1.0 = 0.093 +- 0.142 (in-sample avg dev_std = 0.183)
NEC for r=0.3 all KL = 0.077 +- 0.142 (in-sample avg dev_std = 0.183)
NEC for r=0.3 all L1 = 0.092 +- 0.119 (in-sample avg dev_std = 0.183)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.592
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.582
NEC for r=0.6 class 0.0 = 0.113 +- 0.184 (in-sample avg dev_std = 0.260)
NEC for r=0.6 class 1.0 = 0.144 +- 0.184 (in-sample avg dev_std = 0.260)
NEC for r=0.6 all KL = 0.112 +- 0.184 (in-sample avg dev_std = 0.260)
NEC for r=0.6 all L1 = 0.139 +- 0.167 (in-sample avg dev_std = 0.260)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.63
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.616
NEC for r=0.9 class 0.0 = 0.13 +- 0.156 (in-sample avg dev_std = 0.250)
NEC for r=0.9 class 1.0 = 0.173 +- 0.156 (in-sample avg dev_std = 0.250)
NEC for r=0.9 all KL = 0.109 +- 0.156 (in-sample avg dev_std = 0.250)
NEC for r=0.9 all L1 = 0.166 +- 0.161 (in-sample avg dev_std = 0.250)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.629
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.632
NEC for r=1.0 class 0.0 = 0.127 +- 0.141 (in-sample avg dev_std = 0.230)
NEC for r=1.0 class 1.0 = 0.172 +- 0.141 (in-sample avg dev_std = 0.230)
NEC for r=1.0 all KL = 0.095 +- 0.141 (in-sample avg dev_std = 0.230)
NEC for r=1.0 all L1 = 0.164 +- 0.151 (in-sample avg dev_std = 0.230)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.524, 0.607, 0.814, 1.0], 'all_L1': [0.597, 0.637, 0.74, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.859, 0.854, 0.932, 1.0], 'all_L1': [0.737, 0.754, 0.855, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.529, 0.566, 0.787, 1.0], 'all_L1': [0.598, 0.644, 0.736, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.848, 0.911, 0.98, 1.0], 'all_L1': [0.705, 0.776, 0.894, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.784, 0.703, 0.835, 1.0], 'all_L1': [0.813, 0.724, 0.779, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.238, 0.198, 0.144, 0.116], 'all_L1': [0.255, 0.232, 0.221, 0.205]}), defaultdict(<class 'list'>, {'all_KL': [0.077, 0.085, 0.05, 0.033], 'all_L1': [0.195, 0.184, 0.123, 0.1]}), defaultdict(<class 'list'>, {'all_KL': [0.268, 0.258, 0.188, 0.158], 'all_L1': [0.275, 0.246, 0.247, 0.252]}), defaultdict(<class 'list'>, {'all_KL': [0.115, 0.058, 0.021, 0.015], 'all_L1': [0.254, 0.178, 0.111, 0.091]}), defaultdict(<class 'list'>, {'all_KL': [0.094, 0.137, 0.137, 0.12], 'all_L1': [0.111, 0.171, 0.199, 0.2]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.518, 0.605, 0.832, 1.0], 'all_L1': [0.599, 0.623, 0.747, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.834, 0.832, 0.924, 1.0], 'all_L1': [0.691, 0.707, 0.823, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.611, 0.586, 0.798, 1.0], 'all_L1': [0.644, 0.644, 0.747, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.861, 0.927, 0.986, 1.0], 'all_L1': [0.722, 0.799, 0.91, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.868, 0.788, 0.892, 1.0], 'all_L1': [0.875, 0.78, 0.829, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.26, 0.213, 0.146, 0.115], 'all_L1': [0.265, 0.253, 0.228, 0.206]}), defaultdict(<class 'list'>, {'all_KL': [0.102, 0.099, 0.063, 0.041], 'all_L1': [0.241, 0.221, 0.162, 0.128]}), defaultdict(<class 'list'>, {'all_KL': [0.24, 0.238, 0.196, 0.16], 'all_L1': [0.262, 0.241, 0.247, 0.244]}), defaultdict(<class 'list'>, {'all_KL': [0.113, 0.056, 0.019, 0.014], 'all_L1': [0.253, 0.174, 0.105, 0.087]}), defaultdict(<class 'list'>, {'all_KL': [0.075, 0.112, 0.113, 0.096], 'all_L1': [0.087, 0.148, 0.178, 0.174]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.522, 0.602, 0.819, 1.0], 'all_L1': [0.615, 0.646, 0.749, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.839, 0.846, 0.929, 1.0], 'all_L1': [0.7, 0.726, 0.829, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.598, 0.606, 0.812, 1.0], 'all_L1': [0.639, 0.657, 0.756, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.865, 0.92, 0.984, 1.0], 'all_L1': [0.723, 0.796, 0.907, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.837, 0.768, 0.884, 1.0], 'all_L1': [0.858, 0.779, 0.831, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.242, 0.198, 0.144, 0.119], 'all_L1': [0.248, 0.227, 0.219, 0.203]}), defaultdict(<class 'list'>, {'all_KL': [0.094, 0.088, 0.057, 0.036], 'all_L1': [0.229, 0.203, 0.153, 0.122]}), defaultdict(<class 'list'>, {'all_KL': [0.231, 0.242, 0.184, 0.155], 'all_L1': [0.26, 0.246, 0.241, 0.241]}), defaultdict(<class 'list'>, {'all_KL': [0.111, 0.058, 0.021, 0.014], 'all_L1': [0.254, 0.174, 0.108, 0.088]}), defaultdict(<class 'list'>, {'all_KL': [0.077, 0.112, 0.109, 0.095], 'all_L1': [0.092, 0.139, 0.166, 0.164]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.690 +- 0.083, 0.707 +- 0.057, 0.801 +- 0.063, 1.000 +- 0.000
suff++ class all_KL  =  0.709 +- 0.151, 0.728 +- 0.135, 0.870 +- 0.074, 1.000 +- 0.000
suff++_acc_int  =  0.586 +- 0.074, 0.630 +- 0.067, 0.671 +- 0.069
nec class all_L1  =  0.218 +- 0.060, 0.202 +- 0.031, 0.180 +- 0.054, 0.170 +- 0.063
nec class all_KL  =  0.158 +- 0.079, 0.147 +- 0.073, 0.108 +- 0.062, 0.088 +- 0.055
nec_acc_int  =  0.595 +- 0.080, 0.662 +- 0.072, 0.686 +- 0.075, 0.695 +- 0.072

Eval split val
suff++ class all_L1  =  0.706 +- 0.094, 0.711 +- 0.070, 0.811 +- 0.061, 1.000 +- 0.000
suff++ class all_KL  =  0.738 +- 0.145, 0.748 +- 0.132, 0.886 +- 0.067, 1.000 +- 0.000
suff++_acc_int  =  0.521 +- 0.030, 0.553 +- 0.034, 0.575 +- 0.027
nec class all_L1  =  0.222 +- 0.068, 0.207 +- 0.040, 0.184 +- 0.050, 0.168 +- 0.056
nec class all_KL  =  0.158 +- 0.076, 0.144 +- 0.070, 0.107 +- 0.062, 0.085 +- 0.052
nec_acc_int  =  0.516 +- 0.049, 0.566 +- 0.033, 0.580 +- 0.035, 0.582 +- 0.038

Eval split test
suff++ class all_L1  =  0.707 +- 0.085, 0.721 +- 0.061, 0.814 +- 0.058, 1.000 +- 0.000
suff++ class all_KL  =  0.732 +- 0.143, 0.748 +- 0.127, 0.886 +- 0.065, 1.000 +- 0.000
suff++_acc_int  =  0.552 +- 0.042, 0.580 +- 0.038, 0.591 +- 0.044
nec class all_L1  =  0.217 +- 0.063, 0.198 +- 0.038, 0.177 +- 0.048, 0.164 +- 0.055
nec class all_KL  =  0.151 +- 0.071, 0.140 +- 0.069, 0.103 +- 0.059, 0.084 +- 0.052
nec_acc_int  =  0.565 +- 0.051, 0.590 +- 0.046, 0.608 +- 0.046, 0.613 +- 0.046


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.454 +- 0.020, 0.455 +- 0.016, 0.491 +- 0.007, 0.585 +- 0.032
Faith. Armon (L1)= 		  =  0.322 +- 0.068, 0.312 +- 0.031, 0.288 +- 0.069, 0.285 +- 0.094
Faith. GMean (L1)= 	  =  0.380 +- 0.042, 0.376 +- 0.015, 0.373 +- 0.045, 0.404 +- 0.080
Faith. Aritm (KL)= 		  =  0.434 +- 0.039, 0.438 +- 0.033, 0.489 +- 0.007, 0.544 +- 0.027
Faith. Armon (KL)= 		  =  0.239 +- 0.086, 0.229 +- 0.090, 0.184 +- 0.099, 0.158 +- 0.094
Faith. GMean (KL)= 	  =  0.314 +- 0.046, 0.308 +- 0.054, 0.285 +- 0.090, 0.278 +- 0.106

Eval split val
Faith. Aritm (L1)= 		  =  0.464 +- 0.020, 0.459 +- 0.017, 0.498 +- 0.007, 0.584 +- 0.028
Faith. Armon (L1)= 		  =  0.326 +- 0.084, 0.316 +- 0.042, 0.295 +- 0.064, 0.283 +- 0.082
Faith. GMean (L1)= 	  =  0.384 +- 0.055, 0.380 +- 0.022, 0.380 +- 0.042, 0.404 +- 0.070
Faith. Aritm (KL)= 		  =  0.448 +- 0.036, 0.446 +- 0.032, 0.497 +- 0.005, 0.543 +- 0.026
Faith. Armon (KL)= 		  =  0.242 +- 0.087, 0.226 +- 0.088, 0.184 +- 0.097, 0.153 +- 0.089
Faith. GMean (KL)= 	  =  0.322 +- 0.047, 0.309 +- 0.053, 0.288 +- 0.091, 0.274 +- 0.101

Eval split test
Faith. Aritm (L1)= 		  =  0.462 +- 0.020, 0.459 +- 0.016, 0.496 +- 0.008, 0.582 +- 0.027
Faith. Armon (L1)= 		  =  0.322 +- 0.079, 0.307 +- 0.043, 0.286 +- 0.061, 0.277 +- 0.081
Faith. GMean (L1)= 	  =  0.382 +- 0.052, 0.374 +- 0.024, 0.374 +- 0.040, 0.398 +- 0.069
Faith. Aritm (KL)= 		  =  0.442 +- 0.038, 0.444 +- 0.031, 0.494 +- 0.007, 0.542 +- 0.026
Faith. Armon (KL)= 		  =  0.234 +- 0.082, 0.222 +- 0.088, 0.178 +- 0.093, 0.150 +- 0.089
Faith. GMean (KL)= 	  =  0.314 +- 0.044, 0.305 +- 0.054, 0.283 +- 0.086, 0.271 +- 0.102
Computed for split load_split = id



Completed in  0:37:40.415646  for GSATvGIN LBAPcore/assay



DONE GSAT LBAPcore/assay

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Mar 23 01:47:21 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:23 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:23 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:23 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:23 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:23 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:23 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:23 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:23 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 01:47:23 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 186...
[0m[1;37mINFO[0m: [1mCheckpoint 186: 
-----------------------------------
Train ACCURACY: 0.9879
Train Loss: 0.0408
ID Validation ACCURACY: 0.8967
ID Validation Loss: 0.3836
ID Test ACCURACY: 0.8910
ID Test Loss: 0.3737
OOD Validation ACCURACY: 0.8210
OOD Validation Loss: 0.7581
OOD Test ACCURACY: 0.3357
OOD Test Loss: 4.8493

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 154...
[0m[1;37mINFO[0m: [1mCheckpoint 154: 
-----------------------------------
Train ACCURACY: 0.9669
Train Loss: 0.1038
ID Validation ACCURACY: 0.8889
ID Validation Loss: 0.3636
ID Test ACCURACY: 0.8920
ID Test Loss: 0.3454
OOD Validation ACCURACY: 0.8796
OOD Validation Loss: 0.3944
OOD Test ACCURACY: 0.5937
OOD Test Loss: 1.5026

[0m[1;37mINFO[0m: [1mChartInfo 0.8910 0.3357 0.8920 0.5937 0.8889 0.8796[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.111
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.105
SUFF++ for r=0.3 class 0 = 0.621 +- 0.137 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 class 1 = 0.561 +- 0.137 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 class 2 = 0.594 +- 0.137 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 class 3 = 0.588 +- 0.137 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 class 4 = 0.592 +- 0.137 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 class 5 = 0.587 +- 0.137 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 class 6 = 0.606 +- 0.137 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 class 7 = 0.587 +- 0.137 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 class 8 = 0.593 +- 0.137 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 class 9 = 0.582 +- 0.137 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 all KL = 0.728 +- 0.137 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 all L1 = 0.591 +- 0.106 (in-sample avg dev_std = 0.247)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.264
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.169
SUFF++ for r=0.6 class 0 = 0.384 +- 0.218 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.6 class 1 = 0.388 +- 0.218 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.6 class 2 = 0.372 +- 0.218 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.6 class 3 = 0.406 +- 0.218 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.6 class 4 = 0.391 +- 0.218 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.6 class 5 = 0.393 +- 0.218 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.6 class 6 = 0.412 +- 0.218 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.6 class 7 = 0.394 +- 0.218 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.6 class 8 = 0.393 +- 0.218 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.6 class 9 = 0.393 +- 0.218 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.6 all KL = 0.345 +- 0.218 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.6 all L1 = 0.393 +- 0.129 (in-sample avg dev_std = 0.401)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.82
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.772
SUFF++ for r=0.9 class 0 = 0.947 +- 0.231 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.9 class 1 = 0.946 +- 0.231 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.9 class 2 = 0.805 +- 0.231 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.9 class 3 = 0.769 +- 0.231 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.9 class 4 = 0.808 +- 0.231 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.9 class 5 = 0.71 +- 0.231 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.9 class 6 = 0.824 +- 0.231 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.9 class 7 = 0.828 +- 0.231 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.9 class 8 = 0.876 +- 0.231 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.9 class 9 = 0.783 +- 0.231 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.9 all KL = 0.844 +- 0.231 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.9 all L1 = 0.833 +- 0.198 (in-sample avg dev_std = 0.258)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.101
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.101
SUFF++ for r=0.3 class 0 = 0.607 +- 0.141 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.3 class 1 = 0.589 +- 0.141 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.3 class 2 = 0.606 +- 0.141 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.3 class 3 = 0.619 +- 0.141 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.3 class 4 = 0.593 +- 0.141 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.3 class 5 = 0.612 +- 0.141 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.3 class 6 = 0.586 +- 0.141 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.3 class 7 = 0.594 +- 0.141 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.3 class 8 = 0.597 +- 0.141 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.3 class 9 = 0.601 +- 0.141 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.3 all KL = 0.727 +- 0.141 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.3 all L1 = 0.6 +- 0.114 (in-sample avg dev_std = 0.251)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.234
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.152
SUFF++ for r=0.6 class 0 = 0.387 +- 0.223 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.6 class 1 = 0.423 +- 0.223 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.6 class 2 = 0.415 +- 0.223 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.6 class 3 = 0.425 +- 0.223 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.6 class 4 = 0.431 +- 0.223 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.6 class 5 = 0.423 +- 0.223 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.6 class 6 = 0.392 +- 0.223 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.6 class 7 = 0.43 +- 0.223 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.6 class 8 = 0.391 +- 0.223 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.6 class 9 = 0.403 +- 0.223 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.6 all KL = 0.365 +- 0.223 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.6 all L1 = 0.412 +- 0.137 (in-sample avg dev_std = 0.438)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.748
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.726
SUFF++ for r=0.9 class 0 = 0.903 +- 0.212 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 1 = 0.961 +- 0.212 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 2 = 0.755 +- 0.212 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 3 = 0.827 +- 0.212 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 4 = 0.755 +- 0.212 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 5 = 0.718 +- 0.212 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 6 = 0.751 +- 0.212 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 7 = 0.862 +- 0.212 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 8 = 0.815 +- 0.212 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 9 = 0.737 +- 0.212 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 all KL = 0.841 +- 0.212 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 all L1 = 0.811 +- 0.202 (in-sample avg dev_std = 0.243)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.126
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.104
SUFF++ for r=0.3 class 0 = 0.612 +- 0.169 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 class 1 = 0.587 +- 0.169 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 class 2 = 0.606 +- 0.169 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 class 3 = 0.603 +- 0.169 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 class 4 = 0.602 +- 0.169 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 class 5 = 0.602 +- 0.169 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 class 6 = 0.595 +- 0.169 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 class 7 = 0.579 +- 0.169 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 class 8 = 0.589 +- 0.169 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 class 9 = 0.564 +- 0.169 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 all KL = 0.69 +- 0.169 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 all L1 = 0.594 +- 0.126 (in-sample avg dev_std = 0.279)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.21
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.157
SUFF++ for r=0.6 class 0 = 0.46 +- 0.256 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.6 class 1 = 0.482 +- 0.256 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.6 class 2 = 0.524 +- 0.256 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.6 class 3 = 0.516 +- 0.256 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.6 class 4 = 0.495 +- 0.256 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.6 class 5 = 0.474 +- 0.256 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.6 class 6 = 0.518 +- 0.256 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.6 class 7 = 0.548 +- 0.256 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.6 class 8 = 0.48 +- 0.256 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.6 class 9 = 0.457 +- 0.256 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.6 all KL = 0.508 +- 0.256 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.6 all L1 = 0.496 +- 0.180 (in-sample avg dev_std = 0.375)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.366
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.354
SUFF++ for r=0.9 class 0 = 0.674 +- 0.217 (in-sample avg dev_std = 0.329)
SUFF++ for r=0.9 class 1 = 0.791 +- 0.217 (in-sample avg dev_std = 0.329)
SUFF++ for r=0.9 class 2 = 0.78 +- 0.217 (in-sample avg dev_std = 0.329)
SUFF++ for r=0.9 class 3 = 0.677 +- 0.217 (in-sample avg dev_std = 0.329)
SUFF++ for r=0.9 class 4 = 0.734 +- 0.217 (in-sample avg dev_std = 0.329)
SUFF++ for r=0.9 class 5 = 0.678 +- 0.217 (in-sample avg dev_std = 0.329)
SUFF++ for r=0.9 class 6 = 0.686 +- 0.217 (in-sample avg dev_std = 0.329)
SUFF++ for r=0.9 class 7 = 0.745 +- 0.217 (in-sample avg dev_std = 0.329)
SUFF++ for r=0.9 class 8 = 0.694 +- 0.217 (in-sample avg dev_std = 0.329)
SUFF++ for r=0.9 class 9 = 0.694 +- 0.217 (in-sample avg dev_std = 0.329)
SUFF++ for r=0.9 all KL = 0.77 +- 0.217 (in-sample avg dev_std = 0.329)
SUFF++ for r=0.9 all L1 = 0.717 +- 0.187 (in-sample avg dev_std = 0.329)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.111
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.108
NEC for r=0.3 class 0 = 0.392 +- 0.157 (in-sample avg dev_std = 0.221)
NEC for r=0.3 class 1 = 0.43 +- 0.157 (in-sample avg dev_std = 0.221)
NEC for r=0.3 class 2 = 0.423 +- 0.157 (in-sample avg dev_std = 0.221)
NEC for r=0.3 class 3 = 0.415 +- 0.157 (in-sample avg dev_std = 0.221)
NEC for r=0.3 class 4 = 0.402 +- 0.157 (in-sample avg dev_std = 0.221)
NEC for r=0.3 class 5 = 0.408 +- 0.157 (in-sample avg dev_std = 0.221)
NEC for r=0.3 class 6 = 0.432 +- 0.157 (in-sample avg dev_std = 0.221)
NEC for r=0.3 class 7 = 0.389 +- 0.157 (in-sample avg dev_std = 0.221)
NEC for r=0.3 class 8 = 0.43 +- 0.157 (in-sample avg dev_std = 0.221)
NEC for r=0.3 class 9 = 0.42 +- 0.157 (in-sample avg dev_std = 0.221)
NEC for r=0.3 all KL = 0.253 +- 0.157 (in-sample avg dev_std = 0.221)
NEC for r=0.3 all L1 = 0.414 +- 0.118 (in-sample avg dev_std = 0.221)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.264
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.221
NEC for r=0.6 class 0 = 0.493 +- 0.194 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 1 = 0.452 +- 0.194 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 2 = 0.479 +- 0.194 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 3 = 0.48 +- 0.194 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 4 = 0.515 +- 0.194 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 5 = 0.469 +- 0.194 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 6 = 0.503 +- 0.194 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 7 = 0.508 +- 0.194 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 8 = 0.505 +- 0.194 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 9 = 0.525 +- 0.194 (in-sample avg dev_std = 0.334)
NEC for r=0.6 all KL = 0.443 +- 0.194 (in-sample avg dev_std = 0.334)
NEC for r=0.6 all L1 = 0.492 +- 0.138 (in-sample avg dev_std = 0.334)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.82
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.653
NEC for r=0.9 class 0 = 0.302 +- 0.309 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 1 = 0.174 +- 0.309 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 2 = 0.332 +- 0.309 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 3 = 0.461 +- 0.309 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 4 = 0.367 +- 0.309 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 5 = 0.553 +- 0.309 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 6 = 0.392 +- 0.309 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 7 = 0.42 +- 0.309 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 8 = 0.29 +- 0.309 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 9 = 0.423 +- 0.309 (in-sample avg dev_std = 0.429)
NEC for r=0.9 all KL = 0.504 +- 0.309 (in-sample avg dev_std = 0.429)
NEC for r=0.9 all L1 = 0.367 +- 0.249 (in-sample avg dev_std = 0.429)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.946
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.836
NEC for r=1.0 class 0 = 0.09 +- 0.328 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 1 = 0.029 +- 0.328 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 2 = 0.262 +- 0.328 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 3 = 0.322 +- 0.328 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 4 = 0.202 +- 0.328 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 5 = 0.397 +- 0.328 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 6 = 0.265 +- 0.328 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 7 = 0.213 +- 0.328 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 8 = 0.171 +- 0.328 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 9 = 0.321 +- 0.328 (in-sample avg dev_std = 0.374)
NEC for r=1.0 all KL = 0.345 +- 0.328 (in-sample avg dev_std = 0.374)
NEC for r=1.0 all L1 = 0.222 +- 0.240 (in-sample avg dev_std = 0.374)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.101
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.105
NEC for r=0.3 class 0 = 0.373 +- 0.137 (in-sample avg dev_std = 0.207)
NEC for r=0.3 class 1 = 0.395 +- 0.137 (in-sample avg dev_std = 0.207)
NEC for r=0.3 class 2 = 0.389 +- 0.137 (in-sample avg dev_std = 0.207)
NEC for r=0.3 class 3 = 0.376 +- 0.137 (in-sample avg dev_std = 0.207)
NEC for r=0.3 class 4 = 0.372 +- 0.137 (in-sample avg dev_std = 0.207)
NEC for r=0.3 class 5 = 0.363 +- 0.137 (in-sample avg dev_std = 0.207)
NEC for r=0.3 class 6 = 0.381 +- 0.137 (in-sample avg dev_std = 0.207)
NEC for r=0.3 class 7 = 0.397 +- 0.137 (in-sample avg dev_std = 0.207)
NEC for r=0.3 class 8 = 0.383 +- 0.137 (in-sample avg dev_std = 0.207)
NEC for r=0.3 class 9 = 0.389 +- 0.137 (in-sample avg dev_std = 0.207)
NEC for r=0.3 all KL = 0.213 +- 0.137 (in-sample avg dev_std = 0.207)
NEC for r=0.3 all L1 = 0.382 +- 0.111 (in-sample avg dev_std = 0.207)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.234
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.202
NEC for r=0.6 class 0 = 0.418 +- 0.221 (in-sample avg dev_std = 0.315)
NEC for r=0.6 class 1 = 0.368 +- 0.221 (in-sample avg dev_std = 0.315)
NEC for r=0.6 class 2 = 0.425 +- 0.221 (in-sample avg dev_std = 0.315)
NEC for r=0.6 class 3 = 0.482 +- 0.221 (in-sample avg dev_std = 0.315)
NEC for r=0.6 class 4 = 0.497 +- 0.221 (in-sample avg dev_std = 0.315)
NEC for r=0.6 class 5 = 0.439 +- 0.221 (in-sample avg dev_std = 0.315)
NEC for r=0.6 class 6 = 0.488 +- 0.221 (in-sample avg dev_std = 0.315)
NEC for r=0.6 class 7 = 0.468 +- 0.221 (in-sample avg dev_std = 0.315)
NEC for r=0.6 class 8 = 0.506 +- 0.221 (in-sample avg dev_std = 0.315)
NEC for r=0.6 class 9 = 0.485 +- 0.221 (in-sample avg dev_std = 0.315)
NEC for r=0.6 all KL = 0.406 +- 0.221 (in-sample avg dev_std = 0.315)
NEC for r=0.6 all L1 = 0.457 +- 0.174 (in-sample avg dev_std = 0.315)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.748
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.613
NEC for r=0.9 class 0 = 0.416 +- 0.307 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 1 = 0.086 +- 0.307 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 2 = 0.41 +- 0.307 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 3 = 0.482 +- 0.307 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 4 = 0.458 +- 0.307 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 5 = 0.522 +- 0.307 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 6 = 0.482 +- 0.307 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 7 = 0.296 +- 0.307 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 8 = 0.338 +- 0.307 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 9 = 0.504 +- 0.307 (in-sample avg dev_std = 0.426)
NEC for r=0.9 all KL = 0.513 +- 0.307 (in-sample avg dev_std = 0.426)
NEC for r=0.9 all L1 = 0.394 +- 0.254 (in-sample avg dev_std = 0.426)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.835
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.759
NEC for r=1.0 class 0 = 0.159 +- 0.308 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 1 = 0.022 +- 0.308 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 2 = 0.297 +- 0.308 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 3 = 0.331 +- 0.308 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 4 = 0.332 +- 0.308 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 5 = 0.365 +- 0.308 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 6 = 0.359 +- 0.308 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 7 = 0.155 +- 0.308 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 8 = 0.224 +- 0.308 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 9 = 0.443 +- 0.308 (in-sample avg dev_std = 0.376)
NEC for r=1.0 all KL = 0.355 +- 0.308 (in-sample avg dev_std = 0.376)
NEC for r=1.0 all L1 = 0.265 +- 0.244 (in-sample avg dev_std = 0.376)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.126
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.109
NEC for r=0.3 class 0 = 0.347 +- 0.142 (in-sample avg dev_std = 0.203)
NEC for r=0.3 class 1 = 0.354 +- 0.142 (in-sample avg dev_std = 0.203)
NEC for r=0.3 class 2 = 0.368 +- 0.142 (in-sample avg dev_std = 0.203)
NEC for r=0.3 class 3 = 0.363 +- 0.142 (in-sample avg dev_std = 0.203)
NEC for r=0.3 class 4 = 0.363 +- 0.142 (in-sample avg dev_std = 0.203)
NEC for r=0.3 class 5 = 0.358 +- 0.142 (in-sample avg dev_std = 0.203)
NEC for r=0.3 class 6 = 0.389 +- 0.142 (in-sample avg dev_std = 0.203)
NEC for r=0.3 class 7 = 0.354 +- 0.142 (in-sample avg dev_std = 0.203)
NEC for r=0.3 class 8 = 0.374 +- 0.142 (in-sample avg dev_std = 0.203)
NEC for r=0.3 class 9 = 0.371 +- 0.142 (in-sample avg dev_std = 0.203)
NEC for r=0.3 all KL = 0.202 +- 0.142 (in-sample avg dev_std = 0.203)
NEC for r=0.3 all L1 = 0.364 +- 0.118 (in-sample avg dev_std = 0.203)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.21
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.192
NEC for r=0.6 class 0 = 0.385 +- 0.212 (in-sample avg dev_std = 0.297)
NEC for r=0.6 class 1 = 0.293 +- 0.212 (in-sample avg dev_std = 0.297)
NEC for r=0.6 class 2 = 0.432 +- 0.212 (in-sample avg dev_std = 0.297)
NEC for r=0.6 class 3 = 0.428 +- 0.212 (in-sample avg dev_std = 0.297)
NEC for r=0.6 class 4 = 0.479 +- 0.212 (in-sample avg dev_std = 0.297)
NEC for r=0.6 class 5 = 0.421 +- 0.212 (in-sample avg dev_std = 0.297)
NEC for r=0.6 class 6 = 0.432 +- 0.212 (in-sample avg dev_std = 0.297)
NEC for r=0.6 class 7 = 0.426 +- 0.212 (in-sample avg dev_std = 0.297)
NEC for r=0.6 class 8 = 0.455 +- 0.212 (in-sample avg dev_std = 0.297)
NEC for r=0.6 class 9 = 0.473 +- 0.212 (in-sample avg dev_std = 0.297)
NEC for r=0.6 all KL = 0.35 +- 0.212 (in-sample avg dev_std = 0.297)
NEC for r=0.6 all L1 = 0.421 +- 0.179 (in-sample avg dev_std = 0.297)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.366
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.311
NEC for r=0.9 class 0 = 0.548 +- 0.274 (in-sample avg dev_std = 0.372)
NEC for r=0.9 class 1 = 0.374 +- 0.274 (in-sample avg dev_std = 0.372)
NEC for r=0.9 class 2 = 0.455 +- 0.274 (in-sample avg dev_std = 0.372)
NEC for r=0.9 class 3 = 0.529 +- 0.274 (in-sample avg dev_std = 0.372)
NEC for r=0.9 class 4 = 0.44 +- 0.274 (in-sample avg dev_std = 0.372)
NEC for r=0.9 class 5 = 0.494 +- 0.274 (in-sample avg dev_std = 0.372)
NEC for r=0.9 class 6 = 0.517 +- 0.274 (in-sample avg dev_std = 0.372)
NEC for r=0.9 class 7 = 0.398 +- 0.274 (in-sample avg dev_std = 0.372)
NEC for r=0.9 class 8 = 0.53 +- 0.274 (in-sample avg dev_std = 0.372)
NEC for r=0.9 class 9 = 0.504 +- 0.274 (in-sample avg dev_std = 0.372)
NEC for r=0.9 all KL = 0.517 +- 0.274 (in-sample avg dev_std = 0.372)
NEC for r=0.9 all L1 = 0.478 +- 0.215 (in-sample avg dev_std = 0.372)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.33
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.366
NEC for r=1.0 class 0 = 0.562 +- 0.320 (in-sample avg dev_std = 0.348)
NEC for r=1.0 class 1 = 0.122 +- 0.320 (in-sample avg dev_std = 0.348)
NEC for r=1.0 class 2 = 0.335 +- 0.320 (in-sample avg dev_std = 0.348)
NEC for r=1.0 class 3 = 0.507 +- 0.320 (in-sample avg dev_std = 0.348)
NEC for r=1.0 class 4 = 0.587 +- 0.320 (in-sample avg dev_std = 0.348)
NEC for r=1.0 class 5 = 0.52 +- 0.320 (in-sample avg dev_std = 0.348)
NEC for r=1.0 class 6 = 0.584 +- 0.320 (in-sample avg dev_std = 0.348)
NEC for r=1.0 class 7 = 0.49 +- 0.320 (in-sample avg dev_std = 0.348)
NEC for r=1.0 class 8 = 0.588 +- 0.320 (in-sample avg dev_std = 0.348)
NEC for r=1.0 class 9 = 0.525 +- 0.320 (in-sample avg dev_std = 0.348)
NEC for r=1.0 all KL = 0.56 +- 0.320 (in-sample avg dev_std = 0.348)
NEC for r=1.0 all L1 = 0.476 +- 0.266 (in-sample avg dev_std = 0.348)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Mar 23 02:08:24 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:24 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:08:25 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 198...
[0m[1;37mINFO[0m: [1mCheckpoint 198: 
-----------------------------------
Train ACCURACY: 0.9954
Train Loss: 0.0235
ID Validation ACCURACY: 0.9044
ID Validation Loss: 0.3485
ID Test ACCURACY: 0.8980
ID Test Loss: 0.3777
OOD Validation ACCURACY: 0.8489
OOD Validation Loss: 0.5902
OOD Test ACCURACY: 0.4007
OOD Test Loss: 3.1852

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 79...
[0m[1;37mINFO[0m: [1mCheckpoint 79: 
-----------------------------------
Train ACCURACY: 0.9265
Train Loss: 0.2243
ID Validation ACCURACY: 0.8853
ID Validation Loss: 0.3617
ID Test ACCURACY: 0.8787
ID Test Loss: 0.3669
OOD Validation ACCURACY: 0.8706
OOD Validation Loss: 0.3979
OOD Test ACCURACY: 0.4916
OOD Test Loss: 2.4039

[0m[1;37mINFO[0m: [1mChartInfo 0.8980 0.4007 0.8787 0.4916 0.8853 0.8706[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.123
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.098
SUFF++ for r=0.3 class 0 = 0.57 +- 0.136 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.3 class 1 = 0.538 +- 0.136 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.3 class 2 = 0.573 +- 0.136 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.3 class 3 = 0.558 +- 0.136 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.3 class 4 = 0.575 +- 0.136 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.3 class 5 = 0.57 +- 0.136 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.3 class 6 = 0.545 +- 0.136 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.3 class 7 = 0.547 +- 0.136 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.3 class 8 = 0.583 +- 0.136 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.3 class 9 = 0.549 +- 0.136 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.3 all KL = 0.67 +- 0.136 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.3 all L1 = 0.56 +- 0.083 (in-sample avg dev_std = 0.323)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.287
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.223
SUFF++ for r=0.6 class 0 = 0.475 +- 0.222 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.6 class 1 = 0.525 +- 0.222 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.6 class 2 = 0.457 +- 0.222 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.6 class 3 = 0.432 +- 0.222 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.6 class 4 = 0.462 +- 0.222 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.6 class 5 = 0.454 +- 0.222 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.6 class 6 = 0.449 +- 0.222 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.6 class 7 = 0.454 +- 0.222 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.6 class 8 = 0.432 +- 0.222 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.6 class 9 = 0.423 +- 0.222 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.6 all KL = 0.477 +- 0.222 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.6 all L1 = 0.457 +- 0.148 (in-sample avg dev_std = 0.275)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.834
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.772
SUFF++ for r=0.9 class 0 = 0.933 +- 0.265 (in-sample avg dev_std = 0.299)
SUFF++ for r=0.9 class 1 = 0.977 +- 0.265 (in-sample avg dev_std = 0.299)
SUFF++ for r=0.9 class 2 = 0.78 +- 0.265 (in-sample avg dev_std = 0.299)
SUFF++ for r=0.9 class 3 = 0.702 +- 0.265 (in-sample avg dev_std = 0.299)
SUFF++ for r=0.9 class 4 = 0.82 +- 0.265 (in-sample avg dev_std = 0.299)
SUFF++ for r=0.9 class 5 = 0.752 +- 0.265 (in-sample avg dev_std = 0.299)
SUFF++ for r=0.9 class 6 = 0.812 +- 0.265 (in-sample avg dev_std = 0.299)
SUFF++ for r=0.9 class 7 = 0.791 +- 0.265 (in-sample avg dev_std = 0.299)
SUFF++ for r=0.9 class 8 = 0.747 +- 0.265 (in-sample avg dev_std = 0.299)
SUFF++ for r=0.9 class 9 = 0.77 +- 0.265 (in-sample avg dev_std = 0.299)
SUFF++ for r=0.9 all KL = 0.787 +- 0.265 (in-sample avg dev_std = 0.299)
SUFF++ for r=0.9 all L1 = 0.811 +- 0.207 (in-sample avg dev_std = 0.299)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.108
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.103
SUFF++ for r=0.3 class 0 = 0.566 +- 0.112 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.3 class 1 = 0.545 +- 0.112 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.3 class 2 = 0.579 +- 0.112 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.3 class 3 = 0.585 +- 0.112 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.3 class 4 = 0.55 +- 0.112 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.3 class 5 = 0.569 +- 0.112 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.3 class 6 = 0.558 +- 0.112 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.3 class 7 = 0.557 +- 0.112 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.3 class 8 = 0.58 +- 0.112 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.3 class 9 = 0.556 +- 0.112 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.3 all KL = 0.69 +- 0.112 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.3 all L1 = 0.564 +- 0.076 (in-sample avg dev_std = 0.292)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.251
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.197
SUFF++ for r=0.6 class 0 = 0.507 +- 0.215 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.6 class 1 = 0.553 +- 0.215 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.6 class 2 = 0.504 +- 0.215 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.6 class 3 = 0.506 +- 0.215 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.6 class 4 = 0.458 +- 0.215 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.6 class 5 = 0.49 +- 0.215 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.6 class 6 = 0.475 +- 0.215 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.6 class 7 = 0.508 +- 0.215 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.6 class 8 = 0.458 +- 0.215 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.6 class 9 = 0.458 +- 0.215 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.6 all KL = 0.544 +- 0.215 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.6 all L1 = 0.493 +- 0.149 (in-sample avg dev_std = 0.260)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.791
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.726
SUFF++ for r=0.9 class 0 = 0.903 +- 0.261 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 1 = 0.955 +- 0.261 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 2 = 0.748 +- 0.261 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 3 = 0.752 +- 0.261 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 4 = 0.783 +- 0.261 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 5 = 0.749 +- 0.261 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 6 = 0.695 +- 0.261 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 7 = 0.848 +- 0.261 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 8 = 0.678 +- 0.261 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 9 = 0.72 +- 0.261 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 all KL = 0.775 +- 0.261 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 all L1 = 0.786 +- 0.214 (in-sample avg dev_std = 0.303)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.116
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.103
SUFF++ for r=0.3 class 0 = 0.565 +- 0.120 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.3 class 1 = 0.543 +- 0.120 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.3 class 2 = 0.554 +- 0.120 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.3 class 3 = 0.569 +- 0.120 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.3 class 4 = 0.543 +- 0.120 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.3 class 5 = 0.56 +- 0.120 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.3 class 6 = 0.543 +- 0.120 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.3 class 7 = 0.536 +- 0.120 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.3 class 8 = 0.552 +- 0.120 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.3 class 9 = 0.563 +- 0.120 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.3 all KL = 0.669 +- 0.120 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.3 all L1 = 0.553 +- 0.078 (in-sample avg dev_std = 0.324)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.231
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.198
SUFF++ for r=0.6 class 0 = 0.505 +- 0.230 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.6 class 1 = 0.511 +- 0.230 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.6 class 2 = 0.519 +- 0.230 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.6 class 3 = 0.514 +- 0.230 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.6 class 4 = 0.464 +- 0.230 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.6 class 5 = 0.489 +- 0.230 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.6 class 6 = 0.487 +- 0.230 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.6 class 7 = 0.493 +- 0.230 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.6 class 8 = 0.477 +- 0.230 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.6 class 9 = 0.417 +- 0.230 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.6 all KL = 0.534 +- 0.230 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.6 all L1 = 0.488 +- 0.160 (in-sample avg dev_std = 0.257)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.434
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.423
SUFF++ for r=0.9 class 0 = 0.661 +- 0.200 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 1 = 0.853 +- 0.200 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 2 = 0.677 +- 0.200 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 3 = 0.712 +- 0.200 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 4 = 0.758 +- 0.200 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 5 = 0.753 +- 0.200 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 6 = 0.738 +- 0.200 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 7 = 0.671 +- 0.200 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 8 = 0.672 +- 0.200 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 9 = 0.671 +- 0.200 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 all KL = 0.791 +- 0.200 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 all L1 = 0.717 +- 0.186 (in-sample avg dev_std = 0.305)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.123
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.104
NEC for r=0.3 class 0 = 0.356 +- 0.123 (in-sample avg dev_std = 0.188)
NEC for r=0.3 class 1 = 0.354 +- 0.123 (in-sample avg dev_std = 0.188)
NEC for r=0.3 class 2 = 0.344 +- 0.123 (in-sample avg dev_std = 0.188)
NEC for r=0.3 class 3 = 0.36 +- 0.123 (in-sample avg dev_std = 0.188)
NEC for r=0.3 class 4 = 0.332 +- 0.123 (in-sample avg dev_std = 0.188)
NEC for r=0.3 class 5 = 0.347 +- 0.123 (in-sample avg dev_std = 0.188)
NEC for r=0.3 class 6 = 0.351 +- 0.123 (in-sample avg dev_std = 0.188)
NEC for r=0.3 class 7 = 0.371 +- 0.123 (in-sample avg dev_std = 0.188)
NEC for r=0.3 class 8 = 0.354 +- 0.123 (in-sample avg dev_std = 0.188)
NEC for r=0.3 class 9 = 0.358 +- 0.123 (in-sample avg dev_std = 0.188)
NEC for r=0.3 all KL = 0.18 +- 0.123 (in-sample avg dev_std = 0.188)
NEC for r=0.3 all L1 = 0.353 +- 0.108 (in-sample avg dev_std = 0.188)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.287
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.251
NEC for r=0.6 class 0 = 0.432 +- 0.204 (in-sample avg dev_std = 0.285)
NEC for r=0.6 class 1 = 0.386 +- 0.204 (in-sample avg dev_std = 0.285)
NEC for r=0.6 class 2 = 0.474 +- 0.204 (in-sample avg dev_std = 0.285)
NEC for r=0.6 class 3 = 0.498 +- 0.204 (in-sample avg dev_std = 0.285)
NEC for r=0.6 class 4 = 0.484 +- 0.204 (in-sample avg dev_std = 0.285)
NEC for r=0.6 class 5 = 0.475 +- 0.204 (in-sample avg dev_std = 0.285)
NEC for r=0.6 class 6 = 0.489 +- 0.204 (in-sample avg dev_std = 0.285)
NEC for r=0.6 class 7 = 0.485 +- 0.204 (in-sample avg dev_std = 0.285)
NEC for r=0.6 class 8 = 0.523 +- 0.204 (in-sample avg dev_std = 0.285)
NEC for r=0.6 class 9 = 0.509 +- 0.204 (in-sample avg dev_std = 0.285)
NEC for r=0.6 all KL = 0.399 +- 0.204 (in-sample avg dev_std = 0.285)
NEC for r=0.6 all L1 = 0.474 +- 0.138 (in-sample avg dev_std = 0.285)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.834
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.67
NEC for r=0.9 class 0 = 0.269 +- 0.325 (in-sample avg dev_std = 0.422)
NEC for r=0.9 class 1 = 0.044 +- 0.325 (in-sample avg dev_std = 0.422)
NEC for r=0.9 class 2 = 0.363 +- 0.325 (in-sample avg dev_std = 0.422)
NEC for r=0.9 class 3 = 0.519 +- 0.325 (in-sample avg dev_std = 0.422)
NEC for r=0.9 class 4 = 0.368 +- 0.325 (in-sample avg dev_std = 0.422)
NEC for r=0.9 class 5 = 0.452 +- 0.325 (in-sample avg dev_std = 0.422)
NEC for r=0.9 class 6 = 0.398 +- 0.325 (in-sample avg dev_std = 0.422)
NEC for r=0.9 class 7 = 0.366 +- 0.325 (in-sample avg dev_std = 0.422)
NEC for r=0.9 class 8 = 0.485 +- 0.325 (in-sample avg dev_std = 0.422)
NEC for r=0.9 class 9 = 0.491 +- 0.325 (in-sample avg dev_std = 0.422)
NEC for r=0.9 all KL = 0.521 +- 0.325 (in-sample avg dev_std = 0.422)
NEC for r=0.9 all L1 = 0.37 +- 0.259 (in-sample avg dev_std = 0.422)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.954
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.858
NEC for r=1.0 class 0 = 0.085 +- 0.335 (in-sample avg dev_std = 0.370)
NEC for r=1.0 class 1 = 0.008 +- 0.335 (in-sample avg dev_std = 0.370)
NEC for r=1.0 class 2 = 0.233 +- 0.335 (in-sample avg dev_std = 0.370)
NEC for r=1.0 class 3 = 0.294 +- 0.335 (in-sample avg dev_std = 0.370)
NEC for r=1.0 class 4 = 0.181 +- 0.335 (in-sample avg dev_std = 0.370)
NEC for r=1.0 class 5 = 0.327 +- 0.335 (in-sample avg dev_std = 0.370)
NEC for r=1.0 class 6 = 0.258 +- 0.335 (in-sample avg dev_std = 0.370)
NEC for r=1.0 class 7 = 0.207 +- 0.335 (in-sample avg dev_std = 0.370)
NEC for r=1.0 class 8 = 0.252 +- 0.335 (in-sample avg dev_std = 0.370)
NEC for r=1.0 class 9 = 0.32 +- 0.335 (in-sample avg dev_std = 0.370)
NEC for r=1.0 all KL = 0.345 +- 0.335 (in-sample avg dev_std = 0.370)
NEC for r=1.0 all L1 = 0.212 +- 0.234 (in-sample avg dev_std = 0.370)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.108
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.097
NEC for r=0.3 class 0 = 0.362 +- 0.114 (in-sample avg dev_std = 0.178)
NEC for r=0.3 class 1 = 0.377 +- 0.114 (in-sample avg dev_std = 0.178)
NEC for r=0.3 class 2 = 0.376 +- 0.114 (in-sample avg dev_std = 0.178)
NEC for r=0.3 class 3 = 0.344 +- 0.114 (in-sample avg dev_std = 0.178)
NEC for r=0.3 class 4 = 0.354 +- 0.114 (in-sample avg dev_std = 0.178)
NEC for r=0.3 class 5 = 0.368 +- 0.114 (in-sample avg dev_std = 0.178)
NEC for r=0.3 class 6 = 0.358 +- 0.114 (in-sample avg dev_std = 0.178)
NEC for r=0.3 class 7 = 0.377 +- 0.114 (in-sample avg dev_std = 0.178)
NEC for r=0.3 class 8 = 0.34 +- 0.114 (in-sample avg dev_std = 0.178)
NEC for r=0.3 class 9 = 0.356 +- 0.114 (in-sample avg dev_std = 0.178)
NEC for r=0.3 all KL = 0.18 +- 0.114 (in-sample avg dev_std = 0.178)
NEC for r=0.3 all L1 = 0.361 +- 0.102 (in-sample avg dev_std = 0.178)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.251
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.21
NEC for r=0.6 class 0 = 0.42 +- 0.201 (in-sample avg dev_std = 0.265)
NEC for r=0.6 class 1 = 0.366 +- 0.201 (in-sample avg dev_std = 0.265)
NEC for r=0.6 class 2 = 0.412 +- 0.201 (in-sample avg dev_std = 0.265)
NEC for r=0.6 class 3 = 0.446 +- 0.201 (in-sample avg dev_std = 0.265)
NEC for r=0.6 class 4 = 0.491 +- 0.201 (in-sample avg dev_std = 0.265)
NEC for r=0.6 class 5 = 0.427 +- 0.201 (in-sample avg dev_std = 0.265)
NEC for r=0.6 class 6 = 0.496 +- 0.201 (in-sample avg dev_std = 0.265)
NEC for r=0.6 class 7 = 0.429 +- 0.201 (in-sample avg dev_std = 0.265)
NEC for r=0.6 class 8 = 0.483 +- 0.201 (in-sample avg dev_std = 0.265)
NEC for r=0.6 class 9 = 0.493 +- 0.201 (in-sample avg dev_std = 0.265)
NEC for r=0.6 all KL = 0.351 +- 0.201 (in-sample avg dev_std = 0.265)
NEC for r=0.6 all L1 = 0.446 +- 0.142 (in-sample avg dev_std = 0.265)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.791
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.614
NEC for r=0.9 class 0 = 0.433 +- 0.317 (in-sample avg dev_std = 0.425)
NEC for r=0.9 class 1 = 0.049 +- 0.317 (in-sample avg dev_std = 0.425)
NEC for r=0.9 class 2 = 0.39 +- 0.317 (in-sample avg dev_std = 0.425)
NEC for r=0.9 class 3 = 0.542 +- 0.317 (in-sample avg dev_std = 0.425)
NEC for r=0.9 class 4 = 0.393 +- 0.317 (in-sample avg dev_std = 0.425)
NEC for r=0.9 class 5 = 0.464 +- 0.317 (in-sample avg dev_std = 0.425)
NEC for r=0.9 class 6 = 0.524 +- 0.317 (in-sample avg dev_std = 0.425)
NEC for r=0.9 class 7 = 0.334 +- 0.317 (in-sample avg dev_std = 0.425)
NEC for r=0.9 class 8 = 0.571 +- 0.317 (in-sample avg dev_std = 0.425)
NEC for r=0.9 class 9 = 0.518 +- 0.317 (in-sample avg dev_std = 0.425)
NEC for r=0.9 all KL = 0.544 +- 0.317 (in-sample avg dev_std = 0.425)
NEC for r=0.9 all L1 = 0.416 +- 0.255 (in-sample avg dev_std = 0.425)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.886
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.783
NEC for r=1.0 class 0 = 0.195 +- 0.318 (in-sample avg dev_std = 0.380)
NEC for r=1.0 class 1 = 0.022 +- 0.318 (in-sample avg dev_std = 0.380)
NEC for r=1.0 class 2 = 0.292 +- 0.318 (in-sample avg dev_std = 0.380)
NEC for r=1.0 class 3 = 0.365 +- 0.318 (in-sample avg dev_std = 0.380)
NEC for r=1.0 class 4 = 0.252 +- 0.318 (in-sample avg dev_std = 0.380)
NEC for r=1.0 class 5 = 0.278 +- 0.318 (in-sample avg dev_std = 0.380)
NEC for r=1.0 class 6 = 0.361 +- 0.318 (in-sample avg dev_std = 0.380)
NEC for r=1.0 class 7 = 0.175 +- 0.318 (in-sample avg dev_std = 0.380)
NEC for r=1.0 class 8 = 0.394 +- 0.318 (in-sample avg dev_std = 0.380)
NEC for r=1.0 class 9 = 0.342 +- 0.318 (in-sample avg dev_std = 0.380)
NEC for r=1.0 all KL = 0.368 +- 0.318 (in-sample avg dev_std = 0.380)
NEC for r=1.0 all L1 = 0.264 +- 0.244 (in-sample avg dev_std = 0.380)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.116
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.103
NEC for r=0.3 class 0 = 0.342 +- 0.121 (in-sample avg dev_std = 0.181)
NEC for r=0.3 class 1 = 0.355 +- 0.121 (in-sample avg dev_std = 0.181)
NEC for r=0.3 class 2 = 0.351 +- 0.121 (in-sample avg dev_std = 0.181)
NEC for r=0.3 class 3 = 0.337 +- 0.121 (in-sample avg dev_std = 0.181)
NEC for r=0.3 class 4 = 0.365 +- 0.121 (in-sample avg dev_std = 0.181)
NEC for r=0.3 class 5 = 0.333 +- 0.121 (in-sample avg dev_std = 0.181)
NEC for r=0.3 class 6 = 0.375 +- 0.121 (in-sample avg dev_std = 0.181)
NEC for r=0.3 class 7 = 0.359 +- 0.121 (in-sample avg dev_std = 0.181)
NEC for r=0.3 class 8 = 0.36 +- 0.121 (in-sample avg dev_std = 0.181)
NEC for r=0.3 class 9 = 0.347 +- 0.121 (in-sample avg dev_std = 0.181)
NEC for r=0.3 all KL = 0.177 +- 0.121 (in-sample avg dev_std = 0.181)
NEC for r=0.3 all L1 = 0.353 +- 0.106 (in-sample avg dev_std = 0.181)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.231
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.213
NEC for r=0.6 class 0 = 0.399 +- 0.206 (in-sample avg dev_std = 0.263)
NEC for r=0.6 class 1 = 0.38 +- 0.206 (in-sample avg dev_std = 0.263)
NEC for r=0.6 class 2 = 0.433 +- 0.206 (in-sample avg dev_std = 0.263)
NEC for r=0.6 class 3 = 0.437 +- 0.206 (in-sample avg dev_std = 0.263)
NEC for r=0.6 class 4 = 0.469 +- 0.206 (in-sample avg dev_std = 0.263)
NEC for r=0.6 class 5 = 0.433 +- 0.206 (in-sample avg dev_std = 0.263)
NEC for r=0.6 class 6 = 0.463 +- 0.206 (in-sample avg dev_std = 0.263)
NEC for r=0.6 class 7 = 0.466 +- 0.206 (in-sample avg dev_std = 0.263)
NEC for r=0.6 class 8 = 0.479 +- 0.206 (in-sample avg dev_std = 0.263)
NEC for r=0.6 class 9 = 0.527 +- 0.206 (in-sample avg dev_std = 0.263)
NEC for r=0.6 all KL = 0.36 +- 0.206 (in-sample avg dev_std = 0.263)
NEC for r=0.6 all L1 = 0.448 +- 0.151 (in-sample avg dev_std = 0.263)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.434
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.379
NEC for r=0.9 class 0 = 0.553 +- 0.260 (in-sample avg dev_std = 0.350)
NEC for r=0.9 class 1 = 0.223 +- 0.260 (in-sample avg dev_std = 0.350)
NEC for r=0.9 class 2 = 0.486 +- 0.260 (in-sample avg dev_std = 0.350)
NEC for r=0.9 class 3 = 0.525 +- 0.260 (in-sample avg dev_std = 0.350)
NEC for r=0.9 class 4 = 0.385 +- 0.260 (in-sample avg dev_std = 0.350)
NEC for r=0.9 class 5 = 0.449 +- 0.260 (in-sample avg dev_std = 0.350)
NEC for r=0.9 class 6 = 0.485 +- 0.260 (in-sample avg dev_std = 0.350)
NEC for r=0.9 class 7 = 0.478 +- 0.260 (in-sample avg dev_std = 0.350)
NEC for r=0.9 class 8 = 0.522 +- 0.260 (in-sample avg dev_std = 0.350)
NEC for r=0.9 class 9 = 0.515 +- 0.260 (in-sample avg dev_std = 0.350)
NEC for r=0.9 all KL = 0.462 +- 0.260 (in-sample avg dev_std = 0.350)
NEC for r=0.9 all L1 = 0.46 +- 0.216 (in-sample avg dev_std = 0.350)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.399
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.403
NEC for r=1.0 class 0 = 0.544 +- 0.277 (in-sample avg dev_std = 0.356)
NEC for r=1.0 class 1 = 0.179 +- 0.277 (in-sample avg dev_std = 0.356)
NEC for r=1.0 class 2 = 0.47 +- 0.277 (in-sample avg dev_std = 0.356)
NEC for r=1.0 class 3 = 0.537 +- 0.277 (in-sample avg dev_std = 0.356)
NEC for r=1.0 class 4 = 0.431 +- 0.277 (in-sample avg dev_std = 0.356)
NEC for r=1.0 class 5 = 0.382 +- 0.277 (in-sample avg dev_std = 0.356)
NEC for r=1.0 class 6 = 0.482 +- 0.277 (in-sample avg dev_std = 0.356)
NEC for r=1.0 class 7 = 0.436 +- 0.277 (in-sample avg dev_std = 0.356)
NEC for r=1.0 class 8 = 0.525 +- 0.277 (in-sample avg dev_std = 0.356)
NEC for r=1.0 class 9 = 0.52 +- 0.277 (in-sample avg dev_std = 0.356)
NEC for r=1.0 all KL = 0.471 +- 0.277 (in-sample avg dev_std = 0.356)
NEC for r=1.0 all L1 = 0.449 +- 0.230 (in-sample avg dev_std = 0.356)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Mar 23 02:29:29 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:30 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:29:31 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 196...
[0m[1;37mINFO[0m: [1mCheckpoint 196: 
-----------------------------------
Train ACCURACY: 0.9962
Train Loss: 0.0184
ID Validation ACCURACY: 0.8971
ID Validation Loss: 0.4034
ID Test ACCURACY: 0.8947
ID Test Loss: 0.3939
OOD Validation ACCURACY: 0.7454
OOD Validation Loss: 1.2265
OOD Test ACCURACY: 0.2080
OOD Test Loss: 15.1594

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 121...
[0m[1;37mINFO[0m: [1mCheckpoint 121: 
-----------------------------------
Train ACCURACY: 0.9543
Train Loss: 0.1370
ID Validation ACCURACY: 0.8837
ID Validation Loss: 0.3612
ID Test ACCURACY: 0.8867
ID Test Loss: 0.3557
OOD Validation ACCURACY: 0.8760
OOD Validation Loss: 0.3949
OOD Test ACCURACY: 0.6457
OOD Test Loss: 1.3561

[0m[1;37mINFO[0m: [1mChartInfo 0.8947 0.2080 0.8867 0.6457 0.8837 0.8760[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.149
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.109
SUFF++ for r=0.3 class 0 = 0.449 +- 0.185 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.3 class 1 = 0.341 +- 0.185 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.3 class 2 = 0.446 +- 0.185 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.3 class 3 = 0.448 +- 0.185 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.3 class 4 = 0.451 +- 0.185 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.3 class 5 = 0.465 +- 0.185 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.3 class 6 = 0.43 +- 0.185 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.3 class 7 = 0.436 +- 0.185 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.3 class 8 = 0.451 +- 0.185 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.3 class 9 = 0.432 +- 0.185 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.3 all KL = 0.478 +- 0.185 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.3 all L1 = 0.433 +- 0.091 (in-sample avg dev_std = 0.445)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.276
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.186
SUFF++ for r=0.6 class 0 = 0.288 +- 0.181 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.6 class 1 = 0.549 +- 0.181 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.6 class 2 = 0.337 +- 0.181 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.6 class 3 = 0.325 +- 0.181 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.6 class 4 = 0.347 +- 0.181 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.6 class 5 = 0.332 +- 0.181 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.6 class 6 = 0.326 +- 0.181 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.6 class 7 = 0.337 +- 0.181 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.6 class 8 = 0.333 +- 0.181 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.6 class 9 = 0.339 +- 0.181 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.6 all KL = 0.189 +- 0.181 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.6 all L1 = 0.354 +- 0.133 (in-sample avg dev_std = 0.472)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.735
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.277
SUFF++ for r=0.9 class 0 = 0.253 +- 0.307 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.9 class 1 = 0.941 +- 0.307 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.9 class 2 = 0.297 +- 0.307 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.9 class 3 = 0.23 +- 0.307 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.9 class 4 = 0.225 +- 0.307 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.9 class 5 = 0.272 +- 0.307 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.9 class 6 = 0.254 +- 0.307 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.9 class 7 = 0.233 +- 0.307 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.9 class 8 = 0.273 +- 0.307 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.9 class 9 = 0.231 +- 0.307 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.9 all KL = 0.133 +- 0.307 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.9 all L1 = 0.329 +- 0.246 (in-sample avg dev_std = 0.506)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.153
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.11
SUFF++ for r=0.3 class 0 = 0.44 +- 0.190 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 class 1 = 0.303 +- 0.190 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 class 2 = 0.434 +- 0.190 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 class 3 = 0.434 +- 0.190 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 class 4 = 0.409 +- 0.190 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 class 5 = 0.44 +- 0.190 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 class 6 = 0.429 +- 0.190 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 class 7 = 0.422 +- 0.190 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 class 8 = 0.43 +- 0.190 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 class 9 = 0.411 +- 0.190 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 all KL = 0.415 +- 0.190 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 all L1 = 0.413 +- 0.099 (in-sample avg dev_std = 0.475)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.207
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.156
SUFF++ for r=0.6 class 0 = 0.273 +- 0.196 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.6 class 1 = 0.625 +- 0.196 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.6 class 2 = 0.3 +- 0.196 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.6 class 3 = 0.313 +- 0.196 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.6 class 4 = 0.367 +- 0.196 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.6 class 5 = 0.309 +- 0.196 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.6 class 6 = 0.34 +- 0.196 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.6 class 7 = 0.342 +- 0.196 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.6 class 8 = 0.319 +- 0.196 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.6 class 9 = 0.353 +- 0.196 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.6 all KL = 0.204 +- 0.196 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.6 all L1 = 0.359 +- 0.158 (in-sample avg dev_std = 0.504)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.521
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.2
SUFF++ for r=0.9 class 0 = 0.231 +- 0.358 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.9 class 1 = 0.947 +- 0.358 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.9 class 2 = 0.299 +- 0.358 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.9 class 3 = 0.249 +- 0.358 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.9 class 4 = 0.375 +- 0.358 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.9 class 5 = 0.294 +- 0.358 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.9 class 6 = 0.328 +- 0.358 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.9 class 7 = 0.283 +- 0.358 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.9 class 8 = 0.27 +- 0.358 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.9 class 9 = 0.366 +- 0.358 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.9 all KL = 0.214 +- 0.358 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.9 all L1 = 0.374 +- 0.285 (in-sample avg dev_std = 0.468)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.147
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.131
SUFF++ for r=0.3 class 0 = 0.469 +- 0.244 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.3 class 1 = 0.25 +- 0.244 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.3 class 2 = 0.459 +- 0.244 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.3 class 3 = 0.411 +- 0.244 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.3 class 4 = 0.353 +- 0.244 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.3 class 5 = 0.384 +- 0.244 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.3 class 6 = 0.396 +- 0.244 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.3 class 7 = 0.398 +- 0.244 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.3 class 8 = 0.378 +- 0.244 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.3 class 9 = 0.325 +- 0.244 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.3 all KL = 0.37 +- 0.244 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.3 all L1 = 0.382 +- 0.135 (in-sample avg dev_std = 0.407)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.138
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.107
SUFF++ for r=0.6 class 0 = 0.279 +- 0.154 (in-sample avg dev_std = 0.548)
SUFF++ for r=0.6 class 1 = 0.328 +- 0.154 (in-sample avg dev_std = 0.548)
SUFF++ for r=0.6 class 2 = 0.295 +- 0.154 (in-sample avg dev_std = 0.548)
SUFF++ for r=0.6 class 3 = 0.33 +- 0.154 (in-sample avg dev_std = 0.548)
SUFF++ for r=0.6 class 4 = 0.305 +- 0.154 (in-sample avg dev_std = 0.548)
SUFF++ for r=0.6 class 5 = 0.322 +- 0.154 (in-sample avg dev_std = 0.548)
SUFF++ for r=0.6 class 6 = 0.301 +- 0.154 (in-sample avg dev_std = 0.548)
SUFF++ for r=0.6 class 7 = 0.327 +- 0.154 (in-sample avg dev_std = 0.548)
SUFF++ for r=0.6 class 8 = 0.33 +- 0.154 (in-sample avg dev_std = 0.548)
SUFF++ for r=0.6 class 9 = 0.322 +- 0.154 (in-sample avg dev_std = 0.548)
SUFF++ for r=0.6 all KL = 0.129 +- 0.154 (in-sample avg dev_std = 0.548)
SUFF++ for r=0.6 all L1 = 0.314 +- 0.117 (in-sample avg dev_std = 0.548)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.171
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.122
SUFF++ for r=0.9 class 0 = 0.325 +- 0.170 (in-sample avg dev_std = 0.679)
SUFF++ for r=0.9 class 1 = 0.391 +- 0.170 (in-sample avg dev_std = 0.679)
SUFF++ for r=0.9 class 2 = 0.304 +- 0.170 (in-sample avg dev_std = 0.679)
SUFF++ for r=0.9 class 3 = 0.311 +- 0.170 (in-sample avg dev_std = 0.679)
SUFF++ for r=0.9 class 4 = 0.31 +- 0.170 (in-sample avg dev_std = 0.679)
SUFF++ for r=0.9 class 5 = 0.276 +- 0.170 (in-sample avg dev_std = 0.679)
SUFF++ for r=0.9 class 6 = 0.32 +- 0.170 (in-sample avg dev_std = 0.679)
SUFF++ for r=0.9 class 7 = 0.292 +- 0.170 (in-sample avg dev_std = 0.679)
SUFF++ for r=0.9 class 8 = 0.322 +- 0.170 (in-sample avg dev_std = 0.679)
SUFF++ for r=0.9 class 9 = 0.327 +- 0.170 (in-sample avg dev_std = 0.679)
SUFF++ for r=0.9 all KL = 0.055 +- 0.170 (in-sample avg dev_std = 0.679)
SUFF++ for r=0.9 all L1 = 0.319 +- 0.162 (in-sample avg dev_std = 0.679)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.149
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.099
NEC for r=0.3 class 0 = 0.561 +- 0.214 (in-sample avg dev_std = 0.214)
NEC for r=0.3 class 1 = 0.617 +- 0.214 (in-sample avg dev_std = 0.214)
NEC for r=0.3 class 2 = 0.543 +- 0.214 (in-sample avg dev_std = 0.214)
NEC for r=0.3 class 3 = 0.534 +- 0.214 (in-sample avg dev_std = 0.214)
NEC for r=0.3 class 4 = 0.524 +- 0.214 (in-sample avg dev_std = 0.214)
NEC for r=0.3 class 5 = 0.506 +- 0.214 (in-sample avg dev_std = 0.214)
NEC for r=0.3 class 6 = 0.542 +- 0.214 (in-sample avg dev_std = 0.214)
NEC for r=0.3 class 7 = 0.527 +- 0.214 (in-sample avg dev_std = 0.214)
NEC for r=0.3 class 8 = 0.54 +- 0.214 (in-sample avg dev_std = 0.214)
NEC for r=0.3 class 9 = 0.528 +- 0.214 (in-sample avg dev_std = 0.214)
NEC for r=0.3 all KL = 0.449 +- 0.214 (in-sample avg dev_std = 0.214)
NEC for r=0.3 all L1 = 0.544 +- 0.121 (in-sample avg dev_std = 0.214)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.276
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.175
NEC for r=0.6 class 0 = 0.719 +- 0.231 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 1 = 0.486 +- 0.231 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 2 = 0.685 +- 0.231 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 3 = 0.673 +- 0.231 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 4 = 0.654 +- 0.231 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 5 = 0.672 +- 0.231 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 6 = 0.646 +- 0.231 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 7 = 0.657 +- 0.231 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 8 = 0.673 +- 0.231 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 9 = 0.662 +- 0.231 (in-sample avg dev_std = 0.353)
NEC for r=0.6 all KL = 0.768 +- 0.231 (in-sample avg dev_std = 0.353)
NEC for r=0.6 all L1 = 0.651 +- 0.154 (in-sample avg dev_std = 0.353)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.735
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.577
NEC for r=0.9 class 0 = 0.523 +- 0.315 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 1 = 0.06 +- 0.315 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 2 = 0.371 +- 0.315 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 3 = 0.513 +- 0.315 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 4 = 0.568 +- 0.315 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 5 = 0.546 +- 0.315 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 6 = 0.611 +- 0.315 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 7 = 0.541 +- 0.315 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 8 = 0.384 +- 0.315 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 9 = 0.687 +- 0.315 (in-sample avg dev_std = 0.447)
NEC for r=0.9 all KL = 0.621 +- 0.315 (in-sample avg dev_std = 0.447)
NEC for r=0.9 all L1 = 0.473 +- 0.256 (in-sample avg dev_std = 0.447)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.956
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.847
NEC for r=1.0 class 0 = 0.107 +- 0.354 (in-sample avg dev_std = 0.399)
NEC for r=1.0 class 1 = 0.007 +- 0.354 (in-sample avg dev_std = 0.399)
NEC for r=1.0 class 2 = 0.235 +- 0.354 (in-sample avg dev_std = 0.399)
NEC for r=1.0 class 3 = 0.264 +- 0.354 (in-sample avg dev_std = 0.399)
NEC for r=1.0 class 4 = 0.162 +- 0.354 (in-sample avg dev_std = 0.399)
NEC for r=1.0 class 5 = 0.337 +- 0.354 (in-sample avg dev_std = 0.399)
NEC for r=1.0 class 6 = 0.312 +- 0.354 (in-sample avg dev_std = 0.399)
NEC for r=1.0 class 7 = 0.266 +- 0.354 (in-sample avg dev_std = 0.399)
NEC for r=1.0 class 8 = 0.172 +- 0.354 (in-sample avg dev_std = 0.399)
NEC for r=1.0 class 9 = 0.333 +- 0.354 (in-sample avg dev_std = 0.399)
NEC for r=1.0 all KL = 0.371 +- 0.354 (in-sample avg dev_std = 0.399)
NEC for r=1.0 all L1 = 0.215 +- 0.239 (in-sample avg dev_std = 0.399)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.153
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.105
NEC for r=0.3 class 0 = 0.551 +- 0.233 (in-sample avg dev_std = 0.206)
NEC for r=0.3 class 1 = 0.641 +- 0.233 (in-sample avg dev_std = 0.206)
NEC for r=0.3 class 2 = 0.543 +- 0.233 (in-sample avg dev_std = 0.206)
NEC for r=0.3 class 3 = 0.538 +- 0.233 (in-sample avg dev_std = 0.206)
NEC for r=0.3 class 4 = 0.524 +- 0.233 (in-sample avg dev_std = 0.206)
NEC for r=0.3 class 5 = 0.515 +- 0.233 (in-sample avg dev_std = 0.206)
NEC for r=0.3 class 6 = 0.53 +- 0.233 (in-sample avg dev_std = 0.206)
NEC for r=0.3 class 7 = 0.53 +- 0.233 (in-sample avg dev_std = 0.206)
NEC for r=0.3 class 8 = 0.514 +- 0.233 (in-sample avg dev_std = 0.206)
NEC for r=0.3 class 9 = 0.517 +- 0.233 (in-sample avg dev_std = 0.206)
NEC for r=0.3 all KL = 0.454 +- 0.233 (in-sample avg dev_std = 0.206)
NEC for r=0.3 all L1 = 0.542 +- 0.136 (in-sample avg dev_std = 0.206)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.207
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.139
NEC for r=0.6 class 0 = 0.733 +- 0.259 (in-sample avg dev_std = 0.358)
NEC for r=0.6 class 1 = 0.389 +- 0.259 (in-sample avg dev_std = 0.358)
NEC for r=0.6 class 2 = 0.676 +- 0.259 (in-sample avg dev_std = 0.358)
NEC for r=0.6 class 3 = 0.658 +- 0.259 (in-sample avg dev_std = 0.358)
NEC for r=0.6 class 4 = 0.652 +- 0.259 (in-sample avg dev_std = 0.358)
NEC for r=0.6 class 5 = 0.686 +- 0.259 (in-sample avg dev_std = 0.358)
NEC for r=0.6 class 6 = 0.669 +- 0.259 (in-sample avg dev_std = 0.358)
NEC for r=0.6 class 7 = 0.662 +- 0.259 (in-sample avg dev_std = 0.358)
NEC for r=0.6 class 8 = 0.664 +- 0.259 (in-sample avg dev_std = 0.358)
NEC for r=0.6 class 9 = 0.642 +- 0.259 (in-sample avg dev_std = 0.358)
NEC for r=0.6 all KL = 0.749 +- 0.259 (in-sample avg dev_std = 0.358)
NEC for r=0.6 all L1 = 0.638 +- 0.189 (in-sample avg dev_std = 0.358)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.521
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.408
NEC for r=0.9 class 0 = 0.637 +- 0.314 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 1 = 0.066 +- 0.314 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 2 = 0.373 +- 0.314 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 3 = 0.536 +- 0.314 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 4 = 0.559 +- 0.314 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 5 = 0.47 +- 0.314 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 6 = 0.617 +- 0.314 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 7 = 0.522 +- 0.314 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 8 = 0.575 +- 0.314 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 9 = 0.631 +- 0.314 (in-sample avg dev_std = 0.393)
NEC for r=0.9 all KL = 0.579 +- 0.314 (in-sample avg dev_std = 0.393)
NEC for r=0.9 all L1 = 0.493 +- 0.252 (in-sample avg dev_std = 0.393)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.765
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.67
NEC for r=1.0 class 0 = 0.489 +- 0.344 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 1 = 0.021 +- 0.344 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 2 = 0.34 +- 0.344 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 3 = 0.302 +- 0.344 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 4 = 0.32 +- 0.344 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 5 = 0.337 +- 0.344 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 6 = 0.425 +- 0.344 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 7 = 0.238 +- 0.344 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 8 = 0.455 +- 0.344 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 9 = 0.475 +- 0.344 (in-sample avg dev_std = 0.402)
NEC for r=1.0 all KL = 0.456 +- 0.344 (in-sample avg dev_std = 0.402)
NEC for r=1.0 all L1 = 0.334 +- 0.273 (in-sample avg dev_std = 0.402)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.147
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.137
NEC for r=0.3 class 0 = 0.51 +- 0.295 (in-sample avg dev_std = 0.193)
NEC for r=0.3 class 1 = 0.729 +- 0.295 (in-sample avg dev_std = 0.193)
NEC for r=0.3 class 2 = 0.519 +- 0.295 (in-sample avg dev_std = 0.193)
NEC for r=0.3 class 3 = 0.555 +- 0.295 (in-sample avg dev_std = 0.193)
NEC for r=0.3 class 4 = 0.635 +- 0.295 (in-sample avg dev_std = 0.193)
NEC for r=0.3 class 5 = 0.565 +- 0.295 (in-sample avg dev_std = 0.193)
NEC for r=0.3 class 6 = 0.577 +- 0.295 (in-sample avg dev_std = 0.193)
NEC for r=0.3 class 7 = 0.554 +- 0.295 (in-sample avg dev_std = 0.193)
NEC for r=0.3 class 8 = 0.593 +- 0.295 (in-sample avg dev_std = 0.193)
NEC for r=0.3 class 9 = 0.653 +- 0.295 (in-sample avg dev_std = 0.193)
NEC for r=0.3 all KL = 0.556 +- 0.295 (in-sample avg dev_std = 0.193)
NEC for r=0.3 all L1 = 0.59 +- 0.171 (in-sample avg dev_std = 0.193)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.138
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.113
NEC for r=0.6 class 0 = 0.715 +- 0.252 (in-sample avg dev_std = 0.362)
NEC for r=0.6 class 1 = 0.648 +- 0.252 (in-sample avg dev_std = 0.362)
NEC for r=0.6 class 2 = 0.661 +- 0.252 (in-sample avg dev_std = 0.362)
NEC for r=0.6 class 3 = 0.646 +- 0.252 (in-sample avg dev_std = 0.362)
NEC for r=0.6 class 4 = 0.718 +- 0.252 (in-sample avg dev_std = 0.362)
NEC for r=0.6 class 5 = 0.646 +- 0.252 (in-sample avg dev_std = 0.362)
NEC for r=0.6 class 6 = 0.637 +- 0.252 (in-sample avg dev_std = 0.362)
NEC for r=0.6 class 7 = 0.632 +- 0.252 (in-sample avg dev_std = 0.362)
NEC for r=0.6 class 8 = 0.689 +- 0.252 (in-sample avg dev_std = 0.362)
NEC for r=0.6 class 9 = 0.709 +- 0.252 (in-sample avg dev_std = 0.362)
NEC for r=0.6 all KL = 0.801 +- 0.252 (in-sample avg dev_std = 0.362)
NEC for r=0.6 all L1 = 0.67 +- 0.190 (in-sample avg dev_std = 0.362)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.171
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.165
NEC for r=0.9 class 0 = 0.318 +- 0.354 (in-sample avg dev_std = 0.358)
NEC for r=0.9 class 1 = 0.605 +- 0.354 (in-sample avg dev_std = 0.358)
NEC for r=0.9 class 2 = 0.28 +- 0.354 (in-sample avg dev_std = 0.358)
NEC for r=0.9 class 3 = 0.412 +- 0.354 (in-sample avg dev_std = 0.358)
NEC for r=0.9 class 4 = 0.53 +- 0.354 (in-sample avg dev_std = 0.358)
NEC for r=0.9 class 5 = 0.476 +- 0.354 (in-sample avg dev_std = 0.358)
NEC for r=0.9 class 6 = 0.51 +- 0.354 (in-sample avg dev_std = 0.358)
NEC for r=0.9 class 7 = 0.492 +- 0.354 (in-sample avg dev_std = 0.358)
NEC for r=0.9 class 8 = 0.551 +- 0.354 (in-sample avg dev_std = 0.358)
NEC for r=0.9 class 9 = 0.552 +- 0.354 (in-sample avg dev_std = 0.358)
NEC for r=0.9 all KL = 0.543 +- 0.354 (in-sample avg dev_std = 0.358)
NEC for r=0.9 all L1 = 0.472 +- 0.284 (in-sample avg dev_std = 0.358)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.214
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.19
NEC for r=1.0 class 0 = 0.37 +- 0.347 (in-sample avg dev_std = 0.341)
NEC for r=1.0 class 1 = 0.382 +- 0.347 (in-sample avg dev_std = 0.341)
NEC for r=1.0 class 2 = 0.304 +- 0.347 (in-sample avg dev_std = 0.341)
NEC for r=1.0 class 3 = 0.407 +- 0.347 (in-sample avg dev_std = 0.341)
NEC for r=1.0 class 4 = 0.428 +- 0.347 (in-sample avg dev_std = 0.341)
NEC for r=1.0 class 5 = 0.438 +- 0.347 (in-sample avg dev_std = 0.341)
NEC for r=1.0 class 6 = 0.486 +- 0.347 (in-sample avg dev_std = 0.341)
NEC for r=1.0 class 7 = 0.421 +- 0.347 (in-sample avg dev_std = 0.341)
NEC for r=1.0 class 8 = 0.455 +- 0.347 (in-sample avg dev_std = 0.341)
NEC for r=1.0 class 9 = 0.468 +- 0.347 (in-sample avg dev_std = 0.341)
NEC for r=1.0 all KL = 0.473 +- 0.347 (in-sample avg dev_std = 0.341)
NEC for r=1.0 all L1 = 0.414 +- 0.284 (in-sample avg dev_std = 0.341)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Mar 23 02:52:41 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 02:52:42 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 199...
[0m[1;37mINFO[0m: [1mCheckpoint 199: 
-----------------------------------
Train ACCURACY: 0.9953
Train Loss: 0.0210
ID Validation ACCURACY: 0.8947
ID Validation Loss: 0.4144
ID Test ACCURACY: 0.8940
ID Test Loss: 0.4075
OOD Validation ACCURACY: 0.8159
OOD Validation Loss: 0.9172
OOD Test ACCURACY: 0.1800
OOD Test Loss: 30.3619

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 128...
[0m[1;37mINFO[0m: [1mCheckpoint 128: 
-----------------------------------
Train ACCURACY: 0.9521
Train Loss: 0.1419
ID Validation ACCURACY: 0.8747
ID Validation Loss: 0.3859
ID Test ACCURACY: 0.8801
ID Test Loss: 0.3806
OOD Validation ACCURACY: 0.8700
OOD Validation Loss: 0.4310
OOD Test ACCURACY: 0.7046
OOD Test Loss: 1.0001

[0m[1;37mINFO[0m: [1mChartInfo 0.8940 0.1800 0.8801 0.7046 0.8747 0.8700[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.119
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.104
SUFF++ for r=0.3 class 0 = 0.556 +- 0.157 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.3 class 1 = 0.514 +- 0.157 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.3 class 2 = 0.546 +- 0.157 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.3 class 3 = 0.541 +- 0.157 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.3 class 4 = 0.529 +- 0.157 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.3 class 5 = 0.53 +- 0.157 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.3 class 6 = 0.532 +- 0.157 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.3 class 7 = 0.534 +- 0.157 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.3 class 8 = 0.548 +- 0.157 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.3 class 9 = 0.531 +- 0.157 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.3 all KL = 0.628 +- 0.157 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.3 all L1 = 0.536 +- 0.103 (in-sample avg dev_std = 0.313)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.244
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.178
SUFF++ for r=0.6 class 0 = 0.381 +- 0.220 (in-sample avg dev_std = 0.406)
SUFF++ for r=0.6 class 1 = 0.384 +- 0.220 (in-sample avg dev_std = 0.406)
SUFF++ for r=0.6 class 2 = 0.431 +- 0.220 (in-sample avg dev_std = 0.406)
SUFF++ for r=0.6 class 3 = 0.381 +- 0.220 (in-sample avg dev_std = 0.406)
SUFF++ for r=0.6 class 4 = 0.399 +- 0.220 (in-sample avg dev_std = 0.406)
SUFF++ for r=0.6 class 5 = 0.389 +- 0.220 (in-sample avg dev_std = 0.406)
SUFF++ for r=0.6 class 6 = 0.39 +- 0.220 (in-sample avg dev_std = 0.406)
SUFF++ for r=0.6 class 7 = 0.408 +- 0.220 (in-sample avg dev_std = 0.406)
SUFF++ for r=0.6 class 8 = 0.392 +- 0.220 (in-sample avg dev_std = 0.406)
SUFF++ for r=0.6 class 9 = 0.4 +- 0.220 (in-sample avg dev_std = 0.406)
SUFF++ for r=0.6 all KL = 0.336 +- 0.220 (in-sample avg dev_std = 0.406)
SUFF++ for r=0.6 all L1 = 0.396 +- 0.136 (in-sample avg dev_std = 0.406)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.827
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.782
SUFF++ for r=0.9 class 0 = 0.933 +- 0.247 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 1 = 0.982 +- 0.247 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 2 = 0.779 +- 0.247 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 3 = 0.768 +- 0.247 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 4 = 0.86 +- 0.247 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 5 = 0.689 +- 0.247 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 6 = 0.843 +- 0.247 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 7 = 0.815 +- 0.247 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 8 = 0.85 +- 0.247 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 9 = 0.763 +- 0.247 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 all KL = 0.832 +- 0.247 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 all L1 = 0.832 +- 0.211 (in-sample avg dev_std = 0.270)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.1
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.098
SUFF++ for r=0.3 class 0 = 0.56 +- 0.152 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.3 class 1 = 0.552 +- 0.152 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.3 class 2 = 0.536 +- 0.152 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.3 class 3 = 0.567 +- 0.152 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.3 class 4 = 0.535 +- 0.152 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.3 class 5 = 0.557 +- 0.152 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.3 class 6 = 0.556 +- 0.152 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.3 class 7 = 0.546 +- 0.152 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.3 class 8 = 0.54 +- 0.152 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.3 class 9 = 0.553 +- 0.152 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.3 all KL = 0.642 +- 0.152 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.3 all L1 = 0.55 +- 0.104 (in-sample avg dev_std = 0.366)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.192
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.137
SUFF++ for r=0.6 class 0 = 0.517 +- 0.229 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.6 class 1 = 0.395 +- 0.229 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.6 class 2 = 0.567 +- 0.229 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.6 class 3 = 0.551 +- 0.229 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.6 class 4 = 0.439 +- 0.229 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.6 class 5 = 0.555 +- 0.229 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.6 class 6 = 0.479 +- 0.229 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.6 class 7 = 0.493 +- 0.229 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.6 class 8 = 0.498 +- 0.229 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.6 class 9 = 0.399 +- 0.229 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.6 all KL = 0.421 +- 0.229 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.6 all L1 = 0.487 +- 0.180 (in-sample avg dev_std = 0.390)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.73
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.683
SUFF++ for r=0.9 class 0 = 0.836 +- 0.237 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 class 1 = 0.946 +- 0.237 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 class 2 = 0.752 +- 0.237 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 class 3 = 0.824 +- 0.237 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 class 4 = 0.78 +- 0.237 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 class 5 = 0.757 +- 0.237 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 class 6 = 0.733 +- 0.237 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 class 7 = 0.818 +- 0.237 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 class 8 = 0.771 +- 0.237 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 class 9 = 0.708 +- 0.237 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 all KL = 0.817 +- 0.237 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 all L1 = 0.795 +- 0.211 (in-sample avg dev_std = 0.277)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.099
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.109
SUFF++ for r=0.3 class 0 = 0.566 +- 0.159 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.3 class 1 = 0.581 +- 0.159 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.3 class 2 = 0.572 +- 0.159 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.3 class 3 = 0.56 +- 0.159 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.3 class 4 = 0.556 +- 0.159 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.3 class 5 = 0.573 +- 0.159 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.3 class 6 = 0.559 +- 0.159 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.3 class 7 = 0.547 +- 0.159 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.3 class 8 = 0.551 +- 0.159 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.3 class 9 = 0.568 +- 0.159 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.3 all KL = 0.669 +- 0.159 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.3 all L1 = 0.563 +- 0.104 (in-sample avg dev_std = 0.384)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.161
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.122
SUFF++ for r=0.6 class 0 = 0.542 +- 0.210 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.6 class 1 = 0.386 +- 0.210 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.6 class 2 = 0.524 +- 0.210 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.6 class 3 = 0.537 +- 0.210 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.6 class 4 = 0.507 +- 0.210 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.6 class 5 = 0.515 +- 0.210 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.6 class 6 = 0.566 +- 0.210 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.6 class 7 = 0.511 +- 0.210 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.6 class 8 = 0.544 +- 0.210 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.6 class 9 = 0.499 +- 0.210 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.6 all KL = 0.359 +- 0.210 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.6 all L1 = 0.512 +- 0.152 (in-sample avg dev_std = 0.519)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.229
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.243
SUFF++ for r=0.9 class 0 = 0.711 +- 0.283 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.9 class 1 = 0.971 +- 0.283 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.9 class 2 = 0.722 +- 0.283 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.9 class 3 = 0.737 +- 0.283 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.9 class 4 = 0.716 +- 0.283 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.9 class 5 = 0.726 +- 0.283 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.9 class 6 = 0.742 +- 0.283 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.9 class 7 = 0.775 +- 0.283 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.9 class 8 = 0.743 +- 0.283 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.9 class 9 = 0.749 +- 0.283 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.9 all KL = 0.763 +- 0.283 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.9 all L1 = 0.762 +- 0.236 (in-sample avg dev_std = 0.341)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.119
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.111
NEC for r=0.3 class 0 = 0.381 +- 0.147 (in-sample avg dev_std = 0.213)
NEC for r=0.3 class 1 = 0.383 +- 0.147 (in-sample avg dev_std = 0.213)
NEC for r=0.3 class 2 = 0.392 +- 0.147 (in-sample avg dev_std = 0.213)
NEC for r=0.3 class 3 = 0.387 +- 0.147 (in-sample avg dev_std = 0.213)
NEC for r=0.3 class 4 = 0.389 +- 0.147 (in-sample avg dev_std = 0.213)
NEC for r=0.3 class 5 = 0.386 +- 0.147 (in-sample avg dev_std = 0.213)
NEC for r=0.3 class 6 = 0.403 +- 0.147 (in-sample avg dev_std = 0.213)
NEC for r=0.3 class 7 = 0.379 +- 0.147 (in-sample avg dev_std = 0.213)
NEC for r=0.3 class 8 = 0.411 +- 0.147 (in-sample avg dev_std = 0.213)
NEC for r=0.3 class 9 = 0.374 +- 0.147 (in-sample avg dev_std = 0.213)
NEC for r=0.3 all KL = 0.227 +- 0.147 (in-sample avg dev_std = 0.213)
NEC for r=0.3 all L1 = 0.388 +- 0.121 (in-sample avg dev_std = 0.213)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.244
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.218
NEC for r=0.6 class 0 = 0.495 +- 0.235 (in-sample avg dev_std = 0.316)
NEC for r=0.6 class 1 = 0.389 +- 0.235 (in-sample avg dev_std = 0.316)
NEC for r=0.6 class 2 = 0.463 +- 0.235 (in-sample avg dev_std = 0.316)
NEC for r=0.6 class 3 = 0.491 +- 0.235 (in-sample avg dev_std = 0.316)
NEC for r=0.6 class 4 = 0.487 +- 0.235 (in-sample avg dev_std = 0.316)
NEC for r=0.6 class 5 = 0.514 +- 0.235 (in-sample avg dev_std = 0.316)
NEC for r=0.6 class 6 = 0.522 +- 0.235 (in-sample avg dev_std = 0.316)
NEC for r=0.6 class 7 = 0.529 +- 0.235 (in-sample avg dev_std = 0.316)
NEC for r=0.6 class 8 = 0.501 +- 0.235 (in-sample avg dev_std = 0.316)
NEC for r=0.6 class 9 = 0.498 +- 0.235 (in-sample avg dev_std = 0.316)
NEC for r=0.6 all KL = 0.454 +- 0.235 (in-sample avg dev_std = 0.316)
NEC for r=0.6 all L1 = 0.487 +- 0.177 (in-sample avg dev_std = 0.316)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.827
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.663
NEC for r=0.9 class 0 = 0.314 +- 0.334 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 1 = 0.045 +- 0.334 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 2 = 0.428 +- 0.334 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 3 = 0.451 +- 0.334 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 4 = 0.284 +- 0.334 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 5 = 0.534 +- 0.334 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 6 = 0.437 +- 0.334 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 7 = 0.378 +- 0.334 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 8 = 0.319 +- 0.334 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 9 = 0.483 +- 0.334 (in-sample avg dev_std = 0.432)
NEC for r=0.9 all KL = 0.521 +- 0.334 (in-sample avg dev_std = 0.432)
NEC for r=0.9 all L1 = 0.361 +- 0.266 (in-sample avg dev_std = 0.432)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.961
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.855
NEC for r=1.0 class 0 = 0.102 +- 0.342 (in-sample avg dev_std = 0.380)
NEC for r=1.0 class 1 = 0.015 +- 0.342 (in-sample avg dev_std = 0.380)
NEC for r=1.0 class 2 = 0.301 +- 0.342 (in-sample avg dev_std = 0.380)
NEC for r=1.0 class 3 = 0.247 +- 0.342 (in-sample avg dev_std = 0.380)
NEC for r=1.0 class 4 = 0.167 +- 0.342 (in-sample avg dev_std = 0.380)
NEC for r=1.0 class 5 = 0.343 +- 0.342 (in-sample avg dev_std = 0.380)
NEC for r=1.0 class 6 = 0.24 +- 0.342 (in-sample avg dev_std = 0.380)
NEC for r=1.0 class 7 = 0.198 +- 0.342 (in-sample avg dev_std = 0.380)
NEC for r=1.0 class 8 = 0.191 +- 0.342 (in-sample avg dev_std = 0.380)
NEC for r=1.0 class 9 = 0.321 +- 0.342 (in-sample avg dev_std = 0.380)
NEC for r=1.0 all KL = 0.358 +- 0.342 (in-sample avg dev_std = 0.380)
NEC for r=1.0 all L1 = 0.208 +- 0.232 (in-sample avg dev_std = 0.380)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.1
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.086
NEC for r=0.3 class 0 = 0.354 +- 0.134 (in-sample avg dev_std = 0.231)
NEC for r=0.3 class 1 = 0.314 +- 0.134 (in-sample avg dev_std = 0.231)
NEC for r=0.3 class 2 = 0.396 +- 0.134 (in-sample avg dev_std = 0.231)
NEC for r=0.3 class 3 = 0.329 +- 0.134 (in-sample avg dev_std = 0.231)
NEC for r=0.3 class 4 = 0.338 +- 0.134 (in-sample avg dev_std = 0.231)
NEC for r=0.3 class 5 = 0.326 +- 0.134 (in-sample avg dev_std = 0.231)
NEC for r=0.3 class 6 = 0.345 +- 0.134 (in-sample avg dev_std = 0.231)
NEC for r=0.3 class 7 = 0.333 +- 0.134 (in-sample avg dev_std = 0.231)
NEC for r=0.3 class 8 = 0.38 +- 0.134 (in-sample avg dev_std = 0.231)
NEC for r=0.3 class 9 = 0.341 +- 0.134 (in-sample avg dev_std = 0.231)
NEC for r=0.3 all KL = 0.193 +- 0.134 (in-sample avg dev_std = 0.231)
NEC for r=0.3 all L1 = 0.345 +- 0.126 (in-sample avg dev_std = 0.231)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.192
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.155
NEC for r=0.6 class 0 = 0.266 +- 0.238 (in-sample avg dev_std = 0.264)
NEC for r=0.6 class 1 = 0.41 +- 0.238 (in-sample avg dev_std = 0.264)
NEC for r=0.6 class 2 = 0.267 +- 0.238 (in-sample avg dev_std = 0.264)
NEC for r=0.6 class 3 = 0.335 +- 0.238 (in-sample avg dev_std = 0.264)
NEC for r=0.6 class 4 = 0.453 +- 0.238 (in-sample avg dev_std = 0.264)
NEC for r=0.6 class 5 = 0.31 +- 0.238 (in-sample avg dev_std = 0.264)
NEC for r=0.6 class 6 = 0.413 +- 0.238 (in-sample avg dev_std = 0.264)
NEC for r=0.6 class 7 = 0.373 +- 0.238 (in-sample avg dev_std = 0.264)
NEC for r=0.6 class 8 = 0.401 +- 0.238 (in-sample avg dev_std = 0.264)
NEC for r=0.6 class 9 = 0.489 +- 0.238 (in-sample avg dev_std = 0.264)
NEC for r=0.6 all KL = 0.317 +- 0.238 (in-sample avg dev_std = 0.264)
NEC for r=0.6 all L1 = 0.374 +- 0.222 (in-sample avg dev_std = 0.264)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.73
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.554
NEC for r=0.9 class 0 = 0.564 +- 0.325 (in-sample avg dev_std = 0.433)
NEC for r=0.9 class 1 = 0.106 +- 0.325 (in-sample avg dev_std = 0.433)
NEC for r=0.9 class 2 = 0.41 +- 0.325 (in-sample avg dev_std = 0.433)
NEC for r=0.9 class 3 = 0.488 +- 0.325 (in-sample avg dev_std = 0.433)
NEC for r=0.9 class 4 = 0.419 +- 0.325 (in-sample avg dev_std = 0.433)
NEC for r=0.9 class 5 = 0.495 +- 0.325 (in-sample avg dev_std = 0.433)
NEC for r=0.9 class 6 = 0.524 +- 0.325 (in-sample avg dev_std = 0.433)
NEC for r=0.9 class 7 = 0.327 +- 0.325 (in-sample avg dev_std = 0.433)
NEC for r=0.9 class 8 = 0.465 +- 0.325 (in-sample avg dev_std = 0.433)
NEC for r=0.9 class 9 = 0.522 +- 0.325 (in-sample avg dev_std = 0.433)
NEC for r=0.9 all KL = 0.558 +- 0.325 (in-sample avg dev_std = 0.433)
NEC for r=0.9 all L1 = 0.426 +- 0.260 (in-sample avg dev_std = 0.433)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.826
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.72
NEC for r=1.0 class 0 = 0.278 +- 0.340 (in-sample avg dev_std = 0.395)
NEC for r=1.0 class 1 = 0.058 +- 0.340 (in-sample avg dev_std = 0.395)
NEC for r=1.0 class 2 = 0.358 +- 0.340 (in-sample avg dev_std = 0.395)
NEC for r=1.0 class 3 = 0.312 +- 0.340 (in-sample avg dev_std = 0.395)
NEC for r=1.0 class 4 = 0.27 +- 0.340 (in-sample avg dev_std = 0.395)
NEC for r=1.0 class 5 = 0.357 +- 0.340 (in-sample avg dev_std = 0.395)
NEC for r=1.0 class 6 = 0.387 +- 0.340 (in-sample avg dev_std = 0.395)
NEC for r=1.0 class 7 = 0.219 +- 0.340 (in-sample avg dev_std = 0.395)
NEC for r=1.0 class 8 = 0.331 +- 0.340 (in-sample avg dev_std = 0.395)
NEC for r=1.0 class 9 = 0.461 +- 0.340 (in-sample avg dev_std = 0.395)
NEC for r=1.0 all KL = 0.42 +- 0.340 (in-sample avg dev_std = 0.395)
NEC for r=1.0 all L1 = 0.299 +- 0.264 (in-sample avg dev_std = 0.395)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.099
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.092
NEC for r=0.3 class 0 = 0.349 +- 0.144 (in-sample avg dev_std = 0.242)
NEC for r=0.3 class 1 = 0.314 +- 0.144 (in-sample avg dev_std = 0.242)
NEC for r=0.3 class 2 = 0.338 +- 0.144 (in-sample avg dev_std = 0.242)
NEC for r=0.3 class 3 = 0.341 +- 0.144 (in-sample avg dev_std = 0.242)
NEC for r=0.3 class 4 = 0.32 +- 0.144 (in-sample avg dev_std = 0.242)
NEC for r=0.3 class 5 = 0.318 +- 0.144 (in-sample avg dev_std = 0.242)
NEC for r=0.3 class 6 = 0.342 +- 0.144 (in-sample avg dev_std = 0.242)
NEC for r=0.3 class 7 = 0.329 +- 0.144 (in-sample avg dev_std = 0.242)
NEC for r=0.3 class 8 = 0.323 +- 0.144 (in-sample avg dev_std = 0.242)
NEC for r=0.3 class 9 = 0.321 +- 0.144 (in-sample avg dev_std = 0.242)
NEC for r=0.3 all KL = 0.191 +- 0.144 (in-sample avg dev_std = 0.242)
NEC for r=0.3 all L1 = 0.33 +- 0.134 (in-sample avg dev_std = 0.242)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.161
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.132
NEC for r=0.6 class 0 = 0.123 +- 0.204 (in-sample avg dev_std = 0.191)
NEC for r=0.6 class 1 = 0.409 +- 0.204 (in-sample avg dev_std = 0.191)
NEC for r=0.6 class 2 = 0.157 +- 0.204 (in-sample avg dev_std = 0.191)
NEC for r=0.6 class 3 = 0.184 +- 0.204 (in-sample avg dev_std = 0.191)
NEC for r=0.6 class 4 = 0.203 +- 0.204 (in-sample avg dev_std = 0.191)
NEC for r=0.6 class 5 = 0.201 +- 0.204 (in-sample avg dev_std = 0.191)
NEC for r=0.6 class 6 = 0.166 +- 0.204 (in-sample avg dev_std = 0.191)
NEC for r=0.6 class 7 = 0.274 +- 0.204 (in-sample avg dev_std = 0.191)
NEC for r=0.6 class 8 = 0.25 +- 0.204 (in-sample avg dev_std = 0.191)
NEC for r=0.6 class 9 = 0.255 +- 0.204 (in-sample avg dev_std = 0.191)
NEC for r=0.6 all KL = 0.174 +- 0.204 (in-sample avg dev_std = 0.191)
NEC for r=0.6 all L1 = 0.224 +- 0.209 (in-sample avg dev_std = 0.191)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.229
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.239
NEC for r=0.9 class 0 = 0.539 +- 0.378 (in-sample avg dev_std = 0.303)
NEC for r=0.9 class 1 = 0.062 +- 0.378 (in-sample avg dev_std = 0.303)
NEC for r=0.9 class 2 = 0.513 +- 0.378 (in-sample avg dev_std = 0.303)
NEC for r=0.9 class 3 = 0.518 +- 0.378 (in-sample avg dev_std = 0.303)
NEC for r=0.9 class 4 = 0.544 +- 0.378 (in-sample avg dev_std = 0.303)
NEC for r=0.9 class 5 = 0.486 +- 0.378 (in-sample avg dev_std = 0.303)
NEC for r=0.9 class 6 = 0.499 +- 0.378 (in-sample avg dev_std = 0.303)
NEC for r=0.9 class 7 = 0.41 +- 0.378 (in-sample avg dev_std = 0.303)
NEC for r=0.9 class 8 = 0.544 +- 0.378 (in-sample avg dev_std = 0.303)
NEC for r=0.9 class 9 = 0.437 +- 0.378 (in-sample avg dev_std = 0.303)
NEC for r=0.9 all KL = 0.545 +- 0.378 (in-sample avg dev_std = 0.303)
NEC for r=0.9 all L1 = 0.451 +- 0.321 (in-sample avg dev_std = 0.303)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.183
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.226
NEC for r=1.0 class 0 = 0.5 +- 0.437 (in-sample avg dev_std = 0.312)
NEC for r=1.0 class 1 = 0.065 +- 0.437 (in-sample avg dev_std = 0.312)
NEC for r=1.0 class 2 = 0.463 +- 0.437 (in-sample avg dev_std = 0.312)
NEC for r=1.0 class 3 = 0.449 +- 0.437 (in-sample avg dev_std = 0.312)
NEC for r=1.0 class 4 = 0.322 +- 0.437 (in-sample avg dev_std = 0.312)
NEC for r=1.0 class 5 = 0.46 +- 0.437 (in-sample avg dev_std = 0.312)
NEC for r=1.0 class 6 = 0.355 +- 0.437 (in-sample avg dev_std = 0.312)
NEC for r=1.0 class 7 = 0.276 +- 0.437 (in-sample avg dev_std = 0.312)
NEC for r=1.0 class 8 = 0.494 +- 0.437 (in-sample avg dev_std = 0.312)
NEC for r=1.0 class 9 = 0.323 +- 0.437 (in-sample avg dev_std = 0.312)
NEC for r=1.0 all KL = 0.506 +- 0.437 (in-sample avg dev_std = 0.312)
NEC for r=1.0 all L1 = 0.368 +- 0.350 (in-sample avg dev_std = 0.312)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Mar 23 03:13:57 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:13:59 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 177...
[0m[1;37mINFO[0m: [1mCheckpoint 177: 
-----------------------------------
Train ACCURACY: 0.9977
Train Loss: 0.0148
ID Validation ACCURACY: 0.8996
ID Validation Loss: 0.3885
ID Test ACCURACY: 0.8940
ID Test Loss: 0.3976
OOD Validation ACCURACY: 0.6997
OOD Validation Loss: 1.7319
OOD Test ACCURACY: 0.1520
OOD Test Loss: 75.5642

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 62...
[0m[1;37mINFO[0m: [1mCheckpoint 62: 
-----------------------------------
Train ACCURACY: 0.9054
Train Loss: 0.2814
ID Validation ACCURACY: 0.8654
ID Validation Loss: 0.4107
ID Test ACCURACY: 0.8644
ID Test Loss: 0.4072
OOD Validation ACCURACY: 0.8570
OOD Validation Loss: 0.4363
OOD Test ACCURACY: 0.7327
OOD Test Loss: 0.9882

[0m[1;37mINFO[0m: [1mChartInfo 0.8940 0.1520 0.8644 0.7327 0.8654 0.8570[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.112
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.1
SUFF++ for r=0.3 class 0 = 0.483 +- 0.238 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 class 1 = 0.462 +- 0.238 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 class 2 = 0.461 +- 0.238 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 class 3 = 0.469 +- 0.238 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 class 4 = 0.445 +- 0.238 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 class 5 = 0.482 +- 0.238 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 class 6 = 0.451 +- 0.238 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 class 7 = 0.49 +- 0.238 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 class 8 = 0.465 +- 0.238 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 class 9 = 0.437 +- 0.238 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 all KL = 0.458 +- 0.238 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 all L1 = 0.465 +- 0.146 (in-sample avg dev_std = 0.415)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.172
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.153
SUFF++ for r=0.6 class 0 = 0.374 +- 0.298 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 class 1 = 0.411 +- 0.298 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 class 2 = 0.436 +- 0.298 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 class 3 = 0.487 +- 0.298 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 class 4 = 0.497 +- 0.298 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 class 5 = 0.419 +- 0.298 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 class 6 = 0.485 +- 0.298 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 class 7 = 0.375 +- 0.298 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 class 8 = 0.616 +- 0.298 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 class 9 = 0.479 +- 0.298 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 all KL = 0.31 +- 0.298 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 all L1 = 0.457 +- 0.240 (in-sample avg dev_std = 0.444)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.83
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.756
SUFF++ for r=0.9 class 0 = 0.948 +- 0.270 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 1 = 0.956 +- 0.270 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 2 = 0.738 +- 0.270 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 3 = 0.67 +- 0.270 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 4 = 0.841 +- 0.270 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 5 = 0.716 +- 0.270 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 6 = 0.756 +- 0.270 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 7 = 0.81 +- 0.270 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 8 = 0.886 +- 0.270 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 9 = 0.739 +- 0.270 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 all KL = 0.799 +- 0.270 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 all L1 = 0.808 +- 0.225 (in-sample avg dev_std = 0.305)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.096
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.102
SUFF++ for r=0.3 class 0 = 0.515 +- 0.243 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.3 class 1 = 0.574 +- 0.243 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.3 class 2 = 0.545 +- 0.243 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.3 class 3 = 0.549 +- 0.243 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.3 class 4 = 0.52 +- 0.243 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.3 class 5 = 0.56 +- 0.243 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.3 class 6 = 0.51 +- 0.243 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.3 class 7 = 0.509 +- 0.243 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.3 class 8 = 0.521 +- 0.243 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.3 class 9 = 0.526 +- 0.243 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.3 all KL = 0.568 +- 0.243 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.3 all L1 = 0.533 +- 0.171 (in-sample avg dev_std = 0.385)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.189
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.142
SUFF++ for r=0.6 class 0 = 0.472 +- 0.295 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 class 1 = 0.413 +- 0.295 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 class 2 = 0.513 +- 0.295 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 class 3 = 0.465 +- 0.295 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 class 4 = 0.461 +- 0.295 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 class 5 = 0.411 +- 0.295 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 class 6 = 0.469 +- 0.295 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 class 7 = 0.452 +- 0.295 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 class 8 = 0.445 +- 0.295 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 class 9 = 0.424 +- 0.295 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 all KL = 0.363 +- 0.295 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 all L1 = 0.452 +- 0.218 (in-sample avg dev_std = 0.452)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.639
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.604
SUFF++ for r=0.9 class 0 = 0.787 +- 0.255 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.9 class 1 = 0.973 +- 0.255 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.9 class 2 = 0.73 +- 0.255 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.9 class 3 = 0.7 +- 0.255 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.9 class 4 = 0.765 +- 0.255 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.9 class 5 = 0.738 +- 0.255 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.9 class 6 = 0.705 +- 0.255 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.9 class 7 = 0.847 +- 0.255 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.9 class 8 = 0.665 +- 0.255 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.9 class 9 = 0.68 +- 0.255 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.9 all KL = 0.774 +- 0.255 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.9 all L1 = 0.763 +- 0.218 (in-sample avg dev_std = 0.324)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.106
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.105
SUFF++ for r=0.3 class 0 = 0.427 +- 0.281 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.3 class 1 = 0.433 +- 0.281 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.3 class 2 = 0.44 +- 0.281 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.3 class 3 = 0.493 +- 0.281 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.3 class 4 = 0.523 +- 0.281 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.3 class 5 = 0.493 +- 0.281 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.3 class 6 = 0.515 +- 0.281 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.3 class 7 = 0.474 +- 0.281 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.3 class 8 = 0.509 +- 0.281 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.3 class 9 = 0.538 +- 0.281 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.3 all KL = 0.402 +- 0.281 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.3 all L1 = 0.483 +- 0.179 (in-sample avg dev_std = 0.593)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.189
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.185
SUFF++ for r=0.6 class 0 = 0.627 +- 0.362 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 class 1 = 0.746 +- 0.362 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 class 2 = 0.727 +- 0.362 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 class 3 = 0.701 +- 0.362 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 class 4 = 0.631 +- 0.362 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 class 5 = 0.686 +- 0.362 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 class 6 = 0.586 +- 0.362 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 class 7 = 0.59 +- 0.362 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 class 8 = 0.679 +- 0.362 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 class 9 = 0.544 +- 0.362 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 all KL = 0.586 +- 0.362 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 all L1 = 0.653 +- 0.289 (in-sample avg dev_std = 0.379)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.172
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.181
SUFF++ for r=0.9 class 0 = 0.849 +- 0.207 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.9 class 1 = 0.992 +- 0.207 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.9 class 2 = 0.863 +- 0.207 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.9 class 3 = 0.866 +- 0.207 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.9 class 4 = 0.851 +- 0.207 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.9 class 5 = 0.849 +- 0.207 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.9 class 6 = 0.883 +- 0.207 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.9 class 7 = 0.889 +- 0.207 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.9 class 8 = 0.843 +- 0.207 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.9 class 9 = 0.891 +- 0.207 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.9 all KL = 0.889 +- 0.207 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.9 all L1 = 0.879 +- 0.188 (in-sample avg dev_std = 0.226)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.112
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.1
NEC for r=0.3 class 0 = 0.427 +- 0.233 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 1 = 0.497 +- 0.233 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 2 = 0.505 +- 0.233 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 3 = 0.447 +- 0.233 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 4 = 0.476 +- 0.233 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 5 = 0.442 +- 0.233 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 6 = 0.498 +- 0.233 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 7 = 0.437 +- 0.233 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 8 = 0.479 +- 0.233 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 9 = 0.508 +- 0.233 (in-sample avg dev_std = 0.293)
NEC for r=0.3 all KL = 0.389 +- 0.233 (in-sample avg dev_std = 0.293)
NEC for r=0.3 all L1 = 0.472 +- 0.159 (in-sample avg dev_std = 0.293)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.172
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.137
NEC for r=0.6 class 0 = 0.487 +- 0.301 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 1 = 0.538 +- 0.301 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 2 = 0.461 +- 0.301 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 3 = 0.361 +- 0.301 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 4 = 0.387 +- 0.301 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 5 = 0.397 +- 0.301 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 6 = 0.422 +- 0.301 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 7 = 0.522 +- 0.301 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 8 = 0.322 +- 0.301 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 9 = 0.442 +- 0.301 (in-sample avg dev_std = 0.387)
NEC for r=0.6 all KL = 0.472 +- 0.301 (in-sample avg dev_std = 0.387)
NEC for r=0.6 all L1 = 0.437 +- 0.252 (in-sample avg dev_std = 0.387)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.83
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.605
NEC for r=0.9 class 0 = 0.274 +- 0.336 (in-sample avg dev_std = 0.468)
NEC for r=0.9 class 1 = 0.174 +- 0.336 (in-sample avg dev_std = 0.468)
NEC for r=0.9 class 2 = 0.507 +- 0.336 (in-sample avg dev_std = 0.468)
NEC for r=0.9 class 3 = 0.64 +- 0.336 (in-sample avg dev_std = 0.468)
NEC for r=0.9 class 4 = 0.33 +- 0.336 (in-sample avg dev_std = 0.468)
NEC for r=0.9 class 5 = 0.551 +- 0.336 (in-sample avg dev_std = 0.468)
NEC for r=0.9 class 6 = 0.45 +- 0.336 (in-sample avg dev_std = 0.468)
NEC for r=0.9 class 7 = 0.378 +- 0.336 (in-sample avg dev_std = 0.468)
NEC for r=0.9 class 8 = 0.302 +- 0.336 (in-sample avg dev_std = 0.468)
NEC for r=0.9 class 9 = 0.477 +- 0.336 (in-sample avg dev_std = 0.468)
NEC for r=0.9 all KL = 0.586 +- 0.336 (in-sample avg dev_std = 0.468)
NEC for r=0.9 all L1 = 0.405 +- 0.270 (in-sample avg dev_std = 0.468)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.952
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.833
NEC for r=1.0 class 0 = 0.095 +- 0.360 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 1 = 0.016 +- 0.360 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 2 = 0.287 +- 0.360 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 3 = 0.386 +- 0.360 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 4 = 0.159 +- 0.360 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 5 = 0.373 +- 0.360 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 6 = 0.285 +- 0.360 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 7 = 0.18 +- 0.360 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 8 = 0.191 +- 0.360 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 9 = 0.358 +- 0.360 (in-sample avg dev_std = 0.402)
NEC for r=1.0 all KL = 0.384 +- 0.360 (in-sample avg dev_std = 0.402)
NEC for r=1.0 all L1 = 0.228 +- 0.251 (in-sample avg dev_std = 0.402)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.096
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.096
NEC for r=0.3 class 0 = 0.444 +- 0.205 (in-sample avg dev_std = 0.303)
NEC for r=0.3 class 1 = 0.372 +- 0.205 (in-sample avg dev_std = 0.303)
NEC for r=0.3 class 2 = 0.423 +- 0.205 (in-sample avg dev_std = 0.303)
NEC for r=0.3 class 3 = 0.401 +- 0.205 (in-sample avg dev_std = 0.303)
NEC for r=0.3 class 4 = 0.438 +- 0.205 (in-sample avg dev_std = 0.303)
NEC for r=0.3 class 5 = 0.416 +- 0.205 (in-sample avg dev_std = 0.303)
NEC for r=0.3 class 6 = 0.462 +- 0.205 (in-sample avg dev_std = 0.303)
NEC for r=0.3 class 7 = 0.453 +- 0.205 (in-sample avg dev_std = 0.303)
NEC for r=0.3 class 8 = 0.448 +- 0.205 (in-sample avg dev_std = 0.303)
NEC for r=0.3 class 9 = 0.444 +- 0.205 (in-sample avg dev_std = 0.303)
NEC for r=0.3 all KL = 0.338 +- 0.205 (in-sample avg dev_std = 0.303)
NEC for r=0.3 all L1 = 0.429 +- 0.161 (in-sample avg dev_std = 0.303)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.189
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.156
NEC for r=0.6 class 0 = 0.42 +- 0.270 (in-sample avg dev_std = 0.381)
NEC for r=0.6 class 1 = 0.459 +- 0.270 (in-sample avg dev_std = 0.381)
NEC for r=0.6 class 2 = 0.451 +- 0.270 (in-sample avg dev_std = 0.381)
NEC for r=0.6 class 3 = 0.448 +- 0.270 (in-sample avg dev_std = 0.381)
NEC for r=0.6 class 4 = 0.453 +- 0.270 (in-sample avg dev_std = 0.381)
NEC for r=0.6 class 5 = 0.47 +- 0.270 (in-sample avg dev_std = 0.381)
NEC for r=0.6 class 6 = 0.48 +- 0.270 (in-sample avg dev_std = 0.381)
NEC for r=0.6 class 7 = 0.475 +- 0.270 (in-sample avg dev_std = 0.381)
NEC for r=0.6 class 8 = 0.472 +- 0.270 (in-sample avg dev_std = 0.381)
NEC for r=0.6 class 9 = 0.474 +- 0.270 (in-sample avg dev_std = 0.381)
NEC for r=0.6 all KL = 0.459 +- 0.270 (in-sample avg dev_std = 0.381)
NEC for r=0.6 all L1 = 0.46 +- 0.219 (in-sample avg dev_std = 0.381)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.639
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.503
NEC for r=0.9 class 0 = 0.527 +- 0.336 (in-sample avg dev_std = 0.431)
NEC for r=0.9 class 1 = 0.061 +- 0.336 (in-sample avg dev_std = 0.431)
NEC for r=0.9 class 2 = 0.393 +- 0.336 (in-sample avg dev_std = 0.431)
NEC for r=0.9 class 3 = 0.575 +- 0.336 (in-sample avg dev_std = 0.431)
NEC for r=0.9 class 4 = 0.417 +- 0.336 (in-sample avg dev_std = 0.431)
NEC for r=0.9 class 5 = 0.447 +- 0.336 (in-sample avg dev_std = 0.431)
NEC for r=0.9 class 6 = 0.539 +- 0.336 (in-sample avg dev_std = 0.431)
NEC for r=0.9 class 7 = 0.298 +- 0.336 (in-sample avg dev_std = 0.431)
NEC for r=0.9 class 8 = 0.537 +- 0.336 (in-sample avg dev_std = 0.431)
NEC for r=0.9 class 9 = 0.492 +- 0.336 (in-sample avg dev_std = 0.431)
NEC for r=0.9 all KL = 0.533 +- 0.336 (in-sample avg dev_std = 0.431)
NEC for r=0.9 all L1 = 0.422 +- 0.271 (in-sample avg dev_std = 0.431)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.719
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.621
NEC for r=1.0 class 0 = 0.439 +- 0.347 (in-sample avg dev_std = 0.426)
NEC for r=1.0 class 1 = 0.024 +- 0.347 (in-sample avg dev_std = 0.426)
NEC for r=1.0 class 2 = 0.366 +- 0.347 (in-sample avg dev_std = 0.426)
NEC for r=1.0 class 3 = 0.497 +- 0.347 (in-sample avg dev_std = 0.426)
NEC for r=1.0 class 4 = 0.313 +- 0.347 (in-sample avg dev_std = 0.426)
NEC for r=1.0 class 5 = 0.336 +- 0.347 (in-sample avg dev_std = 0.426)
NEC for r=1.0 class 6 = 0.446 +- 0.347 (in-sample avg dev_std = 0.426)
NEC for r=1.0 class 7 = 0.208 +- 0.347 (in-sample avg dev_std = 0.426)
NEC for r=1.0 class 8 = 0.451 +- 0.347 (in-sample avg dev_std = 0.426)
NEC for r=1.0 class 9 = 0.445 +- 0.347 (in-sample avg dev_std = 0.426)
NEC for r=1.0 all KL = 0.457 +- 0.347 (in-sample avg dev_std = 0.426)
NEC for r=1.0 all L1 = 0.347 +- 0.277 (in-sample avg dev_std = 0.426)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.106
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.116
NEC for r=0.3 class 0 = 0.362 +- 0.258 (in-sample avg dev_std = 0.333)
NEC for r=0.3 class 1 = 0.347 +- 0.258 (in-sample avg dev_std = 0.333)
NEC for r=0.3 class 2 = 0.367 +- 0.258 (in-sample avg dev_std = 0.333)
NEC for r=0.3 class 3 = 0.373 +- 0.258 (in-sample avg dev_std = 0.333)
NEC for r=0.3 class 4 = 0.362 +- 0.258 (in-sample avg dev_std = 0.333)
NEC for r=0.3 class 5 = 0.376 +- 0.258 (in-sample avg dev_std = 0.333)
NEC for r=0.3 class 6 = 0.394 +- 0.258 (in-sample avg dev_std = 0.333)
NEC for r=0.3 class 7 = 0.411 +- 0.258 (in-sample avg dev_std = 0.333)
NEC for r=0.3 class 8 = 0.413 +- 0.258 (in-sample avg dev_std = 0.333)
NEC for r=0.3 class 9 = 0.38 +- 0.258 (in-sample avg dev_std = 0.333)
NEC for r=0.3 all KL = 0.326 +- 0.258 (in-sample avg dev_std = 0.333)
NEC for r=0.3 all L1 = 0.378 +- 0.193 (in-sample avg dev_std = 0.333)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.189
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.188
NEC for r=0.6 class 0 = 0.311 +- 0.292 (in-sample avg dev_std = 0.352)
NEC for r=0.6 class 1 = 0.124 +- 0.292 (in-sample avg dev_std = 0.352)
NEC for r=0.6 class 2 = 0.292 +- 0.292 (in-sample avg dev_std = 0.352)
NEC for r=0.6 class 3 = 0.283 +- 0.292 (in-sample avg dev_std = 0.352)
NEC for r=0.6 class 4 = 0.28 +- 0.292 (in-sample avg dev_std = 0.352)
NEC for r=0.6 class 5 = 0.287 +- 0.292 (in-sample avg dev_std = 0.352)
NEC for r=0.6 class 6 = 0.286 +- 0.292 (in-sample avg dev_std = 0.352)
NEC for r=0.6 class 7 = 0.344 +- 0.292 (in-sample avg dev_std = 0.352)
NEC for r=0.6 class 8 = 0.298 +- 0.292 (in-sample avg dev_std = 0.352)
NEC for r=0.6 class 9 = 0.382 +- 0.292 (in-sample avg dev_std = 0.352)
NEC for r=0.6 all KL = 0.318 +- 0.292 (in-sample avg dev_std = 0.352)
NEC for r=0.6 all L1 = 0.287 +- 0.250 (in-sample avg dev_std = 0.352)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.172
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.182
NEC for r=0.9 class 0 = 0.253 +- 0.315 (in-sample avg dev_std = 0.259)
NEC for r=0.9 class 1 = 0.013 +- 0.315 (in-sample avg dev_std = 0.259)
NEC for r=0.9 class 2 = 0.202 +- 0.315 (in-sample avg dev_std = 0.259)
NEC for r=0.9 class 3 = 0.23 +- 0.315 (in-sample avg dev_std = 0.259)
NEC for r=0.9 class 4 = 0.265 +- 0.315 (in-sample avg dev_std = 0.259)
NEC for r=0.9 class 5 = 0.25 +- 0.315 (in-sample avg dev_std = 0.259)
NEC for r=0.9 class 6 = 0.175 +- 0.315 (in-sample avg dev_std = 0.259)
NEC for r=0.9 class 7 = 0.205 +- 0.315 (in-sample avg dev_std = 0.259)
NEC for r=0.9 class 8 = 0.259 +- 0.315 (in-sample avg dev_std = 0.259)
NEC for r=0.9 class 9 = 0.168 +- 0.315 (in-sample avg dev_std = 0.259)
NEC for r=0.9 all KL = 0.238 +- 0.315 (in-sample avg dev_std = 0.259)
NEC for r=0.9 all L1 = 0.199 +- 0.260 (in-sample avg dev_std = 0.259)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.147
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.164
NEC for r=1.0 class 0 = 0.289 +- 0.363 (in-sample avg dev_std = 0.257)
NEC for r=1.0 class 1 = 0.009 +- 0.363 (in-sample avg dev_std = 0.257)
NEC for r=1.0 class 2 = 0.295 +- 0.363 (in-sample avg dev_std = 0.257)
NEC for r=1.0 class 3 = 0.257 +- 0.363 (in-sample avg dev_std = 0.257)
NEC for r=1.0 class 4 = 0.185 +- 0.363 (in-sample avg dev_std = 0.257)
NEC for r=1.0 class 5 = 0.303 +- 0.363 (in-sample avg dev_std = 0.257)
NEC for r=1.0 class 6 = 0.137 +- 0.363 (in-sample avg dev_std = 0.257)
NEC for r=1.0 class 7 = 0.119 +- 0.363 (in-sample avg dev_std = 0.257)
NEC for r=1.0 class 8 = 0.219 +- 0.363 (in-sample avg dev_std = 0.257)
NEC for r=1.0 class 9 = 0.127 +- 0.363 (in-sample avg dev_std = 0.257)
NEC for r=1.0 all KL = 0.271 +- 0.363 (in-sample avg dev_std = 0.257)
NEC for r=1.0 all L1 = 0.192 +- 0.272 (in-sample avg dev_std = 0.257)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.728, 0.345, 0.844, 1.0], 'all_L1': [0.591, 0.393, 0.833, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.67, 0.477, 0.787, 1.0], 'all_L1': [0.56, 0.457, 0.811, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.478, 0.189, 0.133, 1.0], 'all_L1': [0.433, 0.354, 0.329, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.628, 0.336, 0.832, 1.0], 'all_L1': [0.536, 0.396, 0.832, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.458, 0.31, 0.799, 1.0], 'all_L1': [0.465, 0.457, 0.808, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.253, 0.443, 0.504, 0.345], 'all_L1': [0.414, 0.492, 0.367, 0.222]}), defaultdict(<class 'list'>, {'all_KL': [0.18, 0.399, 0.521, 0.345], 'all_L1': [0.353, 0.474, 0.37, 0.212]}), defaultdict(<class 'list'>, {'all_KL': [0.449, 0.768, 0.621, 0.371], 'all_L1': [0.544, 0.651, 0.473, 0.215]}), defaultdict(<class 'list'>, {'all_KL': [0.227, 0.454, 0.521, 0.358], 'all_L1': [0.388, 0.487, 0.361, 0.208]}), defaultdict(<class 'list'>, {'all_KL': [0.389, 0.472, 0.586, 0.384], 'all_L1': [0.472, 0.437, 0.405, 0.228]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.727, 0.365, 0.841, 1.0], 'all_L1': [0.6, 0.412, 0.811, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.69, 0.544, 0.775, 1.0], 'all_L1': [0.564, 0.493, 0.786, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.415, 0.204, 0.214, 1.0], 'all_L1': [0.413, 0.359, 0.374, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.642, 0.421, 0.817, 1.0], 'all_L1': [0.55, 0.487, 0.795, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.568, 0.363, 0.774, 1.0], 'all_L1': [0.533, 0.452, 0.763, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.213, 0.406, 0.513, 0.355], 'all_L1': [0.382, 0.457, 0.394, 0.265]}), defaultdict(<class 'list'>, {'all_KL': [0.18, 0.351, 0.544, 0.368], 'all_L1': [0.361, 0.446, 0.416, 0.264]}), defaultdict(<class 'list'>, {'all_KL': [0.454, 0.749, 0.579, 0.456], 'all_L1': [0.542, 0.638, 0.493, 0.334]}), defaultdict(<class 'list'>, {'all_KL': [0.193, 0.317, 0.558, 0.42], 'all_L1': [0.345, 0.374, 0.426, 0.299]}), defaultdict(<class 'list'>, {'all_KL': [0.338, 0.459, 0.533, 0.457], 'all_L1': [0.429, 0.46, 0.422, 0.347]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.69, 0.508, 0.77, 1.0], 'all_L1': [0.594, 0.496, 0.717, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.669, 0.534, 0.791, 1.0], 'all_L1': [0.553, 0.488, 0.717, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.37, 0.129, 0.055, 1.0], 'all_L1': [0.382, 0.314, 0.319, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.669, 0.359, 0.763, 1.0], 'all_L1': [0.563, 0.512, 0.762, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.402, 0.586, 0.889, 1.0], 'all_L1': [0.483, 0.653, 0.879, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.202, 0.35, 0.517, 0.56], 'all_L1': [0.364, 0.421, 0.478, 0.476]}), defaultdict(<class 'list'>, {'all_KL': [0.177, 0.36, 0.462, 0.471], 'all_L1': [0.353, 0.448, 0.46, 0.449]}), defaultdict(<class 'list'>, {'all_KL': [0.556, 0.801, 0.543, 0.473], 'all_L1': [0.59, 0.67, 0.472, 0.414]}), defaultdict(<class 'list'>, {'all_KL': [0.191, 0.174, 0.545, 0.506], 'all_L1': [0.33, 0.224, 0.451, 0.368]}), defaultdict(<class 'list'>, {'all_KL': [0.326, 0.318, 0.238, 0.271], 'all_L1': [0.378, 0.287, 0.199, 0.192]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.517 +- 0.059, 0.411 +- 0.040, 0.723 +- 0.197, 1.000 +- 0.000
suff++ class all_KL  =  0.592 +- 0.107, 0.331 +- 0.092, 0.679 +- 0.274, 1.000 +- 0.000
suff++_acc_int  =  0.103 +- 0.004, 0.182 +- 0.023, 0.672 +- 0.197
nec class all_L1  =  0.434 +- 0.067, 0.508 +- 0.074, 0.395 +- 0.042, 0.217 +- 0.007
nec class all_KL  =  0.300 +- 0.102, 0.507 +- 0.133, 0.551 +- 0.045, 0.361 +- 0.015
nec_acc_int  =  0.104 +- 0.005, 0.200 +- 0.040, 0.634 +- 0.036, 0.846 +- 0.010

Eval split val
suff++ class all_L1  =  0.532 +- 0.063, 0.441 +- 0.050, 0.706 +- 0.167, 1.000 +- 0.000
suff++ class all_KL  =  0.608 +- 0.110, 0.379 +- 0.110, 0.684 +- 0.236, 1.000 +- 0.000
suff++_acc_int  =  0.103 +- 0.004, 0.157 +- 0.021, 0.588 +- 0.199
nec class all_L1  =  0.412 +- 0.071, 0.475 +- 0.087, 0.430 +- 0.033, 0.302 +- 0.034
nec class all_KL  =  0.276 +- 0.105, 0.456 +- 0.154, 0.545 +- 0.022, 0.411 +- 0.043
nec_acc_int  =  0.098 +- 0.007, 0.173 +- 0.028, 0.538 +- 0.077, 0.710 +- 0.059

Eval split test
suff++ class all_L1  =  0.515 +- 0.076, 0.493 +- 0.108, 0.679 +- 0.189, 1.000 +- 0.000
suff++ class all_KL  =  0.560 +- 0.143, 0.423 +- 0.165, 0.654 +- 0.303, 1.000 +- 0.000
suff++_acc_int  =  0.110 +- 0.010, 0.154 +- 0.035, 0.264 +- 0.110
nec class all_L1  =  0.403 +- 0.095, 0.410 +- 0.154, 0.412 +- 0.107, 0.380 +- 0.101
nec class all_KL  =  0.290 +- 0.143, 0.401 +- 0.211, 0.461 +- 0.115, 0.456 +- 0.098
nec_acc_int  =  0.112 +- 0.015, 0.168 +- 0.038, 0.255 +- 0.080, 0.270 +- 0.097


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.476 +- 0.017, 0.460 +- 0.023, 0.559 +- 0.079, 0.609 +- 0.004
Faith. Armon (L1)= 		  =  0.464 +- 0.020, 0.449 +- 0.011, 0.490 +- 0.052, 0.357 +- 0.010
Faith. GMean (L1)= 	  =  0.470 +- 0.018, 0.454 +- 0.016, 0.523 +- 0.065, 0.466 +- 0.008
Faith. Aritm (KL)= 		  =  0.446 +- 0.027, 0.419 +- 0.034, 0.615 +- 0.120, 0.680 +- 0.008
Faith. Armon (KL)= 		  =  0.375 +- 0.063, 0.377 +- 0.042, 0.559 +- 0.171, 0.530 +- 0.016
Faith. GMean (KL)= 	  =  0.408 +- 0.041, 0.396 +- 0.020, 0.585 +- 0.149, 0.600 +- 0.013

Eval split val
Faith. Aritm (L1)= 		  =  0.472 +- 0.015, 0.458 +- 0.025, 0.568 +- 0.067, 0.651 +- 0.017
Faith. Armon (L1)= 		  =  0.455 +- 0.020, 0.448 +- 0.017, 0.520 +- 0.048, 0.463 +- 0.040
Faith. GMean (L1)= 	  =  0.463 +- 0.017, 0.453 +- 0.020, 0.543 +- 0.057, 0.548 +- 0.031
Faith. Aritm (KL)= 		  =  0.442 +- 0.018, 0.418 +- 0.039, 0.615 +- 0.110, 0.706 +- 0.021
Faith. Armon (KL)= 		  =  0.354 +- 0.063, 0.380 +- 0.037, 0.577 +- 0.133, 0.581 +- 0.043
Faith. GMean (KL)= 	  =  0.394 +- 0.038, 0.397 +- 0.024, 0.595 +- 0.122, 0.640 +- 0.034

Eval split test
Faith. Aritm (L1)= 		  =  0.459 +- 0.021, 0.451 +- 0.043, 0.545 +- 0.079, 0.690 +- 0.050
Faith. Armon (L1)= 		  =  0.437 +- 0.018, 0.412 +- 0.056, 0.481 +- 0.107, 0.542 +- 0.116
Faith. GMean (L1)= 	  =  0.448 +- 0.019, 0.431 +- 0.048, 0.510 +- 0.088, 0.610 +- 0.090
Faith. Aritm (KL)= 		  =  0.425 +- 0.034, 0.412 +- 0.074, 0.557 +- 0.133, 0.728 +- 0.049
Faith. Armon (KL)= 		  =  0.339 +- 0.059, 0.343 +- 0.094, 0.463 +- 0.204, 0.620 +- 0.101
Faith. GMean (KL)= 	  =  0.378 +- 0.039, 0.373 +- 0.075, 0.503 +- 0.178, 0.671 +- 0.078
Computed for split load_split = id



Completed in  1:48:01.773924  for LECIvGIN GOODCMNIST/color



DONE LECI GOODCMNIST/color

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Mar 23 03:35:47 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:48 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:48 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mCreating GINFeatExtractor:  5
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mUsing  3  layers for classifier
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mInit Backbone:  5
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mCreating vGINFeatExtractor:  5
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mInit CLF:  5
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:35:49 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 72...
[0m[1;37mINFO[0m: [1mCheckpoint 72: 
-----------------------------------
Train ACCURACY: 0.3715
Train Loss: 2.7499
ID Validation ACCURACY: 0.3654
ID Validation Loss: 2.7861
ID Test ACCURACY: 0.3729
ID Test Loss: 2.7814
OOD Validation ACCURACY: 0.3491
OOD Validation Loss: 3.1257
OOD Test ACCURACY: 0.2690
OOD Test Loss: 4.6794

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 85...
[0m[1;37mINFO[0m: [1mCheckpoint 85: 
-----------------------------------
Train ACCURACY: 0.3198
Train Loss: 3.3902
ID Validation ACCURACY: 0.3150
ID Validation Loss: 3.4229
ID Test ACCURACY: 0.3230
ID Test Loss: 3.4163
OOD Validation ACCURACY: 0.3611
OOD Validation Loss: 3.3370
OOD Test ACCURACY: 0.2419
OOD Test Loss: 7.8889

[0m[1;37mINFO[0m: [1mChartInfo 0.3729 0.2690 0.3230 0.2419 0.3150 0.3611[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.381
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.22
SUFF++ for r=0.6 class 0 = 0.335 +- 0.229 (in-sample avg dev_std = 0.581)
SUFF++ for r=0.6 class 1 = 0.484 +- 0.229 (in-sample avg dev_std = 0.581)
SUFF++ for r=0.6 class 2 = 0.304 +- 0.229 (in-sample avg dev_std = 0.581)
SUFF++ for r=0.6 class 3 = 0.295 +- 0.229 (in-sample avg dev_std = 0.581)
SUFF++ for r=0.6 class 4 = 0.404 +- 0.229 (in-sample avg dev_std = 0.581)
SUFF++ for r=0.6 class 5 = 0.327 +- 0.229 (in-sample avg dev_std = 0.581)
SUFF++ for r=0.6 class 6 = 0.382 +- 0.229 (in-sample avg dev_std = 0.581)
SUFF++ for r=0.6 class 7 = 0.362 +- 0.229 (in-sample avg dev_std = 0.581)
SUFF++ for r=0.6 class 8 = 0.314 +- 0.229 (in-sample avg dev_std = 0.581)
SUFF++ for r=0.6 class 9 = 0.482 +- 0.229 (in-sample avg dev_std = 0.581)
SUFF++ for r=0.6 all KL = 0.234 +- 0.229 (in-sample avg dev_std = 0.581)
SUFF++ for r=0.6 all L1 = 0.369 +- 0.139 (in-sample avg dev_std = 0.581)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.349
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.207
SUFF++ for r=0.6 class 0 = 0.339 +- 0.254 (in-sample avg dev_std = 0.625)
SUFF++ for r=0.6 class 1 = 0.793 +- 0.254 (in-sample avg dev_std = 0.625)
SUFF++ for r=0.6 class 2 = 0.29 +- 0.254 (in-sample avg dev_std = 0.625)
SUFF++ for r=0.6 class 3 = 0.27 +- 0.254 (in-sample avg dev_std = 0.625)
SUFF++ for r=0.6 class 4 = 0.367 +- 0.254 (in-sample avg dev_std = 0.625)
SUFF++ for r=0.6 class 5 = 0.291 +- 0.254 (in-sample avg dev_std = 0.625)
SUFF++ for r=0.6 class 6 = 0.309 +- 0.254 (in-sample avg dev_std = 0.625)
SUFF++ for r=0.6 class 7 = 0.34 +- 0.254 (in-sample avg dev_std = 0.625)
SUFF++ for r=0.6 class 8 = 0.286 +- 0.254 (in-sample avg dev_std = 0.625)
SUFF++ for r=0.6 class 9 = 0.322 +- 0.254 (in-sample avg dev_std = 0.625)
SUFF++ for r=0.6 all KL = 0.188 +- 0.254 (in-sample avg dev_std = 0.625)
SUFF++ for r=0.6 all L1 = 0.368 +- 0.190 (in-sample avg dev_std = 0.625)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.25
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.196
SUFF++ for r=0.6 class 0 = 0.283 +- 0.277 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.6 class 1 = 0.77 +- 0.277 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.6 class 2 = 0.243 +- 0.277 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.6 class 3 = 0.24 +- 0.277 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.6 class 4 = 0.201 +- 0.277 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.6 class 5 = 0.258 +- 0.277 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.6 class 6 = 0.222 +- 0.277 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.6 class 7 = 0.253 +- 0.277 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.6 class 8 = 0.221 +- 0.277 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.6 class 9 = 0.225 +- 0.277 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.6 all KL = 0.149 +- 0.277 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.6 all L1 = 0.298 +- 0.208 (in-sample avg dev_std = 0.486)


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.381
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.264
NEC for r=0.6 class 0 = 0.236 +- 0.265 (in-sample avg dev_std = 0.274)
NEC for r=0.6 class 1 = 0.588 +- 0.265 (in-sample avg dev_std = 0.274)
NEC for r=0.6 class 2 = 0.569 +- 0.265 (in-sample avg dev_std = 0.274)
NEC for r=0.6 class 3 = 0.561 +- 0.265 (in-sample avg dev_std = 0.274)
NEC for r=0.6 class 4 = 0.429 +- 0.265 (in-sample avg dev_std = 0.274)
NEC for r=0.6 class 5 = 0.58 +- 0.265 (in-sample avg dev_std = 0.274)
NEC for r=0.6 class 6 = 0.491 +- 0.265 (in-sample avg dev_std = 0.274)
NEC for r=0.6 class 7 = 0.512 +- 0.265 (in-sample avg dev_std = 0.274)
NEC for r=0.6 class 8 = 0.564 +- 0.265 (in-sample avg dev_std = 0.274)
NEC for r=0.6 class 9 = 0.339 +- 0.265 (in-sample avg dev_std = 0.274)
NEC for r=0.6 all KL = 0.448 +- 0.265 (in-sample avg dev_std = 0.274)
NEC for r=0.6 all L1 = 0.489 +- 0.211 (in-sample avg dev_std = 0.274)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.349
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.315
NEC for r=0.6 class 0 = 0.225 +- 0.262 (in-sample avg dev_std = 0.309)
NEC for r=0.6 class 1 = 0.422 +- 0.262 (in-sample avg dev_std = 0.309)
NEC for r=0.6 class 2 = 0.584 +- 0.262 (in-sample avg dev_std = 0.309)
NEC for r=0.6 class 3 = 0.593 +- 0.262 (in-sample avg dev_std = 0.309)
NEC for r=0.6 class 4 = 0.488 +- 0.262 (in-sample avg dev_std = 0.309)
NEC for r=0.6 class 5 = 0.588 +- 0.262 (in-sample avg dev_std = 0.309)
NEC for r=0.6 class 6 = 0.554 +- 0.262 (in-sample avg dev_std = 0.309)
NEC for r=0.6 class 7 = 0.563 +- 0.262 (in-sample avg dev_std = 0.309)
NEC for r=0.6 class 8 = 0.59 +- 0.262 (in-sample avg dev_std = 0.309)
NEC for r=0.6 class 9 = 0.451 +- 0.262 (in-sample avg dev_std = 0.309)
NEC for r=0.6 all KL = 0.504 +- 0.262 (in-sample avg dev_std = 0.309)
NEC for r=0.6 all L1 = 0.505 +- 0.212 (in-sample avg dev_std = 0.309)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.25
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.232
NEC for r=0.6 class 0 = 0.386 +- 0.272 (in-sample avg dev_std = 0.272)
NEC for r=0.6 class 1 = 0.249 +- 0.272 (in-sample avg dev_std = 0.272)
NEC for r=0.6 class 2 = 0.52 +- 0.272 (in-sample avg dev_std = 0.272)
NEC for r=0.6 class 3 = 0.504 +- 0.272 (in-sample avg dev_std = 0.272)
NEC for r=0.6 class 4 = 0.381 +- 0.272 (in-sample avg dev_std = 0.272)
NEC for r=0.6 class 5 = 0.527 +- 0.272 (in-sample avg dev_std = 0.272)
NEC for r=0.6 class 6 = 0.51 +- 0.272 (in-sample avg dev_std = 0.272)
NEC for r=0.6 class 7 = 0.559 +- 0.272 (in-sample avg dev_std = 0.272)
NEC for r=0.6 class 8 = 0.566 +- 0.272 (in-sample avg dev_std = 0.272)
NEC for r=0.6 class 9 = 0.473 +- 0.272 (in-sample avg dev_std = 0.272)
NEC for r=0.6 all KL = 0.427 +- 0.272 (in-sample avg dev_std = 0.272)
NEC for r=0.6 all L1 = 0.465 +- 0.238 (in-sample avg dev_std = 0.272)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Mar 23 03:42:45 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:46 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:46 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:46 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:46 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:46 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:46 AM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:46 AM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:46 AM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:46 AM : [1mCreating GINFeatExtractor:  5
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:46 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:46 AM : [1mUsing  3  layers for classifier
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:46 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:46 AM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:46 AM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:46 AM : [1mInit Backbone:  5
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:46 AM : [1mCreating vGINFeatExtractor:  5
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:46 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:46 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:47 AM : [1mInit CLF:  5
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:47 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:47 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:42:47 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 87...
[0m[1;37mINFO[0m: [1mCheckpoint 87: 
-----------------------------------
Train ACCURACY: 0.7181
Train Loss: 0.8746
ID Validation ACCURACY: 0.6574
ID Validation Loss: 1.2188
ID Test ACCURACY: 0.6584
ID Test Loss: 1.2023
OOD Validation ACCURACY: 0.4703
OOD Validation Loss: 2.8402
OOD Test ACCURACY: 0.1883
OOD Test Loss: 15.9927

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 67...
[0m[1;37mINFO[0m: [1mCheckpoint 67: 
-----------------------------------
Train ACCURACY: 0.6624
Train Loss: 1.0155
ID Validation ACCURACY: 0.6256
ID Validation Loss: 1.1994
ID Test ACCURACY: 0.6141
ID Test Loss: 1.2223
OOD Validation ACCURACY: 0.5277
OOD Validation Loss: 1.8377
OOD Test ACCURACY: 0.2083
OOD Test Loss: 11.1952

[0m[1;37mINFO[0m: [1mChartInfo 0.6584 0.1883 0.6141 0.2083 0.6256 0.5277[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.699
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.212
SUFF++ for r=0.6 class 0 = 0.234 +- 0.073 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.6 class 1 = 0.373 +- 0.073 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.6 class 2 = 0.214 +- 0.073 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.6 class 3 = 0.193 +- 0.073 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.6 class 4 = 0.238 +- 0.073 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.6 class 5 = 0.24 +- 0.073 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.6 class 6 = 0.204 +- 0.073 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.6 class 7 = 0.253 +- 0.073 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.6 class 8 = 0.197 +- 0.073 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.6 class 9 = 0.267 +- 0.073 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.6 all KL = 0.034 +- 0.073 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.6 all L1 = 0.243 +- 0.105 (in-sample avg dev_std = 0.586)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.477
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.181
SUFF++ for r=0.6 class 0 = 0.247 +- 0.116 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.6 class 1 = 0.539 +- 0.116 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.6 class 2 = 0.197 +- 0.116 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.6 class 3 = 0.183 +- 0.116 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.6 class 4 = 0.245 +- 0.116 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.6 class 5 = 0.197 +- 0.116 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.6 class 6 = 0.218 +- 0.116 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.6 class 7 = 0.239 +- 0.116 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.6 class 8 = 0.225 +- 0.116 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.6 class 9 = 0.26 +- 0.116 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.6 all KL = 0.037 +- 0.116 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.6 all L1 = 0.26 +- 0.154 (in-sample avg dev_std = 0.595)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.172
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.156
SUFF++ for r=0.6 class 0 = 0.335 +- 0.330 (in-sample avg dev_std = 0.682)
SUFF++ for r=0.6 class 1 = 0.604 +- 0.330 (in-sample avg dev_std = 0.682)
SUFF++ for r=0.6 class 2 = 0.375 +- 0.330 (in-sample avg dev_std = 0.682)
SUFF++ for r=0.6 class 3 = 0.407 +- 0.330 (in-sample avg dev_std = 0.682)
SUFF++ for r=0.6 class 4 = 0.482 +- 0.330 (in-sample avg dev_std = 0.682)
SUFF++ for r=0.6 class 5 = 0.445 +- 0.330 (in-sample avg dev_std = 0.682)
SUFF++ for r=0.6 class 6 = 0.48 +- 0.330 (in-sample avg dev_std = 0.682)
SUFF++ for r=0.6 class 7 = 0.544 +- 0.330 (in-sample avg dev_std = 0.682)
SUFF++ for r=0.6 class 8 = 0.486 +- 0.330 (in-sample avg dev_std = 0.682)
SUFF++ for r=0.6 class 9 = 0.545 +- 0.330 (in-sample avg dev_std = 0.682)
SUFF++ for r=0.6 all KL = 0.205 +- 0.330 (in-sample avg dev_std = 0.682)
SUFF++ for r=0.6 all L1 = 0.471 +- 0.276 (in-sample avg dev_std = 0.682)


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.699
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.429
NEC for r=0.6 class 0 = 0.669 +- 0.264 (in-sample avg dev_std = 0.440)
NEC for r=0.6 class 1 = 0.271 +- 0.264 (in-sample avg dev_std = 0.440)
NEC for r=0.6 class 2 = 0.587 +- 0.264 (in-sample avg dev_std = 0.440)
NEC for r=0.6 class 3 = 0.553 +- 0.264 (in-sample avg dev_std = 0.440)
NEC for r=0.6 class 4 = 0.516 +- 0.264 (in-sample avg dev_std = 0.440)
NEC for r=0.6 class 5 = 0.597 +- 0.264 (in-sample avg dev_std = 0.440)
NEC for r=0.6 class 6 = 0.663 +- 0.264 (in-sample avg dev_std = 0.440)
NEC for r=0.6 class 7 = 0.64 +- 0.264 (in-sample avg dev_std = 0.440)
NEC for r=0.6 class 8 = 0.537 +- 0.264 (in-sample avg dev_std = 0.440)
NEC for r=0.6 class 9 = 0.6 +- 0.264 (in-sample avg dev_std = 0.440)
NEC for r=0.6 all KL = 0.689 +- 0.264 (in-sample avg dev_std = 0.440)
NEC for r=0.6 all L1 = 0.559 +- 0.215 (in-sample avg dev_std = 0.440)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.477
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.368
NEC for r=0.6 class 0 = 0.564 +- 0.311 (in-sample avg dev_std = 0.443)
NEC for r=0.6 class 1 = 0.125 +- 0.311 (in-sample avg dev_std = 0.443)
NEC for r=0.6 class 2 = 0.608 +- 0.311 (in-sample avg dev_std = 0.443)
NEC for r=0.6 class 3 = 0.503 +- 0.311 (in-sample avg dev_std = 0.443)
NEC for r=0.6 class 4 = 0.566 +- 0.311 (in-sample avg dev_std = 0.443)
NEC for r=0.6 class 5 = 0.611 +- 0.311 (in-sample avg dev_std = 0.443)
NEC for r=0.6 class 6 = 0.61 +- 0.311 (in-sample avg dev_std = 0.443)
NEC for r=0.6 class 7 = 0.635 +- 0.311 (in-sample avg dev_std = 0.443)
NEC for r=0.6 class 8 = 0.445 +- 0.311 (in-sample avg dev_std = 0.443)
NEC for r=0.6 class 9 = 0.588 +- 0.311 (in-sample avg dev_std = 0.443)
NEC for r=0.6 all KL = 0.631 +- 0.311 (in-sample avg dev_std = 0.443)
NEC for r=0.6 all L1 = 0.52 +- 0.251 (in-sample avg dev_std = 0.443)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.172
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.177
NEC for r=0.6 class 0 = 0.35 +- 0.401 (in-sample avg dev_std = 0.373)
NEC for r=0.6 class 1 = 0.102 +- 0.401 (in-sample avg dev_std = 0.373)
NEC for r=0.6 class 2 = 0.41 +- 0.401 (in-sample avg dev_std = 0.373)
NEC for r=0.6 class 3 = 0.394 +- 0.401 (in-sample avg dev_std = 0.373)
NEC for r=0.6 class 4 = 0.276 +- 0.401 (in-sample avg dev_std = 0.373)
NEC for r=0.6 class 5 = 0.43 +- 0.401 (in-sample avg dev_std = 0.373)
NEC for r=0.6 class 6 = 0.25 +- 0.401 (in-sample avg dev_std = 0.373)
NEC for r=0.6 class 7 = 0.294 +- 0.401 (in-sample avg dev_std = 0.373)
NEC for r=0.6 class 8 = 0.354 +- 0.401 (in-sample avg dev_std = 0.373)
NEC for r=0.6 class 9 = 0.227 +- 0.401 (in-sample avg dev_std = 0.373)
NEC for r=0.6 all KL = 0.409 +- 0.401 (in-sample avg dev_std = 0.373)
NEC for r=0.6 all L1 = 0.306 +- 0.310 (in-sample avg dev_std = 0.373)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Mar 23 03:49:48 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:48 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mCreating GINFeatExtractor:  5
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mUsing  3  layers for classifier
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mInit Backbone:  5
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mCreating vGINFeatExtractor:  5
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mInit CLF:  5
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:49:49 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 56...
[0m[1;37mINFO[0m: [1mCheckpoint 56: 
-----------------------------------
Train ACCURACY: 0.4452
Train Loss: 1.8491
ID Validation ACCURACY: 0.4349
ID Validation Loss: 1.9176
ID Test ACCURACY: 0.4390
ID Test Loss: 1.8691
OOD Validation ACCURACY: 0.3544
OOD Validation Loss: 2.4861
OOD Test ACCURACY: 0.2210
OOD Test Loss: 3.7235

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 73...
[0m[1;37mINFO[0m: [1mCheckpoint 73: 
-----------------------------------
Train ACCURACY: 0.4067
Train Loss: 2.3142
ID Validation ACCURACY: 0.3957
ID Validation Loss: 2.4284
ID Test ACCURACY: 0.4073
ID Test Loss: 2.3439
OOD Validation ACCURACY: 0.3826
OOD Validation Loss: 2.4420
OOD Test ACCURACY: 0.2560
OOD Test Loss: 4.6004

[0m[1;37mINFO[0m: [1mChartInfo 0.4390 0.2210 0.4073 0.2560 0.3957 0.3826[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.452
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.19
SUFF++ for r=0.6 class 0 = 0.254 +- 0.150 (in-sample avg dev_std = 0.518)
SUFF++ for r=0.6 class 1 = 0.453 +- 0.150 (in-sample avg dev_std = 0.518)
SUFF++ for r=0.6 class 2 = 0.227 +- 0.150 (in-sample avg dev_std = 0.518)
SUFF++ for r=0.6 class 3 = 0.233 +- 0.150 (in-sample avg dev_std = 0.518)
SUFF++ for r=0.6 class 4 = 0.224 +- 0.150 (in-sample avg dev_std = 0.518)
SUFF++ for r=0.6 class 5 = 0.232 +- 0.150 (in-sample avg dev_std = 0.518)
SUFF++ for r=0.6 class 6 = 0.242 +- 0.150 (in-sample avg dev_std = 0.518)
SUFF++ for r=0.6 class 7 = 0.25 +- 0.150 (in-sample avg dev_std = 0.518)
SUFF++ for r=0.6 class 8 = 0.228 +- 0.150 (in-sample avg dev_std = 0.518)
SUFF++ for r=0.6 class 9 = 0.235 +- 0.150 (in-sample avg dev_std = 0.518)
SUFF++ for r=0.6 all KL = 0.078 +- 0.150 (in-sample avg dev_std = 0.518)
SUFF++ for r=0.6 all L1 = 0.261 +- 0.106 (in-sample avg dev_std = 0.518)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.338
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.191
SUFF++ for r=0.6 class 0 = 0.344 +- 0.165 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.6 class 1 = 0.433 +- 0.165 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.6 class 2 = 0.285 +- 0.165 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.6 class 3 = 0.273 +- 0.165 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.6 class 4 = 0.267 +- 0.165 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.6 class 5 = 0.297 +- 0.165 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.6 class 6 = 0.294 +- 0.165 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.6 class 7 = 0.297 +- 0.165 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.6 class 8 = 0.258 +- 0.165 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.6 class 9 = 0.287 +- 0.165 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.6 all KL = 0.119 +- 0.165 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.6 all L1 = 0.305 +- 0.101 (in-sample avg dev_std = 0.580)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.199
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.16
SUFF++ for r=0.6 class 0 = 0.295 +- 0.128 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 1 = 0.351 +- 0.128 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 2 = 0.218 +- 0.128 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 3 = 0.214 +- 0.128 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 4 = 0.211 +- 0.128 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 5 = 0.237 +- 0.128 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 6 = 0.227 +- 0.128 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 7 = 0.241 +- 0.128 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 8 = 0.221 +- 0.128 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 9 = 0.224 +- 0.128 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 all KL = 0.076 +- 0.128 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 all L1 = 0.245 +- 0.083 (in-sample avg dev_std = 0.478)


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.452
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.351
NEC for r=0.6 class 0 = 0.23 +- 0.219 (in-sample avg dev_std = 0.277)
NEC for r=0.6 class 1 = 0.512 +- 0.219 (in-sample avg dev_std = 0.277)
NEC for r=0.6 class 2 = 0.534 +- 0.219 (in-sample avg dev_std = 0.277)
NEC for r=0.6 class 3 = 0.514 +- 0.219 (in-sample avg dev_std = 0.277)
NEC for r=0.6 class 4 = 0.424 +- 0.219 (in-sample avg dev_std = 0.277)
NEC for r=0.6 class 5 = 0.509 +- 0.219 (in-sample avg dev_std = 0.277)
NEC for r=0.6 class 6 = 0.489 +- 0.219 (in-sample avg dev_std = 0.277)
NEC for r=0.6 class 7 = 0.488 +- 0.219 (in-sample avg dev_std = 0.277)
NEC for r=0.6 class 8 = 0.438 +- 0.219 (in-sample avg dev_std = 0.277)
NEC for r=0.6 class 9 = 0.366 +- 0.219 (in-sample avg dev_std = 0.277)
NEC for r=0.6 all KL = 0.365 +- 0.219 (in-sample avg dev_std = 0.277)
NEC for r=0.6 all L1 = 0.452 +- 0.183 (in-sample avg dev_std = 0.277)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.338
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.289
NEC for r=0.6 class 0 = 0.143 +- 0.218 (in-sample avg dev_std = 0.294)
NEC for r=0.6 class 1 = 0.547 +- 0.218 (in-sample avg dev_std = 0.294)
NEC for r=0.6 class 2 = 0.51 +- 0.218 (in-sample avg dev_std = 0.294)
NEC for r=0.6 class 3 = 0.505 +- 0.218 (in-sample avg dev_std = 0.294)
NEC for r=0.6 class 4 = 0.455 +- 0.218 (in-sample avg dev_std = 0.294)
NEC for r=0.6 class 5 = 0.505 +- 0.218 (in-sample avg dev_std = 0.294)
NEC for r=0.6 class 6 = 0.478 +- 0.218 (in-sample avg dev_std = 0.294)
NEC for r=0.6 class 7 = 0.507 +- 0.218 (in-sample avg dev_std = 0.294)
NEC for r=0.6 class 8 = 0.517 +- 0.218 (in-sample avg dev_std = 0.294)
NEC for r=0.6 class 9 = 0.473 +- 0.218 (in-sample avg dev_std = 0.294)
NEC for r=0.6 all KL = 0.395 +- 0.218 (in-sample avg dev_std = 0.294)
NEC for r=0.6 all L1 = 0.466 +- 0.193 (in-sample avg dev_std = 0.294)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.199
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.192
NEC for r=0.6 class 0 = 0.288 +- 0.254 (in-sample avg dev_std = 0.283)
NEC for r=0.6 class 1 = 0.36 +- 0.254 (in-sample avg dev_std = 0.283)
NEC for r=0.6 class 2 = 0.422 +- 0.254 (in-sample avg dev_std = 0.283)
NEC for r=0.6 class 3 = 0.487 +- 0.254 (in-sample avg dev_std = 0.283)
NEC for r=0.6 class 4 = 0.413 +- 0.254 (in-sample avg dev_std = 0.283)
NEC for r=0.6 class 5 = 0.472 +- 0.254 (in-sample avg dev_std = 0.283)
NEC for r=0.6 class 6 = 0.472 +- 0.254 (in-sample avg dev_std = 0.283)
NEC for r=0.6 class 7 = 0.494 +- 0.254 (in-sample avg dev_std = 0.283)
NEC for r=0.6 class 8 = 0.522 +- 0.254 (in-sample avg dev_std = 0.283)
NEC for r=0.6 class 9 = 0.469 +- 0.254 (in-sample avg dev_std = 0.283)
NEC for r=0.6 all KL = 0.348 +- 0.254 (in-sample avg dev_std = 0.283)
NEC for r=0.6 all L1 = 0.438 +- 0.203 (in-sample avg dev_std = 0.283)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Mar 23 03:56:48 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mCreating GINFeatExtractor:  5
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mUsing  3  layers for classifier
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mInit Backbone:  5
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mCreating vGINFeatExtractor:  5
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mInit CLF:  5
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 03:56:49 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 51...
[0m[1;37mINFO[0m: [1mCheckpoint 51: 
-----------------------------------
Train ACCURACY: 0.6588
Train Loss: 0.9911
ID Validation ACCURACY: 0.6276
ID Validation Loss: 1.1178
ID Test ACCURACY: 0.6277
ID Test Loss: 1.1142
OOD Validation ACCURACY: 0.4983
OOD Validation Loss: 1.7285
OOD Test ACCURACY: 0.2486
OOD Test Loss: 4.9047

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 57...
[0m[1;37mINFO[0m: [1mCheckpoint 57: 
-----------------------------------
Train ACCURACY: 0.5989
Train Loss: 1.1783
ID Validation ACCURACY: 0.5699
ID Validation Loss: 1.3077
ID Test ACCURACY: 0.5776
ID Test Loss: 1.2851
OOD Validation ACCURACY: 0.5351
OOD Validation Loss: 1.4928
OOD Test ACCURACY: 0.2547
OOD Test Loss: 5.2471

[0m[1;37mINFO[0m: [1mChartInfo 0.6277 0.2486 0.5776 0.2547 0.5699 0.5351[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.639
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.232
SUFF++ for r=0.6 class 0 = 0.294 +- 0.224 (in-sample avg dev_std = 0.556)
SUFF++ for r=0.6 class 1 = 0.815 +- 0.224 (in-sample avg dev_std = 0.556)
SUFF++ for r=0.6 class 2 = 0.206 +- 0.224 (in-sample avg dev_std = 0.556)
SUFF++ for r=0.6 class 3 = 0.213 +- 0.224 (in-sample avg dev_std = 0.556)
SUFF++ for r=0.6 class 4 = 0.25 +- 0.224 (in-sample avg dev_std = 0.556)
SUFF++ for r=0.6 class 5 = 0.235 +- 0.224 (in-sample avg dev_std = 0.556)
SUFF++ for r=0.6 class 6 = 0.22 +- 0.224 (in-sample avg dev_std = 0.556)
SUFF++ for r=0.6 class 7 = 0.222 +- 0.224 (in-sample avg dev_std = 0.556)
SUFF++ for r=0.6 class 8 = 0.222 +- 0.224 (in-sample avg dev_std = 0.556)
SUFF++ for r=0.6 class 9 = 0.242 +- 0.224 (in-sample avg dev_std = 0.556)
SUFF++ for r=0.6 all KL = 0.107 +- 0.224 (in-sample avg dev_std = 0.556)
SUFF++ for r=0.6 all L1 = 0.299 +- 0.205 (in-sample avg dev_std = 0.556)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.507
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.206
SUFF++ for r=0.6 class 0 = 0.303 +- 0.300 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.6 class 1 = 0.915 +- 0.300 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.6 class 2 = 0.212 +- 0.300 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.6 class 3 = 0.218 +- 0.300 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.6 class 4 = 0.266 +- 0.300 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.6 class 5 = 0.227 +- 0.300 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.6 class 6 = 0.238 +- 0.300 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.6 class 7 = 0.261 +- 0.300 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.6 class 8 = 0.268 +- 0.300 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.6 class 9 = 0.311 +- 0.300 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.6 all KL = 0.176 +- 0.300 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.6 all L1 = 0.331 +- 0.247 (in-sample avg dev_std = 0.542)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.26
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.185
SUFF++ for r=0.6 class 0 = 0.308 +- 0.337 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.6 class 1 = 0.894 +- 0.337 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.6 class 2 = 0.283 +- 0.337 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.6 class 3 = 0.355 +- 0.337 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.6 class 4 = 0.458 +- 0.337 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.6 class 5 = 0.361 +- 0.337 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.6 class 6 = 0.478 +- 0.337 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.6 class 7 = 0.456 +- 0.337 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.6 class 8 = 0.467 +- 0.337 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.6 class 9 = 0.636 +- 0.337 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.6 all KL = 0.358 +- 0.337 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.6 all L1 = 0.473 +- 0.283 (in-sample avg dev_std = 0.516)


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.639
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.431
NEC for r=0.6 class 0 = 0.591 +- 0.270 (in-sample avg dev_std = 0.316)
NEC for r=0.6 class 1 = 0.096 +- 0.270 (in-sample avg dev_std = 0.316)
NEC for r=0.6 class 2 = 0.519 +- 0.270 (in-sample avg dev_std = 0.316)
NEC for r=0.6 class 3 = 0.499 +- 0.270 (in-sample avg dev_std = 0.316)
NEC for r=0.6 class 4 = 0.491 +- 0.270 (in-sample avg dev_std = 0.316)
NEC for r=0.6 class 5 = 0.552 +- 0.270 (in-sample avg dev_std = 0.316)
NEC for r=0.6 class 6 = 0.634 +- 0.270 (in-sample avg dev_std = 0.316)
NEC for r=0.6 class 7 = 0.603 +- 0.270 (in-sample avg dev_std = 0.316)
NEC for r=0.6 class 8 = 0.564 +- 0.270 (in-sample avg dev_std = 0.316)
NEC for r=0.6 class 9 = 0.612 +- 0.270 (in-sample avg dev_std = 0.316)
NEC for r=0.6 all KL = 0.525 +- 0.270 (in-sample avg dev_std = 0.316)
NEC for r=0.6 all L1 = 0.51 +- 0.214 (in-sample avg dev_std = 0.316)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.507
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.417
NEC for r=0.6 class 0 = 0.418 +- 0.275 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 1 = 0.054 +- 0.275 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 2 = 0.541 +- 0.275 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 3 = 0.552 +- 0.275 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 4 = 0.549 +- 0.275 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 5 = 0.556 +- 0.275 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 6 = 0.576 +- 0.275 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 7 = 0.602 +- 0.275 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 8 = 0.483 +- 0.275 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 9 = 0.566 +- 0.275 (in-sample avg dev_std = 0.328)
NEC for r=0.6 all KL = 0.482 +- 0.275 (in-sample avg dev_std = 0.328)
NEC for r=0.6 all L1 = 0.484 +- 0.228 (in-sample avg dev_std = 0.328)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.26
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.247
NEC for r=0.6 class 0 = 0.448 +- 0.268 (in-sample avg dev_std = 0.284)
NEC for r=0.6 class 1 = 0.049 +- 0.268 (in-sample avg dev_std = 0.284)
NEC for r=0.6 class 2 = 0.506 +- 0.268 (in-sample avg dev_std = 0.284)
NEC for r=0.6 class 3 = 0.446 +- 0.268 (in-sample avg dev_std = 0.284)
NEC for r=0.6 class 4 = 0.35 +- 0.268 (in-sample avg dev_std = 0.284)
NEC for r=0.6 class 5 = 0.447 +- 0.268 (in-sample avg dev_std = 0.284)
NEC for r=0.6 class 6 = 0.302 +- 0.268 (in-sample avg dev_std = 0.284)
NEC for r=0.6 class 7 = 0.39 +- 0.268 (in-sample avg dev_std = 0.284)
NEC for r=0.6 class 8 = 0.374 +- 0.268 (in-sample avg dev_std = 0.284)
NEC for r=0.6 class 9 = 0.213 +- 0.268 (in-sample avg dev_std = 0.284)
NEC for r=0.6 all KL = 0.318 +- 0.268 (in-sample avg dev_std = 0.284)
NEC for r=0.6 all L1 = 0.35 +- 0.252 (in-sample avg dev_std = 0.284)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Mar 23 04:03:58 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mCreating GINFeatExtractor:  5
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mUsing  3  layers for classifier
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mInit Backbone:  5
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mCreating vGINFeatExtractor:  5
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mInit CLF:  5
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:03:59 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:04:00 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 42...
[0m[1;37mINFO[0m: [1mCheckpoint 42: 
-----------------------------------
Train ACCURACY: 0.4206
Train Loss: 1.8923
ID Validation ACCURACY: 0.4203
ID Validation Loss: 1.9484
ID Test ACCURACY: 0.4191
ID Test Loss: 1.8983
OOD Validation ACCURACY: 0.3490
OOD Validation Loss: 2.3843
OOD Test ACCURACY: 0.2689
OOD Test Loss: 2.7813

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 49...
[0m[1;37mINFO[0m: [1mCheckpoint 49: 
-----------------------------------
Train ACCURACY: 0.4088
Train Loss: 1.8664
ID Validation ACCURACY: 0.4009
ID Validation Loss: 1.9187
ID Test ACCURACY: 0.4040
ID Test Loss: 1.9019
OOD Validation ACCURACY: 0.3840
OOD Validation Loss: 2.1207
OOD Test ACCURACY: 0.2513
OOD Test Loss: 3.0490

[0m[1;37mINFO[0m: [1mChartInfo 0.4191 0.2689 0.4040 0.2513 0.4009 0.3840[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.431
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.226
SUFF++ for r=0.6 class 0 = 0.328 +- 0.213 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.6 class 1 = 0.626 +- 0.213 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.6 class 2 = 0.266 +- 0.213 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.6 class 3 = 0.295 +- 0.213 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.6 class 4 = 0.287 +- 0.213 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.6 class 5 = 0.297 +- 0.213 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.6 class 6 = 0.282 +- 0.213 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.6 class 7 = 0.317 +- 0.213 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.6 class 8 = 0.292 +- 0.213 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.6 class 9 = 0.288 +- 0.213 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.6 all KL = 0.19 +- 0.213 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.6 all L1 = 0.332 +- 0.140 (in-sample avg dev_std = 0.577)



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.335
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.195
SUFF++ for r=0.6 class 0 = 0.365 +- 0.238 (in-sample avg dev_std = 0.626)
SUFF++ for r=0.6 class 1 = 0.615 +- 0.238 (in-sample avg dev_std = 0.626)
SUFF++ for r=0.6 class 2 = 0.294 +- 0.238 (in-sample avg dev_std = 0.626)
SUFF++ for r=0.6 class 3 = 0.296 +- 0.238 (in-sample avg dev_std = 0.626)
SUFF++ for r=0.6 class 4 = 0.289 +- 0.238 (in-sample avg dev_std = 0.626)
SUFF++ for r=0.6 class 5 = 0.302 +- 0.238 (in-sample avg dev_std = 0.626)
SUFF++ for r=0.6 class 6 = 0.302 +- 0.238 (in-sample avg dev_std = 0.626)
SUFF++ for r=0.6 class 7 = 0.309 +- 0.238 (in-sample avg dev_std = 0.626)
SUFF++ for r=0.6 class 8 = 0.318 +- 0.238 (in-sample avg dev_std = 0.626)
SUFF++ for r=0.6 class 9 = 0.312 +- 0.238 (in-sample avg dev_std = 0.626)
SUFF++ for r=0.6 all KL = 0.196 +- 0.238 (in-sample avg dev_std = 0.626)
SUFF++ for r=0.6 all L1 = 0.344 +- 0.130 (in-sample avg dev_std = 0.626)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.255
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.186
SUFF++ for r=0.6 class 0 = 0.347 +- 0.210 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.6 class 1 = 0.469 +- 0.210 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.6 class 2 = 0.248 +- 0.210 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.6 class 3 = 0.241 +- 0.210 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.6 class 4 = 0.232 +- 0.210 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.6 class 5 = 0.265 +- 0.210 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.6 class 6 = 0.239 +- 0.210 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.6 class 7 = 0.275 +- 0.210 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.6 class 8 = 0.238 +- 0.210 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.6 class 9 = 0.264 +- 0.210 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.6 all KL = 0.167 +- 0.210 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.6 all L1 = 0.284 +- 0.113 (in-sample avg dev_std = 0.516)


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.431
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.4
NEC for r=0.6 class 0 = 0.242 +- 0.196 (in-sample avg dev_std = 0.242)
NEC for r=0.6 class 1 = 0.317 +- 0.196 (in-sample avg dev_std = 0.242)
NEC for r=0.6 class 2 = 0.455 +- 0.196 (in-sample avg dev_std = 0.242)
NEC for r=0.6 class 3 = 0.442 +- 0.196 (in-sample avg dev_std = 0.242)
NEC for r=0.6 class 4 = 0.386 +- 0.196 (in-sample avg dev_std = 0.242)
NEC for r=0.6 class 5 = 0.493 +- 0.196 (in-sample avg dev_std = 0.242)
NEC for r=0.6 class 6 = 0.501 +- 0.196 (in-sample avg dev_std = 0.242)
NEC for r=0.6 class 7 = 0.467 +- 0.196 (in-sample avg dev_std = 0.242)
NEC for r=0.6 class 8 = 0.441 +- 0.196 (in-sample avg dev_std = 0.242)
NEC for r=0.6 class 9 = 0.421 +- 0.196 (in-sample avg dev_std = 0.242)
NEC for r=0.6 all KL = 0.307 +- 0.196 (in-sample avg dev_std = 0.242)
NEC for r=0.6 all L1 = 0.415 +- 0.168 (in-sample avg dev_std = 0.242)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.335
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.332
NEC for r=0.6 class 0 = 0.074 +- 0.189 (in-sample avg dev_std = 0.262)
NEC for r=0.6 class 1 = 0.379 +- 0.189 (in-sample avg dev_std = 0.262)
NEC for r=0.6 class 2 = 0.43 +- 0.189 (in-sample avg dev_std = 0.262)
NEC for r=0.6 class 3 = 0.45 +- 0.189 (in-sample avg dev_std = 0.262)
NEC for r=0.6 class 4 = 0.418 +- 0.189 (in-sample avg dev_std = 0.262)
NEC for r=0.6 class 5 = 0.431 +- 0.189 (in-sample avg dev_std = 0.262)
NEC for r=0.6 class 6 = 0.446 +- 0.189 (in-sample avg dev_std = 0.262)
NEC for r=0.6 class 7 = 0.461 +- 0.189 (in-sample avg dev_std = 0.262)
NEC for r=0.6 class 8 = 0.407 +- 0.189 (in-sample avg dev_std = 0.262)
NEC for r=0.6 class 9 = 0.439 +- 0.189 (in-sample avg dev_std = 0.262)
NEC for r=0.6 all KL = 0.297 +- 0.189 (in-sample avg dev_std = 0.262)
NEC for r=0.6 all L1 = 0.395 +- 0.185 (in-sample avg dev_std = 0.262)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.255
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.269
NEC for r=0.6 class 0 = 0.203 +- 0.202 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 1 = 0.297 +- 0.202 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 2 = 0.494 +- 0.202 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 3 = 0.495 +- 0.202 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 4 = 0.449 +- 0.202 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 5 = 0.472 +- 0.202 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 6 = 0.486 +- 0.202 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 7 = 0.455 +- 0.202 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 8 = 0.485 +- 0.202 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 9 = 0.428 +- 0.202 (in-sample avg dev_std = 0.237)
NEC for r=0.6 all KL = 0.31 +- 0.202 (in-sample avg dev_std = 0.237)
NEC for r=0.6 all L1 = 0.424 +- 0.173 (in-sample avg dev_std = 0.237)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.234], 'all_L1': [0.369]}), defaultdict(<class 'list'>, {'all_KL': [0.034], 'all_L1': [0.243]}), defaultdict(<class 'list'>, {'all_KL': [0.078], 'all_L1': [0.261]}), defaultdict(<class 'list'>, {'all_KL': [0.107], 'all_L1': [0.299]}), defaultdict(<class 'list'>, {'all_KL': [0.19], 'all_L1': [0.332]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.448], 'all_L1': [0.489]}), defaultdict(<class 'list'>, {'all_KL': [0.689], 'all_L1': [0.559]}), defaultdict(<class 'list'>, {'all_KL': [0.365], 'all_L1': [0.452]}), defaultdict(<class 'list'>, {'all_KL': [0.525], 'all_L1': [0.51]}), defaultdict(<class 'list'>, {'all_KL': [0.307], 'all_L1': [0.415]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.188], 'all_L1': [0.368]}), defaultdict(<class 'list'>, {'all_KL': [0.037], 'all_L1': [0.26]}), defaultdict(<class 'list'>, {'all_KL': [0.119], 'all_L1': [0.305]}), defaultdict(<class 'list'>, {'all_KL': [0.176], 'all_L1': [0.331]}), defaultdict(<class 'list'>, {'all_KL': [0.196], 'all_L1': [0.344]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.504], 'all_L1': [0.505]}), defaultdict(<class 'list'>, {'all_KL': [0.631], 'all_L1': [0.52]}), defaultdict(<class 'list'>, {'all_KL': [0.395], 'all_L1': [0.466]}), defaultdict(<class 'list'>, {'all_KL': [0.482], 'all_L1': [0.484]}), defaultdict(<class 'list'>, {'all_KL': [0.297], 'all_L1': [0.395]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.149], 'all_L1': [0.298]}), defaultdict(<class 'list'>, {'all_KL': [0.205], 'all_L1': [0.471]}), defaultdict(<class 'list'>, {'all_KL': [0.076], 'all_L1': [0.245]}), defaultdict(<class 'list'>, {'all_KL': [0.358], 'all_L1': [0.473]}), defaultdict(<class 'list'>, {'all_KL': [0.167], 'all_L1': [0.284]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.427], 'all_L1': [0.465]}), defaultdict(<class 'list'>, {'all_KL': [0.409], 'all_L1': [0.306]}), defaultdict(<class 'list'>, {'all_KL': [0.348], 'all_L1': [0.438]}), defaultdict(<class 'list'>, {'all_KL': [0.318], 'all_L1': [0.35]}), defaultdict(<class 'list'>, {'all_KL': [0.31], 'all_L1': [0.424]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.301 +- 0.046
suff++ class all_KL  =  0.129 +- 0.073
suff++_acc_int  =  0.216 +- 0.014
nec class all_L1  =  0.485 +- 0.049
nec class all_KL  =  0.467 +- 0.133
nec_acc_int  =  0.375 +- 0.063

Eval split val
suff++ class all_L1  =  0.322 +- 0.037
suff++ class all_KL  =  0.143 +- 0.060
suff++_acc_int  =  0.196 +- 0.010
nec class all_L1  =  0.474 +- 0.044
nec class all_KL  =  0.462 +- 0.112
nec_acc_int  =  0.344 +- 0.045

Eval split test
suff++ class all_L1  =  0.354 +- 0.098
suff++ class all_KL  =  0.191 +- 0.093
suff++_acc_int  =  0.177 +- 0.016
nec class all_L1  =  0.397 +- 0.059
nec class all_KL  =  0.362 +- 0.047
nec_acc_int  =  0.223 +- 0.034


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.393 +- 0.025
Faith. Armon (L1)= 		  =  0.367 +- 0.032
Faith. GMean (L1)= 	  =  0.380 +- 0.027
Faith. Aritm (KL)= 		  =  0.298 +- 0.054
Faith. Armon (KL)= 		  =  0.183 +- 0.084
Faith. GMean (KL)= 	  =  0.225 +- 0.061

Eval split val
Faith. Aritm (L1)= 		  =  0.398 +- 0.023
Faith. Armon (L1)= 		  =  0.380 +- 0.027
Faith. GMean (L1)= 	  =  0.389 +- 0.024
Faith. Aritm (KL)= 		  =  0.303 +- 0.042
Faith. Armon (KL)= 		  =  0.204 +- 0.074
Faith. GMean (KL)= 	  =  0.242 +- 0.055

Eval split test
Faith. Aritm (L1)= 		  =  0.375 +- 0.025
Faith. Armon (L1)= 		  =  0.358 +- 0.030
Faith. GMean (L1)= 	  =  0.367 +- 0.027
Faith. Aritm (KL)= 		  =  0.277 +- 0.046
Faith. Armon (KL)= 		  =  0.235 +- 0.070
Faith. GMean (KL)= 	  =  0.254 +- 0.059
Computed for split load_split = id



Completed in  0:35:11.040492  for CIGAvGIN GOODCMNIST/color



DONE CIGA GOODCMNIST/color

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Mar 23 04:11:15 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:11:16 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 168...
[0m[1;37mINFO[0m: [1mCheckpoint 168: 
-----------------------------------
Train ACCURACY: 0.9513
Train Loss: 0.1416
ID Validation ACCURACY: 0.8979
ID Validation Loss: 0.3406
ID Test ACCURACY: 0.8910
ID Test Loss: 0.3538
OOD Validation ACCURACY: 0.7780
OOD Validation Loss: 0.8665
OOD Test ACCURACY: 0.2856
OOD Test Loss: 5.0562

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 94...
[0m[1;37mINFO[0m: [1mCheckpoint 94: 
-----------------------------------
Train ACCURACY: 0.8921
Train Loss: 0.3223
ID Validation ACCURACY: 0.8611
ID Validation Loss: 0.4189
ID Test ACCURACY: 0.8610
ID Test Loss: 0.4250
OOD Validation ACCURACY: 0.8180
OOD Validation Loss: 0.5733
OOD Test ACCURACY: 0.3071
OOD Test Loss: 3.0050

[0m[1;37mINFO[0m: [1mChartInfo 0.8910 0.2856 0.8610 0.3071 0.8611 0.8180[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.094
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.106
SUFF++ for r=0.3 class 0 = 0.801 +- 0.251 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 class 1 = 0.902 +- 0.251 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 class 2 = 0.748 +- 0.251 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 class 3 = 0.849 +- 0.251 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 class 4 = 0.657 +- 0.251 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 class 5 = 0.779 +- 0.251 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 class 6 = 0.805 +- 0.251 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 class 7 = 0.678 +- 0.251 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 class 8 = 0.815 +- 0.251 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 class 9 = 0.799 +- 0.251 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 all KL = 0.793 +- 0.251 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 all L1 = 0.785 +- 0.231 (in-sample avg dev_std = 0.279)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.132
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.125
SUFF++ for r=0.6 class 0 = 0.305 +- 0.210 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.6 class 1 = 0.539 +- 0.210 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.6 class 2 = 0.381 +- 0.210 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.6 class 3 = 0.372 +- 0.210 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.6 class 4 = 0.353 +- 0.210 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.6 class 5 = 0.352 +- 0.210 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.6 class 6 = 0.329 +- 0.210 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.6 class 7 = 0.364 +- 0.210 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.6 class 8 = 0.31 +- 0.210 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.6 class 9 = 0.341 +- 0.210 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.6 all KL = 0.274 +- 0.210 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.6 all L1 = 0.368 +- 0.144 (in-sample avg dev_std = 0.501)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.794
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.387
SUFF++ for r=0.9 class 0 = 0.272 +- 0.212 (in-sample avg dev_std = 0.662)
SUFF++ for r=0.9 class 1 = 0.303 +- 0.212 (in-sample avg dev_std = 0.662)
SUFF++ for r=0.9 class 2 = 0.348 +- 0.212 (in-sample avg dev_std = 0.662)
SUFF++ for r=0.9 class 3 = 0.327 +- 0.212 (in-sample avg dev_std = 0.662)
SUFF++ for r=0.9 class 4 = 0.347 +- 0.212 (in-sample avg dev_std = 0.662)
SUFF++ for r=0.9 class 5 = 0.336 +- 0.212 (in-sample avg dev_std = 0.662)
SUFF++ for r=0.9 class 6 = 0.343 +- 0.212 (in-sample avg dev_std = 0.662)
SUFF++ for r=0.9 class 7 = 0.681 +- 0.212 (in-sample avg dev_std = 0.662)
SUFF++ for r=0.9 class 8 = 0.343 +- 0.212 (in-sample avg dev_std = 0.662)
SUFF++ for r=0.9 class 9 = 0.34 +- 0.212 (in-sample avg dev_std = 0.662)
SUFF++ for r=0.9 all KL = 0.157 +- 0.212 (in-sample avg dev_std = 0.662)
SUFF++ for r=0.9 all L1 = 0.367 +- 0.165 (in-sample avg dev_std = 0.662)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.117
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.105
SUFF++ for r=0.3 class 0 = 0.657 +- 0.292 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.3 class 1 = 0.765 +- 0.292 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.3 class 2 = 0.614 +- 0.292 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.3 class 3 = 0.634 +- 0.292 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.3 class 4 = 0.675 +- 0.292 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.3 class 5 = 0.61 +- 0.292 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.3 class 6 = 0.784 +- 0.292 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.3 class 7 = 0.686 +- 0.292 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.3 class 8 = 0.689 +- 0.292 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.3 class 9 = 0.731 +- 0.292 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.3 all KL = 0.683 +- 0.292 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.3 all L1 = 0.687 +- 0.250 (in-sample avg dev_std = 0.385)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.11
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.1
SUFF++ for r=0.6 class 0 = 0.345 +- 0.171 (in-sample avg dev_std = 0.611)
SUFF++ for r=0.6 class 1 = 0.378 +- 0.171 (in-sample avg dev_std = 0.611)
SUFF++ for r=0.6 class 2 = 0.418 +- 0.171 (in-sample avg dev_std = 0.611)
SUFF++ for r=0.6 class 3 = 0.404 +- 0.171 (in-sample avg dev_std = 0.611)
SUFF++ for r=0.6 class 4 = 0.397 +- 0.171 (in-sample avg dev_std = 0.611)
SUFF++ for r=0.6 class 5 = 0.423 +- 0.171 (in-sample avg dev_std = 0.611)
SUFF++ for r=0.6 class 6 = 0.402 +- 0.171 (in-sample avg dev_std = 0.611)
SUFF++ for r=0.6 class 7 = 0.395 +- 0.171 (in-sample avg dev_std = 0.611)
SUFF++ for r=0.6 class 8 = 0.364 +- 0.171 (in-sample avg dev_std = 0.611)
SUFF++ for r=0.6 class 9 = 0.389 +- 0.171 (in-sample avg dev_std = 0.611)
SUFF++ for r=0.6 all KL = 0.187 +- 0.171 (in-sample avg dev_std = 0.611)
SUFF++ for r=0.6 all L1 = 0.391 +- 0.107 (in-sample avg dev_std = 0.611)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.565
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.266
SUFF++ for r=0.9 class 0 = 0.271 +- 0.188 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.9 class 1 = 0.364 +- 0.188 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.9 class 2 = 0.395 +- 0.188 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.9 class 3 = 0.329 +- 0.188 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.9 class 4 = 0.372 +- 0.188 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.9 class 5 = 0.338 +- 0.188 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.9 class 6 = 0.337 +- 0.188 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.9 class 7 = 0.473 +- 0.188 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.9 class 8 = 0.304 +- 0.188 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.9 class 9 = 0.334 +- 0.188 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.9 all KL = 0.189 +- 0.188 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.9 all L1 = 0.353 +- 0.138 (in-sample avg dev_std = 0.575)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.117
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.101
SUFF++ for r=0.3 class 0 = 0.501 +- 0.297 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 class 1 = 0.515 +- 0.297 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 class 2 = 0.577 +- 0.297 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 class 3 = 0.599 +- 0.297 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 class 4 = 0.704 +- 0.297 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 class 5 = 0.626 +- 0.297 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 class 6 = 0.649 +- 0.297 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 class 7 = 0.586 +- 0.297 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 class 8 = 0.665 +- 0.297 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 class 9 = 0.594 +- 0.297 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 all KL = 0.558 +- 0.297 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 all L1 = 0.599 +- 0.218 (in-sample avg dev_std = 0.441)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.119
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.109
SUFF++ for r=0.6 class 0 = 0.663 +- 0.258 (in-sample avg dev_std = 0.369)
SUFF++ for r=0.6 class 1 = 0.769 +- 0.258 (in-sample avg dev_std = 0.369)
SUFF++ for r=0.6 class 2 = 0.633 +- 0.258 (in-sample avg dev_std = 0.369)
SUFF++ for r=0.6 class 3 = 0.637 +- 0.258 (in-sample avg dev_std = 0.369)
SUFF++ for r=0.6 class 4 = 0.568 +- 0.258 (in-sample avg dev_std = 0.369)
SUFF++ for r=0.6 class 5 = 0.623 +- 0.258 (in-sample avg dev_std = 0.369)
SUFF++ for r=0.6 class 6 = 0.566 +- 0.258 (in-sample avg dev_std = 0.369)
SUFF++ for r=0.6 class 7 = 0.587 +- 0.258 (in-sample avg dev_std = 0.369)
SUFF++ for r=0.6 class 8 = 0.541 +- 0.258 (in-sample avg dev_std = 0.369)
SUFF++ for r=0.6 class 9 = 0.475 +- 0.258 (in-sample avg dev_std = 0.369)
SUFF++ for r=0.6 all KL = 0.465 +- 0.258 (in-sample avg dev_std = 0.369)
SUFF++ for r=0.6 all L1 = 0.609 +- 0.211 (in-sample avg dev_std = 0.369)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.251
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.174
SUFF++ for r=0.9 class 0 = 0.404 +- 0.275 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.9 class 1 = 0.503 +- 0.275 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.9 class 2 = 0.625 +- 0.275 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.9 class 3 = 0.491 +- 0.275 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.9 class 4 = 0.562 +- 0.275 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.9 class 5 = 0.605 +- 0.275 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.9 class 6 = 0.527 +- 0.275 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.9 class 7 = 0.548 +- 0.275 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.9 class 8 = 0.445 +- 0.275 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.9 class 9 = 0.472 +- 0.275 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.9 all KL = 0.389 +- 0.275 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.9 all L1 = 0.517 +- 0.236 (in-sample avg dev_std = 0.411)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.094
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.11
NEC for r=0.3 class 0 = 0.233 +- 0.283 (in-sample avg dev_std = 0.268)
NEC for r=0.3 class 1 = 0.102 +- 0.283 (in-sample avg dev_std = 0.268)
NEC for r=0.3 class 2 = 0.233 +- 0.283 (in-sample avg dev_std = 0.268)
NEC for r=0.3 class 3 = 0.214 +- 0.283 (in-sample avg dev_std = 0.268)
NEC for r=0.3 class 4 = 0.345 +- 0.283 (in-sample avg dev_std = 0.268)
NEC for r=0.3 class 5 = 0.236 +- 0.283 (in-sample avg dev_std = 0.268)
NEC for r=0.3 class 6 = 0.194 +- 0.283 (in-sample avg dev_std = 0.268)
NEC for r=0.3 class 7 = 0.311 +- 0.283 (in-sample avg dev_std = 0.268)
NEC for r=0.3 class 8 = 0.208 +- 0.283 (in-sample avg dev_std = 0.268)
NEC for r=0.3 class 9 = 0.221 +- 0.283 (in-sample avg dev_std = 0.268)
NEC for r=0.3 all KL = 0.224 +- 0.283 (in-sample avg dev_std = 0.268)
NEC for r=0.3 all L1 = 0.228 +- 0.246 (in-sample avg dev_std = 0.268)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.132
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.132
NEC for r=0.6 class 0 = 0.623 +- 0.262 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 1 = 0.33 +- 0.262 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 2 = 0.552 +- 0.262 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 3 = 0.549 +- 0.262 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 4 = 0.587 +- 0.262 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 5 = 0.587 +- 0.262 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 6 = 0.582 +- 0.262 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 7 = 0.538 +- 0.262 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 8 = 0.629 +- 0.262 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 9 = 0.609 +- 0.262 (in-sample avg dev_std = 0.387)
NEC for r=0.6 all KL = 0.59 +- 0.262 (in-sample avg dev_std = 0.387)
NEC for r=0.6 all L1 = 0.554 +- 0.192 (in-sample avg dev_std = 0.387)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.794
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.64
NEC for r=0.9 class 0 = 0.54 +- 0.286 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 1 = 0.489 +- 0.286 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 2 = 0.449 +- 0.286 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 3 = 0.412 +- 0.286 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 4 = 0.421 +- 0.286 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 5 = 0.52 +- 0.286 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 6 = 0.533 +- 0.286 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 7 = 0.23 +- 0.286 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 8 = 0.328 +- 0.286 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 9 = 0.596 +- 0.286 (in-sample avg dev_std = 0.450)
NEC for r=0.9 all KL = 0.565 +- 0.286 (in-sample avg dev_std = 0.450)
NEC for r=0.9 all L1 = 0.448 +- 0.232 (in-sample avg dev_std = 0.450)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.915
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.834
NEC for r=1.0 class 0 = 0.129 +- 0.307 (in-sample avg dev_std = 0.337)
NEC for r=1.0 class 1 = 0.032 +- 0.307 (in-sample avg dev_std = 0.337)
NEC for r=1.0 class 2 = 0.34 +- 0.307 (in-sample avg dev_std = 0.337)
NEC for r=1.0 class 3 = 0.286 +- 0.307 (in-sample avg dev_std = 0.337)
NEC for r=1.0 class 4 = 0.17 +- 0.307 (in-sample avg dev_std = 0.337)
NEC for r=1.0 class 5 = 0.356 +- 0.307 (in-sample avg dev_std = 0.337)
NEC for r=1.0 class 6 = 0.311 +- 0.307 (in-sample avg dev_std = 0.337)
NEC for r=1.0 class 7 = 0.132 +- 0.307 (in-sample avg dev_std = 0.337)
NEC for r=1.0 class 8 = 0.239 +- 0.307 (in-sample avg dev_std = 0.337)
NEC for r=1.0 class 9 = 0.379 +- 0.307 (in-sample avg dev_std = 0.337)
NEC for r=1.0 all KL = 0.313 +- 0.307 (in-sample avg dev_std = 0.337)
NEC for r=1.0 all L1 = 0.232 +- 0.239 (in-sample avg dev_std = 0.337)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.117
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.121
NEC for r=0.3 class 0 = 0.333 +- 0.296 (in-sample avg dev_std = 0.314)
NEC for r=0.3 class 1 = 0.187 +- 0.296 (in-sample avg dev_std = 0.314)
NEC for r=0.3 class 2 = 0.331 +- 0.296 (in-sample avg dev_std = 0.314)
NEC for r=0.3 class 3 = 0.361 +- 0.296 (in-sample avg dev_std = 0.314)
NEC for r=0.3 class 4 = 0.269 +- 0.296 (in-sample avg dev_std = 0.314)
NEC for r=0.3 class 5 = 0.377 +- 0.296 (in-sample avg dev_std = 0.314)
NEC for r=0.3 class 6 = 0.191 +- 0.296 (in-sample avg dev_std = 0.314)
NEC for r=0.3 class 7 = 0.241 +- 0.296 (in-sample avg dev_std = 0.314)
NEC for r=0.3 class 8 = 0.277 +- 0.296 (in-sample avg dev_std = 0.314)
NEC for r=0.3 class 9 = 0.197 +- 0.296 (in-sample avg dev_std = 0.314)
NEC for r=0.3 all KL = 0.254 +- 0.296 (in-sample avg dev_std = 0.314)
NEC for r=0.3 all L1 = 0.273 +- 0.260 (in-sample avg dev_std = 0.314)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.11
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.107
NEC for r=0.6 class 0 = 0.471 +- 0.281 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 1 = 0.506 +- 0.281 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 2 = 0.349 +- 0.281 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 3 = 0.325 +- 0.281 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 4 = 0.383 +- 0.281 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 5 = 0.289 +- 0.281 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 6 = 0.386 +- 0.281 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 7 = 0.38 +- 0.281 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 8 = 0.452 +- 0.281 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 9 = 0.411 +- 0.281 (in-sample avg dev_std = 0.351)
NEC for r=0.6 all KL = 0.445 +- 0.281 (in-sample avg dev_std = 0.351)
NEC for r=0.6 all L1 = 0.397 +- 0.241 (in-sample avg dev_std = 0.351)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.565
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.45
NEC for r=0.9 class 0 = 0.603 +- 0.264 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 1 = 0.559 +- 0.264 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 2 = 0.406 +- 0.264 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 3 = 0.432 +- 0.264 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 4 = 0.52 +- 0.264 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 5 = 0.541 +- 0.264 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 6 = 0.599 +- 0.264 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 7 = 0.413 +- 0.264 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 8 = 0.557 +- 0.264 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 9 = 0.627 +- 0.264 (in-sample avg dev_std = 0.441)
NEC for r=0.9 all KL = 0.606 +- 0.264 (in-sample avg dev_std = 0.441)
NEC for r=0.9 all L1 = 0.525 +- 0.206 (in-sample avg dev_std = 0.441)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.776
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.702
NEC for r=1.0 class 0 = 0.32 +- 0.292 (in-sample avg dev_std = 0.382)
NEC for r=1.0 class 1 = 0.062 +- 0.292 (in-sample avg dev_std = 0.382)
NEC for r=1.0 class 2 = 0.318 +- 0.292 (in-sample avg dev_std = 0.382)
NEC for r=1.0 class 3 = 0.289 +- 0.292 (in-sample avg dev_std = 0.382)
NEC for r=1.0 class 4 = 0.311 +- 0.292 (in-sample avg dev_std = 0.382)
NEC for r=1.0 class 5 = 0.384 +- 0.292 (in-sample avg dev_std = 0.382)
NEC for r=1.0 class 6 = 0.429 +- 0.292 (in-sample avg dev_std = 0.382)
NEC for r=1.0 class 7 = 0.189 +- 0.292 (in-sample avg dev_std = 0.382)
NEC for r=1.0 class 8 = 0.426 +- 0.292 (in-sample avg dev_std = 0.382)
NEC for r=1.0 class 9 = 0.44 +- 0.292 (in-sample avg dev_std = 0.382)
NEC for r=1.0 all KL = 0.362 +- 0.292 (in-sample avg dev_std = 0.382)
NEC for r=1.0 all L1 = 0.312 +- 0.244 (in-sample avg dev_std = 0.382)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.117
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.113
NEC for r=0.3 class 0 = 0.492 +- 0.311 (in-sample avg dev_std = 0.364)
NEC for r=0.3 class 1 = 0.37 +- 0.311 (in-sample avg dev_std = 0.364)
NEC for r=0.3 class 2 = 0.399 +- 0.311 (in-sample avg dev_std = 0.364)
NEC for r=0.3 class 3 = 0.384 +- 0.311 (in-sample avg dev_std = 0.364)
NEC for r=0.3 class 4 = 0.276 +- 0.311 (in-sample avg dev_std = 0.364)
NEC for r=0.3 class 5 = 0.387 +- 0.311 (in-sample avg dev_std = 0.364)
NEC for r=0.3 class 6 = 0.325 +- 0.311 (in-sample avg dev_std = 0.364)
NEC for r=0.3 class 7 = 0.335 +- 0.311 (in-sample avg dev_std = 0.364)
NEC for r=0.3 class 8 = 0.317 +- 0.311 (in-sample avg dev_std = 0.364)
NEC for r=0.3 class 9 = 0.373 +- 0.311 (in-sample avg dev_std = 0.364)
NEC for r=0.3 all KL = 0.366 +- 0.311 (in-sample avg dev_std = 0.364)
NEC for r=0.3 all L1 = 0.367 +- 0.237 (in-sample avg dev_std = 0.364)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.119
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.115
NEC for r=0.6 class 0 = 0.241 +- 0.271 (in-sample avg dev_std = 0.248)
NEC for r=0.6 class 1 = 0.157 +- 0.271 (in-sample avg dev_std = 0.248)
NEC for r=0.6 class 2 = 0.274 +- 0.271 (in-sample avg dev_std = 0.248)
NEC for r=0.6 class 3 = 0.243 +- 0.271 (in-sample avg dev_std = 0.248)
NEC for r=0.6 class 4 = 0.365 +- 0.271 (in-sample avg dev_std = 0.248)
NEC for r=0.6 class 5 = 0.259 +- 0.271 (in-sample avg dev_std = 0.248)
NEC for r=0.6 class 6 = 0.349 +- 0.271 (in-sample avg dev_std = 0.248)
NEC for r=0.6 class 7 = 0.335 +- 0.271 (in-sample avg dev_std = 0.248)
NEC for r=0.6 class 8 = 0.378 +- 0.271 (in-sample avg dev_std = 0.248)
NEC for r=0.6 class 9 = 0.438 +- 0.271 (in-sample avg dev_std = 0.248)
NEC for r=0.6 all KL = 0.306 +- 0.271 (in-sample avg dev_std = 0.248)
NEC for r=0.6 all L1 = 0.302 +- 0.241 (in-sample avg dev_std = 0.248)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.251
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.218
NEC for r=0.9 class 0 = 0.581 +- 0.298 (in-sample avg dev_std = 0.405)
NEC for r=0.9 class 1 = 0.394 +- 0.298 (in-sample avg dev_std = 0.405)
NEC for r=0.9 class 2 = 0.388 +- 0.298 (in-sample avg dev_std = 0.405)
NEC for r=0.9 class 3 = 0.495 +- 0.298 (in-sample avg dev_std = 0.405)
NEC for r=0.9 class 4 = 0.428 +- 0.298 (in-sample avg dev_std = 0.405)
NEC for r=0.9 class 5 = 0.432 +- 0.298 (in-sample avg dev_std = 0.405)
NEC for r=0.9 class 6 = 0.498 +- 0.298 (in-sample avg dev_std = 0.405)
NEC for r=0.9 class 7 = 0.436 +- 0.298 (in-sample avg dev_std = 0.405)
NEC for r=0.9 class 8 = 0.568 +- 0.298 (in-sample avg dev_std = 0.405)
NEC for r=0.9 class 9 = 0.545 +- 0.298 (in-sample avg dev_std = 0.405)
NEC for r=0.9 all KL = 0.578 +- 0.298 (in-sample avg dev_std = 0.405)
NEC for r=0.9 all L1 = 0.476 +- 0.235 (in-sample avg dev_std = 0.405)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.3
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.344
NEC for r=1.0 class 0 = 0.529 +- 0.307 (in-sample avg dev_std = 0.321)
NEC for r=1.0 class 1 = 0.289 +- 0.307 (in-sample avg dev_std = 0.321)
NEC for r=1.0 class 2 = 0.299 +- 0.307 (in-sample avg dev_std = 0.321)
NEC for r=1.0 class 3 = 0.481 +- 0.307 (in-sample avg dev_std = 0.321)
NEC for r=1.0 class 4 = 0.454 +- 0.307 (in-sample avg dev_std = 0.321)
NEC for r=1.0 class 5 = 0.435 +- 0.307 (in-sample avg dev_std = 0.321)
NEC for r=1.0 class 6 = 0.499 +- 0.307 (in-sample avg dev_std = 0.321)
NEC for r=1.0 class 7 = 0.365 +- 0.307 (in-sample avg dev_std = 0.321)
NEC for r=1.0 class 8 = 0.543 +- 0.307 (in-sample avg dev_std = 0.321)
NEC for r=1.0 class 9 = 0.51 +- 0.307 (in-sample avg dev_std = 0.321)
NEC for r=1.0 all KL = 0.454 +- 0.307 (in-sample avg dev_std = 0.321)
NEC for r=1.0 all L1 = 0.438 +- 0.254 (in-sample avg dev_std = 0.321)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Mar 23 04:39:53 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 04:39:54 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 185...
[0m[1;37mINFO[0m: [1mCheckpoint 185: 
-----------------------------------
Train ACCURACY: 0.9519
Train Loss: 0.1382
ID Validation ACCURACY: 0.8961
ID Validation Loss: 0.3621
ID Test ACCURACY: 0.8871
ID Test Loss: 0.3798
OOD Validation ACCURACY: 0.7449
OOD Validation Loss: 1.1037
OOD Test ACCURACY: 0.3044
OOD Test Loss: 5.2755

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 172...
[0m[1;37mINFO[0m: [1mCheckpoint 172: 
-----------------------------------
Train ACCURACY: 0.9417
Train Loss: 0.1662
ID Validation ACCURACY: 0.8909
ID Validation Loss: 0.3620
ID Test ACCURACY: 0.8841
ID Test Loss: 0.3721
OOD Validation ACCURACY: 0.8134
OOD Validation Loss: 0.6389
OOD Test ACCURACY: 0.4137
OOD Test Loss: 2.6973

[0m[1;37mINFO[0m: [1mChartInfo 0.8871 0.3044 0.8841 0.4137 0.8909 0.8134[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.125
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.112
SUFF++ for r=0.3 class 0 = 0.38 +- 0.300 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.3 class 1 = 0.522 +- 0.300 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.3 class 2 = 0.43 +- 0.300 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.3 class 3 = 0.52 +- 0.300 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.3 class 4 = 0.547 +- 0.300 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.3 class 5 = 0.536 +- 0.300 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.3 class 6 = 0.496 +- 0.300 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.3 class 7 = 0.644 +- 0.300 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.3 class 8 = 0.464 +- 0.300 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.3 class 9 = 0.569 +- 0.300 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.3 all KL = 0.437 +- 0.300 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.3 all L1 = 0.511 +- 0.242 (in-sample avg dev_std = 0.420)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.127
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.121
SUFF++ for r=0.6 class 0 = 0.232 +- 0.184 (in-sample avg dev_std = 0.487)
SUFF++ for r=0.6 class 1 = 0.388 +- 0.184 (in-sample avg dev_std = 0.487)
SUFF++ for r=0.6 class 2 = 0.319 +- 0.184 (in-sample avg dev_std = 0.487)
SUFF++ for r=0.6 class 3 = 0.312 +- 0.184 (in-sample avg dev_std = 0.487)
SUFF++ for r=0.6 class 4 = 0.263 +- 0.184 (in-sample avg dev_std = 0.487)
SUFF++ for r=0.6 class 5 = 0.306 +- 0.184 (in-sample avg dev_std = 0.487)
SUFF++ for r=0.6 class 6 = 0.251 +- 0.184 (in-sample avg dev_std = 0.487)
SUFF++ for r=0.6 class 7 = 0.31 +- 0.184 (in-sample avg dev_std = 0.487)
SUFF++ for r=0.6 class 8 = 0.266 +- 0.184 (in-sample avg dev_std = 0.487)
SUFF++ for r=0.6 class 9 = 0.276 +- 0.184 (in-sample avg dev_std = 0.487)
SUFF++ for r=0.6 all KL = 0.175 +- 0.184 (in-sample avg dev_std = 0.487)
SUFF++ for r=0.6 all L1 = 0.294 +- 0.136 (in-sample avg dev_std = 0.487)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.783
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.391
SUFF++ for r=0.9 class 0 = 0.274 +- 0.179 (in-sample avg dev_std = 0.697)
SUFF++ for r=0.9 class 1 = 0.351 +- 0.179 (in-sample avg dev_std = 0.697)
SUFF++ for r=0.9 class 2 = 0.31 +- 0.179 (in-sample avg dev_std = 0.697)
SUFF++ for r=0.9 class 3 = 0.376 +- 0.179 (in-sample avg dev_std = 0.697)
SUFF++ for r=0.9 class 4 = 0.317 +- 0.179 (in-sample avg dev_std = 0.697)
SUFF++ for r=0.9 class 5 = 0.331 +- 0.179 (in-sample avg dev_std = 0.697)
SUFF++ for r=0.9 class 6 = 0.304 +- 0.179 (in-sample avg dev_std = 0.697)
SUFF++ for r=0.9 class 7 = 0.509 +- 0.179 (in-sample avg dev_std = 0.697)
SUFF++ for r=0.9 class 8 = 0.34 +- 0.179 (in-sample avg dev_std = 0.697)
SUFF++ for r=0.9 class 9 = 0.286 +- 0.179 (in-sample avg dev_std = 0.697)
SUFF++ for r=0.9 all KL = 0.102 +- 0.179 (in-sample avg dev_std = 0.697)
SUFF++ for r=0.9 all L1 = 0.343 +- 0.137 (in-sample avg dev_std = 0.697)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.104
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.106
SUFF++ for r=0.3 class 0 = 0.512 +- 0.320 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 1 = 0.44 +- 0.320 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 2 = 0.566 +- 0.320 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 3 = 0.599 +- 0.320 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 4 = 0.438 +- 0.320 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 5 = 0.558 +- 0.320 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 6 = 0.58 +- 0.320 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 7 = 0.653 +- 0.320 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 8 = 0.533 +- 0.320 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 9 = 0.665 +- 0.320 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 all KL = 0.481 +- 0.320 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 all L1 = 0.554 +- 0.274 (in-sample avg dev_std = 0.342)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.11
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.112
SUFF++ for r=0.6 class 0 = 0.261 +- 0.161 (in-sample avg dev_std = 0.578)
SUFF++ for r=0.6 class 1 = 0.38 +- 0.161 (in-sample avg dev_std = 0.578)
SUFF++ for r=0.6 class 2 = 0.268 +- 0.161 (in-sample avg dev_std = 0.578)
SUFF++ for r=0.6 class 3 = 0.264 +- 0.161 (in-sample avg dev_std = 0.578)
SUFF++ for r=0.6 class 4 = 0.232 +- 0.161 (in-sample avg dev_std = 0.578)
SUFF++ for r=0.6 class 5 = 0.265 +- 0.161 (in-sample avg dev_std = 0.578)
SUFF++ for r=0.6 class 6 = 0.276 +- 0.161 (in-sample avg dev_std = 0.578)
SUFF++ for r=0.6 class 7 = 0.296 +- 0.161 (in-sample avg dev_std = 0.578)
SUFF++ for r=0.6 class 8 = 0.259 +- 0.161 (in-sample avg dev_std = 0.578)
SUFF++ for r=0.6 class 9 = 0.254 +- 0.161 (in-sample avg dev_std = 0.578)
SUFF++ for r=0.6 all KL = 0.119 +- 0.161 (in-sample avg dev_std = 0.578)
SUFF++ for r=0.6 all L1 = 0.277 +- 0.112 (in-sample avg dev_std = 0.578)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.509
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.298
SUFF++ for r=0.9 class 0 = 0.296 +- 0.196 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.9 class 1 = 0.597 +- 0.196 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.9 class 2 = 0.341 +- 0.196 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.9 class 3 = 0.456 +- 0.196 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.9 class 4 = 0.305 +- 0.196 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.9 class 5 = 0.322 +- 0.196 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.9 class 6 = 0.331 +- 0.196 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.9 class 7 = 0.383 +- 0.196 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.9 class 8 = 0.301 +- 0.196 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.9 class 9 = 0.322 +- 0.196 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.9 all KL = 0.169 +- 0.196 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.9 all L1 = 0.37 +- 0.185 (in-sample avg dev_std = 0.557)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.16
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.108
SUFF++ for r=0.3 class 0 = 0.657 +- 0.343 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.3 class 1 = 0.245 +- 0.343 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.3 class 2 = 0.573 +- 0.343 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.3 class 3 = 0.525 +- 0.343 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.3 class 4 = 0.444 +- 0.343 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.3 class 5 = 0.569 +- 0.343 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.3 class 6 = 0.391 +- 0.343 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.3 class 7 = 0.526 +- 0.343 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.3 class 8 = 0.516 +- 0.343 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.3 class 9 = 0.353 +- 0.343 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.3 all KL = 0.421 +- 0.343 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.3 all L1 = 0.478 +- 0.287 (in-sample avg dev_std = 0.332)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.199
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.123
SUFF++ for r=0.6 class 0 = 0.353 +- 0.241 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 1 = 0.29 +- 0.241 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 2 = 0.303 +- 0.241 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 3 = 0.312 +- 0.241 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 4 = 0.302 +- 0.241 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 5 = 0.339 +- 0.241 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 6 = 0.34 +- 0.241 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 7 = 0.392 +- 0.241 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 8 = 0.388 +- 0.241 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 9 = 0.398 +- 0.241 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 all KL = 0.194 +- 0.241 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 all L1 = 0.341 +- 0.184 (in-sample avg dev_std = 0.531)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.256
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.216
SUFF++ for r=0.9 class 0 = 0.405 +- 0.321 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.9 class 1 = 0.777 +- 0.321 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.9 class 2 = 0.601 +- 0.321 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.9 class 3 = 0.602 +- 0.321 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.9 class 4 = 0.446 +- 0.321 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.9 class 5 = 0.513 +- 0.321 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.9 class 6 = 0.505 +- 0.321 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.9 class 7 = 0.465 +- 0.321 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.9 class 8 = 0.403 +- 0.321 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.9 class 9 = 0.4 +- 0.321 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.9 all KL = 0.372 +- 0.321 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.9 all L1 = 0.515 +- 0.276 (in-sample avg dev_std = 0.427)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.125
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.116
NEC for r=0.3 class 0 = 0.668 +- 0.302 (in-sample avg dev_std = 0.433)
NEC for r=0.3 class 1 = 0.454 +- 0.302 (in-sample avg dev_std = 0.433)
NEC for r=0.3 class 2 = 0.623 +- 0.302 (in-sample avg dev_std = 0.433)
NEC for r=0.3 class 3 = 0.587 +- 0.302 (in-sample avg dev_std = 0.433)
NEC for r=0.3 class 4 = 0.502 +- 0.302 (in-sample avg dev_std = 0.433)
NEC for r=0.3 class 5 = 0.551 +- 0.302 (in-sample avg dev_std = 0.433)
NEC for r=0.3 class 6 = 0.481 +- 0.302 (in-sample avg dev_std = 0.433)
NEC for r=0.3 class 7 = 0.433 +- 0.302 (in-sample avg dev_std = 0.433)
NEC for r=0.3 class 8 = 0.579 +- 0.302 (in-sample avg dev_std = 0.433)
NEC for r=0.3 class 9 = 0.472 +- 0.302 (in-sample avg dev_std = 0.433)
NEC for r=0.3 all KL = 0.635 +- 0.302 (in-sample avg dev_std = 0.433)
NEC for r=0.3 all L1 = 0.534 +- 0.236 (in-sample avg dev_std = 0.433)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.127
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.122
NEC for r=0.6 class 0 = 0.715 +- 0.211 (in-sample avg dev_std = 0.414)
NEC for r=0.6 class 1 = 0.636 +- 0.211 (in-sample avg dev_std = 0.414)
NEC for r=0.6 class 2 = 0.663 +- 0.211 (in-sample avg dev_std = 0.414)
NEC for r=0.6 class 3 = 0.615 +- 0.211 (in-sample avg dev_std = 0.414)
NEC for r=0.6 class 4 = 0.636 +- 0.211 (in-sample avg dev_std = 0.414)
NEC for r=0.6 class 5 = 0.665 +- 0.211 (in-sample avg dev_std = 0.414)
NEC for r=0.6 class 6 = 0.653 +- 0.211 (in-sample avg dev_std = 0.414)
NEC for r=0.6 class 7 = 0.627 +- 0.211 (in-sample avg dev_std = 0.414)
NEC for r=0.6 class 8 = 0.67 +- 0.211 (in-sample avg dev_std = 0.414)
NEC for r=0.6 class 9 = 0.645 +- 0.211 (in-sample avg dev_std = 0.414)
NEC for r=0.6 all KL = 0.762 +- 0.211 (in-sample avg dev_std = 0.414)
NEC for r=0.6 all L1 = 0.652 +- 0.154 (in-sample avg dev_std = 0.414)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.783
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.669
NEC for r=0.9 class 0 = 0.569 +- 0.304 (in-sample avg dev_std = 0.442)
NEC for r=0.9 class 1 = 0.163 +- 0.304 (in-sample avg dev_std = 0.442)
NEC for r=0.9 class 2 = 0.478 +- 0.304 (in-sample avg dev_std = 0.442)
NEC for r=0.9 class 3 = 0.409 +- 0.304 (in-sample avg dev_std = 0.442)
NEC for r=0.9 class 4 = 0.393 +- 0.304 (in-sample avg dev_std = 0.442)
NEC for r=0.9 class 5 = 0.397 +- 0.304 (in-sample avg dev_std = 0.442)
NEC for r=0.9 class 6 = 0.523 +- 0.304 (in-sample avg dev_std = 0.442)
NEC for r=0.9 class 7 = 0.449 +- 0.304 (in-sample avg dev_std = 0.442)
NEC for r=0.9 class 8 = 0.31 +- 0.304 (in-sample avg dev_std = 0.442)
NEC for r=0.9 class 9 = 0.617 +- 0.304 (in-sample avg dev_std = 0.442)
NEC for r=0.9 all KL = 0.562 +- 0.304 (in-sample avg dev_std = 0.442)
NEC for r=0.9 all L1 = 0.427 +- 0.252 (in-sample avg dev_std = 0.442)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.933
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.842
NEC for r=1.0 class 0 = 0.111 +- 0.311 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 1 = 0.007 +- 0.311 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 2 = 0.339 +- 0.311 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 3 = 0.314 +- 0.311 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 4 = 0.167 +- 0.311 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 5 = 0.301 +- 0.311 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 6 = 0.216 +- 0.311 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 7 = 0.277 +- 0.311 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 8 = 0.168 +- 0.311 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 9 = 0.357 +- 0.311 (in-sample avg dev_std = 0.345)
NEC for r=1.0 all KL = 0.309 +- 0.311 (in-sample avg dev_std = 0.345)
NEC for r=1.0 all L1 = 0.223 +- 0.237 (in-sample avg dev_std = 0.345)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.104
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.11
NEC for r=0.3 class 0 = 0.538 +- 0.314 (in-sample avg dev_std = 0.410)
NEC for r=0.3 class 1 = 0.442 +- 0.314 (in-sample avg dev_std = 0.410)
NEC for r=0.3 class 2 = 0.504 +- 0.314 (in-sample avg dev_std = 0.410)
NEC for r=0.3 class 3 = 0.461 +- 0.314 (in-sample avg dev_std = 0.410)
NEC for r=0.3 class 4 = 0.488 +- 0.314 (in-sample avg dev_std = 0.410)
NEC for r=0.3 class 5 = 0.474 +- 0.314 (in-sample avg dev_std = 0.410)
NEC for r=0.3 class 6 = 0.454 +- 0.314 (in-sample avg dev_std = 0.410)
NEC for r=0.3 class 7 = 0.38 +- 0.314 (in-sample avg dev_std = 0.410)
NEC for r=0.3 class 8 = 0.479 +- 0.314 (in-sample avg dev_std = 0.410)
NEC for r=0.3 class 9 = 0.304 +- 0.314 (in-sample avg dev_std = 0.410)
NEC for r=0.3 all KL = 0.526 +- 0.314 (in-sample avg dev_std = 0.410)
NEC for r=0.3 all L1 = 0.45 +- 0.249 (in-sample avg dev_std = 0.410)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.11
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.092
NEC for r=0.6 class 0 = 0.612 +- 0.269 (in-sample avg dev_std = 0.460)
NEC for r=0.6 class 1 = 0.539 +- 0.269 (in-sample avg dev_std = 0.460)
NEC for r=0.6 class 2 = 0.572 +- 0.269 (in-sample avg dev_std = 0.460)
NEC for r=0.6 class 3 = 0.607 +- 0.269 (in-sample avg dev_std = 0.460)
NEC for r=0.6 class 4 = 0.523 +- 0.269 (in-sample avg dev_std = 0.460)
NEC for r=0.6 class 5 = 0.53 +- 0.269 (in-sample avg dev_std = 0.460)
NEC for r=0.6 class 6 = 0.479 +- 0.269 (in-sample avg dev_std = 0.460)
NEC for r=0.6 class 7 = 0.44 +- 0.269 (in-sample avg dev_std = 0.460)
NEC for r=0.6 class 8 = 0.622 +- 0.269 (in-sample avg dev_std = 0.460)
NEC for r=0.6 class 9 = 0.505 +- 0.269 (in-sample avg dev_std = 0.460)
NEC for r=0.6 all KL = 0.651 +- 0.269 (in-sample avg dev_std = 0.460)
NEC for r=0.6 all L1 = 0.542 +- 0.211 (in-sample avg dev_std = 0.460)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.509
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.451
NEC for r=0.9 class 0 = 0.529 +- 0.282 (in-sample avg dev_std = 0.442)
NEC for r=0.9 class 1 = 0.201 +- 0.282 (in-sample avg dev_std = 0.442)
NEC for r=0.9 class 2 = 0.519 +- 0.282 (in-sample avg dev_std = 0.442)
NEC for r=0.9 class 3 = 0.443 +- 0.282 (in-sample avg dev_std = 0.442)
NEC for r=0.9 class 4 = 0.559 +- 0.282 (in-sample avg dev_std = 0.442)
NEC for r=0.9 class 5 = 0.561 +- 0.282 (in-sample avg dev_std = 0.442)
NEC for r=0.9 class 6 = 0.63 +- 0.282 (in-sample avg dev_std = 0.442)
NEC for r=0.9 class 7 = 0.599 +- 0.282 (in-sample avg dev_std = 0.442)
NEC for r=0.9 class 8 = 0.613 +- 0.282 (in-sample avg dev_std = 0.442)
NEC for r=0.9 class 9 = 0.621 +- 0.282 (in-sample avg dev_std = 0.442)
NEC for r=0.9 all KL = 0.634 +- 0.282 (in-sample avg dev_std = 0.442)
NEC for r=0.9 all L1 = 0.523 +- 0.237 (in-sample avg dev_std = 0.442)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.754
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.69
NEC for r=1.0 class 0 = 0.264 +- 0.313 (in-sample avg dev_std = 0.388)
NEC for r=1.0 class 1 = 0.024 +- 0.313 (in-sample avg dev_std = 0.388)
NEC for r=1.0 class 2 = 0.356 +- 0.313 (in-sample avg dev_std = 0.388)
NEC for r=1.0 class 3 = 0.309 +- 0.313 (in-sample avg dev_std = 0.388)
NEC for r=1.0 class 4 = 0.317 +- 0.313 (in-sample avg dev_std = 0.388)
NEC for r=1.0 class 5 = 0.377 +- 0.313 (in-sample avg dev_std = 0.388)
NEC for r=1.0 class 6 = 0.46 +- 0.313 (in-sample avg dev_std = 0.388)
NEC for r=1.0 class 7 = 0.301 +- 0.313 (in-sample avg dev_std = 0.388)
NEC for r=1.0 class 8 = 0.413 +- 0.313 (in-sample avg dev_std = 0.388)
NEC for r=1.0 class 9 = 0.479 +- 0.313 (in-sample avg dev_std = 0.388)
NEC for r=1.0 all KL = 0.391 +- 0.313 (in-sample avg dev_std = 0.388)
NEC for r=1.0 all L1 = 0.325 +- 0.259 (in-sample avg dev_std = 0.388)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.16
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.112
NEC for r=0.3 class 0 = 0.35 +- 0.318 (in-sample avg dev_std = 0.378)
NEC for r=0.3 class 1 = 0.695 +- 0.318 (in-sample avg dev_std = 0.378)
NEC for r=0.3 class 2 = 0.442 +- 0.318 (in-sample avg dev_std = 0.378)
NEC for r=0.3 class 3 = 0.453 +- 0.318 (in-sample avg dev_std = 0.378)
NEC for r=0.3 class 4 = 0.558 +- 0.318 (in-sample avg dev_std = 0.378)
NEC for r=0.3 class 5 = 0.424 +- 0.318 (in-sample avg dev_std = 0.378)
NEC for r=0.3 class 6 = 0.564 +- 0.318 (in-sample avg dev_std = 0.378)
NEC for r=0.3 class 7 = 0.484 +- 0.318 (in-sample avg dev_std = 0.378)
NEC for r=0.3 class 8 = 0.489 +- 0.318 (in-sample avg dev_std = 0.378)
NEC for r=0.3 class 9 = 0.584 +- 0.318 (in-sample avg dev_std = 0.378)
NEC for r=0.3 all KL = 0.562 +- 0.318 (in-sample avg dev_std = 0.378)
NEC for r=0.3 all L1 = 0.506 +- 0.253 (in-sample avg dev_std = 0.378)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.199
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.182
NEC for r=0.6 class 0 = 0.545 +- 0.292 (in-sample avg dev_std = 0.422)
NEC for r=0.6 class 1 = 0.408 +- 0.292 (in-sample avg dev_std = 0.422)
NEC for r=0.6 class 2 = 0.581 +- 0.292 (in-sample avg dev_std = 0.422)
NEC for r=0.6 class 3 = 0.589 +- 0.292 (in-sample avg dev_std = 0.422)
NEC for r=0.6 class 4 = 0.631 +- 0.292 (in-sample avg dev_std = 0.422)
NEC for r=0.6 class 5 = 0.552 +- 0.292 (in-sample avg dev_std = 0.422)
NEC for r=0.6 class 6 = 0.578 +- 0.292 (in-sample avg dev_std = 0.422)
NEC for r=0.6 class 7 = 0.551 +- 0.292 (in-sample avg dev_std = 0.422)
NEC for r=0.6 class 8 = 0.54 +- 0.292 (in-sample avg dev_std = 0.422)
NEC for r=0.6 class 9 = 0.581 +- 0.292 (in-sample avg dev_std = 0.422)
NEC for r=0.6 all KL = 0.632 +- 0.292 (in-sample avg dev_std = 0.422)
NEC for r=0.6 all L1 = 0.554 +- 0.230 (in-sample avg dev_std = 0.422)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.256
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.253
NEC for r=0.9 class 0 = 0.506 +- 0.326 (in-sample avg dev_std = 0.436)
NEC for r=0.9 class 1 = 0.183 +- 0.326 (in-sample avg dev_std = 0.436)
NEC for r=0.9 class 2 = 0.43 +- 0.326 (in-sample avg dev_std = 0.436)
NEC for r=0.9 class 3 = 0.431 +- 0.326 (in-sample avg dev_std = 0.436)
NEC for r=0.9 class 4 = 0.571 +- 0.326 (in-sample avg dev_std = 0.436)
NEC for r=0.9 class 5 = 0.483 +- 0.326 (in-sample avg dev_std = 0.436)
NEC for r=0.9 class 6 = 0.51 +- 0.326 (in-sample avg dev_std = 0.436)
NEC for r=0.9 class 7 = 0.527 +- 0.326 (in-sample avg dev_std = 0.436)
NEC for r=0.9 class 8 = 0.599 +- 0.326 (in-sample avg dev_std = 0.436)
NEC for r=0.9 class 9 = 0.572 +- 0.326 (in-sample avg dev_std = 0.436)
NEC for r=0.9 all KL = 0.587 +- 0.326 (in-sample avg dev_std = 0.436)
NEC for r=0.9 all L1 = 0.477 +- 0.264 (in-sample avg dev_std = 0.436)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.304
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.318
NEC for r=1.0 class 0 = 0.347 +- 0.356 (in-sample avg dev_std = 0.343)
NEC for r=1.0 class 1 = 0.29 +- 0.356 (in-sample avg dev_std = 0.343)
NEC for r=1.0 class 2 = 0.457 +- 0.356 (in-sample avg dev_std = 0.343)
NEC for r=1.0 class 3 = 0.368 +- 0.356 (in-sample avg dev_std = 0.343)
NEC for r=1.0 class 4 = 0.608 +- 0.356 (in-sample avg dev_std = 0.343)
NEC for r=1.0 class 5 = 0.512 +- 0.356 (in-sample avg dev_std = 0.343)
NEC for r=1.0 class 6 = 0.519 +- 0.356 (in-sample avg dev_std = 0.343)
NEC for r=1.0 class 7 = 0.475 +- 0.356 (in-sample avg dev_std = 0.343)
NEC for r=1.0 class 8 = 0.561 +- 0.356 (in-sample avg dev_std = 0.343)
NEC for r=1.0 class 9 = 0.546 +- 0.356 (in-sample avg dev_std = 0.343)
NEC for r=1.0 all KL = 0.512 +- 0.356 (in-sample avg dev_std = 0.343)
NEC for r=1.0 all L1 = 0.465 +- 0.292 (in-sample avg dev_std = 0.343)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Mar 23 05:08:29 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:30 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:30 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 05:08:31 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 189...
[0m[1;37mINFO[0m: [1mCheckpoint 189: 
-----------------------------------
Train ACCURACY: 0.9534
Train Loss: 0.1343
ID Validation ACCURACY: 0.8954
ID Validation Loss: 0.3620
ID Test ACCURACY: 0.8914
ID Test Loss: 0.3791
OOD Validation ACCURACY: 0.7987
OOD Validation Loss: 0.7966
OOD Test ACCURACY: 0.2186
OOD Test Loss: 11.4348

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 175...
[0m[1;37mINFO[0m: [1mCheckpoint 175: 
-----------------------------------
Train ACCURACY: 0.9452
Train Loss: 0.1585
ID Validation ACCURACY: 0.8876
ID Validation Loss: 0.3718
ID Test ACCURACY: 0.8883
ID Test Loss: 0.3697
OOD Validation ACCURACY: 0.8087
OOD Validation Loss: 0.7290
OOD Test ACCURACY: 0.2657
OOD Test Loss: 10.3527

[0m[1;37mINFO[0m: [1mChartInfo 0.8914 0.2186 0.8883 0.2657 0.8876 0.8087[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.112
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.092
SUFF++ for r=0.3 class 0 = 0.556 +- 0.306 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.3 class 1 = 0.75 +- 0.306 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.3 class 2 = 0.473 +- 0.306 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.3 class 3 = 0.569 +- 0.306 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.3 class 4 = 0.658 +- 0.306 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.3 class 5 = 0.502 +- 0.306 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.3 class 6 = 0.61 +- 0.306 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.3 class 7 = 0.72 +- 0.306 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.3 class 8 = 0.543 +- 0.306 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.3 class 9 = 0.676 +- 0.306 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.3 all KL = 0.604 +- 0.306 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.3 all L1 = 0.609 +- 0.250 (in-sample avg dev_std = 0.338)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.134
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.121
SUFF++ for r=0.6 class 0 = 0.307 +- 0.164 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 class 1 = 0.32 +- 0.164 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 class 2 = 0.294 +- 0.164 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 class 3 = 0.293 +- 0.164 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 class 4 = 0.297 +- 0.164 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 class 5 = 0.281 +- 0.164 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 class 6 = 0.286 +- 0.164 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 class 7 = 0.338 +- 0.164 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 class 8 = 0.286 +- 0.164 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 class 9 = 0.292 +- 0.164 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 all KL = 0.208 +- 0.164 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 all L1 = 0.3 +- 0.101 (in-sample avg dev_std = 0.444)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.783
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.378
SUFF++ for r=0.9 class 0 = 0.288 +- 0.129 (in-sample avg dev_std = 0.678)
SUFF++ for r=0.9 class 1 = 0.327 +- 0.129 (in-sample avg dev_std = 0.678)
SUFF++ for r=0.9 class 2 = 0.376 +- 0.129 (in-sample avg dev_std = 0.678)
SUFF++ for r=0.9 class 3 = 0.315 +- 0.129 (in-sample avg dev_std = 0.678)
SUFF++ for r=0.9 class 4 = 0.324 +- 0.129 (in-sample avg dev_std = 0.678)
SUFF++ for r=0.9 class 5 = 0.304 +- 0.129 (in-sample avg dev_std = 0.678)
SUFF++ for r=0.9 class 6 = 0.297 +- 0.129 (in-sample avg dev_std = 0.678)
SUFF++ for r=0.9 class 7 = 0.347 +- 0.129 (in-sample avg dev_std = 0.678)
SUFF++ for r=0.9 class 8 = 0.303 +- 0.129 (in-sample avg dev_std = 0.678)
SUFF++ for r=0.9 class 9 = 0.418 +- 0.129 (in-sample avg dev_std = 0.678)
SUFF++ for r=0.9 all KL = 0.092 +- 0.129 (in-sample avg dev_std = 0.678)
SUFF++ for r=0.9 all L1 = 0.33 +- 0.114 (in-sample avg dev_std = 0.678)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.119
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.107
SUFF++ for r=0.3 class 0 = 0.692 +- 0.232 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.3 class 1 = 0.785 +- 0.232 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.3 class 2 = 0.65 +- 0.232 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.3 class 3 = 0.701 +- 0.232 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.3 class 4 = 0.752 +- 0.232 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.3 class 5 = 0.777 +- 0.232 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.3 class 6 = 0.7 +- 0.232 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.3 class 7 = 0.774 +- 0.232 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.3 class 8 = 0.716 +- 0.232 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.3 class 9 = 0.824 +- 0.232 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.3 all KL = 0.757 +- 0.232 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.3 all L1 = 0.738 +- 0.217 (in-sample avg dev_std = 0.190)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.117
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.118
SUFF++ for r=0.6 class 0 = 0.307 +- 0.182 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.6 class 1 = 0.315 +- 0.182 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.6 class 2 = 0.308 +- 0.182 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.6 class 3 = 0.315 +- 0.182 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.6 class 4 = 0.291 +- 0.182 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.6 class 5 = 0.304 +- 0.182 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.6 class 6 = 0.311 +- 0.182 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.6 class 7 = 0.337 +- 0.182 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.6 class 8 = 0.305 +- 0.182 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.6 class 9 = 0.32 +- 0.182 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.6 all KL = 0.239 +- 0.182 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.6 all L1 = 0.312 +- 0.109 (in-sample avg dev_std = 0.432)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.577
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.26
SUFF++ for r=0.9 class 0 = 0.24 +- 0.124 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.9 class 1 = 0.296 +- 0.124 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.9 class 2 = 0.306 +- 0.124 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.9 class 3 = 0.264 +- 0.124 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.9 class 4 = 0.295 +- 0.124 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.9 class 5 = 0.286 +- 0.124 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.9 class 6 = 0.276 +- 0.124 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.9 class 7 = 0.298 +- 0.124 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.9 class 8 = 0.255 +- 0.124 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.9 class 9 = 0.358 +- 0.124 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.9 all KL = 0.094 +- 0.124 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.9 all L1 = 0.288 +- 0.102 (in-sample avg dev_std = 0.580)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.108
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.1
SUFF++ for r=0.3 class 0 = 0.645 +- 0.369 (in-sample avg dev_std = 0.361)
SUFF++ for r=0.3 class 1 = 0.27 +- 0.369 (in-sample avg dev_std = 0.361)
SUFF++ for r=0.3 class 2 = 0.591 +- 0.369 (in-sample avg dev_std = 0.361)
SUFF++ for r=0.3 class 3 = 0.626 +- 0.369 (in-sample avg dev_std = 0.361)
SUFF++ for r=0.3 class 4 = 0.444 +- 0.369 (in-sample avg dev_std = 0.361)
SUFF++ for r=0.3 class 5 = 0.636 +- 0.369 (in-sample avg dev_std = 0.361)
SUFF++ for r=0.3 class 6 = 0.503 +- 0.369 (in-sample avg dev_std = 0.361)
SUFF++ for r=0.3 class 7 = 0.547 +- 0.369 (in-sample avg dev_std = 0.361)
SUFF++ for r=0.3 class 8 = 0.61 +- 0.369 (in-sample avg dev_std = 0.361)
SUFF++ for r=0.3 class 9 = 0.449 +- 0.369 (in-sample avg dev_std = 0.361)
SUFF++ for r=0.3 all KL = 0.459 +- 0.369 (in-sample avg dev_std = 0.361)
SUFF++ for r=0.3 all L1 = 0.529 +- 0.284 (in-sample avg dev_std = 0.361)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.131
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.109
SUFF++ for r=0.6 class 0 = 0.25 +- 0.199 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.6 class 1 = 0.459 +- 0.199 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.6 class 2 = 0.273 +- 0.199 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.6 class 3 = 0.255 +- 0.199 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.6 class 4 = 0.315 +- 0.199 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.6 class 5 = 0.262 +- 0.199 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.6 class 6 = 0.337 +- 0.199 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.6 class 7 = 0.274 +- 0.199 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.6 class 8 = 0.301 +- 0.199 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.6 class 9 = 0.339 +- 0.199 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.6 all KL = 0.121 +- 0.199 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.6 all L1 = 0.308 +- 0.167 (in-sample avg dev_std = 0.593)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.166
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.154
SUFF++ for r=0.9 class 0 = 0.308 +- 0.112 (in-sample avg dev_std = 0.579)
SUFF++ for r=0.9 class 1 = 0.264 +- 0.112 (in-sample avg dev_std = 0.579)
SUFF++ for r=0.9 class 2 = 0.333 +- 0.112 (in-sample avg dev_std = 0.579)
SUFF++ for r=0.9 class 3 = 0.315 +- 0.112 (in-sample avg dev_std = 0.579)
SUFF++ for r=0.9 class 4 = 0.312 +- 0.112 (in-sample avg dev_std = 0.579)
SUFF++ for r=0.9 class 5 = 0.303 +- 0.112 (in-sample avg dev_std = 0.579)
SUFF++ for r=0.9 class 6 = 0.307 +- 0.112 (in-sample avg dev_std = 0.579)
SUFF++ for r=0.9 class 7 = 0.331 +- 0.112 (in-sample avg dev_std = 0.579)
SUFF++ for r=0.9 class 8 = 0.315 +- 0.112 (in-sample avg dev_std = 0.579)
SUFF++ for r=0.9 class 9 = 0.299 +- 0.112 (in-sample avg dev_std = 0.579)
SUFF++ for r=0.9 all KL = 0.081 +- 0.112 (in-sample avg dev_std = 0.579)
SUFF++ for r=0.9 all L1 = 0.308 +- 0.108 (in-sample avg dev_std = 0.579)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.112
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.099
NEC for r=0.3 class 0 = 0.563 +- 0.328 (in-sample avg dev_std = 0.372)
NEC for r=0.3 class 1 = 0.219 +- 0.328 (in-sample avg dev_std = 0.372)
NEC for r=0.3 class 2 = 0.549 +- 0.328 (in-sample avg dev_std = 0.372)
NEC for r=0.3 class 3 = 0.497 +- 0.328 (in-sample avg dev_std = 0.372)
NEC for r=0.3 class 4 = 0.376 +- 0.328 (in-sample avg dev_std = 0.372)
NEC for r=0.3 class 5 = 0.538 +- 0.328 (in-sample avg dev_std = 0.372)
NEC for r=0.3 class 6 = 0.417 +- 0.328 (in-sample avg dev_std = 0.372)
NEC for r=0.3 class 7 = 0.331 +- 0.328 (in-sample avg dev_std = 0.372)
NEC for r=0.3 class 8 = 0.475 +- 0.328 (in-sample avg dev_std = 0.372)
NEC for r=0.3 class 9 = 0.332 +- 0.328 (in-sample avg dev_std = 0.372)
NEC for r=0.3 all KL = 0.463 +- 0.328 (in-sample avg dev_std = 0.372)
NEC for r=0.3 all L1 = 0.426 +- 0.248 (in-sample avg dev_std = 0.372)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.134
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.112
NEC for r=0.6 class 0 = 0.631 +- 0.222 (in-sample avg dev_std = 0.379)
NEC for r=0.6 class 1 = 0.675 +- 0.222 (in-sample avg dev_std = 0.379)
NEC for r=0.6 class 2 = 0.625 +- 0.222 (in-sample avg dev_std = 0.379)
NEC for r=0.6 class 3 = 0.625 +- 0.222 (in-sample avg dev_std = 0.379)
NEC for r=0.6 class 4 = 0.617 +- 0.222 (in-sample avg dev_std = 0.379)
NEC for r=0.6 class 5 = 0.629 +- 0.222 (in-sample avg dev_std = 0.379)
NEC for r=0.6 class 6 = 0.612 +- 0.222 (in-sample avg dev_std = 0.379)
NEC for r=0.6 class 7 = 0.607 +- 0.222 (in-sample avg dev_std = 0.379)
NEC for r=0.6 class 8 = 0.65 +- 0.222 (in-sample avg dev_std = 0.379)
NEC for r=0.6 class 9 = 0.632 +- 0.222 (in-sample avg dev_std = 0.379)
NEC for r=0.6 all KL = 0.689 +- 0.222 (in-sample avg dev_std = 0.379)
NEC for r=0.6 all L1 = 0.631 +- 0.142 (in-sample avg dev_std = 0.379)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.783
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.664
NEC for r=0.9 class 0 = 0.467 +- 0.291 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 1 = 0.33 +- 0.291 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 2 = 0.422 +- 0.291 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 3 = 0.484 +- 0.291 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 4 = 0.416 +- 0.291 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 5 = 0.511 +- 0.291 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 6 = 0.511 +- 0.291 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 7 = 0.338 +- 0.291 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 8 = 0.356 +- 0.291 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 9 = 0.549 +- 0.291 (in-sample avg dev_std = 0.450)
NEC for r=0.9 all KL = 0.564 +- 0.291 (in-sample avg dev_std = 0.450)
NEC for r=0.9 all L1 = 0.434 +- 0.240 (in-sample avg dev_std = 0.450)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.924
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.842
NEC for r=1.0 class 0 = 0.067 +- 0.300 (in-sample avg dev_std = 0.343)
NEC for r=1.0 class 1 = 0.04 +- 0.300 (in-sample avg dev_std = 0.343)
NEC for r=1.0 class 2 = 0.303 +- 0.300 (in-sample avg dev_std = 0.343)
NEC for r=1.0 class 3 = 0.333 +- 0.300 (in-sample avg dev_std = 0.343)
NEC for r=1.0 class 4 = 0.189 +- 0.300 (in-sample avg dev_std = 0.343)
NEC for r=1.0 class 5 = 0.342 +- 0.300 (in-sample avg dev_std = 0.343)
NEC for r=1.0 class 6 = 0.209 +- 0.300 (in-sample avg dev_std = 0.343)
NEC for r=1.0 class 7 = 0.146 +- 0.300 (in-sample avg dev_std = 0.343)
NEC for r=1.0 class 8 = 0.192 +- 0.300 (in-sample avg dev_std = 0.343)
NEC for r=1.0 class 9 = 0.348 +- 0.300 (in-sample avg dev_std = 0.343)
NEC for r=1.0 all KL = 0.305 +- 0.300 (in-sample avg dev_std = 0.343)
NEC for r=1.0 all L1 = 0.213 +- 0.227 (in-sample avg dev_std = 0.343)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.119
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.111
NEC for r=0.3 class 0 = 0.351 +- 0.261 (in-sample avg dev_std = 0.240)
NEC for r=0.3 class 1 = 0.209 +- 0.261 (in-sample avg dev_std = 0.240)
NEC for r=0.3 class 2 = 0.376 +- 0.261 (in-sample avg dev_std = 0.240)
NEC for r=0.3 class 3 = 0.335 +- 0.261 (in-sample avg dev_std = 0.240)
NEC for r=0.3 class 4 = 0.283 +- 0.261 (in-sample avg dev_std = 0.240)
NEC for r=0.3 class 5 = 0.266 +- 0.261 (in-sample avg dev_std = 0.240)
NEC for r=0.3 class 6 = 0.306 +- 0.261 (in-sample avg dev_std = 0.240)
NEC for r=0.3 class 7 = 0.221 +- 0.261 (in-sample avg dev_std = 0.240)
NEC for r=0.3 class 8 = 0.293 +- 0.261 (in-sample avg dev_std = 0.240)
NEC for r=0.3 class 9 = 0.205 +- 0.261 (in-sample avg dev_std = 0.240)
NEC for r=0.3 all KL = 0.273 +- 0.261 (in-sample avg dev_std = 0.240)
NEC for r=0.3 all L1 = 0.283 +- 0.213 (in-sample avg dev_std = 0.240)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.117
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.114
NEC for r=0.6 class 0 = 0.591 +- 0.227 (in-sample avg dev_std = 0.378)
NEC for r=0.6 class 1 = 0.56 +- 0.227 (in-sample avg dev_std = 0.378)
NEC for r=0.6 class 2 = 0.597 +- 0.227 (in-sample avg dev_std = 0.378)
NEC for r=0.6 class 3 = 0.545 +- 0.227 (in-sample avg dev_std = 0.378)
NEC for r=0.6 class 4 = 0.606 +- 0.227 (in-sample avg dev_std = 0.378)
NEC for r=0.6 class 5 = 0.584 +- 0.227 (in-sample avg dev_std = 0.378)
NEC for r=0.6 class 6 = 0.612 +- 0.227 (in-sample avg dev_std = 0.378)
NEC for r=0.6 class 7 = 0.6 +- 0.227 (in-sample avg dev_std = 0.378)
NEC for r=0.6 class 8 = 0.607 +- 0.227 (in-sample avg dev_std = 0.378)
NEC for r=0.6 class 9 = 0.588 +- 0.227 (in-sample avg dev_std = 0.378)
NEC for r=0.6 all KL = 0.62 +- 0.227 (in-sample avg dev_std = 0.378)
NEC for r=0.6 all L1 = 0.589 +- 0.142 (in-sample avg dev_std = 0.378)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.577
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.421
NEC for r=0.9 class 0 = 0.653 +- 0.256 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 1 = 0.528 +- 0.256 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 2 = 0.46 +- 0.256 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 3 = 0.552 +- 0.256 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 4 = 0.518 +- 0.256 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 5 = 0.565 +- 0.256 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 6 = 0.66 +- 0.256 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 7 = 0.503 +- 0.256 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 8 = 0.613 +- 0.256 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 9 = 0.577 +- 0.256 (in-sample avg dev_std = 0.458)
NEC for r=0.9 all KL = 0.668 +- 0.256 (in-sample avg dev_std = 0.458)
NEC for r=0.9 all L1 = 0.562 +- 0.201 (in-sample avg dev_std = 0.458)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.824
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.71
NEC for r=1.0 class 0 = 0.291 +- 0.307 (in-sample avg dev_std = 0.399)
NEC for r=1.0 class 1 = 0.094 +- 0.307 (in-sample avg dev_std = 0.399)
NEC for r=1.0 class 2 = 0.306 +- 0.307 (in-sample avg dev_std = 0.399)
NEC for r=1.0 class 3 = 0.399 +- 0.307 (in-sample avg dev_std = 0.399)
NEC for r=1.0 class 4 = 0.288 +- 0.307 (in-sample avg dev_std = 0.399)
NEC for r=1.0 class 5 = 0.453 +- 0.307 (in-sample avg dev_std = 0.399)
NEC for r=1.0 class 6 = 0.47 +- 0.307 (in-sample avg dev_std = 0.399)
NEC for r=1.0 class 7 = 0.198 +- 0.307 (in-sample avg dev_std = 0.399)
NEC for r=1.0 class 8 = 0.43 +- 0.307 (in-sample avg dev_std = 0.399)
NEC for r=1.0 class 9 = 0.43 +- 0.307 (in-sample avg dev_std = 0.399)
NEC for r=1.0 all KL = 0.414 +- 0.307 (in-sample avg dev_std = 0.399)
NEC for r=1.0 all L1 = 0.331 +- 0.248 (in-sample avg dev_std = 0.399)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.108
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.117
NEC for r=0.3 class 0 = 0.418 +- 0.365 (in-sample avg dev_std = 0.219)
NEC for r=0.3 class 1 = 0.782 +- 0.365 (in-sample avg dev_std = 0.219)
NEC for r=0.3 class 2 = 0.485 +- 0.365 (in-sample avg dev_std = 0.219)
NEC for r=0.3 class 3 = 0.412 +- 0.365 (in-sample avg dev_std = 0.219)
NEC for r=0.3 class 4 = 0.606 +- 0.365 (in-sample avg dev_std = 0.219)
NEC for r=0.3 class 5 = 0.394 +- 0.365 (in-sample avg dev_std = 0.219)
NEC for r=0.3 class 6 = 0.524 +- 0.365 (in-sample avg dev_std = 0.219)
NEC for r=0.3 class 7 = 0.448 +- 0.365 (in-sample avg dev_std = 0.219)
NEC for r=0.3 class 8 = 0.438 +- 0.365 (in-sample avg dev_std = 0.219)
NEC for r=0.3 class 9 = 0.591 +- 0.365 (in-sample avg dev_std = 0.219)
NEC for r=0.3 all KL = 0.571 +- 0.365 (in-sample avg dev_std = 0.219)
NEC for r=0.3 all L1 = 0.513 +- 0.296 (in-sample avg dev_std = 0.219)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.131
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.157
NEC for r=0.6 class 0 = 0.679 +- 0.213 (in-sample avg dev_std = 0.363)
NEC for r=0.6 class 1 = 0.732 +- 0.213 (in-sample avg dev_std = 0.363)
NEC for r=0.6 class 2 = 0.663 +- 0.213 (in-sample avg dev_std = 0.363)
NEC for r=0.6 class 3 = 0.697 +- 0.213 (in-sample avg dev_std = 0.363)
NEC for r=0.6 class 4 = 0.716 +- 0.213 (in-sample avg dev_std = 0.363)
NEC for r=0.6 class 5 = 0.704 +- 0.213 (in-sample avg dev_std = 0.363)
NEC for r=0.6 class 6 = 0.732 +- 0.213 (in-sample avg dev_std = 0.363)
NEC for r=0.6 class 7 = 0.695 +- 0.213 (in-sample avg dev_std = 0.363)
NEC for r=0.6 class 8 = 0.706 +- 0.213 (in-sample avg dev_std = 0.363)
NEC for r=0.6 class 9 = 0.77 +- 0.213 (in-sample avg dev_std = 0.363)
NEC for r=0.6 all KL = 0.841 +- 0.213 (in-sample avg dev_std = 0.363)
NEC for r=0.6 all L1 = 0.709 +- 0.160 (in-sample avg dev_std = 0.363)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.166
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.204
NEC for r=0.9 class 0 = 0.7 +- 0.240 (in-sample avg dev_std = 0.383)
NEC for r=0.9 class 1 = 0.678 +- 0.240 (in-sample avg dev_std = 0.383)
NEC for r=0.9 class 2 = 0.613 +- 0.240 (in-sample avg dev_std = 0.383)
NEC for r=0.9 class 3 = 0.665 +- 0.240 (in-sample avg dev_std = 0.383)
NEC for r=0.9 class 4 = 0.695 +- 0.240 (in-sample avg dev_std = 0.383)
NEC for r=0.9 class 5 = 0.664 +- 0.240 (in-sample avg dev_std = 0.383)
NEC for r=0.9 class 6 = 0.686 +- 0.240 (in-sample avg dev_std = 0.383)
NEC for r=0.9 class 7 = 0.668 +- 0.240 (in-sample avg dev_std = 0.383)
NEC for r=0.9 class 8 = 0.723 +- 0.240 (in-sample avg dev_std = 0.383)
NEC for r=0.9 class 9 = 0.709 +- 0.240 (in-sample avg dev_std = 0.383)
NEC for r=0.9 all KL = 0.818 +- 0.240 (in-sample avg dev_std = 0.383)
NEC for r=0.9 all L1 = 0.68 +- 0.188 (in-sample avg dev_std = 0.383)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.243
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.283
NEC for r=1.0 class 0 = 0.626 +- 0.305 (in-sample avg dev_std = 0.365)
NEC for r=1.0 class 1 = 0.626 +- 0.305 (in-sample avg dev_std = 0.365)
NEC for r=1.0 class 2 = 0.491 +- 0.305 (in-sample avg dev_std = 0.365)
NEC for r=1.0 class 3 = 0.615 +- 0.305 (in-sample avg dev_std = 0.365)
NEC for r=1.0 class 4 = 0.644 +- 0.305 (in-sample avg dev_std = 0.365)
NEC for r=1.0 class 5 = 0.651 +- 0.305 (in-sample avg dev_std = 0.365)
NEC for r=1.0 class 6 = 0.665 +- 0.305 (in-sample avg dev_std = 0.365)
NEC for r=1.0 class 7 = 0.597 +- 0.305 (in-sample avg dev_std = 0.365)
NEC for r=1.0 class 8 = 0.666 +- 0.305 (in-sample avg dev_std = 0.365)
NEC for r=1.0 class 9 = 0.683 +- 0.305 (in-sample avg dev_std = 0.365)
NEC for r=1.0 all KL = 0.75 +- 0.305 (in-sample avg dev_std = 0.365)
NEC for r=1.0 all L1 = 0.625 +- 0.242 (in-sample avg dev_std = 0.365)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Mar 23 05:37:17 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:18 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 05:37:19 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 197...
[0m[1;37mINFO[0m: [1mCheckpoint 197: 
-----------------------------------
Train ACCURACY: 0.9613
Train Loss: 0.1134
ID Validation ACCURACY: 0.8956
ID Validation Loss: 0.3556
ID Test ACCURACY: 0.8920
ID Test Loss: 0.3603
OOD Validation ACCURACY: 0.7163
OOD Validation Loss: 1.1427
OOD Test ACCURACY: 0.1731
OOD Test Loss: 12.4917

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 134...
[0m[1;37mINFO[0m: [1mCheckpoint 134: 
-----------------------------------
Train ACCURACY: 0.9177
Train Loss: 0.2366
ID Validation ACCURACY: 0.8739
ID Validation Loss: 0.3990
ID Test ACCURACY: 0.8733
ID Test Loss: 0.3982
OOD Validation ACCURACY: 0.7943
OOD Validation Loss: 0.6922
OOD Test ACCURACY: 0.3307
OOD Test Loss: 3.3639

[0m[1;37mINFO[0m: [1mChartInfo 0.8920 0.1731 0.8733 0.3307 0.8739 0.7943[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.126
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.119
SUFF++ for r=0.3 class 0 = 0.476 +- 0.207 (in-sample avg dev_std = 0.485)
SUFF++ for r=0.3 class 1 = 0.326 +- 0.207 (in-sample avg dev_std = 0.485)
SUFF++ for r=0.3 class 2 = 0.45 +- 0.207 (in-sample avg dev_std = 0.485)
SUFF++ for r=0.3 class 3 = 0.419 +- 0.207 (in-sample avg dev_std = 0.485)
SUFF++ for r=0.3 class 4 = 0.386 +- 0.207 (in-sample avg dev_std = 0.485)
SUFF++ for r=0.3 class 5 = 0.426 +- 0.207 (in-sample avg dev_std = 0.485)
SUFF++ for r=0.3 class 6 = 0.446 +- 0.207 (in-sample avg dev_std = 0.485)
SUFF++ for r=0.3 class 7 = 0.459 +- 0.207 (in-sample avg dev_std = 0.485)
SUFF++ for r=0.3 class 8 = 0.434 +- 0.207 (in-sample avg dev_std = 0.485)
SUFF++ for r=0.3 class 9 = 0.429 +- 0.207 (in-sample avg dev_std = 0.485)
SUFF++ for r=0.3 all KL = 0.323 +- 0.207 (in-sample avg dev_std = 0.485)
SUFF++ for r=0.3 all L1 = 0.424 +- 0.133 (in-sample avg dev_std = 0.485)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.145
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.108
SUFF++ for r=0.6 class 0 = 0.461 +- 0.231 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.6 class 1 = 0.289 +- 0.231 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.6 class 2 = 0.509 +- 0.231 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.6 class 3 = 0.548 +- 0.231 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.6 class 4 = 0.411 +- 0.231 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.6 class 5 = 0.439 +- 0.231 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.6 class 6 = 0.413 +- 0.231 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.6 class 7 = 0.441 +- 0.231 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.6 class 8 = 0.56 +- 0.231 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.6 class 9 = 0.455 +- 0.231 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.6 all KL = 0.362 +- 0.231 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.6 all L1 = 0.452 +- 0.180 (in-sample avg dev_std = 0.445)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.762
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.372
SUFF++ for r=0.9 class 0 = 0.25 +- 0.172 (in-sample avg dev_std = 0.614)
SUFF++ for r=0.9 class 1 = 0.287 +- 0.172 (in-sample avg dev_std = 0.614)
SUFF++ for r=0.9 class 2 = 0.499 +- 0.172 (in-sample avg dev_std = 0.614)
SUFF++ for r=0.9 class 3 = 0.331 +- 0.172 (in-sample avg dev_std = 0.614)
SUFF++ for r=0.9 class 4 = 0.299 +- 0.172 (in-sample avg dev_std = 0.614)
SUFF++ for r=0.9 class 5 = 0.326 +- 0.172 (in-sample avg dev_std = 0.614)
SUFF++ for r=0.9 class 6 = 0.404 +- 0.172 (in-sample avg dev_std = 0.614)
SUFF++ for r=0.9 class 7 = 0.531 +- 0.172 (in-sample avg dev_std = 0.614)
SUFF++ for r=0.9 class 8 = 0.337 +- 0.172 (in-sample avg dev_std = 0.614)
SUFF++ for r=0.9 class 9 = 0.368 +- 0.172 (in-sample avg dev_std = 0.614)
SUFF++ for r=0.9 all KL = 0.148 +- 0.172 (in-sample avg dev_std = 0.614)
SUFF++ for r=0.9 all L1 = 0.365 +- 0.153 (in-sample avg dev_std = 0.614)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.104
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.103
SUFF++ for r=0.3 class 0 = 0.438 +- 0.203 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.3 class 1 = 0.38 +- 0.203 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.3 class 2 = 0.431 +- 0.203 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.3 class 3 = 0.43 +- 0.203 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.3 class 4 = 0.416 +- 0.203 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.3 class 5 = 0.437 +- 0.203 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.3 class 6 = 0.435 +- 0.203 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.3 class 7 = 0.43 +- 0.203 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.3 class 8 = 0.404 +- 0.203 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.3 class 9 = 0.392 +- 0.203 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.3 all KL = 0.355 +- 0.203 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.3 all L1 = 0.419 +- 0.116 (in-sample avg dev_std = 0.419)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.11
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.101
SUFF++ for r=0.6 class 0 = 0.567 +- 0.262 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.6 class 1 = 0.416 +- 0.262 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.6 class 2 = 0.627 +- 0.262 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.6 class 3 = 0.614 +- 0.262 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.6 class 4 = 0.611 +- 0.262 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.6 class 5 = 0.637 +- 0.262 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.6 class 6 = 0.597 +- 0.262 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.6 class 7 = 0.579 +- 0.262 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.6 class 8 = 0.605 +- 0.262 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.6 class 9 = 0.595 +- 0.262 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.6 all KL = 0.511 +- 0.262 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.6 all L1 = 0.582 +- 0.229 (in-sample avg dev_std = 0.350)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.53
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.259
SUFF++ for r=0.9 class 0 = 0.267 +- 0.219 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.9 class 1 = 0.327 +- 0.219 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.9 class 2 = 0.527 +- 0.219 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.9 class 3 = 0.36 +- 0.219 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.9 class 4 = 0.369 +- 0.219 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.9 class 5 = 0.378 +- 0.219 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.9 class 6 = 0.38 +- 0.219 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.9 class 7 = 0.435 +- 0.219 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.9 class 8 = 0.339 +- 0.219 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.9 class 9 = 0.348 +- 0.219 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.9 all KL = 0.236 +- 0.219 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.9 all L1 = 0.373 +- 0.158 (in-sample avg dev_std = 0.506)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.117
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.119
SUFF++ for r=0.3 class 0 = 0.544 +- 0.224 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.3 class 1 = 0.431 +- 0.224 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.3 class 2 = 0.536 +- 0.224 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.3 class 3 = 0.535 +- 0.224 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.3 class 4 = 0.525 +- 0.224 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.3 class 5 = 0.544 +- 0.224 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.3 class 6 = 0.518 +- 0.224 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.3 class 7 = 0.467 +- 0.224 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.3 class 8 = 0.466 +- 0.224 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.3 class 9 = 0.473 +- 0.224 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.3 all KL = 0.416 +- 0.224 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.3 all L1 = 0.503 +- 0.138 (in-sample avg dev_std = 0.424)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.117
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.109
SUFF++ for r=0.6 class 0 = 0.792 +- 0.266 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.6 class 1 = 0.412 +- 0.266 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.6 class 2 = 0.811 +- 0.266 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.6 class 3 = 0.766 +- 0.266 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.6 class 4 = 0.811 +- 0.266 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.6 class 5 = 0.817 +- 0.266 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.6 class 6 = 0.776 +- 0.266 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.6 class 7 = 0.722 +- 0.266 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.6 class 8 = 0.716 +- 0.266 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.6 class 9 = 0.63 +- 0.266 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.6 all KL = 0.701 +- 0.266 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.6 all L1 = 0.721 +- 0.252 (in-sample avg dev_std = 0.230)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.146
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.14
SUFF++ for r=0.9 class 0 = 0.463 +- 0.324 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 class 1 = 0.331 +- 0.324 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 class 2 = 0.716 +- 0.324 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 class 3 = 0.632 +- 0.324 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 class 4 = 0.615 +- 0.324 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 class 5 = 0.613 +- 0.324 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 class 6 = 0.6 +- 0.324 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 class 7 = 0.55 +- 0.324 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 class 8 = 0.581 +- 0.324 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 class 9 = 0.518 +- 0.324 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 all KL = 0.437 +- 0.324 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 all L1 = 0.559 +- 0.257 (in-sample avg dev_std = 0.346)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.126
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.109
NEC for r=0.3 class 0 = 0.516 +- 0.254 (in-sample avg dev_std = 0.457)
NEC for r=0.3 class 1 = 0.594 +- 0.254 (in-sample avg dev_std = 0.457)
NEC for r=0.3 class 2 = 0.58 +- 0.254 (in-sample avg dev_std = 0.457)
NEC for r=0.3 class 3 = 0.621 +- 0.254 (in-sample avg dev_std = 0.457)
NEC for r=0.3 class 4 = 0.647 +- 0.254 (in-sample avg dev_std = 0.457)
NEC for r=0.3 class 5 = 0.587 +- 0.254 (in-sample avg dev_std = 0.457)
NEC for r=0.3 class 6 = 0.558 +- 0.254 (in-sample avg dev_std = 0.457)
NEC for r=0.3 class 7 = 0.574 +- 0.254 (in-sample avg dev_std = 0.457)
NEC for r=0.3 class 8 = 0.612 +- 0.254 (in-sample avg dev_std = 0.457)
NEC for r=0.3 class 9 = 0.547 +- 0.254 (in-sample avg dev_std = 0.457)
NEC for r=0.3 all KL = 0.667 +- 0.254 (in-sample avg dev_std = 0.457)
NEC for r=0.3 all L1 = 0.584 +- 0.182 (in-sample avg dev_std = 0.457)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.145
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.132
NEC for r=0.6 class 0 = 0.489 +- 0.264 (in-sample avg dev_std = 0.420)
NEC for r=0.6 class 1 = 0.668 +- 0.264 (in-sample avg dev_std = 0.420)
NEC for r=0.6 class 2 = 0.45 +- 0.264 (in-sample avg dev_std = 0.420)
NEC for r=0.6 class 3 = 0.47 +- 0.264 (in-sample avg dev_std = 0.420)
NEC for r=0.6 class 4 = 0.548 +- 0.264 (in-sample avg dev_std = 0.420)
NEC for r=0.6 class 5 = 0.5 +- 0.264 (in-sample avg dev_std = 0.420)
NEC for r=0.6 class 6 = 0.529 +- 0.264 (in-sample avg dev_std = 0.420)
NEC for r=0.6 class 7 = 0.518 +- 0.264 (in-sample avg dev_std = 0.420)
NEC for r=0.6 class 8 = 0.393 +- 0.264 (in-sample avg dev_std = 0.420)
NEC for r=0.6 class 9 = 0.523 +- 0.264 (in-sample avg dev_std = 0.420)
NEC for r=0.6 all KL = 0.557 +- 0.264 (in-sample avg dev_std = 0.420)
NEC for r=0.6 all L1 = 0.51 +- 0.206 (in-sample avg dev_std = 0.420)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.762
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.599
NEC for r=0.9 class 0 = 0.506 +- 0.294 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 1 = 0.548 +- 0.294 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 2 = 0.285 +- 0.294 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 3 = 0.491 +- 0.294 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 4 = 0.563 +- 0.294 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 5 = 0.589 +- 0.294 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 6 = 0.44 +- 0.294 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 7 = 0.386 +- 0.294 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 8 = 0.298 +- 0.294 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 9 = 0.582 +- 0.294 (in-sample avg dev_std = 0.461)
NEC for r=0.9 all KL = 0.592 +- 0.294 (in-sample avg dev_std = 0.461)
NEC for r=0.9 all L1 = 0.466 +- 0.242 (in-sample avg dev_std = 0.461)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.926
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.838
NEC for r=1.0 class 0 = 0.081 +- 0.306 (in-sample avg dev_std = 0.348)
NEC for r=1.0 class 1 = 0.05 +- 0.306 (in-sample avg dev_std = 0.348)
NEC for r=1.0 class 2 = 0.242 +- 0.306 (in-sample avg dev_std = 0.348)
NEC for r=1.0 class 3 = 0.321 +- 0.306 (in-sample avg dev_std = 0.348)
NEC for r=1.0 class 4 = 0.241 +- 0.306 (in-sample avg dev_std = 0.348)
NEC for r=1.0 class 5 = 0.429 +- 0.306 (in-sample avg dev_std = 0.348)
NEC for r=1.0 class 6 = 0.233 +- 0.306 (in-sample avg dev_std = 0.348)
NEC for r=1.0 class 7 = 0.242 +- 0.306 (in-sample avg dev_std = 0.348)
NEC for r=1.0 class 8 = 0.188 +- 0.306 (in-sample avg dev_std = 0.348)
NEC for r=1.0 class 9 = 0.322 +- 0.306 (in-sample avg dev_std = 0.348)
NEC for r=1.0 all KL = 0.325 +- 0.306 (in-sample avg dev_std = 0.348)
NEC for r=1.0 all L1 = 0.23 +- 0.237 (in-sample avg dev_std = 0.348)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.104
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.107
NEC for r=0.3 class 0 = 0.565 +- 0.253 (in-sample avg dev_std = 0.407)
NEC for r=0.3 class 1 = 0.576 +- 0.253 (in-sample avg dev_std = 0.407)
NEC for r=0.3 class 2 = 0.569 +- 0.253 (in-sample avg dev_std = 0.407)
NEC for r=0.3 class 3 = 0.533 +- 0.253 (in-sample avg dev_std = 0.407)
NEC for r=0.3 class 4 = 0.539 +- 0.253 (in-sample avg dev_std = 0.407)
NEC for r=0.3 class 5 = 0.522 +- 0.253 (in-sample avg dev_std = 0.407)
NEC for r=0.3 class 6 = 0.526 +- 0.253 (in-sample avg dev_std = 0.407)
NEC for r=0.3 class 7 = 0.539 +- 0.253 (in-sample avg dev_std = 0.407)
NEC for r=0.3 class 8 = 0.599 +- 0.253 (in-sample avg dev_std = 0.407)
NEC for r=0.3 class 9 = 0.535 +- 0.253 (in-sample avg dev_std = 0.407)
NEC for r=0.3 all KL = 0.573 +- 0.253 (in-sample avg dev_std = 0.407)
NEC for r=0.3 all L1 = 0.55 +- 0.164 (in-sample avg dev_std = 0.407)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.11
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.105
NEC for r=0.6 class 0 = 0.414 +- 0.276 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 1 = 0.543 +- 0.276 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 2 = 0.378 +- 0.276 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 3 = 0.391 +- 0.276 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 4 = 0.395 +- 0.276 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 5 = 0.349 +- 0.276 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 6 = 0.368 +- 0.276 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 7 = 0.388 +- 0.276 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 8 = 0.407 +- 0.276 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 9 = 0.396 +- 0.276 (in-sample avg dev_std = 0.360)
NEC for r=0.6 all KL = 0.444 +- 0.276 (in-sample avg dev_std = 0.360)
NEC for r=0.6 all L1 = 0.405 +- 0.231 (in-sample avg dev_std = 0.360)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.53
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.423
NEC for r=0.9 class 0 = 0.61 +- 0.263 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 1 = 0.489 +- 0.263 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 2 = 0.392 +- 0.263 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 3 = 0.552 +- 0.263 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 4 = 0.562 +- 0.263 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 5 = 0.566 +- 0.263 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 6 = 0.615 +- 0.263 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 7 = 0.447 +- 0.263 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 8 = 0.579 +- 0.263 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 9 = 0.604 +- 0.263 (in-sample avg dev_std = 0.447)
NEC for r=0.9 all KL = 0.633 +- 0.263 (in-sample avg dev_std = 0.447)
NEC for r=0.9 all L1 = 0.54 +- 0.208 (in-sample avg dev_std = 0.447)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.741
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.669
NEC for r=1.0 class 0 = 0.273 +- 0.298 (in-sample avg dev_std = 0.384)
NEC for r=1.0 class 1 = 0.108 +- 0.298 (in-sample avg dev_std = 0.384)
NEC for r=1.0 class 2 = 0.31 +- 0.298 (in-sample avg dev_std = 0.384)
NEC for r=1.0 class 3 = 0.409 +- 0.298 (in-sample avg dev_std = 0.384)
NEC for r=1.0 class 4 = 0.365 +- 0.298 (in-sample avg dev_std = 0.384)
NEC for r=1.0 class 5 = 0.453 +- 0.298 (in-sample avg dev_std = 0.384)
NEC for r=1.0 class 6 = 0.409 +- 0.298 (in-sample avg dev_std = 0.384)
NEC for r=1.0 class 7 = 0.206 +- 0.298 (in-sample avg dev_std = 0.384)
NEC for r=1.0 class 8 = 0.433 +- 0.298 (in-sample avg dev_std = 0.384)
NEC for r=1.0 class 9 = 0.481 +- 0.298 (in-sample avg dev_std = 0.384)
NEC for r=1.0 all KL = 0.389 +- 0.298 (in-sample avg dev_std = 0.384)
NEC for r=1.0 all L1 = 0.34 +- 0.250 (in-sample avg dev_std = 0.384)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.117
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.115
NEC for r=0.3 class 0 = 0.496 +- 0.282 (in-sample avg dev_std = 0.367)
NEC for r=0.3 class 1 = 0.461 +- 0.282 (in-sample avg dev_std = 0.367)
NEC for r=0.3 class 2 = 0.465 +- 0.282 (in-sample avg dev_std = 0.367)
NEC for r=0.3 class 3 = 0.46 +- 0.282 (in-sample avg dev_std = 0.367)
NEC for r=0.3 class 4 = 0.443 +- 0.282 (in-sample avg dev_std = 0.367)
NEC for r=0.3 class 5 = 0.459 +- 0.282 (in-sample avg dev_std = 0.367)
NEC for r=0.3 class 6 = 0.482 +- 0.282 (in-sample avg dev_std = 0.367)
NEC for r=0.3 class 7 = 0.479 +- 0.282 (in-sample avg dev_std = 0.367)
NEC for r=0.3 class 8 = 0.521 +- 0.282 (in-sample avg dev_std = 0.367)
NEC for r=0.3 class 9 = 0.484 +- 0.282 (in-sample avg dev_std = 0.367)
NEC for r=0.3 all KL = 0.533 +- 0.282 (in-sample avg dev_std = 0.367)
NEC for r=0.3 all L1 = 0.475 +- 0.188 (in-sample avg dev_std = 0.367)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.117
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.113
NEC for r=0.6 class 0 = 0.249 +- 0.273 (in-sample avg dev_std = 0.245)
NEC for r=0.6 class 1 = 0.534 +- 0.273 (in-sample avg dev_std = 0.245)
NEC for r=0.6 class 2 = 0.198 +- 0.273 (in-sample avg dev_std = 0.245)
NEC for r=0.6 class 3 = 0.241 +- 0.273 (in-sample avg dev_std = 0.245)
NEC for r=0.6 class 4 = 0.193 +- 0.273 (in-sample avg dev_std = 0.245)
NEC for r=0.6 class 5 = 0.185 +- 0.273 (in-sample avg dev_std = 0.245)
NEC for r=0.6 class 6 = 0.244 +- 0.273 (in-sample avg dev_std = 0.245)
NEC for r=0.6 class 7 = 0.259 +- 0.273 (in-sample avg dev_std = 0.245)
NEC for r=0.6 class 8 = 0.298 +- 0.273 (in-sample avg dev_std = 0.245)
NEC for r=0.6 class 9 = 0.359 +- 0.273 (in-sample avg dev_std = 0.245)
NEC for r=0.6 all KL = 0.295 +- 0.273 (in-sample avg dev_std = 0.245)
NEC for r=0.6 all L1 = 0.28 +- 0.242 (in-sample avg dev_std = 0.245)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.146
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.17
NEC for r=0.9 class 0 = 0.659 +- 0.288 (in-sample avg dev_std = 0.395)
NEC for r=0.9 class 1 = 0.503 +- 0.288 (in-sample avg dev_std = 0.395)
NEC for r=0.9 class 2 = 0.349 +- 0.288 (in-sample avg dev_std = 0.395)
NEC for r=0.9 class 3 = 0.46 +- 0.288 (in-sample avg dev_std = 0.395)
NEC for r=0.9 class 4 = 0.451 +- 0.288 (in-sample avg dev_std = 0.395)
NEC for r=0.9 class 5 = 0.465 +- 0.288 (in-sample avg dev_std = 0.395)
NEC for r=0.9 class 6 = 0.494 +- 0.288 (in-sample avg dev_std = 0.395)
NEC for r=0.9 class 7 = 0.501 +- 0.288 (in-sample avg dev_std = 0.395)
NEC for r=0.9 class 8 = 0.544 +- 0.288 (in-sample avg dev_std = 0.395)
NEC for r=0.9 class 9 = 0.55 +- 0.288 (in-sample avg dev_std = 0.395)
NEC for r=0.9 all KL = 0.701 +- 0.288 (in-sample avg dev_std = 0.395)
NEC for r=0.9 all L1 = 0.497 +- 0.227 (in-sample avg dev_std = 0.395)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.183
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.215
NEC for r=1.0 class 0 = 0.604 +- 0.340 (in-sample avg dev_std = 0.341)
NEC for r=1.0 class 1 = 0.428 +- 0.340 (in-sample avg dev_std = 0.341)
NEC for r=1.0 class 2 = 0.362 +- 0.340 (in-sample avg dev_std = 0.341)
NEC for r=1.0 class 3 = 0.437 +- 0.340 (in-sample avg dev_std = 0.341)
NEC for r=1.0 class 4 = 0.359 +- 0.340 (in-sample avg dev_std = 0.341)
NEC for r=1.0 class 5 = 0.5 +- 0.340 (in-sample avg dev_std = 0.341)
NEC for r=1.0 class 6 = 0.412 +- 0.340 (in-sample avg dev_std = 0.341)
NEC for r=1.0 class 7 = 0.465 +- 0.340 (in-sample avg dev_std = 0.341)
NEC for r=1.0 class 8 = 0.471 +- 0.340 (in-sample avg dev_std = 0.341)
NEC for r=1.0 class 9 = 0.391 +- 0.340 (in-sample avg dev_std = 0.341)
NEC for r=1.0 all KL = 0.618 +- 0.340 (in-sample avg dev_std = 0.341)
NEC for r=1.0 all L1 = 0.442 +- 0.269 (in-sample avg dev_std = 0.341)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Mar 23 06:06:15 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mInit GINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mInit vGINFeatExtractor
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:16 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 03/23/2024 06:06:17 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 187...
[0m[1;37mINFO[0m: [1mCheckpoint 187: 
-----------------------------------
Train ACCURACY: 0.9609
Train Loss: 0.1130
ID Validation ACCURACY: 0.8967
ID Validation Loss: 0.3439
ID Test ACCURACY: 0.8937
ID Test Loss: 0.3554
OOD Validation ACCURACY: 0.7863
OOD Validation Loss: 0.8914
OOD Test ACCURACY: 0.2307
OOD Test Loss: 10.8940

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 127...
[0m[1;37mINFO[0m: [1mCheckpoint 127: 
-----------------------------------
Train ACCURACY: 0.9328
Train Loss: 0.1957
ID Validation ACCURACY: 0.8821
ID Validation Loss: 0.3581
ID Test ACCURACY: 0.8791
ID Test Loss: 0.3593
OOD Validation ACCURACY: 0.8147
OOD Validation Loss: 0.5922
OOD Test ACCURACY: 0.3769
OOD Test Loss: 3.0655

[0m[1;37mINFO[0m: [1mChartInfo 0.8937 0.2307 0.8791 0.3769 0.8821 0.8147[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.114
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.107
SUFF++ for r=0.3 class 0 = 0.392 +- 0.263 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.3 class 1 = 0.483 +- 0.263 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.3 class 2 = 0.444 +- 0.263 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.3 class 3 = 0.45 +- 0.263 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.3 class 4 = 0.44 +- 0.263 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.3 class 5 = 0.451 +- 0.263 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.3 class 6 = 0.459 +- 0.263 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.3 class 7 = 0.518 +- 0.263 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.3 class 8 = 0.386 +- 0.263 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.3 class 9 = 0.41 +- 0.263 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.3 all KL = 0.441 +- 0.263 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.3 all L1 = 0.445 +- 0.155 (in-sample avg dev_std = 0.425)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.18
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.128
SUFF++ for r=0.6 class 0 = 0.257 +- 0.162 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.6 class 1 = 0.401 +- 0.162 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.6 class 2 = 0.289 +- 0.162 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.6 class 3 = 0.301 +- 0.162 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.6 class 4 = 0.286 +- 0.162 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.6 class 5 = 0.298 +- 0.162 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.6 class 6 = 0.276 +- 0.162 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.6 class 7 = 0.318 +- 0.162 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.6 class 8 = 0.261 +- 0.162 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.6 class 9 = 0.287 +- 0.162 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.6 all KL = 0.18 +- 0.162 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.6 all L1 = 0.299 +- 0.093 (in-sample avg dev_std = 0.507)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.771
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.42
SUFF++ for r=0.9 class 0 = 0.264 +- 0.158 (in-sample avg dev_std = 0.659)
SUFF++ for r=0.9 class 1 = 0.468 +- 0.158 (in-sample avg dev_std = 0.659)
SUFF++ for r=0.9 class 2 = 0.396 +- 0.158 (in-sample avg dev_std = 0.659)
SUFF++ for r=0.9 class 3 = 0.347 +- 0.158 (in-sample avg dev_std = 0.659)
SUFF++ for r=0.9 class 4 = 0.293 +- 0.158 (in-sample avg dev_std = 0.659)
SUFF++ for r=0.9 class 5 = 0.298 +- 0.158 (in-sample avg dev_std = 0.659)
SUFF++ for r=0.9 class 6 = 0.344 +- 0.158 (in-sample avg dev_std = 0.659)
SUFF++ for r=0.9 class 7 = 0.521 +- 0.158 (in-sample avg dev_std = 0.659)
SUFF++ for r=0.9 class 8 = 0.322 +- 0.158 (in-sample avg dev_std = 0.659)
SUFF++ for r=0.9 class 9 = 0.36 +- 0.158 (in-sample avg dev_std = 0.659)
SUFF++ for r=0.9 all KL = 0.119 +- 0.158 (in-sample avg dev_std = 0.659)
SUFF++ for r=0.9 all L1 = 0.366 +- 0.152 (in-sample avg dev_std = 0.659)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.115
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.114
SUFF++ for r=0.3 class 0 = 0.469 +- 0.248 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.3 class 1 = 0.456 +- 0.248 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.3 class 2 = 0.471 +- 0.248 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.3 class 3 = 0.46 +- 0.248 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.3 class 4 = 0.463 +- 0.248 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.3 class 5 = 0.455 +- 0.248 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.3 class 6 = 0.46 +- 0.248 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.3 class 7 = 0.494 +- 0.248 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.3 class 8 = 0.423 +- 0.248 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.3 class 9 = 0.465 +- 0.248 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.3 all KL = 0.498 +- 0.248 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.3 all L1 = 0.462 +- 0.145 (in-sample avg dev_std = 0.396)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.162
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.135
SUFF++ for r=0.6 class 0 = 0.278 +- 0.148 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.6 class 1 = 0.39 +- 0.148 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.6 class 2 = 0.275 +- 0.148 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.6 class 3 = 0.278 +- 0.148 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.6 class 4 = 0.296 +- 0.148 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.6 class 5 = 0.27 +- 0.148 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.6 class 6 = 0.284 +- 0.148 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.6 class 7 = 0.303 +- 0.148 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.6 class 8 = 0.258 +- 0.148 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.6 class 9 = 0.279 +- 0.148 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.6 all KL = 0.162 +- 0.148 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.6 all L1 = 0.293 +- 0.090 (in-sample avg dev_std = 0.508)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.549
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.344
SUFF++ for r=0.9 class 0 = 0.296 +- 0.189 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.9 class 1 = 0.71 +- 0.189 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.9 class 2 = 0.468 +- 0.189 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.9 class 3 = 0.351 +- 0.189 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.9 class 4 = 0.31 +- 0.189 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.9 class 5 = 0.352 +- 0.189 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.9 class 6 = 0.349 +- 0.189 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.9 class 7 = 0.38 +- 0.189 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.9 class 8 = 0.328 +- 0.189 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.9 class 9 = 0.334 +- 0.189 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.9 all KL = 0.171 +- 0.189 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.9 all L1 = 0.393 +- 0.192 (in-sample avg dev_std = 0.558)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.119
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.108
SUFF++ for r=0.3 class 0 = 0.399 +- 0.249 (in-sample avg dev_std = 0.400)
SUFF++ for r=0.3 class 1 = 0.386 +- 0.249 (in-sample avg dev_std = 0.400)
SUFF++ for r=0.3 class 2 = 0.359 +- 0.249 (in-sample avg dev_std = 0.400)
SUFF++ for r=0.3 class 3 = 0.377 +- 0.249 (in-sample avg dev_std = 0.400)
SUFF++ for r=0.3 class 4 = 0.405 +- 0.249 (in-sample avg dev_std = 0.400)
SUFF++ for r=0.3 class 5 = 0.409 +- 0.249 (in-sample avg dev_std = 0.400)
SUFF++ for r=0.3 class 6 = 0.364 +- 0.249 (in-sample avg dev_std = 0.400)
SUFF++ for r=0.3 class 7 = 0.4 +- 0.249 (in-sample avg dev_std = 0.400)
SUFF++ for r=0.3 class 8 = 0.404 +- 0.249 (in-sample avg dev_std = 0.400)
SUFF++ for r=0.3 class 9 = 0.416 +- 0.249 (in-sample avg dev_std = 0.400)
SUFF++ for r=0.3 all KL = 0.37 +- 0.249 (in-sample avg dev_std = 0.400)
SUFF++ for r=0.3 all L1 = 0.391 +- 0.144 (in-sample avg dev_std = 0.400)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.184
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.165
SUFF++ for r=0.6 class 0 = 0.383 +- 0.189 (in-sample avg dev_std = 0.606)
SUFF++ for r=0.6 class 1 = 0.488 +- 0.189 (in-sample avg dev_std = 0.606)
SUFF++ for r=0.6 class 2 = 0.374 +- 0.189 (in-sample avg dev_std = 0.606)
SUFF++ for r=0.6 class 3 = 0.361 +- 0.189 (in-sample avg dev_std = 0.606)
SUFF++ for r=0.6 class 4 = 0.372 +- 0.189 (in-sample avg dev_std = 0.606)
SUFF++ for r=0.6 class 5 = 0.363 +- 0.189 (in-sample avg dev_std = 0.606)
SUFF++ for r=0.6 class 6 = 0.38 +- 0.189 (in-sample avg dev_std = 0.606)
SUFF++ for r=0.6 class 7 = 0.354 +- 0.189 (in-sample avg dev_std = 0.606)
SUFF++ for r=0.6 class 8 = 0.343 +- 0.189 (in-sample avg dev_std = 0.606)
SUFF++ for r=0.6 class 9 = 0.322 +- 0.189 (in-sample avg dev_std = 0.606)
SUFF++ for r=0.6 all KL = 0.192 +- 0.189 (in-sample avg dev_std = 0.606)
SUFF++ for r=0.6 all L1 = 0.375 +- 0.152 (in-sample avg dev_std = 0.606)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.168
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.178
SUFF++ for r=0.9 class 0 = 0.369 +- 0.288 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.9 class 1 = 0.66 +- 0.288 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.9 class 2 = 0.457 +- 0.288 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.9 class 3 = 0.453 +- 0.288 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.9 class 4 = 0.335 +- 0.288 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.9 class 5 = 0.388 +- 0.288 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.9 class 6 = 0.368 +- 0.288 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.9 class 7 = 0.431 +- 0.288 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.9 class 8 = 0.341 +- 0.288 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.9 class 9 = 0.351 +- 0.288 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.9 all KL = 0.243 +- 0.288 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.9 all L1 = 0.419 +- 0.254 (in-sample avg dev_std = 0.459)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.114
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.112
NEC for r=0.3 class 0 = 0.598 +- 0.292 (in-sample avg dev_std = 0.377)
NEC for r=0.3 class 1 = 0.449 +- 0.292 (in-sample avg dev_std = 0.377)
NEC for r=0.3 class 2 = 0.552 +- 0.292 (in-sample avg dev_std = 0.377)
NEC for r=0.3 class 3 = 0.552 +- 0.292 (in-sample avg dev_std = 0.377)
NEC for r=0.3 class 4 = 0.558 +- 0.292 (in-sample avg dev_std = 0.377)
NEC for r=0.3 class 5 = 0.563 +- 0.292 (in-sample avg dev_std = 0.377)
NEC for r=0.3 class 6 = 0.517 +- 0.292 (in-sample avg dev_std = 0.377)
NEC for r=0.3 class 7 = 0.49 +- 0.292 (in-sample avg dev_std = 0.377)
NEC for r=0.3 class 8 = 0.638 +- 0.292 (in-sample avg dev_std = 0.377)
NEC for r=0.3 class 9 = 0.579 +- 0.292 (in-sample avg dev_std = 0.377)
NEC for r=0.3 all KL = 0.555 +- 0.292 (in-sample avg dev_std = 0.377)
NEC for r=0.3 all L1 = 0.547 +- 0.194 (in-sample avg dev_std = 0.377)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.18
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.154
NEC for r=0.6 class 0 = 0.663 +- 0.242 (in-sample avg dev_std = 0.408)
NEC for r=0.6 class 1 = 0.499 +- 0.242 (in-sample avg dev_std = 0.408)
NEC for r=0.6 class 2 = 0.622 +- 0.242 (in-sample avg dev_std = 0.408)
NEC for r=0.6 class 3 = 0.615 +- 0.242 (in-sample avg dev_std = 0.408)
NEC for r=0.6 class 4 = 0.633 +- 0.242 (in-sample avg dev_std = 0.408)
NEC for r=0.6 class 5 = 0.622 +- 0.242 (in-sample avg dev_std = 0.408)
NEC for r=0.6 class 6 = 0.624 +- 0.242 (in-sample avg dev_std = 0.408)
NEC for r=0.6 class 7 = 0.55 +- 0.242 (in-sample avg dev_std = 0.408)
NEC for r=0.6 class 8 = 0.628 +- 0.242 (in-sample avg dev_std = 0.408)
NEC for r=0.6 class 9 = 0.641 +- 0.242 (in-sample avg dev_std = 0.408)
NEC for r=0.6 all KL = 0.669 +- 0.242 (in-sample avg dev_std = 0.408)
NEC for r=0.6 all L1 = 0.607 +- 0.161 (in-sample avg dev_std = 0.408)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.771
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.649
NEC for r=0.9 class 0 = 0.556 +- 0.300 (in-sample avg dev_std = 0.446)
NEC for r=0.9 class 1 = 0.253 +- 0.300 (in-sample avg dev_std = 0.446)
NEC for r=0.9 class 2 = 0.33 +- 0.300 (in-sample avg dev_std = 0.446)
NEC for r=0.9 class 3 = 0.427 +- 0.300 (in-sample avg dev_std = 0.446)
NEC for r=0.9 class 4 = 0.408 +- 0.300 (in-sample avg dev_std = 0.446)
NEC for r=0.9 class 5 = 0.57 +- 0.300 (in-sample avg dev_std = 0.446)
NEC for r=0.9 class 6 = 0.542 +- 0.300 (in-sample avg dev_std = 0.446)
NEC for r=0.9 class 7 = 0.348 +- 0.300 (in-sample avg dev_std = 0.446)
NEC for r=0.9 class 8 = 0.364 +- 0.300 (in-sample avg dev_std = 0.446)
NEC for r=0.9 class 9 = 0.616 +- 0.300 (in-sample avg dev_std = 0.446)
NEC for r=0.9 all KL = 0.555 +- 0.300 (in-sample avg dev_std = 0.446)
NEC for r=0.9 all L1 = 0.434 +- 0.245 (in-sample avg dev_std = 0.446)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.931
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.85
NEC for r=1.0 class 0 = 0.131 +- 0.302 (in-sample avg dev_std = 0.332)
NEC for r=1.0 class 1 = 0.037 +- 0.302 (in-sample avg dev_std = 0.332)
NEC for r=1.0 class 2 = 0.204 +- 0.302 (in-sample avg dev_std = 0.332)
NEC for r=1.0 class 3 = 0.282 +- 0.302 (in-sample avg dev_std = 0.332)
NEC for r=1.0 class 4 = 0.153 +- 0.302 (in-sample avg dev_std = 0.332)
NEC for r=1.0 class 5 = 0.371 +- 0.302 (in-sample avg dev_std = 0.332)
NEC for r=1.0 class 6 = 0.243 +- 0.302 (in-sample avg dev_std = 0.332)
NEC for r=1.0 class 7 = 0.219 +- 0.302 (in-sample avg dev_std = 0.332)
NEC for r=1.0 class 8 = 0.196 +- 0.302 (in-sample avg dev_std = 0.332)
NEC for r=1.0 class 9 = 0.373 +- 0.302 (in-sample avg dev_std = 0.332)
NEC for r=1.0 all KL = 0.293 +- 0.302 (in-sample avg dev_std = 0.332)
NEC for r=1.0 all L1 = 0.216 +- 0.236 (in-sample avg dev_std = 0.332)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.115
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.11
NEC for r=0.3 class 0 = 0.514 +- 0.275 (in-sample avg dev_std = 0.359)
NEC for r=0.3 class 1 = 0.461 +- 0.275 (in-sample avg dev_std = 0.359)
NEC for r=0.3 class 2 = 0.51 +- 0.275 (in-sample avg dev_std = 0.359)
NEC for r=0.3 class 3 = 0.535 +- 0.275 (in-sample avg dev_std = 0.359)
NEC for r=0.3 class 4 = 0.452 +- 0.275 (in-sample avg dev_std = 0.359)
NEC for r=0.3 class 5 = 0.503 +- 0.275 (in-sample avg dev_std = 0.359)
NEC for r=0.3 class 6 = 0.5 +- 0.275 (in-sample avg dev_std = 0.359)
NEC for r=0.3 class 7 = 0.457 +- 0.275 (in-sample avg dev_std = 0.359)
NEC for r=0.3 class 8 = 0.548 +- 0.275 (in-sample avg dev_std = 0.359)
NEC for r=0.3 class 9 = 0.442 +- 0.275 (in-sample avg dev_std = 0.359)
NEC for r=0.3 all KL = 0.446 +- 0.275 (in-sample avg dev_std = 0.359)
NEC for r=0.3 all L1 = 0.491 +- 0.194 (in-sample avg dev_std = 0.359)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.162
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.139
NEC for r=0.6 class 0 = 0.626 +- 0.256 (in-sample avg dev_std = 0.402)
NEC for r=0.6 class 1 = 0.362 +- 0.256 (in-sample avg dev_std = 0.402)
NEC for r=0.6 class 2 = 0.608 +- 0.256 (in-sample avg dev_std = 0.402)
NEC for r=0.6 class 3 = 0.586 +- 0.256 (in-sample avg dev_std = 0.402)
NEC for r=0.6 class 4 = 0.588 +- 0.256 (in-sample avg dev_std = 0.402)
NEC for r=0.6 class 5 = 0.601 +- 0.256 (in-sample avg dev_std = 0.402)
NEC for r=0.6 class 6 = 0.558 +- 0.256 (in-sample avg dev_std = 0.402)
NEC for r=0.6 class 7 = 0.547 +- 0.256 (in-sample avg dev_std = 0.402)
NEC for r=0.6 class 8 = 0.599 +- 0.256 (in-sample avg dev_std = 0.402)
NEC for r=0.6 class 9 = 0.546 +- 0.256 (in-sample avg dev_std = 0.402)
NEC for r=0.6 all KL = 0.604 +- 0.256 (in-sample avg dev_std = 0.402)
NEC for r=0.6 all L1 = 0.558 +- 0.181 (in-sample avg dev_std = 0.402)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.549
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.487
NEC for r=0.9 class 0 = 0.523 +- 0.290 (in-sample avg dev_std = 0.438)
NEC for r=0.9 class 1 = 0.166 +- 0.290 (in-sample avg dev_std = 0.438)
NEC for r=0.9 class 2 = 0.434 +- 0.290 (in-sample avg dev_std = 0.438)
NEC for r=0.9 class 3 = 0.466 +- 0.290 (in-sample avg dev_std = 0.438)
NEC for r=0.9 class 4 = 0.587 +- 0.290 (in-sample avg dev_std = 0.438)
NEC for r=0.9 class 5 = 0.562 +- 0.290 (in-sample avg dev_std = 0.438)
NEC for r=0.9 class 6 = 0.621 +- 0.290 (in-sample avg dev_std = 0.438)
NEC for r=0.9 class 7 = 0.505 +- 0.290 (in-sample avg dev_std = 0.438)
NEC for r=0.9 class 8 = 0.576 +- 0.290 (in-sample avg dev_std = 0.438)
NEC for r=0.9 class 9 = 0.615 +- 0.290 (in-sample avg dev_std = 0.438)
NEC for r=0.9 all KL = 0.597 +- 0.290 (in-sample avg dev_std = 0.438)
NEC for r=0.9 all L1 = 0.5 +- 0.243 (in-sample avg dev_std = 0.438)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.788
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.713
NEC for r=1.0 class 0 = 0.205 +- 0.303 (in-sample avg dev_std = 0.378)
NEC for r=1.0 class 1 = 0.035 +- 0.303 (in-sample avg dev_std = 0.378)
NEC for r=1.0 class 2 = 0.264 +- 0.303 (in-sample avg dev_std = 0.378)
NEC for r=1.0 class 3 = 0.334 +- 0.303 (in-sample avg dev_std = 0.378)
NEC for r=1.0 class 4 = 0.352 +- 0.303 (in-sample avg dev_std = 0.378)
NEC for r=1.0 class 5 = 0.377 +- 0.303 (in-sample avg dev_std = 0.378)
NEC for r=1.0 class 6 = 0.385 +- 0.303 (in-sample avg dev_std = 0.378)
NEC for r=1.0 class 7 = 0.254 +- 0.303 (in-sample avg dev_std = 0.378)
NEC for r=1.0 class 8 = 0.389 +- 0.303 (in-sample avg dev_std = 0.378)
NEC for r=1.0 class 9 = 0.442 +- 0.303 (in-sample avg dev_std = 0.378)
NEC for r=1.0 all KL = 0.36 +- 0.303 (in-sample avg dev_std = 0.378)
NEC for r=1.0 all L1 = 0.299 +- 0.251 (in-sample avg dev_std = 0.378)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.119
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.112
NEC for r=0.3 class 0 = 0.577 +- 0.283 (in-sample avg dev_std = 0.356)
NEC for r=0.3 class 1 = 0.493 +- 0.283 (in-sample avg dev_std = 0.356)
NEC for r=0.3 class 2 = 0.538 +- 0.283 (in-sample avg dev_std = 0.356)
NEC for r=0.3 class 3 = 0.563 +- 0.283 (in-sample avg dev_std = 0.356)
NEC for r=0.3 class 4 = 0.493 +- 0.283 (in-sample avg dev_std = 0.356)
NEC for r=0.3 class 5 = 0.584 +- 0.283 (in-sample avg dev_std = 0.356)
NEC for r=0.3 class 6 = 0.557 +- 0.283 (in-sample avg dev_std = 0.356)
NEC for r=0.3 class 7 = 0.53 +- 0.283 (in-sample avg dev_std = 0.356)
NEC for r=0.3 class 8 = 0.551 +- 0.283 (in-sample avg dev_std = 0.356)
NEC for r=0.3 class 9 = 0.506 +- 0.283 (in-sample avg dev_std = 0.356)
NEC for r=0.3 all KL = 0.513 +- 0.283 (in-sample avg dev_std = 0.356)
NEC for r=0.3 all L1 = 0.538 +- 0.181 (in-sample avg dev_std = 0.356)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.184
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.195
NEC for r=0.6 class 0 = 0.331 +- 0.342 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 1 = 0.305 +- 0.342 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 2 = 0.367 +- 0.342 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 3 = 0.399 +- 0.342 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 4 = 0.425 +- 0.342 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 5 = 0.428 +- 0.342 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 6 = 0.455 +- 0.342 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 7 = 0.477 +- 0.342 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 8 = 0.474 +- 0.342 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 9 = 0.528 +- 0.342 (in-sample avg dev_std = 0.348)
NEC for r=0.6 all KL = 0.483 +- 0.342 (in-sample avg dev_std = 0.348)
NEC for r=0.6 all L1 = 0.416 +- 0.278 (in-sample avg dev_std = 0.348)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.168
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.218
NEC for r=0.9 class 0 = 0.595 +- 0.337 (in-sample avg dev_std = 0.367)
NEC for r=0.9 class 1 = 0.381 +- 0.337 (in-sample avg dev_std = 0.367)
NEC for r=0.9 class 2 = 0.485 +- 0.337 (in-sample avg dev_std = 0.367)
NEC for r=0.9 class 3 = 0.522 +- 0.337 (in-sample avg dev_std = 0.367)
NEC for r=0.9 class 4 = 0.664 +- 0.337 (in-sample avg dev_std = 0.367)
NEC for r=0.9 class 5 = 0.56 +- 0.337 (in-sample avg dev_std = 0.367)
NEC for r=0.9 class 6 = 0.639 +- 0.337 (in-sample avg dev_std = 0.367)
NEC for r=0.9 class 7 = 0.58 +- 0.337 (in-sample avg dev_std = 0.367)
NEC for r=0.9 class 8 = 0.669 +- 0.337 (in-sample avg dev_std = 0.367)
NEC for r=0.9 class 9 = 0.677 +- 0.337 (in-sample avg dev_std = 0.367)
NEC for r=0.9 all KL = 0.672 +- 0.337 (in-sample avg dev_std = 0.367)
NEC for r=0.9 all L1 = 0.574 +- 0.274 (in-sample avg dev_std = 0.367)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.241
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.29
NEC for r=1.0 class 0 = 0.575 +- 0.306 (in-sample avg dev_std = 0.371)
NEC for r=1.0 class 1 = 0.441 +- 0.306 (in-sample avg dev_std = 0.371)
NEC for r=1.0 class 2 = 0.643 +- 0.306 (in-sample avg dev_std = 0.371)
NEC for r=1.0 class 3 = 0.622 +- 0.306 (in-sample avg dev_std = 0.371)
NEC for r=1.0 class 4 = 0.697 +- 0.306 (in-sample avg dev_std = 0.371)
NEC for r=1.0 class 5 = 0.627 +- 0.306 (in-sample avg dev_std = 0.371)
NEC for r=1.0 class 6 = 0.643 +- 0.306 (in-sample avg dev_std = 0.371)
NEC for r=1.0 class 7 = 0.713 +- 0.306 (in-sample avg dev_std = 0.371)
NEC for r=1.0 class 8 = 0.647 +- 0.306 (in-sample avg dev_std = 0.371)
NEC for r=1.0 class 9 = 0.697 +- 0.306 (in-sample avg dev_std = 0.371)
NEC for r=1.0 all KL = 0.743 +- 0.306 (in-sample avg dev_std = 0.371)
NEC for r=1.0 all L1 = 0.628 +- 0.242 (in-sample avg dev_std = 0.371)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.793, 0.274, 0.157, 1.0], 'all_L1': [0.785, 0.368, 0.367, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.437, 0.175, 0.102, 1.0], 'all_L1': [0.511, 0.294, 0.343, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.604, 0.208, 0.092, 1.0], 'all_L1': [0.609, 0.3, 0.33, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.323, 0.362, 0.148, 1.0], 'all_L1': [0.424, 0.452, 0.365, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.441, 0.18, 0.119, 1.0], 'all_L1': [0.445, 0.299, 0.366, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.224, 0.59, 0.565, 0.313], 'all_L1': [0.228, 0.554, 0.448, 0.232]}), defaultdict(<class 'list'>, {'all_KL': [0.635, 0.762, 0.562, 0.309], 'all_L1': [0.534, 0.652, 0.427, 0.223]}), defaultdict(<class 'list'>, {'all_KL': [0.463, 0.689, 0.564, 0.305], 'all_L1': [0.426, 0.631, 0.434, 0.213]}), defaultdict(<class 'list'>, {'all_KL': [0.667, 0.557, 0.592, 0.325], 'all_L1': [0.584, 0.51, 0.466, 0.23]}), defaultdict(<class 'list'>, {'all_KL': [0.555, 0.669, 0.555, 0.293], 'all_L1': [0.547, 0.607, 0.434, 0.216]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.683, 0.187, 0.189, 1.0], 'all_L1': [0.687, 0.391, 0.353, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.481, 0.119, 0.169, 1.0], 'all_L1': [0.554, 0.277, 0.37, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.757, 0.239, 0.094, 1.0], 'all_L1': [0.738, 0.312, 0.288, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.355, 0.511, 0.236, 1.0], 'all_L1': [0.419, 0.582, 0.373, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.498, 0.162, 0.171, 1.0], 'all_L1': [0.462, 0.293, 0.393, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.254, 0.445, 0.606, 0.362], 'all_L1': [0.273, 0.397, 0.525, 0.312]}), defaultdict(<class 'list'>, {'all_KL': [0.526, 0.651, 0.634, 0.391], 'all_L1': [0.45, 0.542, 0.523, 0.325]}), defaultdict(<class 'list'>, {'all_KL': [0.273, 0.62, 0.668, 0.414], 'all_L1': [0.283, 0.589, 0.562, 0.331]}), defaultdict(<class 'list'>, {'all_KL': [0.573, 0.444, 0.633, 0.389], 'all_L1': [0.55, 0.405, 0.54, 0.34]}), defaultdict(<class 'list'>, {'all_KL': [0.446, 0.604, 0.597, 0.36], 'all_L1': [0.491, 0.558, 0.5, 0.299]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.558, 0.465, 0.389, 1.0], 'all_L1': [0.599, 0.609, 0.517, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.421, 0.194, 0.372, 1.0], 'all_L1': [0.478, 0.341, 0.515, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.459, 0.121, 0.081, 1.0], 'all_L1': [0.529, 0.308, 0.308, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.416, 0.701, 0.437, 1.0], 'all_L1': [0.503, 0.721, 0.559, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.37, 0.192, 0.243, 1.0], 'all_L1': [0.391, 0.375, 0.419, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.366, 0.306, 0.578, 0.454], 'all_L1': [0.367, 0.302, 0.476, 0.438]}), defaultdict(<class 'list'>, {'all_KL': [0.562, 0.632, 0.587, 0.512], 'all_L1': [0.506, 0.554, 0.477, 0.465]}), defaultdict(<class 'list'>, {'all_KL': [0.571, 0.841, 0.818, 0.75], 'all_L1': [0.513, 0.709, 0.68, 0.625]}), defaultdict(<class 'list'>, {'all_KL': [0.533, 0.295, 0.701, 0.618], 'all_L1': [0.475, 0.28, 0.497, 0.442]}), defaultdict(<class 'list'>, {'all_KL': [0.513, 0.483, 0.672, 0.743], 'all_L1': [0.538, 0.416, 0.574, 0.628]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.555 +- 0.132, 0.343 +- 0.061, 0.354 +- 0.015, 1.000 +- 0.000
suff++ class all_KL  =  0.520 +- 0.163, 0.240 +- 0.071, 0.124 +- 0.025, 1.000 +- 0.000
suff++_acc_int  =  0.107 +- 0.009, 0.121 +- 0.007, 0.390 +- 0.017
nec class all_L1  =  0.464 +- 0.129, 0.591 +- 0.052, 0.442 +- 0.014, 0.223 +- 0.007
nec class all_KL  =  0.509 +- 0.159, 0.653 +- 0.073, 0.568 +- 0.013, 0.309 +- 0.010
nec_acc_int  =  0.109 +- 0.006, 0.130 +- 0.014, 0.644 +- 0.025, 0.841 +- 0.005

Eval split val
suff++ class all_L1  =  0.572 +- 0.124, 0.371 +- 0.113, 0.355 +- 0.036, 1.000 +- 0.000
suff++ class all_KL  =  0.555 +- 0.146, 0.244 +- 0.139, 0.172 +- 0.046, 1.000 +- 0.000
suff++_acc_int  =  0.107 +- 0.004, 0.113 +- 0.013, 0.285 +- 0.033
nec class all_L1  =  0.409 +- 0.112, 0.498 +- 0.081, 0.530 +- 0.020, 0.321 +- 0.014
nec class all_KL  =  0.414 +- 0.130, 0.553 +- 0.090, 0.628 +- 0.025, 0.383 +- 0.020
nec_acc_int  =  0.112 +- 0.005, 0.111 +- 0.015, 0.446 +- 0.024, 0.697 +- 0.016

Eval split test
suff++ class all_L1  =  0.500 +- 0.068, 0.471 +- 0.164, 0.464 +- 0.090, 1.000 +- 0.000
suff++ class all_KL  =  0.445 +- 0.063, 0.335 +- 0.218, 0.304 +- 0.129, 1.000 +- 0.000
suff++_acc_int  =  0.107 +- 0.007, 0.123 +- 0.022, 0.172 +- 0.026
nec class all_L1  =  0.480 +- 0.060, 0.452 +- 0.161, 0.541 +- 0.078, 0.520 +- 0.088
nec class all_KL  =  0.509 +- 0.074, 0.511 +- 0.206, 0.671 +- 0.087, 0.615 +- 0.119
nec_acc_int  =  0.114 +- 0.002, 0.152 +- 0.034, 0.213 +- 0.027, 0.290 +- 0.043


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.509 +- 0.010, 0.467 +- 0.010, 0.398 +- 0.013, 0.611 +- 0.004
Faith. Armon (L1)= 		  =  0.472 +- 0.060, 0.427 +- 0.030, 0.393 +- 0.013, 0.364 +- 0.010
Faith. GMean (L1)= 	  =  0.489 +- 0.035, 0.446 +- 0.019, 0.396 +- 0.013, 0.472 +- 0.008
Faith. Aritm (KL)= 		  =  0.514 +- 0.017, 0.447 +- 0.016, 0.346 +- 0.017, 0.655 +- 0.005
Faith. Armon (KL)= 		  =  0.464 +- 0.065, 0.340 +- 0.059, 0.202 +- 0.034, 0.472 +- 0.012
Faith. GMean (KL)= 	  =  0.487 +- 0.041, 0.388 +- 0.035, 0.264 +- 0.029, 0.556 +- 0.009

Eval split val
Faith. Aritm (L1)= 		  =  0.491 +- 0.013, 0.435 +- 0.035, 0.443 +- 0.010, 0.661 +- 0.007
Faith. Armon (L1)= 		  =  0.450 +- 0.042, 0.406 +- 0.038, 0.424 +- 0.022, 0.486 +- 0.017
Faith. GMean (L1)= 	  =  0.469 +- 0.022, 0.420 +- 0.036, 0.433 +- 0.016, 0.567 +- 0.013
Faith. Aritm (KL)= 		  =  0.485 +- 0.021, 0.398 +- 0.054, 0.400 +- 0.019, 0.692 +- 0.010
Faith. Armon (KL)= 		  =  0.437 +- 0.047, 0.308 +- 0.095, 0.266 +- 0.058, 0.554 +- 0.021
Faith. GMean (KL)= 	  =  0.459 +- 0.028, 0.348 +- 0.074, 0.324 +- 0.044, 0.619 +- 0.016

Eval split test
Faith. Aritm (L1)= 		  =  0.490 +- 0.018, 0.461 +- 0.041, 0.502 +- 0.013, 0.760 +- 0.044
Faith. Armon (L1)= 		  =  0.482 +- 0.025, 0.411 +- 0.013, 0.485 +- 0.034, 0.680 +- 0.075
Faith. GMean (L1)= 	  =  0.486 +- 0.021, 0.435 +- 0.024, 0.493 +- 0.022, 0.718 +- 0.060
Faith. Aritm (KL)= 		  =  0.477 +- 0.025, 0.423 +- 0.060, 0.488 +- 0.043, 0.808 +- 0.060
Faith. Armon (KL)= 		  =  0.466 +- 0.028, 0.314 +- 0.072, 0.393 +- 0.136, 0.755 +- 0.093
Faith. GMean (KL)= 	  =  0.471 +- 0.027, 0.361 +- 0.053, 0.431 +- 0.099, 0.781 +- 0.077
Computed for split load_split = id



Completed in  2:23:58.209580  for GSATvGIN GOODCMNIST/color



DONE GSAT GOODCMNIST/color
DONE all :)
