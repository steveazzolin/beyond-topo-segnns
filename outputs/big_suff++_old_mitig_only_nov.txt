nohup: ignoring input

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Thu May  2 22:45:00 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:00 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:13 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:15 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:17 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:20 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 10:45:27 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 71...
[0m[1;37mINFO[0m: [1mCheckpoint 71: 
-----------------------------------
Train ACCURACY: 0.8942
Train Loss: 0.4344
ID Validation ACCURACY: 0.8973
ID Validation Loss: 0.4044
ID Test ACCURACY: 0.9013
ID Test Loss: 0.4260
OOD Validation ACCURACY: 0.8457
OOD Validation Loss: 0.5846
OOD Test ACCURACY: 0.5280
OOD Test Loss: 8.1118

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 117...
[0m[1;37mINFO[0m: [1mCheckpoint 117: 
-----------------------------------
Train ACCURACY: 0.8516
Train Loss: 0.6026
ID Validation ACCURACY: 0.8620
ID Validation Loss: 0.5670
ID Test ACCURACY: 0.8640
ID Test Loss: 0.5821
OOD Validation ACCURACY: 0.8510
OOD Validation Loss: 0.6003
OOD Test ACCURACY: 0.5033
OOD Test Loss: 7.6422

[0m[1;37mINFO[0m: [1mChartInfo 0.9013 0.5280 0.8640 0.5033 0.8620 0.8510[0mGOODMotif(18000)
Data example from train: Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
Label distribution from train: (tensor([0, 1, 2]), tensor([5912, 6084, 6004]))

Gold ratio (train) =  tensor(0.3628) +- tensor(0.1901)
F1 for r=0.3 = 0.464
WIoU for r=0.3 = 0.348
F1 for r=0.6 = 0.514
WIoU for r=0.6 = 0.379
F1 for r=0.9 = 0.513
WIoU for r=0.9 = 0.378
F1 for r=1.0 = 0.506
WIoU for r=1.0 = 0.373
GOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.433
WIoU for r=0.3 = 0.318
F1 for r=0.6 = 0.499
WIoU for r=0.6 = 0.363
F1 for r=0.9 = 0.498
WIoU for r=0.9 = 0.361
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.357
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.359
WIoU for r=0.3 = 0.279
F1 for r=0.6 = 0.282
WIoU for r=0.6 = 0.206
F1 for r=0.9 = 0.246
WIoU for r=0.9 = 0.178
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.171
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.114
WIoU for r=0.3 = 0.063
F1 for r=0.6 = 0.113
WIoU for r=0.6 = 0.061
F1 for r=0.9 = 0.110
WIoU for r=0.9 = 0.059
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.060


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.373
Model XAI F1 of binarized graphs for r=0.3 =  0.46359625
Model XAI WIoU of binarized graphs for r=0.3 =  0.34830124999999995
len(reference) = 724
Effective ratio: 0.314 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.353
SUFF++ for r=0.3 class 0 = 0.563 +- 0.211 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.3 class 1 = 0.572 +- 0.211 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.3 class 2 = 0.577 +- 0.211 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.3 all KL = 0.648 +- 0.211 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.3 all L1 = 0.57 +- 0.142 (in-sample avg dev_std = 0.480)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.423
Model XAI F1 of binarized graphs for r=0.6 =  0.51403875
Model XAI WIoU of binarized graphs for r=0.6 =  0.37938249999999996
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.39
SUFF++ for r=0.6 class 0 = 0.583 +- 0.272 (in-sample avg dev_std = 0.502)
SUFF++ for r=0.6 class 1 = 0.586 +- 0.272 (in-sample avg dev_std = 0.502)
SUFF++ for r=0.6 class 2 = 0.594 +- 0.272 (in-sample avg dev_std = 0.502)
SUFF++ for r=0.6 all KL = 0.607 +- 0.272 (in-sample avg dev_std = 0.502)
SUFF++ for r=0.6 all L1 = 0.588 +- 0.161 (in-sample avg dev_std = 0.502)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.564
Model XAI F1 of binarized graphs for r=0.9 =  0.5130899999999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.37777249999999996
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.576
SUFF++ for r=0.9 class 0 = 0.696 +- 0.241 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.9 class 1 = 0.692 +- 0.241 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.9 class 2 = 0.658 +- 0.241 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.9 all KL = 0.729 +- 0.241 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.9 all L1 = 0.682 +- 0.196 (in-sample avg dev_std = 0.424)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.35
Model XAI F1 of binarized graphs for r=0.3 =  0.43332375
Model XAI WIoU of binarized graphs for r=0.3 =  0.3180525
len(reference) = 726
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.345
SUFF++ for r=0.3 class 0 = 0.586 +- 0.208 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.3 class 1 = 0.581 +- 0.208 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.3 class 2 = 0.593 +- 0.208 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.3 all KL = 0.67 +- 0.208 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.3 all L1 = 0.587 +- 0.148 (in-sample avg dev_std = 0.468)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.425
Model XAI F1 of binarized graphs for r=0.6 =  0.49894625000000004
Model XAI WIoU of binarized graphs for r=0.6 =  0.36302500000000004
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.398
SUFF++ for r=0.6 class 0 = 0.597 +- 0.257 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 class 1 = 0.593 +- 0.257 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 class 2 = 0.594 +- 0.257 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 all KL = 0.631 +- 0.257 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 all L1 = 0.594 +- 0.164 (in-sample avg dev_std = 0.468)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.596
Model XAI F1 of binarized graphs for r=0.9 =  0.49832499999999996
Model XAI WIoU of binarized graphs for r=0.9 =  0.36123000000000005
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.595
SUFF++ for r=0.9 class 0 = 0.655 +- 0.224 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.9 class 1 = 0.713 +- 0.224 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.9 class 2 = 0.66 +- 0.224 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.9 all KL = 0.734 +- 0.224 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.9 all L1 = 0.676 +- 0.187 (in-sample avg dev_std = 0.419)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.383
Model XAI F1 of binarized graphs for r=0.3 =  0.35947874999999996
Model XAI WIoU of binarized graphs for r=0.3 =  0.27911749999999996
len(reference) = 793
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.415
SUFF++ for r=0.3 class 0 = 0.579 +- 0.275 (in-sample avg dev_std = 0.518)
SUFF++ for r=0.3 class 1 = 0.581 +- 0.275 (in-sample avg dev_std = 0.518)
SUFF++ for r=0.3 class 2 = 0.64 +- 0.275 (in-sample avg dev_std = 0.518)
SUFF++ for r=0.3 all KL = 0.614 +- 0.275 (in-sample avg dev_std = 0.518)
SUFF++ for r=0.3 all L1 = 0.599 +- 0.140 (in-sample avg dev_std = 0.518)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.377
Model XAI F1 of binarized graphs for r=0.6 =  0.28167375
Model XAI WIoU of binarized graphs for r=0.6 =  0.206395
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.389
SUFF++ for r=0.6 class 0 = 0.6 +- 0.227 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.6 class 1 = 0.599 +- 0.227 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.6 class 2 = 0.627 +- 0.227 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.6 all KL = 0.647 +- 0.227 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.6 all L1 = 0.608 +- 0.127 (in-sample avg dev_std = 0.470)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.656
Model XAI F1 of binarized graphs for r=0.9 =  0.2460825
Model XAI WIoU of binarized graphs for r=0.9 =  0.17782875
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.616
SUFF++ for r=0.9 class 0 = 0.7 +- 0.167 (in-sample avg dev_std = 0.309)
SUFF++ for r=0.9 class 1 = 0.691 +- 0.167 (in-sample avg dev_std = 0.309)
SUFF++ for r=0.9 class 2 = 0.716 +- 0.167 (in-sample avg dev_std = 0.309)
SUFF++ for r=0.9 all KL = 0.827 +- 0.167 (in-sample avg dev_std = 0.309)
SUFF++ for r=0.9 all L1 = 0.702 +- 0.165 (in-sample avg dev_std = 0.309)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.325
Model XAI F1 of binarized graphs for r=0.3 =  0.11364625
Model XAI WIoU of binarized graphs for r=0.3 =  0.0626675
len(reference) = 779
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.327
SUFF++ for r=0.3 class 0 = 0.574 +- 0.314 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.3 class 1 = 0.59 +- 0.314 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.3 class 2 = 0.578 +- 0.314 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.3 all KL = 0.602 +- 0.314 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.3 all L1 = 0.581 +- 0.195 (in-sample avg dev_std = 0.429)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.34
Model XAI F1 of binarized graphs for r=0.6 =  0.11329875000000002
Model XAI WIoU of binarized graphs for r=0.6 =  0.06106625
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.333
SUFF++ for r=0.6 class 0 = 0.66 +- 0.336 (in-sample avg dev_std = 0.404)
SUFF++ for r=0.6 class 1 = 0.663 +- 0.336 (in-sample avg dev_std = 0.404)
SUFF++ for r=0.6 class 2 = 0.664 +- 0.336 (in-sample avg dev_std = 0.404)
SUFF++ for r=0.6 all KL = 0.715 +- 0.336 (in-sample avg dev_std = 0.404)
SUFF++ for r=0.6 all L1 = 0.662 +- 0.216 (in-sample avg dev_std = 0.404)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.345
Model XAI F1 of binarized graphs for r=0.9 =  0.11011500000000002
Model XAI WIoU of binarized graphs for r=0.9 =  0.05883375000000001
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.365
SUFF++ for r=0.9 class 0 = 0.803 +- 0.115 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 class 1 = 0.782 +- 0.115 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 class 2 = 0.797 +- 0.115 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 all KL = 0.902 +- 0.115 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 all L1 = 0.794 +- 0.147 (in-sample avg dev_std = 0.266)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.366
Model XAI F1 of binarized graphs for r=0.3 =  0.46359625
Model XAI WIoU of binarized graphs for r=0.3 =  0.34830124999999995
len(reference) = 800
Effective ratio: 0.314 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.333
NEC for r=0.3 class 0 = 0.376 +- 0.263 (in-sample avg dev_std = 0.351)
NEC for r=0.3 class 1 = 0.342 +- 0.263 (in-sample avg dev_std = 0.351)
NEC for r=0.3 class 2 = 0.346 +- 0.263 (in-sample avg dev_std = 0.351)
NEC for r=0.3 all KL = 0.275 +- 0.263 (in-sample avg dev_std = 0.351)
NEC for r=0.3 all L1 = 0.354 +- 0.212 (in-sample avg dev_std = 0.351)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.423
Model XAI F1 of binarized graphs for r=0.6 =  0.51403875
Model XAI WIoU of binarized graphs for r=0.6 =  0.37938249999999996
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.359
NEC for r=0.6 class 0 = 0.354 +- 0.262 (in-sample avg dev_std = 0.363)
NEC for r=0.6 class 1 = 0.357 +- 0.262 (in-sample avg dev_std = 0.363)
NEC for r=0.6 class 2 = 0.372 +- 0.262 (in-sample avg dev_std = 0.363)
NEC for r=0.6 all KL = 0.291 +- 0.262 (in-sample avg dev_std = 0.363)
NEC for r=0.6 all L1 = 0.361 +- 0.196 (in-sample avg dev_std = 0.363)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.562
Model XAI F1 of binarized graphs for r=0.9 =  0.5130899999999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.37777249999999996
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.411
NEC for r=0.9 class 0 = 0.534 +- 0.259 (in-sample avg dev_std = 0.482)
NEC for r=0.9 class 1 = 0.497 +- 0.259 (in-sample avg dev_std = 0.482)
NEC for r=0.9 class 2 = 0.591 +- 0.259 (in-sample avg dev_std = 0.482)
NEC for r=0.9 all KL = 0.515 +- 0.259 (in-sample avg dev_std = 0.482)
NEC for r=0.9 all L1 = 0.541 +- 0.171 (in-sample avg dev_std = 0.482)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.879
Model XAI F1 of binarized graphs for r=1.0 =  0.50582625
Model XAI WIoU of binarized graphs for r=1.0 =  0.37288250000000006
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.461
NEC for r=1.0 class 0 = 0.502 +- 0.269 (in-sample avg dev_std = 0.597)
NEC for r=1.0 class 1 = 0.581 +- 0.269 (in-sample avg dev_std = 0.597)
NEC for r=1.0 class 2 = 0.618 +- 0.269 (in-sample avg dev_std = 0.597)
NEC for r=1.0 all KL = 0.629 +- 0.269 (in-sample avg dev_std = 0.597)
NEC for r=1.0 all L1 = 0.568 +- 0.169 (in-sample avg dev_std = 0.597)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.349
Model XAI F1 of binarized graphs for r=0.3 =  0.43332375
Model XAI WIoU of binarized graphs for r=0.3 =  0.3180525
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.323
NEC for r=0.3 class 0 = 0.363 +- 0.254 (in-sample avg dev_std = 0.332)
NEC for r=0.3 class 1 = 0.328 +- 0.254 (in-sample avg dev_std = 0.332)
NEC for r=0.3 class 2 = 0.34 +- 0.254 (in-sample avg dev_std = 0.332)
NEC for r=0.3 all KL = 0.255 +- 0.254 (in-sample avg dev_std = 0.332)
NEC for r=0.3 all L1 = 0.344 +- 0.209 (in-sample avg dev_std = 0.332)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.425
Model XAI F1 of binarized graphs for r=0.6 =  0.49894625000000004
Model XAI WIoU of binarized graphs for r=0.6 =  0.36302500000000004
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.374
NEC for r=0.6 class 0 = 0.341 +- 0.249 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 1 = 0.363 +- 0.249 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 2 = 0.386 +- 0.249 (in-sample avg dev_std = 0.354)
NEC for r=0.6 all KL = 0.279 +- 0.249 (in-sample avg dev_std = 0.354)
NEC for r=0.6 all L1 = 0.364 +- 0.193 (in-sample avg dev_std = 0.354)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.594
Model XAI F1 of binarized graphs for r=0.9 =  0.49832499999999996
Model XAI WIoU of binarized graphs for r=0.9 =  0.36123000000000005
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.424
NEC for r=0.9 class 0 = 0.511 +- 0.272 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 1 = 0.502 +- 0.272 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 2 = 0.583 +- 0.272 (in-sample avg dev_std = 0.463)
NEC for r=0.9 all KL = 0.498 +- 0.272 (in-sample avg dev_std = 0.463)
NEC for r=0.9 all L1 = 0.532 +- 0.181 (in-sample avg dev_std = 0.463)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.902
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.35718000000000005
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.486
NEC for r=1.0 class 0 = 0.486 +- 0.278 (in-sample avg dev_std = 0.596)
NEC for r=1.0 class 1 = 0.585 +- 0.278 (in-sample avg dev_std = 0.596)
NEC for r=1.0 class 2 = 0.606 +- 0.278 (in-sample avg dev_std = 0.596)
NEC for r=1.0 all KL = 0.618 +- 0.278 (in-sample avg dev_std = 0.596)
NEC for r=1.0 all L1 = 0.558 +- 0.175 (in-sample avg dev_std = 0.596)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.382
Model XAI F1 of binarized graphs for r=0.3 =  0.35947874999999996
Model XAI WIoU of binarized graphs for r=0.3 =  0.27911749999999996
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.334
NEC for r=0.3 class 0 = 0.22 +- 0.210 (in-sample avg dev_std = 0.191)
NEC for r=0.3 class 1 = 0.246 +- 0.210 (in-sample avg dev_std = 0.191)
NEC for r=0.3 class 2 = 0.3 +- 0.210 (in-sample avg dev_std = 0.191)
NEC for r=0.3 all KL = 0.152 +- 0.210 (in-sample avg dev_std = 0.191)
NEC for r=0.3 all L1 = 0.254 +- 0.197 (in-sample avg dev_std = 0.191)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.377
Model XAI F1 of binarized graphs for r=0.6 =  0.28167375
Model XAI WIoU of binarized graphs for r=0.6 =  0.206395
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.331
NEC for r=0.6 class 0 = 0.306 +- 0.189 (in-sample avg dev_std = 0.275)
NEC for r=0.6 class 1 = 0.305 +- 0.189 (in-sample avg dev_std = 0.275)
NEC for r=0.6 class 2 = 0.357 +- 0.189 (in-sample avg dev_std = 0.275)
NEC for r=0.6 all KL = 0.206 +- 0.189 (in-sample avg dev_std = 0.275)
NEC for r=0.6 all L1 = 0.322 +- 0.165 (in-sample avg dev_std = 0.275)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.656
Model XAI F1 of binarized graphs for r=0.9 =  0.2460825
Model XAI WIoU of binarized graphs for r=0.9 =  0.17782875
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.443
NEC for r=0.9 class 0 = 0.408 +- 0.183 (in-sample avg dev_std = 0.330)
NEC for r=0.9 class 1 = 0.432 +- 0.183 (in-sample avg dev_std = 0.330)
NEC for r=0.9 class 2 = 0.478 +- 0.183 (in-sample avg dev_std = 0.330)
NEC for r=0.9 all KL = 0.291 +- 0.183 (in-sample avg dev_std = 0.330)
NEC for r=0.9 all L1 = 0.439 +- 0.150 (in-sample avg dev_std = 0.330)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.869
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.17094875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.488
NEC for r=1.0 class 0 = 0.406 +- 0.205 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 1 = 0.464 +- 0.205 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 2 = 0.512 +- 0.205 (in-sample avg dev_std = 0.354)
NEC for r=1.0 all KL = 0.321 +- 0.205 (in-sample avg dev_std = 0.354)
NEC for r=1.0 all L1 = 0.46 +- 0.147 (in-sample avg dev_std = 0.354)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.322
Model XAI F1 of binarized graphs for r=0.3 =  0.11364625
Model XAI WIoU of binarized graphs for r=0.3 =  0.0626675
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.33
NEC for r=0.3 class 0 = 0.276 +- 0.298 (in-sample avg dev_std = 0.194)
NEC for r=0.3 class 1 = 0.273 +- 0.298 (in-sample avg dev_std = 0.194)
NEC for r=0.3 class 2 = 0.276 +- 0.298 (in-sample avg dev_std = 0.194)
NEC for r=0.3 all KL = 0.201 +- 0.298 (in-sample avg dev_std = 0.194)
NEC for r=0.3 all L1 = 0.275 +- 0.234 (in-sample avg dev_std = 0.194)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.34
Model XAI F1 of binarized graphs for r=0.6 =  0.11329875000000002
Model XAI WIoU of binarized graphs for r=0.6 =  0.06106625
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.334
NEC for r=0.6 class 0 = 0.222 +- 0.246 (in-sample avg dev_std = 0.175)
NEC for r=0.6 class 1 = 0.214 +- 0.246 (in-sample avg dev_std = 0.175)
NEC for r=0.6 class 2 = 0.227 +- 0.246 (in-sample avg dev_std = 0.175)
NEC for r=0.6 all KL = 0.164 +- 0.246 (in-sample avg dev_std = 0.175)
NEC for r=0.6 all L1 = 0.221 +- 0.136 (in-sample avg dev_std = 0.175)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.345
Model XAI F1 of binarized graphs for r=0.9 =  0.11011500000000002
Model XAI WIoU of binarized graphs for r=0.9 =  0.05883375000000001
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.365
NEC for r=0.9 class 0 = 0.262 +- 0.177 (in-sample avg dev_std = 0.161)
NEC for r=0.9 class 1 = 0.301 +- 0.177 (in-sample avg dev_std = 0.161)
NEC for r=0.9 class 2 = 0.274 +- 0.177 (in-sample avg dev_std = 0.161)
NEC for r=0.9 all KL = 0.142 +- 0.177 (in-sample avg dev_std = 0.161)
NEC for r=0.9 all L1 = 0.279 +- 0.203 (in-sample avg dev_std = 0.161)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.527
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.06045875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.391
NEC for r=1.0 class 0 = 0.299 +- 0.166 (in-sample avg dev_std = 0.176)
NEC for r=1.0 class 1 = 0.281 +- 0.166 (in-sample avg dev_std = 0.176)
NEC for r=1.0 class 2 = 0.309 +- 0.166 (in-sample avg dev_std = 0.176)
NEC for r=1.0 all KL = 0.145 +- 0.166 (in-sample avg dev_std = 0.176)
NEC for r=1.0 all L1 = 0.296 +- 0.203 (in-sample avg dev_std = 0.176)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Thu May  2 22:52:35 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/02/2024 10:52:35 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/02/2024 10:52:48 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/02/2024 10:52:50 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/02/2024 10:52:52 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/02/2024 10:52:55 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 10:53:02 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 192...
[0m[1;37mINFO[0m: [1mCheckpoint 192: 
-----------------------------------
Train ACCURACY: 0.9280
Train Loss: 0.3286
ID Validation ACCURACY: 0.9357
ID Validation Loss: 0.3071
ID Test ACCURACY: 0.9303
ID Test Loss: 0.3316
OOD Validation ACCURACY: 0.8810
OOD Validation Loss: 0.5653
OOD Test ACCURACY: 0.5063
OOD Test Loss: 5.4499

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 137...
[0m[1;37mINFO[0m: [1mCheckpoint 137: 
-----------------------------------
Train ACCURACY: 0.9272
Train Loss: 0.3319
ID Validation ACCURACY: 0.9323
ID Validation Loss: 0.3139
ID Test ACCURACY: 0.9303
ID Test Loss: 0.3326
OOD Validation ACCURACY: 0.9110
OOD Validation Loss: 0.5104
OOD Test ACCURACY: 0.7090
OOD Test Loss: 2.8718

[0m[1;37mINFO[0m: [1mChartInfo 0.9303 0.5063 0.9303 0.7090 0.9323 0.9110[0mGOODMotif(18000)
Data example from train: Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
Label distribution from train: (tensor([0, 1, 2]), tensor([5912, 6084, 6004]))

Gold ratio (train) =  tensor(0.3628) +- tensor(0.1901)
F1 for r=0.3 = 0.499
WIoU for r=0.3 = 0.382
F1 for r=0.6 = 0.562
WIoU for r=0.6 = 0.455
F1 for r=0.9 = 0.517
WIoU for r=0.9 = 0.430
F1 for r=1.0 = 0.506
WIoU for r=1.0 = 0.424
GOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.482
WIoU for r=0.3 = 0.364
F1 for r=0.6 = 0.547
WIoU for r=0.6 = 0.438
F1 for r=0.9 = 0.505
WIoU for r=0.9 = 0.414
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.407
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.373
WIoU for r=0.3 = 0.286
F1 for r=0.6 = 0.300
WIoU for r=0.6 = 0.226
F1 for r=0.9 = 0.244
WIoU for r=0.9 = 0.190
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.185
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.141
WIoU for r=0.3 = 0.081
F1 for r=0.6 = 0.114
WIoU for r=0.6 = 0.069
F1 for r=0.9 = 0.107
WIoU for r=0.9 = 0.069
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.072


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.355
Model XAI F1 of binarized graphs for r=0.3 =  0.49854374999999995
Model XAI WIoU of binarized graphs for r=0.3 =  0.381655
len(reference) = 768
Effective ratio: 0.314 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.341
SUFF++ for r=0.3 class 0 = 0.659 +- 0.243 (in-sample avg dev_std = 0.357)
SUFF++ for r=0.3 class 1 = 0.675 +- 0.243 (in-sample avg dev_std = 0.357)
SUFF++ for r=0.3 class 2 = 0.671 +- 0.243 (in-sample avg dev_std = 0.357)
SUFF++ for r=0.3 all KL = 0.783 +- 0.243 (in-sample avg dev_std = 0.357)
SUFF++ for r=0.3 all L1 = 0.668 +- 0.138 (in-sample avg dev_std = 0.357)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.559
Model XAI F1 of binarized graphs for r=0.6 =  0.56234375
Model XAI WIoU of binarized graphs for r=0.6 =  0.45470625
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.51
SUFF++ for r=0.6 class 0 = 0.629 +- 0.292 (in-sample avg dev_std = 0.465)
SUFF++ for r=0.6 class 1 = 0.662 +- 0.292 (in-sample avg dev_std = 0.465)
SUFF++ for r=0.6 class 2 = 0.628 +- 0.292 (in-sample avg dev_std = 0.465)
SUFF++ for r=0.6 all KL = 0.645 +- 0.292 (in-sample avg dev_std = 0.465)
SUFF++ for r=0.6 all L1 = 0.64 +- 0.176 (in-sample avg dev_std = 0.465)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.767
Model XAI F1 of binarized graphs for r=0.9 =  0.51728625
Model XAI WIoU of binarized graphs for r=0.9 =  0.43008375
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.727
SUFF++ for r=0.9 class 0 = 0.726 +- 0.282 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.9 class 1 = 0.755 +- 0.282 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.9 class 2 = 0.788 +- 0.282 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.9 all KL = 0.777 +- 0.282 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.9 all L1 = 0.756 +- 0.230 (in-sample avg dev_std = 0.375)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.37
Model XAI F1 of binarized graphs for r=0.3 =  0.4822775
Model XAI WIoU of binarized graphs for r=0.3 =  0.36431
len(reference) = 767
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.354
SUFF++ for r=0.3 class 0 = 0.676 +- 0.250 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.3 class 1 = 0.691 +- 0.250 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.3 class 2 = 0.657 +- 0.250 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.3 all KL = 0.792 +- 0.250 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.3 all L1 = 0.674 +- 0.148 (in-sample avg dev_std = 0.355)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.584
Model XAI F1 of binarized graphs for r=0.6 =  0.5473875
Model XAI WIoU of binarized graphs for r=0.6 =  0.43784375
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.519
SUFF++ for r=0.6 class 0 = 0.631 +- 0.282 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.6 class 1 = 0.67 +- 0.282 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.6 class 2 = 0.639 +- 0.282 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.6 all KL = 0.66 +- 0.282 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.6 all L1 = 0.646 +- 0.169 (in-sample avg dev_std = 0.466)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.769
Model XAI F1 of binarized graphs for r=0.9 =  0.5050375
Model XAI WIoU of binarized graphs for r=0.9 =  0.41352375
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.74
SUFF++ for r=0.9 class 0 = 0.681 +- 0.292 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.9 class 1 = 0.754 +- 0.292 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.9 class 2 = 0.769 +- 0.292 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.9 all KL = 0.749 +- 0.292 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.9 all L1 = 0.734 +- 0.229 (in-sample avg dev_std = 0.399)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.54
Model XAI F1 of binarized graphs for r=0.3 =  0.37314625
Model XAI WIoU of binarized graphs for r=0.3 =  0.28609124999999996
len(reference) = 798
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.506
SUFF++ for r=0.3 class 0 = 0.664 +- 0.208 (in-sample avg dev_std = 0.368)
SUFF++ for r=0.3 class 1 = 0.704 +- 0.208 (in-sample avg dev_std = 0.368)
SUFF++ for r=0.3 class 2 = 0.699 +- 0.208 (in-sample avg dev_std = 0.368)
SUFF++ for r=0.3 all KL = 0.778 +- 0.208 (in-sample avg dev_std = 0.368)
SUFF++ for r=0.3 all L1 = 0.689 +- 0.154 (in-sample avg dev_std = 0.368)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.594
Model XAI F1 of binarized graphs for r=0.6 =  0.300275
Model XAI WIoU of binarized graphs for r=0.6 =  0.22564125000000002
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.587
SUFF++ for r=0.6 class 0 = 0.608 +- 0.273 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.6 class 1 = 0.704 +- 0.273 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.6 class 2 = 0.653 +- 0.273 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.6 all KL = 0.709 +- 0.273 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.6 all L1 = 0.655 +- 0.171 (in-sample avg dev_std = 0.397)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.726
Model XAI F1 of binarized graphs for r=0.9 =  0.24424000000000004
Model XAI WIoU of binarized graphs for r=0.9 =  0.18957875000000002
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.685
SUFF++ for r=0.9 class 0 = 0.716 +- 0.209 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.9 class 1 = 0.767 +- 0.209 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.9 class 2 = 0.722 +- 0.209 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.9 all KL = 0.809 +- 0.209 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.9 all L1 = 0.735 +- 0.191 (in-sample avg dev_std = 0.326)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.391
Model XAI F1 of binarized graphs for r=0.3 =  0.14098625
Model XAI WIoU of binarized graphs for r=0.3 =  0.08103125
len(reference) = 786
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.382
SUFF++ for r=0.3 class 0 = 0.713 +- 0.138 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.3 class 1 = 0.718 +- 0.138 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.3 class 2 = 0.7 +- 0.138 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.3 all KL = 0.844 +- 0.138 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.3 all L1 = 0.711 +- 0.123 (in-sample avg dev_std = 0.355)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.452
Model XAI F1 of binarized graphs for r=0.6 =  0.11411999999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.06896625
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.419
SUFF++ for r=0.6 class 0 = 0.633 +- 0.221 (in-sample avg dev_std = 0.413)
SUFF++ for r=0.6 class 1 = 0.654 +- 0.221 (in-sample avg dev_std = 0.413)
SUFF++ for r=0.6 class 2 = 0.638 +- 0.221 (in-sample avg dev_std = 0.413)
SUFF++ for r=0.6 all KL = 0.743 +- 0.221 (in-sample avg dev_std = 0.413)
SUFF++ for r=0.6 all L1 = 0.642 +- 0.141 (in-sample avg dev_std = 0.413)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.414
Model XAI F1 of binarized graphs for r=0.9 =  0.10745250000000002
Model XAI WIoU of binarized graphs for r=0.9 =  0.06891375
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.389
SUFF++ for r=0.9 class 0 = 0.802 +- 0.143 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 class 1 = 0.818 +- 0.143 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 class 2 = 0.789 +- 0.143 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 all KL = 0.887 +- 0.143 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 all L1 = 0.804 +- 0.159 (in-sample avg dev_std = 0.296)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.357
Model XAI F1 of binarized graphs for r=0.3 =  0.49854374999999995
Model XAI WIoU of binarized graphs for r=0.3 =  0.381655
len(reference) = 800
Effective ratio: 0.314 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.313
NEC for r=0.3 class 0 = 0.376 +- 0.285 (in-sample avg dev_std = 0.294)
NEC for r=0.3 class 1 = 0.356 +- 0.285 (in-sample avg dev_std = 0.294)
NEC for r=0.3 class 2 = 0.35 +- 0.285 (in-sample avg dev_std = 0.294)
NEC for r=0.3 all KL = 0.245 +- 0.285 (in-sample avg dev_std = 0.294)
NEC for r=0.3 all L1 = 0.36 +- 0.197 (in-sample avg dev_std = 0.294)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.56
Model XAI F1 of binarized graphs for r=0.6 =  0.56234375
Model XAI WIoU of binarized graphs for r=0.6 =  0.45470625
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.37
NEC for r=0.6 class 0 = 0.497 +- 0.327 (in-sample avg dev_std = 0.497)
NEC for r=0.6 class 1 = 0.507 +- 0.327 (in-sample avg dev_std = 0.497)
NEC for r=0.6 class 2 = 0.583 +- 0.327 (in-sample avg dev_std = 0.497)
NEC for r=0.6 all KL = 0.549 +- 0.327 (in-sample avg dev_std = 0.497)
NEC for r=0.6 all L1 = 0.529 +- 0.181 (in-sample avg dev_std = 0.497)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.767
Model XAI F1 of binarized graphs for r=0.9 =  0.51728625
Model XAI WIoU of binarized graphs for r=0.9 =  0.43008375
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.467
NEC for r=0.9 class 0 = 0.516 +- 0.259 (in-sample avg dev_std = 0.556)
NEC for r=0.9 class 1 = 0.545 +- 0.259 (in-sample avg dev_std = 0.556)
NEC for r=0.9 class 2 = 0.629 +- 0.259 (in-sample avg dev_std = 0.556)
NEC for r=0.9 all KL = 0.606 +- 0.259 (in-sample avg dev_std = 0.556)
NEC for r=0.9 all L1 = 0.564 +- 0.160 (in-sample avg dev_std = 0.556)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.911
Model XAI F1 of binarized graphs for r=1.0 =  0.50582625
Model XAI WIoU of binarized graphs for r=1.0 =  0.42427750000000003
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.475
NEC for r=1.0 class 0 = 0.523 +- 0.229 (in-sample avg dev_std = 0.620)
NEC for r=1.0 class 1 = 0.555 +- 0.229 (in-sample avg dev_std = 0.620)
NEC for r=1.0 class 2 = 0.629 +- 0.229 (in-sample avg dev_std = 0.620)
NEC for r=1.0 all KL = 0.655 +- 0.229 (in-sample avg dev_std = 0.620)
NEC for r=1.0 all L1 = 0.569 +- 0.161 (in-sample avg dev_std = 0.620)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.369
Model XAI F1 of binarized graphs for r=0.3 =  0.4822775
Model XAI WIoU of binarized graphs for r=0.3 =  0.36431
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.311
NEC for r=0.3 class 0 = 0.336 +- 0.282 (in-sample avg dev_std = 0.298)
NEC for r=0.3 class 1 = 0.342 +- 0.282 (in-sample avg dev_std = 0.298)
NEC for r=0.3 class 2 = 0.342 +- 0.282 (in-sample avg dev_std = 0.298)
NEC for r=0.3 all KL = 0.227 +- 0.282 (in-sample avg dev_std = 0.298)
NEC for r=0.3 all L1 = 0.34 +- 0.195 (in-sample avg dev_std = 0.298)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.584
Model XAI F1 of binarized graphs for r=0.6 =  0.5473875
Model XAI WIoU of binarized graphs for r=0.6 =  0.43784375
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.381
NEC for r=0.6 class 0 = 0.483 +- 0.330 (in-sample avg dev_std = 0.487)
NEC for r=0.6 class 1 = 0.501 +- 0.330 (in-sample avg dev_std = 0.487)
NEC for r=0.6 class 2 = 0.589 +- 0.330 (in-sample avg dev_std = 0.487)
NEC for r=0.6 all KL = 0.534 +- 0.330 (in-sample avg dev_std = 0.487)
NEC for r=0.6 all L1 = 0.525 +- 0.186 (in-sample avg dev_std = 0.487)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.769
Model XAI F1 of binarized graphs for r=0.9 =  0.5050375
Model XAI WIoU of binarized graphs for r=0.9 =  0.41352375
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.485
NEC for r=0.9 class 0 = 0.504 +- 0.262 (in-sample avg dev_std = 0.570)
NEC for r=0.9 class 1 = 0.543 +- 0.262 (in-sample avg dev_std = 0.570)
NEC for r=0.9 class 2 = 0.626 +- 0.262 (in-sample avg dev_std = 0.570)
NEC for r=0.9 all KL = 0.6 +- 0.262 (in-sample avg dev_std = 0.570)
NEC for r=0.9 all L1 = 0.558 +- 0.157 (in-sample avg dev_std = 0.570)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.934
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.4071775
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.498
NEC for r=1.0 class 0 = 0.502 +- 0.239 (in-sample avg dev_std = 0.615)
NEC for r=1.0 class 1 = 0.553 +- 0.239 (in-sample avg dev_std = 0.615)
NEC for r=1.0 class 2 = 0.622 +- 0.239 (in-sample avg dev_std = 0.615)
NEC for r=1.0 all KL = 0.637 +- 0.239 (in-sample avg dev_std = 0.615)
NEC for r=1.0 all L1 = 0.559 +- 0.166 (in-sample avg dev_std = 0.615)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.54
Model XAI F1 of binarized graphs for r=0.3 =  0.37314625
Model XAI WIoU of binarized graphs for r=0.3 =  0.28609124999999996
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.364
NEC for r=0.3 class 0 = 0.415 +- 0.349 (in-sample avg dev_std = 0.291)
NEC for r=0.3 class 1 = 0.422 +- 0.349 (in-sample avg dev_std = 0.291)
NEC for r=0.3 class 2 = 0.45 +- 0.349 (in-sample avg dev_std = 0.291)
NEC for r=0.3 all KL = 0.369 +- 0.349 (in-sample avg dev_std = 0.291)
NEC for r=0.3 all L1 = 0.428 +- 0.238 (in-sample avg dev_std = 0.291)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.594
Model XAI F1 of binarized graphs for r=0.6 =  0.300275
Model XAI WIoU of binarized graphs for r=0.6 =  0.22564125000000002
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.399
NEC for r=0.6 class 0 = 0.462 +- 0.307 (in-sample avg dev_std = 0.402)
NEC for r=0.6 class 1 = 0.481 +- 0.307 (in-sample avg dev_std = 0.402)
NEC for r=0.6 class 2 = 0.546 +- 0.307 (in-sample avg dev_std = 0.402)
NEC for r=0.6 all KL = 0.462 +- 0.307 (in-sample avg dev_std = 0.402)
NEC for r=0.6 all L1 = 0.495 +- 0.172 (in-sample avg dev_std = 0.402)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.726
Model XAI F1 of binarized graphs for r=0.9 =  0.24424000000000004
Model XAI WIoU of binarized graphs for r=0.9 =  0.18957875000000002
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.49
NEC for r=0.9 class 0 = 0.455 +- 0.187 (in-sample avg dev_std = 0.408)
NEC for r=0.9 class 1 = 0.465 +- 0.187 (in-sample avg dev_std = 0.408)
NEC for r=0.9 class 2 = 0.499 +- 0.187 (in-sample avg dev_std = 0.408)
NEC for r=0.9 all KL = 0.377 +- 0.187 (in-sample avg dev_std = 0.408)
NEC for r=0.9 all L1 = 0.473 +- 0.135 (in-sample avg dev_std = 0.408)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.896
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.18454250000000003
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.52
NEC for r=1.0 class 0 = 0.484 +- 0.205 (in-sample avg dev_std = 0.407)
NEC for r=1.0 class 1 = 0.479 +- 0.205 (in-sample avg dev_std = 0.407)
NEC for r=1.0 class 2 = 0.529 +- 0.205 (in-sample avg dev_std = 0.407)
NEC for r=1.0 all KL = 0.417 +- 0.205 (in-sample avg dev_std = 0.407)
NEC for r=1.0 all L1 = 0.497 +- 0.126 (in-sample avg dev_std = 0.407)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.39
Model XAI F1 of binarized graphs for r=0.3 =  0.14098625
Model XAI WIoU of binarized graphs for r=0.3 =  0.08103125
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.349
NEC for r=0.3 class 0 = 0.209 +- 0.183 (in-sample avg dev_std = 0.135)
NEC for r=0.3 class 1 = 0.237 +- 0.183 (in-sample avg dev_std = 0.135)
NEC for r=0.3 class 2 = 0.246 +- 0.183 (in-sample avg dev_std = 0.135)
NEC for r=0.3 all KL = 0.107 +- 0.183 (in-sample avg dev_std = 0.135)
NEC for r=0.3 all L1 = 0.23 +- 0.184 (in-sample avg dev_std = 0.135)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.452
Model XAI F1 of binarized graphs for r=0.6 =  0.11411999999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.06896625
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.373
NEC for r=0.6 class 0 = 0.278 +- 0.145 (in-sample avg dev_std = 0.180)
NEC for r=0.6 class 1 = 0.275 +- 0.145 (in-sample avg dev_std = 0.180)
NEC for r=0.6 class 2 = 0.307 +- 0.145 (in-sample avg dev_std = 0.180)
NEC for r=0.6 all KL = 0.138 +- 0.145 (in-sample avg dev_std = 0.180)
NEC for r=0.6 all L1 = 0.286 +- 0.152 (in-sample avg dev_std = 0.180)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.414
Model XAI F1 of binarized graphs for r=0.9 =  0.10745250000000002
Model XAI WIoU of binarized graphs for r=0.9 =  0.06891375
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.361
NEC for r=0.9 class 0 = 0.213 +- 0.087 (in-sample avg dev_std = 0.178)
NEC for r=0.9 class 1 = 0.217 +- 0.087 (in-sample avg dev_std = 0.178)
NEC for r=0.9 class 2 = 0.247 +- 0.087 (in-sample avg dev_std = 0.178)
NEC for r=0.9 all KL = 0.096 +- 0.087 (in-sample avg dev_std = 0.178)
NEC for r=0.9 all L1 = 0.225 +- 0.141 (in-sample avg dev_std = 0.178)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.507
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.0716025
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.386
NEC for r=1.0 class 0 = 0.272 +- 0.102 (in-sample avg dev_std = 0.173)
NEC for r=1.0 class 1 = 0.27 +- 0.102 (in-sample avg dev_std = 0.173)
NEC for r=1.0 class 2 = 0.269 +- 0.102 (in-sample avg dev_std = 0.173)
NEC for r=1.0 all KL = 0.13 +- 0.102 (in-sample avg dev_std = 0.173)
NEC for r=1.0 all L1 = 0.27 +- 0.165 (in-sample avg dev_std = 0.173)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Thu May  2 23:00:15 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:15 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:28 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:29 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:31 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:35 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:00:42 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 116...
[0m[1;37mINFO[0m: [1mCheckpoint 116: 
-----------------------------------
Train ACCURACY: 0.9012
Train Loss: 0.4345
ID Validation ACCURACY: 0.9077
ID Validation Loss: 0.4159
ID Test ACCURACY: 0.9057
ID Test Loss: 0.4261
OOD Validation ACCURACY: 0.8647
OOD Validation Loss: 0.5410
OOD Test ACCURACY: 0.5473
OOD Test Loss: 1.2609

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 162...
[0m[1;37mINFO[0m: [1mCheckpoint 162: 
-----------------------------------
Train ACCURACY: 0.8549
Train Loss: 0.7043
ID Validation ACCURACY: 0.8660
ID Validation Loss: 0.6725
ID Test ACCURACY: 0.8597
ID Test Loss: 0.6986
OOD Validation ACCURACY: 0.8793
OOD Validation Loss: 0.5436
OOD Test ACCURACY: 0.5663
OOD Test Loss: 1.9432

[0m[1;37mINFO[0m: [1mChartInfo 0.9057 0.5473 0.8597 0.5663 0.8660 0.8793[0mGOODMotif(18000)
Data example from train: Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
Label distribution from train: (tensor([0, 1, 2]), tensor([5912, 6084, 6004]))

Gold ratio (train) =  tensor(0.3628) +- tensor(0.1901)
F1 for r=0.3 = 0.555
WIoU for r=0.3 = 0.434
F1 for r=0.6 = 0.587
WIoU for r=0.6 = 0.476
F1 for r=0.9 = 0.527
WIoU for r=0.9 = 0.463
F1 for r=1.0 = 0.506
WIoU for r=1.0 = 0.458
GOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.537
WIoU for r=0.3 = 0.416
F1 for r=0.6 = 0.574
WIoU for r=0.6 = 0.460
F1 for r=0.9 = 0.513
WIoU for r=0.9 = 0.445
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.440
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.397
WIoU for r=0.3 = 0.310
F1 for r=0.6 = 0.307
WIoU for r=0.6 = 0.229
F1 for r=0.9 = 0.250
WIoU for r=0.9 = 0.190
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.184
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.224
WIoU for r=0.3 = 0.185
F1 for r=0.6 = 0.156
WIoU for r=0.6 = 0.123
F1 for r=0.9 = 0.120
WIoU for r=0.9 = 0.096
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.093


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.371
Model XAI F1 of binarized graphs for r=0.3 =  0.5546425
Model XAI WIoU of binarized graphs for r=0.3 =  0.43350625
len(reference) = 760
Effective ratio: 0.314 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.346
SUFF++ for r=0.3 class 0 = 0.653 +- 0.311 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.3 class 1 = 0.656 +- 0.311 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.3 class 2 = 0.663 +- 0.311 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.3 all KL = 0.699 +- 0.311 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.3 all L1 = 0.658 +- 0.149 (in-sample avg dev_std = 0.390)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.543
Model XAI F1 of binarized graphs for r=0.6 =  0.58734375
Model XAI WIoU of binarized graphs for r=0.6 =  0.47569125
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.494
SUFF++ for r=0.6 class 0 = 0.63 +- 0.321 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.6 class 1 = 0.701 +- 0.321 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.6 class 2 = 0.621 +- 0.321 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.6 all KL = 0.586 +- 0.321 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.6 all L1 = 0.651 +- 0.195 (in-sample avg dev_std = 0.508)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.766
Model XAI F1 of binarized graphs for r=0.9 =  0.5268275
Model XAI WIoU of binarized graphs for r=0.9 =  0.46331500000000003
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.729
SUFF++ for r=0.9 class 0 = 0.771 +- 0.295 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.9 class 1 = 0.786 +- 0.295 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.9 class 2 = 0.772 +- 0.295 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.9 all KL = 0.774 +- 0.295 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.9 all L1 = 0.776 +- 0.228 (in-sample avg dev_std = 0.366)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.362
Model XAI F1 of binarized graphs for r=0.3 =  0.5373125000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.41579875
len(reference) = 766
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.332
SUFF++ for r=0.3 class 0 = 0.672 +- 0.320 (in-sample avg dev_std = 0.377)
SUFF++ for r=0.3 class 1 = 0.682 +- 0.320 (in-sample avg dev_std = 0.377)
SUFF++ for r=0.3 class 2 = 0.643 +- 0.320 (in-sample avg dev_std = 0.377)
SUFF++ for r=0.3 all KL = 0.704 +- 0.320 (in-sample avg dev_std = 0.377)
SUFF++ for r=0.3 all L1 = 0.666 +- 0.151 (in-sample avg dev_std = 0.377)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.544
Model XAI F1 of binarized graphs for r=0.6 =  0.5735675
Model XAI WIoU of binarized graphs for r=0.6 =  0.46005875
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.493
SUFF++ for r=0.6 class 0 = 0.636 +- 0.328 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.6 class 1 = 0.696 +- 0.328 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.6 class 2 = 0.603 +- 0.328 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.6 all KL = 0.574 +- 0.328 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.6 all L1 = 0.644 +- 0.199 (in-sample avg dev_std = 0.504)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.736
Model XAI F1 of binarized graphs for r=0.9 =  0.5126762500000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.44478625
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.729
SUFF++ for r=0.9 class 0 = 0.738 +- 0.308 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.9 class 1 = 0.77 +- 0.308 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.9 class 2 = 0.75 +- 0.308 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.9 all KL = 0.751 +- 0.308 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.9 all L1 = 0.753 +- 0.236 (in-sample avg dev_std = 0.378)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.484
Model XAI F1 of binarized graphs for r=0.3 =  0.39697249999999995
Model XAI WIoU of binarized graphs for r=0.3 =  0.3096125
len(reference) = 796
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.462
SUFF++ for r=0.3 class 0 = 0.694 +- 0.232 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.3 class 1 = 0.725 +- 0.232 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.3 class 2 = 0.706 +- 0.232 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.3 all KL = 0.75 +- 0.232 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.3 all L1 = 0.708 +- 0.129 (in-sample avg dev_std = 0.383)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.581
Model XAI F1 of binarized graphs for r=0.6 =  0.306695
Model XAI WIoU of binarized graphs for r=0.6 =  0.22853375
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.548
SUFF++ for r=0.6 class 0 = 0.706 +- 0.313 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.6 class 1 = 0.721 +- 0.313 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.6 class 2 = 0.655 +- 0.313 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.6 all KL = 0.663 +- 0.313 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.6 all L1 = 0.695 +- 0.148 (in-sample avg dev_std = 0.459)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.746
Model XAI F1 of binarized graphs for r=0.9 =  0.24982750000000004
Model XAI WIoU of binarized graphs for r=0.9 =  0.18991624999999998
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.667
SUFF++ for r=0.9 class 0 = 0.693 +- 0.213 (in-sample avg dev_std = 0.308)
SUFF++ for r=0.9 class 1 = 0.76 +- 0.213 (in-sample avg dev_std = 0.308)
SUFF++ for r=0.9 class 2 = 0.682 +- 0.213 (in-sample avg dev_std = 0.308)
SUFF++ for r=0.9 all KL = 0.799 +- 0.213 (in-sample avg dev_std = 0.308)
SUFF++ for r=0.9 all L1 = 0.712 +- 0.201 (in-sample avg dev_std = 0.308)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.499
Model XAI F1 of binarized graphs for r=0.3 =  0.22388249999999998
Model XAI WIoU of binarized graphs for r=0.3 =  0.1851125
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.459
SUFF++ for r=0.3 class 0 = 0.687 +- 0.169 (in-sample avg dev_std = 0.329)
SUFF++ for r=0.3 class 1 = 0.705 +- 0.169 (in-sample avg dev_std = 0.329)
SUFF++ for r=0.3 class 2 = 0.681 +- 0.169 (in-sample avg dev_std = 0.329)
SUFF++ for r=0.3 all KL = 0.83 +- 0.169 (in-sample avg dev_std = 0.329)
SUFF++ for r=0.3 all L1 = 0.691 +- 0.155 (in-sample avg dev_std = 0.329)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.504
Model XAI F1 of binarized graphs for r=0.6 =  0.15563625
Model XAI WIoU of binarized graphs for r=0.6 =  0.12336625000000001
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.512
SUFF++ for r=0.6 class 0 = 0.622 +- 0.262 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.6 class 1 = 0.63 +- 0.262 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.6 class 2 = 0.606 +- 0.262 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.6 all KL = 0.739 +- 0.262 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.6 all L1 = 0.62 +- 0.200 (in-sample avg dev_std = 0.303)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.471
Model XAI F1 of binarized graphs for r=0.9 =  0.11984000000000002
Model XAI WIoU of binarized graphs for r=0.9 =  0.09644125
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.496
SUFF++ for r=0.9 class 0 = 0.701 +- 0.236 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.9 class 1 = 0.712 +- 0.236 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.9 class 2 = 0.714 +- 0.236 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.9 all KL = 0.803 +- 0.236 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.9 all L1 = 0.709 +- 0.186 (in-sample avg dev_std = 0.295)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.371
Model XAI F1 of binarized graphs for r=0.3 =  0.5546425
Model XAI WIoU of binarized graphs for r=0.3 =  0.43350625
len(reference) = 800
Effective ratio: 0.314 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.271
NEC for r=0.3 class 0 = 0.379 +- 0.340 (in-sample avg dev_std = 0.316)
NEC for r=0.3 class 1 = 0.373 +- 0.340 (in-sample avg dev_std = 0.316)
NEC for r=0.3 class 2 = 0.379 +- 0.340 (in-sample avg dev_std = 0.316)
NEC for r=0.3 all KL = 0.322 +- 0.340 (in-sample avg dev_std = 0.316)
NEC for r=0.3 all L1 = 0.377 +- 0.205 (in-sample avg dev_std = 0.316)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.543
Model XAI F1 of binarized graphs for r=0.6 =  0.58734375
Model XAI WIoU of binarized graphs for r=0.6 =  0.47569125
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.339
NEC for r=0.6 class 0 = 0.499 +- 0.307 (in-sample avg dev_std = 0.510)
NEC for r=0.6 class 1 = 0.49 +- 0.307 (in-sample avg dev_std = 0.510)
NEC for r=0.6 class 2 = 0.537 +- 0.307 (in-sample avg dev_std = 0.510)
NEC for r=0.6 all KL = 0.584 +- 0.307 (in-sample avg dev_std = 0.510)
NEC for r=0.6 all L1 = 0.509 +- 0.200 (in-sample avg dev_std = 0.510)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.766
Model XAI F1 of binarized graphs for r=0.9 =  0.5268275
Model XAI WIoU of binarized graphs for r=0.9 =  0.46331500000000003
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.436
NEC for r=0.9 class 0 = 0.583 +- 0.226 (in-sample avg dev_std = 0.583)
NEC for r=0.9 class 1 = 0.606 +- 0.226 (in-sample avg dev_std = 0.583)
NEC for r=0.9 class 2 = 0.621 +- 0.226 (in-sample avg dev_std = 0.583)
NEC for r=0.9 all KL = 0.672 +- 0.226 (in-sample avg dev_std = 0.583)
NEC for r=0.9 all L1 = 0.603 +- 0.138 (in-sample avg dev_std = 0.583)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.88
Model XAI F1 of binarized graphs for r=1.0 =  0.50582625
Model XAI WIoU of binarized graphs for r=1.0 =  0.45820875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.461
NEC for r=1.0 class 0 = 0.546 +- 0.239 (in-sample avg dev_std = 0.600)
NEC for r=1.0 class 1 = 0.579 +- 0.239 (in-sample avg dev_std = 0.600)
NEC for r=1.0 class 2 = 0.596 +- 0.239 (in-sample avg dev_std = 0.600)
NEC for r=1.0 all KL = 0.649 +- 0.239 (in-sample avg dev_std = 0.600)
NEC for r=1.0 all L1 = 0.574 +- 0.159 (in-sample avg dev_std = 0.600)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.356
Model XAI F1 of binarized graphs for r=0.3 =  0.5373125000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.41579875
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.272
NEC for r=0.3 class 0 = 0.374 +- 0.347 (in-sample avg dev_std = 0.317)
NEC for r=0.3 class 1 = 0.36 +- 0.347 (in-sample avg dev_std = 0.317)
NEC for r=0.3 class 2 = 0.377 +- 0.347 (in-sample avg dev_std = 0.317)
NEC for r=0.3 all KL = 0.322 +- 0.347 (in-sample avg dev_std = 0.317)
NEC for r=0.3 all L1 = 0.37 +- 0.203 (in-sample avg dev_std = 0.317)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.544
Model XAI F1 of binarized graphs for r=0.6 =  0.5735675
Model XAI WIoU of binarized graphs for r=0.6 =  0.46005875
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.332
NEC for r=0.6 class 0 = 0.505 +- 0.309 (in-sample avg dev_std = 0.501)
NEC for r=0.6 class 1 = 0.503 +- 0.309 (in-sample avg dev_std = 0.501)
NEC for r=0.6 class 2 = 0.526 +- 0.309 (in-sample avg dev_std = 0.501)
NEC for r=0.6 all KL = 0.591 +- 0.309 (in-sample avg dev_std = 0.501)
NEC for r=0.6 all L1 = 0.511 +- 0.207 (in-sample avg dev_std = 0.501)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.736
Model XAI F1 of binarized graphs for r=0.9 =  0.5126762500000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.44478625
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.434
NEC for r=0.9 class 0 = 0.59 +- 0.219 (in-sample avg dev_std = 0.578)
NEC for r=0.9 class 1 = 0.597 +- 0.219 (in-sample avg dev_std = 0.578)
NEC for r=0.9 class 2 = 0.625 +- 0.219 (in-sample avg dev_std = 0.578)
NEC for r=0.9 all KL = 0.665 +- 0.219 (in-sample avg dev_std = 0.578)
NEC for r=0.9 all L1 = 0.604 +- 0.131 (in-sample avg dev_std = 0.578)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.908
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.440455
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.48
NEC for r=1.0 class 0 = 0.519 +- 0.252 (in-sample avg dev_std = 0.598)
NEC for r=1.0 class 1 = 0.578 +- 0.252 (in-sample avg dev_std = 0.598)
NEC for r=1.0 class 2 = 0.593 +- 0.252 (in-sample avg dev_std = 0.598)
NEC for r=1.0 all KL = 0.629 +- 0.252 (in-sample avg dev_std = 0.598)
NEC for r=1.0 all L1 = 0.563 +- 0.165 (in-sample avg dev_std = 0.598)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.482
Model XAI F1 of binarized graphs for r=0.3 =  0.39697249999999995
Model XAI WIoU of binarized graphs for r=0.3 =  0.3096125
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.325
NEC for r=0.3 class 0 = 0.401 +- 0.323 (in-sample avg dev_std = 0.288)
NEC for r=0.3 class 1 = 0.41 +- 0.323 (in-sample avg dev_std = 0.288)
NEC for r=0.3 class 2 = 0.426 +- 0.323 (in-sample avg dev_std = 0.288)
NEC for r=0.3 all KL = 0.376 +- 0.323 (in-sample avg dev_std = 0.288)
NEC for r=0.3 all L1 = 0.412 +- 0.217 (in-sample avg dev_std = 0.288)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.581
Model XAI F1 of binarized graphs for r=0.6 =  0.306695
Model XAI WIoU of binarized graphs for r=0.6 =  0.22853375
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.359
NEC for r=0.6 class 0 = 0.363 +- 0.227 (in-sample avg dev_std = 0.368)
NEC for r=0.6 class 1 = 0.388 +- 0.227 (in-sample avg dev_std = 0.368)
NEC for r=0.6 class 2 = 0.417 +- 0.227 (in-sample avg dev_std = 0.368)
NEC for r=0.6 all KL = 0.347 +- 0.227 (in-sample avg dev_std = 0.368)
NEC for r=0.6 all L1 = 0.389 +- 0.217 (in-sample avg dev_std = 0.368)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.746
Model XAI F1 of binarized graphs for r=0.9 =  0.24982750000000004
Model XAI WIoU of binarized graphs for r=0.9 =  0.18991624999999998
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.443
NEC for r=0.9 class 0 = 0.518 +- 0.203 (in-sample avg dev_std = 0.416)
NEC for r=0.9 class 1 = 0.496 +- 0.203 (in-sample avg dev_std = 0.416)
NEC for r=0.9 class 2 = 0.554 +- 0.203 (in-sample avg dev_std = 0.416)
NEC for r=0.9 all KL = 0.431 +- 0.203 (in-sample avg dev_std = 0.416)
NEC for r=0.9 all L1 = 0.522 +- 0.126 (in-sample avg dev_std = 0.416)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.884
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.18372500000000003
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.487
NEC for r=1.0 class 0 = 0.427 +- 0.186 (in-sample avg dev_std = 0.395)
NEC for r=1.0 class 1 = 0.491 +- 0.186 (in-sample avg dev_std = 0.395)
NEC for r=1.0 class 2 = 0.506 +- 0.186 (in-sample avg dev_std = 0.395)
NEC for r=1.0 all KL = 0.343 +- 0.186 (in-sample avg dev_std = 0.395)
NEC for r=1.0 all L1 = 0.474 +- 0.125 (in-sample avg dev_std = 0.395)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.499
Model XAI F1 of binarized graphs for r=0.3 =  0.22388249999999998
Model XAI WIoU of binarized graphs for r=0.3 =  0.1851125
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.354
NEC for r=0.3 class 0 = 0.377 +- 0.272 (in-sample avg dev_std = 0.206)
NEC for r=0.3 class 1 = 0.365 +- 0.272 (in-sample avg dev_std = 0.206)
NEC for r=0.3 class 2 = 0.413 +- 0.272 (in-sample avg dev_std = 0.206)
NEC for r=0.3 all KL = 0.248 +- 0.272 (in-sample avg dev_std = 0.206)
NEC for r=0.3 all L1 = 0.384 +- 0.226 (in-sample avg dev_std = 0.206)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.504
Model XAI F1 of binarized graphs for r=0.6 =  0.15563625
Model XAI WIoU of binarized graphs for r=0.6 =  0.12336625000000001
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.385
NEC for r=0.6 class 0 = 0.425 +- 0.270 (in-sample avg dev_std = 0.232)
NEC for r=0.6 class 1 = 0.4 +- 0.270 (in-sample avg dev_std = 0.232)
NEC for r=0.6 class 2 = 0.459 +- 0.270 (in-sample avg dev_std = 0.232)
NEC for r=0.6 all KL = 0.284 +- 0.270 (in-sample avg dev_std = 0.232)
NEC for r=0.6 all L1 = 0.427 +- 0.204 (in-sample avg dev_std = 0.232)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.471
Model XAI F1 of binarized graphs for r=0.9 =  0.11984000000000002
Model XAI WIoU of binarized graphs for r=0.9 =  0.09644125
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.407
NEC for r=0.9 class 0 = 0.425 +- 0.282 (in-sample avg dev_std = 0.213)
NEC for r=0.9 class 1 = 0.461 +- 0.282 (in-sample avg dev_std = 0.213)
NEC for r=0.9 class 2 = 0.471 +- 0.282 (in-sample avg dev_std = 0.213)
NEC for r=0.9 all KL = 0.322 +- 0.282 (in-sample avg dev_std = 0.213)
NEC for r=0.9 all L1 = 0.452 +- 0.183 (in-sample avg dev_std = 0.213)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.545
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.09285
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.405
NEC for r=1.0 class 0 = 0.371 +- 0.275 (in-sample avg dev_std = 0.176)
NEC for r=1.0 class 1 = 0.399 +- 0.275 (in-sample avg dev_std = 0.176)
NEC for r=1.0 class 2 = 0.405 +- 0.275 (in-sample avg dev_std = 0.176)
NEC for r=1.0 all KL = 0.242 +- 0.275 (in-sample avg dev_std = 0.176)
NEC for r=1.0 all L1 = 0.391 +- 0.197 (in-sample avg dev_std = 0.176)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Thu May  2 23:07:58 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/02/2024 11:07:58 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/02/2024 11:08:10 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/02/2024 11:08:12 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/02/2024 11:08:14 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/02/2024 11:08:18 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:08:25 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 198...
[0m[1;37mINFO[0m: [1mCheckpoint 198: 
-----------------------------------
Train ACCURACY: 0.9261
Train Loss: 0.3424
ID Validation ACCURACY: 0.9340
ID Validation Loss: 0.3215
ID Test ACCURACY: 0.9283
ID Test Loss: 0.3471
OOD Validation ACCURACY: 0.9040
OOD Validation Loss: 0.5054
OOD Test ACCURACY: 0.7073
OOD Test Loss: 0.9018

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 199...
[0m[1;37mINFO[0m: [1mCheckpoint 199: 
-----------------------------------
Train ACCURACY: 0.9257
Train Loss: 0.3409
ID Validation ACCURACY: 0.9330
ID Validation Loss: 0.3203
ID Test ACCURACY: 0.9263
ID Test Loss: 0.3421
OOD Validation ACCURACY: 0.9107
OOD Validation Loss: 0.4829
OOD Test ACCURACY: 0.5813
OOD Test Loss: 1.5702

[0m[1;37mINFO[0m: [1mChartInfo 0.9283 0.7073 0.9263 0.5813 0.9330 0.9107[0mGOODMotif(18000)
Data example from train: Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
Label distribution from train: (tensor([0, 1, 2]), tensor([5912, 6084, 6004]))

Gold ratio (train) =  tensor(0.3628) +- tensor(0.1901)
F1 for r=0.3 = 0.479
WIoU for r=0.3 = 0.360
F1 for r=0.6 = 0.553
WIoU for r=0.6 = 0.464
F1 for r=0.9 = 0.522
WIoU for r=0.9 = 0.480
F1 for r=1.0 = 0.506
WIoU for r=1.0 = 0.478
GOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.452
WIoU for r=0.3 = 0.332
F1 for r=0.6 = 0.524
WIoU for r=0.6 = 0.428
F1 for r=0.9 = 0.503
WIoU for r=0.9 = 0.448
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.450
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.409
WIoU for r=0.3 = 0.396
F1 for r=0.6 = 0.310
WIoU for r=0.6 = 0.402
F1 for r=0.9 = 0.251
WIoU for r=0.9 = 0.405
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.405
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.225
WIoU for r=0.3 = 0.302
F1 for r=0.6 = 0.156
WIoU for r=0.6 = 0.286
F1 for r=0.9 = 0.121
WIoU for r=0.9 = 0.280
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.278


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.371
Model XAI F1 of binarized graphs for r=0.3 =  0.47949375000000005
Model XAI WIoU of binarized graphs for r=0.3 =  0.35985500000000004
len(reference) = 730
Effective ratio: 0.314 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.352
SUFF++ for r=0.3 class 0 = 0.689 +- 0.311 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.3 class 1 = 0.726 +- 0.311 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.3 class 2 = 0.711 +- 0.311 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.3 all KL = 0.758 +- 0.311 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.3 all L1 = 0.709 +- 0.178 (in-sample avg dev_std = 0.396)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.544
Model XAI F1 of binarized graphs for r=0.6 =  0.55293875
Model XAI WIoU of binarized graphs for r=0.6 =  0.4644475
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.459
SUFF++ for r=0.6 class 0 = 0.606 +- 0.300 (in-sample avg dev_std = 0.487)
SUFF++ for r=0.6 class 1 = 0.664 +- 0.300 (in-sample avg dev_std = 0.487)
SUFF++ for r=0.6 class 2 = 0.622 +- 0.300 (in-sample avg dev_std = 0.487)
SUFF++ for r=0.6 all KL = 0.625 +- 0.300 (in-sample avg dev_std = 0.487)
SUFF++ for r=0.6 all L1 = 0.631 +- 0.194 (in-sample avg dev_std = 0.487)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.728
Model XAI F1 of binarized graphs for r=0.9 =  0.52156375
Model XAI WIoU of binarized graphs for r=0.9 =  0.479955
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.729
SUFF++ for r=0.9 class 0 = 0.811 +- 0.243 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.9 class 1 = 0.788 +- 0.243 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.9 class 2 = 0.852 +- 0.243 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.9 all KL = 0.83 +- 0.243 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.9 all L1 = 0.817 +- 0.187 (in-sample avg dev_std = 0.350)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.438
Model XAI F1 of binarized graphs for r=0.3 =  0.4520975
Model XAI WIoU of binarized graphs for r=0.3 =  0.33244875000000007
len(reference) = 747
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.369
SUFF++ for r=0.3 class 0 = 0.722 +- 0.310 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.3 class 1 = 0.711 +- 0.310 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.3 class 2 = 0.725 +- 0.310 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.3 all KL = 0.769 +- 0.310 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.3 all L1 = 0.719 +- 0.174 (in-sample avg dev_std = 0.383)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.502
Model XAI F1 of binarized graphs for r=0.6 =  0.52382875
Model XAI WIoU of binarized graphs for r=0.6 =  0.4279787500000001
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.441
SUFF++ for r=0.6 class 0 = 0.631 +- 0.292 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.6 class 1 = 0.679 +- 0.292 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.6 class 2 = 0.622 +- 0.292 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.6 all KL = 0.648 +- 0.292 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.6 all L1 = 0.643 +- 0.189 (in-sample avg dev_std = 0.471)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.681
Model XAI F1 of binarized graphs for r=0.9 =  0.5030625000000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.44820375
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.693
SUFF++ for r=0.9 class 0 = 0.777 +- 0.246 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.9 class 1 = 0.784 +- 0.246 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.9 class 2 = 0.855 +- 0.246 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.9 all KL = 0.82 +- 0.246 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.9 all L1 = 0.806 +- 0.185 (in-sample avg dev_std = 0.365)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.607
Model XAI F1 of binarized graphs for r=0.3 =  0.4091075
Model XAI WIoU of binarized graphs for r=0.3 =  0.39623375000000005
len(reference) = 796
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.518
SUFF++ for r=0.3 class 0 = 0.673 +- 0.248 (in-sample avg dev_std = 0.447)
SUFF++ for r=0.3 class 1 = 0.71 +- 0.248 (in-sample avg dev_std = 0.447)
SUFF++ for r=0.3 class 2 = 0.701 +- 0.248 (in-sample avg dev_std = 0.447)
SUFF++ for r=0.3 all KL = 0.719 +- 0.248 (in-sample avg dev_std = 0.447)
SUFF++ for r=0.3 all L1 = 0.694 +- 0.164 (in-sample avg dev_std = 0.447)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.715
Model XAI F1 of binarized graphs for r=0.6 =  0.31027625000000003
Model XAI WIoU of binarized graphs for r=0.6 =  0.40243750000000006
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.623
SUFF++ for r=0.6 class 0 = 0.681 +- 0.200 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.6 class 1 = 0.712 +- 0.200 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.6 class 2 = 0.675 +- 0.200 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.6 all KL = 0.797 +- 0.200 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.6 all L1 = 0.69 +- 0.169 (in-sample avg dev_std = 0.367)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.761
Model XAI F1 of binarized graphs for r=0.9 =  0.25090625000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.40485249999999995
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.756
SUFF++ for r=0.9 class 0 = 0.803 +- 0.111 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 class 1 = 0.818 +- 0.111 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 class 2 = 0.839 +- 0.111 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 all KL = 0.91 +- 0.111 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 all L1 = 0.82 +- 0.127 (in-sample avg dev_std = 0.246)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.584
Model XAI F1 of binarized graphs for r=0.3 =  0.22540374999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.30204000000000003
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.489
SUFF++ for r=0.3 class 0 = 0.738 +- 0.107 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.3 class 1 = 0.737 +- 0.107 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.3 class 2 = 0.726 +- 0.107 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.3 all KL = 0.876 +- 0.107 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.3 all L1 = 0.733 +- 0.127 (in-sample avg dev_std = 0.281)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.594
Model XAI F1 of binarized graphs for r=0.6 =  0.15597124999999998
Model XAI WIoU of binarized graphs for r=0.6 =  0.28578749999999997
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.509
SUFF++ for r=0.6 class 0 = 0.704 +- 0.171 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.6 class 1 = 0.681 +- 0.171 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.6 class 2 = 0.674 +- 0.171 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.6 all KL = 0.835 +- 0.171 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.6 all L1 = 0.687 +- 0.142 (in-sample avg dev_std = 0.245)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.598
Model XAI F1 of binarized graphs for r=0.9 =  0.12061999999999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.27956875
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.531
SUFF++ for r=0.9 class 0 = 0.826 +- 0.068 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.9 class 1 = 0.792 +- 0.068 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.9 class 2 = 0.811 +- 0.068 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.9 all KL = 0.928 +- 0.068 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.9 all L1 = 0.81 +- 0.100 (in-sample avg dev_std = 0.210)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.365
Model XAI F1 of binarized graphs for r=0.3 =  0.47949375000000005
Model XAI WIoU of binarized graphs for r=0.3 =  0.35985500000000004
len(reference) = 800
Effective ratio: 0.314 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.327
NEC for r=0.3 class 0 = 0.301 +- 0.338 (in-sample avg dev_std = 0.301)
NEC for r=0.3 class 1 = 0.303 +- 0.338 (in-sample avg dev_std = 0.301)
NEC for r=0.3 class 2 = 0.3 +- 0.338 (in-sample avg dev_std = 0.301)
NEC for r=0.3 all KL = 0.235 +- 0.338 (in-sample avg dev_std = 0.301)
NEC for r=0.3 all L1 = 0.301 +- 0.233 (in-sample avg dev_std = 0.301)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.544
Model XAI F1 of binarized graphs for r=0.6 =  0.55293875
Model XAI WIoU of binarized graphs for r=0.6 =  0.4644475
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.371
NEC for r=0.6 class 0 = 0.487 +- 0.336 (in-sample avg dev_std = 0.496)
NEC for r=0.6 class 1 = 0.471 +- 0.336 (in-sample avg dev_std = 0.496)
NEC for r=0.6 class 2 = 0.52 +- 0.336 (in-sample avg dev_std = 0.496)
NEC for r=0.6 all KL = 0.508 +- 0.336 (in-sample avg dev_std = 0.496)
NEC for r=0.6 all L1 = 0.492 +- 0.198 (in-sample avg dev_std = 0.496)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.729
Model XAI F1 of binarized graphs for r=0.9 =  0.52156375
Model XAI WIoU of binarized graphs for r=0.9 =  0.479955
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.452
NEC for r=0.9 class 0 = 0.526 +- 0.254 (in-sample avg dev_std = 0.575)
NEC for r=0.9 class 1 = 0.558 +- 0.254 (in-sample avg dev_std = 0.575)
NEC for r=0.9 class 2 = 0.572 +- 0.254 (in-sample avg dev_std = 0.575)
NEC for r=0.9 all KL = 0.599 +- 0.254 (in-sample avg dev_std = 0.575)
NEC for r=0.9 all L1 = 0.552 +- 0.153 (in-sample avg dev_std = 0.575)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.911
Model XAI F1 of binarized graphs for r=1.0 =  0.50582625
Model XAI WIoU of binarized graphs for r=1.0 =  0.47759500000000005
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.493
NEC for r=1.0 class 0 = 0.51 +- 0.249 (in-sample avg dev_std = 0.606)
NEC for r=1.0 class 1 = 0.577 +- 0.249 (in-sample avg dev_std = 0.606)
NEC for r=1.0 class 2 = 0.584 +- 0.249 (in-sample avg dev_std = 0.606)
NEC for r=1.0 all KL = 0.625 +- 0.249 (in-sample avg dev_std = 0.606)
NEC for r=1.0 all L1 = 0.557 +- 0.160 (in-sample avg dev_std = 0.606)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.421
Model XAI F1 of binarized graphs for r=0.3 =  0.4520975
Model XAI WIoU of binarized graphs for r=0.3 =  0.33244875000000007
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.348
NEC for r=0.3 class 0 = 0.28 +- 0.336 (in-sample avg dev_std = 0.307)
NEC for r=0.3 class 1 = 0.315 +- 0.336 (in-sample avg dev_std = 0.307)
NEC for r=0.3 class 2 = 0.303 +- 0.336 (in-sample avg dev_std = 0.307)
NEC for r=0.3 all KL = 0.232 +- 0.336 (in-sample avg dev_std = 0.307)
NEC for r=0.3 all L1 = 0.299 +- 0.228 (in-sample avg dev_std = 0.307)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.502
Model XAI F1 of binarized graphs for r=0.6 =  0.52382875
Model XAI WIoU of binarized graphs for r=0.6 =  0.4279787500000001
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.373
NEC for r=0.6 class 0 = 0.463 +- 0.331 (in-sample avg dev_std = 0.501)
NEC for r=0.6 class 1 = 0.446 +- 0.331 (in-sample avg dev_std = 0.501)
NEC for r=0.6 class 2 = 0.51 +- 0.331 (in-sample avg dev_std = 0.501)
NEC for r=0.6 all KL = 0.481 +- 0.331 (in-sample avg dev_std = 0.501)
NEC for r=0.6 all L1 = 0.473 +- 0.196 (in-sample avg dev_std = 0.501)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.681
Model XAI F1 of binarized graphs for r=0.9 =  0.5030625000000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.44820375
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.448
NEC for r=0.9 class 0 = 0.524 +- 0.264 (in-sample avg dev_std = 0.573)
NEC for r=0.9 class 1 = 0.54 +- 0.264 (in-sample avg dev_std = 0.573)
NEC for r=0.9 class 2 = 0.569 +- 0.264 (in-sample avg dev_std = 0.573)
NEC for r=0.9 all KL = 0.587 +- 0.264 (in-sample avg dev_std = 0.573)
NEC for r=0.9 all L1 = 0.544 +- 0.161 (in-sample avg dev_std = 0.573)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.934
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.45005749999999994
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.497
NEC for r=1.0 class 0 = 0.497 +- 0.257 (in-sample avg dev_std = 0.614)
NEC for r=1.0 class 1 = 0.58 +- 0.257 (in-sample avg dev_std = 0.614)
NEC for r=1.0 class 2 = 0.589 +- 0.257 (in-sample avg dev_std = 0.614)
NEC for r=1.0 all KL = 0.617 +- 0.257 (in-sample avg dev_std = 0.614)
NEC for r=1.0 all L1 = 0.555 +- 0.164 (in-sample avg dev_std = 0.614)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.604
Model XAI F1 of binarized graphs for r=0.3 =  0.4091075
Model XAI WIoU of binarized graphs for r=0.3 =  0.39623375000000005
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.337
NEC for r=0.3 class 0 = 0.424 +- 0.379 (in-sample avg dev_std = 0.298)
NEC for r=0.3 class 1 = 0.446 +- 0.379 (in-sample avg dev_std = 0.298)
NEC for r=0.3 class 2 = 0.443 +- 0.379 (in-sample avg dev_std = 0.298)
NEC for r=0.3 all KL = 0.415 +- 0.379 (in-sample avg dev_std = 0.298)
NEC for r=0.3 all L1 = 0.438 +- 0.267 (in-sample avg dev_std = 0.298)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.715
Model XAI F1 of binarized graphs for r=0.6 =  0.31027625000000003
Model XAI WIoU of binarized graphs for r=0.6 =  0.40243750000000006
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.432
NEC for r=0.6 class 0 = 0.383 +- 0.224 (in-sample avg dev_std = 0.368)
NEC for r=0.6 class 1 = 0.441 +- 0.224 (in-sample avg dev_std = 0.368)
NEC for r=0.6 class 2 = 0.484 +- 0.224 (in-sample avg dev_std = 0.368)
NEC for r=0.6 all KL = 0.308 +- 0.224 (in-sample avg dev_std = 0.368)
NEC for r=0.6 all L1 = 0.435 +- 0.162 (in-sample avg dev_std = 0.368)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.761
Model XAI F1 of binarized graphs for r=0.9 =  0.25090625000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.40485249999999995
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.507
NEC for r=0.9 class 0 = 0.378 +- 0.173 (in-sample avg dev_std = 0.384)
NEC for r=0.9 class 1 = 0.438 +- 0.173 (in-sample avg dev_std = 0.384)
NEC for r=0.9 class 2 = 0.458 +- 0.173 (in-sample avg dev_std = 0.384)
NEC for r=0.9 all KL = 0.292 +- 0.173 (in-sample avg dev_std = 0.384)
NEC for r=0.9 all L1 = 0.424 +- 0.131 (in-sample avg dev_std = 0.384)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.921
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.40527749999999996
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.531
NEC for r=1.0 class 0 = 0.371 +- 0.189 (in-sample avg dev_std = 0.367)
NEC for r=1.0 class 1 = 0.464 +- 0.189 (in-sample avg dev_std = 0.367)
NEC for r=1.0 class 2 = 0.484 +- 0.189 (in-sample avg dev_std = 0.367)
NEC for r=1.0 all KL = 0.291 +- 0.189 (in-sample avg dev_std = 0.367)
NEC for r=1.0 all L1 = 0.439 +- 0.133 (in-sample avg dev_std = 0.367)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.584
Model XAI F1 of binarized graphs for r=0.3 =  0.22540374999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.30204000000000003
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.365
NEC for r=0.3 class 0 = 0.284 +- 0.220 (in-sample avg dev_std = 0.210)
NEC for r=0.3 class 1 = 0.362 +- 0.220 (in-sample avg dev_std = 0.210)
NEC for r=0.3 class 2 = 0.385 +- 0.220 (in-sample avg dev_std = 0.210)
NEC for r=0.3 all KL = 0.201 +- 0.220 (in-sample avg dev_std = 0.210)
NEC for r=0.3 all L1 = 0.343 +- 0.215 (in-sample avg dev_std = 0.210)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.594
Model XAI F1 of binarized graphs for r=0.6 =  0.15597124999999998
Model XAI WIoU of binarized graphs for r=0.6 =  0.28578749999999997
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.434
NEC for r=0.6 class 0 = 0.307 +- 0.157 (in-sample avg dev_std = 0.216)
NEC for r=0.6 class 1 = 0.373 +- 0.157 (in-sample avg dev_std = 0.216)
NEC for r=0.6 class 2 = 0.365 +- 0.157 (in-sample avg dev_std = 0.216)
NEC for r=0.6 all KL = 0.178 +- 0.157 (in-sample avg dev_std = 0.216)
NEC for r=0.6 all L1 = 0.348 +- 0.145 (in-sample avg dev_std = 0.216)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.599
Model XAI F1 of binarized graphs for r=0.9 =  0.12061999999999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.27956875
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.455
NEC for r=0.9 class 0 = 0.272 +- 0.102 (in-sample avg dev_std = 0.212)
NEC for r=0.9 class 1 = 0.325 +- 0.102 (in-sample avg dev_std = 0.212)
NEC for r=0.9 class 2 = 0.322 +- 0.102 (in-sample avg dev_std = 0.212)
NEC for r=0.9 all KL = 0.139 +- 0.102 (in-sample avg dev_std = 0.212)
NEC for r=0.9 all L1 = 0.306 +- 0.112 (in-sample avg dev_std = 0.212)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.711
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.27807125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.463
NEC for r=1.0 class 0 = 0.27 +- 0.109 (in-sample avg dev_std = 0.208)
NEC for r=1.0 class 1 = 0.352 +- 0.109 (in-sample avg dev_std = 0.208)
NEC for r=1.0 class 2 = 0.34 +- 0.109 (in-sample avg dev_std = 0.208)
NEC for r=1.0 all KL = 0.138 +- 0.109 (in-sample avg dev_std = 0.208)
NEC for r=1.0 all L1 = 0.32 +- 0.106 (in-sample avg dev_std = 0.208)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Thu May  2 23:15:45 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/02/2024 11:15:45 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/02/2024 11:15:58 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/02/2024 11:16:00 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/02/2024 11:16:02 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/02/2024 11:16:06 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:16:13 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 82...
[0m[1;37mINFO[0m: [1mCheckpoint 82: 
-----------------------------------
Train ACCURACY: 0.8917
Train Loss: 0.4445
ID Validation ACCURACY: 0.8997
ID Validation Loss: 0.4269
ID Test ACCURACY: 0.9003
ID Test Loss: 0.4238
OOD Validation ACCURACY: 0.7667
OOD Validation Loss: 0.7056
OOD Test ACCURACY: 0.4170
OOD Test Loss: 12.7943

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 88...
[0m[1;37mINFO[0m: [1mCheckpoint 88: 
-----------------------------------
Train ACCURACY: 0.8814
Train Loss: 0.4528
ID Validation ACCURACY: 0.8903
ID Validation Loss: 0.4357
ID Test ACCURACY: 0.8880
ID Test Loss: 0.4328
OOD Validation ACCURACY: 0.8283
OOD Validation Loss: 0.6515
OOD Test ACCURACY: 0.4807
OOD Test Loss: 18.8037

[0m[1;37mINFO[0m: [1mChartInfo 0.9003 0.4170 0.8880 0.4807 0.8903 0.8283[0mGOODMotif(18000)
Data example from train: Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
Label distribution from train: (tensor([0, 1, 2]), tensor([5912, 6084, 6004]))

Gold ratio (train) =  tensor(0.3628) +- tensor(0.1901)
F1 for r=0.3 = 0.467
WIoU for r=0.3 = 0.357
F1 for r=0.6 = 0.503
WIoU for r=0.6 = 0.367
F1 for r=0.9 = 0.501
WIoU for r=0.9 = 0.359
F1 for r=1.0 = 0.506
WIoU for r=1.0 = 0.365
GOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.442
WIoU for r=0.3 = 0.330
F1 for r=0.6 = 0.477
WIoU for r=0.6 = 0.342
F1 for r=0.9 = 0.490
WIoU for r=0.9 = 0.348
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.350
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.349
WIoU for r=0.3 = 0.261
F1 for r=0.6 = 0.265
WIoU for r=0.6 = 0.181
F1 for r=0.9 = 0.234
WIoU for r=0.9 = 0.155
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.157
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.151
WIoU for r=0.3 = 0.087
F1 for r=0.6 = 0.117
WIoU for r=0.6 = 0.064
F1 for r=0.9 = 0.102
WIoU for r=0.9 = 0.055
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.062


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.373
Model XAI F1 of binarized graphs for r=0.3 =  0.46745374999999995
Model XAI WIoU of binarized graphs for r=0.3 =  0.35662124999999995
len(reference) = 747
Effective ratio: 0.314 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.347
SUFF++ for r=0.3 class 0 = 0.537 +- 0.242 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.3 class 1 = 0.573 +- 0.242 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.3 class 2 = 0.553 +- 0.242 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.3 all KL = 0.631 +- 0.242 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.3 all L1 = 0.554 +- 0.159 (in-sample avg dev_std = 0.459)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.405
Model XAI F1 of binarized graphs for r=0.6 =  0.50273625
Model XAI WIoU of binarized graphs for r=0.6 =  0.3666175
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.387
SUFF++ for r=0.6 class 0 = 0.603 +- 0.264 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.6 class 1 = 0.593 +- 0.264 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.6 class 2 = 0.634 +- 0.264 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.6 all KL = 0.643 +- 0.264 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.6 all L1 = 0.61 +- 0.181 (in-sample avg dev_std = 0.448)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.51
Model XAI F1 of binarized graphs for r=0.9 =  0.500685
Model XAI WIoU of binarized graphs for r=0.9 =  0.3593187500000001
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.525
SUFF++ for r=0.9 class 0 = 0.688 +- 0.242 (in-sample avg dev_std = 0.404)
SUFF++ for r=0.9 class 1 = 0.682 +- 0.242 (in-sample avg dev_std = 0.404)
SUFF++ for r=0.9 class 2 = 0.645 +- 0.242 (in-sample avg dev_std = 0.404)
SUFF++ for r=0.9 all KL = 0.732 +- 0.242 (in-sample avg dev_std = 0.404)
SUFF++ for r=0.9 all L1 = 0.672 +- 0.197 (in-sample avg dev_std = 0.404)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.372
Model XAI F1 of binarized graphs for r=0.3 =  0.44206125
Model XAI WIoU of binarized graphs for r=0.3 =  0.33041624999999997
len(reference) = 752
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.357
SUFF++ for r=0.3 class 0 = 0.56 +- 0.240 (in-sample avg dev_std = 0.436)
SUFF++ for r=0.3 class 1 = 0.582 +- 0.240 (in-sample avg dev_std = 0.436)
SUFF++ for r=0.3 class 2 = 0.548 +- 0.240 (in-sample avg dev_std = 0.436)
SUFF++ for r=0.3 all KL = 0.651 +- 0.240 (in-sample avg dev_std = 0.436)
SUFF++ for r=0.3 all L1 = 0.563 +- 0.158 (in-sample avg dev_std = 0.436)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.411
Model XAI F1 of binarized graphs for r=0.6 =  0.476845
Model XAI WIoU of binarized graphs for r=0.6 =  0.34152625000000003
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.404
SUFF++ for r=0.6 class 0 = 0.626 +- 0.252 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.6 class 1 = 0.613 +- 0.252 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.6 class 2 = 0.626 +- 0.252 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.6 all KL = 0.657 +- 0.252 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.6 all L1 = 0.622 +- 0.172 (in-sample avg dev_std = 0.438)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.545
Model XAI F1 of binarized graphs for r=0.9 =  0.4896125
Model XAI WIoU of binarized graphs for r=0.9 =  0.3479025
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.556
SUFF++ for r=0.9 class 0 = 0.686 +- 0.239 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.9 class 1 = 0.708 +- 0.239 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.9 class 2 = 0.642 +- 0.239 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.9 all KL = 0.745 +- 0.239 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.9 all L1 = 0.678 +- 0.198 (in-sample avg dev_std = 0.384)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.377
Model XAI F1 of binarized graphs for r=0.3 =  0.3490625
Model XAI WIoU of binarized graphs for r=0.3 =  0.26061375
len(reference) = 796
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.415
SUFF++ for r=0.3 class 0 = 0.568 +- 0.229 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 class 1 = 0.583 +- 0.229 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 class 2 = 0.632 +- 0.229 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 all KL = 0.641 +- 0.229 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 all L1 = 0.594 +- 0.141 (in-sample avg dev_std = 0.475)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.407
Model XAI F1 of binarized graphs for r=0.6 =  0.265385
Model XAI WIoU of binarized graphs for r=0.6 =  0.18098875
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.405
SUFF++ for r=0.6 class 0 = 0.606 +- 0.231 (in-sample avg dev_std = 0.442)
SUFF++ for r=0.6 class 1 = 0.624 +- 0.231 (in-sample avg dev_std = 0.442)
SUFF++ for r=0.6 class 2 = 0.646 +- 0.231 (in-sample avg dev_std = 0.442)
SUFF++ for r=0.6 all KL = 0.67 +- 0.231 (in-sample avg dev_std = 0.442)
SUFF++ for r=0.6 all L1 = 0.625 +- 0.143 (in-sample avg dev_std = 0.442)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.564
Model XAI F1 of binarized graphs for r=0.9 =  0.23367625
Model XAI WIoU of binarized graphs for r=0.9 =  0.15530125000000003
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.532
SUFF++ for r=0.9 class 0 = 0.72 +- 0.154 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 class 1 = 0.736 +- 0.154 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 class 2 = 0.68 +- 0.154 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 all KL = 0.838 +- 0.154 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 all L1 = 0.713 +- 0.168 (in-sample avg dev_std = 0.279)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.339
Model XAI F1 of binarized graphs for r=0.3 =  0.15104125
Model XAI WIoU of binarized graphs for r=0.3 =  0.08742000000000001
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.335
SUFF++ for r=0.3 class 0 = 0.617 +- 0.335 (in-sample avg dev_std = 0.551)
SUFF++ for r=0.3 class 1 = 0.614 +- 0.335 (in-sample avg dev_std = 0.551)
SUFF++ for r=0.3 class 2 = 0.62 +- 0.335 (in-sample avg dev_std = 0.551)
SUFF++ for r=0.3 all KL = 0.63 +- 0.335 (in-sample avg dev_std = 0.551)
SUFF++ for r=0.3 all L1 = 0.617 +- 0.168 (in-sample avg dev_std = 0.551)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.335
Model XAI F1 of binarized graphs for r=0.6 =  0.11712499999999998
Model XAI WIoU of binarized graphs for r=0.6 =  0.06392625
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.332
SUFF++ for r=0.6 class 0 = 0.753 +- 0.315 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.6 class 1 = 0.759 +- 0.315 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.6 class 2 = 0.773 +- 0.315 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.6 all KL = 0.808 +- 0.315 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.6 all L1 = 0.762 +- 0.216 (in-sample avg dev_std = 0.339)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.345
Model XAI F1 of binarized graphs for r=0.9 =  0.10182500000000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.0554425
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.349
SUFF++ for r=0.9 class 0 = 0.869 +- 0.097 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.9 class 1 = 0.842 +- 0.097 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.9 class 2 = 0.844 +- 0.097 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.9 all KL = 0.937 +- 0.097 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.9 all L1 = 0.852 +- 0.155 (in-sample avg dev_std = 0.190)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.363
Model XAI F1 of binarized graphs for r=0.3 =  0.46745374999999995
Model XAI WIoU of binarized graphs for r=0.3 =  0.35662124999999995
len(reference) = 800
Effective ratio: 0.314 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.333
NEC for r=0.3 class 0 = 0.435 +- 0.290 (in-sample avg dev_std = 0.318)
NEC for r=0.3 class 1 = 0.368 +- 0.290 (in-sample avg dev_std = 0.318)
NEC for r=0.3 class 2 = 0.418 +- 0.290 (in-sample avg dev_std = 0.318)
NEC for r=0.3 all KL = 0.314 +- 0.290 (in-sample avg dev_std = 0.318)
NEC for r=0.3 all L1 = 0.407 +- 0.216 (in-sample avg dev_std = 0.318)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.405
Model XAI F1 of binarized graphs for r=0.6 =  0.50273625
Model XAI WIoU of binarized graphs for r=0.6 =  0.3666175
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.337
NEC for r=0.6 class 0 = 0.358 +- 0.277 (in-sample avg dev_std = 0.335)
NEC for r=0.6 class 1 = 0.399 +- 0.277 (in-sample avg dev_std = 0.335)
NEC for r=0.6 class 2 = 0.387 +- 0.277 (in-sample avg dev_std = 0.335)
NEC for r=0.6 all KL = 0.316 +- 0.277 (in-sample avg dev_std = 0.335)
NEC for r=0.6 all L1 = 0.382 +- 0.205 (in-sample avg dev_std = 0.335)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.51
Model XAI F1 of binarized graphs for r=0.9 =  0.500685
Model XAI WIoU of binarized graphs for r=0.9 =  0.3593187500000001
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.412
NEC for r=0.9 class 0 = 0.509 +- 0.284 (in-sample avg dev_std = 0.444)
NEC for r=0.9 class 1 = 0.449 +- 0.284 (in-sample avg dev_std = 0.444)
NEC for r=0.9 class 2 = 0.557 +- 0.284 (in-sample avg dev_std = 0.444)
NEC for r=0.9 all KL = 0.456 +- 0.284 (in-sample avg dev_std = 0.444)
NEC for r=0.9 all L1 = 0.505 +- 0.198 (in-sample avg dev_std = 0.444)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.876
Model XAI F1 of binarized graphs for r=1.0 =  0.50582625
Model XAI WIoU of binarized graphs for r=1.0 =  0.36452249999999997
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.468
NEC for r=1.0 class 0 = 0.491 +- 0.266 (in-sample avg dev_std = 0.577)
NEC for r=1.0 class 1 = 0.584 +- 0.266 (in-sample avg dev_std = 0.577)
NEC for r=1.0 class 2 = 0.61 +- 0.266 (in-sample avg dev_std = 0.577)
NEC for r=1.0 all KL = 0.592 +- 0.266 (in-sample avg dev_std = 0.577)
NEC for r=1.0 all L1 = 0.562 +- 0.171 (in-sample avg dev_std = 0.577)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.369
Model XAI F1 of binarized graphs for r=0.3 =  0.44206125
Model XAI WIoU of binarized graphs for r=0.3 =  0.33041624999999997
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.334
NEC for r=0.3 class 0 = 0.407 +- 0.287 (in-sample avg dev_std = 0.300)
NEC for r=0.3 class 1 = 0.363 +- 0.287 (in-sample avg dev_std = 0.300)
NEC for r=0.3 class 2 = 0.417 +- 0.287 (in-sample avg dev_std = 0.300)
NEC for r=0.3 all KL = 0.296 +- 0.287 (in-sample avg dev_std = 0.300)
NEC for r=0.3 all L1 = 0.396 +- 0.213 (in-sample avg dev_std = 0.300)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.411
Model XAI F1 of binarized graphs for r=0.6 =  0.476845
Model XAI WIoU of binarized graphs for r=0.6 =  0.34152625000000003
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.365
NEC for r=0.6 class 0 = 0.365 +- 0.271 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 1 = 0.388 +- 0.271 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 2 = 0.385 +- 0.271 (in-sample avg dev_std = 0.348)
NEC for r=0.6 all KL = 0.316 +- 0.271 (in-sample avg dev_std = 0.348)
NEC for r=0.6 all L1 = 0.379 +- 0.198 (in-sample avg dev_std = 0.348)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.545
Model XAI F1 of binarized graphs for r=0.9 =  0.4896125
Model XAI WIoU of binarized graphs for r=0.9 =  0.3479025
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.397
NEC for r=0.9 class 0 = 0.498 +- 0.279 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 1 = 0.472 +- 0.279 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 2 = 0.569 +- 0.279 (in-sample avg dev_std = 0.439)
NEC for r=0.9 all KL = 0.465 +- 0.279 (in-sample avg dev_std = 0.439)
NEC for r=0.9 all L1 = 0.513 +- 0.192 (in-sample avg dev_std = 0.439)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.902
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.35048875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.472
NEC for r=1.0 class 0 = 0.477 +- 0.275 (in-sample avg dev_std = 0.574)
NEC for r=1.0 class 1 = 0.585 +- 0.275 (in-sample avg dev_std = 0.574)
NEC for r=1.0 class 2 = 0.61 +- 0.275 (in-sample avg dev_std = 0.574)
NEC for r=1.0 all KL = 0.58 +- 0.275 (in-sample avg dev_std = 0.574)
NEC for r=1.0 all L1 = 0.557 +- 0.173 (in-sample avg dev_std = 0.574)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.376
Model XAI F1 of binarized graphs for r=0.3 =  0.3490625
Model XAI WIoU of binarized graphs for r=0.3 =  0.26061375
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.338
NEC for r=0.3 class 0 = 0.273 +- 0.205 (in-sample avg dev_std = 0.198)
NEC for r=0.3 class 1 = 0.289 +- 0.205 (in-sample avg dev_std = 0.198)
NEC for r=0.3 class 2 = 0.315 +- 0.205 (in-sample avg dev_std = 0.198)
NEC for r=0.3 all KL = 0.173 +- 0.205 (in-sample avg dev_std = 0.198)
NEC for r=0.3 all L1 = 0.292 +- 0.189 (in-sample avg dev_std = 0.198)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.407
Model XAI F1 of binarized graphs for r=0.6 =  0.265385
Model XAI WIoU of binarized graphs for r=0.6 =  0.18098875
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.355
NEC for r=0.6 class 0 = 0.313 +- 0.197 (in-sample avg dev_std = 0.283)
NEC for r=0.6 class 1 = 0.306 +- 0.197 (in-sample avg dev_std = 0.283)
NEC for r=0.6 class 2 = 0.347 +- 0.197 (in-sample avg dev_std = 0.283)
NEC for r=0.6 all KL = 0.219 +- 0.197 (in-sample avg dev_std = 0.283)
NEC for r=0.6 all L1 = 0.321 +- 0.163 (in-sample avg dev_std = 0.283)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.569
Model XAI F1 of binarized graphs for r=0.9 =  0.23367625
Model XAI WIoU of binarized graphs for r=0.9 =  0.15530125000000003
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.368
NEC for r=0.9 class 0 = 0.378 +- 0.195 (in-sample avg dev_std = 0.268)
NEC for r=0.9 class 1 = 0.373 +- 0.195 (in-sample avg dev_std = 0.268)
NEC for r=0.9 class 2 = 0.468 +- 0.195 (in-sample avg dev_std = 0.268)
NEC for r=0.9 all KL = 0.258 +- 0.195 (in-sample avg dev_std = 0.268)
NEC for r=0.9 all L1 = 0.405 +- 0.187 (in-sample avg dev_std = 0.268)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.791
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.1569775
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.409
NEC for r=1.0 class 0 = 0.436 +- 0.230 (in-sample avg dev_std = 0.294)
NEC for r=1.0 class 1 = 0.465 +- 0.230 (in-sample avg dev_std = 0.294)
NEC for r=1.0 class 2 = 0.525 +- 0.230 (in-sample avg dev_std = 0.294)
NEC for r=1.0 all KL = 0.336 +- 0.230 (in-sample avg dev_std = 0.294)
NEC for r=1.0 all L1 = 0.474 +- 0.180 (in-sample avg dev_std = 0.294)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.339
Model XAI F1 of binarized graphs for r=0.3 =  0.15104125
Model XAI WIoU of binarized graphs for r=0.3 =  0.08742000000000001
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.325
NEC for r=0.3 class 0 = 0.218 +- 0.182 (in-sample avg dev_std = 0.157)
NEC for r=0.3 class 1 = 0.199 +- 0.182 (in-sample avg dev_std = 0.157)
NEC for r=0.3 class 2 = 0.235 +- 0.182 (in-sample avg dev_std = 0.157)
NEC for r=0.3 all KL = 0.132 +- 0.182 (in-sample avg dev_std = 0.157)
NEC for r=0.3 all L1 = 0.217 +- 0.170 (in-sample avg dev_std = 0.157)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.335
Model XAI F1 of binarized graphs for r=0.6 =  0.11712499999999998
Model XAI WIoU of binarized graphs for r=0.6 =  0.06392625
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.336
NEC for r=0.6 class 0 = 0.165 +- 0.108 (in-sample avg dev_std = 0.131)
NEC for r=0.6 class 1 = 0.168 +- 0.108 (in-sample avg dev_std = 0.131)
NEC for r=0.6 class 2 = 0.177 +- 0.108 (in-sample avg dev_std = 0.131)
NEC for r=0.6 all KL = 0.071 +- 0.108 (in-sample avg dev_std = 0.131)
NEC for r=0.6 all L1 = 0.17 +- 0.145 (in-sample avg dev_std = 0.131)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.345
Model XAI F1 of binarized graphs for r=0.9 =  0.10182500000000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.0554425
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.341
NEC for r=0.9 class 0 = 0.163 +- 0.162 (in-sample avg dev_std = 0.101)
NEC for r=0.9 class 1 = 0.202 +- 0.162 (in-sample avg dev_std = 0.101)
NEC for r=0.9 class 2 = 0.202 +- 0.162 (in-sample avg dev_std = 0.101)
NEC for r=0.9 all KL = 0.096 +- 0.162 (in-sample avg dev_std = 0.101)
NEC for r=0.9 all L1 = 0.189 +- 0.214 (in-sample avg dev_std = 0.101)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.434
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.061721250000000005
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.356
NEC for r=1.0 class 0 = 0.216 +- 0.178 (in-sample avg dev_std = 0.136)
NEC for r=1.0 class 1 = 0.257 +- 0.178 (in-sample avg dev_std = 0.136)
NEC for r=1.0 class 2 = 0.261 +- 0.178 (in-sample avg dev_std = 0.136)
NEC for r=1.0 all KL = 0.129 +- 0.178 (in-sample avg dev_std = 0.136)
NEC for r=1.0 all L1 = 0.244 +- 0.239 (in-sample avg dev_std = 0.136)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split train
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.648, 0.607, 0.729, 1.0], 'all_L1': [0.57, 0.588, 0.682, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.783, 0.645, 0.777, 1.0], 'all_L1': [0.668, 0.64, 0.756, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.699, 0.586, 0.774, 1.0], 'all_L1': [0.658, 0.651, 0.776, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.758, 0.625, 0.83, 1.0], 'all_L1': [0.709, 0.631, 0.817, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.631, 0.643, 0.732, 1.0], 'all_L1': [0.554, 0.61, 0.672, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.275, 0.291, 0.515, 0.629], 'all_L1': [0.354, 0.361, 0.541, 0.568]}), defaultdict(<class 'list'>, {'all_KL': [0.245, 0.549, 0.606, 0.655], 'all_L1': [0.36, 0.529, 0.564, 0.569]}), defaultdict(<class 'list'>, {'all_KL': [0.322, 0.584, 0.672, 0.649], 'all_L1': [0.377, 0.509, 0.603, 0.574]}), defaultdict(<class 'list'>, {'all_KL': [0.235, 0.508, 0.599, 0.625], 'all_L1': [0.301, 0.492, 0.552, 0.557]}), defaultdict(<class 'list'>, {'all_KL': [0.314, 0.316, 0.456, 0.592], 'all_L1': [0.407, 0.382, 0.505, 0.562]})]

Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.67, 0.631, 0.734, 1.0], 'all_L1': [0.587, 0.594, 0.676, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.792, 0.66, 0.749, 1.0], 'all_L1': [0.674, 0.646, 0.734, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.704, 0.574, 0.751, 1.0], 'all_L1': [0.666, 0.644, 0.753, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.769, 0.648, 0.82, 1.0], 'all_L1': [0.719, 0.643, 0.806, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.651, 0.657, 0.745, 1.0], 'all_L1': [0.563, 0.622, 0.678, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.255, 0.279, 0.498, 0.618], 'all_L1': [0.344, 0.364, 0.532, 0.558]}), defaultdict(<class 'list'>, {'all_KL': [0.227, 0.534, 0.6, 0.637], 'all_L1': [0.34, 0.525, 0.558, 0.559]}), defaultdict(<class 'list'>, {'all_KL': [0.322, 0.591, 0.665, 0.629], 'all_L1': [0.37, 0.511, 0.604, 0.563]}), defaultdict(<class 'list'>, {'all_KL': [0.232, 0.481, 0.587, 0.617], 'all_L1': [0.299, 0.473, 0.544, 0.555]}), defaultdict(<class 'list'>, {'all_KL': [0.296, 0.316, 0.465, 0.58], 'all_L1': [0.396, 0.379, 0.513, 0.557]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.614, 0.647, 0.827, 1.0], 'all_L1': [0.599, 0.608, 0.702, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.778, 0.709, 0.809, 1.0], 'all_L1': [0.689, 0.655, 0.735, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.75, 0.663, 0.799, 1.0], 'all_L1': [0.708, 0.695, 0.712, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.719, 0.797, 0.91, 1.0], 'all_L1': [0.694, 0.69, 0.82, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.641, 0.67, 0.838, 1.0], 'all_L1': [0.594, 0.625, 0.713, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.152, 0.206, 0.291, 0.321], 'all_L1': [0.254, 0.322, 0.439, 0.46]}), defaultdict(<class 'list'>, {'all_KL': [0.369, 0.462, 0.377, 0.417], 'all_L1': [0.428, 0.495, 0.473, 0.497]}), defaultdict(<class 'list'>, {'all_KL': [0.376, 0.347, 0.431, 0.343], 'all_L1': [0.412, 0.389, 0.522, 0.474]}), defaultdict(<class 'list'>, {'all_KL': [0.415, 0.308, 0.292, 0.291], 'all_L1': [0.438, 0.435, 0.424, 0.439]}), defaultdict(<class 'list'>, {'all_KL': [0.173, 0.219, 0.258, 0.336], 'all_L1': [0.292, 0.321, 0.405, 0.474]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.602, 0.715, 0.902, 1.0], 'all_L1': [0.581, 0.662, 0.794, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.844, 0.743, 0.887, 1.0], 'all_L1': [0.711, 0.642, 0.804, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.83, 0.739, 0.803, 1.0], 'all_L1': [0.691, 0.62, 0.709, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.876, 0.835, 0.928, 1.0], 'all_L1': [0.733, 0.687, 0.81, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.63, 0.808, 0.937, 1.0], 'all_L1': [0.617, 0.762, 0.852, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.201, 0.164, 0.142, 0.145], 'all_L1': [0.275, 0.221, 0.279, 0.296]}), defaultdict(<class 'list'>, {'all_KL': [0.107, 0.138, 0.096, 0.13], 'all_L1': [0.23, 0.286, 0.225, 0.27]}), defaultdict(<class 'list'>, {'all_KL': [0.248, 0.284, 0.322, 0.242], 'all_L1': [0.384, 0.427, 0.452, 0.391]}), defaultdict(<class 'list'>, {'all_KL': [0.201, 0.178, 0.139, 0.138], 'all_L1': [0.343, 0.348, 0.306, 0.32]}), defaultdict(<class 'list'>, {'all_KL': [0.132, 0.071, 0.096, 0.129], 'all_L1': [0.217, 0.17, 0.189, 0.244]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split train
suff++ class all_L1  =  0.632 +- 0.060, 0.624 +- 0.022, 0.741 +- 0.056, 1.000 +- 0.000
suff++ class all_KL  =  0.704 +- 0.059, 0.621 +- 0.022, 0.768 +- 0.037, 1.000 +- 0.000
suff++_acc_int  =  0.348 +- 0.004, 0.448 +- 0.051, 0.657 +- 0.088
nec class all_L1  =  0.360 +- 0.035, 0.455 +- 0.069, 0.553 +- 0.032, 0.566 +- 0.006
nec class all_KL  =  0.278 +- 0.035, 0.450 +- 0.122, 0.570 +- 0.076, 0.630 +- 0.022
nec_acc_int  =  0.316 +- 0.023, 0.355 +- 0.015, 0.436 +- 0.022, 0.472 +- 0.012

Eval split id_val
suff++ class all_L1  =  0.642 +- 0.058, 0.630 +- 0.020, 0.729 +- 0.049, 1.000 +- 0.000
suff++ class all_KL  =  0.717 +- 0.055, 0.634 +- 0.032, 0.760 +- 0.031, 1.000 +- 0.000
suff++_acc_int  =  0.351 +- 0.012, 0.451 +- 0.048, 0.663 +- 0.074
nec class all_L1  =  0.350 +- 0.032, 0.450 +- 0.067, 0.550 +- 0.031, 0.558 +- 0.003
nec class all_KL  =  0.266 +- 0.037, 0.440 +- 0.122, 0.563 +- 0.072, 0.616 +- 0.020
nec_acc_int  =  0.318 +- 0.026, 0.365 +- 0.017, 0.438 +- 0.029, 0.487 +- 0.010

Eval split val
suff++ class all_L1  =  0.657 +- 0.050, 0.655 +- 0.034, 0.736 +- 0.043, 1.000 +- 0.000
suff++ class all_KL  =  0.700 +- 0.063, 0.697 +- 0.054, 0.837 +- 0.039, 1.000 +- 0.000
suff++_acc_int  =  0.463 +- 0.044, 0.510 +- 0.096, 0.651 +- 0.075
nec class all_L1  =  0.365 +- 0.076, 0.392 +- 0.067, 0.453 +- 0.041, 0.469 +- 0.019
nec class all_KL  =  0.297 +- 0.111, 0.308 +- 0.093, 0.330 +- 0.064, 0.342 +- 0.042
nec_acc_int  =  0.340 +- 0.013, 0.375 +- 0.036, 0.450 +- 0.048, 0.487 +- 0.043

Eval split test
suff++ class all_L1  =  0.667 +- 0.058, 0.675 +- 0.049, 0.794 +- 0.047, 1.000 +- 0.000
suff++ class all_KL  =  0.756 +- 0.116, 0.768 +- 0.046, 0.891 +- 0.048, 1.000 +- 0.000
suff++_acc_int  =  0.398 +- 0.065, 0.421 +- 0.080, 0.426 +- 0.073
nec class all_L1  =  0.290 +- 0.064, 0.290 +- 0.091, 0.290 +- 0.091, 0.304 +- 0.050
nec class all_KL  =  0.178 +- 0.051, 0.167 +- 0.069, 0.159 +- 0.084, 0.157 +- 0.043
nec_acc_int  =  0.345 +- 0.015, 0.373 +- 0.037, 0.386 +- 0.041, 0.400 +- 0.035


 -------------------------------------------------- 
Computing faithfulness

Eval split train
Faith. Aritm (L1)= 		  =  0.496 +- 0.021, 0.539 +- 0.045, 0.647 +- 0.040, 0.783 +- 0.003
Faith. Armon (L1)= 		  =  0.455 +- 0.022, 0.524 +- 0.055, 0.633 +- 0.037, 0.723 +- 0.005
Faith. GMean (L1)= 	  =  0.475 +- 0.018, 0.532 +- 0.050, 0.640 +- 0.039, 0.752 +- 0.004
Faith. Aritm (KL)= 		  =  0.491 +- 0.021, 0.535 +- 0.060, 0.669 +- 0.052, 0.815 +- 0.011
Faith. Armon (KL)= 		  =  0.396 +- 0.030, 0.511 +- 0.085, 0.652 +- 0.060, 0.773 +- 0.017
Faith. GMean (KL)= 	  =  0.440 +- 0.019, 0.523 +- 0.073, 0.661 +- 0.056, 0.794 +- 0.014

Eval split id_val
Faith. Aritm (L1)= 		  =  0.496 +- 0.020, 0.540 +- 0.043, 0.640 +- 0.035, 0.779 +- 0.001
Faith. Armon (L1)= 		  =  0.450 +- 0.020, 0.523 +- 0.052, 0.627 +- 0.032, 0.717 +- 0.002
Faith. GMean (L1)= 	  =  0.472 +- 0.016, 0.532 +- 0.048, 0.633 +- 0.033, 0.747 +- 0.002
Faith. Aritm (KL)= 		  =  0.492 +- 0.020, 0.537 +- 0.056, 0.661 +- 0.043, 0.808 +- 0.010
Faith. Armon (KL)= 		  =  0.386 +- 0.034, 0.508 +- 0.084, 0.644 +- 0.052, 0.762 +- 0.015
Faith. GMean (KL)= 	  =  0.435 +- 0.022, 0.522 +- 0.071, 0.653 +- 0.048, 0.785 +- 0.013

Eval split val
Faith. Aritm (L1)= 		  =  0.511 +- 0.062, 0.524 +- 0.046, 0.594 +- 0.025, 0.734 +- 0.010
Faith. Armon (L1)= 		  =  0.467 +- 0.077, 0.488 +- 0.057, 0.559 +- 0.029, 0.638 +- 0.018
Faith. GMean (L1)= 	  =  0.488 +- 0.070, 0.506 +- 0.052, 0.576 +- 0.026, 0.685 +- 0.014
Faith. Aritm (KL)= 		  =  0.499 +- 0.085, 0.503 +- 0.061, 0.583 +- 0.025, 0.671 +- 0.021
Faith. Armon (KL)= 		  =  0.409 +- 0.124, 0.420 +- 0.090, 0.468 +- 0.060, 0.508 +- 0.045
Faith. GMean (KL)= 	  =  0.450 +- 0.107, 0.459 +- 0.076, 0.522 +- 0.043, 0.583 +- 0.035

Eval split test
Faith. Aritm (L1)= 		  =  0.478 +- 0.052, 0.483 +- 0.032, 0.542 +- 0.024, 0.652 +- 0.025
Faith. Armon (L1)= 		  =  0.401 +- 0.068, 0.395 +- 0.083, 0.414 +- 0.083, 0.464 +- 0.058
Faith. GMean (L1)= 	  =  0.437 +- 0.060, 0.435 +- 0.059, 0.472 +- 0.058, 0.550 +- 0.045
Faith. Aritm (KL)= 		  =  0.467 +- 0.066, 0.468 +- 0.034, 0.525 +- 0.023, 0.578 +- 0.021
Faith. Armon (KL)= 		  =  0.284 +- 0.071, 0.267 +- 0.091, 0.259 +- 0.105, 0.269 +- 0.061
Faith. GMean (KL)= 	  =  0.362 +- 0.065, 0.349 +- 0.072, 0.363 +- 0.078, 0.393 +- 0.050
Computed for split load_split = id



Completed in  0:38:27.043552  for LECIGIN GOODMotif/size



DONE LECI GOODMotif/size

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Thu May  2 23:23:52 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/02/2024 11:23:52 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/02/2024 11:23:55 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/02/2024 11:23:55 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/02/2024 11:23:56 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/02/2024 11:23:58 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:24:00 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 7...
[0m[1;37mINFO[0m: [1mCheckpoint 7: 
-----------------------------------
Train ACCURACY: 0.7884
Train Loss: 0.5337
ID Validation ACCURACY: 0.6931
ID Validation Loss: 0.7689
ID Test ACCURACY: 0.6823
ID Test Loss: 0.7935
OOD Validation ACCURACY: 0.6022
OOD Validation Loss: 0.9445
OOD Test ACCURACY: 0.5559
OOD Test Loss: 1.0869

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 102...
[0m[1;37mINFO[0m: [1mCheckpoint 102: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0005
ID Validation ACCURACY: 0.6931
ID Validation Loss: 2.0819
ID Test ACCURACY: 0.6733
ID Test Loss: 2.1937
OOD Validation ACCURACY: 0.6246
OOD Validation Loss: 2.5268
OOD Test ACCURACY: 0.5594
OOD Test Loss: 2.9977

[0m[1;37mINFO[0m: [1mChartInfo 0.6823 0.5559 0.6733 0.5594 0.6931 0.6246[0mGOODTwitter(2590)
Data example from train: Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
Label distribution from train: (tensor([0, 1, 2]), tensor([ 625, 1283,  682]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.728
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 797
Effective ratio: 0.314 +- 0.014
Model Accuracy over intervened graphs for r=0.3 =  0.689
SUFF++ for r=0.3 class 0 = 0.769 +- 0.080 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.3 class 1 = 0.797 +- 0.080 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.3 class 2 = 0.763 +- 0.080 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.3 all KL = 0.917 +- 0.080 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.3 all L1 = 0.781 +- 0.089 (in-sample avg dev_std = 0.226)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.759
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 797
Effective ratio: 0.615 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.736
SUFF++ for r=0.6 class 0 = 0.805 +- 0.072 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 class 1 = 0.82 +- 0.072 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 class 2 = 0.8 +- 0.072 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 all KL = 0.933 +- 0.072 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 all L1 = 0.811 +- 0.088 (in-sample avg dev_std = 0.195)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.783
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 794
Effective ratio: 0.915 +- 0.015
Model Accuracy over intervened graphs for r=0.9 =  0.777
SUFF++ for r=0.9 class 0 = 0.907 +- 0.019 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.9 class 1 = 0.9 +- 0.019 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.9 class 2 = 0.907 +- 0.019 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.9 all KL = 0.981 +- 0.019 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.9 all L1 = 0.904 +- 0.055 (in-sample avg dev_std = 0.105)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.65
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.612
SUFF++ for r=0.3 class 0 = 0.755 +- 0.092 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.3 class 1 = 0.792 +- 0.092 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.3 class 2 = 0.747 +- 0.092 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.3 all KL = 0.911 +- 0.092 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.3 all L1 = 0.771 +- 0.100 (in-sample avg dev_std = 0.235)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.662
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.659
SUFF++ for r=0.6 class 0 = 0.796 +- 0.080 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.6 class 1 = 0.821 +- 0.080 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.6 class 2 = 0.79 +- 0.080 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.6 all KL = 0.93 +- 0.080 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.6 all L1 = 0.806 +- 0.097 (in-sample avg dev_std = 0.205)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.68
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.676
SUFF++ for r=0.9 class 0 = 0.899 +- 0.023 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 class 1 = 0.902 +- 0.023 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 class 2 = 0.898 +- 0.023 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 all KL = 0.98 +- 0.023 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 all L1 = 0.9 +- 0.058 (in-sample avg dev_std = 0.113)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.577
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.573
SUFF++ for r=0.3 class 0 = 0.778 +- 0.064 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.3 class 1 = 0.791 +- 0.064 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.3 class 2 = 0.79 +- 0.064 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.3 all KL = 0.932 +- 0.064 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.3 all L1 = 0.788 +- 0.083 (in-sample avg dev_std = 0.191)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.6
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.584
SUFF++ for r=0.6 class 0 = 0.829 +- 0.045 (in-sample avg dev_std = 0.150)
SUFF++ for r=0.6 class 1 = 0.832 +- 0.045 (in-sample avg dev_std = 0.150)
SUFF++ for r=0.6 class 2 = 0.828 +- 0.045 (in-sample avg dev_std = 0.150)
SUFF++ for r=0.6 all KL = 0.956 +- 0.045 (in-sample avg dev_std = 0.150)
SUFF++ for r=0.6 all L1 = 0.83 +- 0.071 (in-sample avg dev_std = 0.150)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.603
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.595
SUFF++ for r=0.9 class 0 = 0.901 +- 0.014 (in-sample avg dev_std = 0.083)
SUFF++ for r=0.9 class 1 = 0.894 +- 0.014 (in-sample avg dev_std = 0.083)
SUFF++ for r=0.9 class 2 = 0.891 +- 0.014 (in-sample avg dev_std = 0.083)
SUFF++ for r=0.9 all KL = 0.984 +- 0.014 (in-sample avg dev_std = 0.083)
SUFF++ for r=0.9 all L1 = 0.895 +- 0.051 (in-sample avg dev_std = 0.083)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.54
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.527
SUFF++ for r=0.3 class 0 = 0.799 +- 0.046 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.3 class 1 = 0.801 +- 0.046 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.3 class 2 = 0.803 +- 0.046 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.3 all KL = 0.943 +- 0.046 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.3 all L1 = 0.801 +- 0.077 (in-sample avg dev_std = 0.176)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.543
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.538
SUFF++ for r=0.6 class 0 = 0.843 +- 0.037 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.6 class 1 = 0.835 +- 0.037 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.6 class 2 = 0.839 +- 0.037 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.6 all KL = 0.96 +- 0.037 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.6 all L1 = 0.838 +- 0.070 (in-sample avg dev_std = 0.145)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.555
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.552
SUFF++ for r=0.9 class 0 = 0.908 +- 0.015 (in-sample avg dev_std = 0.079)
SUFF++ for r=0.9 class 1 = 0.896 +- 0.015 (in-sample avg dev_std = 0.079)
SUFF++ for r=0.9 class 2 = 0.896 +- 0.015 (in-sample avg dev_std = 0.079)
SUFF++ for r=0.9 all KL = 0.985 +- 0.015 (in-sample avg dev_std = 0.079)
SUFF++ for r=0.9 all L1 = 0.899 +- 0.052 (in-sample avg dev_std = 0.079)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.728
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 797
Effective ratio: 0.314 +- 0.014
Model Accuracy over intervened graphs for r=0.3 =  0.724
NEC for r=0.3 class 0 = 0.21 +- 0.081 (in-sample avg dev_std = 0.153)
NEC for r=0.3 class 1 = 0.187 +- 0.081 (in-sample avg dev_std = 0.153)
NEC for r=0.3 class 2 = 0.228 +- 0.081 (in-sample avg dev_std = 0.153)
NEC for r=0.3 all KL = 0.065 +- 0.081 (in-sample avg dev_std = 0.153)
NEC for r=0.3 all L1 = 0.203 +- 0.109 (in-sample avg dev_std = 0.153)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.759
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 797
Effective ratio: 0.615 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.759
NEC for r=0.6 class 0 = 0.158 +- 0.057 (in-sample avg dev_std = 0.129)
NEC for r=0.6 class 1 = 0.145 +- 0.057 (in-sample avg dev_std = 0.129)
NEC for r=0.6 class 2 = 0.163 +- 0.057 (in-sample avg dev_std = 0.129)
NEC for r=0.6 all KL = 0.041 +- 0.057 (in-sample avg dev_std = 0.129)
NEC for r=0.6 all L1 = 0.153 +- 0.090 (in-sample avg dev_std = 0.129)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.784
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 797
Effective ratio: 0.915 +- 0.015
Model Accuracy over intervened graphs for r=0.9 =  0.773
NEC for r=0.9 class 0 = 0.096 +- 0.027 (in-sample avg dev_std = 0.083)
NEC for r=0.9 class 1 = 0.099 +- 0.027 (in-sample avg dev_std = 0.083)
NEC for r=0.9 class 2 = 0.106 +- 0.027 (in-sample avg dev_std = 0.083)
NEC for r=0.9 all KL = 0.018 +- 0.027 (in-sample avg dev_std = 0.083)
NEC for r=0.9 all L1 = 0.1 +- 0.067 (in-sample avg dev_std = 0.083)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.779
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 797
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.776
NEC for r=1.0 class 0 = 0.097 +- 0.030 (in-sample avg dev_std = 0.084)
NEC for r=1.0 class 1 = 0.091 +- 0.030 (in-sample avg dev_std = 0.084)
NEC for r=1.0 class 2 = 0.086 +- 0.030 (in-sample avg dev_std = 0.084)
NEC for r=1.0 all KL = 0.017 +- 0.030 (in-sample avg dev_std = 0.084)
NEC for r=1.0 all L1 = 0.091 +- 0.069 (in-sample avg dev_std = 0.084)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.65
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.641
NEC for r=0.3 class 0 = 0.217 +- 0.091 (in-sample avg dev_std = 0.160)
NEC for r=0.3 class 1 = 0.191 +- 0.091 (in-sample avg dev_std = 0.160)
NEC for r=0.3 class 2 = 0.228 +- 0.091 (in-sample avg dev_std = 0.160)
NEC for r=0.3 all KL = 0.068 +- 0.091 (in-sample avg dev_std = 0.160)
NEC for r=0.3 all L1 = 0.208 +- 0.119 (in-sample avg dev_std = 0.160)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.662
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.667
NEC for r=0.6 class 0 = 0.158 +- 0.064 (in-sample avg dev_std = 0.135)
NEC for r=0.6 class 1 = 0.142 +- 0.064 (in-sample avg dev_std = 0.135)
NEC for r=0.6 class 2 = 0.163 +- 0.064 (in-sample avg dev_std = 0.135)
NEC for r=0.6 all KL = 0.041 +- 0.064 (in-sample avg dev_std = 0.135)
NEC for r=0.6 all L1 = 0.152 +- 0.097 (in-sample avg dev_std = 0.135)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.682
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.674
NEC for r=0.9 class 0 = 0.122 +- 0.041 (in-sample avg dev_std = 0.088)
NEC for r=0.9 class 1 = 0.098 +- 0.041 (in-sample avg dev_std = 0.088)
NEC for r=0.9 class 2 = 0.112 +- 0.041 (in-sample avg dev_std = 0.088)
NEC for r=0.9 all KL = 0.021 +- 0.041 (in-sample avg dev_std = 0.088)
NEC for r=0.9 all L1 = 0.108 +- 0.081 (in-sample avg dev_std = 0.088)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.692
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.675
NEC for r=1.0 class 0 = 0.11 +- 0.039 (in-sample avg dev_std = 0.092)
NEC for r=1.0 class 1 = 0.094 +- 0.039 (in-sample avg dev_std = 0.092)
NEC for r=1.0 class 2 = 0.098 +- 0.039 (in-sample avg dev_std = 0.092)
NEC for r=1.0 all KL = 0.02 +- 0.039 (in-sample avg dev_std = 0.092)
NEC for r=1.0 all L1 = 0.099 +- 0.077 (in-sample avg dev_std = 0.092)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.577
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.585
NEC for r=0.3 class 0 = 0.214 +- 0.077 (in-sample avg dev_std = 0.141)
NEC for r=0.3 class 1 = 0.204 +- 0.077 (in-sample avg dev_std = 0.141)
NEC for r=0.3 class 2 = 0.219 +- 0.077 (in-sample avg dev_std = 0.141)
NEC for r=0.3 all KL = 0.063 +- 0.077 (in-sample avg dev_std = 0.141)
NEC for r=0.3 all L1 = 0.21 +- 0.105 (in-sample avg dev_std = 0.141)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.6
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.604
NEC for r=0.6 class 0 = 0.155 +- 0.042 (in-sample avg dev_std = 0.107)
NEC for r=0.6 class 1 = 0.152 +- 0.042 (in-sample avg dev_std = 0.107)
NEC for r=0.6 class 2 = 0.154 +- 0.042 (in-sample avg dev_std = 0.107)
NEC for r=0.6 all KL = 0.033 +- 0.042 (in-sample avg dev_std = 0.107)
NEC for r=0.6 all L1 = 0.153 +- 0.084 (in-sample avg dev_std = 0.107)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.603
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.596
NEC for r=0.9 class 0 = 0.107 +- 0.023 (in-sample avg dev_std = 0.074)
NEC for r=0.9 class 1 = 0.105 +- 0.023 (in-sample avg dev_std = 0.074)
NEC for r=0.9 class 2 = 0.109 +- 0.023 (in-sample avg dev_std = 0.074)
NEC for r=0.9 all KL = 0.016 +- 0.023 (in-sample avg dev_std = 0.074)
NEC for r=0.9 all L1 = 0.106 +- 0.063 (in-sample avg dev_std = 0.074)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.596
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.606
NEC for r=1.0 class 0 = 0.111 +- 0.029 (in-sample avg dev_std = 0.083)
NEC for r=1.0 class 1 = 0.109 +- 0.029 (in-sample avg dev_std = 0.083)
NEC for r=1.0 class 2 = 0.105 +- 0.029 (in-sample avg dev_std = 0.083)
NEC for r=1.0 all KL = 0.019 +- 0.029 (in-sample avg dev_std = 0.083)
NEC for r=1.0 all L1 = 0.109 +- 0.071 (in-sample avg dev_std = 0.083)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.54
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.55
NEC for r=0.3 class 0 = 0.196 +- 0.050 (in-sample avg dev_std = 0.130)
NEC for r=0.3 class 1 = 0.195 +- 0.050 (in-sample avg dev_std = 0.130)
NEC for r=0.3 class 2 = 0.194 +- 0.050 (in-sample avg dev_std = 0.130)
NEC for r=0.3 all KL = 0.05 +- 0.050 (in-sample avg dev_std = 0.130)
NEC for r=0.3 all L1 = 0.195 +- 0.094 (in-sample avg dev_std = 0.130)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.543
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.553
NEC for r=0.6 class 0 = 0.138 +- 0.034 (in-sample avg dev_std = 0.102)
NEC for r=0.6 class 1 = 0.148 +- 0.034 (in-sample avg dev_std = 0.102)
NEC for r=0.6 class 2 = 0.152 +- 0.034 (in-sample avg dev_std = 0.102)
NEC for r=0.6 all KL = 0.03 +- 0.034 (in-sample avg dev_std = 0.102)
NEC for r=0.6 all L1 = 0.146 +- 0.083 (in-sample avg dev_std = 0.102)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.555
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.553
NEC for r=0.9 class 0 = 0.089 +- 0.016 (in-sample avg dev_std = 0.070)
NEC for r=0.9 class 1 = 0.103 +- 0.016 (in-sample avg dev_std = 0.070)
NEC for r=0.9 class 2 = 0.109 +- 0.016 (in-sample avg dev_std = 0.070)
NEC for r=0.9 all KL = 0.014 +- 0.016 (in-sample avg dev_std = 0.070)
NEC for r=0.9 all L1 = 0.101 +- 0.061 (in-sample avg dev_std = 0.070)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.559
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.553
NEC for r=1.0 class 0 = 0.091 +- 0.018 (in-sample avg dev_std = 0.075)
NEC for r=1.0 class 1 = 0.101 +- 0.018 (in-sample avg dev_std = 0.075)
NEC for r=1.0 class 2 = 0.102 +- 0.018 (in-sample avg dev_std = 0.075)
NEC for r=1.0 all KL = 0.015 +- 0.018 (in-sample avg dev_std = 0.075)
NEC for r=1.0 all L1 = 0.099 +- 0.065 (in-sample avg dev_std = 0.075)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Thu May  2 23:30:44 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:44 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:46 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:46 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:47 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:49 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:30:51 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 6...
[0m[1;37mINFO[0m: [1mCheckpoint 6: 
-----------------------------------
Train ACCURACY: 0.7610
Train Loss: 0.5749
ID Validation ACCURACY: 0.6859
ID Validation Loss: 0.7960
ID Test ACCURACY: 0.6805
ID Test Loss: 0.7919
OOD Validation ACCURACY: 0.6275
OOD Validation Loss: 0.9112
OOD Test ACCURACY: 0.5765
OOD Test Loss: 1.0569

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 5...
[0m[1;37mINFO[0m: [1mCheckpoint 5: 
-----------------------------------
Train ACCURACY: 0.7506
Train Loss: 0.6182
ID Validation ACCURACY: 0.6823
ID Validation Loss: 0.8169
ID Test ACCURACY: 0.6697
ID Test Loss: 0.8107
OOD Validation ACCURACY: 0.6415
OOD Validation Loss: 0.8881
OOD Test ACCURACY: 0.5957
OOD Test Loss: 0.9882

[0m[1;37mINFO[0m: [1mChartInfo 0.6805 0.5765 0.6697 0.5957 0.6823 0.6415[0mGOODTwitter(2590)
Data example from train: Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
Label distribution from train: (tensor([0, 1, 2]), tensor([ 625, 1283,  682]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.685
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 797
Effective ratio: 0.314 +- 0.014
Model Accuracy over intervened graphs for r=0.3 =  0.651
SUFF++ for r=0.3 class 0 = 0.75 +- 0.089 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.3 class 1 = 0.812 +- 0.089 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.3 class 2 = 0.795 +- 0.089 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.3 all KL = 0.916 +- 0.089 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.3 all L1 = 0.793 +- 0.105 (in-sample avg dev_std = 0.239)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.729
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 797
Effective ratio: 0.615 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.713
SUFF++ for r=0.6 class 0 = 0.78 +- 0.079 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 class 1 = 0.846 +- 0.079 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 class 2 = 0.835 +- 0.079 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 all KL = 0.937 +- 0.079 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 all L1 = 0.827 +- 0.101 (in-sample avg dev_std = 0.195)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.758
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 794
Effective ratio: 0.915 +- 0.015
Model Accuracy over intervened graphs for r=0.9 =  0.753
SUFF++ for r=0.9 class 0 = 0.888 +- 0.025 (in-sample avg dev_std = 0.099)
SUFF++ for r=0.9 class 1 = 0.915 +- 0.025 (in-sample avg dev_std = 0.099)
SUFF++ for r=0.9 class 2 = 0.912 +- 0.025 (in-sample avg dev_std = 0.099)
SUFF++ for r=0.9 all KL = 0.982 +- 0.025 (in-sample avg dev_std = 0.099)
SUFF++ for r=0.9 all L1 = 0.908 +- 0.064 (in-sample avg dev_std = 0.099)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.631
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.608
SUFF++ for r=0.3 class 0 = 0.748 +- 0.102 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.3 class 1 = 0.81 +- 0.102 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.3 class 2 = 0.793 +- 0.102 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.3 all KL = 0.912 +- 0.102 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.3 all L1 = 0.79 +- 0.112 (in-sample avg dev_std = 0.238)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.659
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.645
SUFF++ for r=0.6 class 0 = 0.802 +- 0.073 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.6 class 1 = 0.848 +- 0.073 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.6 class 2 = 0.824 +- 0.073 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.6 all KL = 0.94 +- 0.073 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.6 all L1 = 0.83 +- 0.096 (in-sample avg dev_std = 0.197)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.682
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.681
SUFF++ for r=0.9 class 0 = 0.889 +- 0.026 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.9 class 1 = 0.908 +- 0.026 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.9 class 2 = 0.906 +- 0.026 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.9 all KL = 0.98 +- 0.026 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.9 all L1 = 0.903 +- 0.063 (in-sample avg dev_std = 0.108)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.596
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.593
SUFF++ for r=0.3 class 0 = 0.772 +- 0.075 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.3 class 1 = 0.806 +- 0.075 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.3 class 2 = 0.789 +- 0.075 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.3 all KL = 0.926 +- 0.075 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.3 all L1 = 0.794 +- 0.097 (in-sample avg dev_std = 0.205)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.621
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.617
SUFF++ for r=0.6 class 0 = 0.801 +- 0.057 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.6 class 1 = 0.839 +- 0.057 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.6 class 2 = 0.838 +- 0.057 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.6 all KL = 0.95 +- 0.057 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.6 all L1 = 0.829 +- 0.087 (in-sample avg dev_std = 0.159)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.619
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.628
SUFF++ for r=0.9 class 0 = 0.876 +- 0.029 (in-sample avg dev_std = 0.086)
SUFF++ for r=0.9 class 1 = 0.895 +- 0.029 (in-sample avg dev_std = 0.086)
SUFF++ for r=0.9 class 2 = 0.9 +- 0.029 (in-sample avg dev_std = 0.086)
SUFF++ for r=0.9 all KL = 0.981 +- 0.029 (in-sample avg dev_std = 0.086)
SUFF++ for r=0.9 all L1 = 0.891 +- 0.069 (in-sample avg dev_std = 0.086)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.56
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.545
SUFF++ for r=0.3 class 0 = 0.771 +- 0.072 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.3 class 1 = 0.795 +- 0.072 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.3 class 2 = 0.784 +- 0.072 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.3 all KL = 0.925 +- 0.072 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.3 all L1 = 0.786 +- 0.094 (in-sample avg dev_std = 0.205)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.571
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.572
SUFF++ for r=0.6 class 0 = 0.812 +- 0.052 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.6 class 1 = 0.831 +- 0.052 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.6 class 2 = 0.83 +- 0.052 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.6 all KL = 0.95 +- 0.052 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.6 all L1 = 0.826 +- 0.082 (in-sample avg dev_std = 0.164)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.572
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.577
SUFF++ for r=0.9 class 0 = 0.877 +- 0.023 (in-sample avg dev_std = 0.093)
SUFF++ for r=0.9 class 1 = 0.889 +- 0.023 (in-sample avg dev_std = 0.093)
SUFF++ for r=0.9 class 2 = 0.889 +- 0.023 (in-sample avg dev_std = 0.093)
SUFF++ for r=0.9 all KL = 0.979 +- 0.023 (in-sample avg dev_std = 0.093)
SUFF++ for r=0.9 all L1 = 0.886 +- 0.065 (in-sample avg dev_std = 0.093)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.685
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 797
Effective ratio: 0.314 +- 0.014
Model Accuracy over intervened graphs for r=0.3 =  0.682
NEC for r=0.3 class 0 = 0.23 +- 0.090 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 1 = 0.157 +- 0.090 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 2 = 0.209 +- 0.090 (in-sample avg dev_std = 0.145)
NEC for r=0.3 all KL = 0.062 +- 0.090 (in-sample avg dev_std = 0.145)
NEC for r=0.3 all L1 = 0.188 +- 0.125 (in-sample avg dev_std = 0.145)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.729
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 797
Effective ratio: 0.615 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.738
NEC for r=0.6 class 0 = 0.179 +- 0.058 (in-sample avg dev_std = 0.123)
NEC for r=0.6 class 1 = 0.129 +- 0.058 (in-sample avg dev_std = 0.123)
NEC for r=0.6 class 2 = 0.157 +- 0.058 (in-sample avg dev_std = 0.123)
NEC for r=0.6 all KL = 0.041 +- 0.058 (in-sample avg dev_std = 0.123)
NEC for r=0.6 all L1 = 0.148 +- 0.102 (in-sample avg dev_std = 0.123)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.759
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 797
Effective ratio: 0.915 +- 0.015
Model Accuracy over intervened graphs for r=0.9 =  0.761
NEC for r=0.9 class 0 = 0.113 +- 0.034 (in-sample avg dev_std = 0.085)
NEC for r=0.9 class 1 = 0.09 +- 0.034 (in-sample avg dev_std = 0.085)
NEC for r=0.9 class 2 = 0.104 +- 0.034 (in-sample avg dev_std = 0.085)
NEC for r=0.9 all KL = 0.02 +- 0.034 (in-sample avg dev_std = 0.085)
NEC for r=0.9 all L1 = 0.099 +- 0.075 (in-sample avg dev_std = 0.085)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.757
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 797
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.761
NEC for r=1.0 class 0 = 0.101 +- 0.030 (in-sample avg dev_std = 0.082)
NEC for r=1.0 class 1 = 0.087 +- 0.030 (in-sample avg dev_std = 0.082)
NEC for r=1.0 class 2 = 0.092 +- 0.030 (in-sample avg dev_std = 0.082)
NEC for r=1.0 all KL = 0.018 +- 0.030 (in-sample avg dev_std = 0.082)
NEC for r=1.0 all L1 = 0.092 +- 0.073 (in-sample avg dev_std = 0.082)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.631
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.623
NEC for r=0.3 class 0 = 0.231 +- 0.116 (in-sample avg dev_std = 0.163)
NEC for r=0.3 class 1 = 0.159 +- 0.116 (in-sample avg dev_std = 0.163)
NEC for r=0.3 class 2 = 0.221 +- 0.116 (in-sample avg dev_std = 0.163)
NEC for r=0.3 all KL = 0.072 +- 0.116 (in-sample avg dev_std = 0.163)
NEC for r=0.3 all L1 = 0.194 +- 0.133 (in-sample avg dev_std = 0.163)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.659
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.649
NEC for r=0.6 class 0 = 0.179 +- 0.063 (in-sample avg dev_std = 0.134)
NEC for r=0.6 class 1 = 0.126 +- 0.063 (in-sample avg dev_std = 0.134)
NEC for r=0.6 class 2 = 0.155 +- 0.063 (in-sample avg dev_std = 0.134)
NEC for r=0.6 all KL = 0.041 +- 0.063 (in-sample avg dev_std = 0.134)
NEC for r=0.6 all L1 = 0.147 +- 0.100 (in-sample avg dev_std = 0.134)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.684
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.67
NEC for r=0.9 class 0 = 0.125 +- 0.036 (in-sample avg dev_std = 0.091)
NEC for r=0.9 class 1 = 0.092 +- 0.036 (in-sample avg dev_std = 0.091)
NEC for r=0.9 class 2 = 0.118 +- 0.036 (in-sample avg dev_std = 0.091)
NEC for r=0.9 all KL = 0.021 +- 0.036 (in-sample avg dev_std = 0.091)
NEC for r=0.9 all L1 = 0.107 +- 0.080 (in-sample avg dev_std = 0.091)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.682
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.671
NEC for r=1.0 class 0 = 0.116 +- 0.044 (in-sample avg dev_std = 0.093)
NEC for r=1.0 class 1 = 0.09 +- 0.044 (in-sample avg dev_std = 0.093)
NEC for r=1.0 class 2 = 0.1 +- 0.044 (in-sample avg dev_std = 0.093)
NEC for r=1.0 all KL = 0.021 +- 0.044 (in-sample avg dev_std = 0.093)
NEC for r=1.0 all L1 = 0.099 +- 0.081 (in-sample avg dev_std = 0.093)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.596
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.614
NEC for r=0.3 class 0 = 0.233 +- 0.098 (in-sample avg dev_std = 0.146)
NEC for r=0.3 class 1 = 0.188 +- 0.098 (in-sample avg dev_std = 0.146)
NEC for r=0.3 class 2 = 0.22 +- 0.098 (in-sample avg dev_std = 0.146)
NEC for r=0.3 all KL = 0.071 +- 0.098 (in-sample avg dev_std = 0.146)
NEC for r=0.3 all L1 = 0.206 +- 0.125 (in-sample avg dev_std = 0.146)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.621
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.629
NEC for r=0.6 class 0 = 0.178 +- 0.062 (in-sample avg dev_std = 0.122)
NEC for r=0.6 class 1 = 0.159 +- 0.062 (in-sample avg dev_std = 0.122)
NEC for r=0.6 class 2 = 0.159 +- 0.062 (in-sample avg dev_std = 0.122)
NEC for r=0.6 all KL = 0.044 +- 0.062 (in-sample avg dev_std = 0.122)
NEC for r=0.6 all L1 = 0.164 +- 0.100 (in-sample avg dev_std = 0.122)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.619
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.63
NEC for r=0.9 class 0 = 0.132 +- 0.034 (in-sample avg dev_std = 0.087)
NEC for r=0.9 class 1 = 0.118 +- 0.034 (in-sample avg dev_std = 0.087)
NEC for r=0.9 class 2 = 0.118 +- 0.034 (in-sample avg dev_std = 0.087)
NEC for r=0.9 all KL = 0.024 +- 0.034 (in-sample avg dev_std = 0.087)
NEC for r=0.9 all L1 = 0.122 +- 0.079 (in-sample avg dev_std = 0.087)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.618
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.628
NEC for r=1.0 class 0 = 0.124 +- 0.029 (in-sample avg dev_std = 0.086)
NEC for r=1.0 class 1 = 0.109 +- 0.029 (in-sample avg dev_std = 0.086)
NEC for r=1.0 class 2 = 0.108 +- 0.029 (in-sample avg dev_std = 0.086)
NEC for r=1.0 all KL = 0.021 +- 0.029 (in-sample avg dev_std = 0.086)
NEC for r=1.0 all L1 = 0.112 +- 0.075 (in-sample avg dev_std = 0.086)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.56
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.579
NEC for r=0.3 class 0 = 0.229 +- 0.094 (in-sample avg dev_std = 0.150)
NEC for r=0.3 class 1 = 0.206 +- 0.094 (in-sample avg dev_std = 0.150)
NEC for r=0.3 class 2 = 0.235 +- 0.094 (in-sample avg dev_std = 0.150)
NEC for r=0.3 all KL = 0.075 +- 0.094 (in-sample avg dev_std = 0.150)
NEC for r=0.3 all L1 = 0.219 +- 0.122 (in-sample avg dev_std = 0.150)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.571
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.58
NEC for r=0.6 class 0 = 0.183 +- 0.058 (in-sample avg dev_std = 0.126)
NEC for r=0.6 class 1 = 0.165 +- 0.058 (in-sample avg dev_std = 0.126)
NEC for r=0.6 class 2 = 0.172 +- 0.058 (in-sample avg dev_std = 0.126)
NEC for r=0.6 all KL = 0.046 +- 0.058 (in-sample avg dev_std = 0.126)
NEC for r=0.6 all L1 = 0.172 +- 0.102 (in-sample avg dev_std = 0.126)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.572
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.581
NEC for r=0.9 class 0 = 0.127 +- 0.030 (in-sample avg dev_std = 0.088)
NEC for r=0.9 class 1 = 0.117 +- 0.030 (in-sample avg dev_std = 0.088)
NEC for r=0.9 class 2 = 0.126 +- 0.030 (in-sample avg dev_std = 0.088)
NEC for r=0.9 all KL = 0.023 +- 0.030 (in-sample avg dev_std = 0.088)
NEC for r=0.9 all L1 = 0.122 +- 0.076 (in-sample avg dev_std = 0.088)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.574
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.57
NEC for r=1.0 class 0 = 0.115 +- 0.024 (in-sample avg dev_std = 0.081)
NEC for r=1.0 class 1 = 0.108 +- 0.024 (in-sample avg dev_std = 0.081)
NEC for r=1.0 class 2 = 0.109 +- 0.024 (in-sample avg dev_std = 0.081)
NEC for r=1.0 all KL = 0.02 +- 0.024 (in-sample avg dev_std = 0.081)
NEC for r=1.0 all L1 = 0.11 +- 0.072 (in-sample avg dev_std = 0.081)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Thu May  2 23:37:30 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:30 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:32 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:33 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:33 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:35 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:37:37 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 26...
[0m[1;37mINFO[0m: [1mCheckpoint 26: 
-----------------------------------
Train ACCURACY: 0.9710
Train Loss: 0.0812
ID Validation ACCURACY: 0.6986
ID Validation Loss: 1.1517
ID Test ACCURACY: 0.6751
ID Test Loss: 1.3339
OOD Validation ACCURACY: 0.6224
OOD Validation Loss: 1.4258
OOD Test ACCURACY: 0.5765
OOD Test Loss: 1.7044

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 8...
[0m[1;37mINFO[0m: [1mCheckpoint 8: 
-----------------------------------
Train ACCURACY: 0.8127
Train Loss: 0.4766
ID Validation ACCURACY: 0.6859
ID Validation Loss: 0.7569
ID Test ACCURACY: 0.6895
ID Test Loss: 0.7870
OOD Validation ACCURACY: 0.6415
OOD Validation Loss: 0.8925
OOD Test ACCURACY: 0.6019
OOD Test Loss: 0.9865

[0m[1;37mINFO[0m: [1mChartInfo 0.6751 0.5765 0.6895 0.6019 0.6859 0.6415[0mGOODTwitter(2590)
Data example from train: Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
Label distribution from train: (tensor([0, 1, 2]), tensor([ 625, 1283,  682]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.881
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 797
Effective ratio: 0.314 +- 0.014
Model Accuracy over intervened graphs for r=0.3 =  0.794
SUFF++ for r=0.3 class 0 = 0.687 +- 0.262 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.3 class 1 = 0.815 +- 0.262 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.3 class 2 = 0.631 +- 0.262 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.3 all KL = 0.676 +- 0.262 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.3 all L1 = 0.736 +- 0.199 (in-sample avg dev_std = 0.476)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.937
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 797
Effective ratio: 0.615 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.89
SUFF++ for r=0.6 class 0 = 0.805 +- 0.180 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.6 class 1 = 0.891 +- 0.180 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.6 class 2 = 0.794 +- 0.180 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.6 all KL = 0.845 +- 0.180 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.6 all L1 = 0.845 +- 0.155 (in-sample avg dev_std = 0.305)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.961
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 794
Effective ratio: 0.915 +- 0.015
Model Accuracy over intervened graphs for r=0.9 =  0.949
SUFF++ for r=0.9 class 0 = 0.898 +- 0.082 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.9 class 1 = 0.96 +- 0.082 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.9 class 2 = 0.933 +- 0.082 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.9 all KL = 0.963 +- 0.082 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.9 all L1 = 0.938 +- 0.097 (in-sample avg dev_std = 0.147)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.655
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.607
SUFF++ for r=0.3 class 0 = 0.679 +- 0.258 (in-sample avg dev_std = 0.497)
SUFF++ for r=0.3 class 1 = 0.727 +- 0.258 (in-sample avg dev_std = 0.497)
SUFF++ for r=0.3 class 2 = 0.679 +- 0.258 (in-sample avg dev_std = 0.497)
SUFF++ for r=0.3 all KL = 0.644 +- 0.258 (in-sample avg dev_std = 0.497)
SUFF++ for r=0.3 all L1 = 0.702 +- 0.197 (in-sample avg dev_std = 0.497)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.679
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.651
SUFF++ for r=0.6 class 0 = 0.765 +- 0.189 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.6 class 1 = 0.804 +- 0.189 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.6 class 2 = 0.775 +- 0.189 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.6 all KL = 0.815 +- 0.189 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.6 all L1 = 0.786 +- 0.181 (in-sample avg dev_std = 0.338)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.682
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.676
SUFF++ for r=0.9 class 0 = 0.887 +- 0.095 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.9 class 1 = 0.895 +- 0.095 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.9 class 2 = 0.879 +- 0.095 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.9 all KL = 0.944 +- 0.095 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.9 all L1 = 0.889 +- 0.131 (in-sample avg dev_std = 0.184)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.585
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.568
SUFF++ for r=0.3 class 0 = 0.733 +- 0.255 (in-sample avg dev_std = 0.449)
SUFF++ for r=0.3 class 1 = 0.716 +- 0.255 (in-sample avg dev_std = 0.449)
SUFF++ for r=0.3 class 2 = 0.657 +- 0.255 (in-sample avg dev_std = 0.449)
SUFF++ for r=0.3 all KL = 0.687 +- 0.255 (in-sample avg dev_std = 0.449)
SUFF++ for r=0.3 all L1 = 0.708 +- 0.206 (in-sample avg dev_std = 0.449)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.6
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.596
SUFF++ for r=0.6 class 0 = 0.792 +- 0.172 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.6 class 1 = 0.801 +- 0.172 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.6 class 2 = 0.743 +- 0.172 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.6 all KL = 0.836 +- 0.172 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.6 all L1 = 0.786 +- 0.174 (in-sample avg dev_std = 0.317)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.618
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.625
SUFF++ for r=0.9 class 0 = 0.871 +- 0.091 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.9 class 1 = 0.875 +- 0.091 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.9 class 2 = 0.863 +- 0.091 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.9 all KL = 0.944 +- 0.091 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.9 all L1 = 0.871 +- 0.131 (in-sample avg dev_std = 0.162)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.545
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.516
SUFF++ for r=0.3 class 0 = 0.733 +- 0.228 (in-sample avg dev_std = 0.436)
SUFF++ for r=0.3 class 1 = 0.69 +- 0.228 (in-sample avg dev_std = 0.436)
SUFF++ for r=0.3 class 2 = 0.642 +- 0.228 (in-sample avg dev_std = 0.436)
SUFF++ for r=0.3 all KL = 0.694 +- 0.228 (in-sample avg dev_std = 0.436)
SUFF++ for r=0.3 all L1 = 0.69 +- 0.199 (in-sample avg dev_std = 0.436)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.551
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.542
SUFF++ for r=0.6 class 0 = 0.796 +- 0.165 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.6 class 1 = 0.77 +- 0.165 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.6 class 2 = 0.742 +- 0.165 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.6 all KL = 0.823 +- 0.165 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.6 all L1 = 0.77 +- 0.168 (in-sample avg dev_std = 0.324)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.566
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.57
SUFF++ for r=0.9 class 0 = 0.871 +- 0.083 (in-sample avg dev_std = 0.173)
SUFF++ for r=0.9 class 1 = 0.867 +- 0.083 (in-sample avg dev_std = 0.173)
SUFF++ for r=0.9 class 2 = 0.854 +- 0.083 (in-sample avg dev_std = 0.173)
SUFF++ for r=0.9 all KL = 0.941 +- 0.083 (in-sample avg dev_std = 0.173)
SUFF++ for r=0.9 all L1 = 0.865 +- 0.131 (in-sample avg dev_std = 0.173)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.881
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 797
Effective ratio: 0.314 +- 0.014
Model Accuracy over intervened graphs for r=0.3 =  0.871
NEC for r=0.3 class 0 = 0.264 +- 0.237 (in-sample avg dev_std = 0.264)
NEC for r=0.3 class 1 = 0.12 +- 0.237 (in-sample avg dev_std = 0.264)
NEC for r=0.3 class 2 = 0.262 +- 0.237 (in-sample avg dev_std = 0.264)
NEC for r=0.3 all KL = 0.172 +- 0.237 (in-sample avg dev_std = 0.264)
NEC for r=0.3 all L1 = 0.192 +- 0.212 (in-sample avg dev_std = 0.264)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.937
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 797
Effective ratio: 0.615 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.93
NEC for r=0.6 class 0 = 0.174 +- 0.151 (in-sample avg dev_std = 0.172)
NEC for r=0.6 class 1 = 0.068 +- 0.151 (in-sample avg dev_std = 0.172)
NEC for r=0.6 class 2 = 0.141 +- 0.151 (in-sample avg dev_std = 0.172)
NEC for r=0.6 all KL = 0.081 +- 0.151 (in-sample avg dev_std = 0.172)
NEC for r=0.6 all L1 = 0.112 +- 0.151 (in-sample avg dev_std = 0.172)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.961
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 797
Effective ratio: 0.915 +- 0.015
Model Accuracy over intervened graphs for r=0.9 =  0.953
NEC for r=0.9 class 0 = 0.105 +- 0.082 (in-sample avg dev_std = 0.117)
NEC for r=0.9 class 1 = 0.045 +- 0.082 (in-sample avg dev_std = 0.117)
NEC for r=0.9 class 2 = 0.069 +- 0.082 (in-sample avg dev_std = 0.117)
NEC for r=0.9 all KL = 0.034 +- 0.082 (in-sample avg dev_std = 0.117)
NEC for r=0.9 all L1 = 0.066 +- 0.108 (in-sample avg dev_std = 0.117)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.964
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 797
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.956
NEC for r=1.0 class 0 = 0.094 +- 0.090 (in-sample avg dev_std = 0.116)
NEC for r=1.0 class 1 = 0.037 +- 0.090 (in-sample avg dev_std = 0.116)
NEC for r=1.0 class 2 = 0.055 +- 0.090 (in-sample avg dev_std = 0.116)
NEC for r=1.0 all KL = 0.031 +- 0.090 (in-sample avg dev_std = 0.116)
NEC for r=1.0 all L1 = 0.056 +- 0.103 (in-sample avg dev_std = 0.116)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.655
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.651
NEC for r=0.3 class 0 = 0.273 +- 0.277 (in-sample avg dev_std = 0.328)
NEC for r=0.3 class 1 = 0.227 +- 0.277 (in-sample avg dev_std = 0.328)
NEC for r=0.3 class 2 = 0.256 +- 0.277 (in-sample avg dev_std = 0.328)
NEC for r=0.3 all KL = 0.235 +- 0.277 (in-sample avg dev_std = 0.328)
NEC for r=0.3 all L1 = 0.246 +- 0.235 (in-sample avg dev_std = 0.328)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.679
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.662
NEC for r=0.6 class 0 = 0.222 +- 0.170 (in-sample avg dev_std = 0.243)
NEC for r=0.6 class 1 = 0.167 +- 0.170 (in-sample avg dev_std = 0.243)
NEC for r=0.6 class 2 = 0.166 +- 0.170 (in-sample avg dev_std = 0.243)
NEC for r=0.6 all KL = 0.122 +- 0.170 (in-sample avg dev_std = 0.243)
NEC for r=0.6 all L1 = 0.18 +- 0.189 (in-sample avg dev_std = 0.243)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.682
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.672
NEC for r=0.9 class 0 = 0.142 +- 0.114 (in-sample avg dev_std = 0.177)
NEC for r=0.9 class 1 = 0.115 +- 0.114 (in-sample avg dev_std = 0.177)
NEC for r=0.9 class 2 = 0.129 +- 0.114 (in-sample avg dev_std = 0.177)
NEC for r=0.9 all KL = 0.064 +- 0.114 (in-sample avg dev_std = 0.177)
NEC for r=0.9 all L1 = 0.125 +- 0.151 (in-sample avg dev_std = 0.177)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.695
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.68
NEC for r=1.0 class 0 = 0.13 +- 0.111 (in-sample avg dev_std = 0.165)
NEC for r=1.0 class 1 = 0.105 +- 0.111 (in-sample avg dev_std = 0.165)
NEC for r=1.0 class 2 = 0.114 +- 0.111 (in-sample avg dev_std = 0.165)
NEC for r=1.0 all KL = 0.057 +- 0.111 (in-sample avg dev_std = 0.165)
NEC for r=1.0 all L1 = 0.114 +- 0.142 (in-sample avg dev_std = 0.165)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.585
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.59
NEC for r=0.3 class 0 = 0.316 +- 0.278 (in-sample avg dev_std = 0.353)
NEC for r=0.3 class 1 = 0.27 +- 0.278 (in-sample avg dev_std = 0.353)
NEC for r=0.3 class 2 = 0.298 +- 0.278 (in-sample avg dev_std = 0.353)
NEC for r=0.3 all KL = 0.28 +- 0.278 (in-sample avg dev_std = 0.353)
NEC for r=0.3 all L1 = 0.288 +- 0.234 (in-sample avg dev_std = 0.353)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.6
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.61
NEC for r=0.6 class 0 = 0.226 +- 0.186 (in-sample avg dev_std = 0.266)
NEC for r=0.6 class 1 = 0.2 +- 0.186 (in-sample avg dev_std = 0.266)
NEC for r=0.6 class 2 = 0.233 +- 0.186 (in-sample avg dev_std = 0.266)
NEC for r=0.6 all KL = 0.153 +- 0.186 (in-sample avg dev_std = 0.266)
NEC for r=0.6 all L1 = 0.213 +- 0.190 (in-sample avg dev_std = 0.266)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.618
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.619
NEC for r=0.9 class 0 = 0.171 +- 0.125 (in-sample avg dev_std = 0.182)
NEC for r=0.9 class 1 = 0.147 +- 0.125 (in-sample avg dev_std = 0.182)
NEC for r=0.9 class 2 = 0.169 +- 0.125 (in-sample avg dev_std = 0.182)
NEC for r=0.9 all KL = 0.082 +- 0.125 (in-sample avg dev_std = 0.182)
NEC for r=0.9 all L1 = 0.158 +- 0.162 (in-sample avg dev_std = 0.182)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.627
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.615
NEC for r=1.0 class 0 = 0.157 +- 0.116 (in-sample avg dev_std = 0.177)
NEC for r=1.0 class 1 = 0.14 +- 0.116 (in-sample avg dev_std = 0.177)
NEC for r=1.0 class 2 = 0.143 +- 0.116 (in-sample avg dev_std = 0.177)
NEC for r=1.0 all KL = 0.073 +- 0.116 (in-sample avg dev_std = 0.177)
NEC for r=1.0 all L1 = 0.145 +- 0.154 (in-sample avg dev_std = 0.177)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.545
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.539
NEC for r=0.3 class 0 = 0.265 +- 0.243 (in-sample avg dev_std = 0.325)
NEC for r=0.3 class 1 = 0.283 +- 0.243 (in-sample avg dev_std = 0.325)
NEC for r=0.3 class 2 = 0.306 +- 0.243 (in-sample avg dev_std = 0.325)
NEC for r=0.3 all KL = 0.244 +- 0.243 (in-sample avg dev_std = 0.325)
NEC for r=0.3 all L1 = 0.284 +- 0.221 (in-sample avg dev_std = 0.325)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.551
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.557
NEC for r=0.6 class 0 = 0.209 +- 0.172 (in-sample avg dev_std = 0.245)
NEC for r=0.6 class 1 = 0.205 +- 0.172 (in-sample avg dev_std = 0.245)
NEC for r=0.6 class 2 = 0.228 +- 0.172 (in-sample avg dev_std = 0.245)
NEC for r=0.6 all KL = 0.138 +- 0.172 (in-sample avg dev_std = 0.245)
NEC for r=0.6 all L1 = 0.212 +- 0.192 (in-sample avg dev_std = 0.245)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.566
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.575
NEC for r=0.9 class 0 = 0.157 +- 0.109 (in-sample avg dev_std = 0.182)
NEC for r=0.9 class 1 = 0.14 +- 0.109 (in-sample avg dev_std = 0.182)
NEC for r=0.9 class 2 = 0.169 +- 0.109 (in-sample avg dev_std = 0.182)
NEC for r=0.9 all KL = 0.073 +- 0.109 (in-sample avg dev_std = 0.182)
NEC for r=0.9 all L1 = 0.151 +- 0.151 (in-sample avg dev_std = 0.182)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.565
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.575
NEC for r=1.0 class 0 = 0.146 +- 0.108 (in-sample avg dev_std = 0.174)
NEC for r=1.0 class 1 = 0.135 +- 0.108 (in-sample avg dev_std = 0.174)
NEC for r=1.0 class 2 = 0.159 +- 0.108 (in-sample avg dev_std = 0.174)
NEC for r=1.0 all KL = 0.069 +- 0.108 (in-sample avg dev_std = 0.174)
NEC for r=1.0 all L1 = 0.143 +- 0.152 (in-sample avg dev_std = 0.174)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Thu May  2 23:44:19 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:19 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:22 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:22 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:23 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:25 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:44:27 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 7...
[0m[1;37mINFO[0m: [1mCheckpoint 7: 
-----------------------------------
Train ACCURACY: 0.7811
Train Loss: 0.5364
ID Validation ACCURACY: 0.7112
ID Validation Loss: 0.7696
ID Test ACCURACY: 0.6877
ID Test Loss: 0.8116
OOD Validation ACCURACY: 0.6196
OOD Validation Loss: 0.9158
OOD Test ACCURACY: 0.5614
OOD Test Loss: 1.0939

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 21...
[0m[1;37mINFO[0m: [1mCheckpoint 21: 
-----------------------------------
Train ACCURACY: 0.9498
Train Loss: 0.1580
ID Validation ACCURACY: 0.6877
ID Validation Loss: 0.9837
ID Test ACCURACY: 0.6751
ID Test Loss: 1.0665
OOD Validation ACCURACY: 0.6308
OOD Validation Loss: 1.1486
OOD Test ACCURACY: 0.5827
OOD Test Loss: 1.3760

[0m[1;37mINFO[0m: [1mChartInfo 0.6877 0.5614 0.6751 0.5827 0.6877 0.6308[0mGOODTwitter(2590)
Data example from train: Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
Label distribution from train: (tensor([0, 1, 2]), tensor([ 625, 1283,  682]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.661
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 797
Effective ratio: 0.314 +- 0.014
Model Accuracy over intervened graphs for r=0.3 =  0.639
SUFF++ for r=0.3 class 0 = 0.806 +- 0.093 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.3 class 1 = 0.81 +- 0.093 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.3 class 2 = 0.758 +- 0.093 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.3 all KL = 0.914 +- 0.093 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.3 all L1 = 0.796 +- 0.104 (in-sample avg dev_std = 0.245)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.747
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 797
Effective ratio: 0.615 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.718
SUFF++ for r=0.6 class 0 = 0.844 +- 0.064 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.6 class 1 = 0.847 +- 0.064 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.6 class 2 = 0.793 +- 0.064 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.6 all KL = 0.943 +- 0.064 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.6 all L1 = 0.832 +- 0.092 (in-sample avg dev_std = 0.185)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.781
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 794
Effective ratio: 0.915 +- 0.015
Model Accuracy over intervened graphs for r=0.9 =  0.772
SUFF++ for r=0.9 class 0 = 0.919 +- 0.022 (in-sample avg dev_std = 0.102)
SUFF++ for r=0.9 class 1 = 0.915 +- 0.022 (in-sample avg dev_std = 0.102)
SUFF++ for r=0.9 class 2 = 0.882 +- 0.022 (in-sample avg dev_std = 0.102)
SUFF++ for r=0.9 all KL = 0.982 +- 0.022 (in-sample avg dev_std = 0.102)
SUFF++ for r=0.9 all L1 = 0.907 +- 0.059 (in-sample avg dev_std = 0.102)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.613
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.571
SUFF++ for r=0.3 class 0 = 0.79 +- 0.106 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.3 class 1 = 0.809 +- 0.106 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.3 class 2 = 0.76 +- 0.106 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.3 all KL = 0.907 +- 0.106 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.3 all L1 = 0.791 +- 0.108 (in-sample avg dev_std = 0.249)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.681
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.632
SUFF++ for r=0.6 class 0 = 0.844 +- 0.073 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 class 1 = 0.839 +- 0.073 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 class 2 = 0.798 +- 0.073 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 all KL = 0.939 +- 0.073 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 all L1 = 0.829 +- 0.093 (in-sample avg dev_std = 0.195)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.708
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.692
SUFF++ for r=0.9 class 0 = 0.9 +- 0.030 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 class 1 = 0.91 +- 0.030 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 class 2 = 0.888 +- 0.030 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 all KL = 0.98 +- 0.030 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 all L1 = 0.902 +- 0.060 (in-sample avg dev_std = 0.113)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.613
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.582
SUFF++ for r=0.3 class 0 = 0.811 +- 0.083 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.3 class 1 = 0.803 +- 0.083 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.3 class 2 = 0.767 +- 0.083 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.3 all KL = 0.919 +- 0.083 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.3 all L1 = 0.797 +- 0.099 (in-sample avg dev_std = 0.220)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.619
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.612
SUFF++ for r=0.6 class 0 = 0.854 +- 0.047 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.6 class 1 = 0.843 +- 0.047 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.6 class 2 = 0.816 +- 0.047 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.6 all KL = 0.955 +- 0.047 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.6 all L1 = 0.84 +- 0.083 (in-sample avg dev_std = 0.155)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.619
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.618
SUFF++ for r=0.9 class 0 = 0.898 +- 0.027 (in-sample avg dev_std = 0.087)
SUFF++ for r=0.9 class 1 = 0.902 +- 0.027 (in-sample avg dev_std = 0.087)
SUFF++ for r=0.9 class 2 = 0.888 +- 0.027 (in-sample avg dev_std = 0.087)
SUFF++ for r=0.9 all KL = 0.982 +- 0.027 (in-sample avg dev_std = 0.087)
SUFF++ for r=0.9 all L1 = 0.898 +- 0.066 (in-sample avg dev_std = 0.087)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.53
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.509
SUFF++ for r=0.3 class 0 = 0.827 +- 0.086 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.3 class 1 = 0.791 +- 0.086 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.3 class 2 = 0.749 +- 0.086 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.3 all KL = 0.914 +- 0.086 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.3 all L1 = 0.79 +- 0.104 (in-sample avg dev_std = 0.232)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.554
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.542
SUFF++ for r=0.6 class 0 = 0.854 +- 0.055 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 class 1 = 0.828 +- 0.055 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 class 2 = 0.813 +- 0.055 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 all KL = 0.948 +- 0.055 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 all L1 = 0.831 +- 0.086 (in-sample avg dev_std = 0.176)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.567
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.564
SUFF++ for r=0.9 class 0 = 0.912 +- 0.021 (in-sample avg dev_std = 0.083)
SUFF++ for r=0.9 class 1 = 0.897 +- 0.021 (in-sample avg dev_std = 0.083)
SUFF++ for r=0.9 class 2 = 0.894 +- 0.021 (in-sample avg dev_std = 0.083)
SUFF++ for r=0.9 all KL = 0.983 +- 0.021 (in-sample avg dev_std = 0.083)
SUFF++ for r=0.9 all L1 = 0.9 +- 0.061 (in-sample avg dev_std = 0.083)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.661
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 797
Effective ratio: 0.314 +- 0.014
Model Accuracy over intervened graphs for r=0.3 =  0.677
NEC for r=0.3 class 0 = 0.195 +- 0.091 (in-sample avg dev_std = 0.139)
NEC for r=0.3 class 1 = 0.16 +- 0.091 (in-sample avg dev_std = 0.139)
NEC for r=0.3 class 2 = 0.206 +- 0.091 (in-sample avg dev_std = 0.139)
NEC for r=0.3 all KL = 0.06 +- 0.091 (in-sample avg dev_std = 0.139)
NEC for r=0.3 all L1 = 0.18 +- 0.119 (in-sample avg dev_std = 0.139)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.747
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 797
Effective ratio: 0.615 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.727
NEC for r=0.6 class 0 = 0.145 +- 0.061 (in-sample avg dev_std = 0.120)
NEC for r=0.6 class 1 = 0.118 +- 0.061 (in-sample avg dev_std = 0.120)
NEC for r=0.6 class 2 = 0.167 +- 0.061 (in-sample avg dev_std = 0.120)
NEC for r=0.6 all KL = 0.038 +- 0.061 (in-sample avg dev_std = 0.120)
NEC for r=0.6 all L1 = 0.138 +- 0.093 (in-sample avg dev_std = 0.120)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.782
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 797
Effective ratio: 0.915 +- 0.015
Model Accuracy over intervened graphs for r=0.9 =  0.774
NEC for r=0.9 class 0 = 0.105 +- 0.053 (in-sample avg dev_std = 0.086)
NEC for r=0.9 class 1 = 0.093 +- 0.053 (in-sample avg dev_std = 0.086)
NEC for r=0.9 class 2 = 0.115 +- 0.053 (in-sample avg dev_std = 0.086)
NEC for r=0.9 all KL = 0.022 +- 0.053 (in-sample avg dev_std = 0.086)
NEC for r=0.9 all L1 = 0.102 +- 0.080 (in-sample avg dev_std = 0.086)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.783
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 797
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.779
NEC for r=1.0 class 0 = 0.096 +- 0.053 (in-sample avg dev_std = 0.090)
NEC for r=1.0 class 1 = 0.093 +- 0.053 (in-sample avg dev_std = 0.090)
NEC for r=1.0 class 2 = 0.105 +- 0.053 (in-sample avg dev_std = 0.090)
NEC for r=1.0 all KL = 0.022 +- 0.053 (in-sample avg dev_std = 0.090)
NEC for r=1.0 all L1 = 0.097 +- 0.079 (in-sample avg dev_std = 0.090)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.613
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.606
NEC for r=0.3 class 0 = 0.209 +- 0.107 (in-sample avg dev_std = 0.161)
NEC for r=0.3 class 1 = 0.164 +- 0.107 (in-sample avg dev_std = 0.161)
NEC for r=0.3 class 2 = 0.202 +- 0.107 (in-sample avg dev_std = 0.161)
NEC for r=0.3 all KL = 0.066 +- 0.107 (in-sample avg dev_std = 0.161)
NEC for r=0.3 all L1 = 0.186 +- 0.121 (in-sample avg dev_std = 0.161)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.681
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.655
NEC for r=0.6 class 0 = 0.158 +- 0.064 (in-sample avg dev_std = 0.131)
NEC for r=0.6 class 1 = 0.132 +- 0.064 (in-sample avg dev_std = 0.131)
NEC for r=0.6 class 2 = 0.165 +- 0.064 (in-sample avg dev_std = 0.131)
NEC for r=0.6 all KL = 0.042 +- 0.064 (in-sample avg dev_std = 0.131)
NEC for r=0.6 all L1 = 0.147 +- 0.099 (in-sample avg dev_std = 0.131)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.71
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.688
NEC for r=0.9 class 0 = 0.11 +- 0.035 (in-sample avg dev_std = 0.089)
NEC for r=0.9 class 1 = 0.093 +- 0.035 (in-sample avg dev_std = 0.089)
NEC for r=0.9 class 2 = 0.116 +- 0.035 (in-sample avg dev_std = 0.089)
NEC for r=0.9 all KL = 0.021 +- 0.035 (in-sample avg dev_std = 0.089)
NEC for r=0.9 all L1 = 0.104 +- 0.073 (in-sample avg dev_std = 0.089)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.708
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.693
NEC for r=1.0 class 0 = 0.107 +- 0.042 (in-sample avg dev_std = 0.092)
NEC for r=1.0 class 1 = 0.087 +- 0.042 (in-sample avg dev_std = 0.092)
NEC for r=1.0 class 2 = 0.112 +- 0.042 (in-sample avg dev_std = 0.092)
NEC for r=1.0 all KL = 0.021 +- 0.042 (in-sample avg dev_std = 0.092)
NEC for r=1.0 all L1 = 0.099 +- 0.078 (in-sample avg dev_std = 0.092)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.613
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.607
NEC for r=0.3 class 0 = 0.213 +- 0.109 (in-sample avg dev_std = 0.151)
NEC for r=0.3 class 1 = 0.187 +- 0.109 (in-sample avg dev_std = 0.151)
NEC for r=0.3 class 2 = 0.212 +- 0.109 (in-sample avg dev_std = 0.151)
NEC for r=0.3 all KL = 0.076 +- 0.109 (in-sample avg dev_std = 0.151)
NEC for r=0.3 all L1 = 0.199 +- 0.116 (in-sample avg dev_std = 0.151)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.619
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.623
NEC for r=0.6 class 0 = 0.149 +- 0.062 (in-sample avg dev_std = 0.117)
NEC for r=0.6 class 1 = 0.147 +- 0.062 (in-sample avg dev_std = 0.117)
NEC for r=0.6 class 2 = 0.167 +- 0.062 (in-sample avg dev_std = 0.117)
NEC for r=0.6 all KL = 0.042 +- 0.062 (in-sample avg dev_std = 0.117)
NEC for r=0.6 all L1 = 0.152 +- 0.094 (in-sample avg dev_std = 0.117)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.619
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.629
NEC for r=0.9 class 0 = 0.119 +- 0.034 (in-sample avg dev_std = 0.085)
NEC for r=0.9 class 1 = 0.11 +- 0.034 (in-sample avg dev_std = 0.085)
NEC for r=0.9 class 2 = 0.119 +- 0.034 (in-sample avg dev_std = 0.085)
NEC for r=0.9 all KL = 0.023 +- 0.034 (in-sample avg dev_std = 0.085)
NEC for r=0.9 all L1 = 0.114 +- 0.080 (in-sample avg dev_std = 0.085)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.621
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.623
NEC for r=1.0 class 0 = 0.107 +- 0.033 (in-sample avg dev_std = 0.084)
NEC for r=1.0 class 1 = 0.101 +- 0.033 (in-sample avg dev_std = 0.084)
NEC for r=1.0 class 2 = 0.11 +- 0.033 (in-sample avg dev_std = 0.084)
NEC for r=1.0 all KL = 0.02 +- 0.033 (in-sample avg dev_std = 0.084)
NEC for r=1.0 all L1 = 0.104 +- 0.078 (in-sample avg dev_std = 0.084)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.53
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.535
NEC for r=0.3 class 0 = 0.196 +- 0.109 (in-sample avg dev_std = 0.154)
NEC for r=0.3 class 1 = 0.199 +- 0.109 (in-sample avg dev_std = 0.154)
NEC for r=0.3 class 2 = 0.233 +- 0.109 (in-sample avg dev_std = 0.154)
NEC for r=0.3 all KL = 0.079 +- 0.109 (in-sample avg dev_std = 0.154)
NEC for r=0.3 all L1 = 0.206 +- 0.121 (in-sample avg dev_std = 0.154)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.554
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.558
NEC for r=0.6 class 0 = 0.147 +- 0.062 (in-sample avg dev_std = 0.116)
NEC for r=0.6 class 1 = 0.158 +- 0.062 (in-sample avg dev_std = 0.116)
NEC for r=0.6 class 2 = 0.174 +- 0.062 (in-sample avg dev_std = 0.116)
NEC for r=0.6 all KL = 0.044 +- 0.062 (in-sample avg dev_std = 0.116)
NEC for r=0.6 all L1 = 0.159 +- 0.100 (in-sample avg dev_std = 0.116)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.567
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.572
NEC for r=0.9 class 0 = 0.102 +- 0.029 (in-sample avg dev_std = 0.084)
NEC for r=0.9 class 1 = 0.119 +- 0.029 (in-sample avg dev_std = 0.084)
NEC for r=0.9 class 2 = 0.119 +- 0.029 (in-sample avg dev_std = 0.084)
NEC for r=0.9 all KL = 0.022 +- 0.029 (in-sample avg dev_std = 0.084)
NEC for r=0.9 all L1 = 0.114 +- 0.077 (in-sample avg dev_std = 0.084)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.567
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.569
NEC for r=1.0 class 0 = 0.094 +- 0.028 (in-sample avg dev_std = 0.084)
NEC for r=1.0 class 1 = 0.11 +- 0.028 (in-sample avg dev_std = 0.084)
NEC for r=1.0 class 2 = 0.114 +- 0.028 (in-sample avg dev_std = 0.084)
NEC for r=1.0 all KL = 0.02 +- 0.028 (in-sample avg dev_std = 0.084)
NEC for r=1.0 all L1 = 0.107 +- 0.076 (in-sample avg dev_std = 0.084)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Thu May  2 23:51:03 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:03 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:06 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:07 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:07 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:09 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:51:11 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 80...
[0m[1;37mINFO[0m: [1mCheckpoint 80: 
-----------------------------------
Train ACCURACY: 0.9996
Train Loss: 0.0013
ID Validation ACCURACY: 0.7004
ID Validation Loss: 2.1344
ID Test ACCURACY: 0.6534
ID Test Loss: 2.4707
OOD Validation ACCURACY: 0.6185
OOD Validation Loss: 2.6028
OOD Test ACCURACY: 0.5477
OOD Test Loss: 3.0302

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 138...
[0m[1;37mINFO[0m: [1mCheckpoint 138: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0003
ID Validation ACCURACY: 0.6805
ID Validation Loss: 2.1438
ID Test ACCURACY: 0.6661
ID Test Loss: 2.4716
OOD Validation ACCURACY: 0.6190
OOD Validation Loss: 2.5169
OOD Test ACCURACY: 0.5587
OOD Test Loss: 2.9699

[0m[1;37mINFO[0m: [1mChartInfo 0.6534 0.5477 0.6661 0.5587 0.6805 0.6190[0mGOODTwitter(2590)
Data example from train: Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
Label distribution from train: (tensor([0, 1, 2]), tensor([ 625, 1283,  682]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.93
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 797
Effective ratio: 0.314 +- 0.014
Model Accuracy over intervened graphs for r=0.3 =  0.823
SUFF++ for r=0.3 class 0 = 0.628 +- 0.360 (in-sample avg dev_std = 0.613)
SUFF++ for r=0.3 class 1 = 0.78 +- 0.360 (in-sample avg dev_std = 0.613)
SUFF++ for r=0.3 class 2 = 0.778 +- 0.360 (in-sample avg dev_std = 0.613)
SUFF++ for r=0.3 all KL = 0.451 +- 0.360 (in-sample avg dev_std = 0.613)
SUFF++ for r=0.3 all L1 = 0.743 +- 0.198 (in-sample avg dev_std = 0.613)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.981
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 797
Effective ratio: 0.615 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.938
SUFF++ for r=0.6 class 0 = 0.789 +- 0.308 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.6 class 1 = 0.945 +- 0.308 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.6 class 2 = 0.908 +- 0.308 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.6 all KL = 0.774 +- 0.308 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.6 all L1 = 0.898 +- 0.156 (in-sample avg dev_std = 0.351)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  1.0
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 794
Effective ratio: 0.915 +- 0.015
Model Accuracy over intervened graphs for r=0.9 =  0.997
SUFF++ for r=0.9 class 0 = 0.969 +- 0.071 (in-sample avg dev_std = 0.073)
SUFF++ for r=0.9 class 1 = 0.997 +- 0.071 (in-sample avg dev_std = 0.073)
SUFF++ for r=0.9 class 2 = 0.988 +- 0.071 (in-sample avg dev_std = 0.073)
SUFF++ for r=0.9 all KL = 0.982 +- 0.071 (in-sample avg dev_std = 0.073)
SUFF++ for r=0.9 all L1 = 0.988 +- 0.048 (in-sample avg dev_std = 0.073)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.657
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.599
SUFF++ for r=0.3 class 0 = 0.629 +- 0.322 (in-sample avg dev_std = 0.588)
SUFF++ for r=0.3 class 1 = 0.708 +- 0.322 (in-sample avg dev_std = 0.588)
SUFF++ for r=0.3 class 2 = 0.707 +- 0.322 (in-sample avg dev_std = 0.588)
SUFF++ for r=0.3 all KL = 0.483 +- 0.322 (in-sample avg dev_std = 0.588)
SUFF++ for r=0.3 all L1 = 0.689 +- 0.218 (in-sample avg dev_std = 0.588)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.677
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.648
SUFF++ for r=0.6 class 0 = 0.754 +- 0.289 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.6 class 1 = 0.824 +- 0.289 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.6 class 2 = 0.778 +- 0.289 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.6 all KL = 0.722 +- 0.289 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.6 all L1 = 0.794 +- 0.223 (in-sample avg dev_std = 0.405)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.688
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.683
SUFF++ for r=0.9 class 0 = 0.879 +- 0.146 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 class 1 = 0.925 +- 0.146 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 class 2 = 0.873 +- 0.146 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 all KL = 0.921 +- 0.146 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 all L1 = 0.899 +- 0.157 (in-sample avg dev_std = 0.222)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.591
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.55
SUFF++ for r=0.3 class 0 = 0.622 +- 0.310 (in-sample avg dev_std = 0.627)
SUFF++ for r=0.3 class 1 = 0.647 +- 0.310 (in-sample avg dev_std = 0.627)
SUFF++ for r=0.3 class 2 = 0.559 +- 0.310 (in-sample avg dev_std = 0.627)
SUFF++ for r=0.3 all KL = 0.414 +- 0.310 (in-sample avg dev_std = 0.627)
SUFF++ for r=0.3 all L1 = 0.622 +- 0.229 (in-sample avg dev_std = 0.627)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.626
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.602
SUFF++ for r=0.6 class 0 = 0.758 +- 0.272 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 class 1 = 0.799 +- 0.272 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 class 2 = 0.715 +- 0.272 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 all KL = 0.721 +- 0.272 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 all L1 = 0.771 +- 0.220 (in-sample avg dev_std = 0.415)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.62
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.621
SUFF++ for r=0.9 class 0 = 0.89 +- 0.133 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.9 class 1 = 0.895 +- 0.133 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.9 class 2 = 0.856 +- 0.133 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.9 all KL = 0.924 +- 0.133 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.9 all L1 = 0.886 +- 0.163 (in-sample avg dev_std = 0.193)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.529
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.51
SUFF++ for r=0.3 class 0 = 0.66 +- 0.293 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.3 class 1 = 0.638 +- 0.293 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.3 class 2 = 0.614 +- 0.293 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.3 all KL = 0.469 +- 0.293 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.3 all L1 = 0.638 +- 0.220 (in-sample avg dev_std = 0.580)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.556
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.54
SUFF++ for r=0.6 class 0 = 0.779 +- 0.249 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.6 class 1 = 0.789 +- 0.249 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.6 class 2 = 0.74 +- 0.249 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.6 all KL = 0.744 +- 0.249 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.6 all L1 = 0.774 +- 0.210 (in-sample avg dev_std = 0.387)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.543
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.545
SUFF++ for r=0.9 class 0 = 0.885 +- 0.123 (in-sample avg dev_std = 0.196)
SUFF++ for r=0.9 class 1 = 0.886 +- 0.123 (in-sample avg dev_std = 0.196)
SUFF++ for r=0.9 class 2 = 0.881 +- 0.123 (in-sample avg dev_std = 0.196)
SUFF++ for r=0.9 all KL = 0.927 +- 0.123 (in-sample avg dev_std = 0.196)
SUFF++ for r=0.9 all L1 = 0.885 +- 0.154 (in-sample avg dev_std = 0.196)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.93
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 797
Effective ratio: 0.314 +- 0.014
Model Accuracy over intervened graphs for r=0.3 =  0.931
NEC for r=0.3 class 0 = 0.21 +- 0.290 (in-sample avg dev_std = 0.281)
NEC for r=0.3 class 1 = 0.083 +- 0.290 (in-sample avg dev_std = 0.281)
NEC for r=0.3 class 2 = 0.106 +- 0.290 (in-sample avg dev_std = 0.281)
NEC for r=0.3 all KL = 0.16 +- 0.290 (in-sample avg dev_std = 0.281)
NEC for r=0.3 all L1 = 0.119 +- 0.213 (in-sample avg dev_std = 0.281)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.981
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 797
Effective ratio: 0.615 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.979
NEC for r=0.6 class 0 = 0.095 +- 0.161 (in-sample avg dev_std = 0.148)
NEC for r=0.6 class 1 = 0.018 +- 0.161 (in-sample avg dev_std = 0.148)
NEC for r=0.6 class 2 = 0.026 +- 0.161 (in-sample avg dev_std = 0.148)
NEC for r=0.6 all KL = 0.053 +- 0.161 (in-sample avg dev_std = 0.148)
NEC for r=0.6 all L1 = 0.039 +- 0.109 (in-sample avg dev_std = 0.148)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  1.0
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 797
Effective ratio: 0.915 +- 0.015
Model Accuracy over intervened graphs for r=0.9 =  0.996
NEC for r=0.9 class 0 = 0.038 +- 0.106 (in-sample avg dev_std = 0.085)
NEC for r=0.9 class 1 = 0.001 +- 0.106 (in-sample avg dev_std = 0.085)
NEC for r=0.9 class 2 = 0.014 +- 0.106 (in-sample avg dev_std = 0.085)
NEC for r=0.9 all KL = 0.022 +- 0.106 (in-sample avg dev_std = 0.085)
NEC for r=0.9 all L1 = 0.013 +- 0.058 (in-sample avg dev_std = 0.085)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  1.0
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 797
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.995
NEC for r=1.0 class 0 = 0.034 +- 0.108 (in-sample avg dev_std = 0.092)
NEC for r=1.0 class 1 = 0.001 +- 0.108 (in-sample avg dev_std = 0.092)
NEC for r=1.0 class 2 = 0.012 +- 0.108 (in-sample avg dev_std = 0.092)
NEC for r=1.0 all KL = 0.02 +- 0.108 (in-sample avg dev_std = 0.092)
NEC for r=1.0 all L1 = 0.012 +- 0.061 (in-sample avg dev_std = 0.092)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.657
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.641
NEC for r=0.3 class 0 = 0.321 +- 0.356 (in-sample avg dev_std = 0.414)
NEC for r=0.3 class 1 = 0.226 +- 0.356 (in-sample avg dev_std = 0.414)
NEC for r=0.3 class 2 = 0.239 +- 0.356 (in-sample avg dev_std = 0.414)
NEC for r=0.3 all KL = 0.317 +- 0.356 (in-sample avg dev_std = 0.414)
NEC for r=0.3 all L1 = 0.253 +- 0.271 (in-sample avg dev_std = 0.414)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.677
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.662
NEC for r=0.6 class 0 = 0.182 +- 0.262 (in-sample avg dev_std = 0.289)
NEC for r=0.6 class 1 = 0.141 +- 0.262 (in-sample avg dev_std = 0.289)
NEC for r=0.6 class 2 = 0.174 +- 0.262 (in-sample avg dev_std = 0.289)
NEC for r=0.6 all KL = 0.165 +- 0.262 (in-sample avg dev_std = 0.289)
NEC for r=0.6 all L1 = 0.16 +- 0.224 (in-sample avg dev_std = 0.289)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.688
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.671
NEC for r=0.9 class 0 = 0.137 +- 0.168 (in-sample avg dev_std = 0.206)
NEC for r=0.9 class 1 = 0.096 +- 0.168 (in-sample avg dev_std = 0.206)
NEC for r=0.9 class 2 = 0.121 +- 0.168 (in-sample avg dev_std = 0.206)
NEC for r=0.9 all KL = 0.089 +- 0.168 (in-sample avg dev_std = 0.206)
NEC for r=0.9 all L1 = 0.113 +- 0.178 (in-sample avg dev_std = 0.206)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.699
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.669
NEC for r=1.0 class 0 = 0.127 +- 0.181 (in-sample avg dev_std = 0.215)
NEC for r=1.0 class 1 = 0.086 +- 0.181 (in-sample avg dev_std = 0.215)
NEC for r=1.0 class 2 = 0.116 +- 0.181 (in-sample avg dev_std = 0.215)
NEC for r=1.0 all KL = 0.086 +- 0.181 (in-sample avg dev_std = 0.215)
NEC for r=1.0 all L1 = 0.104 +- 0.173 (in-sample avg dev_std = 0.215)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.591
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.577
NEC for r=0.3 class 0 = 0.329 +- 0.365 (in-sample avg dev_std = 0.471)
NEC for r=0.3 class 1 = 0.297 +- 0.365 (in-sample avg dev_std = 0.471)
NEC for r=0.3 class 2 = 0.361 +- 0.365 (in-sample avg dev_std = 0.471)
NEC for r=0.3 all KL = 0.421 +- 0.365 (in-sample avg dev_std = 0.471)
NEC for r=0.3 all L1 = 0.319 +- 0.281 (in-sample avg dev_std = 0.471)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.626
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.605
NEC for r=0.6 class 0 = 0.218 +- 0.279 (in-sample avg dev_std = 0.320)
NEC for r=0.6 class 1 = 0.177 +- 0.279 (in-sample avg dev_std = 0.320)
NEC for r=0.6 class 2 = 0.266 +- 0.279 (in-sample avg dev_std = 0.320)
NEC for r=0.6 all KL = 0.216 +- 0.279 (in-sample avg dev_std = 0.320)
NEC for r=0.6 all L1 = 0.206 +- 0.240 (in-sample avg dev_std = 0.320)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.62
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.616
NEC for r=0.9 class 0 = 0.145 +- 0.187 (in-sample avg dev_std = 0.218)
NEC for r=0.9 class 1 = 0.116 +- 0.187 (in-sample avg dev_std = 0.218)
NEC for r=0.9 class 2 = 0.174 +- 0.187 (in-sample avg dev_std = 0.218)
NEC for r=0.9 all KL = 0.106 +- 0.187 (in-sample avg dev_std = 0.218)
NEC for r=0.9 all L1 = 0.136 +- 0.195 (in-sample avg dev_std = 0.218)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.619
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.611
NEC for r=1.0 class 0 = 0.143 +- 0.182 (in-sample avg dev_std = 0.216)
NEC for r=1.0 class 1 = 0.11 +- 0.182 (in-sample avg dev_std = 0.216)
NEC for r=1.0 class 2 = 0.155 +- 0.182 (in-sample avg dev_std = 0.216)
NEC for r=1.0 all KL = 0.1 +- 0.182 (in-sample avg dev_std = 0.216)
NEC for r=1.0 all L1 = 0.128 +- 0.190 (in-sample avg dev_std = 0.216)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.529
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.547
NEC for r=0.3 class 0 = 0.295 +- 0.344 (in-sample avg dev_std = 0.432)
NEC for r=0.3 class 1 = 0.315 +- 0.344 (in-sample avg dev_std = 0.432)
NEC for r=0.3 class 2 = 0.346 +- 0.344 (in-sample avg dev_std = 0.432)
NEC for r=0.3 all KL = 0.387 +- 0.344 (in-sample avg dev_std = 0.432)
NEC for r=0.3 all L1 = 0.317 +- 0.275 (in-sample avg dev_std = 0.432)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.556
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.546
NEC for r=0.6 class 0 = 0.215 +- 0.259 (in-sample avg dev_std = 0.302)
NEC for r=0.6 class 1 = 0.19 +- 0.259 (in-sample avg dev_std = 0.302)
NEC for r=0.6 class 2 = 0.218 +- 0.259 (in-sample avg dev_std = 0.302)
NEC for r=0.6 all KL = 0.202 +- 0.259 (in-sample avg dev_std = 0.302)
NEC for r=0.6 all L1 = 0.203 +- 0.230 (in-sample avg dev_std = 0.302)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.543
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.55
NEC for r=0.9 class 0 = 0.142 +- 0.178 (in-sample avg dev_std = 0.210)
NEC for r=0.9 class 1 = 0.133 +- 0.178 (in-sample avg dev_std = 0.210)
NEC for r=0.9 class 2 = 0.15 +- 0.178 (in-sample avg dev_std = 0.210)
NEC for r=0.9 all KL = 0.104 +- 0.178 (in-sample avg dev_std = 0.210)
NEC for r=0.9 all L1 = 0.139 +- 0.192 (in-sample avg dev_std = 0.210)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.535
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.552
NEC for r=1.0 class 0 = 0.128 +- 0.170 (in-sample avg dev_std = 0.214)
NEC for r=1.0 class 1 = 0.125 +- 0.170 (in-sample avg dev_std = 0.214)
NEC for r=1.0 class 2 = 0.138 +- 0.170 (in-sample avg dev_std = 0.214)
NEC for r=1.0 all KL = 0.097 +- 0.170 (in-sample avg dev_std = 0.214)
NEC for r=1.0 all L1 = 0.129 +- 0.186 (in-sample avg dev_std = 0.214)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split train
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.917, 0.933, 0.981, 1.0], 'all_L1': [0.781, 0.811, 0.904, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.916, 0.937, 0.982, 1.0], 'all_L1': [0.793, 0.827, 0.908, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.676, 0.845, 0.963, 1.0], 'all_L1': [0.736, 0.845, 0.938, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.914, 0.943, 0.982, 1.0], 'all_L1': [0.796, 0.832, 0.907, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.451, 0.774, 0.982, 1.0], 'all_L1': [0.743, 0.898, 0.988, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.065, 0.041, 0.018, 0.017], 'all_L1': [0.203, 0.153, 0.1, 0.091]}), defaultdict(<class 'list'>, {'all_KL': [0.062, 0.041, 0.02, 0.018], 'all_L1': [0.188, 0.148, 0.099, 0.092]}), defaultdict(<class 'list'>, {'all_KL': [0.172, 0.081, 0.034, 0.031], 'all_L1': [0.192, 0.112, 0.066, 0.056]}), defaultdict(<class 'list'>, {'all_KL': [0.06, 0.038, 0.022, 0.022], 'all_L1': [0.18, 0.138, 0.102, 0.097]}), defaultdict(<class 'list'>, {'all_KL': [0.16, 0.053, 0.022, 0.02], 'all_L1': [0.119, 0.039, 0.013, 0.012]})]

Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.911, 0.93, 0.98, 1.0], 'all_L1': [0.771, 0.806, 0.9, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.912, 0.94, 0.98, 1.0], 'all_L1': [0.79, 0.83, 0.903, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.644, 0.815, 0.944, 1.0], 'all_L1': [0.702, 0.786, 0.889, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.907, 0.939, 0.98, 1.0], 'all_L1': [0.791, 0.829, 0.902, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.483, 0.722, 0.921, 1.0], 'all_L1': [0.689, 0.794, 0.899, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.068, 0.041, 0.021, 0.02], 'all_L1': [0.208, 0.152, 0.108, 0.099]}), defaultdict(<class 'list'>, {'all_KL': [0.072, 0.041, 0.021, 0.021], 'all_L1': [0.194, 0.147, 0.107, 0.099]}), defaultdict(<class 'list'>, {'all_KL': [0.235, 0.122, 0.064, 0.057], 'all_L1': [0.246, 0.18, 0.125, 0.114]}), defaultdict(<class 'list'>, {'all_KL': [0.066, 0.042, 0.021, 0.021], 'all_L1': [0.186, 0.147, 0.104, 0.099]}), defaultdict(<class 'list'>, {'all_KL': [0.317, 0.165, 0.089, 0.086], 'all_L1': [0.253, 0.16, 0.113, 0.104]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.932, 0.956, 0.984, 1.0], 'all_L1': [0.788, 0.83, 0.895, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.926, 0.95, 0.981, 1.0], 'all_L1': [0.794, 0.829, 0.891, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.687, 0.836, 0.944, 1.0], 'all_L1': [0.708, 0.786, 0.871, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.919, 0.955, 0.982, 1.0], 'all_L1': [0.797, 0.84, 0.898, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.414, 0.721, 0.924, 1.0], 'all_L1': [0.622, 0.771, 0.886, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.063, 0.033, 0.016, 0.019], 'all_L1': [0.21, 0.153, 0.106, 0.109]}), defaultdict(<class 'list'>, {'all_KL': [0.071, 0.044, 0.024, 0.021], 'all_L1': [0.206, 0.164, 0.122, 0.112]}), defaultdict(<class 'list'>, {'all_KL': [0.28, 0.153, 0.082, 0.073], 'all_L1': [0.288, 0.213, 0.158, 0.145]}), defaultdict(<class 'list'>, {'all_KL': [0.076, 0.042, 0.023, 0.02], 'all_L1': [0.199, 0.152, 0.114, 0.104]}), defaultdict(<class 'list'>, {'all_KL': [0.421, 0.216, 0.106, 0.1], 'all_L1': [0.319, 0.206, 0.136, 0.128]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.943, 0.96, 0.985, 1.0], 'all_L1': [0.801, 0.838, 0.899, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.925, 0.95, 0.979, 1.0], 'all_L1': [0.786, 0.826, 0.886, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.694, 0.823, 0.941, 1.0], 'all_L1': [0.69, 0.77, 0.865, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.914, 0.948, 0.983, 1.0], 'all_L1': [0.79, 0.831, 0.9, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.469, 0.744, 0.927, 1.0], 'all_L1': [0.638, 0.774, 0.885, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.05, 0.03, 0.014, 0.015], 'all_L1': [0.195, 0.146, 0.101, 0.099]}), defaultdict(<class 'list'>, {'all_KL': [0.075, 0.046, 0.023, 0.02], 'all_L1': [0.219, 0.172, 0.122, 0.11]}), defaultdict(<class 'list'>, {'all_KL': [0.244, 0.138, 0.073, 0.069], 'all_L1': [0.284, 0.212, 0.151, 0.143]}), defaultdict(<class 'list'>, {'all_KL': [0.079, 0.044, 0.022, 0.02], 'all_L1': [0.206, 0.159, 0.114, 0.107]}), defaultdict(<class 'list'>, {'all_KL': [0.387, 0.202, 0.104, 0.097], 'all_L1': [0.317, 0.203, 0.139, 0.129]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split train
suff++ class all_L1  =  0.770 +- 0.025, 0.843 +- 0.030, 0.929 +- 0.032, 1.000 +- 0.000
suff++ class all_KL  =  0.775 +- 0.187, 0.886 +- 0.067, 0.978 +- 0.008, 1.000 +- 0.000
suff++_acc_int  =  0.719 +- 0.075, 0.799 +- 0.095, 0.850 +- 0.102
nec class all_L1  =  0.176 +- 0.030, 0.118 +- 0.042, 0.076 +- 0.034, 0.070 +- 0.032
nec class all_KL  =  0.104 +- 0.051, 0.051 +- 0.016, 0.023 +- 0.006, 0.022 +- 0.005
nec_acc_int  =  0.777 +- 0.104, 0.827 +- 0.106, 0.851 +- 0.101, 0.853 +- 0.101

Eval split id_val
suff++ class all_L1  =  0.749 +- 0.044, 0.809 +- 0.018, 0.899 +- 0.005, 1.000 +- 0.000
suff++ class all_KL  =  0.771 +- 0.177, 0.869 +- 0.087, 0.961 +- 0.024, 1.000 +- 0.000
suff++_acc_int  =  0.599 +- 0.015, 0.647 +- 0.009, 0.681 +- 0.006
nec class all_L1  =  0.217 +- 0.027, 0.157 +- 0.012, 0.111 +- 0.007, 0.103 +- 0.006
nec class all_KL  =  0.152 +- 0.105, 0.082 +- 0.052, 0.043 +- 0.028, 0.041 +- 0.027
nec_acc_int  =  0.632 +- 0.016, 0.659 +- 0.006, 0.675 +- 0.007, 0.678 +- 0.008

Eval split val
suff++ class all_L1  =  0.742 +- 0.068, 0.811 +- 0.027, 0.888 +- 0.009, 1.000 +- 0.000
suff++ class all_KL  =  0.776 +- 0.203, 0.884 +- 0.093, 0.963 +- 0.025, 1.000 +- 0.000
suff++_acc_int  =  0.573 +- 0.014, 0.602 +- 0.012, 0.617 +- 0.012
nec class all_L1  =  0.244 +- 0.049, 0.178 +- 0.026, 0.127 +- 0.018, 0.120 +- 0.015
nec class all_KL  =  0.182 +- 0.145, 0.098 +- 0.074, 0.050 +- 0.037, 0.047 +- 0.034
nec_acc_int  =  0.595 +- 0.014, 0.614 +- 0.010, 0.618 +- 0.012, 0.617 +- 0.008

Eval split test
suff++ class all_L1  =  0.741 +- 0.065, 0.808 +- 0.030, 0.887 +- 0.013, 1.000 +- 0.000
suff++ class all_KL  =  0.789 +- 0.184, 0.885 +- 0.087, 0.963 +- 0.024, 1.000 +- 0.000
suff++_acc_int  =  0.521 +- 0.014, 0.546 +- 0.013, 0.562 +- 0.012
nec class all_L1  =  0.244 +- 0.048, 0.178 +- 0.025, 0.125 +- 0.018, 0.118 +- 0.016
nec class all_KL  =  0.167 +- 0.130, 0.092 +- 0.067, 0.047 +- 0.035, 0.044 +- 0.033
nec_acc_int  =  0.550 +- 0.015, 0.559 +- 0.011, 0.566 +- 0.012, 0.564 +- 0.010


 -------------------------------------------------- 
Computing faithfulness

Eval split train
Faith. Aritm (L1)= 		  =  0.473 +- 0.023, 0.480 +- 0.007, 0.502 +- 0.001, 0.535 +- 0.016
Faith. Armon (L1)= 		  =  0.286 +- 0.041, 0.204 +- 0.068, 0.138 +- 0.061, 0.128 +- 0.058
Faith. GMean (L1)= 	  =  0.367 +- 0.036, 0.307 +- 0.062, 0.253 +- 0.073, 0.253 +- 0.076
Faith. Aritm (KL)= 		  =  0.439 +- 0.071, 0.469 +- 0.029, 0.501 +- 0.001, 0.511 +- 0.003
Faith. Armon (KL)= 		  =  0.172 +- 0.069, 0.095 +- 0.028, 0.045 +- 0.011, 0.042 +- 0.010
Faith. GMean (KL)= 	  =  0.265 +- 0.040, 0.209 +- 0.027, 0.150 +- 0.017, 0.146 +- 0.016

Eval split id_val
Faith. Aritm (L1)= 		  =  0.483 +- 0.009, 0.483 +- 0.005, 0.505 +- 0.001, 0.551 +- 0.003
Faith. Armon (L1)= 		  =  0.335 +- 0.028, 0.263 +- 0.016, 0.198 +- 0.011, 0.187 +- 0.010
Faith. GMean (L1)= 	  =  0.402 +- 0.013, 0.356 +- 0.010, 0.316 +- 0.009, 0.321 +- 0.009
Faith. Aritm (KL)= 		  =  0.462 +- 0.036, 0.476 +- 0.018, 0.502 +- 0.002, 0.521 +- 0.013
Faith. Armon (KL)= 		  =  0.222 +- 0.116, 0.144 +- 0.081, 0.081 +- 0.051, 0.078 +- 0.048
Faith. GMean (KL)= 	  =  0.306 +- 0.069, 0.250 +- 0.066, 0.192 +- 0.061, 0.193 +- 0.062

Eval split val
Faith. Aritm (L1)= 		  =  0.493 +- 0.011, 0.494 +- 0.004, 0.508 +- 0.005, 0.560 +- 0.008
Faith. Armon (L1)= 		  =  0.362 +- 0.044, 0.290 +- 0.033, 0.222 +- 0.027, 0.213 +- 0.024
Faith. GMean (L1)= 	  =  0.421 +- 0.022, 0.378 +- 0.022, 0.335 +- 0.022, 0.345 +- 0.021
Faith. Aritm (KL)= 		  =  0.479 +- 0.031, 0.491 +- 0.011, 0.507 +- 0.006, 0.523 +- 0.017
Faith. Armon (KL)= 		  =  0.241 +- 0.136, 0.164 +- 0.110, 0.093 +- 0.065, 0.087 +- 0.060
Faith. GMean (KL)= 	  =  0.324 +- 0.086, 0.267 +- 0.090, 0.204 +- 0.076, 0.202 +- 0.076

Eval split test
Faith. Aritm (L1)= 		  =  0.493 +- 0.009, 0.493 +- 0.004, 0.506 +- 0.004, 0.559 +- 0.008
Faith. Armon (L1)= 		  =  0.362 +- 0.043, 0.291 +- 0.032, 0.219 +- 0.027, 0.210 +- 0.026
Faith. GMean (L1)= 	  =  0.421 +- 0.021, 0.378 +- 0.020, 0.333 +- 0.021, 0.342 +- 0.023
Faith. Aritm (KL)= 		  =  0.478 +- 0.027, 0.489 +- 0.010, 0.505 +- 0.006, 0.522 +- 0.016
Faith. Armon (KL)= 		  =  0.233 +- 0.133, 0.157 +- 0.102, 0.088 +- 0.063, 0.083 +- 0.059
Faith. GMean (KL)= 	  =  0.317 +- 0.085, 0.262 +- 0.085, 0.197 +- 0.075, 0.196 +- 0.076
Computed for split load_split = id



Completed in  0:33:59.460872  for LECIGIN GOODTwitter/length



DONE LECI GOODTwitter/length

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Thu May  2 23:58:20 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/02/2024 11:58:21 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 157...
[0m[1;37mINFO[0m: [1mCheckpoint 157: 
-----------------------------------
Train ACCURACY: 0.9999
Train Loss: 0.0018
ID Validation ACCURACY: 0.9183
ID Validation Loss: 0.3380
ID Test ACCURACY: 0.9172
ID Test Loss: 0.3753
OOD Validation ACCURACY: 0.8775
OOD Validation Loss: 0.3681
OOD Test ACCURACY: 0.8031
OOD Test Loss: 0.5385

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 117...
[0m[1;37mINFO[0m: [1mCheckpoint 117: 
-----------------------------------
Train ACCURACY: 0.9990
Train Loss: 0.0067
ID Validation ACCURACY: 0.9136
ID Validation Loss: 0.3073
ID Test ACCURACY: 0.9130
ID Test Loss: 0.3474
OOD Validation ACCURACY: 0.8809
OOD Validation Loss: 0.3430
OOD Test ACCURACY: 0.8340
OOD Test Loss: 0.4255

[0m[1;37mINFO[0m: [1mChartInfo 0.9172 0.8031 0.9130 0.8340 0.9136 0.8809[0mGOODSST2(24744)
Data example from train: Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
Label distribution from train: (tensor([0., 1.]), tensor([10099, 14645]))
[1;34mDEBUG[0m: 05/02/2024 11:58:23 PM : [1mUnbalanced warning for GOODSST2 (train)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 05/02/2024 11:58:27 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.996
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 273
Effective ratio: 0.663 +- 0.263
Model Accuracy over intervened graphs for r=0.6 =  0.925
SUFF++ for r=0.6 class 0.0 = 0.78 +- 0.342 (in-sample avg dev_std = 0.449)
SUFF++ for r=0.6 class 1.0 = 0.951 +- 0.342 (in-sample avg dev_std = 0.449)
SUFF++ for r=0.6 all KL = 0.721 +- 0.342 (in-sample avg dev_std = 0.449)
SUFF++ for r=0.6 all L1 = 0.878 +- 0.157 (in-sample avg dev_std = 0.449)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  1.0
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 169
Effective ratio: 0.877 +- 0.301
Model Accuracy over intervened graphs for r=0.9 =  0.997
SUFF++ for r=0.9 class 0.0 = 0.99 +- 0.051 (in-sample avg dev_std = 0.053)
SUFF++ for r=0.9 class 1.0 = 0.996 +- 0.051 (in-sample avg dev_std = 0.053)
SUFF++ for r=0.9 all KL = 0.993 +- 0.051 (in-sample avg dev_std = 0.053)
SUFF++ for r=0.9 all L1 = 0.993 +- 0.039 (in-sample avg dev_std = 0.053)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.825
SUFF++ for r=0.6 class 0.0 = 0.779 +- 0.310 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 class 1.0 = 0.907 +- 0.310 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 all KL = 0.744 +- 0.310 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 all L1 = 0.854 +- 0.182 (in-sample avg dev_std = 0.444)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.9
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.887
SUFF++ for r=0.9 class 0.0 = 0.965 +- 0.075 (in-sample avg dev_std = 0.070)
SUFF++ for r=0.9 class 1.0 = 0.98 +- 0.075 (in-sample avg dev_std = 0.070)
SUFF++ for r=0.9 all KL = 0.985 +- 0.075 (in-sample avg dev_std = 0.070)
SUFF++ for r=0.9 all L1 = 0.973 +- 0.079 (in-sample avg dev_std = 0.070)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.835
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.761
SUFF++ for r=0.3 class 0.0 = 0.711 +- 0.348 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.3 class 1.0 = 0.927 +- 0.348 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.3 all KL = 0.702 +- 0.348 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.3 all L1 = 0.824 +- 0.196 (in-sample avg dev_std = 0.495)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.876
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.834
SUFF++ for r=0.6 class 0.0 = 0.805 +- 0.225 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 class 1.0 = 0.942 +- 0.225 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 all KL = 0.846 +- 0.225 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 all L1 = 0.877 +- 0.159 (in-sample avg dev_std = 0.346)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.885
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.875
SUFF++ for r=0.9 class 0.0 = 0.933 +- 0.066 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.9 class 1.0 = 0.962 +- 0.066 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.9 all KL = 0.97 +- 0.066 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.9 all L1 = 0.948 +- 0.077 (in-sample avg dev_std = 0.159)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.728
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.661
SUFF++ for r=0.3 class 0.0 = 0.732 +- 0.304 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.3 class 1.0 = 0.961 +- 0.304 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.3 all KL = 0.799 +- 0.304 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.3 all L1 = 0.85 +- 0.203 (in-sample avg dev_std = 0.411)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.785
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.742
SUFF++ for r=0.6 class 0.0 = 0.785 +- 0.189 (in-sample avg dev_std = 0.312)
SUFF++ for r=0.6 class 1.0 = 0.961 +- 0.189 (in-sample avg dev_std = 0.312)
SUFF++ for r=0.6 all KL = 0.884 +- 0.189 (in-sample avg dev_std = 0.312)
SUFF++ for r=0.6 all L1 = 0.876 +- 0.165 (in-sample avg dev_std = 0.312)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.822
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.816
SUFF++ for r=0.9 class 0.0 = 0.916 +- 0.042 (in-sample avg dev_std = 0.134)
SUFF++ for r=0.9 class 1.0 = 0.963 +- 0.042 (in-sample avg dev_std = 0.134)
SUFF++ for r=0.9 all KL = 0.978 +- 0.042 (in-sample avg dev_std = 0.134)
SUFF++ for r=0.9 all L1 = 0.94 +- 0.080 (in-sample avg dev_std = 0.134)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.996
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 273
Effective ratio: 0.663 +- 0.263
Model Accuracy over intervened graphs for r=0.6 =  0.993
NEC for r=0.6 class 0.0 = 0.017 +- 0.108 (in-sample avg dev_std = 0.080)
NEC for r=0.6 class 1.0 = 0.013 +- 0.108 (in-sample avg dev_std = 0.080)
NEC for r=0.6 all KL = 0.023 +- 0.108 (in-sample avg dev_std = 0.080)
NEC for r=0.6 all L1 = 0.015 +- 0.056 (in-sample avg dev_std = 0.080)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  1.0
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 273
Effective ratio: 0.877 +- 0.301
Model Accuracy over intervened graphs for r=0.9 =  0.996
NEC for r=0.9 class 0.0 = 0.013 +- 0.069 (in-sample avg dev_std = 0.055)
NEC for r=0.9 class 1.0 = 0.004 +- 0.069 (in-sample avg dev_std = 0.055)
NEC for r=0.9 all KL = 0.01 +- 0.069 (in-sample avg dev_std = 0.055)
NEC for r=0.9 all L1 = 0.008 +- 0.044 (in-sample avg dev_std = 0.055)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  1.0
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 273
Effective ratio: 0.896 +- 0.305
Model Accuracy over intervened graphs for r=1.0 =  0.996
NEC for r=1.0 class 0.0 = 0.013 +- 0.069 (in-sample avg dev_std = 0.055)
NEC for r=1.0 class 1.0 = 0.004 +- 0.069 (in-sample avg dev_std = 0.055)
NEC for r=1.0 all KL = 0.01 +- 0.069 (in-sample avg dev_std = 0.055)
NEC for r=1.0 all L1 = 0.008 +- 0.044 (in-sample avg dev_std = 0.055)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.87
NEC for r=0.6 class 0.0 = 0.062 +- 0.151 (in-sample avg dev_std = 0.129)
NEC for r=0.6 class 1.0 = 0.039 +- 0.151 (in-sample avg dev_std = 0.129)
NEC for r=0.6 all KL = 0.045 +- 0.151 (in-sample avg dev_std = 0.129)
NEC for r=0.6 all L1 = 0.048 +- 0.126 (in-sample avg dev_std = 0.129)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.884
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.875
NEC for r=0.9 class 0.0 = 0.033 +- 0.089 (in-sample avg dev_std = 0.076)
NEC for r=0.9 class 1.0 = 0.023 +- 0.089 (in-sample avg dev_std = 0.076)
NEC for r=0.9 all KL = 0.017 +- 0.089 (in-sample avg dev_std = 0.076)
NEC for r=0.9 all L1 = 0.027 +- 0.090 (in-sample avg dev_std = 0.076)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.884
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.875
NEC for r=1.0 class 0.0 = 0.033 +- 0.089 (in-sample avg dev_std = 0.076)
NEC for r=1.0 class 1.0 = 0.023 +- 0.089 (in-sample avg dev_std = 0.076)
NEC for r=1.0 all KL = 0.017 +- 0.089 (in-sample avg dev_std = 0.076)
NEC for r=1.0 all L1 = 0.027 +- 0.090 (in-sample avg dev_std = 0.076)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.835
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.829
NEC for r=0.3 class 0.0 = 0.132 +- 0.198 (in-sample avg dev_std = 0.155)
NEC for r=0.3 class 1.0 = 0.04 +- 0.198 (in-sample avg dev_std = 0.155)
NEC for r=0.3 all KL = 0.081 +- 0.198 (in-sample avg dev_std = 0.155)
NEC for r=0.3 all L1 = 0.084 +- 0.175 (in-sample avg dev_std = 0.155)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.876
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.864
NEC for r=0.6 class 0.0 = 0.091 +- 0.124 (in-sample avg dev_std = 0.143)
NEC for r=0.6 class 1.0 = 0.039 +- 0.124 (in-sample avg dev_std = 0.143)
NEC for r=0.6 all KL = 0.044 +- 0.124 (in-sample avg dev_std = 0.143)
NEC for r=0.6 all L1 = 0.064 +- 0.130 (in-sample avg dev_std = 0.143)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.885
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.881
NEC for r=0.9 class 0.0 = 0.036 +- 0.046 (in-sample avg dev_std = 0.063)
NEC for r=0.9 class 1.0 = 0.023 +- 0.046 (in-sample avg dev_std = 0.063)
NEC for r=0.9 all KL = 0.011 +- 0.046 (in-sample avg dev_std = 0.063)
NEC for r=0.9 all L1 = 0.029 +- 0.076 (in-sample avg dev_std = 0.063)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.885
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.882
NEC for r=1.0 class 0.0 = 0.031 +- 0.041 (in-sample avg dev_std = 0.063)
NEC for r=1.0 class 1.0 = 0.017 +- 0.041 (in-sample avg dev_std = 0.063)
NEC for r=1.0 all KL = 0.009 +- 0.041 (in-sample avg dev_std = 0.063)
NEC for r=1.0 all L1 = 0.024 +- 0.068 (in-sample avg dev_std = 0.063)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.728
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.709
NEC for r=0.3 class 0.0 = 0.152 +- 0.184 (in-sample avg dev_std = 0.181)
NEC for r=0.3 class 1.0 = 0.028 +- 0.184 (in-sample avg dev_std = 0.181)
NEC for r=0.3 all KL = 0.076 +- 0.184 (in-sample avg dev_std = 0.181)
NEC for r=0.3 all L1 = 0.088 +- 0.169 (in-sample avg dev_std = 0.181)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.785
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.772
NEC for r=0.6 class 0.0 = 0.129 +- 0.110 (in-sample avg dev_std = 0.140)
NEC for r=0.6 class 1.0 = 0.034 +- 0.110 (in-sample avg dev_std = 0.140)
NEC for r=0.6 all KL = 0.044 +- 0.110 (in-sample avg dev_std = 0.140)
NEC for r=0.6 all L1 = 0.08 +- 0.139 (in-sample avg dev_std = 0.140)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.822
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.82
NEC for r=0.9 class 0.0 = 0.058 +- 0.030 (in-sample avg dev_std = 0.065)
NEC for r=0.9 class 1.0 = 0.027 +- 0.030 (in-sample avg dev_std = 0.065)
NEC for r=0.9 all KL = 0.01 +- 0.030 (in-sample avg dev_std = 0.065)
NEC for r=0.9 all L1 = 0.042 +- 0.073 (in-sample avg dev_std = 0.065)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.825
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.824
NEC for r=1.0 class 0.0 = 0.039 +- 0.022 (in-sample avg dev_std = 0.052)
NEC for r=1.0 class 1.0 = 0.021 +- 0.022 (in-sample avg dev_std = 0.052)
NEC for r=1.0 all KL = 0.006 +- 0.022 (in-sample avg dev_std = 0.052)
NEC for r=1.0 all L1 = 0.029 +- 0.059 (in-sample avg dev_std = 0.052)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 00:01:56 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 128...
[0m[1;37mINFO[0m: [1mCheckpoint 128: 
-----------------------------------
Train ACCURACY: 0.9994
Train Loss: 0.0038
ID Validation ACCURACY: 0.9200
ID Validation Loss: 0.3551
ID Test ACCURACY: 0.9093
ID Test Loss: 0.4267
OOD Validation ACCURACY: 0.8753
OOD Validation Loss: 0.3988
OOD Test ACCURACY: 0.7891
OOD Test Loss: 0.6170

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 196...
[0m[1;37mINFO[0m: [1mCheckpoint 196: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0004
ID Validation ACCURACY: 0.9191
ID Validation Loss: 0.4356
ID Test ACCURACY: 0.9140
ID Test Loss: 0.4797
OOD Validation ACCURACY: 0.8836
OOD Validation Loss: 0.4121
OOD Test ACCURACY: 0.8148
OOD Test Loss: 0.5531

[0m[1;37mINFO[0m: [1mChartInfo 0.9093 0.7891 0.9140 0.8148 0.9191 0.8836[0mGOODSST2(24744)
Data example from train: Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
Label distribution from train: (tensor([0., 1.]), tensor([10099, 14645]))
[1;34mDEBUG[0m: 05/03/2024 12:01:58 AM : [1mUnbalanced warning for GOODSST2 (train)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 05/03/2024 12:02:01 AM : [1mUnbalanced warning for GOODSST2 (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.996
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 273
Effective ratio: 0.663 +- 0.263
Model Accuracy over intervened graphs for r=0.6 =  0.941
SUFF++ for r=0.6 class 0.0 = 0.897 +- 0.317 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.6 class 1.0 = 0.878 +- 0.317 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.6 all KL = 0.749 +- 0.317 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.6 all L1 = 0.886 +- 0.158 (in-sample avg dev_std = 0.387)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  1.0
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 169
Effective ratio: 0.877 +- 0.301
Model Accuracy over intervened graphs for r=0.9 =  0.993
SUFF++ for r=0.9 class 0.0 = 0.995 +- 0.051 (in-sample avg dev_std = 0.043)
SUFF++ for r=0.9 class 1.0 = 0.989 +- 0.051 (in-sample avg dev_std = 0.043)
SUFF++ for r=0.9 all KL = 0.993 +- 0.051 (in-sample avg dev_std = 0.043)
SUFF++ for r=0.9 all L1 = 0.991 +- 0.055 (in-sample avg dev_std = 0.043)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.867
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.833
SUFF++ for r=0.6 class 0.0 = 0.858 +- 0.299 (in-sample avg dev_std = 0.400)
SUFF++ for r=0.6 class 1.0 = 0.851 +- 0.299 (in-sample avg dev_std = 0.400)
SUFF++ for r=0.6 all KL = 0.744 +- 0.299 (in-sample avg dev_std = 0.400)
SUFF++ for r=0.6 all L1 = 0.854 +- 0.177 (in-sample avg dev_std = 0.400)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.9
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.885
SUFF++ for r=0.9 class 0.0 = 0.958 +- 0.092 (in-sample avg dev_std = 0.098)
SUFF++ for r=0.9 class 1.0 = 0.968 +- 0.092 (in-sample avg dev_std = 0.098)
SUFF++ for r=0.9 all KL = 0.98 +- 0.092 (in-sample avg dev_std = 0.098)
SUFF++ for r=0.9 all L1 = 0.963 +- 0.103 (in-sample avg dev_std = 0.098)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.85
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.775
SUFF++ for r=0.3 class 0.0 = 0.805 +- 0.327 (in-sample avg dev_std = 0.523)
SUFF++ for r=0.3 class 1.0 = 0.765 +- 0.327 (in-sample avg dev_std = 0.523)
SUFF++ for r=0.3 all KL = 0.62 +- 0.327 (in-sample avg dev_std = 0.523)
SUFF++ for r=0.3 all L1 = 0.784 +- 0.178 (in-sample avg dev_std = 0.523)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.869
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.842
SUFF++ for r=0.6 class 0.0 = 0.86 +- 0.182 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.6 class 1.0 = 0.889 +- 0.182 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.6 all KL = 0.854 +- 0.182 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.6 all L1 = 0.875 +- 0.143 (in-sample avg dev_std = 0.313)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.876
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.865
SUFF++ for r=0.9 class 0.0 = 0.917 +- 0.079 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.9 class 1.0 = 0.96 +- 0.079 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.9 all KL = 0.962 +- 0.079 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.9 all L1 = 0.94 +- 0.096 (in-sample avg dev_std = 0.165)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.798
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.744
SUFF++ for r=0.3 class 0.0 = 0.727 +- 0.263 (in-sample avg dev_std = 0.465)
SUFF++ for r=0.3 class 1.0 = 0.796 +- 0.263 (in-sample avg dev_std = 0.465)
SUFF++ for r=0.3 all KL = 0.696 +- 0.263 (in-sample avg dev_std = 0.465)
SUFF++ for r=0.3 all L1 = 0.763 +- 0.184 (in-sample avg dev_std = 0.465)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.812
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.783
SUFF++ for r=0.6 class 0.0 = 0.789 +- 0.151 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.6 class 1.0 = 0.909 +- 0.151 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.6 all KL = 0.881 +- 0.151 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.6 all L1 = 0.851 +- 0.159 (in-sample avg dev_std = 0.284)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.809
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.801
SUFF++ for r=0.9 class 0.0 = 0.893 +- 0.044 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.9 class 1.0 = 0.966 +- 0.044 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.9 all KL = 0.975 +- 0.044 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.9 all L1 = 0.931 +- 0.093 (in-sample avg dev_std = 0.131)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.996
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 273
Effective ratio: 0.663 +- 0.263
Model Accuracy over intervened graphs for r=0.6 =  0.988
NEC for r=0.6 class 0.0 = 0.015 +- 0.153 (in-sample avg dev_std = 0.096)
NEC for r=0.6 class 1.0 = 0.048 +- 0.153 (in-sample avg dev_std = 0.096)
NEC for r=0.6 all KL = 0.042 +- 0.153 (in-sample avg dev_std = 0.096)
NEC for r=0.6 all L1 = 0.034 +- 0.117 (in-sample avg dev_std = 0.096)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  1.0
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 273
Effective ratio: 0.877 +- 0.301
Model Accuracy over intervened graphs for r=0.9 =  0.993
NEC for r=0.9 class 0.0 = 0.007 +- 0.063 (in-sample avg dev_std = 0.021)
NEC for r=0.9 class 1.0 = 0.01 +- 0.063 (in-sample avg dev_std = 0.021)
NEC for r=0.9 all KL = 0.009 +- 0.063 (in-sample avg dev_std = 0.021)
NEC for r=0.9 all L1 = 0.009 +- 0.055 (in-sample avg dev_std = 0.021)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  1.0
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 273
Effective ratio: 0.896 +- 0.305
Model Accuracy over intervened graphs for r=1.0 =  0.993
NEC for r=1.0 class 0.0 = 0.007 +- 0.063 (in-sample avg dev_std = 0.021)
NEC for r=1.0 class 1.0 = 0.01 +- 0.063 (in-sample avg dev_std = 0.021)
NEC for r=1.0 all KL = 0.009 +- 0.063 (in-sample avg dev_std = 0.021)
NEC for r=1.0 all L1 = 0.009 +- 0.055 (in-sample avg dev_std = 0.021)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.867
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.866
NEC for r=0.6 class 0.0 = 0.085 +- 0.223 (in-sample avg dev_std = 0.201)
NEC for r=0.6 class 1.0 = 0.096 +- 0.223 (in-sample avg dev_std = 0.201)
NEC for r=0.6 all KL = 0.098 +- 0.223 (in-sample avg dev_std = 0.201)
NEC for r=0.6 all L1 = 0.091 +- 0.188 (in-sample avg dev_std = 0.201)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.888
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.875
NEC for r=0.9 class 0.0 = 0.041 +- 0.093 (in-sample avg dev_std = 0.081)
NEC for r=0.9 class 1.0 = 0.03 +- 0.093 (in-sample avg dev_std = 0.081)
NEC for r=0.9 all KL = 0.022 +- 0.093 (in-sample avg dev_std = 0.081)
NEC for r=0.9 all L1 = 0.035 +- 0.100 (in-sample avg dev_std = 0.081)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.888
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.875
NEC for r=1.0 class 0.0 = 0.041 +- 0.093 (in-sample avg dev_std = 0.081)
NEC for r=1.0 class 1.0 = 0.029 +- 0.093 (in-sample avg dev_std = 0.081)
NEC for r=1.0 all KL = 0.021 +- 0.093 (in-sample avg dev_std = 0.081)
NEC for r=1.0 all L1 = 0.034 +- 0.099 (in-sample avg dev_std = 0.081)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.85
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.843
NEC for r=0.3 class 0.0 = 0.113 +- 0.219 (in-sample avg dev_std = 0.198)
NEC for r=0.3 class 1.0 = 0.122 +- 0.219 (in-sample avg dev_std = 0.198)
NEC for r=0.3 all KL = 0.111 +- 0.219 (in-sample avg dev_std = 0.198)
NEC for r=0.3 all L1 = 0.118 +- 0.198 (in-sample avg dev_std = 0.198)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.869
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.871
NEC for r=0.6 class 0.0 = 0.078 +- 0.127 (in-sample avg dev_std = 0.150)
NEC for r=0.6 class 1.0 = 0.069 +- 0.127 (in-sample avg dev_std = 0.150)
NEC for r=0.6 all KL = 0.051 +- 0.127 (in-sample avg dev_std = 0.150)
NEC for r=0.6 all L1 = 0.074 +- 0.134 (in-sample avg dev_std = 0.150)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.876
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.871
NEC for r=0.9 class 0.0 = 0.038 +- 0.052 (in-sample avg dev_std = 0.074)
NEC for r=0.9 class 1.0 = 0.028 +- 0.052 (in-sample avg dev_std = 0.074)
NEC for r=0.9 all KL = 0.013 +- 0.052 (in-sample avg dev_std = 0.074)
NEC for r=0.9 all L1 = 0.033 +- 0.076 (in-sample avg dev_std = 0.074)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.874
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.87
NEC for r=1.0 class 0.0 = 0.029 +- 0.043 (in-sample avg dev_std = 0.062)
NEC for r=1.0 class 1.0 = 0.02 +- 0.043 (in-sample avg dev_std = 0.062)
NEC for r=1.0 all KL = 0.009 +- 0.043 (in-sample avg dev_std = 0.062)
NEC for r=1.0 all L1 = 0.024 +- 0.066 (in-sample avg dev_std = 0.062)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.798
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.803
NEC for r=0.3 class 0.0 = 0.199 +- 0.226 (in-sample avg dev_std = 0.227)
NEC for r=0.3 class 1.0 = 0.145 +- 0.226 (in-sample avg dev_std = 0.227)
NEC for r=0.3 all KL = 0.142 +- 0.226 (in-sample avg dev_std = 0.227)
NEC for r=0.3 all L1 = 0.171 +- 0.221 (in-sample avg dev_std = 0.227)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.812
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.806
NEC for r=0.6 class 0.0 = 0.141 +- 0.112 (in-sample avg dev_std = 0.146)
NEC for r=0.6 class 1.0 = 0.066 +- 0.112 (in-sample avg dev_std = 0.146)
NEC for r=0.6 all KL = 0.054 +- 0.112 (in-sample avg dev_std = 0.146)
NEC for r=0.6 all L1 = 0.102 +- 0.146 (in-sample avg dev_std = 0.146)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.809
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.807
NEC for r=0.9 class 0.0 = 0.076 +- 0.038 (in-sample avg dev_std = 0.078)
NEC for r=0.9 class 1.0 = 0.031 +- 0.038 (in-sample avg dev_std = 0.078)
NEC for r=0.9 all KL = 0.015 +- 0.038 (in-sample avg dev_std = 0.078)
NEC for r=0.9 all L1 = 0.053 +- 0.084 (in-sample avg dev_std = 0.078)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.804
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.803
NEC for r=1.0 class 0.0 = 0.047 +- 0.031 (in-sample avg dev_std = 0.060)
NEC for r=1.0 class 1.0 = 0.02 +- 0.031 (in-sample avg dev_std = 0.060)
NEC for r=1.0 all KL = 0.008 +- 0.031 (in-sample avg dev_std = 0.060)
NEC for r=1.0 all L1 = 0.033 +- 0.065 (in-sample avg dev_std = 0.060)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 00:05:37 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 164...
[0m[1;37mINFO[0m: [1mCheckpoint 164: 
-----------------------------------
Train ACCURACY: 0.9998
Train Loss: 0.0007
ID Validation ACCURACY: 0.9172
ID Validation Loss: 0.4352
ID Test ACCURACY: 0.9164
ID Test Loss: 0.4480
OOD Validation ACCURACY: 0.8825
OOD Validation Loss: 0.4191
OOD Test ACCURACY: 0.8136
OOD Test Loss: 0.5985

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 179...
[0m[1;37mINFO[0m: [1mCheckpoint 179: 
-----------------------------------
Train ACCURACY: 0.9999
Train Loss: 0.0007
ID Validation ACCURACY: 0.9161
ID Validation Loss: 0.4185
ID Test ACCURACY: 0.9178
ID Test Loss: 0.4294
OOD Validation ACCURACY: 0.8842
OOD Validation Loss: 0.3814
OOD Test ACCURACY: 0.8224
OOD Test Loss: 0.5053

[0m[1;37mINFO[0m: [1mChartInfo 0.9164 0.8136 0.9178 0.8224 0.9161 0.8842[0mGOODSST2(24744)
Data example from train: Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
Label distribution from train: (tensor([0., 1.]), tensor([10099, 14645]))
[1;34mDEBUG[0m: 05/03/2024 12:05:38 AM : [1mUnbalanced warning for GOODSST2 (train)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 05/03/2024 12:05:41 AM : [1mUnbalanced warning for GOODSST2 (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.996
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 273
Effective ratio: 0.663 +- 0.263
Model Accuracy over intervened graphs for r=0.6 =  0.918
SUFF++ for r=0.6 class 0.0 = 0.768 +- 0.363 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.6 class 1.0 = 0.927 +- 0.363 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.6 all KL = 0.65 +- 0.363 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.6 all L1 = 0.859 +- 0.164 (in-sample avg dev_std = 0.482)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  1.0
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 169
Effective ratio: 0.877 +- 0.301
Model Accuracy over intervened graphs for r=0.9 =  0.998
SUFF++ for r=0.9 class 0.0 = 0.998 +- 0.040 (in-sample avg dev_std = 0.044)
SUFF++ for r=0.9 class 1.0 = 0.995 +- 0.040 (in-sample avg dev_std = 0.044)
SUFF++ for r=0.9 all KL = 0.994 +- 0.040 (in-sample avg dev_std = 0.044)
SUFF++ for r=0.9 all L1 = 0.996 +- 0.029 (in-sample avg dev_std = 0.044)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.891
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.831
SUFF++ for r=0.6 class 0.0 = 0.77 +- 0.327 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.6 class 1.0 = 0.902 +- 0.327 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.6 all KL = 0.699 +- 0.327 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.6 all L1 = 0.847 +- 0.176 (in-sample avg dev_std = 0.460)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.906
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.895
SUFF++ for r=0.9 class 0.0 = 0.958 +- 0.073 (in-sample avg dev_std = 0.070)
SUFF++ for r=0.9 class 1.0 = 0.982 +- 0.073 (in-sample avg dev_std = 0.070)
SUFF++ for r=0.9 all KL = 0.985 +- 0.073 (in-sample avg dev_std = 0.070)
SUFF++ for r=0.9 all L1 = 0.971 +- 0.089 (in-sample avg dev_std = 0.070)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.846
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.753
SUFF++ for r=0.3 class 0.0 = 0.674 +- 0.368 (in-sample avg dev_std = 0.591)
SUFF++ for r=0.3 class 1.0 = 0.857 +- 0.368 (in-sample avg dev_std = 0.591)
SUFF++ for r=0.3 all KL = 0.578 +- 0.368 (in-sample avg dev_std = 0.591)
SUFF++ for r=0.3 all L1 = 0.77 +- 0.205 (in-sample avg dev_std = 0.591)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.874
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.828
SUFF++ for r=0.6 class 0.0 = 0.804 +- 0.259 (in-sample avg dev_std = 0.381)
SUFF++ for r=0.6 class 1.0 = 0.923 +- 0.259 (in-sample avg dev_std = 0.381)
SUFF++ for r=0.6 all KL = 0.803 +- 0.259 (in-sample avg dev_std = 0.381)
SUFF++ for r=0.6 all L1 = 0.866 +- 0.170 (in-sample avg dev_std = 0.381)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.877
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.868
SUFF++ for r=0.9 class 0.0 = 0.937 +- 0.072 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.9 class 1.0 = 0.962 +- 0.072 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.9 all KL = 0.968 +- 0.072 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.9 all L1 = 0.95 +- 0.088 (in-sample avg dev_std = 0.164)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.777
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.703
SUFF++ for r=0.3 class 0.0 = 0.706 +- 0.333 (in-sample avg dev_std = 0.458)
SUFF++ for r=0.3 class 1.0 = 0.931 +- 0.333 (in-sample avg dev_std = 0.458)
SUFF++ for r=0.3 all KL = 0.728 +- 0.333 (in-sample avg dev_std = 0.458)
SUFF++ for r=0.3 all L1 = 0.822 +- 0.219 (in-sample avg dev_std = 0.458)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.804
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.769
SUFF++ for r=0.6 class 0.0 = 0.82 +- 0.192 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.6 class 1.0 = 0.956 +- 0.192 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.6 all KL = 0.883 +- 0.192 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.6 all L1 = 0.89 +- 0.154 (in-sample avg dev_std = 0.301)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.83
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.825
SUFF++ for r=0.9 class 0.0 = 0.93 +- 0.040 (in-sample avg dev_std = 0.115)
SUFF++ for r=0.9 class 1.0 = 0.969 +- 0.040 (in-sample avg dev_std = 0.115)
SUFF++ for r=0.9 all KL = 0.981 +- 0.040 (in-sample avg dev_std = 0.115)
SUFF++ for r=0.9 all L1 = 0.95 +- 0.076 (in-sample avg dev_std = 0.115)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.996
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 273
Effective ratio: 0.663 +- 0.263
Model Accuracy over intervened graphs for r=0.6 =  0.995
NEC for r=0.6 class 0.0 = 0.011 +- 0.115 (in-sample avg dev_std = 0.067)
NEC for r=0.6 class 1.0 = 0.021 +- 0.115 (in-sample avg dev_std = 0.067)
NEC for r=0.6 all KL = 0.024 +- 0.115 (in-sample avg dev_std = 0.067)
NEC for r=0.6 all L1 = 0.017 +- 0.080 (in-sample avg dev_std = 0.067)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  1.0
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 273
Effective ratio: 0.877 +- 0.301
Model Accuracy over intervened graphs for r=0.9 =  0.998
NEC for r=0.9 class 0.0 = 0.004 +- 0.055 (in-sample avg dev_std = 0.043)
NEC for r=0.9 class 1.0 = 0.004 +- 0.055 (in-sample avg dev_std = 0.043)
NEC for r=0.9 all KL = 0.007 +- 0.055 (in-sample avg dev_std = 0.043)
NEC for r=0.9 all L1 = 0.004 +- 0.033 (in-sample avg dev_std = 0.043)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  1.0
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 273
Effective ratio: 0.896 +- 0.305
Model Accuracy over intervened graphs for r=1.0 =  0.998
NEC for r=1.0 class 0.0 = 0.004 +- 0.055 (in-sample avg dev_std = 0.043)
NEC for r=1.0 class 1.0 = 0.004 +- 0.055 (in-sample avg dev_std = 0.043)
NEC for r=1.0 all KL = 0.007 +- 0.055 (in-sample avg dev_std = 0.043)
NEC for r=1.0 all L1 = 0.004 +- 0.033 (in-sample avg dev_std = 0.043)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.891
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.874
NEC for r=0.6 class 0.0 = 0.069 +- 0.160 (in-sample avg dev_std = 0.125)
NEC for r=0.6 class 1.0 = 0.042 +- 0.160 (in-sample avg dev_std = 0.125)
NEC for r=0.6 all KL = 0.057 +- 0.160 (in-sample avg dev_std = 0.125)
NEC for r=0.6 all L1 = 0.053 +- 0.133 (in-sample avg dev_std = 0.125)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.902
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.888
NEC for r=0.9 class 0.0 = 0.04 +- 0.087 (in-sample avg dev_std = 0.070)
NEC for r=0.9 class 1.0 = 0.019 +- 0.087 (in-sample avg dev_std = 0.070)
NEC for r=0.9 all KL = 0.017 +- 0.087 (in-sample avg dev_std = 0.070)
NEC for r=0.9 all L1 = 0.028 +- 0.093 (in-sample avg dev_std = 0.070)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.902
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.888
NEC for r=1.0 class 0.0 = 0.041 +- 0.087 (in-sample avg dev_std = 0.070)
NEC for r=1.0 class 1.0 = 0.019 +- 0.087 (in-sample avg dev_std = 0.070)
NEC for r=1.0 all KL = 0.017 +- 0.087 (in-sample avg dev_std = 0.070)
NEC for r=1.0 all L1 = 0.028 +- 0.093 (in-sample avg dev_std = 0.070)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.846
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.828
NEC for r=0.3 class 0.0 = 0.134 +- 0.258 (in-sample avg dev_std = 0.211)
NEC for r=0.3 class 1.0 = 0.079 +- 0.258 (in-sample avg dev_std = 0.211)
NEC for r=0.3 all KL = 0.121 +- 0.258 (in-sample avg dev_std = 0.211)
NEC for r=0.3 all L1 = 0.106 +- 0.205 (in-sample avg dev_std = 0.211)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.874
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.861
NEC for r=0.6 class 0.0 = 0.079 +- 0.135 (in-sample avg dev_std = 0.154)
NEC for r=0.6 class 1.0 = 0.047 +- 0.135 (in-sample avg dev_std = 0.154)
NEC for r=0.6 all KL = 0.048 +- 0.135 (in-sample avg dev_std = 0.154)
NEC for r=0.6 all L1 = 0.063 +- 0.138 (in-sample avg dev_std = 0.154)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.877
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.872
NEC for r=0.9 class 0.0 = 0.032 +- 0.041 (in-sample avg dev_std = 0.063)
NEC for r=0.9 class 1.0 = 0.023 +- 0.041 (in-sample avg dev_std = 0.063)
NEC for r=0.9 all KL = 0.01 +- 0.041 (in-sample avg dev_std = 0.063)
NEC for r=0.9 all L1 = 0.027 +- 0.072 (in-sample avg dev_std = 0.063)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.877
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.872
NEC for r=1.0 class 0.0 = 0.027 +- 0.040 (in-sample avg dev_std = 0.059)
NEC for r=1.0 class 1.0 = 0.019 +- 0.040 (in-sample avg dev_std = 0.059)
NEC for r=1.0 all KL = 0.008 +- 0.040 (in-sample avg dev_std = 0.059)
NEC for r=1.0 all L1 = 0.023 +- 0.067 (in-sample avg dev_std = 0.059)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.777
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.757
NEC for r=0.3 class 0.0 = 0.178 +- 0.243 (in-sample avg dev_std = 0.214)
NEC for r=0.3 class 1.0 = 0.042 +- 0.243 (in-sample avg dev_std = 0.214)
NEC for r=0.3 all KL = 0.112 +- 0.243 (in-sample avg dev_std = 0.214)
NEC for r=0.3 all L1 = 0.108 +- 0.206 (in-sample avg dev_std = 0.214)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.804
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.797
NEC for r=0.6 class 0.0 = 0.112 +- 0.119 (in-sample avg dev_std = 0.144)
NEC for r=0.6 class 1.0 = 0.036 +- 0.119 (in-sample avg dev_std = 0.144)
NEC for r=0.6 all KL = 0.046 +- 0.119 (in-sample avg dev_std = 0.144)
NEC for r=0.6 all L1 = 0.073 +- 0.138 (in-sample avg dev_std = 0.144)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.83
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.824
NEC for r=0.9 class 0.0 = 0.057 +- 0.042 (in-sample avg dev_std = 0.071)
NEC for r=0.9 class 1.0 = 0.028 +- 0.042 (in-sample avg dev_std = 0.071)
NEC for r=0.9 all KL = 0.013 +- 0.042 (in-sample avg dev_std = 0.071)
NEC for r=0.9 all L1 = 0.042 +- 0.082 (in-sample avg dev_std = 0.071)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.834
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.828
NEC for r=1.0 class 0.0 = 0.036 +- 0.026 (in-sample avg dev_std = 0.057)
NEC for r=1.0 class 1.0 = 0.021 +- 0.026 (in-sample avg dev_std = 0.057)
NEC for r=1.0 all KL = 0.007 +- 0.026 (in-sample avg dev_std = 0.057)
NEC for r=1.0 all L1 = 0.028 +- 0.060 (in-sample avg dev_std = 0.057)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 00:09:01 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 99...
[0m[1;37mINFO[0m: [1mCheckpoint 99: 
-----------------------------------
Train ACCURACY: 0.9987
Train Loss: 0.0071
ID Validation ACCURACY: 0.9149
ID Validation Loss: 0.3353
ID Test ACCURACY: 0.9098
ID Test Loss: 0.3559
OOD Validation ACCURACY: 0.8657
OOD Validation Loss: 0.3762
OOD Test ACCURACY: 0.7989
OOD Test Loss: 0.5418

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 115...
[0m[1;37mINFO[0m: [1mCheckpoint 115: 
-----------------------------------
Train ACCURACY: 0.9994
Train Loss: 0.0052
ID Validation ACCURACY: 0.9110
ID Validation Loss: 0.3513
ID Test ACCURACY: 0.9119
ID Test Loss: 0.3779
OOD Validation ACCURACY: 0.8795
OOD Validation Loss: 0.3487
OOD Test ACCURACY: 0.8314
OOD Test Loss: 0.4254

[0m[1;37mINFO[0m: [1mChartInfo 0.9098 0.7989 0.9119 0.8314 0.9110 0.8795[0mGOODSST2(24744)
Data example from train: Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
Label distribution from train: (tensor([0., 1.]), tensor([10099, 14645]))
[1;34mDEBUG[0m: 05/03/2024 12:09:02 AM : [1mUnbalanced warning for GOODSST2 (train)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 05/03/2024 12:09:06 AM : [1mUnbalanced warning for GOODSST2 (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  1.0
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 273
Effective ratio: 0.663 +- 0.263
Model Accuracy over intervened graphs for r=0.6 =  0.953
SUFF++ for r=0.6 class 0.0 = 0.876 +- 0.276 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.6 class 1.0 = 0.928 +- 0.276 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.6 all KL = 0.8 +- 0.276 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.6 all L1 = 0.906 +- 0.134 (in-sample avg dev_std = 0.366)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  1.0
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 169
Effective ratio: 0.877 +- 0.301
Model Accuracy over intervened graphs for r=0.9 =  0.994
SUFF++ for r=0.9 class 0.0 = 0.978 +- 0.062 (in-sample avg dev_std = 0.017)
SUFF++ for r=0.9 class 1.0 = 0.997 +- 0.062 (in-sample avg dev_std = 0.017)
SUFF++ for r=0.9 all KL = 0.992 +- 0.062 (in-sample avg dev_std = 0.017)
SUFF++ for r=0.9 all L1 = 0.989 +- 0.061 (in-sample avg dev_std = 0.017)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.877
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.844
SUFF++ for r=0.6 class 0.0 = 0.848 +- 0.238 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.6 class 1.0 = 0.903 +- 0.238 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.6 all KL = 0.818 +- 0.238 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.6 all L1 = 0.88 +- 0.159 (in-sample avg dev_std = 0.360)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.883
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.885
SUFF++ for r=0.9 class 0.0 = 0.953 +- 0.052 (in-sample avg dev_std = 0.080)
SUFF++ for r=0.9 class 1.0 = 0.979 +- 0.052 (in-sample avg dev_std = 0.080)
SUFF++ for r=0.9 all KL = 0.986 +- 0.052 (in-sample avg dev_std = 0.080)
SUFF++ for r=0.9 all L1 = 0.967 +- 0.086 (in-sample avg dev_std = 0.080)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.871
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.802
SUFF++ for r=0.3 class 0.0 = 0.764 +- 0.316 (in-sample avg dev_std = 0.547)
SUFF++ for r=0.3 class 1.0 = 0.826 +- 0.316 (in-sample avg dev_std = 0.547)
SUFF++ for r=0.3 all KL = 0.632 +- 0.316 (in-sample avg dev_std = 0.547)
SUFF++ for r=0.3 all L1 = 0.796 +- 0.184 (in-sample avg dev_std = 0.547)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.873
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.853
SUFF++ for r=0.6 class 0.0 = 0.873 +- 0.162 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.6 class 1.0 = 0.923 +- 0.162 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.6 all KL = 0.896 +- 0.162 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.6 all L1 = 0.899 +- 0.135 (in-sample avg dev_std = 0.274)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.876
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.877
SUFF++ for r=0.9 class 0.0 = 0.938 +- 0.039 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 class 1.0 = 0.965 +- 0.039 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 all KL = 0.982 +- 0.039 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 all L1 = 0.952 +- 0.074 (in-sample avg dev_std = 0.113)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.827
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.786
SUFF++ for r=0.3 class 0.0 = 0.772 +- 0.260 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.3 class 1.0 = 0.883 +- 0.260 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.3 all KL = 0.745 +- 0.260 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.3 all L1 = 0.829 +- 0.174 (in-sample avg dev_std = 0.430)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.829
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.811
SUFF++ for r=0.6 class 0.0 = 0.857 +- 0.098 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.6 class 1.0 = 0.942 +- 0.098 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.6 all KL = 0.937 +- 0.098 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.6 all L1 = 0.901 +- 0.127 (in-sample avg dev_std = 0.201)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.816
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.813
SUFF++ for r=0.9 class 0.0 = 0.926 +- 0.022 (in-sample avg dev_std = 0.077)
SUFF++ for r=0.9 class 1.0 = 0.97 +- 0.022 (in-sample avg dev_std = 0.077)
SUFF++ for r=0.9 all KL = 0.989 +- 0.022 (in-sample avg dev_std = 0.077)
SUFF++ for r=0.9 all L1 = 0.949 +- 0.069 (in-sample avg dev_std = 0.077)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  1.0
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 273
Effective ratio: 0.663 +- 0.263
Model Accuracy over intervened graphs for r=0.6 =  0.988
NEC for r=0.6 class 0.0 = 0.041 +- 0.135 (in-sample avg dev_std = 0.094)
NEC for r=0.6 class 1.0 = 0.014 +- 0.135 (in-sample avg dev_std = 0.094)
NEC for r=0.6 all KL = 0.028 +- 0.135 (in-sample avg dev_std = 0.094)
NEC for r=0.6 all L1 = 0.025 +- 0.101 (in-sample avg dev_std = 0.094)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  1.0
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 273
Effective ratio: 0.877 +- 0.301
Model Accuracy over intervened graphs for r=0.9 =  0.995
NEC for r=0.9 class 0.0 = 0.02 +- 0.062 (in-sample avg dev_std = 0.058)
NEC for r=0.9 class 1.0 = 0.006 +- 0.062 (in-sample avg dev_std = 0.058)
NEC for r=0.9 all KL = 0.01 +- 0.062 (in-sample avg dev_std = 0.058)
NEC for r=0.9 all L1 = 0.012 +- 0.058 (in-sample avg dev_std = 0.058)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  1.0
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 273
Effective ratio: 0.896 +- 0.305
Model Accuracy over intervened graphs for r=1.0 =  0.995
NEC for r=1.0 class 0.0 = 0.02 +- 0.062 (in-sample avg dev_std = 0.058)
NEC for r=1.0 class 1.0 = 0.006 +- 0.062 (in-sample avg dev_std = 0.058)
NEC for r=1.0 all KL = 0.01 +- 0.062 (in-sample avg dev_std = 0.058)
NEC for r=1.0 all L1 = 0.012 +- 0.058 (in-sample avg dev_std = 0.058)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.877
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.864
NEC for r=0.6 class 0.0 = 0.067 +- 0.139 (in-sample avg dev_std = 0.116)
NEC for r=0.6 class 1.0 = 0.049 +- 0.139 (in-sample avg dev_std = 0.116)
NEC for r=0.6 all KL = 0.043 +- 0.139 (in-sample avg dev_std = 0.116)
NEC for r=0.6 all L1 = 0.057 +- 0.144 (in-sample avg dev_std = 0.116)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.881
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.875
NEC for r=0.9 class 0.0 = 0.053 +- 0.083 (in-sample avg dev_std = 0.074)
NEC for r=0.9 class 1.0 = 0.025 +- 0.083 (in-sample avg dev_std = 0.074)
NEC for r=0.9 all KL = 0.02 +- 0.083 (in-sample avg dev_std = 0.074)
NEC for r=0.9 all L1 = 0.037 +- 0.104 (in-sample avg dev_std = 0.074)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.881
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.875
NEC for r=1.0 class 0.0 = 0.053 +- 0.083 (in-sample avg dev_std = 0.074)
NEC for r=1.0 class 1.0 = 0.025 +- 0.083 (in-sample avg dev_std = 0.074)
NEC for r=1.0 all KL = 0.02 +- 0.083 (in-sample avg dev_std = 0.074)
NEC for r=1.0 all L1 = 0.037 +- 0.104 (in-sample avg dev_std = 0.074)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.871
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.859
NEC for r=0.3 class 0.0 = 0.11 +- 0.222 (in-sample avg dev_std = 0.195)
NEC for r=0.3 class 1.0 = 0.076 +- 0.222 (in-sample avg dev_std = 0.195)
NEC for r=0.3 all KL = 0.096 +- 0.222 (in-sample avg dev_std = 0.195)
NEC for r=0.3 all L1 = 0.093 +- 0.191 (in-sample avg dev_std = 0.195)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.873
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.873
NEC for r=0.6 class 0.0 = 0.081 +- 0.115 (in-sample avg dev_std = 0.130)
NEC for r=0.6 class 1.0 = 0.048 +- 0.115 (in-sample avg dev_std = 0.130)
NEC for r=0.6 all KL = 0.041 +- 0.115 (in-sample avg dev_std = 0.130)
NEC for r=0.6 all L1 = 0.064 +- 0.129 (in-sample avg dev_std = 0.130)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.876
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.873
NEC for r=0.9 class 0.0 = 0.043 +- 0.044 (in-sample avg dev_std = 0.065)
NEC for r=0.9 class 1.0 = 0.026 +- 0.044 (in-sample avg dev_std = 0.065)
NEC for r=0.9 all KL = 0.011 +- 0.044 (in-sample avg dev_std = 0.065)
NEC for r=0.9 all L1 = 0.034 +- 0.075 (in-sample avg dev_std = 0.065)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.877
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.873
NEC for r=1.0 class 0.0 = 0.031 +- 0.037 (in-sample avg dev_std = 0.059)
NEC for r=1.0 class 1.0 = 0.019 +- 0.037 (in-sample avg dev_std = 0.059)
NEC for r=1.0 all KL = 0.008 +- 0.037 (in-sample avg dev_std = 0.059)
NEC for r=1.0 all L1 = 0.025 +- 0.066 (in-sample avg dev_std = 0.059)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.827
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.813
NEC for r=0.3 class 0.0 = 0.138 +- 0.205 (in-sample avg dev_std = 0.210)
NEC for r=0.3 class 1.0 = 0.078 +- 0.205 (in-sample avg dev_std = 0.210)
NEC for r=0.3 all KL = 0.098 +- 0.205 (in-sample avg dev_std = 0.210)
NEC for r=0.3 all L1 = 0.107 +- 0.189 (in-sample avg dev_std = 0.210)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.829
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.818
NEC for r=0.6 class 0.0 = 0.112 +- 0.090 (in-sample avg dev_std = 0.131)
NEC for r=0.6 class 1.0 = 0.054 +- 0.090 (in-sample avg dev_std = 0.131)
NEC for r=0.6 all KL = 0.04 +- 0.090 (in-sample avg dev_std = 0.131)
NEC for r=0.6 all L1 = 0.082 +- 0.131 (in-sample avg dev_std = 0.131)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.816
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.815
NEC for r=0.9 class 0.0 = 0.069 +- 0.026 (in-sample avg dev_std = 0.068)
NEC for r=0.9 class 1.0 = 0.03 +- 0.026 (in-sample avg dev_std = 0.068)
NEC for r=0.9 all KL = 0.011 +- 0.026 (in-sample avg dev_std = 0.068)
NEC for r=0.9 all L1 = 0.049 +- 0.075 (in-sample avg dev_std = 0.068)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.82
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.818
NEC for r=1.0 class 0.0 = 0.041 +- 0.017 (in-sample avg dev_std = 0.050)
NEC for r=1.0 class 1.0 = 0.019 +- 0.017 (in-sample avg dev_std = 0.050)
NEC for r=1.0 all KL = 0.005 +- 0.017 (in-sample avg dev_std = 0.050)
NEC for r=1.0 all L1 = 0.029 +- 0.054 (in-sample avg dev_std = 0.050)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 00:12:37 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 12:12:38 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 192...
[0m[1;37mINFO[0m: [1mCheckpoint 192: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0005
ID Validation ACCURACY: 0.9153
ID Validation Loss: 0.4322
ID Test ACCURACY: 0.9144
ID Test Loss: 0.5002
OOD Validation ACCURACY: 0.8788
OOD Validation Loss: 0.4087
OOD Test ACCURACY: 0.8256
OOD Test Loss: 0.4929

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 137...
[0m[1;37mINFO[0m: [1mCheckpoint 137: 
-----------------------------------
Train ACCURACY: 0.9997
Train Loss: 0.0030
ID Validation ACCURACY: 0.9117
ID Validation Loss: 0.3966
ID Test ACCURACY: 0.9117
ID Test Loss: 0.4474
OOD Validation ACCURACY: 0.8814
OOD Validation Loss: 0.3906
OOD Test ACCURACY: 0.8333
OOD Test Loss: 0.4454

[0m[1;37mINFO[0m: [1mChartInfo 0.9144 0.8256 0.9117 0.8333 0.9117 0.8814[0mGOODSST2(24744)
Data example from train: Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
Label distribution from train: (tensor([0., 1.]), tensor([10099, 14645]))
[1;34mDEBUG[0m: 05/03/2024 12:12:39 AM : [1mUnbalanced warning for GOODSST2 (train)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 05/03/2024 12:12:41 AM : [1mUnbalanced warning for GOODSST2 (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  1.0
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 273
Effective ratio: 0.663 +- 0.263
Model Accuracy over intervened graphs for r=0.6 =  0.933
SUFF++ for r=0.6 class 0.0 = 0.897 +- 0.362 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 class 1.0 = 0.869 +- 0.362 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 all KL = 0.66 +- 0.362 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 all L1 = 0.881 +- 0.143 (in-sample avg dev_std = 0.444)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  1.0
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 169
Effective ratio: 0.877 +- 0.301
Model Accuracy over intervened graphs for r=0.9 =  1.0
SUFF++ for r=0.9 class 0.0 = 0.998 +- 0.010 (in-sample avg dev_std = 0.005)
SUFF++ for r=0.9 class 1.0 = 0.999 +- 0.010 (in-sample avg dev_std = 0.005)
SUFF++ for r=0.9 all KL = 0.999 +- 0.010 (in-sample avg dev_std = 0.005)
SUFF++ for r=0.9 all L1 = 0.999 +- 0.008 (in-sample avg dev_std = 0.005)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.832
SUFF++ for r=0.6 class 0.0 = 0.858 +- 0.323 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.6 class 1.0 = 0.856 +- 0.323 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.6 all KL = 0.714 +- 0.323 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.6 all L1 = 0.857 +- 0.180 (in-sample avg dev_std = 0.433)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.889
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.874
SUFF++ for r=0.9 class 0.0 = 0.962 +- 0.095 (in-sample avg dev_std = 0.083)
SUFF++ for r=0.9 class 1.0 = 0.976 +- 0.095 (in-sample avg dev_std = 0.083)
SUFF++ for r=0.9 all KL = 0.978 +- 0.095 (in-sample avg dev_std = 0.083)
SUFF++ for r=0.9 all L1 = 0.97 +- 0.095 (in-sample avg dev_std = 0.083)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.848
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.773
SUFF++ for r=0.3 class 0.0 = 0.876 +- 0.353 (in-sample avg dev_std = 0.526)
SUFF++ for r=0.3 class 1.0 = 0.729 +- 0.353 (in-sample avg dev_std = 0.526)
SUFF++ for r=0.3 all KL = 0.634 +- 0.353 (in-sample avg dev_std = 0.526)
SUFF++ for r=0.3 all L1 = 0.8 +- 0.195 (in-sample avg dev_std = 0.526)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.877
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.842
SUFF++ for r=0.6 class 0.0 = 0.906 +- 0.240 (in-sample avg dev_std = 0.344)
SUFF++ for r=0.6 class 1.0 = 0.848 +- 0.240 (in-sample avg dev_std = 0.344)
SUFF++ for r=0.6 all KL = 0.82 +- 0.240 (in-sample avg dev_std = 0.344)
SUFF++ for r=0.6 all L1 = 0.876 +- 0.154 (in-sample avg dev_std = 0.344)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.885
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.876
SUFF++ for r=0.9 class 0.0 = 0.944 +- 0.060 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.9 class 1.0 = 0.952 +- 0.060 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.9 all KL = 0.969 +- 0.060 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.9 all L1 = 0.948 +- 0.083 (in-sample avg dev_std = 0.151)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.804
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.735
SUFF++ for r=0.3 class 0.0 = 0.888 +- 0.319 (in-sample avg dev_std = 0.474)
SUFF++ for r=0.3 class 1.0 = 0.712 +- 0.319 (in-sample avg dev_std = 0.474)
SUFF++ for r=0.3 all KL = 0.699 +- 0.319 (in-sample avg dev_std = 0.474)
SUFF++ for r=0.3 all L1 = 0.797 +- 0.201 (in-sample avg dev_std = 0.474)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.853
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.821
SUFF++ for r=0.6 class 0.0 = 0.899 +- 0.168 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.6 class 1.0 = 0.846 +- 0.168 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.6 all KL = 0.877 +- 0.168 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.6 all L1 = 0.871 +- 0.150 (in-sample avg dev_std = 0.291)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.854
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.849
SUFF++ for r=0.9 class 0.0 = 0.932 +- 0.038 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.9 class 1.0 = 0.955 +- 0.038 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.9 all KL = 0.98 +- 0.038 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.9 all L1 = 0.944 +- 0.081 (in-sample avg dev_std = 0.112)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  1.0
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 273
Effective ratio: 0.663 +- 0.263
Model Accuracy over intervened graphs for r=0.6 =  0.998
NEC for r=0.6 class 0.0 = 0.009 +- 0.083 (in-sample avg dev_std = 0.050)
NEC for r=0.6 class 1.0 = 0.009 +- 0.083 (in-sample avg dev_std = 0.050)
NEC for r=0.6 all KL = 0.016 +- 0.083 (in-sample avg dev_std = 0.050)
NEC for r=0.6 all L1 = 0.009 +- 0.045 (in-sample avg dev_std = 0.050)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  1.0
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 273
Effective ratio: 0.877 +- 0.301
Model Accuracy over intervened graphs for r=0.9 =  1.0
NEC for r=0.9 class 0.0 = 0.003 +- 0.028 (in-sample avg dev_std = 0.015)
NEC for r=0.9 class 1.0 = 0.001 +- 0.028 (in-sample avg dev_std = 0.015)
NEC for r=0.9 all KL = 0.003 +- 0.028 (in-sample avg dev_std = 0.015)
NEC for r=0.9 all L1 = 0.002 +- 0.017 (in-sample avg dev_std = 0.015)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  1.0
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 273
Effective ratio: 0.896 +- 0.305
Model Accuracy over intervened graphs for r=1.0 =  1.0
NEC for r=1.0 class 0.0 = 0.003 +- 0.028 (in-sample avg dev_std = 0.015)
NEC for r=1.0 class 1.0 = 0.001 +- 0.028 (in-sample avg dev_std = 0.015)
NEC for r=1.0 all KL = 0.003 +- 0.028 (in-sample avg dev_std = 0.015)
NEC for r=1.0 all L1 = 0.002 +- 0.017 (in-sample avg dev_std = 0.015)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.868
NEC for r=0.6 class 0.0 = 0.074 +- 0.192 (in-sample avg dev_std = 0.147)
NEC for r=0.6 class 1.0 = 0.054 +- 0.192 (in-sample avg dev_std = 0.147)
NEC for r=0.6 all KL = 0.071 +- 0.192 (in-sample avg dev_std = 0.147)
NEC for r=0.6 all L1 = 0.062 +- 0.158 (in-sample avg dev_std = 0.147)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.891
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.882
NEC for r=0.9 class 0.0 = 0.032 +- 0.088 (in-sample avg dev_std = 0.068)
NEC for r=0.9 class 1.0 = 0.024 +- 0.088 (in-sample avg dev_std = 0.068)
NEC for r=0.9 all KL = 0.02 +- 0.088 (in-sample avg dev_std = 0.068)
NEC for r=0.9 all L1 = 0.028 +- 0.088 (in-sample avg dev_std = 0.068)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.891
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.882
NEC for r=1.0 class 0.0 = 0.032 +- 0.088 (in-sample avg dev_std = 0.068)
NEC for r=1.0 class 1.0 = 0.024 +- 0.088 (in-sample avg dev_std = 0.068)
NEC for r=1.0 all KL = 0.02 +- 0.088 (in-sample avg dev_std = 0.068)
NEC for r=1.0 all L1 = 0.028 +- 0.088 (in-sample avg dev_std = 0.068)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.848
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.846
NEC for r=0.3 class 0.0 = 0.072 +- 0.230 (in-sample avg dev_std = 0.193)
NEC for r=0.3 class 1.0 = 0.121 +- 0.230 (in-sample avg dev_std = 0.193)
NEC for r=0.3 all KL = 0.104 +- 0.230 (in-sample avg dev_std = 0.193)
NEC for r=0.3 all L1 = 0.097 +- 0.191 (in-sample avg dev_std = 0.193)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.877
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.869
NEC for r=0.6 class 0.0 = 0.053 +- 0.125 (in-sample avg dev_std = 0.139)
NEC for r=0.6 class 1.0 = 0.068 +- 0.125 (in-sample avg dev_std = 0.139)
NEC for r=0.6 all KL = 0.044 +- 0.125 (in-sample avg dev_std = 0.139)
NEC for r=0.6 all L1 = 0.061 +- 0.133 (in-sample avg dev_std = 0.139)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.885
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.877
NEC for r=0.9 class 0.0 = 0.037 +- 0.065 (in-sample avg dev_std = 0.077)
NEC for r=0.9 class 1.0 = 0.025 +- 0.065 (in-sample avg dev_std = 0.077)
NEC for r=0.9 all KL = 0.014 +- 0.065 (in-sample avg dev_std = 0.077)
NEC for r=0.9 all L1 = 0.031 +- 0.084 (in-sample avg dev_std = 0.077)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.885
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.879
NEC for r=1.0 class 0.0 = 0.034 +- 0.060 (in-sample avg dev_std = 0.065)
NEC for r=1.0 class 1.0 = 0.018 +- 0.060 (in-sample avg dev_std = 0.065)
NEC for r=1.0 all KL = 0.011 +- 0.060 (in-sample avg dev_std = 0.065)
NEC for r=1.0 all L1 = 0.026 +- 0.077 (in-sample avg dev_std = 0.065)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.804
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.799
NEC for r=0.3 class 0.0 = 0.07 +- 0.175 (in-sample avg dev_std = 0.180)
NEC for r=0.3 class 1.0 = 0.135 +- 0.175 (in-sample avg dev_std = 0.180)
NEC for r=0.3 all KL = 0.084 +- 0.175 (in-sample avg dev_std = 0.180)
NEC for r=0.3 all L1 = 0.104 +- 0.182 (in-sample avg dev_std = 0.180)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.853
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.842
NEC for r=0.6 class 0.0 = 0.068 +- 0.092 (in-sample avg dev_std = 0.137)
NEC for r=0.6 class 1.0 = 0.088 +- 0.092 (in-sample avg dev_std = 0.137)
NEC for r=0.6 all KL = 0.042 +- 0.092 (in-sample avg dev_std = 0.137)
NEC for r=0.6 all L1 = 0.079 +- 0.129 (in-sample avg dev_std = 0.137)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.854
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.849
NEC for r=0.9 class 0.0 = 0.055 +- 0.040 (in-sample avg dev_std = 0.082)
NEC for r=0.9 class 1.0 = 0.04 +- 0.040 (in-sample avg dev_std = 0.082)
NEC for r=0.9 all KL = 0.015 +- 0.040 (in-sample avg dev_std = 0.082)
NEC for r=0.9 all L1 = 0.047 +- 0.085 (in-sample avg dev_std = 0.082)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.849
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.847
NEC for r=1.0 class 0.0 = 0.038 +- 0.028 (in-sample avg dev_std = 0.056)
NEC for r=1.0 class 1.0 = 0.022 +- 0.028 (in-sample avg dev_std = 0.056)
NEC for r=1.0 all KL = 0.008 +- 0.028 (in-sample avg dev_std = 0.056)
NEC for r=1.0 all L1 = 0.03 +- 0.062 (in-sample avg dev_std = 0.056)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split train
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.721, 0.993, 1.0], 'all_L1': [0.878, 0.993, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.749, 0.993, 1.0], 'all_L1': [0.886, 0.991, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.65, 0.994, 1.0], 'all_L1': [0.859, 0.996, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.8, 0.992, 1.0], 'all_L1': [0.906, 0.989, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.66, 0.999, 1.0], 'all_L1': [0.881, 0.999, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.023, 0.01, 0.01], 'all_L1': [0.015, 0.008, 0.008]}), defaultdict(<class 'list'>, {'all_KL': [0.042, 0.009, 0.009], 'all_L1': [0.034, 0.009, 0.009]}), defaultdict(<class 'list'>, {'all_KL': [0.024, 0.007, 0.007], 'all_L1': [0.017, 0.004, 0.004]}), defaultdict(<class 'list'>, {'all_KL': [0.028, 0.01, 0.01], 'all_L1': [0.025, 0.012, 0.012]}), defaultdict(<class 'list'>, {'all_KL': [0.016, 0.003, 0.003], 'all_L1': [0.009, 0.002, 0.002]})]

Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.744, 0.985, 1.0], 'all_L1': [0.854, 0.973, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.744, 0.98, 1.0], 'all_L1': [0.854, 0.963, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.699, 0.985, 1.0], 'all_L1': [0.847, 0.971, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.818, 0.986, 1.0], 'all_L1': [0.88, 0.967, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.714, 0.978, 1.0], 'all_L1': [0.857, 0.97, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.045, 0.017, 0.017], 'all_L1': [0.048, 0.027, 0.027]}), defaultdict(<class 'list'>, {'all_KL': [0.098, 0.022, 0.021], 'all_L1': [0.091, 0.035, 0.034]}), defaultdict(<class 'list'>, {'all_KL': [0.057, 0.017, 0.017], 'all_L1': [0.053, 0.028, 0.028]}), defaultdict(<class 'list'>, {'all_KL': [0.043, 0.02, 0.02], 'all_L1': [0.057, 0.037, 0.037]}), defaultdict(<class 'list'>, {'all_KL': [0.071, 0.02, 0.02], 'all_L1': [0.062, 0.028, 0.028]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.702, 0.846, 0.97, 1.0], 'all_L1': [0.824, 0.877, 0.948, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.62, 0.854, 0.962, 1.0], 'all_L1': [0.784, 0.875, 0.94, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.578, 0.803, 0.968, 1.0], 'all_L1': [0.77, 0.866, 0.95, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.632, 0.896, 0.982, 1.0], 'all_L1': [0.796, 0.899, 0.952, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.634, 0.82, 0.969, 1.0], 'all_L1': [0.8, 0.876, 0.948, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.081, 0.044, 0.011, 0.009], 'all_L1': [0.084, 0.064, 0.029, 0.024]}), defaultdict(<class 'list'>, {'all_KL': [0.111, 0.051, 0.013, 0.009], 'all_L1': [0.118, 0.074, 0.033, 0.024]}), defaultdict(<class 'list'>, {'all_KL': [0.121, 0.048, 0.01, 0.008], 'all_L1': [0.106, 0.063, 0.027, 0.023]}), defaultdict(<class 'list'>, {'all_KL': [0.096, 0.041, 0.011, 0.008], 'all_L1': [0.093, 0.064, 0.034, 0.025]}), defaultdict(<class 'list'>, {'all_KL': [0.104, 0.044, 0.014, 0.011], 'all_L1': [0.097, 0.061, 0.031, 0.026]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.799, 0.884, 0.978, 1.0], 'all_L1': [0.85, 0.876, 0.94, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.696, 0.881, 0.975, 1.0], 'all_L1': [0.763, 0.851, 0.931, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.728, 0.883, 0.981, 1.0], 'all_L1': [0.822, 0.89, 0.95, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.745, 0.937, 0.989, 1.0], 'all_L1': [0.829, 0.901, 0.949, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.699, 0.877, 0.98, 1.0], 'all_L1': [0.797, 0.871, 0.944, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.076, 0.044, 0.01, 0.006], 'all_L1': [0.088, 0.08, 0.042, 0.029]}), defaultdict(<class 'list'>, {'all_KL': [0.142, 0.054, 0.015, 0.008], 'all_L1': [0.171, 0.102, 0.053, 0.033]}), defaultdict(<class 'list'>, {'all_KL': [0.112, 0.046, 0.013, 0.007], 'all_L1': [0.108, 0.073, 0.042, 0.028]}), defaultdict(<class 'list'>, {'all_KL': [0.098, 0.04, 0.011, 0.005], 'all_L1': [0.107, 0.082, 0.049, 0.029]}), defaultdict(<class 'list'>, {'all_KL': [0.084, 0.042, 0.015, 0.008], 'all_L1': [0.104, 0.079, 0.047, 0.03]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split train
suff++ class all_L1  =  0.882 +- 0.015, 0.994 +- 0.004, 1.000 +- 0.000
suff++ class all_KL  =  0.716 +- 0.056, 0.994 +- 0.002, 1.000 +- 0.000
suff++_acc_int  =  0.934 +- 0.012, 0.996 +- 0.003
nec class all_L1  =  0.020 +- 0.009, 0.007 +- 0.004, 0.007 +- 0.004
nec class all_KL  =  0.027 +- 0.009, 0.008 +- 0.003, 0.008 +- 0.003
nec_acc_int  =  0.992 +- 0.004, 0.996 +- 0.002, 0.996 +- 0.002

Eval split id_val
suff++ class all_L1  =  0.858 +- 0.011, 0.969 +- 0.003, 1.000 +- 0.000
suff++ class all_KL  =  0.744 +- 0.041, 0.983 +- 0.003, 1.000 +- 0.000
suff++_acc_int  =  0.833 +- 0.006, 0.885 +- 0.007
nec class all_L1  =  0.062 +- 0.015, 0.031 +- 0.004, 0.031 +- 0.004
nec class all_KL  =  0.063 +- 0.020, 0.019 +- 0.002, 0.019 +- 0.002
nec_acc_int  =  0.868 +- 0.003, 0.879 +- 0.005, 0.879 +- 0.005

Eval split val
suff++ class all_L1  =  0.795 +- 0.018, 0.879 +- 0.011, 0.948 +- 0.004, 1.000 +- 0.000
suff++ class all_KL  =  0.633 +- 0.040, 0.844 +- 0.032, 0.970 +- 0.007, 1.000 +- 0.000
suff++_acc_int  =  0.773 +- 0.017, 0.840 +- 0.008, 0.872 +- 0.005
nec class all_L1  =  0.100 +- 0.012, 0.065 +- 0.005, 0.031 +- 0.003, 0.024 +- 0.001
nec class all_KL  =  0.103 +- 0.014, 0.046 +- 0.003, 0.012 +- 0.001, 0.009 +- 0.001
nec_acc_int  =  0.841 +- 0.012, 0.867 +- 0.005, 0.875 +- 0.004, 0.875 +- 0.005

Eval split test
suff++ class all_L1  =  0.812 +- 0.030, 0.878 +- 0.017, 0.943 +- 0.007, 1.000 +- 0.000
suff++ class all_KL  =  0.733 +- 0.038, 0.892 +- 0.022, 0.981 +- 0.005, 1.000 +- 0.000
suff++_acc_int  =  0.726 +- 0.042, 0.785 +- 0.029, 0.821 +- 0.016
nec class all_L1  =  0.116 +- 0.029, 0.083 +- 0.010, 0.047 +- 0.004, 0.030 +- 0.002
nec class all_KL  =  0.102 +- 0.023, 0.045 +- 0.005, 0.013 +- 0.002, 0.007 +- 0.001
nec_acc_int  =  0.776 +- 0.039, 0.807 +- 0.023, 0.823 +- 0.014, 0.824 +- 0.014


 -------------------------------------------------- 
Computing faithfulness

Eval split train
Faith. Aritm (L1)= 		  =  0.451 +- 0.010, 0.500 +- 0.000, 0.503 +- 0.002
Faith. Armon (L1)= 		  =  0.039 +- 0.017, 0.014 +- 0.007, 0.014 +- 0.007
Faith. GMean (L1)= 	  =  0.130 +- 0.029, 0.080 +- 0.023, 0.080 +- 0.023
Faith. Aritm (KL)= 		  =  0.371 +- 0.031, 0.501 +- 0.000, 0.504 +- 0.001
Faith. Armon (KL)= 		  =  0.051 +- 0.016, 0.015 +- 0.005, 0.015 +- 0.005
Faith. GMean (KL)= 	  =  0.137 +- 0.025, 0.086 +- 0.017, 0.087 +- 0.017

Eval split id_val
Faith. Aritm (L1)= 		  =  0.460 +- 0.009, 0.500 +- 0.001, 0.515 +- 0.002
Faith. Armon (L1)= 		  =  0.116 +- 0.026, 0.060 +- 0.008, 0.060 +- 0.007
Faith. GMean (L1)= 	  =  0.230 +- 0.026, 0.173 +- 0.011, 0.175 +- 0.011
Faith. Aritm (KL)= 		  =  0.403 +- 0.019, 0.501 +- 0.001, 0.509 +- 0.001
Faith. Armon (KL)= 		  =  0.115 +- 0.034, 0.038 +- 0.004, 0.037 +- 0.003
Faith. GMean (KL)= 	  =  0.213 +- 0.032, 0.137 +- 0.007, 0.138 +- 0.006

Eval split val
Faith. Aritm (L1)= 		  =  0.447 +- 0.006, 0.472 +- 0.006, 0.489 +- 0.002, 0.512 +- 0.001
Faith. Armon (L1)= 		  =  0.177 +- 0.018, 0.121 +- 0.008, 0.060 +- 0.005, 0.048 +- 0.002
Faith. GMean (L1)= 	  =  0.281 +- 0.014, 0.239 +- 0.008, 0.171 +- 0.007, 0.156 +- 0.003
Faith. Aritm (KL)= 		  =  0.368 +- 0.014, 0.445 +- 0.015, 0.491 +- 0.003, 0.505 +- 0.001
Faith. Armon (KL)= 		  =  0.176 +- 0.019, 0.086 +- 0.006, 0.023 +- 0.003, 0.018 +- 0.002
Faith. GMean (KL)= 	  =  0.254 +- 0.010, 0.196 +- 0.007, 0.107 +- 0.006, 0.095 +- 0.006

Eval split test
Faith. Aritm (L1)= 		  =  0.464 +- 0.007, 0.480 +- 0.006, 0.495 +- 0.003, 0.515 +- 0.001
Faith. Armon (L1)= 		  =  0.201 +- 0.041, 0.152 +- 0.016, 0.089 +- 0.008, 0.058 +- 0.003
Faith. GMean (L1)= 	  =  0.304 +- 0.030, 0.270 +- 0.014, 0.209 +- 0.009, 0.173 +- 0.005
Faith. Aritm (KL)= 		  =  0.418 +- 0.015, 0.469 +- 0.010, 0.497 +- 0.002, 0.503 +- 0.001
Faith. Armon (KL)= 		  =  0.178 +- 0.035, 0.086 +- 0.009, 0.025 +- 0.004, 0.014 +- 0.002
Faith. GMean (KL)= 	  =  0.272 +- 0.027, 0.200 +- 0.009, 0.112 +- 0.009, 0.082 +- 0.007
Computed for split load_split = id



Completed in  0:17:50.419923  for LECIGIN GOODSST2/length



DONE LECI GOODSST2/length

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 00:16:36 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 05/03/2024 12:16:36 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/03/2024 12:16:40 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/03/2024 12:16:44 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/03/2024 12:16:47 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:16:50 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 76...
[0m[1;37mINFO[0m: [1mCheckpoint 76: 
-----------------------------------
Train ROC-AUC: 0.9112
Train Loss: 0.0959
ID Validation ROC-AUC: 0.8397
ID Validation Loss: 0.1242
ID Test ROC-AUC: 0.8258
ID Test Loss: 0.1074
OOD Validation ROC-AUC: 0.7708
OOD Validation Loss: 0.1306
OOD Test ROC-AUC: 0.7085
OOD Test Loss: 0.0951

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 98...
[0m[1;37mINFO[0m: [1mCheckpoint 98: 
-----------------------------------
Train ROC-AUC: 0.9185
Train Loss: 0.0931
ID Validation ROC-AUC: 0.8219
ID Validation Loss: 0.1302
ID Test ROC-AUC: 0.8142
ID Test Loss: 0.1157
OOD Validation ROC-AUC: 0.7943
OOD Validation Loss: 0.1353
OOD Test ROC-AUC: 0.7235
OOD Test Loss: 0.1040

[0m[1;37mINFO[0m: [1mChartInfo 0.8258 0.7085 0.8142 0.7235 0.8219 0.7943[0mGOODHIV(24682)
Data example from train: Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
Label distribution from train: (tensor([0., 1.]), tensor([23758,   924]))
[1;34mDEBUG[0m: 05/03/2024 12:16:51 AM : [1mUnbalanced warning for GOODHIV (train)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([924, 924]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 05/03/2024 12:16:57 AM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 05/03/2024 12:16:59 AM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 05/03/2024 12:17:01 AM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.728
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 799
Effective ratio: 0.309 +- 0.011
Model ROC-AUC over intervened graphs for r=0.3 =  0.672
SUFF++ for r=0.3 class 0.0 = 0.977 +- 0.091 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.3 class 1.0 = 0.927 +- 0.091 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.3 all KL = 0.965 +- 0.091 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.3 all L1 = 0.952 +- 0.095 (in-sample avg dev_std = 0.111)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.772
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 799
Effective ratio: 0.609 +- 0.016
Model ROC-AUC over intervened graphs for r=0.6 =  0.719
SUFF++ for r=0.6 class 0.0 = 0.976 +- 0.084 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.6 class 1.0 = 0.909 +- 0.084 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.6 all KL = 0.964 +- 0.084 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.6 all L1 = 0.942 +- 0.104 (in-sample avg dev_std = 0.111)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.858
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 799
Effective ratio: 0.908 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.803
SUFF++ for r=0.9 class 0.0 = 0.969 +- 0.164 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.9 class 1.0 = 0.759 +- 0.164 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.9 all KL = 0.916 +- 0.164 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.9 all L1 = 0.864 +- 0.200 (in-sample avg dev_std = 0.170)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.742
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.666
SUFF++ for r=0.3 class 0.0 = 0.975 +- 0.117 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.3 class 1.0 = 0.926 +- 0.117 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.3 all KL = 0.957 +- 0.117 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.3 all L1 = 0.951 +- 0.108 (in-sample avg dev_std = 0.124)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.77
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.725
SUFF++ for r=0.6 class 0.0 = 0.974 +- 0.099 (in-sample avg dev_std = 0.096)
SUFF++ for r=0.6 class 1.0 = 0.9 +- 0.099 (in-sample avg dev_std = 0.096)
SUFF++ for r=0.6 all KL = 0.959 +- 0.099 (in-sample avg dev_std = 0.096)
SUFF++ for r=0.6 all L1 = 0.937 +- 0.124 (in-sample avg dev_std = 0.096)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.829
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.789
SUFF++ for r=0.9 class 0.0 = 0.972 +- 0.194 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.9 class 1.0 = 0.754 +- 0.194 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.9 all KL = 0.904 +- 0.194 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.9 all L1 = 0.863 +- 0.213 (in-sample avg dev_std = 0.193)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.683
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.693
SUFF++ for r=0.3 class 0.0 = 0.98 +- 0.087 (in-sample avg dev_std = 0.109)
SUFF++ for r=0.3 class 1.0 = 0.945 +- 0.087 (in-sample avg dev_std = 0.109)
SUFF++ for r=0.3 all KL = 0.967 +- 0.087 (in-sample avg dev_std = 0.109)
SUFF++ for r=0.3 all L1 = 0.962 +- 0.079 (in-sample avg dev_std = 0.109)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.664
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.702
SUFF++ for r=0.6 class 0.0 = 0.979 +- 0.077 (in-sample avg dev_std = 0.104)
SUFF++ for r=0.6 class 1.0 = 0.912 +- 0.077 (in-sample avg dev_std = 0.104)
SUFF++ for r=0.6 all KL = 0.966 +- 0.077 (in-sample avg dev_std = 0.104)
SUFF++ for r=0.6 all L1 = 0.945 +- 0.098 (in-sample avg dev_std = 0.104)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.69
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.696
SUFF++ for r=0.9 class 0.0 = 0.934 +- 0.193 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.9 class 1.0 = 0.76 +- 0.193 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.9 all KL = 0.892 +- 0.193 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.9 all L1 = 0.847 +- 0.214 (in-sample avg dev_std = 0.216)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.633
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.568
SUFF++ for r=0.3 class 0.0 = 0.975 +- 0.064 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.3 class 1.0 = 0.954 +- 0.064 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.3 all KL = 0.971 +- 0.064 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.3 all L1 = 0.965 +- 0.066 (in-sample avg dev_std = 0.106)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.59
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.592
SUFF++ for r=0.6 class 0.0 = 0.963 +- 0.085 (in-sample avg dev_std = 0.080)
SUFF++ for r=0.6 class 1.0 = 0.941 +- 0.085 (in-sample avg dev_std = 0.080)
SUFF++ for r=0.6 all KL = 0.966 +- 0.085 (in-sample avg dev_std = 0.080)
SUFF++ for r=0.6 all L1 = 0.952 +- 0.103 (in-sample avg dev_std = 0.080)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.608
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.587
SUFF++ for r=0.9 class 0.0 = 0.971 +- 0.122 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 class 1.0 = 0.899 +- 0.122 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 all KL = 0.954 +- 0.122 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 all L1 = 0.935 +- 0.113 (in-sample avg dev_std = 0.152)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.728
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 799
Effective ratio: 0.309 +- 0.011
Model ROC-AUC over intervened graphs for r=0.3 =  0.662
NEC for r=0.3 class 0.0 = 0.022 +- 0.113 (in-sample avg dev_std = 0.100)
NEC for r=0.3 class 1.0 = 0.077 +- 0.113 (in-sample avg dev_std = 0.100)
NEC for r=0.3 all KL = 0.036 +- 0.113 (in-sample avg dev_std = 0.100)
NEC for r=0.3 all L1 = 0.049 +- 0.112 (in-sample avg dev_std = 0.100)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.772
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 799
Effective ratio: 0.609 +- 0.016
Model ROC-AUC over intervened graphs for r=0.6 =  0.707
NEC for r=0.6 class 0.0 = 0.023 +- 0.087 (in-sample avg dev_std = 0.096)
NEC for r=0.6 class 1.0 = 0.094 +- 0.087 (in-sample avg dev_std = 0.096)
NEC for r=0.6 all KL = 0.035 +- 0.087 (in-sample avg dev_std = 0.096)
NEC for r=0.6 all L1 = 0.058 +- 0.106 (in-sample avg dev_std = 0.096)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.858
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 799
Effective ratio: 0.908 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.797
NEC for r=0.9 class 0.0 = 0.031 +- 0.177 (in-sample avg dev_std = 0.195)
NEC for r=0.9 class 1.0 = 0.247 +- 0.177 (in-sample avg dev_std = 0.195)
NEC for r=0.9 all KL = 0.091 +- 0.177 (in-sample avg dev_std = 0.195)
NEC for r=0.9 all L1 = 0.139 +- 0.204 (in-sample avg dev_std = 0.195)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.896
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 799
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.811
NEC for r=1.0 class 0.0 = 0.031 +- 0.218 (in-sample avg dev_std = 0.252)
NEC for r=1.0 class 1.0 = 0.307 +- 0.218 (in-sample avg dev_std = 0.252)
NEC for r=1.0 all KL = 0.127 +- 0.218 (in-sample avg dev_std = 0.252)
NEC for r=1.0 all L1 = 0.169 +- 0.233 (in-sample avg dev_std = 0.252)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.742
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.63
NEC for r=0.3 class 0.0 = 0.021 +- 0.129 (in-sample avg dev_std = 0.082)
NEC for r=0.3 class 1.0 = 0.079 +- 0.129 (in-sample avg dev_std = 0.082)
NEC for r=0.3 all KL = 0.039 +- 0.129 (in-sample avg dev_std = 0.082)
NEC for r=0.3 all L1 = 0.05 +- 0.126 (in-sample avg dev_std = 0.082)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.77
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.68
NEC for r=0.6 class 0.0 = 0.026 +- 0.112 (in-sample avg dev_std = 0.102)
NEC for r=0.6 class 1.0 = 0.108 +- 0.112 (in-sample avg dev_std = 0.102)
NEC for r=0.6 all KL = 0.047 +- 0.112 (in-sample avg dev_std = 0.102)
NEC for r=0.6 all L1 = 0.067 +- 0.132 (in-sample avg dev_std = 0.102)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.829
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.746
NEC for r=0.9 class 0.0 = 0.028 +- 0.224 (in-sample avg dev_std = 0.192)
NEC for r=0.9 class 1.0 = 0.272 +- 0.224 (in-sample avg dev_std = 0.192)
NEC for r=0.9 all KL = 0.113 +- 0.224 (in-sample avg dev_std = 0.192)
NEC for r=0.9 all L1 = 0.15 +- 0.232 (in-sample avg dev_std = 0.192)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.85
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.759
NEC for r=1.0 class 0.0 = 0.03 +- 0.255 (in-sample avg dev_std = 0.236)
NEC for r=1.0 class 1.0 = 0.316 +- 0.255 (in-sample avg dev_std = 0.236)
NEC for r=1.0 all KL = 0.142 +- 0.255 (in-sample avg dev_std = 0.236)
NEC for r=1.0 all L1 = 0.173 +- 0.254 (in-sample avg dev_std = 0.236)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.683
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.681
NEC for r=0.3 class 0.0 = 0.021 +- 0.094 (in-sample avg dev_std = 0.105)
NEC for r=0.3 class 1.0 = 0.047 +- 0.094 (in-sample avg dev_std = 0.105)
NEC for r=0.3 all KL = 0.032 +- 0.094 (in-sample avg dev_std = 0.105)
NEC for r=0.3 all L1 = 0.034 +- 0.067 (in-sample avg dev_std = 0.105)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.664
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.685
NEC for r=0.6 class 0.0 = 0.033 +- 0.125 (in-sample avg dev_std = 0.142)
NEC for r=0.6 class 1.0 = 0.103 +- 0.125 (in-sample avg dev_std = 0.142)
NEC for r=0.6 all KL = 0.055 +- 0.125 (in-sample avg dev_std = 0.142)
NEC for r=0.6 all L1 = 0.068 +- 0.117 (in-sample avg dev_std = 0.142)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.69
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.697
NEC for r=0.9 class 0.0 = 0.065 +- 0.247 (in-sample avg dev_std = 0.199)
NEC for r=0.9 class 1.0 = 0.285 +- 0.247 (in-sample avg dev_std = 0.199)
NEC for r=0.9 all KL = 0.139 +- 0.247 (in-sample avg dev_std = 0.199)
NEC for r=0.9 all L1 = 0.175 +- 0.250 (in-sample avg dev_std = 0.199)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.762
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.707
NEC for r=1.0 class 0.0 = 0.06 +- 0.253 (in-sample avg dev_std = 0.238)
NEC for r=1.0 class 1.0 = 0.332 +- 0.253 (in-sample avg dev_std = 0.238)
NEC for r=1.0 all KL = 0.157 +- 0.253 (in-sample avg dev_std = 0.238)
NEC for r=1.0 all L1 = 0.196 +- 0.255 (in-sample avg dev_std = 0.238)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.633
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.578
NEC for r=0.3 class 0.0 = 0.017 +- 0.082 (in-sample avg dev_std = 0.096)
NEC for r=0.3 class 1.0 = 0.05 +- 0.082 (in-sample avg dev_std = 0.096)
NEC for r=0.3 all KL = 0.025 +- 0.082 (in-sample avg dev_std = 0.096)
NEC for r=0.3 all L1 = 0.033 +- 0.075 (in-sample avg dev_std = 0.096)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.588
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.545
NEC for r=0.6 class 0.0 = 0.029 +- 0.084 (in-sample avg dev_std = 0.096)
NEC for r=0.6 class 1.0 = 0.059 +- 0.084 (in-sample avg dev_std = 0.096)
NEC for r=0.6 all KL = 0.03 +- 0.084 (in-sample avg dev_std = 0.096)
NEC for r=0.6 all L1 = 0.044 +- 0.102 (in-sample avg dev_std = 0.096)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.608
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.58
NEC for r=0.9 class 0.0 = 0.028 +- 0.139 (in-sample avg dev_std = 0.090)
NEC for r=0.9 class 1.0 = 0.099 +- 0.139 (in-sample avg dev_std = 0.090)
NEC for r=0.9 all KL = 0.045 +- 0.139 (in-sample avg dev_std = 0.090)
NEC for r=0.9 all L1 = 0.064 +- 0.133 (in-sample avg dev_std = 0.090)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.695
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.615
NEC for r=1.0 class 0.0 = 0.029 +- 0.139 (in-sample avg dev_std = 0.087)
NEC for r=1.0 class 1.0 = 0.126 +- 0.139 (in-sample avg dev_std = 0.087)
NEC for r=1.0 all KL = 0.048 +- 0.139 (in-sample avg dev_std = 0.087)
NEC for r=1.0 all L1 = 0.078 +- 0.156 (in-sample avg dev_std = 0.087)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 00:19:46 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 05/03/2024 12:19:46 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/03/2024 12:19:49 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/03/2024 12:19:52 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/03/2024 12:19:55 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 113...
[0m[1;37mINFO[0m: [1mCheckpoint 113: 
-----------------------------------
Train ROC-AUC: 0.9328
Train Loss: 0.0878
ID Validation ROC-AUC: 0.8349
ID Validation Loss: 0.1306
ID Test ROC-AUC: 0.8310
ID Test Loss: 0.1169
OOD Validation ROC-AUC: 0.7716
OOD Validation Loss: 0.1561
OOD Test ROC-AUC: 0.6985
OOD Test Loss: 0.1126

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 140...
[0m[1;37mINFO[0m: [1mCheckpoint 140: 
-----------------------------------
Train ROC-AUC: 0.9441
Train Loss: 0.0829
ID Validation ROC-AUC: 0.8160
ID Validation Loss: 0.1352
ID Test ROC-AUC: 0.8261
ID Test Loss: 0.1154
OOD Validation ROC-AUC: 0.7909
OOD Validation Loss: 0.1575
OOD Test ROC-AUC: 0.7194
OOD Test Loss: 0.1152

[0m[1;37mINFO[0m: [1mChartInfo 0.8310 0.6985 0.8261 0.7194 0.8160 0.7909[0mGOODHIV(24682)
Data example from train: Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
Label distribution from train: (tensor([0., 1.]), tensor([23758,   924]))
[1;34mDEBUG[0m: 05/03/2024 12:19:58 AM : [1mUnbalanced warning for GOODHIV (train)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([924, 924]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 05/03/2024 12:20:04 AM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 05/03/2024 12:20:06 AM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 05/03/2024 12:20:07 AM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.768
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 799
Effective ratio: 0.309 +- 0.011
Model ROC-AUC over intervened graphs for r=0.3 =  0.661
SUFF++ for r=0.3 class 0.0 = 0.727 +- 0.283 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.3 class 1.0 = 0.587 +- 0.283 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.3 all KL = 0.628 +- 0.283 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.3 all L1 = 0.657 +- 0.208 (in-sample avg dev_std = 0.509)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.839
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 799
Effective ratio: 0.609 +- 0.016
Model ROC-AUC over intervened graphs for r=0.6 =  0.761
SUFF++ for r=0.6 class 0.0 = 0.804 +- 0.251 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.6 class 1.0 = 0.66 +- 0.251 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.6 all KL = 0.752 +- 0.251 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.6 all L1 = 0.732 +- 0.199 (in-sample avg dev_std = 0.394)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.904
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 799
Effective ratio: 0.908 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.853
SUFF++ for r=0.9 class 0.0 = 0.919 +- 0.199 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.9 class 1.0 = 0.768 +- 0.199 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.9 all KL = 0.883 +- 0.199 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.9 all L1 = 0.844 +- 0.176 (in-sample avg dev_std = 0.269)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.755
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.641
SUFF++ for r=0.3 class 0.0 = 0.719 +- 0.297 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.3 class 1.0 = 0.578 +- 0.297 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.3 all KL = 0.601 +- 0.297 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.3 all L1 = 0.648 +- 0.218 (in-sample avg dev_std = 0.509)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.787
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.724
SUFF++ for r=0.6 class 0.0 = 0.831 +- 0.283 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.6 class 1.0 = 0.659 +- 0.283 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.6 all KL = 0.746 +- 0.283 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.6 all L1 = 0.745 +- 0.217 (in-sample avg dev_std = 0.401)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.854
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.801
SUFF++ for r=0.9 class 0.0 = 0.931 +- 0.229 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.9 class 1.0 = 0.747 +- 0.229 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.9 all KL = 0.862 +- 0.229 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.9 all L1 = 0.839 +- 0.193 (in-sample avg dev_std = 0.317)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.643
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.616
SUFF++ for r=0.3 class 0.0 = 0.665 +- 0.320 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 class 1.0 = 0.622 +- 0.320 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 all KL = 0.543 +- 0.320 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 all L1 = 0.644 +- 0.207 (in-sample avg dev_std = 0.563)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.712
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.669
SUFF++ for r=0.6 class 0.0 = 0.749 +- 0.265 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 class 1.0 = 0.726 +- 0.265 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 all KL = 0.742 +- 0.265 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 all L1 = 0.737 +- 0.206 (in-sample avg dev_std = 0.396)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.71
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.723
SUFF++ for r=0.9 class 0.0 = 0.869 +- 0.166 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.9 class 1.0 = 0.832 +- 0.166 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.9 all KL = 0.901 +- 0.166 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.9 all L1 = 0.85 +- 0.159 (in-sample avg dev_std = 0.226)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.617
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.523
SUFF++ for r=0.3 class 0.0 = 0.711 +- 0.293 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.3 class 1.0 = 0.632 +- 0.293 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.3 all KL = 0.652 +- 0.293 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.3 all L1 = 0.672 +- 0.240 (in-sample avg dev_std = 0.467)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.631
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.594
SUFF++ for r=0.6 class 0.0 = 0.81 +- 0.266 (in-sample avg dev_std = 0.345)
SUFF++ for r=0.6 class 1.0 = 0.692 +- 0.266 (in-sample avg dev_std = 0.345)
SUFF++ for r=0.6 all KL = 0.77 +- 0.266 (in-sample avg dev_std = 0.345)
SUFF++ for r=0.6 all L1 = 0.751 +- 0.230 (in-sample avg dev_std = 0.345)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.708
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.662
SUFF++ for r=0.9 class 0.0 = 0.918 +- 0.174 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.9 class 1.0 = 0.802 +- 0.174 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.9 all KL = 0.902 +- 0.174 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.9 all L1 = 0.86 +- 0.192 (in-sample avg dev_std = 0.214)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.768
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 799
Effective ratio: 0.309 +- 0.011
Model ROC-AUC over intervened graphs for r=0.3 =  0.672
NEC for r=0.3 class 0.0 = 0.234 +- 0.317 (in-sample avg dev_std = 0.390)
NEC for r=0.3 class 1.0 = 0.367 +- 0.317 (in-sample avg dev_std = 0.390)
NEC for r=0.3 all KL = 0.299 +- 0.317 (in-sample avg dev_std = 0.390)
NEC for r=0.3 all L1 = 0.3 +- 0.252 (in-sample avg dev_std = 0.390)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.839
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 799
Effective ratio: 0.609 +- 0.016
Model ROC-AUC over intervened graphs for r=0.6 =  0.738
NEC for r=0.6 class 0.0 = 0.197 +- 0.313 (in-sample avg dev_std = 0.382)
NEC for r=0.6 class 1.0 = 0.416 +- 0.313 (in-sample avg dev_std = 0.382)
NEC for r=0.6 all KL = 0.289 +- 0.313 (in-sample avg dev_std = 0.382)
NEC for r=0.6 all L1 = 0.307 +- 0.247 (in-sample avg dev_std = 0.382)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.904
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 799
Effective ratio: 0.908 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.805
NEC for r=0.9 class 0.0 = 0.085 +- 0.306 (in-sample avg dev_std = 0.351)
NEC for r=0.9 class 1.0 = 0.387 +- 0.306 (in-sample avg dev_std = 0.351)
NEC for r=0.9 all KL = 0.225 +- 0.306 (in-sample avg dev_std = 0.351)
NEC for r=0.9 all L1 = 0.236 +- 0.247 (in-sample avg dev_std = 0.351)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.916
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 799
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.807
NEC for r=1.0 class 0.0 = 0.06 +- 0.278 (in-sample avg dev_std = 0.315)
NEC for r=1.0 class 1.0 = 0.378 +- 0.278 (in-sample avg dev_std = 0.315)
NEC for r=1.0 all KL = 0.197 +- 0.278 (in-sample avg dev_std = 0.315)
NEC for r=1.0 all L1 = 0.219 +- 0.249 (in-sample avg dev_std = 0.315)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.755
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.652
NEC for r=0.3 class 0.0 = 0.221 +- 0.332 (in-sample avg dev_std = 0.390)
NEC for r=0.3 class 1.0 = 0.402 +- 0.332 (in-sample avg dev_std = 0.390)
NEC for r=0.3 all KL = 0.318 +- 0.332 (in-sample avg dev_std = 0.390)
NEC for r=0.3 all L1 = 0.312 +- 0.267 (in-sample avg dev_std = 0.390)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.787
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.697
NEC for r=0.6 class 0.0 = 0.18 +- 0.328 (in-sample avg dev_std = 0.386)
NEC for r=0.6 class 1.0 = 0.415 +- 0.328 (in-sample avg dev_std = 0.386)
NEC for r=0.6 all KL = 0.298 +- 0.328 (in-sample avg dev_std = 0.386)
NEC for r=0.6 all L1 = 0.297 +- 0.255 (in-sample avg dev_std = 0.386)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.854
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.75
NEC for r=0.9 class 0.0 = 0.074 +- 0.309 (in-sample avg dev_std = 0.338)
NEC for r=0.9 class 1.0 = 0.374 +- 0.309 (in-sample avg dev_std = 0.338)
NEC for r=0.9 all KL = 0.22 +- 0.309 (in-sample avg dev_std = 0.338)
NEC for r=0.9 all L1 = 0.224 +- 0.254 (in-sample avg dev_std = 0.338)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.851
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.749
NEC for r=1.0 class 0.0 = 0.06 +- 0.291 (in-sample avg dev_std = 0.311)
NEC for r=1.0 class 1.0 = 0.348 +- 0.291 (in-sample avg dev_std = 0.311)
NEC for r=1.0 all KL = 0.195 +- 0.291 (in-sample avg dev_std = 0.311)
NEC for r=1.0 all L1 = 0.204 +- 0.252 (in-sample avg dev_std = 0.311)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.643
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.567
NEC for r=0.3 class 0.0 = 0.332 +- 0.377 (in-sample avg dev_std = 0.466)
NEC for r=0.3 class 1.0 = 0.446 +- 0.377 (in-sample avg dev_std = 0.466)
NEC for r=0.3 all KL = 0.445 +- 0.377 (in-sample avg dev_std = 0.466)
NEC for r=0.3 all L1 = 0.389 +- 0.279 (in-sample avg dev_std = 0.466)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.712
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.665
NEC for r=0.6 class 0.0 = 0.284 +- 0.337 (in-sample avg dev_std = 0.422)
NEC for r=0.6 class 1.0 = 0.411 +- 0.337 (in-sample avg dev_std = 0.422)
NEC for r=0.6 all KL = 0.362 +- 0.337 (in-sample avg dev_std = 0.422)
NEC for r=0.6 all L1 = 0.347 +- 0.258 (in-sample avg dev_std = 0.422)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.71
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.711
NEC for r=0.9 class 0.0 = 0.176 +- 0.293 (in-sample avg dev_std = 0.337)
NEC for r=0.9 class 1.0 = 0.346 +- 0.293 (in-sample avg dev_std = 0.337)
NEC for r=0.9 all KL = 0.242 +- 0.293 (in-sample avg dev_std = 0.337)
NEC for r=0.9 all L1 = 0.261 +- 0.239 (in-sample avg dev_std = 0.337)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.734
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.717
NEC for r=1.0 class 0.0 = 0.128 +- 0.266 (in-sample avg dev_std = 0.295)
NEC for r=1.0 class 1.0 = 0.313 +- 0.266 (in-sample avg dev_std = 0.295)
NEC for r=1.0 all KL = 0.199 +- 0.266 (in-sample avg dev_std = 0.295)
NEC for r=1.0 all L1 = 0.22 +- 0.227 (in-sample avg dev_std = 0.295)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.617
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.51
NEC for r=0.3 class 0.0 = 0.24 +- 0.315 (in-sample avg dev_std = 0.372)
NEC for r=0.3 class 1.0 = 0.352 +- 0.315 (in-sample avg dev_std = 0.372)
NEC for r=0.3 all KL = 0.297 +- 0.315 (in-sample avg dev_std = 0.372)
NEC for r=0.3 all L1 = 0.296 +- 0.261 (in-sample avg dev_std = 0.372)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.631
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.545
NEC for r=0.6 class 0.0 = 0.2 +- 0.295 (in-sample avg dev_std = 0.315)
NEC for r=0.6 class 1.0 = 0.323 +- 0.295 (in-sample avg dev_std = 0.315)
NEC for r=0.6 all KL = 0.238 +- 0.295 (in-sample avg dev_std = 0.315)
NEC for r=0.6 all L1 = 0.262 +- 0.250 (in-sample avg dev_std = 0.315)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.708
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.587
NEC for r=0.9 class 0.0 = 0.097 +- 0.254 (in-sample avg dev_std = 0.261)
NEC for r=0.9 class 1.0 = 0.291 +- 0.254 (in-sample avg dev_std = 0.261)
NEC for r=0.9 all KL = 0.168 +- 0.254 (in-sample avg dev_std = 0.261)
NEC for r=0.9 all L1 = 0.194 +- 0.235 (in-sample avg dev_std = 0.261)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.731
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.626
NEC for r=1.0 class 0.0 = 0.073 +- 0.205 (in-sample avg dev_std = 0.214)
NEC for r=1.0 class 1.0 = 0.207 +- 0.205 (in-sample avg dev_std = 0.214)
NEC for r=1.0 all KL = 0.116 +- 0.205 (in-sample avg dev_std = 0.214)
NEC for r=1.0 all L1 = 0.14 +- 0.195 (in-sample avg dev_std = 0.214)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 00:23:04 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 05/03/2024 12:23:04 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/03/2024 12:23:07 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/03/2024 12:23:10 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/03/2024 12:23:14 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 60...
[0m[1;37mINFO[0m: [1mCheckpoint 60: 
-----------------------------------
Train ROC-AUC: 0.8914
Train Loss: 0.1030
ID Validation ROC-AUC: 0.8333
ID Validation Loss: 0.1268
ID Test ROC-AUC: 0.8162
ID Test Loss: 0.1118
OOD Validation ROC-AUC: 0.7585
OOD Validation Loss: 0.1609
OOD Test ROC-AUC: 0.7069
OOD Test Loss: 0.1103

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 78...
[0m[1;37mINFO[0m: [1mCheckpoint 78: 
-----------------------------------
Train ROC-AUC: 0.9091
Train Loss: 0.0967
ID Validation ROC-AUC: 0.8144
ID Validation Loss: 0.1288
ID Test ROC-AUC: 0.8068
ID Test Loss: 0.1150
OOD Validation ROC-AUC: 0.7991
OOD Validation Loss: 0.1289
OOD Test ROC-AUC: 0.7176
OOD Test Loss: 0.1091

[0m[1;37mINFO[0m: [1mChartInfo 0.8162 0.7069 0.8068 0.7176 0.8144 0.7991[0mGOODHIV(24682)
Data example from train: Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
Label distribution from train: (tensor([0., 1.]), tensor([23758,   924]))
[1;34mDEBUG[0m: 05/03/2024 12:23:16 AM : [1mUnbalanced warning for GOODHIV (train)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([924, 924]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 05/03/2024 12:23:21 AM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 05/03/2024 12:23:24 AM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 05/03/2024 12:23:25 AM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.717
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 799
Effective ratio: 0.309 +- 0.011
Model ROC-AUC over intervened graphs for r=0.3 =  0.663
SUFF++ for r=0.3 class 0.0 = 0.9 +- 0.190 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.3 class 1.0 = 0.779 +- 0.190 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.3 all KL = 0.879 +- 0.190 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.3 all L1 = 0.839 +- 0.192 (in-sample avg dev_std = 0.268)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.779
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 799
Effective ratio: 0.609 +- 0.016
Model ROC-AUC over intervened graphs for r=0.6 =  0.72
SUFF++ for r=0.6 class 0.0 = 0.914 +- 0.209 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.6 class 1.0 = 0.737 +- 0.209 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.6 all KL = 0.874 +- 0.209 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.6 all L1 = 0.826 +- 0.209 (in-sample avg dev_std = 0.264)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.869
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 799
Effective ratio: 0.908 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.785
SUFF++ for r=0.9 class 0.0 = 0.948 +- 0.215 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.9 class 1.0 = 0.735 +- 0.215 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.9 all KL = 0.885 +- 0.215 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.9 all L1 = 0.842 +- 0.208 (in-sample avg dev_std = 0.259)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.738
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.648
SUFF++ for r=0.3 class 0.0 = 0.917 +- 0.193 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.3 class 1.0 = 0.765 +- 0.193 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.3 all KL = 0.878 +- 0.193 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.3 all L1 = 0.841 +- 0.193 (in-sample avg dev_std = 0.264)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.788
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.688
SUFF++ for r=0.6 class 0.0 = 0.923 +- 0.216 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.6 class 1.0 = 0.718 +- 0.216 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.6 all KL = 0.868 +- 0.216 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.6 all L1 = 0.821 +- 0.221 (in-sample avg dev_std = 0.262)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.824
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.749
SUFF++ for r=0.9 class 0.0 = 0.937 +- 0.244 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.9 class 1.0 = 0.71 +- 0.244 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.9 all KL = 0.859 +- 0.244 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.9 all L1 = 0.824 +- 0.224 (in-sample avg dev_std = 0.301)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.642
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.597
SUFF++ for r=0.3 class 0.0 = 0.872 +- 0.172 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.3 class 1.0 = 0.78 +- 0.172 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.3 all KL = 0.872 +- 0.172 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.3 all L1 = 0.826 +- 0.198 (in-sample avg dev_std = 0.287)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.688
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.644
SUFF++ for r=0.6 class 0.0 = 0.88 +- 0.176 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.6 class 1.0 = 0.753 +- 0.176 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.6 all KL = 0.878 +- 0.176 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.6 all L1 = 0.817 +- 0.188 (in-sample avg dev_std = 0.256)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.732
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.699
SUFF++ for r=0.9 class 0.0 = 0.904 +- 0.251 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.9 class 1.0 = 0.691 +- 0.251 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.9 all KL = 0.843 +- 0.251 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.9 all L1 = 0.798 +- 0.238 (in-sample avg dev_std = 0.258)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.554
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.515
SUFF++ for r=0.3 class 0.0 = 0.93 +- 0.146 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.3 class 1.0 = 0.883 +- 0.146 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.3 all KL = 0.925 +- 0.146 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.3 all L1 = 0.907 +- 0.148 (in-sample avg dev_std = 0.228)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.623
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.54
SUFF++ for r=0.6 class 0.0 = 0.921 +- 0.162 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.6 class 1.0 = 0.836 +- 0.162 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.6 all KL = 0.904 +- 0.162 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.6 all L1 = 0.878 +- 0.158 (in-sample avg dev_std = 0.228)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.68
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.61
SUFF++ for r=0.9 class 0.0 = 0.944 +- 0.160 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.9 class 1.0 = 0.864 +- 0.160 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.9 all KL = 0.929 +- 0.160 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.9 all L1 = 0.904 +- 0.158 (in-sample avg dev_std = 0.205)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.717
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 799
Effective ratio: 0.309 +- 0.011
Model ROC-AUC over intervened graphs for r=0.3 =  0.644
NEC for r=0.3 class 0.0 = 0.1 +- 0.217 (in-sample avg dev_std = 0.221)
NEC for r=0.3 class 1.0 = 0.233 +- 0.217 (in-sample avg dev_std = 0.221)
NEC for r=0.3 all KL = 0.125 +- 0.217 (in-sample avg dev_std = 0.221)
NEC for r=0.3 all L1 = 0.167 +- 0.216 (in-sample avg dev_std = 0.221)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.779
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 799
Effective ratio: 0.609 +- 0.016
Model ROC-AUC over intervened graphs for r=0.6 =  0.734
NEC for r=0.6 class 0.0 = 0.078 +- 0.205 (in-sample avg dev_std = 0.222)
NEC for r=0.6 class 1.0 = 0.261 +- 0.205 (in-sample avg dev_std = 0.222)
NEC for r=0.6 all KL = 0.119 +- 0.205 (in-sample avg dev_std = 0.222)
NEC for r=0.6 all L1 = 0.169 +- 0.216 (in-sample avg dev_std = 0.222)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.869
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 799
Effective ratio: 0.908 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.787
NEC for r=0.9 class 0.0 = 0.045 +- 0.220 (in-sample avg dev_std = 0.252)
NEC for r=0.9 class 1.0 = 0.28 +- 0.220 (in-sample avg dev_std = 0.252)
NEC for r=0.9 all KL = 0.12 +- 0.220 (in-sample avg dev_std = 0.252)
NEC for r=0.9 all L1 = 0.163 +- 0.214 (in-sample avg dev_std = 0.252)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.884
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 799
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.795
NEC for r=1.0 class 0.0 = 0.04 +- 0.240 (in-sample avg dev_std = 0.278)
NEC for r=1.0 class 1.0 = 0.323 +- 0.240 (in-sample avg dev_std = 0.278)
NEC for r=1.0 all KL = 0.143 +- 0.240 (in-sample avg dev_std = 0.278)
NEC for r=1.0 all L1 = 0.181 +- 0.236 (in-sample avg dev_std = 0.278)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.738
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.619
NEC for r=0.3 class 0.0 = 0.078 +- 0.217 (in-sample avg dev_std = 0.199)
NEC for r=0.3 class 1.0 = 0.25 +- 0.217 (in-sample avg dev_std = 0.199)
NEC for r=0.3 all KL = 0.125 +- 0.217 (in-sample avg dev_std = 0.199)
NEC for r=0.3 all L1 = 0.164 +- 0.218 (in-sample avg dev_std = 0.199)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.788
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.692
NEC for r=0.6 class 0.0 = 0.069 +- 0.220 (in-sample avg dev_std = 0.214)
NEC for r=0.6 class 1.0 = 0.284 +- 0.220 (in-sample avg dev_std = 0.214)
NEC for r=0.6 all KL = 0.126 +- 0.220 (in-sample avg dev_std = 0.214)
NEC for r=0.6 all L1 = 0.176 +- 0.229 (in-sample avg dev_std = 0.214)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.824
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.724
NEC for r=0.9 class 0.0 = 0.047 +- 0.252 (in-sample avg dev_std = 0.226)
NEC for r=0.9 class 1.0 = 0.309 +- 0.252 (in-sample avg dev_std = 0.226)
NEC for r=0.9 all KL = 0.139 +- 0.252 (in-sample avg dev_std = 0.226)
NEC for r=0.9 all L1 = 0.178 +- 0.242 (in-sample avg dev_std = 0.226)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.836
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.732
NEC for r=1.0 class 0.0 = 0.045 +- 0.287 (in-sample avg dev_std = 0.273)
NEC for r=1.0 class 1.0 = 0.35 +- 0.287 (in-sample avg dev_std = 0.273)
NEC for r=1.0 all KL = 0.173 +- 0.287 (in-sample avg dev_std = 0.273)
NEC for r=1.0 all L1 = 0.197 +- 0.267 (in-sample avg dev_std = 0.273)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.642
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.532
NEC for r=0.3 class 0.0 = 0.134 +- 0.210 (in-sample avg dev_std = 0.195)
NEC for r=0.3 class 1.0 = 0.223 +- 0.210 (in-sample avg dev_std = 0.195)
NEC for r=0.3 all KL = 0.132 +- 0.210 (in-sample avg dev_std = 0.195)
NEC for r=0.3 all L1 = 0.179 +- 0.223 (in-sample avg dev_std = 0.195)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.688
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.63
NEC for r=0.6 class 0.0 = 0.109 +- 0.206 (in-sample avg dev_std = 0.222)
NEC for r=0.6 class 1.0 = 0.268 +- 0.206 (in-sample avg dev_std = 0.222)
NEC for r=0.6 all KL = 0.128 +- 0.206 (in-sample avg dev_std = 0.222)
NEC for r=0.6 all L1 = 0.188 +- 0.218 (in-sample avg dev_std = 0.222)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.732
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.678
NEC for r=0.9 class 0.0 = 0.085 +- 0.262 (in-sample avg dev_std = 0.248)
NEC for r=0.9 class 1.0 = 0.323 +- 0.262 (in-sample avg dev_std = 0.248)
NEC for r=0.9 all KL = 0.159 +- 0.262 (in-sample avg dev_std = 0.248)
NEC for r=0.9 all L1 = 0.204 +- 0.246 (in-sample avg dev_std = 0.248)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.742
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.688
NEC for r=1.0 class 0.0 = 0.079 +- 0.276 (in-sample avg dev_std = 0.268)
NEC for r=1.0 class 1.0 = 0.345 +- 0.276 (in-sample avg dev_std = 0.268)
NEC for r=1.0 all KL = 0.175 +- 0.276 (in-sample avg dev_std = 0.268)
NEC for r=1.0 all L1 = 0.212 +- 0.259 (in-sample avg dev_std = 0.268)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.553
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.53
NEC for r=0.3 class 0.0 = 0.057 +- 0.158 (in-sample avg dev_std = 0.181)
NEC for r=0.3 class 1.0 = 0.123 +- 0.158 (in-sample avg dev_std = 0.181)
NEC for r=0.3 all KL = 0.073 +- 0.158 (in-sample avg dev_std = 0.181)
NEC for r=0.3 all L1 = 0.09 +- 0.148 (in-sample avg dev_std = 0.181)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.623
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.547
NEC for r=0.6 class 0.0 = 0.063 +- 0.167 (in-sample avg dev_std = 0.195)
NEC for r=0.6 class 1.0 = 0.167 +- 0.167 (in-sample avg dev_std = 0.195)
NEC for r=0.6 all KL = 0.082 +- 0.167 (in-sample avg dev_std = 0.195)
NEC for r=0.6 all L1 = 0.115 +- 0.168 (in-sample avg dev_std = 0.195)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.679
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.615
NEC for r=0.9 class 0.0 = 0.046 +- 0.185 (in-sample avg dev_std = 0.167)
NEC for r=0.9 class 1.0 = 0.154 +- 0.185 (in-sample avg dev_std = 0.167)
NEC for r=0.9 all KL = 0.074 +- 0.185 (in-sample avg dev_std = 0.167)
NEC for r=0.9 all L1 = 0.1 +- 0.178 (in-sample avg dev_std = 0.167)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.677
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.602
NEC for r=1.0 class 0.0 = 0.053 +- 0.189 (in-sample avg dev_std = 0.144)
NEC for r=1.0 class 1.0 = 0.153 +- 0.189 (in-sample avg dev_std = 0.144)
NEC for r=1.0 all KL = 0.074 +- 0.189 (in-sample avg dev_std = 0.144)
NEC for r=1.0 all L1 = 0.103 +- 0.180 (in-sample avg dev_std = 0.144)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 00:26:10 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 05/03/2024 12:26:10 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/03/2024 12:26:13 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/03/2024 12:26:17 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/03/2024 12:26:20 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 147...
[0m[1;37mINFO[0m: [1mCheckpoint 147: 
-----------------------------------
Train ROC-AUC: 0.9460
Train Loss: 0.0798
ID Validation ROC-AUC: 0.8348
ID Validation Loss: 0.1236
ID Test ROC-AUC: 0.8277
ID Test Loss: 0.1100
OOD Validation ROC-AUC: 0.7600
OOD Validation Loss: 0.1336
OOD Test ROC-AUC: 0.6881
OOD Test Loss: 0.1033

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 134...
[0m[1;37mINFO[0m: [1mCheckpoint 134: 
-----------------------------------
Train ROC-AUC: 0.9382
Train Loss: 0.0885
ID Validation ROC-AUC: 0.8110
ID Validation Loss: 0.1374
ID Test ROC-AUC: 0.8157
ID Test Loss: 0.1247
OOD Validation ROC-AUC: 0.7896
OOD Validation Loss: 0.1525
OOD Test ROC-AUC: 0.6915
OOD Test Loss: 0.1147

[0m[1;37mINFO[0m: [1mChartInfo 0.8277 0.6881 0.8157 0.6915 0.8110 0.7896[0mGOODHIV(24682)
Data example from train: Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
Label distribution from train: (tensor([0., 1.]), tensor([23758,   924]))
[1;34mDEBUG[0m: 05/03/2024 12:26:23 AM : [1mUnbalanced warning for GOODHIV (train)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([924, 924]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 05/03/2024 12:26:28 AM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 05/03/2024 12:26:30 AM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 05/03/2024 12:26:32 AM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.776
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 799
Effective ratio: 0.309 +- 0.011
Model ROC-AUC over intervened graphs for r=0.3 =  0.713
SUFF++ for r=0.3 class 0.0 = 0.699 +- 0.309 (in-sample avg dev_std = 0.521)
SUFF++ for r=0.3 class 1.0 = 0.649 +- 0.309 (in-sample avg dev_std = 0.521)
SUFF++ for r=0.3 all KL = 0.61 +- 0.309 (in-sample avg dev_std = 0.521)
SUFF++ for r=0.3 all L1 = 0.674 +- 0.211 (in-sample avg dev_std = 0.521)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.852
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 799
Effective ratio: 0.609 +- 0.016
Model ROC-AUC over intervened graphs for r=0.6 =  0.769
SUFF++ for r=0.6 class 0.0 = 0.806 +- 0.277 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 class 1.0 = 0.677 +- 0.277 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 all KL = 0.734 +- 0.277 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 all L1 = 0.741 +- 0.208 (in-sample avg dev_std = 0.417)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.912
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 799
Effective ratio: 0.908 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.835
SUFF++ for r=0.9 class 0.0 = 0.934 +- 0.229 (in-sample avg dev_std = 0.318)
SUFF++ for r=0.9 class 1.0 = 0.719 +- 0.229 (in-sample avg dev_std = 0.318)
SUFF++ for r=0.9 all KL = 0.861 +- 0.229 (in-sample avg dev_std = 0.318)
SUFF++ for r=0.9 all L1 = 0.826 +- 0.208 (in-sample avg dev_std = 0.318)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.755
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.666
SUFF++ for r=0.3 class 0.0 = 0.692 +- 0.326 (in-sample avg dev_std = 0.559)
SUFF++ for r=0.3 class 1.0 = 0.625 +- 0.326 (in-sample avg dev_std = 0.559)
SUFF++ for r=0.3 all KL = 0.56 +- 0.326 (in-sample avg dev_std = 0.559)
SUFF++ for r=0.3 all L1 = 0.659 +- 0.209 (in-sample avg dev_std = 0.559)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.829
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.715
SUFF++ for r=0.6 class 0.0 = 0.804 +- 0.305 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.6 class 1.0 = 0.64 +- 0.305 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.6 all KL = 0.689 +- 0.305 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.6 all L1 = 0.722 +- 0.213 (in-sample avg dev_std = 0.466)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.855
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.783
SUFF++ for r=0.9 class 0.0 = 0.94 +- 0.266 (in-sample avg dev_std = 0.359)
SUFF++ for r=0.9 class 1.0 = 0.71 +- 0.266 (in-sample avg dev_std = 0.359)
SUFF++ for r=0.9 all KL = 0.838 +- 0.266 (in-sample avg dev_std = 0.359)
SUFF++ for r=0.9 all L1 = 0.825 +- 0.220 (in-sample avg dev_std = 0.359)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.706
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.617
SUFF++ for r=0.3 class 0.0 = 0.64 +- 0.302 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.3 class 1.0 = 0.608 +- 0.302 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.3 all KL = 0.521 +- 0.302 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.3 all L1 = 0.624 +- 0.184 (in-sample avg dev_std = 0.582)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.728
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.67
SUFF++ for r=0.6 class 0.0 = 0.715 +- 0.280 (in-sample avg dev_std = 0.479)
SUFF++ for r=0.6 class 1.0 = 0.689 +- 0.280 (in-sample avg dev_std = 0.479)
SUFF++ for r=0.6 all KL = 0.668 +- 0.280 (in-sample avg dev_std = 0.479)
SUFF++ for r=0.6 all L1 = 0.702 +- 0.184 (in-sample avg dev_std = 0.479)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.718
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.705
SUFF++ for r=0.9 class 0.0 = 0.89 +- 0.268 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.9 class 1.0 = 0.748 +- 0.268 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.9 all KL = 0.83 +- 0.268 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.9 all L1 = 0.819 +- 0.200 (in-sample avg dev_std = 0.365)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.619
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.59
SUFF++ for r=0.3 class 0.0 = 0.674 +- 0.290 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.3 class 1.0 = 0.646 +- 0.290 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.3 all KL = 0.635 +- 0.290 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.3 all L1 = 0.66 +- 0.215 (in-sample avg dev_std = 0.478)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.639
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.571
SUFF++ for r=0.6 class 0.0 = 0.825 +- 0.256 (in-sample avg dev_std = 0.373)
SUFF++ for r=0.6 class 1.0 = 0.722 +- 0.256 (in-sample avg dev_std = 0.373)
SUFF++ for r=0.6 all KL = 0.783 +- 0.256 (in-sample avg dev_std = 0.373)
SUFF++ for r=0.6 all L1 = 0.774 +- 0.217 (in-sample avg dev_std = 0.373)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.707
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.646
SUFF++ for r=0.9 class 0.0 = 0.95 +- 0.177 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.9 class 1.0 = 0.859 +- 0.177 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.9 all KL = 0.924 +- 0.177 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.9 all L1 = 0.905 +- 0.167 (in-sample avg dev_std = 0.216)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.776
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 799
Effective ratio: 0.309 +- 0.011
Model ROC-AUC over intervened graphs for r=0.3 =  0.702
NEC for r=0.3 class 0.0 = 0.28 +- 0.327 (in-sample avg dev_std = 0.419)
NEC for r=0.3 class 1.0 = 0.336 +- 0.327 (in-sample avg dev_std = 0.419)
NEC for r=0.3 all KL = 0.337 +- 0.327 (in-sample avg dev_std = 0.419)
NEC for r=0.3 all L1 = 0.308 +- 0.244 (in-sample avg dev_std = 0.419)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.852
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 799
Effective ratio: 0.609 +- 0.016
Model ROC-AUC over intervened graphs for r=0.6 =  0.77
NEC for r=0.6 class 0.0 = 0.165 +- 0.295 (in-sample avg dev_std = 0.382)
NEC for r=0.6 class 1.0 = 0.339 +- 0.295 (in-sample avg dev_std = 0.382)
NEC for r=0.6 all KL = 0.258 +- 0.295 (in-sample avg dev_std = 0.382)
NEC for r=0.6 all L1 = 0.252 +- 0.223 (in-sample avg dev_std = 0.382)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.912
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 799
Effective ratio: 0.908 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.809
NEC for r=0.9 class 0.0 = 0.071 +- 0.280 (in-sample avg dev_std = 0.330)
NEC for r=0.9 class 1.0 = 0.366 +- 0.280 (in-sample avg dev_std = 0.330)
NEC for r=0.9 all KL = 0.199 +- 0.280 (in-sample avg dev_std = 0.330)
NEC for r=0.9 all L1 = 0.219 +- 0.243 (in-sample avg dev_std = 0.330)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.927
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 799
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.829
NEC for r=1.0 class 0.0 = 0.05 +- 0.269 (in-sample avg dev_std = 0.306)
NEC for r=1.0 class 1.0 = 0.36 +- 0.269 (in-sample avg dev_std = 0.306)
NEC for r=1.0 all KL = 0.18 +- 0.269 (in-sample avg dev_std = 0.306)
NEC for r=1.0 all L1 = 0.205 +- 0.247 (in-sample avg dev_std = 0.306)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.755
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.682
NEC for r=0.3 class 0.0 = 0.28 +- 0.345 (in-sample avg dev_std = 0.453)
NEC for r=0.3 class 1.0 = 0.383 +- 0.345 (in-sample avg dev_std = 0.453)
NEC for r=0.3 all KL = 0.395 +- 0.345 (in-sample avg dev_std = 0.453)
NEC for r=0.3 all L1 = 0.331 +- 0.249 (in-sample avg dev_std = 0.453)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.829
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.748
NEC for r=0.6 class 0.0 = 0.172 +- 0.317 (in-sample avg dev_std = 0.394)
NEC for r=0.6 class 1.0 = 0.38 +- 0.317 (in-sample avg dev_std = 0.394)
NEC for r=0.6 all KL = 0.289 +- 0.317 (in-sample avg dev_std = 0.394)
NEC for r=0.6 all L1 = 0.276 +- 0.241 (in-sample avg dev_std = 0.394)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.855
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.749
NEC for r=0.9 class 0.0 = 0.069 +- 0.311 (in-sample avg dev_std = 0.333)
NEC for r=0.9 class 1.0 = 0.374 +- 0.311 (in-sample avg dev_std = 0.333)
NEC for r=0.9 all KL = 0.22 +- 0.311 (in-sample avg dev_std = 0.333)
NEC for r=0.9 all L1 = 0.222 +- 0.259 (in-sample avg dev_std = 0.333)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.85
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.751
NEC for r=1.0 class 0.0 = 0.048 +- 0.308 (in-sample avg dev_std = 0.314)
NEC for r=1.0 class 1.0 = 0.362 +- 0.308 (in-sample avg dev_std = 0.314)
NEC for r=1.0 all KL = 0.204 +- 0.308 (in-sample avg dev_std = 0.314)
NEC for r=1.0 all L1 = 0.205 +- 0.264 (in-sample avg dev_std = 0.314)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.706
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.639
NEC for r=0.3 class 0.0 = 0.379 +- 0.332 (in-sample avg dev_std = 0.484)
NEC for r=0.3 class 1.0 = 0.405 +- 0.332 (in-sample avg dev_std = 0.484)
NEC for r=0.3 all KL = 0.458 +- 0.332 (in-sample avg dev_std = 0.484)
NEC for r=0.3 all L1 = 0.392 +- 0.248 (in-sample avg dev_std = 0.484)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.728
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.636
NEC for r=0.6 class 0.0 = 0.251 +- 0.319 (in-sample avg dev_std = 0.431)
NEC for r=0.6 class 1.0 = 0.385 +- 0.319 (in-sample avg dev_std = 0.431)
NEC for r=0.6 all KL = 0.345 +- 0.319 (in-sample avg dev_std = 0.431)
NEC for r=0.6 all L1 = 0.318 +- 0.224 (in-sample avg dev_std = 0.431)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.718
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.695
NEC for r=0.9 class 0.0 = 0.144 +- 0.292 (in-sample avg dev_std = 0.347)
NEC for r=0.9 class 1.0 = 0.337 +- 0.292 (in-sample avg dev_std = 0.347)
NEC for r=0.9 all KL = 0.229 +- 0.292 (in-sample avg dev_std = 0.347)
NEC for r=0.9 all L1 = 0.241 +- 0.237 (in-sample avg dev_std = 0.347)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.72
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.682
NEC for r=1.0 class 0.0 = 0.106 +- 0.295 (in-sample avg dev_std = 0.324)
NEC for r=1.0 class 1.0 = 0.34 +- 0.295 (in-sample avg dev_std = 0.324)
NEC for r=1.0 all KL = 0.21 +- 0.295 (in-sample avg dev_std = 0.324)
NEC for r=1.0 all L1 = 0.223 +- 0.252 (in-sample avg dev_std = 0.324)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.619
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.492
NEC for r=0.3 class 0.0 = 0.319 +- 0.323 (in-sample avg dev_std = 0.444)
NEC for r=0.3 class 1.0 = 0.381 +- 0.323 (in-sample avg dev_std = 0.444)
NEC for r=0.3 all KL = 0.367 +- 0.323 (in-sample avg dev_std = 0.444)
NEC for r=0.3 all L1 = 0.35 +- 0.249 (in-sample avg dev_std = 0.444)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.639
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.574
NEC for r=0.6 class 0.0 = 0.168 +- 0.271 (in-sample avg dev_std = 0.332)
NEC for r=0.6 class 1.0 = 0.28 +- 0.271 (in-sample avg dev_std = 0.332)
NEC for r=0.6 all KL = 0.217 +- 0.271 (in-sample avg dev_std = 0.332)
NEC for r=0.6 all L1 = 0.224 +- 0.219 (in-sample avg dev_std = 0.332)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.707
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.604
NEC for r=0.9 class 0.0 = 0.062 +- 0.224 (in-sample avg dev_std = 0.195)
NEC for r=0.9 class 1.0 = 0.201 +- 0.224 (in-sample avg dev_std = 0.195)
NEC for r=0.9 all KL = 0.114 +- 0.224 (in-sample avg dev_std = 0.195)
NEC for r=0.9 all L1 = 0.131 +- 0.206 (in-sample avg dev_std = 0.195)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.707
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.578
NEC for r=1.0 class 0.0 = 0.05 +- 0.183 (in-sample avg dev_std = 0.186)
NEC for r=1.0 class 1.0 = 0.147 +- 0.183 (in-sample avg dev_std = 0.186)
NEC for r=1.0 all KL = 0.086 +- 0.183 (in-sample avg dev_std = 0.186)
NEC for r=1.0 all L1 = 0.098 +- 0.165 (in-sample avg dev_std = 0.186)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 00:29:25 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 05/03/2024 12:29:25 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/03/2024 12:29:28 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/03/2024 12:29:32 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/03/2024 12:29:35 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 95...
[0m[1;37mINFO[0m: [1mCheckpoint 95: 
-----------------------------------
Train ROC-AUC: 0.9270
Train Loss: 0.0935
ID Validation ROC-AUC: 0.8352
ID Validation Loss: 0.1312
ID Test ROC-AUC: 0.8173
ID Test Loss: 0.1177
OOD Validation ROC-AUC: 0.7920
OOD Validation Loss: 0.1589
OOD Test ROC-AUC: 0.7147
OOD Test Loss: 0.1198

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 149...
[0m[1;37mINFO[0m: [1mCheckpoint 149: 
-----------------------------------
Train ROC-AUC: 0.9480
Train Loss: 0.0810
ID Validation ROC-AUC: 0.8212
ID Validation Loss: 0.1352
ID Test ROC-AUC: 0.8078
ID Test Loss: 0.1194
OOD Validation ROC-AUC: 0.7979
OOD Validation Loss: 0.1581
OOD Test ROC-AUC: 0.6967
OOD Test Loss: 0.1179

[0m[1;37mINFO[0m: [1mChartInfo 0.8173 0.7147 0.8078 0.6967 0.8212 0.7979[0mGOODHIV(24682)
Data example from train: Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
Label distribution from train: (tensor([0., 1.]), tensor([23758,   924]))
[1;34mDEBUG[0m: 05/03/2024 12:29:38 AM : [1mUnbalanced warning for GOODHIV (train)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([924, 924]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 05/03/2024 12:29:43 AM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 05/03/2024 12:29:45 AM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 05/03/2024 12:29:47 AM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.779
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 799
Effective ratio: 0.309 +- 0.011
Model ROC-AUC over intervened graphs for r=0.3 =  0.699
SUFF++ for r=0.3 class 0.0 = 0.779 +- 0.253 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 class 1.0 = 0.646 +- 0.253 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 all KL = 0.741 +- 0.253 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 all L1 = 0.712 +- 0.204 (in-sample avg dev_std = 0.415)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.846
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 799
Effective ratio: 0.609 +- 0.016
Model ROC-AUC over intervened graphs for r=0.6 =  0.777
SUFF++ for r=0.6 class 0.0 = 0.847 +- 0.252 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.6 class 1.0 = 0.689 +- 0.252 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.6 all KL = 0.789 +- 0.252 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.6 all L1 = 0.768 +- 0.199 (in-sample avg dev_std = 0.372)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.899
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 799
Effective ratio: 0.908 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.829
SUFF++ for r=0.9 class 0.0 = 0.926 +- 0.231 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.9 class 1.0 = 0.735 +- 0.231 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.9 all KL = 0.864 +- 0.231 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.9 all L1 = 0.83 +- 0.195 (in-sample avg dev_std = 0.301)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.757
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.669
SUFF++ for r=0.3 class 0.0 = 0.801 +- 0.278 (in-sample avg dev_std = 0.422)
SUFF++ for r=0.3 class 1.0 = 0.614 +- 0.278 (in-sample avg dev_std = 0.422)
SUFF++ for r=0.3 all KL = 0.72 +- 0.278 (in-sample avg dev_std = 0.422)
SUFF++ for r=0.3 all L1 = 0.708 +- 0.225 (in-sample avg dev_std = 0.422)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.807
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.717
SUFF++ for r=0.6 class 0.0 = 0.841 +- 0.277 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 class 1.0 = 0.688 +- 0.277 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 all KL = 0.765 +- 0.277 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 all L1 = 0.765 +- 0.202 (in-sample avg dev_std = 0.402)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.844
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.749
SUFF++ for r=0.9 class 0.0 = 0.916 +- 0.268 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.9 class 1.0 = 0.711 +- 0.268 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.9 all KL = 0.828 +- 0.268 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.9 all L1 = 0.814 +- 0.214 (in-sample avg dev_std = 0.353)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.687
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.623
SUFF++ for r=0.3 class 0.0 = 0.726 +- 0.248 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.3 class 1.0 = 0.618 +- 0.248 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.3 all KL = 0.696 +- 0.248 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.3 all L1 = 0.672 +- 0.199 (in-sample avg dev_std = 0.443)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.733
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.684
SUFF++ for r=0.6 class 0.0 = 0.774 +- 0.270 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 class 1.0 = 0.644 +- 0.270 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 all KL = 0.74 +- 0.270 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 all L1 = 0.709 +- 0.210 (in-sample avg dev_std = 0.396)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.75
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.713
SUFF++ for r=0.9 class 0.0 = 0.863 +- 0.231 (in-sample avg dev_std = 0.299)
SUFF++ for r=0.9 class 1.0 = 0.756 +- 0.231 (in-sample avg dev_std = 0.299)
SUFF++ for r=0.9 all KL = 0.847 +- 0.231 (in-sample avg dev_std = 0.299)
SUFF++ for r=0.9 all L1 = 0.809 +- 0.185 (in-sample avg dev_std = 0.299)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.706
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.628
SUFF++ for r=0.3 class 0.0 = 0.788 +- 0.258 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.3 class 1.0 = 0.662 +- 0.258 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.3 all KL = 0.733 +- 0.258 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.3 all L1 = 0.725 +- 0.206 (in-sample avg dev_std = 0.421)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.745
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.647
SUFF++ for r=0.6 class 0.0 = 0.866 +- 0.238 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 class 1.0 = 0.71 +- 0.238 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 all KL = 0.813 +- 0.238 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 all L1 = 0.788 +- 0.196 (in-sample avg dev_std = 0.346)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.751
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.67
SUFF++ for r=0.9 class 0.0 = 0.917 +- 0.165 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.9 class 1.0 = 0.832 +- 0.165 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.9 all KL = 0.913 +- 0.165 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.9 all L1 = 0.874 +- 0.159 (in-sample avg dev_std = 0.218)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.779
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 799
Effective ratio: 0.309 +- 0.011
Model ROC-AUC over intervened graphs for r=0.3 =  0.697
NEC for r=0.3 class 0.0 = 0.217 +- 0.283 (in-sample avg dev_std = 0.331)
NEC for r=0.3 class 1.0 = 0.368 +- 0.283 (in-sample avg dev_std = 0.331)
NEC for r=0.3 all KL = 0.247 +- 0.283 (in-sample avg dev_std = 0.331)
NEC for r=0.3 all L1 = 0.292 +- 0.237 (in-sample avg dev_std = 0.331)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.846
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 799
Effective ratio: 0.609 +- 0.016
Model ROC-AUC over intervened graphs for r=0.6 =  0.772
NEC for r=0.6 class 0.0 = 0.142 +- 0.293 (in-sample avg dev_std = 0.350)
NEC for r=0.6 class 1.0 = 0.358 +- 0.293 (in-sample avg dev_std = 0.350)
NEC for r=0.6 all KL = 0.232 +- 0.293 (in-sample avg dev_std = 0.350)
NEC for r=0.6 all L1 = 0.25 +- 0.231 (in-sample avg dev_std = 0.350)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.899
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 799
Effective ratio: 0.908 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.806
NEC for r=0.9 class 0.0 = 0.074 +- 0.284 (in-sample avg dev_std = 0.339)
NEC for r=0.9 class 1.0 = 0.348 +- 0.284 (in-sample avg dev_std = 0.339)
NEC for r=0.9 all KL = 0.199 +- 0.284 (in-sample avg dev_std = 0.339)
NEC for r=0.9 all L1 = 0.211 +- 0.232 (in-sample avg dev_std = 0.339)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.915
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 799
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.814
NEC for r=1.0 class 0.0 = 0.054 +- 0.286 (in-sample avg dev_std = 0.322)
NEC for r=1.0 class 1.0 = 0.355 +- 0.286 (in-sample avg dev_std = 0.322)
NEC for r=1.0 all KL = 0.191 +- 0.286 (in-sample avg dev_std = 0.322)
NEC for r=1.0 all L1 = 0.205 +- 0.242 (in-sample avg dev_std = 0.322)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.757
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.651
NEC for r=0.3 class 0.0 = 0.183 +- 0.298 (in-sample avg dev_std = 0.348)
NEC for r=0.3 class 1.0 = 0.392 +- 0.298 (in-sample avg dev_std = 0.348)
NEC for r=0.3 all KL = 0.262 +- 0.298 (in-sample avg dev_std = 0.348)
NEC for r=0.3 all L1 = 0.287 +- 0.249 (in-sample avg dev_std = 0.348)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.807
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.703
NEC for r=0.6 class 0.0 = 0.144 +- 0.321 (in-sample avg dev_std = 0.356)
NEC for r=0.6 class 1.0 = 0.384 +- 0.321 (in-sample avg dev_std = 0.356)
NEC for r=0.6 all KL = 0.253 +- 0.321 (in-sample avg dev_std = 0.356)
NEC for r=0.6 all L1 = 0.264 +- 0.250 (in-sample avg dev_std = 0.356)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.844
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.735
NEC for r=0.9 class 0.0 = 0.087 +- 0.318 (in-sample avg dev_std = 0.339)
NEC for r=0.9 class 1.0 = 0.376 +- 0.318 (in-sample avg dev_std = 0.339)
NEC for r=0.9 all KL = 0.231 +- 0.318 (in-sample avg dev_std = 0.339)
NEC for r=0.9 all L1 = 0.232 +- 0.259 (in-sample avg dev_std = 0.339)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.843
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.749
NEC for r=1.0 class 0.0 = 0.071 +- 0.311 (in-sample avg dev_std = 0.324)
NEC for r=1.0 class 1.0 = 0.354 +- 0.311 (in-sample avg dev_std = 0.324)
NEC for r=1.0 all KL = 0.211 +- 0.311 (in-sample avg dev_std = 0.324)
NEC for r=1.0 all L1 = 0.212 +- 0.259 (in-sample avg dev_std = 0.324)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.687
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.625
NEC for r=0.3 class 0.0 = 0.275 +- 0.284 (in-sample avg dev_std = 0.416)
NEC for r=0.3 class 1.0 = 0.396 +- 0.284 (in-sample avg dev_std = 0.416)
NEC for r=0.3 all KL = 0.306 +- 0.284 (in-sample avg dev_std = 0.416)
NEC for r=0.3 all L1 = 0.335 +- 0.231 (in-sample avg dev_std = 0.416)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.733
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.639
NEC for r=0.6 class 0.0 = 0.225 +- 0.302 (in-sample avg dev_std = 0.386)
NEC for r=0.6 class 1.0 = 0.392 +- 0.302 (in-sample avg dev_std = 0.386)
NEC for r=0.6 all KL = 0.279 +- 0.302 (in-sample avg dev_std = 0.386)
NEC for r=0.6 all L1 = 0.308 +- 0.235 (in-sample avg dev_std = 0.386)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.75
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.684
NEC for r=0.9 class 0.0 = 0.136 +- 0.299 (in-sample avg dev_std = 0.336)
NEC for r=0.9 class 1.0 = 0.353 +- 0.299 (in-sample avg dev_std = 0.336)
NEC for r=0.9 all KL = 0.224 +- 0.299 (in-sample avg dev_std = 0.336)
NEC for r=0.9 all L1 = 0.244 +- 0.242 (in-sample avg dev_std = 0.336)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.768
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.686
NEC for r=1.0 class 0.0 = 0.091 +- 0.318 (in-sample avg dev_std = 0.321)
NEC for r=1.0 class 1.0 = 0.358 +- 0.318 (in-sample avg dev_std = 0.321)
NEC for r=1.0 all KL = 0.216 +- 0.318 (in-sample avg dev_std = 0.321)
NEC for r=1.0 all L1 = 0.224 +- 0.254 (in-sample avg dev_std = 0.321)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.706
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.643
NEC for r=0.3 class 0.0 = 0.245 +- 0.294 (in-sample avg dev_std = 0.389)
NEC for r=0.3 class 1.0 = 0.338 +- 0.294 (in-sample avg dev_std = 0.389)
NEC for r=0.3 all KL = 0.282 +- 0.294 (in-sample avg dev_std = 0.389)
NEC for r=0.3 all L1 = 0.291 +- 0.231 (in-sample avg dev_std = 0.389)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.745
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.637
NEC for r=0.6 class 0.0 = 0.126 +- 0.241 (in-sample avg dev_std = 0.302)
NEC for r=0.6 class 1.0 = 0.269 +- 0.241 (in-sample avg dev_std = 0.302)
NEC for r=0.6 all KL = 0.165 +- 0.241 (in-sample avg dev_std = 0.302)
NEC for r=0.6 all L1 = 0.197 +- 0.202 (in-sample avg dev_std = 0.302)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.751
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.658
NEC for r=0.9 class 0.0 = 0.074 +- 0.192 (in-sample avg dev_std = 0.221)
NEC for r=0.9 class 1.0 = 0.212 +- 0.192 (in-sample avg dev_std = 0.221)
NEC for r=0.9 all KL = 0.107 +- 0.192 (in-sample avg dev_std = 0.221)
NEC for r=0.9 all L1 = 0.143 +- 0.184 (in-sample avg dev_std = 0.221)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.745
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.643
NEC for r=1.0 class 0.0 = 0.056 +- 0.186 (in-sample avg dev_std = 0.197)
NEC for r=1.0 class 1.0 = 0.183 +- 0.186 (in-sample avg dev_std = 0.197)
NEC for r=1.0 all KL = 0.09 +- 0.186 (in-sample avg dev_std = 0.197)
NEC for r=1.0 all L1 = 0.119 +- 0.171 (in-sample avg dev_std = 0.197)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split train
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.965, 0.964, 0.916, 1.0], 'all_L1': [0.952, 0.942, 0.864, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.628, 0.752, 0.883, 1.0], 'all_L1': [0.657, 0.732, 0.844, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.879, 0.874, 0.885, 1.0], 'all_L1': [0.839, 0.826, 0.842, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.61, 0.734, 0.861, 1.0], 'all_L1': [0.674, 0.741, 0.826, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.741, 0.789, 0.864, 1.0], 'all_L1': [0.712, 0.768, 0.83, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.036, 0.035, 0.091, 0.127], 'all_L1': [0.049, 0.058, 0.139, 0.169]}), defaultdict(<class 'list'>, {'all_KL': [0.299, 0.289, 0.225, 0.197], 'all_L1': [0.3, 0.307, 0.236, 0.219]}), defaultdict(<class 'list'>, {'all_KL': [0.125, 0.119, 0.12, 0.143], 'all_L1': [0.167, 0.169, 0.163, 0.181]}), defaultdict(<class 'list'>, {'all_KL': [0.337, 0.258, 0.199, 0.18], 'all_L1': [0.308, 0.252, 0.219, 0.205]}), defaultdict(<class 'list'>, {'all_KL': [0.247, 0.232, 0.199, 0.191], 'all_L1': [0.292, 0.25, 0.211, 0.205]})]

Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.957, 0.959, 0.904, 1.0], 'all_L1': [0.951, 0.937, 0.863, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.601, 0.746, 0.862, 1.0], 'all_L1': [0.648, 0.745, 0.839, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.878, 0.868, 0.859, 1.0], 'all_L1': [0.841, 0.821, 0.824, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.56, 0.689, 0.838, 1.0], 'all_L1': [0.659, 0.722, 0.825, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.72, 0.765, 0.828, 1.0], 'all_L1': [0.708, 0.765, 0.814, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.039, 0.047, 0.113, 0.142], 'all_L1': [0.05, 0.067, 0.15, 0.173]}), defaultdict(<class 'list'>, {'all_KL': [0.318, 0.298, 0.22, 0.195], 'all_L1': [0.312, 0.297, 0.224, 0.204]}), defaultdict(<class 'list'>, {'all_KL': [0.125, 0.126, 0.139, 0.173], 'all_L1': [0.164, 0.176, 0.178, 0.197]}), defaultdict(<class 'list'>, {'all_KL': [0.395, 0.289, 0.22, 0.204], 'all_L1': [0.331, 0.276, 0.222, 0.205]}), defaultdict(<class 'list'>, {'all_KL': [0.262, 0.253, 0.231, 0.211], 'all_L1': [0.287, 0.264, 0.232, 0.212]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.967, 0.966, 0.892, 1.0], 'all_L1': [0.962, 0.945, 0.847, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.543, 0.742, 0.901, 1.0], 'all_L1': [0.644, 0.737, 0.85, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.872, 0.878, 0.843, 1.0], 'all_L1': [0.826, 0.817, 0.798, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.521, 0.668, 0.83, 1.0], 'all_L1': [0.624, 0.702, 0.819, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.696, 0.74, 0.847, 1.0], 'all_L1': [0.672, 0.709, 0.809, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.032, 0.055, 0.139, 0.157], 'all_L1': [0.034, 0.068, 0.175, 0.196]}), defaultdict(<class 'list'>, {'all_KL': [0.445, 0.362, 0.242, 0.199], 'all_L1': [0.389, 0.347, 0.261, 0.22]}), defaultdict(<class 'list'>, {'all_KL': [0.132, 0.128, 0.159, 0.175], 'all_L1': [0.179, 0.188, 0.204, 0.212]}), defaultdict(<class 'list'>, {'all_KL': [0.458, 0.345, 0.229, 0.21], 'all_L1': [0.392, 0.318, 0.241, 0.223]}), defaultdict(<class 'list'>, {'all_KL': [0.306, 0.279, 0.224, 0.216], 'all_L1': [0.335, 0.308, 0.244, 0.224]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.971, 0.966, 0.954, 1.0], 'all_L1': [0.965, 0.952, 0.935, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.652, 0.77, 0.902, 1.0], 'all_L1': [0.672, 0.751, 0.86, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.925, 0.904, 0.929, 1.0], 'all_L1': [0.907, 0.878, 0.904, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.635, 0.783, 0.924, 1.0], 'all_L1': [0.66, 0.774, 0.905, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.733, 0.813, 0.913, 1.0], 'all_L1': [0.725, 0.788, 0.874, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.025, 0.03, 0.045, 0.048], 'all_L1': [0.033, 0.044, 0.064, 0.078]}), defaultdict(<class 'list'>, {'all_KL': [0.297, 0.238, 0.168, 0.116], 'all_L1': [0.296, 0.262, 0.194, 0.14]}), defaultdict(<class 'list'>, {'all_KL': [0.073, 0.082, 0.074, 0.074], 'all_L1': [0.09, 0.115, 0.1, 0.103]}), defaultdict(<class 'list'>, {'all_KL': [0.367, 0.217, 0.114, 0.086], 'all_L1': [0.35, 0.224, 0.131, 0.098]}), defaultdict(<class 'list'>, {'all_KL': [0.282, 0.165, 0.107, 0.09], 'all_L1': [0.291, 0.197, 0.143, 0.119]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split train
suff++ class all_L1  =  0.767 +- 0.112, 0.802 +- 0.077, 0.841 +- 0.013, 1.000 +- 0.000
suff++ class all_KL  =  0.765 +- 0.139, 0.823 +- 0.086, 0.882 +- 0.020, 1.000 +- 0.000
suff++_acc_int  =  0.682 +- 0.021, 0.749 +- 0.025, 0.821 +- 0.024
nec class all_L1  =  0.223 +- 0.101, 0.207 +- 0.087, 0.194 +- 0.037, 0.196 +- 0.018
nec class all_KL  =  0.209 +- 0.112, 0.187 +- 0.095, 0.167 +- 0.052, 0.168 +- 0.028
nec_acc_int  =  0.675 +- 0.022, 0.744 +- 0.024, 0.801 +- 0.008, 0.811 +- 0.011

Eval split id_val
suff++ class all_L1  =  0.761 +- 0.117, 0.798 +- 0.077, 0.833 +- 0.017, 1.000 +- 0.000
suff++ class all_KL  =  0.743 +- 0.154, 0.805 +- 0.096, 0.858 +- 0.026, 1.000 +- 0.000
suff++_acc_int  =  0.658 +- 0.011, 0.714 +- 0.013, 0.774 +- 0.021
nec class all_L1  =  0.229 +- 0.107, 0.216 +- 0.085, 0.201 +- 0.032, 0.198 +- 0.013
nec class all_KL  =  0.228 +- 0.129, 0.203 +- 0.099, 0.185 +- 0.049, 0.185 +- 0.025
nec_acc_int  =  0.647 +- 0.022, 0.704 +- 0.023, 0.741 +- 0.010, 0.748 +- 0.009

Eval split val
suff++ class all_L1  =  0.746 +- 0.129, 0.782 +- 0.091, 0.825 +- 0.021, 1.000 +- 0.000
suff++ class all_KL  =  0.720 +- 0.176, 0.799 +- 0.108, 0.863 +- 0.028, 1.000 +- 0.000
suff++_acc_int  =  0.629 +- 0.033, 0.674 +- 0.019, 0.707 +- 0.010
nec class all_L1  =  0.266 +- 0.139, 0.246 +- 0.104, 0.225 +- 0.031, 0.215 +- 0.010
nec class all_KL  =  0.275 +- 0.169, 0.234 +- 0.122, 0.199 +- 0.041, 0.191 +- 0.022
nec_acc_int  =  0.609 +- 0.053, 0.651 +- 0.021, 0.693 +- 0.011, 0.696 +- 0.013

Eval split test
suff++ class all_L1  =  0.786 +- 0.126, 0.829 +- 0.075, 0.896 +- 0.026, 1.000 +- 0.000
suff++ class all_KL  =  0.783 +- 0.139, 0.847 +- 0.076, 0.924 +- 0.017, 1.000 +- 0.000
suff++_acc_int  =  0.565 +- 0.042, 0.589 +- 0.035, 0.635 +- 0.032
nec class all_L1  =  0.212 +- 0.126, 0.168 +- 0.079, 0.126 +- 0.043, 0.108 +- 0.021
nec class all_KL  =  0.209 +- 0.134, 0.146 +- 0.079, 0.102 +- 0.041, 0.083 +- 0.022
nec_acc_int  =  0.551 +- 0.055, 0.570 +- 0.036, 0.609 +- 0.028, 0.613 +- 0.022


 -------------------------------------------------- 
Computing faithfulness

Eval split train
Faith. Aritm (L1)= 		  =  0.495 +- 0.009, 0.505 +- 0.009, 0.517 +- 0.014, 0.598 +- 0.009
Faith. Armon (L1)= 		  =  0.324 +- 0.127, 0.315 +- 0.114, 0.313 +- 0.049, 0.327 +- 0.025
Faith. GMean (L1)= 	  =  0.389 +- 0.092, 0.390 +- 0.085, 0.401 +- 0.037, 0.442 +- 0.021
Faith. Aritm (KL)= 		  =  0.487 +- 0.015, 0.505 +- 0.010, 0.524 +- 0.019, 0.584 +- 0.014
Faith. Armon (KL)= 		  =  0.300 +- 0.137, 0.287 +- 0.131, 0.276 +- 0.074, 0.286 +- 0.041
Faith. GMean (KL)= 	  =  0.366 +- 0.099, 0.367 +- 0.104, 0.378 +- 0.060, 0.408 +- 0.034

Eval split id_val
Faith. Aritm (L1)= 		  =  0.495 +- 0.008, 0.507 +- 0.009, 0.517 +- 0.011, 0.599 +- 0.007
Faith. Armon (L1)= 		  =  0.328 +- 0.130, 0.326 +- 0.111, 0.323 +- 0.041, 0.331 +- 0.019
Faith. GMean (L1)= 	  =  0.391 +- 0.093, 0.399 +- 0.080, 0.408 +- 0.031, 0.445 +- 0.015
Faith. Aritm (KL)= 		  =  0.486 +- 0.015, 0.504 +- 0.011, 0.521 +- 0.015, 0.592 +- 0.013
Faith. Armon (KL)= 		  =  0.311 +- 0.144, 0.305 +- 0.130, 0.300 +- 0.067, 0.311 +- 0.036
Faith. GMean (KL)= 	  =  0.373 +- 0.101, 0.380 +- 0.097, 0.393 +- 0.050, 0.429 +- 0.030

Eval split val
Faith. Aritm (L1)= 		  =  0.506 +- 0.006, 0.514 +- 0.014, 0.525 +- 0.019, 0.607 +- 0.005
Faith. Armon (L1)= 		  =  0.355 +- 0.160, 0.354 +- 0.127, 0.352 +- 0.039, 0.354 +- 0.014
Faith. GMean (L1)= 	  =  0.407 +- 0.121, 0.418 +- 0.090, 0.430 +- 0.031, 0.464 +- 0.011
Faith. Aritm (KL)= 		  =  0.497 +- 0.005, 0.516 +- 0.018, 0.531 +- 0.024, 0.596 +- 0.011
Faith. Armon (KL)= 		  =  0.339 +- 0.168, 0.335 +- 0.147, 0.321 +- 0.056, 0.321 +- 0.032
Faith. GMean (KL)= 	  =  0.391 +- 0.121, 0.404 +- 0.106, 0.411 +- 0.044, 0.437 +- 0.026

Eval split test
Faith. Aritm (L1)= 		  =  0.499 +- 0.008, 0.499 +- 0.005, 0.511 +- 0.010, 0.554 +- 0.010
Faith. Armon (L1)= 		  =  0.302 +- 0.158, 0.268 +- 0.110, 0.218 +- 0.066, 0.194 +- 0.034
Faith. GMean (L1)= 	  =  0.370 +- 0.118, 0.355 +- 0.086, 0.330 +- 0.055, 0.326 +- 0.032
Faith. Aritm (KL)= 		  =  0.496 +- 0.011, 0.497 +- 0.005, 0.513 +- 0.013, 0.541 +- 0.011
Faith. Armon (KL)= 		  =  0.293 +- 0.168, 0.237 +- 0.116, 0.180 +- 0.066, 0.152 +- 0.038
Faith. GMean (KL)= 	  =  0.359 +- 0.128, 0.330 +- 0.096, 0.299 +- 0.061, 0.285 +- 0.040
Computed for split load_split = id



Completed in  0:15:56.165879  for LECIGIN GOODHIV/scaffold



DONE LECI GOODHIV/scaffold

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 00:32:58 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/03/2024 12:32:59 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/03/2024 12:33:36 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/03/2024 12:33:48 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/03/2024 12:34:02 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/03/2024 12:34:20 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/03/2024 12:34:35 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/03/2024 12:34:35 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 12:34:36 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:34:36 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:34:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:34:36 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:34:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:34:36 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:34:36 AM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:34:36 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:34:36 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:34:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:34:36 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:34:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:34:36 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:34:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:34:36 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:34:36 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:34:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:34:36 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:34:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:34:36 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:34:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:34:36 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:34:36 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:34:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:34:36 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:34:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:34:36 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:34:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:34:36 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:34:36 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:34:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:34:36 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:34:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:34:36 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:34:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:34:36 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 167...
[0m[1;37mINFO[0m: [1mCheckpoint 167: 
-----------------------------------
Train ROC-AUC: 0.9683
Train Loss: 0.1420
ID Validation ROC-AUC: 0.9217
ID Validation Loss: 0.2255
ID Test ROC-AUC: 0.9251
ID Test Loss: 0.2246
OOD Validation ROC-AUC: 0.6374
OOD Validation Loss: 0.4787
OOD Test ROC-AUC: 0.6853
OOD Test Loss: 0.5698

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 23...
[0m[1;37mINFO[0m: [1mCheckpoint 23: 
-----------------------------------
Train ROC-AUC: 0.9140
Train Loss: 0.2226
ID Validation ROC-AUC: 0.9010
ID Validation Loss: 0.2385
ID Test ROC-AUC: 0.9039
ID Test Loss: 0.2385
OOD Validation ROC-AUC: 0.6822
OOD Validation Loss: 0.3129
OOD Test ROC-AUC: 0.7143
OOD Test Loss: 0.4523

[0m[1;37mINFO[0m: [1mChartInfo 0.9251 0.6853 0.9039 0.7143 0.9010 0.6822[0mLBAPcore(34179)
Data example from train: Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
Label distribution from train: (tensor([0., 1.]), tensor([ 3960, 30219]))
[1;34mDEBUG[0m: 05/03/2024 12:34:37 AM : [1mUnbalanced warning for LBAPcore (train)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 05/03/2024 12:34:43 AM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 05/03/2024 12:34:48 AM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 05/03/2024 12:34:53 AM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.611
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.598
SUFF++ for r=0.3 class 0.0 = 0.719 +- 0.304 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.3 class 1.0 = 0.756 +- 0.304 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.3 all KL = 0.6 +- 0.304 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.3 all L1 = 0.752 +- 0.209 (in-sample avg dev_std = 0.425)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.674
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.605
SUFF++ for r=0.6 class 0.0 = 0.753 +- 0.230 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.6 class 1.0 = 0.82 +- 0.230 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.6 all KL = 0.772 +- 0.230 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.6 all L1 = 0.812 +- 0.166 (in-sample avg dev_std = 0.341)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.659
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.63
SUFF++ for r=0.9 class 0.0 = 0.729 +- 0.171 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.9 class 1.0 = 0.818 +- 0.171 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.9 all KL = 0.866 +- 0.171 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.9 all L1 = 0.808 +- 0.179 (in-sample avg dev_std = 0.267)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.61
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.611
SUFF++ for r=0.3 class 0.0 = 0.697 +- 0.314 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.3 class 1.0 = 0.77 +- 0.314 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.3 all KL = 0.607 +- 0.314 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.3 all L1 = 0.761 +- 0.206 (in-sample avg dev_std = 0.429)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.649
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.619
SUFF++ for r=0.6 class 0.0 = 0.764 +- 0.229 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.6 class 1.0 = 0.838 +- 0.229 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.6 all KL = 0.788 +- 0.229 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.6 all L1 = 0.829 +- 0.169 (in-sample avg dev_std = 0.317)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.629
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.61
SUFF++ for r=0.9 class 0.0 = 0.769 +- 0.160 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 class 1.0 = 0.818 +- 0.160 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 all KL = 0.871 +- 0.160 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 all L1 = 0.812 +- 0.176 (in-sample avg dev_std = 0.251)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.502
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.556
SUFF++ for r=0.3 class 0.0 = 0.69 +- 0.301 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.3 class 1.0 = 0.731 +- 0.301 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.3 all KL = 0.579 +- 0.301 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.3 all L1 = 0.727 +- 0.204 (in-sample avg dev_std = 0.437)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.547
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.556
SUFF++ for r=0.6 class 0.0 = 0.755 +- 0.224 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.6 class 1.0 = 0.814 +- 0.224 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.6 all KL = 0.786 +- 0.224 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.6 all L1 = 0.809 +- 0.179 (in-sample avg dev_std = 0.328)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.509
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.529
SUFF++ for r=0.9 class 0.0 = 0.779 +- 0.169 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.9 class 1.0 = 0.794 +- 0.169 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.9 all KL = 0.859 +- 0.169 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.9 all L1 = 0.793 +- 0.177 (in-sample avg dev_std = 0.272)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.511
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.524
SUFF++ for r=0.3 class 0.0 = 0.711 +- 0.304 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.3 class 1.0 = 0.711 +- 0.304 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.3 all KL = 0.583 +- 0.304 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.3 all L1 = 0.711 +- 0.217 (in-sample avg dev_std = 0.438)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.576
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.556
SUFF++ for r=0.6 class 0.0 = 0.781 +- 0.235 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 class 1.0 = 0.787 +- 0.235 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 all KL = 0.766 +- 0.235 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 all L1 = 0.786 +- 0.192 (in-sample avg dev_std = 0.346)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.573
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.568
SUFF++ for r=0.9 class 0.0 = 0.748 +- 0.190 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.9 class 1.0 = 0.781 +- 0.190 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.9 all KL = 0.843 +- 0.190 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.9 all L1 = 0.776 +- 0.189 (in-sample avg dev_std = 0.297)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.611
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.605
NEC for r=0.3 class 0.0 = 0.281 +- 0.310 (in-sample avg dev_std = 0.377)
NEC for r=0.3 class 1.0 = 0.215 +- 0.310 (in-sample avg dev_std = 0.377)
NEC for r=0.3 all KL = 0.319 +- 0.310 (in-sample avg dev_std = 0.377)
NEC for r=0.3 all L1 = 0.223 +- 0.216 (in-sample avg dev_std = 0.377)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.674
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.621
NEC for r=0.6 class 0.0 = 0.273 +- 0.217 (in-sample avg dev_std = 0.299)
NEC for r=0.6 class 1.0 = 0.172 +- 0.217 (in-sample avg dev_std = 0.299)
NEC for r=0.6 all KL = 0.203 +- 0.217 (in-sample avg dev_std = 0.299)
NEC for r=0.6 all L1 = 0.184 +- 0.176 (in-sample avg dev_std = 0.299)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.659
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.635
NEC for r=0.9 class 0.0 = 0.254 +- 0.159 (in-sample avg dev_std = 0.259)
NEC for r=0.9 class 1.0 = 0.18 +- 0.159 (in-sample avg dev_std = 0.259)
NEC for r=0.9 all KL = 0.133 +- 0.159 (in-sample avg dev_std = 0.259)
NEC for r=0.9 all L1 = 0.189 +- 0.171 (in-sample avg dev_std = 0.259)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.647
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.621
NEC for r=1.0 class 0.0 = 0.26 +- 0.145 (in-sample avg dev_std = 0.257)
NEC for r=1.0 class 1.0 = 0.174 +- 0.145 (in-sample avg dev_std = 0.257)
NEC for r=1.0 all KL = 0.119 +- 0.145 (in-sample avg dev_std = 0.257)
NEC for r=1.0 all L1 = 0.184 +- 0.164 (in-sample avg dev_std = 0.257)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.61
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.633
NEC for r=0.3 class 0.0 = 0.33 +- 0.320 (in-sample avg dev_std = 0.371)
NEC for r=0.3 class 1.0 = 0.208 +- 0.320 (in-sample avg dev_std = 0.371)
NEC for r=0.3 all KL = 0.332 +- 0.320 (in-sample avg dev_std = 0.371)
NEC for r=0.3 all L1 = 0.222 +- 0.216 (in-sample avg dev_std = 0.371)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.649
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.625
NEC for r=0.6 class 0.0 = 0.24 +- 0.227 (in-sample avg dev_std = 0.298)
NEC for r=0.6 class 1.0 = 0.163 +- 0.227 (in-sample avg dev_std = 0.298)
NEC for r=0.6 all KL = 0.193 +- 0.227 (in-sample avg dev_std = 0.298)
NEC for r=0.6 all L1 = 0.172 +- 0.176 (in-sample avg dev_std = 0.298)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.629
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.626
NEC for r=0.9 class 0.0 = 0.265 +- 0.161 (in-sample avg dev_std = 0.260)
NEC for r=0.9 class 1.0 = 0.179 +- 0.161 (in-sample avg dev_std = 0.260)
NEC for r=0.9 all KL = 0.137 +- 0.161 (in-sample avg dev_std = 0.260)
NEC for r=0.9 all L1 = 0.189 +- 0.173 (in-sample avg dev_std = 0.260)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.637
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.628
NEC for r=1.0 class 0.0 = 0.277 +- 0.152 (in-sample avg dev_std = 0.260)
NEC for r=1.0 class 1.0 = 0.171 +- 0.152 (in-sample avg dev_std = 0.260)
NEC for r=1.0 all KL = 0.119 +- 0.152 (in-sample avg dev_std = 0.260)
NEC for r=1.0 all L1 = 0.183 +- 0.169 (in-sample avg dev_std = 0.260)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.502
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.562
NEC for r=0.3 class 0.0 = 0.282 +- 0.310 (in-sample avg dev_std = 0.375)
NEC for r=0.3 class 1.0 = 0.25 +- 0.310 (in-sample avg dev_std = 0.375)
NEC for r=0.3 all KL = 0.353 +- 0.310 (in-sample avg dev_std = 0.375)
NEC for r=0.3 all L1 = 0.252 +- 0.219 (in-sample avg dev_std = 0.375)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.547
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.55
NEC for r=0.6 class 0.0 = 0.255 +- 0.224 (in-sample avg dev_std = 0.315)
NEC for r=0.6 class 1.0 = 0.194 +- 0.224 (in-sample avg dev_std = 0.315)
NEC for r=0.6 all KL = 0.213 +- 0.224 (in-sample avg dev_std = 0.315)
NEC for r=0.6 all L1 = 0.199 +- 0.185 (in-sample avg dev_std = 0.315)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.509
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.576
NEC for r=0.9 class 0.0 = 0.263 +- 0.176 (in-sample avg dev_std = 0.264)
NEC for r=0.9 class 1.0 = 0.202 +- 0.176 (in-sample avg dev_std = 0.264)
NEC for r=0.9 all KL = 0.148 +- 0.176 (in-sample avg dev_std = 0.264)
NEC for r=0.9 all L1 = 0.208 +- 0.178 (in-sample avg dev_std = 0.264)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.503
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.545
NEC for r=1.0 class 0.0 = 0.25 +- 0.153 (in-sample avg dev_std = 0.273)
NEC for r=1.0 class 1.0 = 0.198 +- 0.153 (in-sample avg dev_std = 0.273)
NEC for r=1.0 all KL = 0.131 +- 0.153 (in-sample avg dev_std = 0.273)
NEC for r=1.0 all L1 = 0.203 +- 0.170 (in-sample avg dev_std = 0.273)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.511
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.535
NEC for r=0.3 class 0.0 = 0.281 +- 0.325 (in-sample avg dev_std = 0.407)
NEC for r=0.3 class 1.0 = 0.28 +- 0.325 (in-sample avg dev_std = 0.407)
NEC for r=0.3 all KL = 0.371 +- 0.325 (in-sample avg dev_std = 0.407)
NEC for r=0.3 all L1 = 0.28 +- 0.231 (in-sample avg dev_std = 0.407)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.576
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.587
NEC for r=0.6 class 0.0 = 0.253 +- 0.234 (in-sample avg dev_std = 0.336)
NEC for r=0.6 class 1.0 = 0.213 +- 0.234 (in-sample avg dev_std = 0.336)
NEC for r=0.6 all KL = 0.229 +- 0.234 (in-sample avg dev_std = 0.336)
NEC for r=0.6 all L1 = 0.22 +- 0.195 (in-sample avg dev_std = 0.336)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.573
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.581
NEC for r=0.9 class 0.0 = 0.258 +- 0.198 (in-sample avg dev_std = 0.292)
NEC for r=0.9 class 1.0 = 0.214 +- 0.198 (in-sample avg dev_std = 0.292)
NEC for r=0.9 all KL = 0.163 +- 0.198 (in-sample avg dev_std = 0.292)
NEC for r=0.9 all L1 = 0.222 +- 0.188 (in-sample avg dev_std = 0.292)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.572
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.588
NEC for r=1.0 class 0.0 = 0.259 +- 0.190 (in-sample avg dev_std = 0.301)
NEC for r=1.0 class 1.0 = 0.214 +- 0.190 (in-sample avg dev_std = 0.301)
NEC for r=1.0 all KL = 0.155 +- 0.190 (in-sample avg dev_std = 0.301)
NEC for r=1.0 all L1 = 0.222 +- 0.185 (in-sample avg dev_std = 0.301)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 00:41:03 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/03/2024 12:41:03 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/03/2024 12:41:37 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/03/2024 12:41:48 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/03/2024 12:42:00 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/03/2024 12:42:19 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/03/2024 12:42:39 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/03/2024 12:42:39 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 12:42:39 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:42:39 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:42:39 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:42:39 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:42:39 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:42:39 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:42:39 AM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:42:39 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:42:39 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:42:39 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:42:39 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:42:39 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:42:40 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:42:40 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:42:40 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:42:40 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:42:40 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:42:40 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:42:40 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:42:40 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:42:40 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:42:40 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:42:40 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:42:40 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:42:40 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:42:40 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:42:40 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:42:40 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:42:40 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:42:40 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:42:40 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:42:40 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:42:40 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:42:40 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:42:40 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:42:40 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 167...
[0m[1;37mINFO[0m: [1mCheckpoint 167: 
-----------------------------------
Train ROC-AUC: 0.9686
Train Loss: 0.1412
ID Validation ROC-AUC: 0.9211
ID Validation Loss: 0.2263
ID Test ROC-AUC: 0.9251
ID Test Loss: 0.2237
OOD Validation ROC-AUC: 0.6449
OOD Validation Loss: 0.4664
OOD Test ROC-AUC: 0.6906
OOD Test Loss: 0.5564

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 30...
[0m[1;37mINFO[0m: [1mCheckpoint 30: 
-----------------------------------
Train ROC-AUC: 0.9194
Train Loss: 0.2142
ID Validation ROC-AUC: 0.9010
ID Validation Loss: 0.2357
ID Test ROC-AUC: 0.9053
ID Test Loss: 0.2328
OOD Validation ROC-AUC: 0.6935
OOD Validation Loss: 0.3224
OOD Test ROC-AUC: 0.7183
OOD Test Loss: 0.4429

[0m[1;37mINFO[0m: [1mChartInfo 0.9251 0.6906 0.9053 0.7183 0.9010 0.6935[0mLBAPcore(34179)
Data example from train: Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
Label distribution from train: (tensor([0., 1.]), tensor([ 3960, 30219]))
[1;34mDEBUG[0m: 05/03/2024 12:42:40 AM : [1mUnbalanced warning for LBAPcore (train)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 05/03/2024 12:42:46 AM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 05/03/2024 12:42:52 AM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 05/03/2024 12:42:58 AM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.666
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.568
SUFF++ for r=0.3 class 0.0 = 0.727 +- 0.298 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.3 class 1.0 = 0.787 +- 0.298 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.3 all KL = 0.673 +- 0.298 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.3 all L1 = 0.78 +- 0.209 (in-sample avg dev_std = 0.414)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.616
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.546
SUFF++ for r=0.6 class 0.0 = 0.853 +- 0.230 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.6 class 1.0 = 0.884 +- 0.230 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.6 all KL = 0.831 +- 0.230 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.6 all L1 = 0.88 +- 0.171 (in-sample avg dev_std = 0.272)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.579
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.523
SUFF++ for r=0.9 class 0.0 = 0.888 +- 0.173 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.9 class 1.0 = 0.899 +- 0.173 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.9 all KL = 0.911 +- 0.173 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.9 all L1 = 0.898 +- 0.158 (in-sample avg dev_std = 0.210)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.656
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.57
SUFF++ for r=0.3 class 0.0 = 0.733 +- 0.308 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.3 class 1.0 = 0.778 +- 0.308 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.3 all KL = 0.657 +- 0.308 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.3 all L1 = 0.773 +- 0.210 (in-sample avg dev_std = 0.430)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.645
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.579
SUFF++ for r=0.6 class 0.0 = 0.852 +- 0.233 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.6 class 1.0 = 0.893 +- 0.233 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.6 all KL = 0.83 +- 0.233 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.6 all L1 = 0.888 +- 0.163 (in-sample avg dev_std = 0.265)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.634
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.555
SUFF++ for r=0.9 class 0.0 = 0.883 +- 0.161 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.9 class 1.0 = 0.905 +- 0.161 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.9 all KL = 0.921 +- 0.161 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.9 all L1 = 0.903 +- 0.154 (in-sample avg dev_std = 0.183)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.542
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.533
SUFF++ for r=0.3 class 0.0 = 0.749 +- 0.300 (in-sample avg dev_std = 0.408)
SUFF++ for r=0.3 class 1.0 = 0.779 +- 0.300 (in-sample avg dev_std = 0.408)
SUFF++ for r=0.3 all KL = 0.676 +- 0.300 (in-sample avg dev_std = 0.408)
SUFF++ for r=0.3 all L1 = 0.777 +- 0.212 (in-sample avg dev_std = 0.408)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.547
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.509
SUFF++ for r=0.6 class 0.0 = 0.872 +- 0.235 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.6 class 1.0 = 0.876 +- 0.235 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.6 all KL = 0.838 +- 0.235 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.6 all L1 = 0.876 +- 0.175 (in-sample avg dev_std = 0.272)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.478
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.504
SUFF++ for r=0.9 class 0.0 = 0.922 +- 0.171 (in-sample avg dev_std = 0.196)
SUFF++ for r=0.9 class 1.0 = 0.888 +- 0.171 (in-sample avg dev_std = 0.196)
SUFF++ for r=0.9 all KL = 0.91 +- 0.171 (in-sample avg dev_std = 0.196)
SUFF++ for r=0.9 all L1 = 0.891 +- 0.152 (in-sample avg dev_std = 0.196)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.497
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.493
SUFF++ for r=0.3 class 0.0 = 0.775 +- 0.300 (in-sample avg dev_std = 0.435)
SUFF++ for r=0.3 class 1.0 = 0.75 +- 0.300 (in-sample avg dev_std = 0.435)
SUFF++ for r=0.3 all KL = 0.652 +- 0.300 (in-sample avg dev_std = 0.435)
SUFF++ for r=0.3 all L1 = 0.754 +- 0.214 (in-sample avg dev_std = 0.435)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.484
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.478
SUFF++ for r=0.6 class 0.0 = 0.865 +- 0.231 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.6 class 1.0 = 0.854 +- 0.231 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.6 all KL = 0.817 +- 0.231 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.6 all L1 = 0.856 +- 0.185 (in-sample avg dev_std = 0.292)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.522
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.501
SUFF++ for r=0.9 class 0.0 = 0.876 +- 0.172 (in-sample avg dev_std = 0.224)
SUFF++ for r=0.9 class 1.0 = 0.878 +- 0.172 (in-sample avg dev_std = 0.224)
SUFF++ for r=0.9 all KL = 0.899 +- 0.172 (in-sample avg dev_std = 0.224)
SUFF++ for r=0.9 all L1 = 0.877 +- 0.165 (in-sample avg dev_std = 0.224)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.666
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.55
NEC for r=0.3 class 0.0 = 0.27 +- 0.309 (in-sample avg dev_std = 0.371)
NEC for r=0.3 class 1.0 = 0.203 +- 0.309 (in-sample avg dev_std = 0.371)
NEC for r=0.3 all KL = 0.277 +- 0.309 (in-sample avg dev_std = 0.371)
NEC for r=0.3 all L1 = 0.211 +- 0.234 (in-sample avg dev_std = 0.371)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.616
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.551
NEC for r=0.6 class 0.0 = 0.13 +- 0.213 (in-sample avg dev_std = 0.244)
NEC for r=0.6 class 1.0 = 0.106 +- 0.213 (in-sample avg dev_std = 0.244)
NEC for r=0.6 all KL = 0.136 +- 0.213 (in-sample avg dev_std = 0.244)
NEC for r=0.6 all L1 = 0.108 +- 0.171 (in-sample avg dev_std = 0.244)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.579
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.52
NEC for r=0.9 class 0.0 = 0.116 +- 0.151 (in-sample avg dev_std = 0.205)
NEC for r=0.9 class 1.0 = 0.101 +- 0.151 (in-sample avg dev_std = 0.205)
NEC for r=0.9 all KL = 0.094 +- 0.151 (in-sample avg dev_std = 0.205)
NEC for r=0.9 all L1 = 0.102 +- 0.146 (in-sample avg dev_std = 0.205)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.605
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.526
NEC for r=1.0 class 0.0 = 0.15 +- 0.152 (in-sample avg dev_std = 0.214)
NEC for r=1.0 class 1.0 = 0.122 +- 0.152 (in-sample avg dev_std = 0.214)
NEC for r=1.0 all KL = 0.099 +- 0.152 (in-sample avg dev_std = 0.214)
NEC for r=1.0 all L1 = 0.125 +- 0.162 (in-sample avg dev_std = 0.214)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.656
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.588
NEC for r=0.3 class 0.0 = 0.278 +- 0.304 (in-sample avg dev_std = 0.372)
NEC for r=0.3 class 1.0 = 0.194 +- 0.304 (in-sample avg dev_std = 0.372)
NEC for r=0.3 all KL = 0.262 +- 0.304 (in-sample avg dev_std = 0.372)
NEC for r=0.3 all L1 = 0.203 +- 0.231 (in-sample avg dev_std = 0.372)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.645
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.616
NEC for r=0.6 class 0.0 = 0.156 +- 0.213 (in-sample avg dev_std = 0.242)
NEC for r=0.6 class 1.0 = 0.094 +- 0.213 (in-sample avg dev_std = 0.242)
NEC for r=0.6 all KL = 0.135 +- 0.213 (in-sample avg dev_std = 0.242)
NEC for r=0.6 all L1 = 0.101 +- 0.161 (in-sample avg dev_std = 0.242)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.634
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.574
NEC for r=0.9 class 0.0 = 0.119 +- 0.143 (in-sample avg dev_std = 0.192)
NEC for r=0.9 class 1.0 = 0.1 +- 0.143 (in-sample avg dev_std = 0.192)
NEC for r=0.9 all KL = 0.088 +- 0.143 (in-sample avg dev_std = 0.192)
NEC for r=0.9 all L1 = 0.102 +- 0.144 (in-sample avg dev_std = 0.192)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.622
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.554
NEC for r=1.0 class 0.0 = 0.155 +- 0.142 (in-sample avg dev_std = 0.197)
NEC for r=1.0 class 1.0 = 0.118 +- 0.142 (in-sample avg dev_std = 0.197)
NEC for r=1.0 all KL = 0.093 +- 0.142 (in-sample avg dev_std = 0.197)
NEC for r=1.0 all L1 = 0.123 +- 0.155 (in-sample avg dev_std = 0.197)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.542
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.563
NEC for r=0.3 class 0.0 = 0.226 +- 0.301 (in-sample avg dev_std = 0.364)
NEC for r=0.3 class 1.0 = 0.211 +- 0.301 (in-sample avg dev_std = 0.364)
NEC for r=0.3 all KL = 0.281 +- 0.301 (in-sample avg dev_std = 0.364)
NEC for r=0.3 all L1 = 0.212 +- 0.227 (in-sample avg dev_std = 0.364)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.547
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.563
NEC for r=0.6 class 0.0 = 0.16 +- 0.210 (in-sample avg dev_std = 0.234)
NEC for r=0.6 class 1.0 = 0.112 +- 0.210 (in-sample avg dev_std = 0.234)
NEC for r=0.6 all KL = 0.139 +- 0.210 (in-sample avg dev_std = 0.234)
NEC for r=0.6 all L1 = 0.116 +- 0.169 (in-sample avg dev_std = 0.234)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.478
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.524
NEC for r=0.9 class 0.0 = 0.134 +- 0.159 (in-sample avg dev_std = 0.202)
NEC for r=0.9 class 1.0 = 0.106 +- 0.159 (in-sample avg dev_std = 0.202)
NEC for r=0.9 all KL = 0.095 +- 0.159 (in-sample avg dev_std = 0.202)
NEC for r=0.9 all L1 = 0.109 +- 0.144 (in-sample avg dev_std = 0.202)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.464
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.522
NEC for r=1.0 class 0.0 = 0.143 +- 0.155 (in-sample avg dev_std = 0.211)
NEC for r=1.0 class 1.0 = 0.126 +- 0.155 (in-sample avg dev_std = 0.211)
NEC for r=1.0 all KL = 0.098 +- 0.155 (in-sample avg dev_std = 0.211)
NEC for r=1.0 all L1 = 0.127 +- 0.150 (in-sample avg dev_std = 0.211)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.497
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.485
NEC for r=0.3 class 0.0 = 0.198 +- 0.310 (in-sample avg dev_std = 0.369)
NEC for r=0.3 class 1.0 = 0.24 +- 0.310 (in-sample avg dev_std = 0.369)
NEC for r=0.3 all KL = 0.289 +- 0.310 (in-sample avg dev_std = 0.369)
NEC for r=0.3 all L1 = 0.233 +- 0.245 (in-sample avg dev_std = 0.369)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.484
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.517
NEC for r=0.6 class 0.0 = 0.141 +- 0.233 (in-sample avg dev_std = 0.265)
NEC for r=0.6 class 1.0 = 0.138 +- 0.233 (in-sample avg dev_std = 0.265)
NEC for r=0.6 all KL = 0.167 +- 0.233 (in-sample avg dev_std = 0.265)
NEC for r=0.6 all L1 = 0.138 +- 0.190 (in-sample avg dev_std = 0.265)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.522
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.507
NEC for r=0.9 class 0.0 = 0.147 +- 0.185 (in-sample avg dev_std = 0.233)
NEC for r=0.9 class 1.0 = 0.13 +- 0.185 (in-sample avg dev_std = 0.233)
NEC for r=0.9 all KL = 0.123 +- 0.185 (in-sample avg dev_std = 0.233)
NEC for r=0.9 all L1 = 0.133 +- 0.170 (in-sample avg dev_std = 0.233)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.513
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.497
NEC for r=1.0 class 0.0 = 0.166 +- 0.165 (in-sample avg dev_std = 0.236)
NEC for r=1.0 class 1.0 = 0.151 +- 0.165 (in-sample avg dev_std = 0.236)
NEC for r=1.0 all KL = 0.113 +- 0.165 (in-sample avg dev_std = 0.236)
NEC for r=1.0 all L1 = 0.153 +- 0.174 (in-sample avg dev_std = 0.236)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 00:49:34 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/03/2024 12:49:34 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/03/2024 12:50:11 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/03/2024 12:50:26 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/03/2024 12:50:39 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/03/2024 12:50:55 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:51:12 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 175...
[0m[1;37mINFO[0m: [1mCheckpoint 175: 
-----------------------------------
Train ROC-AUC: 0.9700
Train Loss: 0.1384
ID Validation ROC-AUC: 0.9239
ID Validation Loss: 0.2236
ID Test ROC-AUC: 0.9258
ID Test Loss: 0.2238
OOD Validation ROC-AUC: 0.6361
OOD Validation Loss: 0.4564
OOD Test ROC-AUC: 0.6863
OOD Test Loss: 0.5633

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 21...
[0m[1;37mINFO[0m: [1mCheckpoint 21: 
-----------------------------------
Train ROC-AUC: 0.9076
Train Loss: 0.2268
ID Validation ROC-AUC: 0.8921
ID Validation Loss: 0.2443
ID Test ROC-AUC: 0.8980
ID Test Loss: 0.2413
OOD Validation ROC-AUC: 0.6868
OOD Validation Loss: 0.3111
OOD Test ROC-AUC: 0.7174
OOD Test Loss: 0.4442

[0m[1;37mINFO[0m: [1mChartInfo 0.9258 0.6863 0.8980 0.7174 0.8921 0.6868[0mLBAPcore(34179)
Data example from train: Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
Label distribution from train: (tensor([0., 1.]), tensor([ 3960, 30219]))
[1;34mDEBUG[0m: 05/03/2024 12:51:13 AM : [1mUnbalanced warning for LBAPcore (train)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 05/03/2024 12:51:18 AM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 05/03/2024 12:51:23 AM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 05/03/2024 12:51:29 AM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.576
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.598
SUFF++ for r=0.3 class 0.0 = 0.657 +- 0.273 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.3 class 1.0 = 0.692 +- 0.273 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.3 all KL = 0.666 +- 0.273 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.3 all L1 = 0.688 +- 0.240 (in-sample avg dev_std = 0.398)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.6
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.565
SUFF++ for r=0.6 class 0.0 = 0.721 +- 0.227 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.6 class 1.0 = 0.779 +- 0.227 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.6 all KL = 0.789 +- 0.227 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.6 all L1 = 0.772 +- 0.232 (in-sample avg dev_std = 0.287)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.654
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.599
SUFF++ for r=0.9 class 0.0 = 0.797 +- 0.186 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.9 class 1.0 = 0.846 +- 0.186 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.9 all KL = 0.881 +- 0.186 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.9 all L1 = 0.841 +- 0.197 (in-sample avg dev_std = 0.247)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.528
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.568
SUFF++ for r=0.3 class 0.0 = 0.658 +- 0.278 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.3 class 1.0 = 0.679 +- 0.278 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.3 all KL = 0.655 +- 0.278 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.3 all L1 = 0.676 +- 0.243 (in-sample avg dev_std = 0.393)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.545
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.565
SUFF++ for r=0.6 class 0.0 = 0.758 +- 0.234 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.6 class 1.0 = 0.777 +- 0.234 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.6 all KL = 0.793 +- 0.234 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.6 all L1 = 0.775 +- 0.231 (in-sample avg dev_std = 0.292)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.613
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.604
SUFF++ for r=0.9 class 0.0 = 0.81 +- 0.172 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.9 class 1.0 = 0.856 +- 0.172 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.9 all KL = 0.891 +- 0.172 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.9 all L1 = 0.851 +- 0.184 (in-sample avg dev_std = 0.229)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.526
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.54
SUFF++ for r=0.3 class 0.0 = 0.632 +- 0.261 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.3 class 1.0 = 0.679 +- 0.261 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.3 all KL = 0.675 +- 0.261 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.3 all L1 = 0.675 +- 0.235 (in-sample avg dev_std = 0.393)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.455
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.56
SUFF++ for r=0.6 class 0.0 = 0.755 +- 0.221 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.6 class 1.0 = 0.777 +- 0.221 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.6 all KL = 0.807 +- 0.221 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.6 all L1 = 0.775 +- 0.223 (in-sample avg dev_std = 0.271)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.539
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.572
SUFF++ for r=0.9 class 0.0 = 0.843 +- 0.145 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.9 class 1.0 = 0.865 +- 0.145 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.9 all KL = 0.91 +- 0.145 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.9 all L1 = 0.863 +- 0.166 (in-sample avg dev_std = 0.203)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.534
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.557
SUFF++ for r=0.3 class 0.0 = 0.614 +- 0.260 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.3 class 1.0 = 0.642 +- 0.260 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.3 all KL = 0.645 +- 0.260 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.3 all L1 = 0.637 +- 0.232 (in-sample avg dev_std = 0.411)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.611
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.566
SUFF++ for r=0.6 class 0.0 = 0.651 +- 0.239 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.6 class 1.0 = 0.754 +- 0.239 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.6 all KL = 0.775 +- 0.239 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.6 all L1 = 0.737 +- 0.241 (in-sample avg dev_std = 0.292)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.621
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.6
SUFF++ for r=0.9 class 0.0 = 0.787 +- 0.189 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.9 class 1.0 = 0.841 +- 0.189 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.9 all KL = 0.876 +- 0.189 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.9 all L1 = 0.832 +- 0.197 (in-sample avg dev_std = 0.264)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.576
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.561
NEC for r=0.3 class 0.0 = 0.351 +- 0.260 (in-sample avg dev_std = 0.397)
NEC for r=0.3 class 1.0 = 0.29 +- 0.260 (in-sample avg dev_std = 0.397)
NEC for r=0.3 all KL = 0.301 +- 0.260 (in-sample avg dev_std = 0.397)
NEC for r=0.3 all L1 = 0.297 +- 0.223 (in-sample avg dev_std = 0.397)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.6
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.55
NEC for r=0.6 class 0.0 = 0.259 +- 0.200 (in-sample avg dev_std = 0.275)
NEC for r=0.6 class 1.0 = 0.19 +- 0.200 (in-sample avg dev_std = 0.275)
NEC for r=0.6 all KL = 0.166 +- 0.200 (in-sample avg dev_std = 0.275)
NEC for r=0.6 all L1 = 0.198 +- 0.209 (in-sample avg dev_std = 0.275)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.654
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.592
NEC for r=0.9 class 0.0 = 0.229 +- 0.179 (in-sample avg dev_std = 0.236)
NEC for r=0.9 class 1.0 = 0.153 +- 0.179 (in-sample avg dev_std = 0.236)
NEC for r=0.9 all KL = 0.125 +- 0.179 (in-sample avg dev_std = 0.236)
NEC for r=0.9 all L1 = 0.162 +- 0.197 (in-sample avg dev_std = 0.236)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.688
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.605
NEC for r=1.0 class 0.0 = 0.234 +- 0.175 (in-sample avg dev_std = 0.249)
NEC for r=1.0 class 1.0 = 0.138 +- 0.175 (in-sample avg dev_std = 0.249)
NEC for r=1.0 all KL = 0.119 +- 0.175 (in-sample avg dev_std = 0.249)
NEC for r=1.0 all L1 = 0.149 +- 0.186 (in-sample avg dev_std = 0.249)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.528
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.571
NEC for r=0.3 class 0.0 = 0.337 +- 0.270 (in-sample avg dev_std = 0.394)
NEC for r=0.3 class 1.0 = 0.303 +- 0.270 (in-sample avg dev_std = 0.394)
NEC for r=0.3 all KL = 0.316 +- 0.270 (in-sample avg dev_std = 0.394)
NEC for r=0.3 all L1 = 0.307 +- 0.222 (in-sample avg dev_std = 0.394)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.545
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.548
NEC for r=0.6 class 0.0 = 0.22 +- 0.203 (in-sample avg dev_std = 0.280)
NEC for r=0.6 class 1.0 = 0.2 +- 0.203 (in-sample avg dev_std = 0.280)
NEC for r=0.6 all KL = 0.173 +- 0.203 (in-sample avg dev_std = 0.280)
NEC for r=0.6 all L1 = 0.203 +- 0.209 (in-sample avg dev_std = 0.280)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.613
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.557
NEC for r=0.9 class 0.0 = 0.229 +- 0.171 (in-sample avg dev_std = 0.234)
NEC for r=0.9 class 1.0 = 0.145 +- 0.171 (in-sample avg dev_std = 0.234)
NEC for r=0.9 all KL = 0.122 +- 0.171 (in-sample avg dev_std = 0.234)
NEC for r=0.9 all L1 = 0.155 +- 0.185 (in-sample avg dev_std = 0.234)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.646
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.58
NEC for r=1.0 class 0.0 = 0.23 +- 0.163 (in-sample avg dev_std = 0.228)
NEC for r=1.0 class 1.0 = 0.13 +- 0.163 (in-sample avg dev_std = 0.228)
NEC for r=1.0 all KL = 0.112 +- 0.163 (in-sample avg dev_std = 0.228)
NEC for r=1.0 all L1 = 0.142 +- 0.176 (in-sample avg dev_std = 0.228)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.526
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.58
NEC for r=0.3 class 0.0 = 0.355 +- 0.255 (in-sample avg dev_std = 0.379)
NEC for r=0.3 class 1.0 = 0.309 +- 0.255 (in-sample avg dev_std = 0.379)
NEC for r=0.3 all KL = 0.299 +- 0.255 (in-sample avg dev_std = 0.379)
NEC for r=0.3 all L1 = 0.313 +- 0.223 (in-sample avg dev_std = 0.379)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.455
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.526
NEC for r=0.6 class 0.0 = 0.233 +- 0.205 (in-sample avg dev_std = 0.268)
NEC for r=0.6 class 1.0 = 0.214 +- 0.205 (in-sample avg dev_std = 0.268)
NEC for r=0.6 all KL = 0.175 +- 0.205 (in-sample avg dev_std = 0.268)
NEC for r=0.6 all L1 = 0.216 +- 0.212 (in-sample avg dev_std = 0.268)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.539
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.545
NEC for r=0.9 class 0.0 = 0.218 +- 0.161 (in-sample avg dev_std = 0.224)
NEC for r=0.9 class 1.0 = 0.146 +- 0.161 (in-sample avg dev_std = 0.224)
NEC for r=0.9 all KL = 0.115 +- 0.161 (in-sample avg dev_std = 0.224)
NEC for r=0.9 all L1 = 0.152 +- 0.174 (in-sample avg dev_std = 0.224)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.527
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.568
NEC for r=1.0 class 0.0 = 0.191 +- 0.165 (in-sample avg dev_std = 0.232)
NEC for r=1.0 class 1.0 = 0.154 +- 0.165 (in-sample avg dev_std = 0.232)
NEC for r=1.0 all KL = 0.118 +- 0.165 (in-sample avg dev_std = 0.232)
NEC for r=1.0 all L1 = 0.157 +- 0.178 (in-sample avg dev_std = 0.232)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.534
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.543
NEC for r=0.3 class 0.0 = 0.387 +- 0.261 (in-sample avg dev_std = 0.399)
NEC for r=0.3 class 1.0 = 0.342 +- 0.261 (in-sample avg dev_std = 0.399)
NEC for r=0.3 all KL = 0.334 +- 0.261 (in-sample avg dev_std = 0.399)
NEC for r=0.3 all L1 = 0.349 +- 0.222 (in-sample avg dev_std = 0.399)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.611
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.573
NEC for r=0.6 class 0.0 = 0.33 +- 0.225 (in-sample avg dev_std = 0.297)
NEC for r=0.6 class 1.0 = 0.234 +- 0.225 (in-sample avg dev_std = 0.297)
NEC for r=0.6 all KL = 0.206 +- 0.225 (in-sample avg dev_std = 0.297)
NEC for r=0.6 all L1 = 0.25 +- 0.227 (in-sample avg dev_std = 0.297)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.621
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.583
NEC for r=0.9 class 0.0 = 0.247 +- 0.190 (in-sample avg dev_std = 0.248)
NEC for r=0.9 class 1.0 = 0.167 +- 0.190 (in-sample avg dev_std = 0.248)
NEC for r=0.9 all KL = 0.14 +- 0.190 (in-sample avg dev_std = 0.248)
NEC for r=0.9 all L1 = 0.18 +- 0.203 (in-sample avg dev_std = 0.248)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.614
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.584
NEC for r=1.0 class 0.0 = 0.241 +- 0.200 (in-sample avg dev_std = 0.258)
NEC for r=1.0 class 1.0 = 0.174 +- 0.200 (in-sample avg dev_std = 0.258)
NEC for r=1.0 all KL = 0.146 +- 0.200 (in-sample avg dev_std = 0.258)
NEC for r=1.0 all L1 = 0.185 +- 0.207 (in-sample avg dev_std = 0.258)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 00:58:16 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/03/2024 12:58:16 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/03/2024 12:58:51 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/03/2024 12:59:01 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/03/2024 12:59:13 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/03/2024 12:59:31 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 12:59:47 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 199...
[0m[1;37mINFO[0m: [1mCheckpoint 199: 
-----------------------------------
Train ROC-AUC: 0.9701
Train Loss: 0.1379
ID Validation ROC-AUC: 0.9219
ID Validation Loss: 0.2309
ID Test ROC-AUC: 0.9249
ID Test Loss: 0.2294
OOD Validation ROC-AUC: 0.6427
OOD Validation Loss: 0.4806
OOD Test ROC-AUC: 0.6915
OOD Test Loss: 0.5778

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 58...
[0m[1;37mINFO[0m: [1mCheckpoint 58: 
-----------------------------------
Train ROC-AUC: 0.9368
Train Loss: 0.1927
ID Validation ROC-AUC: 0.9098
ID Validation Loss: 0.2281
ID Test ROC-AUC: 0.9159
ID Test Loss: 0.2220
OOD Validation ROC-AUC: 0.6858
OOD Validation Loss: 0.3482
OOD Test ROC-AUC: 0.7149
OOD Test Loss: 0.4585

[0m[1;37mINFO[0m: [1mChartInfo 0.9249 0.6915 0.9159 0.7149 0.9098 0.6858[0mLBAPcore(34179)
Data example from train: Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
Label distribution from train: (tensor([0., 1.]), tensor([ 3960, 30219]))
[1;34mDEBUG[0m: 05/03/2024 12:59:48 AM : [1mUnbalanced warning for LBAPcore (train)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 05/03/2024 12:59:53 AM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 05/03/2024 12:59:58 AM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 05/03/2024 01:00:03 AM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.615
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.517
SUFF++ for r=0.3 class 0.0 = 0.752 +- 0.256 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.3 class 1.0 = 0.775 +- 0.256 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.3 all KL = 0.713 +- 0.256 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.3 all L1 = 0.772 +- 0.189 (in-sample avg dev_std = 0.392)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.466
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.486
SUFF++ for r=0.6 class 0.0 = 0.827 +- 0.210 (in-sample avg dev_std = 0.308)
SUFF++ for r=0.6 class 1.0 = 0.796 +- 0.210 (in-sample avg dev_std = 0.308)
SUFF++ for r=0.6 all KL = 0.813 +- 0.210 (in-sample avg dev_std = 0.308)
SUFF++ for r=0.6 all L1 = 0.799 +- 0.199 (in-sample avg dev_std = 0.308)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.504
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.49
SUFF++ for r=0.9 class 0.0 = 0.887 +- 0.180 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 class 1.0 = 0.869 +- 0.180 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 all KL = 0.9 +- 0.180 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 all L1 = 0.871 +- 0.173 (in-sample avg dev_std = 0.222)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.562
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.535
SUFF++ for r=0.3 class 0.0 = 0.743 +- 0.258 (in-sample avg dev_std = 0.408)
SUFF++ for r=0.3 class 1.0 = 0.764 +- 0.258 (in-sample avg dev_std = 0.408)
SUFF++ for r=0.3 all KL = 0.706 +- 0.258 (in-sample avg dev_std = 0.408)
SUFF++ for r=0.3 all L1 = 0.762 +- 0.197 (in-sample avg dev_std = 0.408)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.506
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.524
SUFF++ for r=0.6 class 0.0 = 0.807 +- 0.228 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.6 class 1.0 = 0.79 +- 0.228 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.6 all KL = 0.8 +- 0.228 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.6 all L1 = 0.792 +- 0.204 (in-sample avg dev_std = 0.321)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.555
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.532
SUFF++ for r=0.9 class 0.0 = 0.868 +- 0.179 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.9 class 1.0 = 0.872 +- 0.179 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.9 all KL = 0.903 +- 0.179 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.9 all L1 = 0.872 +- 0.172 (in-sample avg dev_std = 0.223)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.549
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.544
SUFF++ for r=0.3 class 0.0 = 0.724 +- 0.241 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.3 class 1.0 = 0.773 +- 0.241 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.3 all KL = 0.73 +- 0.241 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.3 all L1 = 0.769 +- 0.184 (in-sample avg dev_std = 0.382)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.472
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.515
SUFF++ for r=0.6 class 0.0 = 0.794 +- 0.214 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.6 class 1.0 = 0.795 +- 0.214 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.6 all KL = 0.815 +- 0.214 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.6 all L1 = 0.795 +- 0.203 (in-sample avg dev_std = 0.320)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.471
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.492
SUFF++ for r=0.9 class 0.0 = 0.887 +- 0.185 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 class 1.0 = 0.871 +- 0.185 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 all KL = 0.9 +- 0.185 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 all L1 = 0.872 +- 0.173 (in-sample avg dev_std = 0.235)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.524
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.484
SUFF++ for r=0.3 class 0.0 = 0.782 +- 0.251 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.3 class 1.0 = 0.762 +- 0.251 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.3 all KL = 0.714 +- 0.251 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.3 all L1 = 0.765 +- 0.187 (in-sample avg dev_std = 0.399)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.48
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.508
SUFF++ for r=0.6 class 0.0 = 0.806 +- 0.223 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.6 class 1.0 = 0.783 +- 0.223 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.6 all KL = 0.799 +- 0.223 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.6 all L1 = 0.787 +- 0.203 (in-sample avg dev_std = 0.332)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.508
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.507
SUFF++ for r=0.9 class 0.0 = 0.881 +- 0.175 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 class 1.0 = 0.86 +- 0.175 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 all KL = 0.899 +- 0.175 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 all L1 = 0.863 +- 0.179 (in-sample avg dev_std = 0.222)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.615
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.542
NEC for r=0.3 class 0.0 = 0.278 +- 0.282 (in-sample avg dev_std = 0.367)
NEC for r=0.3 class 1.0 = 0.236 +- 0.282 (in-sample avg dev_std = 0.367)
NEC for r=0.3 all KL = 0.299 +- 0.282 (in-sample avg dev_std = 0.367)
NEC for r=0.3 all L1 = 0.241 +- 0.209 (in-sample avg dev_std = 0.367)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.466
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.478
NEC for r=0.6 class 0.0 = 0.202 +- 0.221 (in-sample avg dev_std = 0.317)
NEC for r=0.6 class 1.0 = 0.221 +- 0.221 (in-sample avg dev_std = 0.317)
NEC for r=0.6 all KL = 0.211 +- 0.221 (in-sample avg dev_std = 0.317)
NEC for r=0.6 all L1 = 0.219 +- 0.196 (in-sample avg dev_std = 0.317)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.504
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.484
NEC for r=0.9 class 0.0 = 0.162 +- 0.184 (in-sample avg dev_std = 0.244)
NEC for r=0.9 class 1.0 = 0.149 +- 0.184 (in-sample avg dev_std = 0.244)
NEC for r=0.9 all KL = 0.129 +- 0.184 (in-sample avg dev_std = 0.244)
NEC for r=0.9 all L1 = 0.151 +- 0.183 (in-sample avg dev_std = 0.244)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.514
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.495
NEC for r=1.0 class 0.0 = 0.117 +- 0.170 (in-sample avg dev_std = 0.231)
NEC for r=1.0 class 1.0 = 0.119 +- 0.170 (in-sample avg dev_std = 0.231)
NEC for r=1.0 all KL = 0.105 +- 0.170 (in-sample avg dev_std = 0.231)
NEC for r=1.0 all L1 = 0.119 +- 0.155 (in-sample avg dev_std = 0.231)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.562
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.532
NEC for r=0.3 class 0.0 = 0.256 +- 0.282 (in-sample avg dev_std = 0.370)
NEC for r=0.3 class 1.0 = 0.243 +- 0.282 (in-sample avg dev_std = 0.370)
NEC for r=0.3 all KL = 0.294 +- 0.282 (in-sample avg dev_std = 0.370)
NEC for r=0.3 all L1 = 0.244 +- 0.217 (in-sample avg dev_std = 0.370)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.506
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.534
NEC for r=0.6 class 0.0 = 0.213 +- 0.227 (in-sample avg dev_std = 0.332)
NEC for r=0.6 class 1.0 = 0.222 +- 0.227 (in-sample avg dev_std = 0.332)
NEC for r=0.6 all KL = 0.217 +- 0.227 (in-sample avg dev_std = 0.332)
NEC for r=0.6 all L1 = 0.221 +- 0.197 (in-sample avg dev_std = 0.332)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.555
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.54
NEC for r=0.9 class 0.0 = 0.17 +- 0.178 (in-sample avg dev_std = 0.241)
NEC for r=0.9 class 1.0 = 0.147 +- 0.178 (in-sample avg dev_std = 0.241)
NEC for r=0.9 all KL = 0.126 +- 0.178 (in-sample avg dev_std = 0.241)
NEC for r=0.9 all L1 = 0.15 +- 0.172 (in-sample avg dev_std = 0.241)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.544
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.538
NEC for r=1.0 class 0.0 = 0.15 +- 0.154 (in-sample avg dev_std = 0.219)
NEC for r=1.0 class 1.0 = 0.116 +- 0.154 (in-sample avg dev_std = 0.219)
NEC for r=1.0 all KL = 0.1 +- 0.154 (in-sample avg dev_std = 0.219)
NEC for r=1.0 all L1 = 0.12 +- 0.148 (in-sample avg dev_std = 0.219)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.549
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.526
NEC for r=0.3 class 0.0 = 0.275 +- 0.269 (in-sample avg dev_std = 0.373)
NEC for r=0.3 class 1.0 = 0.255 +- 0.269 (in-sample avg dev_std = 0.373)
NEC for r=0.3 all KL = 0.298 +- 0.269 (in-sample avg dev_std = 0.373)
NEC for r=0.3 all L1 = 0.256 +- 0.208 (in-sample avg dev_std = 0.373)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.472
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.516
NEC for r=0.6 class 0.0 = 0.224 +- 0.211 (in-sample avg dev_std = 0.330)
NEC for r=0.6 class 1.0 = 0.228 +- 0.211 (in-sample avg dev_std = 0.330)
NEC for r=0.6 all KL = 0.216 +- 0.211 (in-sample avg dev_std = 0.330)
NEC for r=0.6 all L1 = 0.228 +- 0.194 (in-sample avg dev_std = 0.330)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.471
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.526
NEC for r=0.9 class 0.0 = 0.176 +- 0.189 (in-sample avg dev_std = 0.261)
NEC for r=0.9 class 1.0 = 0.147 +- 0.189 (in-sample avg dev_std = 0.261)
NEC for r=0.9 all KL = 0.129 +- 0.189 (in-sample avg dev_std = 0.261)
NEC for r=0.9 all L1 = 0.15 +- 0.177 (in-sample avg dev_std = 0.261)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.475
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.49
NEC for r=1.0 class 0.0 = 0.146 +- 0.179 (in-sample avg dev_std = 0.242)
NEC for r=1.0 class 1.0 = 0.122 +- 0.179 (in-sample avg dev_std = 0.242)
NEC for r=1.0 all KL = 0.112 +- 0.179 (in-sample avg dev_std = 0.242)
NEC for r=1.0 all L1 = 0.124 +- 0.158 (in-sample avg dev_std = 0.242)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.524
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.507
NEC for r=0.3 class 0.0 = 0.254 +- 0.286 (in-sample avg dev_std = 0.388)
NEC for r=0.3 class 1.0 = 0.27 +- 0.286 (in-sample avg dev_std = 0.388)
NEC for r=0.3 all KL = 0.317 +- 0.286 (in-sample avg dev_std = 0.388)
NEC for r=0.3 all L1 = 0.268 +- 0.219 (in-sample avg dev_std = 0.388)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.48
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.507
NEC for r=0.6 class 0.0 = 0.225 +- 0.224 (in-sample avg dev_std = 0.326)
NEC for r=0.6 class 1.0 = 0.23 +- 0.224 (in-sample avg dev_std = 0.326)
NEC for r=0.6 all KL = 0.222 +- 0.224 (in-sample avg dev_std = 0.326)
NEC for r=0.6 all L1 = 0.229 +- 0.200 (in-sample avg dev_std = 0.326)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.508
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.524
NEC for r=0.9 class 0.0 = 0.156 +- 0.182 (in-sample avg dev_std = 0.256)
NEC for r=0.9 class 1.0 = 0.166 +- 0.182 (in-sample avg dev_std = 0.256)
NEC for r=0.9 all KL = 0.137 +- 0.182 (in-sample avg dev_std = 0.256)
NEC for r=0.9 all L1 = 0.164 +- 0.184 (in-sample avg dev_std = 0.256)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.506
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.515
NEC for r=1.0 class 0.0 = 0.131 +- 0.162 (in-sample avg dev_std = 0.242)
NEC for r=1.0 class 1.0 = 0.134 +- 0.162 (in-sample avg dev_std = 0.242)
NEC for r=1.0 all KL = 0.111 +- 0.162 (in-sample avg dev_std = 0.242)
NEC for r=1.0 all L1 = 0.134 +- 0.166 (in-sample avg dev_std = 0.242)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 01:06:44 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/03/2024 01:06:44 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/03/2024 01:07:22 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/03/2024 01:07:33 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/03/2024 01:07:44 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/03/2024 01:08:01 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:08:18 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 149...
[0m[1;37mINFO[0m: [1mCheckpoint 149: 
-----------------------------------
Train ROC-AUC: 0.9611
Train Loss: 0.1567
ID Validation ROC-AUC: 0.9233
ID Validation Loss: 0.2180
ID Test ROC-AUC: 0.9240
ID Test Loss: 0.2206
OOD Validation ROC-AUC: 0.6334
OOD Validation Loss: 0.4667
OOD Test ROC-AUC: 0.6879
OOD Test Loss: 0.5492

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 43...
[0m[1;37mINFO[0m: [1mCheckpoint 43: 
-----------------------------------
Train ROC-AUC: 0.9251
Train Loss: 0.2093
ID Validation ROC-AUC: 0.9033
ID Validation Loss: 0.2367
ID Test ROC-AUC: 0.9102
ID Test Loss: 0.2300
OOD Validation ROC-AUC: 0.6806
OOD Validation Loss: 0.3241
OOD Test ROC-AUC: 0.7074
OOD Test Loss: 0.4616

[0m[1;37mINFO[0m: [1mChartInfo 0.9240 0.6879 0.9102 0.7074 0.9033 0.6806[0mLBAPcore(34179)
Data example from train: Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
Label distribution from train: (tensor([0., 1.]), tensor([ 3960, 30219]))
[1;34mDEBUG[0m: 05/03/2024 01:08:19 AM : [1mUnbalanced warning for LBAPcore (train)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 05/03/2024 01:08:24 AM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 05/03/2024 01:08:29 AM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 05/03/2024 01:08:34 AM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.724
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.66
SUFF++ for r=0.3 class 0.0 = 0.778 +- 0.271 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.3 class 1.0 = 0.913 +- 0.271 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.3 all KL = 0.798 +- 0.271 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.3 all L1 = 0.897 +- 0.158 (in-sample avg dev_std = 0.270)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.653
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.637
SUFF++ for r=0.6 class 0.0 = 0.919 +- 0.156 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.6 class 1.0 = 0.967 +- 0.156 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.6 all KL = 0.934 +- 0.156 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.6 all L1 = 0.962 +- 0.090 (in-sample avg dev_std = 0.139)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.597
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.601
SUFF++ for r=0.9 class 0.0 = 0.965 +- 0.070 (in-sample avg dev_std = 0.064)
SUFF++ for r=0.9 class 1.0 = 0.983 +- 0.070 (in-sample avg dev_std = 0.064)
SUFF++ for r=0.9 all KL = 0.983 +- 0.070 (in-sample avg dev_std = 0.064)
SUFF++ for r=0.9 all L1 = 0.98 +- 0.060 (in-sample avg dev_std = 0.064)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.72
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.683
SUFF++ for r=0.3 class 0.0 = 0.786 +- 0.259 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.3 class 1.0 = 0.92 +- 0.259 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.3 all KL = 0.823 +- 0.259 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.3 all L1 = 0.905 +- 0.156 (in-sample avg dev_std = 0.264)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.68
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.681
SUFF++ for r=0.6 class 0.0 = 0.915 +- 0.150 (in-sample avg dev_std = 0.140)
SUFF++ for r=0.6 class 1.0 = 0.974 +- 0.150 (in-sample avg dev_std = 0.140)
SUFF++ for r=0.6 all KL = 0.937 +- 0.150 (in-sample avg dev_std = 0.140)
SUFF++ for r=0.6 all L1 = 0.967 +- 0.083 (in-sample avg dev_std = 0.140)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.665
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.653
SUFF++ for r=0.9 class 0.0 = 0.964 +- 0.060 (in-sample avg dev_std = 0.051)
SUFF++ for r=0.9 class 1.0 = 0.985 +- 0.060 (in-sample avg dev_std = 0.051)
SUFF++ for r=0.9 all KL = 0.984 +- 0.060 (in-sample avg dev_std = 0.051)
SUFF++ for r=0.9 all L1 = 0.983 +- 0.050 (in-sample avg dev_std = 0.051)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.631
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.564
SUFF++ for r=0.3 class 0.0 = 0.832 +- 0.267 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.3 class 1.0 = 0.886 +- 0.267 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.3 all KL = 0.795 +- 0.267 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.3 all L1 = 0.881 +- 0.167 (in-sample avg dev_std = 0.282)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.548
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.579
SUFF++ for r=0.6 class 0.0 = 0.94 +- 0.130 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.6 class 1.0 = 0.965 +- 0.130 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.6 all KL = 0.943 +- 0.130 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.6 all L1 = 0.963 +- 0.085 (in-sample avg dev_std = 0.124)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.606
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.567
SUFF++ for r=0.9 class 0.0 = 0.977 +- 0.061 (in-sample avg dev_std = 0.060)
SUFF++ for r=0.9 class 1.0 = 0.982 +- 0.061 (in-sample avg dev_std = 0.060)
SUFF++ for r=0.9 all KL = 0.985 +- 0.061 (in-sample avg dev_std = 0.060)
SUFF++ for r=0.9 all L1 = 0.982 +- 0.054 (in-sample avg dev_std = 0.060)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.612
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.59
SUFF++ for r=0.3 class 0.0 = 0.812 +- 0.283 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.3 class 1.0 = 0.896 +- 0.283 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.3 all KL = 0.784 +- 0.283 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.3 all L1 = 0.882 +- 0.162 (in-sample avg dev_std = 0.292)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.569
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.598
SUFF++ for r=0.6 class 0.0 = 0.918 +- 0.153 (in-sample avg dev_std = 0.150)
SUFF++ for r=0.6 class 1.0 = 0.96 +- 0.153 (in-sample avg dev_std = 0.150)
SUFF++ for r=0.6 all KL = 0.928 +- 0.153 (in-sample avg dev_std = 0.150)
SUFF++ for r=0.6 all L1 = 0.953 +- 0.101 (in-sample avg dev_std = 0.150)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.578
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.578
SUFF++ for r=0.9 class 0.0 = 0.969 +- 0.076 (in-sample avg dev_std = 0.078)
SUFF++ for r=0.9 class 1.0 = 0.979 +- 0.076 (in-sample avg dev_std = 0.078)
SUFF++ for r=0.9 all KL = 0.982 +- 0.076 (in-sample avg dev_std = 0.078)
SUFF++ for r=0.9 all L1 = 0.978 +- 0.066 (in-sample avg dev_std = 0.078)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.724
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.675
NEC for r=0.3 class 0.0 = 0.225 +- 0.230 (in-sample avg dev_std = 0.201)
NEC for r=0.3 class 1.0 = 0.071 +- 0.230 (in-sample avg dev_std = 0.201)
NEC for r=0.3 all KL = 0.124 +- 0.230 (in-sample avg dev_std = 0.201)
NEC for r=0.3 all L1 = 0.089 +- 0.179 (in-sample avg dev_std = 0.201)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.653
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.621
NEC for r=0.6 class 0.0 = 0.077 +- 0.139 (in-sample avg dev_std = 0.133)
NEC for r=0.6 class 1.0 = 0.027 +- 0.139 (in-sample avg dev_std = 0.133)
NEC for r=0.6 all KL = 0.051 +- 0.139 (in-sample avg dev_std = 0.133)
NEC for r=0.6 all L1 = 0.033 +- 0.087 (in-sample avg dev_std = 0.133)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.597
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.603
NEC for r=0.9 class 0.0 = 0.049 +- 0.085 (in-sample avg dev_std = 0.088)
NEC for r=0.9 class 1.0 = 0.021 +- 0.085 (in-sample avg dev_std = 0.088)
NEC for r=0.9 all KL = 0.027 +- 0.085 (in-sample avg dev_std = 0.088)
NEC for r=0.9 all L1 = 0.025 +- 0.065 (in-sample avg dev_std = 0.088)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.604
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.605
NEC for r=1.0 class 0.0 = 0.038 +- 0.071 (in-sample avg dev_std = 0.077)
NEC for r=1.0 class 1.0 = 0.02 +- 0.071 (in-sample avg dev_std = 0.077)
NEC for r=1.0 all KL = 0.021 +- 0.071 (in-sample avg dev_std = 0.077)
NEC for r=1.0 all L1 = 0.022 +- 0.060 (in-sample avg dev_std = 0.077)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.72
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.656
NEC for r=0.3 class 0.0 = 0.235 +- 0.237 (in-sample avg dev_std = 0.199)
NEC for r=0.3 class 1.0 = 0.068 +- 0.237 (in-sample avg dev_std = 0.199)
NEC for r=0.3 all KL = 0.125 +- 0.237 (in-sample avg dev_std = 0.199)
NEC for r=0.3 all L1 = 0.088 +- 0.180 (in-sample avg dev_std = 0.199)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.68
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.651
NEC for r=0.6 class 0.0 = 0.077 +- 0.135 (in-sample avg dev_std = 0.116)
NEC for r=0.6 class 1.0 = 0.023 +- 0.135 (in-sample avg dev_std = 0.116)
NEC for r=0.6 all KL = 0.05 +- 0.135 (in-sample avg dev_std = 0.116)
NEC for r=0.6 all L1 = 0.029 +- 0.077 (in-sample avg dev_std = 0.116)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.665
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.648
NEC for r=0.9 class 0.0 = 0.062 +- 0.093 (in-sample avg dev_std = 0.094)
NEC for r=0.9 class 1.0 = 0.018 +- 0.093 (in-sample avg dev_std = 0.094)
NEC for r=0.9 all KL = 0.028 +- 0.093 (in-sample avg dev_std = 0.094)
NEC for r=0.9 all L1 = 0.023 +- 0.063 (in-sample avg dev_std = 0.094)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.644
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.657
NEC for r=1.0 class 0.0 = 0.07 +- 0.075 (in-sample avg dev_std = 0.080)
NEC for r=1.0 class 1.0 = 0.017 +- 0.075 (in-sample avg dev_std = 0.080)
NEC for r=1.0 all KL = 0.022 +- 0.075 (in-sample avg dev_std = 0.080)
NEC for r=1.0 all L1 = 0.023 +- 0.067 (in-sample avg dev_std = 0.080)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.631
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.579
NEC for r=0.3 class 0.0 = 0.176 +- 0.230 (in-sample avg dev_std = 0.208)
NEC for r=0.3 class 1.0 = 0.099 +- 0.230 (in-sample avg dev_std = 0.208)
NEC for r=0.3 all KL = 0.139 +- 0.230 (in-sample avg dev_std = 0.208)
NEC for r=0.3 all L1 = 0.105 +- 0.186 (in-sample avg dev_std = 0.208)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.548
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.575
NEC for r=0.6 class 0.0 = 0.059 +- 0.126 (in-sample avg dev_std = 0.117)
NEC for r=0.6 class 1.0 = 0.034 +- 0.126 (in-sample avg dev_std = 0.117)
NEC for r=0.6 all KL = 0.052 +- 0.126 (in-sample avg dev_std = 0.117)
NEC for r=0.6 all L1 = 0.036 +- 0.085 (in-sample avg dev_std = 0.117)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.606
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.613
NEC for r=0.9 class 0.0 = 0.041 +- 0.074 (in-sample avg dev_std = 0.084)
NEC for r=0.9 class 1.0 = 0.021 +- 0.074 (in-sample avg dev_std = 0.084)
NEC for r=0.9 all KL = 0.022 +- 0.074 (in-sample avg dev_std = 0.084)
NEC for r=0.9 all L1 = 0.023 +- 0.060 (in-sample avg dev_std = 0.084)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.603
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.61
NEC for r=1.0 class 0.0 = 0.048 +- 0.075 (in-sample avg dev_std = 0.082)
NEC for r=1.0 class 1.0 = 0.024 +- 0.075 (in-sample avg dev_std = 0.082)
NEC for r=1.0 all KL = 0.023 +- 0.075 (in-sample avg dev_std = 0.082)
NEC for r=1.0 all L1 = 0.026 +- 0.072 (in-sample avg dev_std = 0.082)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.612
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.576
NEC for r=0.3 class 0.0 = 0.162 +- 0.252 (in-sample avg dev_std = 0.230)
NEC for r=0.3 class 1.0 = 0.092 +- 0.252 (in-sample avg dev_std = 0.230)
NEC for r=0.3 all KL = 0.156 +- 0.252 (in-sample avg dev_std = 0.230)
NEC for r=0.3 all L1 = 0.104 +- 0.177 (in-sample avg dev_std = 0.230)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.569
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.596
NEC for r=0.6 class 0.0 = 0.082 +- 0.133 (in-sample avg dev_std = 0.126)
NEC for r=0.6 class 1.0 = 0.036 +- 0.133 (in-sample avg dev_std = 0.126)
NEC for r=0.6 all KL = 0.058 +- 0.133 (in-sample avg dev_std = 0.126)
NEC for r=0.6 all L1 = 0.043 +- 0.100 (in-sample avg dev_std = 0.126)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.578
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.572
NEC for r=0.9 class 0.0 = 0.048 +- 0.089 (in-sample avg dev_std = 0.095)
NEC for r=0.9 class 1.0 = 0.028 +- 0.089 (in-sample avg dev_std = 0.095)
NEC for r=0.9 all KL = 0.031 +- 0.089 (in-sample avg dev_std = 0.095)
NEC for r=0.9 all L1 = 0.031 +- 0.077 (in-sample avg dev_std = 0.095)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.552
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.568
NEC for r=1.0 class 0.0 = 0.042 +- 0.070 (in-sample avg dev_std = 0.089)
NEC for r=1.0 class 1.0 = 0.027 +- 0.070 (in-sample avg dev_std = 0.089)
NEC for r=1.0 all KL = 0.025 +- 0.070 (in-sample avg dev_std = 0.089)
NEC for r=1.0 all L1 = 0.029 +- 0.070 (in-sample avg dev_std = 0.089)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split train
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.6, 0.772, 0.866, 1.0], 'all_L1': [0.752, 0.812, 0.808, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.673, 0.831, 0.911, 1.0], 'all_L1': [0.78, 0.88, 0.898, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.666, 0.789, 0.881, 1.0], 'all_L1': [0.688, 0.772, 0.841, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.713, 0.813, 0.9, 1.0], 'all_L1': [0.772, 0.799, 0.871, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.798, 0.934, 0.983, 1.0], 'all_L1': [0.897, 0.962, 0.98, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.319, 0.203, 0.133, 0.119], 'all_L1': [0.223, 0.184, 0.189, 0.184]}), defaultdict(<class 'list'>, {'all_KL': [0.277, 0.136, 0.094, 0.099], 'all_L1': [0.211, 0.108, 0.102, 0.125]}), defaultdict(<class 'list'>, {'all_KL': [0.301, 0.166, 0.125, 0.119], 'all_L1': [0.297, 0.198, 0.162, 0.149]}), defaultdict(<class 'list'>, {'all_KL': [0.299, 0.211, 0.129, 0.105], 'all_L1': [0.241, 0.219, 0.151, 0.119]}), defaultdict(<class 'list'>, {'all_KL': [0.124, 0.051, 0.027, 0.021], 'all_L1': [0.089, 0.033, 0.025, 0.022]})]

Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.607, 0.788, 0.871, 1.0], 'all_L1': [0.761, 0.829, 0.812, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.657, 0.83, 0.921, 1.0], 'all_L1': [0.773, 0.888, 0.903, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.655, 0.793, 0.891, 1.0], 'all_L1': [0.676, 0.775, 0.851, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.706, 0.8, 0.903, 1.0], 'all_L1': [0.762, 0.792, 0.872, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.823, 0.937, 0.984, 1.0], 'all_L1': [0.905, 0.967, 0.983, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.332, 0.193, 0.137, 0.119], 'all_L1': [0.222, 0.172, 0.189, 0.183]}), defaultdict(<class 'list'>, {'all_KL': [0.262, 0.135, 0.088, 0.093], 'all_L1': [0.203, 0.101, 0.102, 0.123]}), defaultdict(<class 'list'>, {'all_KL': [0.316, 0.173, 0.122, 0.112], 'all_L1': [0.307, 0.203, 0.155, 0.142]}), defaultdict(<class 'list'>, {'all_KL': [0.294, 0.217, 0.126, 0.1], 'all_L1': [0.244, 0.221, 0.15, 0.12]}), defaultdict(<class 'list'>, {'all_KL': [0.125, 0.05, 0.028, 0.022], 'all_L1': [0.088, 0.029, 0.023, 0.023]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.579, 0.786, 0.859, 1.0], 'all_L1': [0.727, 0.809, 0.793, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.676, 0.838, 0.91, 1.0], 'all_L1': [0.777, 0.876, 0.891, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.675, 0.807, 0.91, 1.0], 'all_L1': [0.675, 0.775, 0.863, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.73, 0.815, 0.9, 1.0], 'all_L1': [0.769, 0.795, 0.872, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.795, 0.943, 0.985, 1.0], 'all_L1': [0.881, 0.963, 0.982, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.353, 0.213, 0.148, 0.131], 'all_L1': [0.252, 0.199, 0.208, 0.203]}), defaultdict(<class 'list'>, {'all_KL': [0.281, 0.139, 0.095, 0.098], 'all_L1': [0.212, 0.116, 0.109, 0.127]}), defaultdict(<class 'list'>, {'all_KL': [0.299, 0.175, 0.115, 0.118], 'all_L1': [0.313, 0.216, 0.152, 0.157]}), defaultdict(<class 'list'>, {'all_KL': [0.298, 0.216, 0.129, 0.112], 'all_L1': [0.256, 0.228, 0.15, 0.124]}), defaultdict(<class 'list'>, {'all_KL': [0.139, 0.052, 0.022, 0.023], 'all_L1': [0.105, 0.036, 0.023, 0.026]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.583, 0.766, 0.843, 1.0], 'all_L1': [0.711, 0.786, 0.776, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.652, 0.817, 0.899, 1.0], 'all_L1': [0.754, 0.856, 0.877, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.645, 0.775, 0.876, 1.0], 'all_L1': [0.637, 0.737, 0.832, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.714, 0.799, 0.899, 1.0], 'all_L1': [0.765, 0.787, 0.863, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.784, 0.928, 0.982, 1.0], 'all_L1': [0.882, 0.953, 0.978, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.371, 0.229, 0.163, 0.155], 'all_L1': [0.28, 0.22, 0.222, 0.222]}), defaultdict(<class 'list'>, {'all_KL': [0.289, 0.167, 0.123, 0.113], 'all_L1': [0.233, 0.138, 0.133, 0.153]}), defaultdict(<class 'list'>, {'all_KL': [0.334, 0.206, 0.14, 0.146], 'all_L1': [0.349, 0.25, 0.18, 0.185]}), defaultdict(<class 'list'>, {'all_KL': [0.317, 0.222, 0.137, 0.111], 'all_L1': [0.268, 0.229, 0.164, 0.134]}), defaultdict(<class 'list'>, {'all_KL': [0.156, 0.058, 0.031, 0.025], 'all_L1': [0.104, 0.043, 0.031, 0.029]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split train
suff++ class all_L1  =  0.778 +- 0.068, 0.845 +- 0.068, 0.880 +- 0.058, 1.000 +- 0.000
suff++ class all_KL  =  0.690 +- 0.065, 0.828 +- 0.057, 0.908 +- 0.040, 1.000 +- 0.000
suff++_acc_int  =  0.588 +- 0.046, 0.568 +- 0.052, 0.569 +- 0.053
nec class all_L1  =  0.212 +- 0.068, 0.148 +- 0.069, 0.126 +- 0.058, 0.120 +- 0.054
nec class all_KL  =  0.264 +- 0.071, 0.153 +- 0.058, 0.102 +- 0.040, 0.093 +- 0.037
nec_acc_int  =  0.587 +- 0.049, 0.564 +- 0.053, 0.567 +- 0.056, 0.571 +- 0.050

Eval split id_val
suff++ class all_L1  =  0.775 +- 0.074, 0.850 +- 0.070, 0.884 +- 0.058, 1.000 +- 0.000
suff++ class all_KL  =  0.690 +- 0.074, 0.830 +- 0.056, 0.914 +- 0.039, 1.000 +- 0.000
suff++_acc_int  =  0.593 +- 0.051, 0.594 +- 0.053, 0.591 +- 0.043
nec class all_L1  =  0.213 +- 0.072, 0.145 +- 0.071, 0.124 +- 0.058, 0.118 +- 0.053
nec class all_KL  =  0.266 +- 0.074, 0.154 +- 0.058, 0.100 +- 0.040, 0.089 +- 0.035
nec_acc_int  =  0.596 +- 0.044, 0.595 +- 0.046, 0.589 +- 0.041, 0.591 +- 0.045

Eval split val
suff++ class all_L1  =  0.766 +- 0.068, 0.844 +- 0.069, 0.880 +- 0.061, 1.000 +- 0.000
suff++ class all_KL  =  0.691 +- 0.071, 0.838 +- 0.055, 0.913 +- 0.041, 1.000 +- 0.000
suff++_acc_int  =  0.548 +- 0.011, 0.544 +- 0.027, 0.533 +- 0.032
nec class all_L1  =  0.228 +- 0.069, 0.159 +- 0.073, 0.128 +- 0.061, 0.127 +- 0.058
nec class all_KL  =  0.274 +- 0.072, 0.159 +- 0.060, 0.102 +- 0.044, 0.096 +- 0.038
nec_acc_int  =  0.562 +- 0.020, 0.546 +- 0.022, 0.557 +- 0.034, 0.547 +- 0.041

Eval split test
suff++ class all_L1  =  0.750 +- 0.080, 0.824 +- 0.075, 0.865 +- 0.066, 1.000 +- 0.000
suff++ class all_KL  =  0.676 +- 0.068, 0.817 +- 0.058, 0.900 +- 0.046, 1.000 +- 0.000
suff++_acc_int  =  0.529 +- 0.040, 0.541 +- 0.043, 0.551 +- 0.040
nec class all_L1  =  0.247 +- 0.081, 0.176 +- 0.077, 0.146 +- 0.064, 0.145 +- 0.065
nec class all_KL  =  0.293 +- 0.074, 0.176 +- 0.063, 0.119 +- 0.046, 0.110 +- 0.046
nec_acc_int  =  0.529 +- 0.031, 0.556 +- 0.037, 0.553 +- 0.032, 0.551 +- 0.038


 -------------------------------------------------- 
Computing faithfulness

Eval split train
Faith. Aritm (L1)= 		  =  0.495 +- 0.006, 0.497 +- 0.008, 0.503 +- 0.004, 0.560 +- 0.027
Faith. Armon (L1)= 		  =  0.324 +- 0.086, 0.243 +- 0.103, 0.213 +- 0.092, 0.210 +- 0.090
Faith. GMean (L1)= 	  =  0.396 +- 0.059, 0.336 +- 0.087, 0.316 +- 0.085, 0.332 +- 0.097
Faith. Aritm (KL)= 		  =  0.477 +- 0.017, 0.491 +- 0.012, 0.505 +- 0.005, 0.546 +- 0.018
Faith. Armon (KL)= 		  =  0.372 +- 0.079, 0.252 +- 0.086, 0.180 +- 0.067, 0.167 +- 0.064
Faith. GMean (KL)= 	  =  0.419 +- 0.053, 0.345 +- 0.069, 0.294 +- 0.068, 0.295 +- 0.076

Eval split id_val
Faith. Aritm (L1)= 		  =  0.494 +- 0.005, 0.498 +- 0.006, 0.504 +- 0.004, 0.559 +- 0.026
Faith. Armon (L1)= 		  =  0.324 +- 0.088, 0.238 +- 0.107, 0.211 +- 0.092, 0.207 +- 0.088
Faith. GMean (L1)= 	  =  0.395 +- 0.060, 0.332 +- 0.091, 0.314 +- 0.087, 0.331 +- 0.094
Faith. Aritm (KL)= 		  =  0.478 +- 0.014, 0.492 +- 0.009, 0.507 +- 0.004, 0.545 +- 0.017
Faith. Armon (KL)= 		  =  0.372 +- 0.080, 0.253 +- 0.087, 0.178 +- 0.067, 0.162 +- 0.061
Faith. GMean (KL)= 	  =  0.419 +- 0.051, 0.346 +- 0.070, 0.293 +- 0.067, 0.290 +- 0.072

Eval split val
Faith. Aritm (L1)= 		  =  0.497 +- 0.008, 0.501 +- 0.006, 0.504 +- 0.004, 0.564 +- 0.029
Faith. Armon (L1)= 		  =  0.341 +- 0.083, 0.257 +- 0.108, 0.217 +- 0.096, 0.221 +- 0.095
Faith. GMean (L1)= 	  =  0.408 +- 0.055, 0.348 +- 0.089, 0.318 +- 0.089, 0.343 +- 0.098
Faith. Aritm (KL)= 		  =  0.482 +- 0.018, 0.498 +- 0.009, 0.507 +- 0.005, 0.548 +- 0.019
Faith. Armon (KL)= 		  =  0.382 +- 0.074, 0.260 +- 0.089, 0.179 +- 0.073, 0.174 +- 0.067
Faith. GMean (KL)= 	  =  0.427 +- 0.048, 0.353 +- 0.071, 0.292 +- 0.076, 0.301 +- 0.076

Eval split test
Faith. Aritm (L1)= 		  =  0.498 +- 0.009, 0.500 +- 0.005, 0.506 +- 0.005, 0.572 +- 0.033
Faith. Armon (L1)= 		  =  0.358 +- 0.091, 0.278 +- 0.109, 0.242 +- 0.098, 0.247 +- 0.104
Faith. GMean (L1)= 	  =  0.418 +- 0.060, 0.363 +- 0.086, 0.339 +- 0.086, 0.366 +- 0.104
Faith. Aritm (KL)= 		  =  0.485 +- 0.017, 0.497 +- 0.007, 0.509 +- 0.005, 0.555 +- 0.023
Faith. Armon (KL)= 		  =  0.399 +- 0.071, 0.282 +- 0.091, 0.206 +- 0.075, 0.195 +- 0.078
Faith. GMean (KL)= 	  =  0.438 +- 0.046, 0.368 +- 0.071, 0.316 +- 0.072, 0.321 +- 0.085
Computed for split load_split = id



Completed in  0:42:27.446680  for LECIGIN LBAPcore/assay



DONE LECI LBAPcore/assay
DONE LECI LBAPcore/assay
big.sh: line 32: syntax error near unexpected token `done'
Time to compute metrics!
The PID of this script is: 1722337
Using splits =  ['id_test', 'test']
Using ratios =  [0.3, 0.6, 0.9, 1.0]


--------------------------------------------------
USING LOAD SPLIT = id


Traceback (most recent call last):
  File "/mnt/cimec-storage6/users/steve.azzolin/venv/leci/bin/goodtg", line 33, in <module>
    sys.exit(load_entry_point('graph-ood', 'console_scripts', 'goodtg')())
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/kernel/main.py", line 636, in goodtg
    main()
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/kernel/main.py", line 536, in main
    evaluate_metric(args)
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/kernel/main.py", line 281, in evaluate_metric
    config = config_summoner(args)
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py", line 271, in config_summoner
    config, duplicate_warnings, duplicate_errors = load_config(args.config_path)
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py", line 82, in load_config
    direct_config = yaml.load(open(path, "r"))
FileNotFoundError: [Errno 2] No such file or directory: '/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/configs/final_configs/GOODMotif2/basis/no_shift/CIGA.yaml'
Time to compute metrics!
The PID of this script is: 1722416

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 11 11:24:28 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/11/2024 11:24:28 AM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/11/2024 11:24:28 AM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/11/2024 11:24:28 AM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/11/2024 11:24:28 AM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/11/2024 11:24:28 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 11:24:28 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:24:28 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:24:28 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:24:28 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:24:28 AM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/11/2024 11:24:28 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 11:24:29 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:24:29 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:24:29 AM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/11/2024 11:24:29 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 111...
[0m[1;37mINFO[0m: [1mCheckpoint 111: 
-----------------------------------
Train ACCURACY: 0.9205
Train Loss: 0.3805
ID Validation ACCURACY: 0.9270
ID Validation Loss: 0.3724
ID Test ACCURACY: 0.9183
ID Test Loss: 0.4140
OOD Validation ACCURACY: 0.8453
OOD Validation Loss: 0.4964
OOD Test ACCURACY: 0.4087
OOD Test Loss: 18.3446

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 50...
[0m[1;37mINFO[0m: [1mCheckpoint 50: 
-----------------------------------
Train ACCURACY: 0.8979
Train Loss: 0.4880
ID Validation ACCURACY: 0.9050
ID Validation Loss: 0.4614
ID Test ACCURACY: 0.8947
ID Test Loss: 0.5226
OOD Validation ACCURACY: 0.9203
OOD Validation Loss: 0.3953
OOD Test ACCURACY: 0.4087
OOD Test Loss: 28.2468

[0m[1;37mINFO[0m: [1mChartInfo 0.9183 0.4087 0.8947 0.4087 0.9050 0.9203[0mGOODMotif2(3000)
Data example from id_test: Data(edge_index=[2, 56], x=[16, 1], node_gt=[16], edge_gt=[56], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=16)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([ 988,  973, 1039]))

Gold ratio (id_test) =  tensor(0.3032) +- tensor(0.1592)
F1 for r=0.8 = 0.503
WIoU for r=0.8 = 0.611
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.8 = 0.363
WIoU for r=0.8 = 0.248


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.924
Model XAI F1 of binarized graphs for r=0.8 =  0.50251
Model XAI WIoU of binarized graphs for r=0.8 =  0.61120125
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.739
SUFF++ for r=0.8 class 0 = 0.593 +- 0.290 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.8 class 1 = 0.688 +- 0.290 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.8 class 2 = 0.755 +- 0.290 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.8 all KL = 0.672 +- 0.290 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.8 all L1 = 0.68 +- 0.231 (in-sample avg dev_std = 0.433)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.404
Model XAI F1 of binarized graphs for r=0.8 =  0.3625387499999999
Model XAI WIoU of binarized graphs for r=0.8 =  0.2476175
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.412
SUFF++ for r=0.8 class 0 = 0.839 +- 0.344 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.8 class 1 = 0.723 +- 0.344 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.8 class 2 = 0.978 +- 0.344 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.8 all KL = 0.819 +- 0.344 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.8 all L1 = 0.846 +- 0.287 (in-sample avg dev_std = 0.326)


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.924
Model XAI F1 of binarized graphs for r=0.8 =  0.50251
Model XAI WIoU of binarized graphs for r=0.8 =  0.61120125
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.451
NEC for r=0.8 class 0 = 0.653 +- 0.239 (in-sample avg dev_std = 0.668)
NEC for r=0.8 class 1 = 0.58 +- 0.239 (in-sample avg dev_std = 0.668)
NEC for r=0.8 class 2 = 0.591 +- 0.239 (in-sample avg dev_std = 0.668)
NEC for r=0.8 all KL = 0.719 +- 0.239 (in-sample avg dev_std = 0.668)
NEC for r=0.8 all L1 = 0.608 +- 0.159 (in-sample avg dev_std = 0.668)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.404
Model XAI F1 of binarized graphs for r=0.8 =  0.3625387499999999
Model XAI WIoU of binarized graphs for r=0.8 =  0.2476175
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.38
NEC for r=0.8 class 0 = 0.263 +- 0.427 (in-sample avg dev_std = 0.454)
NEC for r=0.8 class 1 = 0.181 +- 0.427 (in-sample avg dev_std = 0.454)
NEC for r=0.8 class 2 = 0.165 +- 0.427 (in-sample avg dev_std = 0.454)
NEC for r=0.8 all KL = 0.341 +- 0.427 (in-sample avg dev_std = 0.454)
NEC for r=0.8 all L1 = 0.203 +- 0.283 (in-sample avg dev_std = 0.454)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 11 11:25:34 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/11/2024 11:25:34 AM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/11/2024 11:25:34 AM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/11/2024 11:25:34 AM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/11/2024 11:25:34 AM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/11/2024 11:25:34 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 11:25:34 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:25:34 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:25:34 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:25:34 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:25:34 AM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/11/2024 11:25:34 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 11:25:34 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:25:34 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:25:34 AM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/11/2024 11:25:34 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 29...
[0m[1;37mINFO[0m: [1mCheckpoint 29: 
-----------------------------------
Train ACCURACY: 0.9219
Train Loss: 0.4585
ID Validation ACCURACY: 0.9277
ID Validation Loss: 0.4446
ID Test ACCURACY: 0.9153
ID Test Loss: 0.5136
OOD Validation ACCURACY: 0.9030
OOD Validation Loss: 0.4462
OOD Test ACCURACY: 0.4087
OOD Test Loss: 12.6375

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 51...
[0m[1;37mINFO[0m: [1mCheckpoint 51: 
-----------------------------------
Train ACCURACY: 0.9233
Train Loss: 0.4108
ID Validation ACCURACY: 0.9277
ID Validation Loss: 0.3921
ID Test ACCURACY: 0.9180
ID Test Loss: 0.4568
OOD Validation ACCURACY: 0.9187
OOD Validation Loss: 0.3832
OOD Test ACCURACY: 0.4087
OOD Test Loss: 14.2353

[0m[1;37mINFO[0m: [1mChartInfo 0.9153 0.4087 0.9180 0.4087 0.9277 0.9187[0mGOODMotif2(3000)
Data example from id_test: Data(edge_index=[2, 56], x=[16, 1], node_gt=[16], edge_gt=[56], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=16)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([ 988,  973, 1039]))

Gold ratio (id_test) =  tensor(0.3032) +- tensor(0.1592)
F1 for r=0.8 = 0.512
WIoU for r=0.8 = 0.500
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.8 = 0.412
WIoU for r=0.8 = 0.309


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.923
Model XAI F1 of binarized graphs for r=0.8 =  0.5122925
Model XAI WIoU of binarized graphs for r=0.8 =  0.49985124999999997
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.767
SUFF++ for r=0.8 class 0 = 0.559 +- 0.312 (in-sample avg dev_std = 0.449)
SUFF++ for r=0.8 class 1 = 0.749 +- 0.312 (in-sample avg dev_std = 0.449)
SUFF++ for r=0.8 class 2 = 0.861 +- 0.312 (in-sample avg dev_std = 0.449)
SUFF++ for r=0.8 all KL = 0.67 +- 0.312 (in-sample avg dev_std = 0.449)
SUFF++ for r=0.8 all L1 = 0.725 +- 0.248 (in-sample avg dev_std = 0.449)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.404
Model XAI F1 of binarized graphs for r=0.8 =  0.4124387499999999
Model XAI WIoU of binarized graphs for r=0.8 =  0.30873625
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.394
SUFF++ for r=0.8 class 0 = 0.859 +- 0.201 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.8 class 1 = 0.916 +- 0.201 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.8 class 2 = 0.943 +- 0.201 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.8 all KL = 0.89 +- 0.201 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.8 all L1 = 0.906 +- 0.168 (in-sample avg dev_std = 0.187)


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.923
Model XAI F1 of binarized graphs for r=0.8 =  0.5122925
Model XAI WIoU of binarized graphs for r=0.8 =  0.49985124999999997
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.474
NEC for r=0.8 class 0 = 0.637 +- 0.237 (in-sample avg dev_std = 0.759)
NEC for r=0.8 class 1 = 0.531 +- 0.237 (in-sample avg dev_std = 0.759)
NEC for r=0.8 class 2 = 0.597 +- 0.237 (in-sample avg dev_std = 0.759)
NEC for r=0.8 all KL = 0.771 +- 0.237 (in-sample avg dev_std = 0.759)
NEC for r=0.8 all L1 = 0.589 +- 0.181 (in-sample avg dev_std = 0.759)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.404
Model XAI F1 of binarized graphs for r=0.8 =  0.4124387499999999
Model XAI WIoU of binarized graphs for r=0.8 =  0.30873625
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.403
NEC for r=0.8 class 0 = 0.319 +- 0.390 (in-sample avg dev_std = 0.554)
NEC for r=0.8 class 1 = 0.371 +- 0.390 (in-sample avg dev_std = 0.554)
NEC for r=0.8 class 2 = 0.204 +- 0.390 (in-sample avg dev_std = 0.554)
NEC for r=0.8 all KL = 0.604 +- 0.390 (in-sample avg dev_std = 0.554)
NEC for r=0.8 all L1 = 0.298 +- 0.269 (in-sample avg dev_std = 0.554)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 11 11:26:37 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/11/2024 11:26:37 AM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/11/2024 11:26:37 AM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/11/2024 11:26:37 AM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/11/2024 11:26:37 AM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/11/2024 11:26:37 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 11:26:37 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:26:37 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:26:37 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:26:37 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:26:37 AM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/11/2024 11:26:37 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 11:26:37 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:26:37 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:26:37 AM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/11/2024 11:26:37 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 28...
[0m[1;37mINFO[0m: [1mCheckpoint 28: 
-----------------------------------
Train ACCURACY: 0.8898
Train Loss: 0.5536
ID Validation ACCURACY: 0.9003
ID Validation Loss: 0.5339
ID Test ACCURACY: 0.8880
ID Test Loss: 0.5790
OOD Validation ACCURACY: 0.8117
OOD Validation Loss: 0.5655
OOD Test ACCURACY: 0.4087
OOD Test Loss: 19.5623

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 144...
[0m[1;37mINFO[0m: [1mCheckpoint 144: 
-----------------------------------
Train ACCURACY: 0.8036
Train Loss: 0.5833
ID Validation ACCURACY: 0.8053
ID Validation Loss: 0.5878
ID Test ACCURACY: 0.7930
ID Test Loss: 0.6074
OOD Validation ACCURACY: 0.8780
OOD Validation Loss: 0.4487
OOD Test ACCURACY: 0.4087
OOD Test Loss: 16.8359

[0m[1;37mINFO[0m: [1mChartInfo 0.8880 0.4087 0.7930 0.4087 0.8053 0.8780[0mGOODMotif2(3000)
Data example from id_test: Data(edge_index=[2, 56], x=[16, 1], node_gt=[16], edge_gt=[56], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=16)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([ 988,  973, 1039]))

Gold ratio (id_test) =  tensor(0.3032) +- tensor(0.1592)
F1 for r=0.8 = 0.499
WIoU for r=0.8 = 0.735
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.8 = 0.325
WIoU for r=0.8 = 0.221


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.885
Model XAI F1 of binarized graphs for r=0.8 =  0.49880625
Model XAI WIoU of binarized graphs for r=0.8 =  0.7349812499999999
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.699
SUFF++ for r=0.8 class 0 = 0.586 +- 0.305 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.8 class 1 = 0.656 +- 0.305 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.8 class 2 = 0.78 +- 0.305 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.8 all KL = 0.668 +- 0.305 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.8 all L1 = 0.676 +- 0.237 (in-sample avg dev_std = 0.417)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.404
Model XAI F1 of binarized graphs for r=0.8 =  0.32493125
Model XAI WIoU of binarized graphs for r=0.8 =  0.22100499999999998
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.4
SUFF++ for r=0.8 class 0 = 0.862 +- 0.325 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.8 class 1 = 0.695 +- 0.325 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.8 class 2 = 0.982 +- 0.325 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.8 all KL = 0.838 +- 0.325 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.8 all L1 = 0.845 +- 0.293 (in-sample avg dev_std = 0.250)


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.885
Model XAI F1 of binarized graphs for r=0.8 =  0.49880625
Model XAI WIoU of binarized graphs for r=0.8 =  0.7349812499999999
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.456
NEC for r=0.8 class 0 = 0.548 +- 0.252 (in-sample avg dev_std = 0.681)
NEC for r=0.8 class 1 = 0.604 +- 0.252 (in-sample avg dev_std = 0.681)
NEC for r=0.8 class 2 = 0.612 +- 0.252 (in-sample avg dev_std = 0.681)
NEC for r=0.8 all KL = 0.7 +- 0.252 (in-sample avg dev_std = 0.681)
NEC for r=0.8 all L1 = 0.588 +- 0.161 (in-sample avg dev_std = 0.681)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.404
Model XAI F1 of binarized graphs for r=0.8 =  0.32493125
Model XAI WIoU of binarized graphs for r=0.8 =  0.22100499999999998
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.356
NEC for r=0.8 class 0 = 0.27 +- 0.443 (in-sample avg dev_std = 0.428)
NEC for r=0.8 class 1 = 0.204 +- 0.443 (in-sample avg dev_std = 0.428)
NEC for r=0.8 class 2 = 0.186 +- 0.443 (in-sample avg dev_std = 0.428)
NEC for r=0.8 all KL = 0.38 +- 0.443 (in-sample avg dev_std = 0.428)
NEC for r=0.8 all L1 = 0.219 +- 0.292 (in-sample avg dev_std = 0.428)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 11 11:27:41 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/11/2024 11:27:41 AM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/11/2024 11:27:41 AM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/11/2024 11:27:41 AM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/11/2024 11:27:41 AM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/11/2024 11:27:41 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 11:27:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:27:41 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:27:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:27:41 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:27:41 AM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/11/2024 11:27:41 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 11:27:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:27:41 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:27:41 AM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/11/2024 11:27:41 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 33...
[0m[1;37mINFO[0m: [1mCheckpoint 33: 
-----------------------------------
Train ACCURACY: 0.9238
Train Loss: 0.4617
ID Validation ACCURACY: 0.9273
ID Validation Loss: 0.4236
ID Test ACCURACY: 0.9190
ID Test Loss: 0.4980
OOD Validation ACCURACY: 0.9040
OOD Validation Loss: 0.4178
OOD Test ACCURACY: 0.4087
OOD Test Loss: 18.1921

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 27...
[0m[1;37mINFO[0m: [1mCheckpoint 27: 
-----------------------------------
Train ACCURACY: 0.9162
Train Loss: 0.4235
ID Validation ACCURACY: 0.9237
ID Validation Loss: 0.3927
ID Test ACCURACY: 0.9133
ID Test Loss: 0.4441
OOD Validation ACCURACY: 0.9150
OOD Validation Loss: 0.3759
OOD Test ACCURACY: 0.6387
OOD Test Loss: 3.0586

[0m[1;37mINFO[0m: [1mChartInfo 0.9190 0.4087 0.9133 0.6387 0.9237 0.9150[0mGOODMotif2(3000)
Data example from id_test: Data(edge_index=[2, 56], x=[16, 1], node_gt=[16], edge_gt=[56], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=16)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([ 988,  973, 1039]))

Gold ratio (id_test) =  tensor(0.3032) +- tensor(0.1592)
F1 for r=0.8 = 0.511
WIoU for r=0.8 = 0.503
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.8 = 0.415
WIoU for r=0.8 = 0.279


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.929
Model XAI F1 of binarized graphs for r=0.8 =  0.5113387500000001
Model XAI WIoU of binarized graphs for r=0.8 =  0.5026125
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.782
SUFF++ for r=0.8 class 0 = 0.551 +- 0.313 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.8 class 1 = 0.862 +- 0.313 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.8 class 2 = 0.8 +- 0.313 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.8 all KL = 0.667 +- 0.313 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.8 all L1 = 0.738 +- 0.239 (in-sample avg dev_std = 0.460)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.405
Model XAI F1 of binarized graphs for r=0.8 =  0.4146775
Model XAI WIoU of binarized graphs for r=0.8 =  0.27916124999999997
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.381
SUFF++ for r=0.8 class 0 = 0.825 +- 0.285 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.8 class 1 = 0.891 +- 0.285 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.8 class 2 = 0.889 +- 0.285 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.8 all KL = 0.828 +- 0.285 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.8 all L1 = 0.869 +- 0.199 (in-sample avg dev_std = 0.300)


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.929
Model XAI F1 of binarized graphs for r=0.8 =  0.5113387500000001
Model XAI WIoU of binarized graphs for r=0.8 =  0.5026125
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.492
NEC for r=0.8 class 0 = 0.633 +- 0.241 (in-sample avg dev_std = 0.784)
NEC for r=0.8 class 1 = 0.502 +- 0.241 (in-sample avg dev_std = 0.784)
NEC for r=0.8 class 2 = 0.62 +- 0.241 (in-sample avg dev_std = 0.784)
NEC for r=0.8 all KL = 0.793 +- 0.241 (in-sample avg dev_std = 0.784)
NEC for r=0.8 all L1 = 0.586 +- 0.187 (in-sample avg dev_std = 0.784)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.405
Model XAI F1 of binarized graphs for r=0.8 =  0.4146775
Model XAI WIoU of binarized graphs for r=0.8 =  0.27916124999999997
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.386
NEC for r=0.8 class 0 = 0.277 +- 0.442 (in-sample avg dev_std = 0.521)
NEC for r=0.8 class 1 = 0.274 +- 0.442 (in-sample avg dev_std = 0.521)
NEC for r=0.8 class 2 = 0.213 +- 0.442 (in-sample avg dev_std = 0.521)
NEC for r=0.8 all KL = 0.478 +- 0.442 (in-sample avg dev_std = 0.521)
NEC for r=0.8 all L1 = 0.255 +- 0.281 (in-sample avg dev_std = 0.521)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 11 11:28:42 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/11/2024 11:28:42 AM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/11/2024 11:28:42 AM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/11/2024 11:28:42 AM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/11/2024 11:28:42 AM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/11/2024 11:28:42 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 11:28:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:28:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:28:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:28:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:28:42 AM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/11/2024 11:28:42 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 11:28:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:28:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:28:42 AM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/11/2024 11:28:42 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 62...
[0m[1;37mINFO[0m: [1mCheckpoint 62: 
-----------------------------------
Train ACCURACY: 0.9232
Train Loss: 0.4686
ID Validation ACCURACY: 0.9290
ID Validation Loss: 0.4482
ID Test ACCURACY: 0.9190
ID Test Loss: 0.5270
OOD Validation ACCURACY: 0.9023
OOD Validation Loss: 0.4335
OOD Test ACCURACY: 0.4097
OOD Test Loss: 11.4881

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 112...
[0m[1;37mINFO[0m: [1mCheckpoint 112: 
-----------------------------------
Train ACCURACY: 0.9212
Train Loss: 0.4121
ID Validation ACCURACY: 0.9280
ID Validation Loss: 0.3988
ID Test ACCURACY: 0.9170
ID Test Loss: 0.4630
OOD Validation ACCURACY: 0.9170
OOD Validation Loss: 0.3851
OOD Test ACCURACY: 0.4087
OOD Test Loss: 36.3874

[0m[1;37mINFO[0m: [1mChartInfo 0.9190 0.4097 0.9170 0.4087 0.9280 0.9170[0mGOODMotif2(3000)
Data example from id_test: Data(edge_index=[2, 56], x=[16, 1], node_gt=[16], edge_gt=[56], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=16)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([ 988,  973, 1039]))

Gold ratio (id_test) =  tensor(0.3032) +- tensor(0.1592)
F1 for r=0.8 = 0.477
WIoU for r=0.8 = 0.468
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.8 = 0.338
WIoU for r=0.8 = 0.261


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.93
Model XAI F1 of binarized graphs for r=0.8 =  0.47729875
Model XAI WIoU of binarized graphs for r=0.8 =  0.46787375
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.662
SUFF++ for r=0.8 class 0 = 0.457 +- 0.369 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.8 class 1 = 0.753 +- 0.369 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.8 class 2 = 0.706 +- 0.369 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.8 all KL = 0.546 +- 0.369 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.8 all L1 = 0.639 +- 0.284 (in-sample avg dev_std = 0.516)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.405
Model XAI F1 of binarized graphs for r=0.8 =  0.33816874999999996
Model XAI WIoU of binarized graphs for r=0.8 =  0.260725
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.394
SUFF++ for r=0.8 class 0 = 0.832 +- 0.368 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.8 class 1 = 0.748 +- 0.368 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.8 class 2 = 0.883 +- 0.368 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.8 all KL = 0.68 +- 0.368 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.8 all L1 = 0.82 +- 0.206 (in-sample avg dev_std = 0.414)


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.93
Model XAI F1 of binarized graphs for r=0.8 =  0.47729875
Model XAI WIoU of binarized graphs for r=0.8 =  0.46787375
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.485
NEC for r=0.8 class 0 = 0.651 +- 0.256 (in-sample avg dev_std = 0.756)
NEC for r=0.8 class 1 = 0.431 +- 0.256 (in-sample avg dev_std = 0.756)
NEC for r=0.8 class 2 = 0.626 +- 0.256 (in-sample avg dev_std = 0.756)
NEC for r=0.8 all KL = 0.769 +- 0.256 (in-sample avg dev_std = 0.756)
NEC for r=0.8 all L1 = 0.571 +- 0.208 (in-sample avg dev_std = 0.756)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.405
Model XAI F1 of binarized graphs for r=0.8 =  0.33816874999999996
Model XAI WIoU of binarized graphs for r=0.8 =  0.260725
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.456
NEC for r=0.8 class 0 = 0.331 +- 0.411 (in-sample avg dev_std = 0.520)
NEC for r=0.8 class 1 = 0.315 +- 0.411 (in-sample avg dev_std = 0.520)
NEC for r=0.8 class 2 = 0.2 +- 0.411 (in-sample avg dev_std = 0.520)
NEC for r=0.8 all KL = 0.529 +- 0.411 (in-sample avg dev_std = 0.520)
NEC for r=0.8 all L1 = 0.282 +- 0.277 (in-sample avg dev_std = 0.520)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.672], 'all_L1': [0.68]}), defaultdict(<class 'list'>, {'all_KL': [0.67], 'all_L1': [0.725]}), defaultdict(<class 'list'>, {'all_KL': [0.668], 'all_L1': [0.676]}), defaultdict(<class 'list'>, {'all_KL': [0.667], 'all_L1': [0.738]}), defaultdict(<class 'list'>, {'all_KL': [0.546], 'all_L1': [0.639]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.719], 'all_L1': [0.608]}), defaultdict(<class 'list'>, {'all_KL': [0.771], 'all_L1': [0.589]}), defaultdict(<class 'list'>, {'all_KL': [0.7], 'all_L1': [0.588]}), defaultdict(<class 'list'>, {'all_KL': [0.793], 'all_L1': [0.586]}), defaultdict(<class 'list'>, {'all_KL': [0.769], 'all_L1': [0.571]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.819], 'all_L1': [0.846]}), defaultdict(<class 'list'>, {'all_KL': [0.89], 'all_L1': [0.906]}), defaultdict(<class 'list'>, {'all_KL': [0.838], 'all_L1': [0.845]}), defaultdict(<class 'list'>, {'all_KL': [0.828], 'all_L1': [0.869]}), defaultdict(<class 'list'>, {'all_KL': [0.68], 'all_L1': [0.82]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.341], 'all_L1': [0.203]}), defaultdict(<class 'list'>, {'all_KL': [0.604], 'all_L1': [0.298]}), defaultdict(<class 'list'>, {'all_KL': [0.38], 'all_L1': [0.219]}), defaultdict(<class 'list'>, {'all_KL': [0.478], 'all_L1': [0.255]}), defaultdict(<class 'list'>, {'all_KL': [0.529], 'all_L1': [0.282]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_test
suff++ class all_L1  =  0.692 +- 0.036
suff++ class all_KL  =  0.645 +- 0.049
suff++_acc_int  =  0.730 +- 0.044
nec class all_L1  =  0.588 +- 0.012
nec class all_KL  =  0.750 +- 0.035
nec_acc_int  =  0.472 +- 0.016

Eval split test
suff++ class all_L1  =  0.857 +- 0.029
suff++ class all_KL  =  0.811 +- 0.070
suff++_acc_int  =  0.396 +- 0.010
nec class all_L1  =  0.251 +- 0.036
nec class all_KL  =  0.466 +- 0.096
nec_acc_int  =  0.396 +- 0.034


 -------------------------------------------------- 
Computing faithfulness

Eval split id_test
Faith. Aritm (L1)= 		  =  0.640 +- 0.020
Faith. Armon (L1)= 		  =  0.635 +- 0.018
Faith. GMean (L1)= 	  =  0.638 +- 0.019
Faith. Aritm (KL)= 		  =  0.697 +- 0.026
Faith. Armon (KL)= 		  =  0.692 +- 0.030
Faith. GMean (KL)= 	  =  0.695 +- 0.028

Eval split test
Faith. Aritm (L1)= 		  =  0.554 +- 0.027
Faith. Armon (L1)= 		  =  0.388 +- 0.045
Faith. GMean (L1)= 	  =  0.463 +- 0.037
Faith. Aritm (KL)= 		  =  0.639 +- 0.059
Faith. Armon (KL)= 		  =  0.585 +- 0.082
Faith. GMean (KL)= 	  =  0.611 +- 0.070
Computed for split load_split = id



Completed in  0:05:19.809328  for CIGAGIN GOODMotif2/basis



DONE CIGA GOODMotif2/basis nov

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 11 11:30:02 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 05/11/2024 11:30:03 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 11:30:03 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 11:30:03 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 11:30:03 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 11:30:03 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 11:30:03 AM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/11/2024 11:30:03 AM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/11/2024 11:30:03 AM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/11/2024 11:30:03 AM : [1mCreating GINFeatExtractor:  5
[0m[1;34mDEBUG[0m: 05/11/2024 11:30:03 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 11:30:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:30:03 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:30:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:30:03 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:30:03 AM : [1mUsing  3  layers for classifier
[0m[1;34mDEBUG[0m: 05/11/2024 11:30:03 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 11:30:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:30:03 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:30:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:30:03 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:30:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:30:03 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:30:03 AM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/11/2024 11:30:03 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 90...
[0m[1;37mINFO[0m: [1mCheckpoint 90: 
-----------------------------------
Train ACCURACY: 0.2997
Train Loss: 3.3387
ID Validation ACCURACY: 0.2909
ID Validation Loss: 3.4073
ID Test ACCURACY: 0.2920
ID Test Loss: 3.3954
OOD Validation ACCURACY: 0.2336
OOD Validation Loss: 5.2601
OOD Test ACCURACY: 0.1400
OOD Test Loss: 6.1619

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 90...
[0m[1;37mINFO[0m: [1mCheckpoint 90: 
-----------------------------------
Train ACCURACY: 0.2997
Train Loss: 3.3387
ID Validation ACCURACY: 0.2909
ID Validation Loss: 3.4073
ID Test ACCURACY: 0.2920
ID Test Loss: 3.3954
OOD Validation ACCURACY: 0.2336
OOD Validation Loss: 5.2601
OOD Test ACCURACY: 0.1400
OOD Test Loss: 6.1619

[0m[1;37mINFO[0m: [1mChartInfo 0.2920 0.1400 0.2920 0.1400 0.2909 0.2336[0mGOODCMNIST(7000)
Data example from id_test: Data(x=[75, 3], edge_index=[2, 1351], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1351], node_perm=[75])
Label distribution from id_test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([657, 814, 676, 706, 676, 663, 688, 748, 702, 670]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.301
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.171
SUFF++ for r=0.6 class 0 = 0.287 +- 0.178 (in-sample avg dev_std = 0.581)
SUFF++ for r=0.6 class 1 = 0.316 +- 0.178 (in-sample avg dev_std = 0.581)
SUFF++ for r=0.6 class 2 = 0.234 +- 0.178 (in-sample avg dev_std = 0.581)
SUFF++ for r=0.6 class 3 = 0.255 +- 0.178 (in-sample avg dev_std = 0.581)
SUFF++ for r=0.6 class 4 = 0.272 +- 0.178 (in-sample avg dev_std = 0.581)
SUFF++ for r=0.6 class 5 = 0.269 +- 0.178 (in-sample avg dev_std = 0.581)
SUFF++ for r=0.6 class 6 = 0.372 +- 0.178 (in-sample avg dev_std = 0.581)
SUFF++ for r=0.6 class 7 = 0.27 +- 0.178 (in-sample avg dev_std = 0.581)
SUFF++ for r=0.6 class 8 = 0.255 +- 0.178 (in-sample avg dev_std = 0.581)
SUFF++ for r=0.6 class 9 = 0.279 +- 0.178 (in-sample avg dev_std = 0.581)
SUFF++ for r=0.6 all KL = 0.143 +- 0.178 (in-sample avg dev_std = 0.581)
SUFF++ for r=0.6 all L1 = 0.282 +- 0.110 (in-sample avg dev_std = 0.581)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.147
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.175
SUFF++ for r=0.6 class 0 = 0.321 +- 0.220 (in-sample avg dev_std = 0.541)
SUFF++ for r=0.6 class 1 = 0.311 +- 0.220 (in-sample avg dev_std = 0.541)
SUFF++ for r=0.6 class 2 = 0.358 +- 0.220 (in-sample avg dev_std = 0.541)
SUFF++ for r=0.6 class 3 = 0.302 +- 0.220 (in-sample avg dev_std = 0.541)
SUFF++ for r=0.6 class 4 = 0.257 +- 0.220 (in-sample avg dev_std = 0.541)
SUFF++ for r=0.6 class 5 = 0.367 +- 0.220 (in-sample avg dev_std = 0.541)
SUFF++ for r=0.6 class 6 = 0.289 +- 0.220 (in-sample avg dev_std = 0.541)
SUFF++ for r=0.6 class 7 = 0.295 +- 0.220 (in-sample avg dev_std = 0.541)
SUFF++ for r=0.6 class 8 = 0.258 +- 0.220 (in-sample avg dev_std = 0.541)
SUFF++ for r=0.6 class 9 = 0.253 +- 0.220 (in-sample avg dev_std = 0.541)
SUFF++ for r=0.6 all KL = 0.205 +- 0.220 (in-sample avg dev_std = 0.541)
SUFF++ for r=0.6 all L1 = 0.301 +- 0.136 (in-sample avg dev_std = 0.541)


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.301
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.292
NEC for r=0.6 class 0 = 0.366 +- 0.247 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 1 = 0.454 +- 0.247 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 2 = 0.567 +- 0.247 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 3 = 0.551 +- 0.247 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 4 = 0.534 +- 0.247 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 5 = 0.531 +- 0.247 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 6 = 0.489 +- 0.247 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 7 = 0.496 +- 0.247 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 8 = 0.546 +- 0.247 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 9 = 0.448 +- 0.247 (in-sample avg dev_std = 0.334)
NEC for r=0.6 all KL = 0.477 +- 0.247 (in-sample avg dev_std = 0.334)
NEC for r=0.6 all L1 = 0.498 +- 0.190 (in-sample avg dev_std = 0.334)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.147
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.128
NEC for r=0.6 class 0 = 0.379 +- 0.272 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 1 = 0.297 +- 0.272 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 2 = 0.422 +- 0.272 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 3 = 0.481 +- 0.272 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 4 = 0.41 +- 0.272 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 5 = 0.425 +- 0.272 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 6 = 0.422 +- 0.272 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 7 = 0.479 +- 0.272 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 8 = 0.486 +- 0.272 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 9 = 0.38 +- 0.272 (in-sample avg dev_std = 0.328)
NEC for r=0.6 all KL = 0.395 +- 0.272 (in-sample avg dev_std = 0.328)
NEC for r=0.6 all L1 = 0.417 +- 0.221 (in-sample avg dev_std = 0.328)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 11 11:35:40 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 05/11/2024 11:35:41 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 11:35:41 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 11:35:41 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 11:35:41 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 11:35:42 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 11:35:42 AM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/11/2024 11:35:42 AM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/11/2024 11:35:42 AM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/11/2024 11:35:42 AM : [1mCreating GINFeatExtractor:  5
[0m[1;34mDEBUG[0m: 05/11/2024 11:35:42 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 11:35:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:35:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:35:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:35:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:35:42 AM : [1mUsing  3  layers for classifier
[0m[1;34mDEBUG[0m: 05/11/2024 11:35:42 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 11:35:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:35:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:35:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:35:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:35:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:35:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:35:42 AM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/11/2024 11:35:42 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 70...
[0m[1;37mINFO[0m: [1mCheckpoint 70: 
-----------------------------------
Train ACCURACY: 0.6581
Train Loss: 0.9910
ID Validation ACCURACY: 0.6360
ID Validation Loss: 1.0899
ID Test ACCURACY: 0.6253
ID Test Loss: 1.1128
OOD Validation ACCURACY: 0.4889
OOD Validation Loss: 1.6348
OOD Test ACCURACY: 0.2900
OOD Test Loss: 2.5498

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 76...
[0m[1;37mINFO[0m: [1mCheckpoint 76: 
-----------------------------------
Train ACCURACY: 0.5949
Train Loss: 1.2307
ID Validation ACCURACY: 0.5809
ID Validation Loss: 1.3357
ID Test ACCURACY: 0.5690
ID Test Loss: 1.3701
OOD Validation ACCURACY: 0.5664
OOD Validation Loss: 1.3707
OOD Test ACCURACY: 0.3381
OOD Test Loss: 2.4209

[0m[1;37mINFO[0m: [1mChartInfo 0.6253 0.2900 0.5690 0.3381 0.5809 0.5664[0mGOODCMNIST(7000)
Data example from id_test: Data(x=[75, 3], edge_index=[2, 1351], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1351], node_perm=[75])
Label distribution from id_test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([657, 814, 676, 706, 676, 663, 688, 748, 702, 670]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.634
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.252
SUFF++ for r=0.6 class 0 = 0.272 +- 0.161 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.6 class 1 = 0.367 +- 0.161 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.6 class 2 = 0.281 +- 0.161 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.6 class 3 = 0.27 +- 0.161 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.6 class 4 = 0.311 +- 0.161 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.6 class 5 = 0.273 +- 0.161 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.6 class 6 = 0.294 +- 0.161 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.6 class 7 = 0.42 +- 0.161 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.6 class 8 = 0.257 +- 0.161 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.6 class 9 = 0.308 +- 0.161 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.6 all KL = 0.16 +- 0.161 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.6 all L1 = 0.307 +- 0.100 (in-sample avg dev_std = 0.568)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.29
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.202
SUFF++ for r=0.6 class 0 = 0.361 +- 0.185 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.6 class 1 = 0.678 +- 0.185 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.6 class 2 = 0.352 +- 0.185 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.6 class 3 = 0.349 +- 0.185 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.6 class 4 = 0.375 +- 0.185 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.6 class 5 = 0.358 +- 0.185 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.6 class 6 = 0.364 +- 0.185 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.6 class 7 = 0.398 +- 0.185 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.6 class 8 = 0.372 +- 0.185 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.6 class 9 = 0.367 +- 0.185 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.6 all KL = 0.29 +- 0.185 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.6 all L1 = 0.401 +- 0.141 (in-sample avg dev_std = 0.558)


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.634
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.418
NEC for r=0.6 class 0 = 0.687 +- 0.242 (in-sample avg dev_std = 0.342)
NEC for r=0.6 class 1 = 0.329 +- 0.242 (in-sample avg dev_std = 0.342)
NEC for r=0.6 class 2 = 0.542 +- 0.242 (in-sample avg dev_std = 0.342)
NEC for r=0.6 class 3 = 0.593 +- 0.242 (in-sample avg dev_std = 0.342)
NEC for r=0.6 class 4 = 0.483 +- 0.242 (in-sample avg dev_std = 0.342)
NEC for r=0.6 class 5 = 0.566 +- 0.242 (in-sample avg dev_std = 0.342)
NEC for r=0.6 class 6 = 0.624 +- 0.242 (in-sample avg dev_std = 0.342)
NEC for r=0.6 class 7 = 0.519 +- 0.242 (in-sample avg dev_std = 0.342)
NEC for r=0.6 class 8 = 0.539 +- 0.242 (in-sample avg dev_std = 0.342)
NEC for r=0.6 class 9 = 0.567 +- 0.242 (in-sample avg dev_std = 0.342)
NEC for r=0.6 all KL = 0.545 +- 0.242 (in-sample avg dev_std = 0.342)
NEC for r=0.6 all L1 = 0.541 +- 0.181 (in-sample avg dev_std = 0.342)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.29
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.299
NEC for r=0.6 class 0 = 0.526 +- 0.199 (in-sample avg dev_std = 0.246)
NEC for r=0.6 class 1 = 0.091 +- 0.199 (in-sample avg dev_std = 0.246)
NEC for r=0.6 class 2 = 0.499 +- 0.199 (in-sample avg dev_std = 0.246)
NEC for r=0.6 class 3 = 0.458 +- 0.199 (in-sample avg dev_std = 0.246)
NEC for r=0.6 class 4 = 0.528 +- 0.199 (in-sample avg dev_std = 0.246)
NEC for r=0.6 class 5 = 0.492 +- 0.199 (in-sample avg dev_std = 0.246)
NEC for r=0.6 class 6 = 0.472 +- 0.199 (in-sample avg dev_std = 0.246)
NEC for r=0.6 class 7 = 0.521 +- 0.199 (in-sample avg dev_std = 0.246)
NEC for r=0.6 class 8 = 0.446 +- 0.199 (in-sample avg dev_std = 0.246)
NEC for r=0.6 class 9 = 0.462 +- 0.199 (in-sample avg dev_std = 0.246)
NEC for r=0.6 all KL = 0.353 +- 0.199 (in-sample avg dev_std = 0.246)
NEC for r=0.6 all L1 = 0.445 +- 0.187 (in-sample avg dev_std = 0.246)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 11 11:41:16 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 05/11/2024 11:41:17 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 11:41:17 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 11:41:17 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 11:41:18 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 11:41:18 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 11:41:18 AM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/11/2024 11:41:18 AM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/11/2024 11:41:18 AM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/11/2024 11:41:18 AM : [1mCreating GINFeatExtractor:  5
[0m[1;34mDEBUG[0m: 05/11/2024 11:41:18 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 11:41:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:41:18 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:41:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:41:18 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:41:18 AM : [1mUsing  3  layers for classifier
[0m[1;34mDEBUG[0m: 05/11/2024 11:41:18 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 11:41:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:41:18 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:41:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:41:18 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:41:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:41:18 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:41:18 AM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/11/2024 11:41:18 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 66...
[0m[1;37mINFO[0m: [1mCheckpoint 66: 
-----------------------------------
Train ACCURACY: 0.6698
Train Loss: 0.9467
ID Validation ACCURACY: 0.6491
ID Validation Loss: 1.0314
ID Test ACCURACY: 0.6391
ID Test Loss: 1.0585
OOD Validation ACCURACY: 0.5524
OOD Validation Loss: 1.4077
OOD Test ACCURACY: 0.3830
OOD Test Loss: 2.2401

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 73...
[0m[1;37mINFO[0m: [1mCheckpoint 73: 
-----------------------------------
Train ACCURACY: 0.6334
Train Loss: 1.1120
ID Validation ACCURACY: 0.6076
ID Validation Loss: 1.2323
ID Test ACCURACY: 0.6007
ID Test Loss: 1.2595
OOD Validation ACCURACY: 0.5951
OOD Validation Loss: 1.2541
OOD Test ACCURACY: 0.3426
OOD Test Loss: 2.3810

[0m[1;37mINFO[0m: [1mChartInfo 0.6391 0.3830 0.6007 0.3426 0.6076 0.5951[0mGOODCMNIST(7000)
Data example from id_test: Data(x=[75, 3], edge_index=[2, 1351], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1351], node_perm=[75])
Label distribution from id_test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([657, 814, 676, 706, 676, 663, 688, 748, 702, 670]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.639
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.256
SUFF++ for r=0.6 class 0 = 0.323 +- 0.155 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.6 class 1 = 0.432 +- 0.155 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.6 class 2 = 0.273 +- 0.155 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.6 class 3 = 0.26 +- 0.155 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.6 class 4 = 0.289 +- 0.155 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.6 class 5 = 0.256 +- 0.155 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.6 class 6 = 0.242 +- 0.155 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.6 class 7 = 0.371 +- 0.155 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.6 class 8 = 0.234 +- 0.155 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.6 class 9 = 0.283 +- 0.155 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.6 all KL = 0.136 +- 0.155 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.6 all L1 = 0.299 +- 0.120 (in-sample avg dev_std = 0.534)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.381
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.238
SUFF++ for r=0.6 class 0 = 0.376 +- 0.226 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.6 class 1 = 0.723 +- 0.226 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.6 class 2 = 0.271 +- 0.226 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.6 class 3 = 0.294 +- 0.226 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.6 class 4 = 0.294 +- 0.226 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.6 class 5 = 0.291 +- 0.226 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.6 class 6 = 0.313 +- 0.226 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.6 class 7 = 0.351 +- 0.226 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.6 class 8 = 0.291 +- 0.226 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.6 class 9 = 0.304 +- 0.226 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.6 all KL = 0.199 +- 0.226 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.6 all L1 = 0.356 +- 0.187 (in-sample avg dev_std = 0.564)


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.639
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.411
NEC for r=0.6 class 0 = 0.668 +- 0.246 (in-sample avg dev_std = 0.343)
NEC for r=0.6 class 1 = 0.542 +- 0.246 (in-sample avg dev_std = 0.343)
NEC for r=0.6 class 2 = 0.508 +- 0.246 (in-sample avg dev_std = 0.343)
NEC for r=0.6 class 3 = 0.551 +- 0.246 (in-sample avg dev_std = 0.343)
NEC for r=0.6 class 4 = 0.391 +- 0.246 (in-sample avg dev_std = 0.343)
NEC for r=0.6 class 5 = 0.536 +- 0.246 (in-sample avg dev_std = 0.343)
NEC for r=0.6 class 6 = 0.555 +- 0.246 (in-sample avg dev_std = 0.343)
NEC for r=0.6 class 7 = 0.505 +- 0.246 (in-sample avg dev_std = 0.343)
NEC for r=0.6 class 8 = 0.549 +- 0.246 (in-sample avg dev_std = 0.343)
NEC for r=0.6 class 9 = 0.539 +- 0.246 (in-sample avg dev_std = 0.343)
NEC for r=0.6 all KL = 0.539 +- 0.246 (in-sample avg dev_std = 0.343)
NEC for r=0.6 all L1 = 0.534 +- 0.175 (in-sample avg dev_std = 0.343)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.381
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.381
NEC for r=0.6 class 0 = 0.372 +- 0.227 (in-sample avg dev_std = 0.283)
NEC for r=0.6 class 1 = 0.142 +- 0.227 (in-sample avg dev_std = 0.283)
NEC for r=0.6 class 2 = 0.54 +- 0.227 (in-sample avg dev_std = 0.283)
NEC for r=0.6 class 3 = 0.546 +- 0.227 (in-sample avg dev_std = 0.283)
NEC for r=0.6 class 4 = 0.541 +- 0.227 (in-sample avg dev_std = 0.283)
NEC for r=0.6 class 5 = 0.545 +- 0.227 (in-sample avg dev_std = 0.283)
NEC for r=0.6 class 6 = 0.553 +- 0.227 (in-sample avg dev_std = 0.283)
NEC for r=0.6 class 7 = 0.526 +- 0.227 (in-sample avg dev_std = 0.283)
NEC for r=0.6 class 8 = 0.545 +- 0.227 (in-sample avg dev_std = 0.283)
NEC for r=0.6 class 9 = 0.549 +- 0.227 (in-sample avg dev_std = 0.283)
NEC for r=0.6 all KL = 0.429 +- 0.227 (in-sample avg dev_std = 0.283)
NEC for r=0.6 all L1 = 0.481 +- 0.201 (in-sample avg dev_std = 0.283)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 11 11:46:53 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 05/11/2024 11:46:54 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 11:46:54 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 11:46:54 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 11:46:55 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 11:46:55 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 11:46:55 AM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/11/2024 11:46:55 AM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/11/2024 11:46:55 AM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/11/2024 11:46:55 AM : [1mCreating GINFeatExtractor:  5
[0m[1;34mDEBUG[0m: 05/11/2024 11:46:55 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 11:46:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:46:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:46:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:46:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:46:55 AM : [1mUsing  3  layers for classifier
[0m[1;34mDEBUG[0m: 05/11/2024 11:46:55 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 11:46:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:46:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:46:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:46:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:46:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:46:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:46:55 AM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/11/2024 11:46:55 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 66...
[0m[1;37mINFO[0m: [1mCheckpoint 66: 
-----------------------------------
Train ACCURACY: 0.5377
Train Loss: 1.5075
ID Validation ACCURACY: 0.5361
ID Validation Loss: 1.5713
ID Test ACCURACY: 0.5206
ID Test Loss: 1.6479
OOD Validation ACCURACY: 0.4199
OOD Validation Loss: 2.4982
OOD Test ACCURACY: 0.3477
OOD Test Loss: 3.0782

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 52...
[0m[1;37mINFO[0m: [1mCheckpoint 52: 
-----------------------------------
Train ACCURACY: 0.4893
Train Loss: 1.5757
ID Validation ACCURACY: 0.4821
ID Validation Loss: 1.6006
ID Test ACCURACY: 0.4747
ID Test Loss: 1.6438
OOD Validation ACCURACY: 0.4277
OOD Validation Loss: 1.9595
OOD Test ACCURACY: 0.3373
OOD Test Loss: 2.5935

[0m[1;37mINFO[0m: [1mChartInfo 0.5206 0.3477 0.4747 0.3373 0.4821 0.4277[0mGOODCMNIST(7000)
Data example from id_test: Data(x=[75, 3], edge_index=[2, 1351], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1351], node_perm=[75])
Label distribution from id_test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([657, 814, 676, 706, 676, 663, 688, 748, 702, 670]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.549
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.216
SUFF++ for r=0.6 class 0 = 0.429 +- 0.137 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.6 class 1 = 0.236 +- 0.137 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.6 class 2 = 0.261 +- 0.137 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.6 class 3 = 0.336 +- 0.137 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.6 class 4 = 0.246 +- 0.137 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.6 class 5 = 0.301 +- 0.137 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.6 class 6 = 0.29 +- 0.137 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.6 class 7 = 0.226 +- 0.137 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.6 class 8 = 0.34 +- 0.137 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.6 class 9 = 0.246 +- 0.137 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.6 all KL = 0.105 +- 0.137 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.6 all L1 = 0.289 +- 0.115 (in-sample avg dev_std = 0.550)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.361
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.242
SUFF++ for r=0.6 class 0 = 0.414 +- 0.201 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.6 class 1 = 0.639 +- 0.201 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.6 class 2 = 0.299 +- 0.201 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.6 class 3 = 0.314 +- 0.201 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.6 class 4 = 0.297 +- 0.201 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.6 class 5 = 0.305 +- 0.201 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.6 class 6 = 0.344 +- 0.201 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.6 class 7 = 0.33 +- 0.201 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.6 class 8 = 0.36 +- 0.201 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.6 class 9 = 0.342 +- 0.201 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.6 all KL = 0.216 +- 0.201 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.6 all L1 = 0.368 +- 0.171 (in-sample avg dev_std = 0.550)


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.549
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.391
NEC for r=0.6 class 0 = 0.177 +- 0.272 (in-sample avg dev_std = 0.364)
NEC for r=0.6 class 1 = 0.683 +- 0.272 (in-sample avg dev_std = 0.364)
NEC for r=0.6 class 2 = 0.599 +- 0.272 (in-sample avg dev_std = 0.364)
NEC for r=0.6 class 3 = 0.485 +- 0.272 (in-sample avg dev_std = 0.364)
NEC for r=0.6 class 4 = 0.536 +- 0.272 (in-sample avg dev_std = 0.364)
NEC for r=0.6 class 5 = 0.55 +- 0.272 (in-sample avg dev_std = 0.364)
NEC for r=0.6 class 6 = 0.484 +- 0.272 (in-sample avg dev_std = 0.364)
NEC for r=0.6 class 7 = 0.516 +- 0.272 (in-sample avg dev_std = 0.364)
NEC for r=0.6 class 8 = 0.524 +- 0.272 (in-sample avg dev_std = 0.364)
NEC for r=0.6 class 9 = 0.531 +- 0.272 (in-sample avg dev_std = 0.364)
NEC for r=0.6 all KL = 0.528 +- 0.272 (in-sample avg dev_std = 0.364)
NEC for r=0.6 all L1 = 0.513 +- 0.210 (in-sample avg dev_std = 0.364)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.361
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.321
NEC for r=0.6 class 0 = 0.355 +- 0.272 (in-sample avg dev_std = 0.355)
NEC for r=0.6 class 1 = 0.089 +- 0.272 (in-sample avg dev_std = 0.355)
NEC for r=0.6 class 2 = 0.621 +- 0.272 (in-sample avg dev_std = 0.355)
NEC for r=0.6 class 3 = 0.628 +- 0.272 (in-sample avg dev_std = 0.355)
NEC for r=0.6 class 4 = 0.605 +- 0.272 (in-sample avg dev_std = 0.355)
NEC for r=0.6 class 5 = 0.603 +- 0.272 (in-sample avg dev_std = 0.355)
NEC for r=0.6 class 6 = 0.599 +- 0.272 (in-sample avg dev_std = 0.355)
NEC for r=0.6 class 7 = 0.602 +- 0.272 (in-sample avg dev_std = 0.355)
NEC for r=0.6 class 8 = 0.597 +- 0.272 (in-sample avg dev_std = 0.355)
NEC for r=0.6 class 9 = 0.586 +- 0.272 (in-sample avg dev_std = 0.355)
NEC for r=0.6 all KL = 0.555 +- 0.272 (in-sample avg dev_std = 0.355)
NEC for r=0.6 all L1 = 0.522 +- 0.234 (in-sample avg dev_std = 0.355)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 11 11:52:33 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 05/11/2024 11:52:34 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 11:52:34 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 11:52:34 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 11:52:34 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 11:52:34 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 11:52:34 AM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/11/2024 11:52:34 AM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/11/2024 11:52:35 AM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/11/2024 11:52:35 AM : [1mCreating GINFeatExtractor:  5
[0m[1;34mDEBUG[0m: 05/11/2024 11:52:35 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 11:52:35 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:52:35 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:52:35 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:52:35 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:52:35 AM : [1mUsing  3  layers for classifier
[0m[1;34mDEBUG[0m: 05/11/2024 11:52:35 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 11:52:35 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:52:35 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:52:35 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:52:35 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:52:35 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 11:52:35 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 11:52:35 AM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/11/2024 11:52:35 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 78...
[0m[1;37mINFO[0m: [1mCheckpoint 78: 
-----------------------------------
Train ACCURACY: 0.5967
Train Loss: 1.3782
ID Validation ACCURACY: 0.5773
ID Validation Loss: 1.5029
ID Test ACCURACY: 0.5697
ID Test Loss: 1.5503
OOD Validation ACCURACY: 0.4626
OOD Validation Loss: 2.5270
OOD Test ACCURACY: 0.3526
OOD Test Loss: 8.1775

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 57...
[0m[1;37mINFO[0m: [1mCheckpoint 57: 
-----------------------------------
Train ACCURACY: 0.5321
Train Loss: 1.5191
ID Validation ACCURACY: 0.5236
ID Validation Loss: 1.5860
ID Test ACCURACY: 0.5176
ID Test Loss: 1.6001
OOD Validation ACCURACY: 0.4831
OOD Validation Loss: 1.8222
OOD Test ACCURACY: 0.3497
OOD Test Loss: 9.4069

[0m[1;37mINFO[0m: [1mChartInfo 0.5697 0.3526 0.5176 0.3497 0.5236 0.4831[0mGOODCMNIST(7000)
Data example from id_test: Data(x=[75, 3], edge_index=[2, 1351], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1351], node_perm=[75])
Label distribution from id_test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([657, 814, 676, 706, 676, 663, 688, 748, 702, 670]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.591
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.278
SUFF++ for r=0.6 class 0 = 0.284 +- 0.152 (in-sample avg dev_std = 0.673)
SUFF++ for r=0.6 class 1 = 0.629 +- 0.152 (in-sample avg dev_std = 0.673)
SUFF++ for r=0.6 class 2 = 0.243 +- 0.152 (in-sample avg dev_std = 0.673)
SUFF++ for r=0.6 class 3 = 0.251 +- 0.152 (in-sample avg dev_std = 0.673)
SUFF++ for r=0.6 class 4 = 0.239 +- 0.152 (in-sample avg dev_std = 0.673)
SUFF++ for r=0.6 class 5 = 0.273 +- 0.152 (in-sample avg dev_std = 0.673)
SUFF++ for r=0.6 class 6 = 0.268 +- 0.152 (in-sample avg dev_std = 0.673)
SUFF++ for r=0.6 class 7 = 0.26 +- 0.152 (in-sample avg dev_std = 0.673)
SUFF++ for r=0.6 class 8 = 0.261 +- 0.152 (in-sample avg dev_std = 0.673)
SUFF++ for r=0.6 class 9 = 0.255 +- 0.152 (in-sample avg dev_std = 0.673)
SUFF++ for r=0.6 all KL = 0.06 +- 0.152 (in-sample avg dev_std = 0.673)
SUFF++ for r=0.6 all L1 = 0.302 +- 0.154 (in-sample avg dev_std = 0.673)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.351
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.218
SUFF++ for r=0.6 class 0 = 0.358 +- 0.303 (in-sample avg dev_std = 0.663)
SUFF++ for r=0.6 class 1 = 0.871 +- 0.303 (in-sample avg dev_std = 0.663)
SUFF++ for r=0.6 class 2 = 0.249 +- 0.303 (in-sample avg dev_std = 0.663)
SUFF++ for r=0.6 class 3 = 0.295 +- 0.303 (in-sample avg dev_std = 0.663)
SUFF++ for r=0.6 class 4 = 0.313 +- 0.303 (in-sample avg dev_std = 0.663)
SUFF++ for r=0.6 class 5 = 0.279 +- 0.303 (in-sample avg dev_std = 0.663)
SUFF++ for r=0.6 class 6 = 0.343 +- 0.303 (in-sample avg dev_std = 0.663)
SUFF++ for r=0.6 class 7 = 0.313 +- 0.303 (in-sample avg dev_std = 0.663)
SUFF++ for r=0.6 class 8 = 0.319 +- 0.303 (in-sample avg dev_std = 0.663)
SUFF++ for r=0.6 class 9 = 0.452 +- 0.303 (in-sample avg dev_std = 0.663)
SUFF++ for r=0.6 all KL = 0.159 +- 0.303 (in-sample avg dev_std = 0.663)
SUFF++ for r=0.6 all L1 = 0.385 +- 0.254 (in-sample avg dev_std = 0.663)


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.591
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.433
NEC for r=0.6 class 0 = 0.276 +- 0.275 (in-sample avg dev_std = 0.399)
NEC for r=0.6 class 1 = 0.295 +- 0.275 (in-sample avg dev_std = 0.399)
NEC for r=0.6 class 2 = 0.674 +- 0.275 (in-sample avg dev_std = 0.399)
NEC for r=0.6 class 3 = 0.527 +- 0.275 (in-sample avg dev_std = 0.399)
NEC for r=0.6 class 4 = 0.577 +- 0.275 (in-sample avg dev_std = 0.399)
NEC for r=0.6 class 5 = 0.56 +- 0.275 (in-sample avg dev_std = 0.399)
NEC for r=0.6 class 6 = 0.595 +- 0.275 (in-sample avg dev_std = 0.399)
NEC for r=0.6 class 7 = 0.505 +- 0.275 (in-sample avg dev_std = 0.399)
NEC for r=0.6 class 8 = 0.573 +- 0.275 (in-sample avg dev_std = 0.399)
NEC for r=0.6 class 9 = 0.566 +- 0.275 (in-sample avg dev_std = 0.399)
NEC for r=0.6 all KL = 0.579 +- 0.275 (in-sample avg dev_std = 0.399)
NEC for r=0.6 all L1 = 0.511 +- 0.230 (in-sample avg dev_std = 0.399)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.351
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.33
NEC for r=0.6 class 0 = 0.202 +- 0.339 (in-sample avg dev_std = 0.402)
NEC for r=0.6 class 1 = 0.061 +- 0.339 (in-sample avg dev_std = 0.402)
NEC for r=0.6 class 2 = 0.542 +- 0.339 (in-sample avg dev_std = 0.402)
NEC for r=0.6 class 3 = 0.579 +- 0.339 (in-sample avg dev_std = 0.402)
NEC for r=0.6 class 4 = 0.563 +- 0.339 (in-sample avg dev_std = 0.402)
NEC for r=0.6 class 5 = 0.575 +- 0.339 (in-sample avg dev_std = 0.402)
NEC for r=0.6 class 6 = 0.597 +- 0.339 (in-sample avg dev_std = 0.402)
NEC for r=0.6 class 7 = 0.573 +- 0.339 (in-sample avg dev_std = 0.402)
NEC for r=0.6 class 8 = 0.628 +- 0.339 (in-sample avg dev_std = 0.402)
NEC for r=0.6 class 9 = 0.583 +- 0.339 (in-sample avg dev_std = 0.402)
NEC for r=0.6 all KL = 0.59 +- 0.339 (in-sample avg dev_std = 0.402)
NEC for r=0.6 all L1 = 0.483 +- 0.282 (in-sample avg dev_std = 0.402)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.143], 'all_L1': [0.282]}), defaultdict(<class 'list'>, {'all_KL': [0.16], 'all_L1': [0.307]}), defaultdict(<class 'list'>, {'all_KL': [0.136], 'all_L1': [0.299]}), defaultdict(<class 'list'>, {'all_KL': [0.105], 'all_L1': [0.289]}), defaultdict(<class 'list'>, {'all_KL': [0.06], 'all_L1': [0.302]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.477], 'all_L1': [0.498]}), defaultdict(<class 'list'>, {'all_KL': [0.545], 'all_L1': [0.541]}), defaultdict(<class 'list'>, {'all_KL': [0.539], 'all_L1': [0.534]}), defaultdict(<class 'list'>, {'all_KL': [0.528], 'all_L1': [0.513]}), defaultdict(<class 'list'>, {'all_KL': [0.579], 'all_L1': [0.511]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.205], 'all_L1': [0.301]}), defaultdict(<class 'list'>, {'all_KL': [0.29], 'all_L1': [0.401]}), defaultdict(<class 'list'>, {'all_KL': [0.199], 'all_L1': [0.356]}), defaultdict(<class 'list'>, {'all_KL': [0.216], 'all_L1': [0.368]}), defaultdict(<class 'list'>, {'all_KL': [0.159], 'all_L1': [0.385]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.395], 'all_L1': [0.417]}), defaultdict(<class 'list'>, {'all_KL': [0.353], 'all_L1': [0.445]}), defaultdict(<class 'list'>, {'all_KL': [0.429], 'all_L1': [0.481]}), defaultdict(<class 'list'>, {'all_KL': [0.555], 'all_L1': [0.522]}), defaultdict(<class 'list'>, {'all_KL': [0.59], 'all_L1': [0.483]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_test
suff++ class all_L1  =  0.296 +- 0.009
suff++ class all_KL  =  0.121 +- 0.035
suff++_acc_int  =  0.235 +- 0.037
nec class all_L1  =  0.519 +- 0.016
nec class all_KL  =  0.534 +- 0.033
nec_acc_int  =  0.389 +- 0.051

Eval split test
suff++ class all_L1  =  0.362 +- 0.034
suff++ class all_KL  =  0.214 +- 0.043
suff++_acc_int  =  0.215 +- 0.025
nec class all_L1  =  0.470 +- 0.036
nec class all_KL  =  0.464 +- 0.092
nec_acc_int  =  0.292 +- 0.086


 -------------------------------------------------- 
Computing faithfulness

Eval split id_test
Faith. Aritm (L1)= 		  =  0.408 +- 0.012
Faith. Armon (L1)= 		  =  0.377 +- 0.011
Faith. GMean (L1)= 	  =  0.392 +- 0.011
Faith. Aritm (KL)= 		  =  0.327 +- 0.016
Faith. Armon (KL)= 		  =  0.194 +- 0.048
Faith. GMean (KL)= 	  =  0.250 +- 0.037

Eval split test
Faith. Aritm (L1)= 		  =  0.416 +- 0.030
Faith. Armon (L1)= 		  =  0.408 +- 0.030
Faith. GMean (L1)= 	  =  0.412 +- 0.030
Faith. Aritm (KL)= 		  =  0.339 +- 0.034
Faith. Armon (KL)= 		  =  0.284 +- 0.026
Faith. GMean (KL)= 	  =  0.310 +- 0.022
Computed for split load_split = id



Completed in  0:28:11.357299  for CIGAGIN GOODCMNIST/color



DONE CIGA GOODCMNIST/color nov

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 11 11:58:28 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/11/2024 11:58:28 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/11/2024 11:59:03 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/11/2024 11:59:16 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/11/2024 11:59:27 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/11/2024 11:59:43 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/11/2024 12:00:01 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/11/2024 12:00:01 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/11/2024 12:00:01 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/11/2024 12:00:01 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/11/2024 12:00:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 12:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/11/2024 12:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 12:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/11/2024 12:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 12:00:01 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/11/2024 12:00:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 12:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/11/2024 12:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 12:00:01 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/11/2024 12:00:01 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 60...
[0m[1;37mINFO[0m: [1mCheckpoint 60: 
-----------------------------------
Train ROC-AUC: 0.9644
Train Loss: 0.3162
ID Validation ROC-AUC: 0.9159
ID Validation Loss: 0.4976
ID Test ROC-AUC: 0.9149
ID Test Loss: 0.5133
OOD Validation ROC-AUC: 0.6062
OOD Validation Loss: 0.7427
OOD Test ROC-AUC: 0.6845
OOD Test Loss: 1.0938

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 11...
[0m[1;37mINFO[0m: [1mCheckpoint 11: 
-----------------------------------
Train ROC-AUC: 0.9089
Train Loss: 0.3173
ID Validation ROC-AUC: 0.8910
ID Validation Loss: 0.3404
ID Test ROC-AUC: 0.8888
ID Test Loss: 0.3479
OOD Validation ROC-AUC: 0.6543
OOD Validation Loss: 0.3422
OOD Test ROC-AUC: 0.6990
OOD Test Loss: 0.5882

[0m[1;37mINFO[0m: [1mChartInfo 0.9149 0.6845 0.8888 0.6990 0.8910 0.6543[0mLBAPcore(11683)
Data example from id_test: Data(x=[33, 39], edge_index=[2, 72], edge_attr=[72, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 72], node_perm=[33])
Label distribution from id_test: (tensor([0., 1.]), tensor([ 1386, 10297]))
[1;34mDEBUG[0m: 05/11/2024 12:00:03 PM : [1mUnbalanced warning for LBAPcore (id_test)
[0mF1 for r=0.6 = nan
WIoU for r=0.6 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 05/11/2024 12:00:30 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.681
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.591
SUFF++ for r=0.6 class 0.0 = 0.657 +- 0.317 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.6 class 1.0 = 0.631 +- 0.317 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.6 all KL = 0.501 +- 0.317 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.6 all L1 = 0.634 +- 0.200 (in-sample avg dev_std = 0.580)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.573
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.531
SUFF++ for r=0.6 class 0.0 = 0.626 +- 0.315 (in-sample avg dev_std = 0.545)
SUFF++ for r=0.6 class 1.0 = 0.625 +- 0.315 (in-sample avg dev_std = 0.545)
SUFF++ for r=0.6 all KL = 0.54 +- 0.315 (in-sample avg dev_std = 0.545)
SUFF++ for r=0.6 all L1 = 0.625 +- 0.213 (in-sample avg dev_std = 0.545)


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.681
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.62
NEC for r=0.6 class 0.0 = 0.338 +- 0.255 (in-sample avg dev_std = 0.372)
NEC for r=0.6 class 1.0 = 0.232 +- 0.255 (in-sample avg dev_std = 0.372)
NEC for r=0.6 all KL = 0.275 +- 0.255 (in-sample avg dev_std = 0.372)
NEC for r=0.6 all L1 = 0.245 +- 0.203 (in-sample avg dev_std = 0.372)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.573
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.537
NEC for r=0.6 class 0.0 = 0.327 +- 0.258 (in-sample avg dev_std = 0.378)
NEC for r=0.6 class 1.0 = 0.285 +- 0.258 (in-sample avg dev_std = 0.378)
NEC for r=0.6 all KL = 0.3 +- 0.258 (in-sample avg dev_std = 0.378)
NEC for r=0.6 all L1 = 0.292 +- 0.216 (in-sample avg dev_std = 0.378)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 11 12:02:03 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/11/2024 12:02:03 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/11/2024 12:02:38 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/11/2024 12:02:49 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/11/2024 12:03:02 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/11/2024 12:03:19 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/11/2024 12:03:37 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/11/2024 12:03:37 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/11/2024 12:03:37 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/11/2024 12:03:37 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/11/2024 12:03:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 12:03:37 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/11/2024 12:03:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 12:03:38 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/11/2024 12:03:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 12:03:38 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/11/2024 12:03:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 12:03:38 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/11/2024 12:03:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 12:03:38 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/11/2024 12:03:38 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 50...
[0m[1;37mINFO[0m: [1mCheckpoint 50: 
-----------------------------------
Train ROC-AUC: 0.9658
Train Loss: 0.1509
ID Validation ROC-AUC: 0.9099
ID Validation Loss: 0.2557
ID Test ROC-AUC: 0.9129
ID Test Loss: 0.2578
OOD Validation ROC-AUC: 0.6398
OOD Validation Loss: 0.4377
OOD Test ROC-AUC: 0.6781
OOD Test Loss: 0.5882

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 13...
[0m[1;37mINFO[0m: [1mCheckpoint 13: 
-----------------------------------
Train ROC-AUC: 0.9221
Train Loss: 0.2152
ID Validation ROC-AUC: 0.8909
ID Validation Loss: 0.2509
ID Test ROC-AUC: 0.8972
ID Test Loss: 0.2480
OOD Validation ROC-AUC: 0.6624
OOD Validation Loss: 0.3222
OOD Test ROC-AUC: 0.7061
OOD Test Loss: 0.4680

[0m[1;37mINFO[0m: [1mChartInfo 0.9129 0.6781 0.8972 0.7061 0.8909 0.6624[0mLBAPcore(11683)
Data example from id_test: Data(x=[33, 39], edge_index=[2, 72], edge_attr=[72, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 72], node_perm=[33])
Label distribution from id_test: (tensor([0., 1.]), tensor([ 1386, 10297]))
[1;34mDEBUG[0m: 05/11/2024 12:03:38 PM : [1mUnbalanced warning for LBAPcore (id_test)
[0mF1 for r=0.6 = nan
WIoU for r=0.6 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 05/11/2024 12:04:10 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.375
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.447
SUFF++ for r=0.6 class 0.0 = 0.735 +- 0.146 (in-sample avg dev_std = 0.357)
SUFF++ for r=0.6 class 1.0 = 0.709 +- 0.146 (in-sample avg dev_std = 0.357)
SUFF++ for r=0.6 all KL = 0.795 +- 0.146 (in-sample avg dev_std = 0.357)
SUFF++ for r=0.6 all L1 = 0.712 +- 0.155 (in-sample avg dev_std = 0.357)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.44
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.474
SUFF++ for r=0.6 class 0.0 = 0.727 +- 0.156 (in-sample avg dev_std = 0.381)
SUFF++ for r=0.6 class 1.0 = 0.694 +- 0.156 (in-sample avg dev_std = 0.381)
SUFF++ for r=0.6 all KL = 0.776 +- 0.156 (in-sample avg dev_std = 0.381)
SUFF++ for r=0.6 all L1 = 0.699 +- 0.156 (in-sample avg dev_std = 0.381)


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.375
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.405
NEC for r=0.6 class 0.0 = 0.252 +- 0.173 (in-sample avg dev_std = 0.327)
NEC for r=0.6 class 1.0 = 0.294 +- 0.173 (in-sample avg dev_std = 0.327)
NEC for r=0.6 all KL = 0.198 +- 0.173 (in-sample avg dev_std = 0.327)
NEC for r=0.6 all L1 = 0.289 +- 0.167 (in-sample avg dev_std = 0.327)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.44
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.432
NEC for r=0.6 class 0.0 = 0.29 +- 0.186 (in-sample avg dev_std = 0.357)
NEC for r=0.6 class 1.0 = 0.316 +- 0.186 (in-sample avg dev_std = 0.357)
NEC for r=0.6 all KL = 0.229 +- 0.186 (in-sample avg dev_std = 0.357)
NEC for r=0.6 all L1 = 0.312 +- 0.173 (in-sample avg dev_std = 0.357)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 11 12:05:38 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/11/2024 12:05:38 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/11/2024 12:06:13 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/11/2024 12:06:25 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/11/2024 12:06:37 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/11/2024 12:06:53 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/11/2024 12:07:12 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/11/2024 12:07:12 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/11/2024 12:07:12 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/11/2024 12:07:12 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/11/2024 12:07:12 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 12:07:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/11/2024 12:07:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 12:07:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/11/2024 12:07:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 12:07:12 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/11/2024 12:07:12 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 12:07:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/11/2024 12:07:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 12:07:12 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/11/2024 12:07:12 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 20...
[0m[1;37mINFO[0m: [1mCheckpoint 20: 
-----------------------------------
Train ROC-AUC: 0.9373
Train Loss: 0.1953
ID Validation ROC-AUC: 0.9097
ID Validation Loss: 0.2289
ID Test ROC-AUC: 0.9081
ID Test Loss: 0.2333
OOD Validation ROC-AUC: 0.6243
OOD Validation Loss: 0.3584
OOD Test ROC-AUC: 0.6758
OOD Test Loss: 0.4758

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 9...
[0m[1;37mINFO[0m: [1mCheckpoint 9: 
-----------------------------------
Train ROC-AUC: 0.9088
Train Loss: 0.2311
ID Validation ROC-AUC: 0.8849
ID Validation Loss: 0.2505
ID Test ROC-AUC: 0.8879
ID Test Loss: 0.2510
OOD Validation ROC-AUC: 0.6619
OOD Validation Loss: 0.3260
OOD Test ROC-AUC: 0.6983
OOD Test Loss: 0.4346

[0m[1;37mINFO[0m: [1mChartInfo 0.9081 0.6758 0.8879 0.6983 0.8849 0.6619[0mLBAPcore(11683)
Data example from id_test: Data(x=[33, 39], edge_index=[2, 72], edge_attr=[72, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 72], node_perm=[33])
Label distribution from id_test: (tensor([0., 1.]), tensor([ 1386, 10297]))
[1;34mDEBUG[0m: 05/11/2024 12:07:12 PM : [1mUnbalanced warning for LBAPcore (id_test)
[0mF1 for r=0.6 = nan
WIoU for r=0.6 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 05/11/2024 12:07:38 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.522
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.51
SUFF++ for r=0.6 class 0.0 = 0.756 +- 0.067 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.6 class 1.0 = 0.76 +- 0.067 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.6 all KL = 0.916 +- 0.067 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.6 all L1 = 0.76 +- 0.086 (in-sample avg dev_std = 0.245)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.494
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.477
SUFF++ for r=0.6 class 0.0 = 0.768 +- 0.072 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.6 class 1.0 = 0.755 +- 0.072 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.6 all KL = 0.915 +- 0.072 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.6 all L1 = 0.757 +- 0.090 (in-sample avg dev_std = 0.241)


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.522
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.484
NEC for r=0.6 class 0.0 = 0.203 +- 0.065 (in-sample avg dev_std = 0.205)
NEC for r=0.6 class 1.0 = 0.212 +- 0.065 (in-sample avg dev_std = 0.205)
NEC for r=0.6 all KL = 0.064 +- 0.065 (in-sample avg dev_std = 0.205)
NEC for r=0.6 all L1 = 0.211 +- 0.092 (in-sample avg dev_std = 0.205)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.494
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.468
NEC for r=0.6 class 0.0 = 0.211 +- 0.071 (in-sample avg dev_std = 0.195)
NEC for r=0.6 class 1.0 = 0.219 +- 0.071 (in-sample avg dev_std = 0.195)
NEC for r=0.6 all KL = 0.068 +- 0.071 (in-sample avg dev_std = 0.195)
NEC for r=0.6 all L1 = 0.217 +- 0.097 (in-sample avg dev_std = 0.195)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 11 12:09:10 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/11/2024 12:09:10 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/11/2024 12:09:48 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/11/2024 12:09:58 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/11/2024 12:10:10 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/11/2024 12:10:29 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/11/2024 12:10:47 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/11/2024 12:10:47 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/11/2024 12:10:47 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/11/2024 12:10:47 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/11/2024 12:10:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 12:10:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/11/2024 12:10:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 12:10:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/11/2024 12:10:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 12:10:47 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/11/2024 12:10:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 12:10:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/11/2024 12:10:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 12:10:47 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/11/2024 12:10:47 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 59...
[0m[1;37mINFO[0m: [1mCheckpoint 59: 
-----------------------------------
Train ROC-AUC: 0.9662
Train Loss: 0.1724
ID Validation ROC-AUC: 0.9138
ID Validation Loss: 0.3123
ID Test ROC-AUC: 0.9111
ID Test Loss: 0.3263
OOD Validation ROC-AUC: 0.5895
OOD Validation Loss: 0.6025
OOD Test ROC-AUC: 0.6681
OOD Test Loss: 0.7747

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 15...
[0m[1;37mINFO[0m: [1mCheckpoint 15: 
-----------------------------------
Train ROC-AUC: 0.9269
Train Loss: 0.2093
ID Validation ROC-AUC: 0.8991
ID Validation Loss: 0.2421
ID Test ROC-AUC: 0.9021
ID Test Loss: 0.2424
OOD Validation ROC-AUC: 0.6642
OOD Validation Loss: 0.3339
OOD Test ROC-AUC: 0.6850
OOD Test Loss: 0.4826

[0m[1;37mINFO[0m: [1mChartInfo 0.9111 0.6681 0.9021 0.6850 0.8991 0.6642[0mLBAPcore(11683)
Data example from id_test: Data(x=[33, 39], edge_index=[2, 72], edge_attr=[72, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 72], node_perm=[33])
Label distribution from id_test: (tensor([0., 1.]), tensor([ 1386, 10297]))
[1;34mDEBUG[0m: 05/11/2024 12:10:47 PM : [1mUnbalanced warning for LBAPcore (id_test)
[0mF1 for r=0.6 = nan
WIoU for r=0.6 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 05/11/2024 12:11:19 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.326
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.4
SUFF++ for r=0.6 class 0.0 = 0.971 +- 0.086 (in-sample avg dev_std = 0.082)
SUFF++ for r=0.6 class 1.0 = 0.982 +- 0.086 (in-sample avg dev_std = 0.082)
SUFF++ for r=0.6 all KL = 0.963 +- 0.086 (in-sample avg dev_std = 0.082)
SUFF++ for r=0.6 all L1 = 0.981 +- 0.046 (in-sample avg dev_std = 0.082)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.405
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.445
SUFF++ for r=0.6 class 0.0 = 0.963 +- 0.112 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.6 class 1.0 = 0.969 +- 0.112 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.6 all KL = 0.949 +- 0.112 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.6 all L1 = 0.968 +- 0.074 (in-sample avg dev_std = 0.118)


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.326
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.393
NEC for r=0.6 class 0.0 = 0.03 +- 0.093 (in-sample avg dev_std = 0.084)
NEC for r=0.6 class 1.0 = 0.02 +- 0.093 (in-sample avg dev_std = 0.084)
NEC for r=0.6 all KL = 0.039 +- 0.093 (in-sample avg dev_std = 0.084)
NEC for r=0.6 all L1 = 0.021 +- 0.052 (in-sample avg dev_std = 0.084)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.405
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.453
NEC for r=0.6 class 0.0 = 0.035 +- 0.123 (in-sample avg dev_std = 0.117)
NEC for r=0.6 class 1.0 = 0.03 +- 0.123 (in-sample avg dev_std = 0.117)
NEC for r=0.6 all KL = 0.048 +- 0.123 (in-sample avg dev_std = 0.117)
NEC for r=0.6 all L1 = 0.031 +- 0.076 (in-sample avg dev_std = 0.117)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 11 12:12:45 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/11/2024 12:12:45 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/11/2024 12:13:22 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/11/2024 12:13:33 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/11/2024 12:13:45 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/11/2024 12:14:01 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/11/2024 12:14:19 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/11/2024 12:14:19 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/11/2024 12:14:19 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/11/2024 12:14:19 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/11/2024 12:14:19 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 12:14:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/11/2024 12:14:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 12:14:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/11/2024 12:14:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 12:14:19 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/11/2024 12:14:19 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 12:14:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/11/2024 12:14:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 12:14:19 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/11/2024 12:14:19 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 51...
[0m[1;37mINFO[0m: [1mCheckpoint 51: 
-----------------------------------
Train ROC-AUC: 0.9661
Train Loss: 0.1473
ID Validation ROC-AUC: 0.9133
ID Validation Loss: 0.2363
ID Test ROC-AUC: 0.9109
ID Test Loss: 0.2418
OOD Validation ROC-AUC: 0.6302
OOD Validation Loss: 0.4522
OOD Test ROC-AUC: 0.6797
OOD Test Loss: 0.5703

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 9...
[0m[1;37mINFO[0m: [1mCheckpoint 9: 
-----------------------------------
Train ROC-AUC: 0.9108
Train Loss: 0.2361
ID Validation ROC-AUC: 0.8892
ID Validation Loss: 0.2523
ID Test ROC-AUC: 0.8864
ID Test Loss: 0.2555
OOD Validation ROC-AUC: 0.6513
OOD Validation Loss: 0.3289
OOD Test ROC-AUC: 0.7073
OOD Test Loss: 0.4218

[0m[1;37mINFO[0m: [1mChartInfo 0.9109 0.6797 0.8864 0.7073 0.8892 0.6513[0mLBAPcore(11683)
Data example from id_test: Data(x=[33, 39], edge_index=[2, 72], edge_attr=[72, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 72], node_perm=[33])
Label distribution from id_test: (tensor([0., 1.]), tensor([ 1386, 10297]))
[1;34mDEBUG[0m: 05/11/2024 12:14:19 PM : [1mUnbalanced warning for LBAPcore (id_test)
[0mF1 for r=0.6 = nan
WIoU for r=0.6 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 05/11/2024 12:14:50 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.703
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.654
SUFF++ for r=0.6 class 0.0 = 0.954 +- 0.123 (in-sample avg dev_std = 0.099)
SUFF++ for r=0.6 class 1.0 = 0.993 +- 0.123 (in-sample avg dev_std = 0.099)
SUFF++ for r=0.6 all KL = 0.967 +- 0.123 (in-sample avg dev_std = 0.099)
SUFF++ for r=0.6 all L1 = 0.988 +- 0.051 (in-sample avg dev_std = 0.099)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.607
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.571
SUFF++ for r=0.6 class 0.0 = 0.978 +- 0.120 (in-sample avg dev_std = 0.090)
SUFF++ for r=0.6 class 1.0 = 0.99 +- 0.120 (in-sample avg dev_std = 0.090)
SUFF++ for r=0.6 all KL = 0.967 +- 0.120 (in-sample avg dev_std = 0.090)
SUFF++ for r=0.6 all L1 = 0.988 +- 0.046 (in-sample avg dev_std = 0.090)


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.703
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.706
NEC for r=0.6 class 0.0 = 0.046 +- 0.127 (in-sample avg dev_std = 0.096)
NEC for r=0.6 class 1.0 = 0.01 +- 0.127 (in-sample avg dev_std = 0.096)
NEC for r=0.6 all KL = 0.042 +- 0.127 (in-sample avg dev_std = 0.096)
NEC for r=0.6 all L1 = 0.014 +- 0.053 (in-sample avg dev_std = 0.096)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.607
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.592
NEC for r=0.6 class 0.0 = 0.037 +- 0.174 (in-sample avg dev_std = 0.134)
NEC for r=0.6 class 1.0 = 0.019 +- 0.174 (in-sample avg dev_std = 0.134)
NEC for r=0.6 all KL = 0.062 +- 0.174 (in-sample avg dev_std = 0.134)
NEC for r=0.6 all L1 = 0.022 +- 0.070 (in-sample avg dev_std = 0.134)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.501], 'all_L1': [0.634]}), defaultdict(<class 'list'>, {'all_KL': [0.795], 'all_L1': [0.712]}), defaultdict(<class 'list'>, {'all_KL': [0.916], 'all_L1': [0.76]}), defaultdict(<class 'list'>, {'all_KL': [0.963], 'all_L1': [0.981]}), defaultdict(<class 'list'>, {'all_KL': [0.967], 'all_L1': [0.988]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.275], 'all_L1': [0.245]}), defaultdict(<class 'list'>, {'all_KL': [0.198], 'all_L1': [0.289]}), defaultdict(<class 'list'>, {'all_KL': [0.064], 'all_L1': [0.211]}), defaultdict(<class 'list'>, {'all_KL': [0.039], 'all_L1': [0.021]}), defaultdict(<class 'list'>, {'all_KL': [0.042], 'all_L1': [0.014]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.54], 'all_L1': [0.625]}), defaultdict(<class 'list'>, {'all_KL': [0.776], 'all_L1': [0.699]}), defaultdict(<class 'list'>, {'all_KL': [0.915], 'all_L1': [0.757]}), defaultdict(<class 'list'>, {'all_KL': [0.949], 'all_L1': [0.968]}), defaultdict(<class 'list'>, {'all_KL': [0.967], 'all_L1': [0.988]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.3], 'all_L1': [0.292]}), defaultdict(<class 'list'>, {'all_KL': [0.229], 'all_L1': [0.312]}), defaultdict(<class 'list'>, {'all_KL': [0.068], 'all_L1': [0.217]}), defaultdict(<class 'list'>, {'all_KL': [0.048], 'all_L1': [0.031]}), defaultdict(<class 'list'>, {'all_KL': [0.062], 'all_L1': [0.022]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_test
suff++ class all_L1  =  0.815 +- 0.144
suff++ class all_KL  =  0.828 +- 0.175
suff++_acc_int  =  0.520 +- 0.092
nec class all_L1  =  0.156 +- 0.116
nec class all_KL  =  0.124 +- 0.096
nec_acc_int  =  0.521 +- 0.123

Eval split test
suff++ class all_L1  =  0.807 +- 0.146
suff++ class all_KL  =  0.829 +- 0.159
suff++_acc_int  =  0.500 +- 0.045
nec class all_L1  =  0.175 +- 0.125
nec class all_KL  =  0.141 +- 0.103
nec_acc_int  =  0.497 +- 0.059


 -------------------------------------------------- 
Computing faithfulness

Eval split id_test
Faith. Aritm (L1)= 		  =  0.486 +- 0.024
Faith. Armon (L1)= 		  =  0.233 +- 0.164
Faith. GMean (L1)= 	  =  0.302 +- 0.142
Faith. Aritm (KL)= 		  =  0.476 +- 0.044
Faith. Armon (KL)= 		  =  0.189 +- 0.121
Faith. GMean (KL)= 	  =  0.281 +- 0.086

Eval split test
Faith. Aritm (L1)= 		  =  0.491 +- 0.018
Faith. Armon (L1)= 		  =  0.254 +- 0.168
Faith. GMean (L1)= 	  =  0.324 +- 0.135
Faith. Aritm (KL)= 		  =  0.485 +- 0.034
Faith. Armon (KL)= 		  =  0.215 +- 0.127
Faith. GMean (KL)= 	  =  0.306 +- 0.087
Computed for split load_split = id



Completed in  0:17:56.899877  for CIGAGIN LBAPcore/assay



DONE CIGA LBAPcore/assay nov

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 11 12:16:37 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/11/2024 12:16:38 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/11/2024 12:16:38 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/11/2024 12:16:38 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/11/2024 12:16:38 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/11/2024 12:16:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 12:16:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 12:16:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 12:16:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 12:16:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 12:16:38 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/11/2024 12:16:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 12:16:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 12:16:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 12:16:38 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/11/2024 12:16:38 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 163...
[0m[1;37mINFO[0m: [1mCheckpoint 163: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0753
ID Validation ACCURACY: 0.8595
ID Validation Loss: 0.7797
ID Test ACCURACY: 0.8602
ID Test Loss: 0.8691
OOD Validation ACCURACY: 0.8551
OOD Validation Loss: 1.0470
OOD Test ACCURACY: 0.8144
OOD Test Loss: 1.2121

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 118...
[0m[1;37mINFO[0m: [1mCheckpoint 118: 
-----------------------------------
Train ACCURACY: 0.9463
Train Loss: 0.0867
ID Validation ACCURACY: 0.8510
ID Validation Loss: 0.5780
ID Test ACCURACY: 0.8459
ID Test Loss: 0.6869
OOD Validation ACCURACY: 0.8562
OOD Validation Loss: 0.6896
OOD Test ACCURACY: 0.8071
OOD Test Loss: 0.8209

[0m[1;37mINFO[0m: [1mChartInfo 0.8602 0.8144 0.8459 0.8071 0.8510 0.8562[0mGOODSST2(5301)
Data example from id_test: Data(x=[5, 768], edge_index=[2, 8], y=[1, 1], idx=[1], sentence_tokens=[5], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_test: (tensor([0., 1.]), tensor([2181, 3120]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.8 = nan
WIoU for r=0.8 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.8 = nan
WIoU for r=0.8 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.8


[1;31mERROR[0m: 05/11/2024 12:16:49 PM - utils.py - line 87 : [1mTraceback (most recent call last):
  File "/mnt/cimec-storage6/users/steve.azzolin/venv/leci/bin/goodtg", line 33, in <module>
    sys.exit(load_entry_point('graph-ood', 'console_scripts', 'goodtg')())
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/kernel/main.py", line 636, in goodtg
    main()
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/kernel/main.py", line 536, in main
    evaluate_metric(args)
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/kernel/main.py", line 331, in evaluate_metric
    score, acc_int, results = pipeline.compute_metric_ratio(
  File "/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/kernel/pipelines/basic_pipeline.py", line 879, in compute_metric_ratio
    causal_subgraphs_r[ratio][j],
IndexError: list index out of range
[0mTime to compute metrics!
The PID of this script is: 1730269

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 11 13:24:25 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/11/2024 01:24:25 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/11/2024 01:24:25 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/11/2024 01:24:25 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/11/2024 01:24:25 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/11/2024 01:24:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 01:24:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 01:24:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 01:24:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 01:24:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 01:24:25 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/11/2024 01:24:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 01:24:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 01:24:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 01:24:25 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/11/2024 01:24:25 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 111...
[0m[1;37mINFO[0m: [1mCheckpoint 111: 
-----------------------------------
Train ACCURACY: 0.9205
Train Loss: 0.3805
ID Validation ACCURACY: 0.9270
ID Validation Loss: 0.3724
ID Test ACCURACY: 0.9183
ID Test Loss: 0.4140
OOD Validation ACCURACY: 0.8453
OOD Validation Loss: 0.4964
OOD Test ACCURACY: 0.4087
OOD Test Loss: 18.3446

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 50...
[0m[1;37mINFO[0m: [1mCheckpoint 50: 
-----------------------------------
Train ACCURACY: 0.8979
Train Loss: 0.4880
ID Validation ACCURACY: 0.9050
ID Validation Loss: 0.4614
ID Test ACCURACY: 0.8947
ID Test Loss: 0.5226
OOD Validation ACCURACY: 0.9203
OOD Validation Loss: 0.3953
OOD Test ACCURACY: 0.4087
OOD Test Loss: 28.2468

[0m[1;37mINFO[0m: [1mChartInfo 0.9183 0.4087 0.8947 0.4087 0.9050 0.9203[0mGOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.8 = 0.363
WIoU for r=0.8 = 0.248


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.404
Model XAI F1 of binarized graphs for r=0.8 =  0.3625387499999999
Model XAI WIoU of binarized graphs for r=0.8 =  0.2476175
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.417
SUFF++ for r=0.8 class 0 = 0.84 +- 0.341 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.8 class 1 = 0.724 +- 0.341 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.8 class 2 = 0.979 +- 0.341 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.8 all KL = 0.821 +- 0.341 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.8 all L1 = 0.847 +- 0.285 (in-sample avg dev_std = 0.323)


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.404
Model XAI F1 of binarized graphs for r=0.8 =  0.3625387499999999
Model XAI WIoU of binarized graphs for r=0.8 =  0.2476175
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.389
NEC for r=0.8 class 0 = 0.256 +- 0.423 (in-sample avg dev_std = 0.453)
NEC for r=0.8 class 1 = 0.177 +- 0.423 (in-sample avg dev_std = 0.453)
NEC for r=0.8 class 2 = 0.16 +- 0.423 (in-sample avg dev_std = 0.453)
NEC for r=0.8 all KL = 0.339 +- 0.423 (in-sample avg dev_std = 0.453)
NEC for r=0.8 all L1 = 0.197 +- 0.275 (in-sample avg dev_std = 0.453)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 11 13:25:01 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/11/2024 01:25:01 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/11/2024 01:25:01 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/11/2024 01:25:01 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/11/2024 01:25:01 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/11/2024 01:25:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 01:25:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 01:25:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 01:25:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 01:25:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 01:25:01 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/11/2024 01:25:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 01:25:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 01:25:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 01:25:01 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/11/2024 01:25:01 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 29...
[0m[1;37mINFO[0m: [1mCheckpoint 29: 
-----------------------------------
Train ACCURACY: 0.9219
Train Loss: 0.4585
ID Validation ACCURACY: 0.9277
ID Validation Loss: 0.4446
ID Test ACCURACY: 0.9153
ID Test Loss: 0.5136
OOD Validation ACCURACY: 0.9030
OOD Validation Loss: 0.4462
OOD Test ACCURACY: 0.4087
OOD Test Loss: 12.6375

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 51...
[0m[1;37mINFO[0m: [1mCheckpoint 51: 
-----------------------------------
Train ACCURACY: 0.9233
Train Loss: 0.4108
ID Validation ACCURACY: 0.9277
ID Validation Loss: 0.3921
ID Test ACCURACY: 0.9180
ID Test Loss: 0.4568
OOD Validation ACCURACY: 0.9187
OOD Validation Loss: 0.3832
OOD Test ACCURACY: 0.4087
OOD Test Loss: 14.2353

[0m[1;37mINFO[0m: [1mChartInfo 0.9153 0.4087 0.9180 0.4087 0.9277 0.9187[0mGOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.8 = 0.412
WIoU for r=0.8 = 0.309


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.404
Model XAI F1 of binarized graphs for r=0.8 =  0.4124387499999999
Model XAI WIoU of binarized graphs for r=0.8 =  0.30873625
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.393
SUFF++ for r=0.8 class 0 = 0.858 +- 0.200 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.8 class 1 = 0.913 +- 0.200 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.8 class 2 = 0.944 +- 0.200 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.8 all KL = 0.89 +- 0.200 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.8 all L1 = 0.906 +- 0.168 (in-sample avg dev_std = 0.187)


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.404
Model XAI F1 of binarized graphs for r=0.8 =  0.4124387499999999
Model XAI WIoU of binarized graphs for r=0.8 =  0.30873625
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.393
NEC for r=0.8 class 0 = 0.326 +- 0.398 (in-sample avg dev_std = 0.545)
NEC for r=0.8 class 1 = 0.362 +- 0.398 (in-sample avg dev_std = 0.545)
NEC for r=0.8 class 2 = 0.212 +- 0.398 (in-sample avg dev_std = 0.545)
NEC for r=0.8 all KL = 0.592 +- 0.398 (in-sample avg dev_std = 0.545)
NEC for r=0.8 all L1 = 0.3 +- 0.271 (in-sample avg dev_std = 0.545)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 11 13:25:33 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/11/2024 01:25:33 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/11/2024 01:25:33 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/11/2024 01:25:33 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/11/2024 01:25:33 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/11/2024 01:25:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 01:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 01:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 01:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 01:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 01:25:33 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/11/2024 01:25:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 01:25:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 01:25:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 01:25:33 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/11/2024 01:25:33 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 28...
[0m[1;37mINFO[0m: [1mCheckpoint 28: 
-----------------------------------
Train ACCURACY: 0.8898
Train Loss: 0.5536
ID Validation ACCURACY: 0.9003
ID Validation Loss: 0.5339
ID Test ACCURACY: 0.8880
ID Test Loss: 0.5790
OOD Validation ACCURACY: 0.8117
OOD Validation Loss: 0.5655
OOD Test ACCURACY: 0.4087
OOD Test Loss: 19.5623

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 144...
[0m[1;37mINFO[0m: [1mCheckpoint 144: 
-----------------------------------
Train ACCURACY: 0.8036
Train Loss: 0.5833
ID Validation ACCURACY: 0.8053
ID Validation Loss: 0.5878
ID Test ACCURACY: 0.7930
ID Test Loss: 0.6074
OOD Validation ACCURACY: 0.8780
OOD Validation Loss: 0.4487
OOD Test ACCURACY: 0.4087
OOD Test Loss: 16.8359

[0m[1;37mINFO[0m: [1mChartInfo 0.8880 0.4087 0.7930 0.4087 0.8053 0.8780[0mGOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.8 = 0.325
WIoU for r=0.8 = 0.221


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.404
Model XAI F1 of binarized graphs for r=0.8 =  0.32493125
Model XAI WIoU of binarized graphs for r=0.8 =  0.22100499999999998
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.404
SUFF++ for r=0.8 class 0 = 0.863 +- 0.321 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.8 class 1 = 0.698 +- 0.321 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.8 class 2 = 0.983 +- 0.321 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.8 all KL = 0.841 +- 0.321 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.8 all L1 = 0.846 +- 0.292 (in-sample avg dev_std = 0.248)


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.404
Model XAI F1 of binarized graphs for r=0.8 =  0.32493125
Model XAI WIoU of binarized graphs for r=0.8 =  0.22100499999999998
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.348
NEC for r=0.8 class 0 = 0.275 +- 0.442 (in-sample avg dev_std = 0.414)
NEC for r=0.8 class 1 = 0.193 +- 0.442 (in-sample avg dev_std = 0.414)
NEC for r=0.8 class 2 = 0.196 +- 0.442 (in-sample avg dev_std = 0.414)
NEC for r=0.8 all KL = 0.381 +- 0.442 (in-sample avg dev_std = 0.414)
NEC for r=0.8 all L1 = 0.22 +- 0.295 (in-sample avg dev_std = 0.414)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 11 13:26:06 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/11/2024 01:26:06 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/11/2024 01:26:06 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/11/2024 01:26:06 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/11/2024 01:26:06 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/11/2024 01:26:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 01:26:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 01:26:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 01:26:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 01:26:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 01:26:06 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/11/2024 01:26:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 01:26:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 01:26:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 01:26:06 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/11/2024 01:26:06 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 33...
[0m[1;37mINFO[0m: [1mCheckpoint 33: 
-----------------------------------
Train ACCURACY: 0.9238
Train Loss: 0.4617
ID Validation ACCURACY: 0.9273
ID Validation Loss: 0.4236
ID Test ACCURACY: 0.9190
ID Test Loss: 0.4980
OOD Validation ACCURACY: 0.9040
OOD Validation Loss: 0.4178
OOD Test ACCURACY: 0.4087
OOD Test Loss: 18.1921

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 27...
[0m[1;37mINFO[0m: [1mCheckpoint 27: 
-----------------------------------
Train ACCURACY: 0.9162
Train Loss: 0.4235
ID Validation ACCURACY: 0.9237
ID Validation Loss: 0.3927
ID Test ACCURACY: 0.9133
ID Test Loss: 0.4441
OOD Validation ACCURACY: 0.9150
OOD Validation Loss: 0.3759
OOD Test ACCURACY: 0.6387
OOD Test Loss: 3.0586

[0m[1;37mINFO[0m: [1mChartInfo 0.9190 0.4087 0.9133 0.6387 0.9237 0.9150[0mGOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.8 = 0.415
WIoU for r=0.8 = 0.279


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.405
Model XAI F1 of binarized graphs for r=0.8 =  0.4146775
Model XAI WIoU of binarized graphs for r=0.8 =  0.27916124999999997
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.379
SUFF++ for r=0.8 class 0 = 0.824 +- 0.287 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.8 class 1 = 0.892 +- 0.287 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.8 class 2 = 0.889 +- 0.287 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.8 all KL = 0.825 +- 0.287 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.8 all L1 = 0.869 +- 0.197 (in-sample avg dev_std = 0.297)


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.405
Model XAI F1 of binarized graphs for r=0.8 =  0.4146775
Model XAI WIoU of binarized graphs for r=0.8 =  0.27916124999999997
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.391
NEC for r=0.8 class 0 = 0.265 +- 0.436 (in-sample avg dev_std = 0.515)
NEC for r=0.8 class 1 = 0.276 +- 0.436 (in-sample avg dev_std = 0.515)
NEC for r=0.8 class 2 = 0.213 +- 0.436 (in-sample avg dev_std = 0.515)
NEC for r=0.8 all KL = 0.471 +- 0.436 (in-sample avg dev_std = 0.515)
NEC for r=0.8 all L1 = 0.251 +- 0.280 (in-sample avg dev_std = 0.515)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 11 13:26:45 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/11/2024 01:26:45 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/11/2024 01:26:45 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/11/2024 01:26:45 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/11/2024 01:26:45 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/11/2024 01:26:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 01:26:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 01:26:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 01:26:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 01:26:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 01:26:45 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/11/2024 01:26:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 01:26:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 01:26:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 01:26:45 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/11/2024 01:26:45 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 62...
[0m[1;37mINFO[0m: [1mCheckpoint 62: 
-----------------------------------
Train ACCURACY: 0.9232
Train Loss: 0.4686
ID Validation ACCURACY: 0.9290
ID Validation Loss: 0.4482
ID Test ACCURACY: 0.9190
ID Test Loss: 0.5270
OOD Validation ACCURACY: 0.9023
OOD Validation Loss: 0.4335
OOD Test ACCURACY: 0.4097
OOD Test Loss: 11.4881

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 112...
[0m[1;37mINFO[0m: [1mCheckpoint 112: 
-----------------------------------
Train ACCURACY: 0.9212
Train Loss: 0.4121
ID Validation ACCURACY: 0.9280
ID Validation Loss: 0.3988
ID Test ACCURACY: 0.9170
ID Test Loss: 0.4630
OOD Validation ACCURACY: 0.9170
OOD Validation Loss: 0.3851
OOD Test ACCURACY: 0.4087
OOD Test Loss: 36.3874

[0m[1;37mINFO[0m: [1mChartInfo 0.9190 0.4097 0.9170 0.4087 0.9280 0.9170[0mGOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.8 = 0.338
WIoU for r=0.8 = 0.261


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.405
Model XAI F1 of binarized graphs for r=0.8 =  0.33816874999999996
Model XAI WIoU of binarized graphs for r=0.8 =  0.260725
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.398
SUFF++ for r=0.8 class 0 = 0.843 +- 0.361 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.8 class 1 = 0.761 +- 0.361 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.8 class 2 = 0.885 +- 0.361 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.8 all KL = 0.689 +- 0.361 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.8 all L1 = 0.829 +- 0.196 (in-sample avg dev_std = 0.401)


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.405
Model XAI F1 of binarized graphs for r=0.8 =  0.33816874999999996
Model XAI WIoU of binarized graphs for r=0.8 =  0.260725
len(reference) = 800
Effective ratio: 0.806 +- 0.006
Model Accuracy over intervened graphs for r=0.8 =  0.451
NEC for r=0.8 class 0 = 0.325 +- 0.411 (in-sample avg dev_std = 0.514)
NEC for r=0.8 class 1 = 0.313 +- 0.411 (in-sample avg dev_std = 0.514)
NEC for r=0.8 class 2 = 0.206 +- 0.411 (in-sample avg dev_std = 0.514)
NEC for r=0.8 all KL = 0.527 +- 0.411 (in-sample avg dev_std = 0.514)
NEC for r=0.8 all L1 = 0.281 +- 0.280 (in-sample avg dev_std = 0.514)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.821], 'all_L1': [0.847]}), defaultdict(<class 'list'>, {'all_KL': [0.89], 'all_L1': [0.906]}), defaultdict(<class 'list'>, {'all_KL': [0.841], 'all_L1': [0.846]}), defaultdict(<class 'list'>, {'all_KL': [0.825], 'all_L1': [0.869]}), defaultdict(<class 'list'>, {'all_KL': [0.689], 'all_L1': [0.829]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.339], 'all_L1': [0.197]}), defaultdict(<class 'list'>, {'all_KL': [0.592], 'all_L1': [0.3]}), defaultdict(<class 'list'>, {'all_KL': [0.381], 'all_L1': [0.22]}), defaultdict(<class 'list'>, {'all_KL': [0.471], 'all_L1': [0.251]}), defaultdict(<class 'list'>, {'all_KL': [0.527], 'all_L1': [0.281]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split test
suff++ class all_L1  =  0.859 +- 0.027
suff++ class all_KL  =  0.813 +- 0.067
suff++_acc_int  =  0.398 +- 0.013
nec class all_L1  =  0.250 +- 0.038
nec class all_KL  =  0.462 +- 0.093
nec_acc_int  =  0.394 +- 0.033


 -------------------------------------------------- 
Computing faithfulness

Eval split test
Faith. Aritm (L1)= 		  =  0.555 +- 0.028
Faith. Armon (L1)= 		  =  0.386 +- 0.047
Faith. GMean (L1)= 	  =  0.462 +- 0.039
Faith. Aritm (KL)= 		  =  0.638 +- 0.056
Faith. Armon (KL)= 		  =  0.582 +- 0.079
Faith. GMean (KL)= 	  =  0.609 +- 0.067
Computed for split load_split = id



Completed in  0:02:54.658415  for CIGAGIN GOODMotif2/basis



DONE CIGA GOODMotif2/basis nov

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 11 13:27:32 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 05/11/2024 01:27:33 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 01:27:33 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 01:27:33 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 01:27:33 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 01:27:33 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 01:27:33 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/11/2024 01:27:33 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/11/2024 01:27:33 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/11/2024 01:27:33 PM : [1mCreating GINFeatExtractor:  5
[0m[1;34mDEBUG[0m: 05/11/2024 01:27:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 01:27:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 01:27:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 01:27:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 01:27:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 01:27:33 PM : [1mUsing  3  layers for classifier
[0m[1;34mDEBUG[0m: 05/11/2024 01:27:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 01:27:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 01:27:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 01:27:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 01:27:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 01:27:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 01:27:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 01:27:33 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/11/2024 01:27:33 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 90...
[0m[1;37mINFO[0m: [1mCheckpoint 90: 
-----------------------------------
Train ACCURACY: 0.2997
Train Loss: 3.3387
ID Validation ACCURACY: 0.2909
ID Validation Loss: 3.4073
ID Test ACCURACY: 0.2920
ID Test Loss: 3.3954
OOD Validation ACCURACY: 0.2336
OOD Validation Loss: 5.2601
OOD Test ACCURACY: 0.1400
OOD Test Loss: 6.1619

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 90...
[0m[1;37mINFO[0m: [1mCheckpoint 90: 
-----------------------------------
Train ACCURACY: 0.2997
Train Loss: 3.3387
ID Validation ACCURACY: 0.2909
ID Validation Loss: 3.4073
ID Test ACCURACY: 0.2920
ID Test Loss: 3.3954
OOD Validation ACCURACY: 0.2336
OOD Validation Loss: 5.2601
OOD Test ACCURACY: 0.1400
OOD Test Loss: 6.1619

[0m[1;37mINFO[0m: [1mChartInfo 0.2920 0.1400 0.2920 0.1400 0.2909 0.2336[0mGOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.6


big2.sh: line 9: 1730748 Killed                  goodtg --config_path final_configs/${DATASET}/covariate/${MODEL}.yaml --seeds "1/2/3/4/5" --task eval_metric --metrics "suff++/nec" --splits "test" --average_edge_attn mean --mitigation_sampling feat --model_name CIGAGIN --gpu_idx 1 --mask --debias --samplingtype deconfounded --nec_number_samples prop_G_dataset --save_metrics --log_id suff++_old_novonly
Time to compute metrics!
The PID of this script is: 1731052

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 11 13:29:16 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/11/2024 01:29:17 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/11/2024 01:29:17 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/11/2024 01:29:17 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/11/2024 01:29:17 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/11/2024 01:29:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 01:29:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 01:29:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 01:29:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 01:29:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 01:29:17 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/11/2024 01:29:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 01:29:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 01:29:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 01:29:17 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/11/2024 01:29:17 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 163...
[0m[1;37mINFO[0m: [1mCheckpoint 163: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0753
ID Validation ACCURACY: 0.8595
ID Validation Loss: 0.7797
ID Test ACCURACY: 0.8602
ID Test Loss: 0.8691
OOD Validation ACCURACY: 0.8551
OOD Validation Loss: 1.0470
OOD Test ACCURACY: 0.8144
OOD Test Loss: 1.2121

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 118...
[0m[1;37mINFO[0m: [1mCheckpoint 118: 
-----------------------------------
Train ACCURACY: 0.9463
Train Loss: 0.0867
ID Validation ACCURACY: 0.8510
ID Validation Loss: 0.5780
ID Test ACCURACY: 0.8459
ID Test Loss: 0.6869
OOD Validation ACCURACY: 0.8562
OOD Validation Loss: 0.6896
OOD Test ACCURACY: 0.8071
OOD Test Loss: 0.8209

[0m[1;37mINFO[0m: [1mChartInfo 0.8602 0.8144 0.8459 0.8071 0.8510 0.8562[0mGOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.8 = nan
WIoU for r=0.8 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.822
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.810 +- 0.008
Model Accuracy over intervened graphs for r=0.8 =  0.797
SUFF++ for r=0.8 class 0.0 = 0.895 +- 0.210 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.8 class 1.0 = 0.879 +- 0.210 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.8 all KL = 0.87 +- 0.210 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.8 all L1 = 0.886 +- 0.180 (in-sample avg dev_std = 0.267)


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.822
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.810 +- 0.008
Model Accuracy over intervened graphs for r=0.8 =  0.809
NEC for r=0.8 class 0.0 = 0.087 +- 0.192 (in-sample avg dev_std = 0.210)
NEC for r=0.8 class 1.0 = 0.102 +- 0.192 (in-sample avg dev_std = 0.210)
NEC for r=0.8 all KL = 0.096 +- 0.192 (in-sample avg dev_std = 0.210)
NEC for r=0.8 all L1 = 0.095 +- 0.174 (in-sample avg dev_std = 0.210)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 11 13:30:02 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/11/2024 01:30:03 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/11/2024 01:30:03 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/11/2024 01:30:03 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/11/2024 01:30:03 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/11/2024 01:30:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 01:30:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 01:30:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 01:30:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 01:30:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 01:30:03 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/11/2024 01:30:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 01:30:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 01:30:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 01:30:03 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/11/2024 01:30:04 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 181...
[0m[1;37mINFO[0m: [1mCheckpoint 181: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0750
ID Validation ACCURACY: 0.8589
ID Validation Loss: 1.0551
ID Test ACCURACY: 0.8568
ID Test Loss: 1.1414
OOD Validation ACCURACY: 0.8585
OOD Validation Loss: 1.4193
OOD Test ACCURACY: 0.8148
OOD Test Loss: 1.5478

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 181...
[0m[1;37mINFO[0m: [1mCheckpoint 181: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0750
ID Validation ACCURACY: 0.8589
ID Validation Loss: 1.0551
ID Test ACCURACY: 0.8568
ID Test Loss: 1.1414
OOD Validation ACCURACY: 0.8585
OOD Validation Loss: 1.4193
OOD Test ACCURACY: 0.8148
OOD Test Loss: 1.5478

[0m[1;37mINFO[0m: [1mChartInfo 0.8568 0.8148 0.8568 0.8148 0.8589 0.8585[0mGOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.8 = nan
WIoU for r=0.8 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.831
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.810 +- 0.008
Model Accuracy over intervened graphs for r=0.8 =  0.809
SUFF++ for r=0.8 class 0.0 = 0.926 +- 0.205 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.8 class 1.0 = 0.889 +- 0.205 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.8 all KL = 0.891 +- 0.205 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.8 all L1 = 0.907 +- 0.174 (in-sample avg dev_std = 0.250)


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.831
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.810 +- 0.008
Model Accuracy over intervened graphs for r=0.8 =  0.825
NEC for r=0.8 class 0.0 = 0.075 +- 0.205 (in-sample avg dev_std = 0.216)
NEC for r=0.8 class 1.0 = 0.096 +- 0.205 (in-sample avg dev_std = 0.216)
NEC for r=0.8 all KL = 0.094 +- 0.205 (in-sample avg dev_std = 0.216)
NEC for r=0.8 all L1 = 0.086 +- 0.172 (in-sample avg dev_std = 0.216)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 11 13:30:47 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/11/2024 01:30:49 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/11/2024 01:30:49 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/11/2024 01:30:49 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/11/2024 01:30:49 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/11/2024 01:30:49 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 01:30:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 01:30:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 01:30:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 01:30:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 01:30:49 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/11/2024 01:30:49 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 01:30:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 01:30:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 01:30:49 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/11/2024 01:30:49 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 140...
[0m[1;37mINFO[0m: [1mCheckpoint 140: 
-----------------------------------
Train ACCURACY: 0.9486
Train Loss: 0.0789
ID Validation ACCURACY: 0.8576
ID Validation Loss: 0.6405
ID Test ACCURACY: 0.8581
ID Test Loss: 0.6827
OOD Validation ACCURACY: 0.8483
OOD Validation Loss: 0.8788
OOD Test ACCURACY: 0.7888
OOD Test Loss: 1.2864

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 60...
[0m[1;37mINFO[0m: [1mCheckpoint 60: 
-----------------------------------
Train ACCURACY: 0.9444
Train Loss: 0.0955
ID Validation ACCURACY: 0.8453
ID Validation Loss: 0.4763
ID Test ACCURACY: 0.8466
ID Test Loss: 0.5186
OOD Validation ACCURACY: 0.8569
OOD Validation Loss: 0.5734
OOD Test ACCURACY: 0.7985
OOD Test Loss: 0.8428

[0m[1;37mINFO[0m: [1mChartInfo 0.8581 0.7888 0.8466 0.7985 0.8453 0.8569[0mGOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.8 = nan
WIoU for r=0.8 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.805
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.810 +- 0.008
Model Accuracy over intervened graphs for r=0.8 =  0.774
SUFF++ for r=0.8 class 0.0 = 0.786 +- 0.235 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.8 class 1.0 = 0.934 +- 0.235 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.8 all KL = 0.842 +- 0.235 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.8 all L1 = 0.862 +- 0.193 (in-sample avg dev_std = 0.287)


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.805
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.810 +- 0.008
Model Accuracy over intervened graphs for r=0.8 =  0.796
NEC for r=0.8 class 0.0 = 0.14 +- 0.160 (in-sample avg dev_std = 0.180)
NEC for r=0.8 class 1.0 = 0.053 +- 0.160 (in-sample avg dev_std = 0.180)
NEC for r=0.8 all KL = 0.082 +- 0.160 (in-sample avg dev_std = 0.180)
NEC for r=0.8 all L1 = 0.095 +- 0.165 (in-sample avg dev_std = 0.180)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 11 13:31:36 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/11/2024 01:31:38 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/11/2024 01:31:38 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/11/2024 01:31:38 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/11/2024 01:31:38 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/11/2024 01:31:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 01:31:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 01:31:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 01:31:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 01:31:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 01:31:38 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/11/2024 01:31:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 01:31:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 01:31:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 01:31:38 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/11/2024 01:31:38 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 180...
[0m[1;37mINFO[0m: [1mCheckpoint 180: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0751
ID Validation ACCURACY: 0.8555
ID Validation Loss: 1.0889
ID Test ACCURACY: 0.8591
ID Test Loss: 1.1779
OOD Validation ACCURACY: 0.8291
OOD Validation Loss: 1.8486
OOD Test ACCURACY: 0.7282
OOD Test Loss: 3.5316

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 109...
[0m[1;37mINFO[0m: [1mCheckpoint 109: 
-----------------------------------
Train ACCURACY: 0.9418
Train Loss: 0.0951
ID Validation ACCURACY: 0.8398
ID Validation Loss: 0.7123
ID Test ACCURACY: 0.8421
ID Test Loss: 0.8161
OOD Validation ACCURACY: 0.8581
OOD Validation Loss: 0.8140
OOD Test ACCURACY: 0.8226
OOD Test Loss: 0.9192

[0m[1;37mINFO[0m: [1mChartInfo 0.8591 0.7282 0.8421 0.8226 0.8398 0.8581[0mGOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.8 = nan
WIoU for r=0.8 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.735
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.810 +- 0.008
Model Accuracy over intervened graphs for r=0.8 =  0.7
SUFF++ for r=0.8 class 0.0 = 0.813 +- 0.260 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.8 class 1.0 = 0.977 +- 0.260 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.8 all KL = 0.86 +- 0.260 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.8 all L1 = 0.898 +- 0.191 (in-sample avg dev_std = 0.284)


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.735
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.810 +- 0.008
Model Accuracy over intervened graphs for r=0.8 =  0.735
NEC for r=0.8 class 0.0 = 0.143 +- 0.213 (in-sample avg dev_std = 0.218)
NEC for r=0.8 class 1.0 = 0.024 +- 0.213 (in-sample avg dev_std = 0.218)
NEC for r=0.8 all KL = 0.091 +- 0.213 (in-sample avg dev_std = 0.218)
NEC for r=0.8 all L1 = 0.082 +- 0.179 (in-sample avg dev_std = 0.218)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 11 13:32:26 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/11/2024 01:32:27 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/11/2024 01:32:27 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/11/2024 01:32:27 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/11/2024 01:32:27 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/11/2024 01:32:27 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 01:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 01:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 01:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 01:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 01:32:27 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/11/2024 01:32:27 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 01:32:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 01:32:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 01:32:27 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/11/2024 01:32:27 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 186...
[0m[1;37mINFO[0m: [1mCheckpoint 186: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0750
ID Validation ACCURACY: 0.8600
ID Validation Loss: 0.9380
ID Test ACCURACY: 0.8612
ID Test Loss: 1.0013
OOD Validation ACCURACY: 0.8654
OOD Validation Loss: 1.0363
OOD Test ACCURACY: 0.8221
OOD Test Loss: 1.1633

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 186...
[0m[1;37mINFO[0m: [1mCheckpoint 186: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0750
ID Validation ACCURACY: 0.8600
ID Validation Loss: 0.9380
ID Test ACCURACY: 0.8612
ID Test Loss: 1.0013
OOD Validation ACCURACY: 0.8654
OOD Validation Loss: 1.0363
OOD Test ACCURACY: 0.8221
OOD Test Loss: 1.1633

[0m[1;37mINFO[0m: [1mChartInfo 0.8612 0.8221 0.8612 0.8221 0.8600 0.8654[0mGOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.8 = nan
WIoU for r=0.8 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.832
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.810 +- 0.008
Model Accuracy over intervened graphs for r=0.8 =  0.817
SUFF++ for r=0.8 class 0.0 = 0.893 +- 0.236 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.8 class 1.0 = 0.89 +- 0.236 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.8 all KL = 0.857 +- 0.236 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.8 all L1 = 0.892 +- 0.184 (in-sample avg dev_std = 0.289)


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.832
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.810 +- 0.008
Model Accuracy over intervened graphs for r=0.8 =  0.833
NEC for r=0.8 class 0.0 = 0.087 +- 0.201 (in-sample avg dev_std = 0.218)
NEC for r=0.8 class 1.0 = 0.086 +- 0.201 (in-sample avg dev_std = 0.218)
NEC for r=0.8 all KL = 0.096 +- 0.201 (in-sample avg dev_std = 0.218)
NEC for r=0.8 all L1 = 0.087 +- 0.172 (in-sample avg dev_std = 0.218)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.87], 'all_L1': [0.886]}), defaultdict(<class 'list'>, {'all_KL': [0.891], 'all_L1': [0.907]}), defaultdict(<class 'list'>, {'all_KL': [0.842], 'all_L1': [0.862]}), defaultdict(<class 'list'>, {'all_KL': [0.86], 'all_L1': [0.898]}), defaultdict(<class 'list'>, {'all_KL': [0.857], 'all_L1': [0.892]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.096], 'all_L1': [0.095]}), defaultdict(<class 'list'>, {'all_KL': [0.094], 'all_L1': [0.086]}), defaultdict(<class 'list'>, {'all_KL': [0.082], 'all_L1': [0.095]}), defaultdict(<class 'list'>, {'all_KL': [0.091], 'all_L1': [0.082]}), defaultdict(<class 'list'>, {'all_KL': [0.096], 'all_L1': [0.087]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split test
suff++ class all_L1  =  0.889 +- 0.015
suff++ class all_KL  =  0.864 +- 0.016
suff++_acc_int  =  0.779 +- 0.042
nec class all_L1  =  0.089 +- 0.005
nec class all_KL  =  0.092 +- 0.005
nec_acc_int  =  0.799 +- 0.035


 -------------------------------------------------- 
Computing faithfulness

Eval split test
Faith. Aritm (L1)= 		  =  0.489 +- 0.006
Faith. Armon (L1)= 		  =  0.162 +- 0.008
Faith. GMean (L1)= 	  =  0.281 +- 0.007
Faith. Aritm (KL)= 		  =  0.478 +- 0.010
Faith. Armon (KL)= 		  =  0.166 +- 0.009
Faith. GMean (KL)= 	  =  0.282 +- 0.010
Computed for split load_split = id



Completed in  0:03:57.509464  for CIGAGIN GOODSST2/length



DONE CIGA GOODSST2/length nov
DONE all :)
Time to compute metrics!
The PID of this script is: 1735462

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 11 14:17:55 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/11/2024 02:17:55 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/11/2024 02:17:55 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/11/2024 02:17:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 02:17:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 02:17:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 02:17:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 02:17:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 02:17:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 02:17:55 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 05/11/2024 02:17:55 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 141...
[0m[1;37mINFO[0m: [1mCheckpoint 141: 
-----------------------------------
Train ACCURACY: 0.9305
Train Loss: 0.3185
ID Validation ACCURACY: 0.9363
ID Validation Loss: 0.3125
ID Test ACCURACY: 0.9260
ID Test Loss: 0.3441
OOD Validation ACCURACY: 0.8640
OOD Validation Loss: 0.4793
OOD Test ACCURACY: 0.6850
OOD Test Loss: 1.1140

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 135...
[0m[1;37mINFO[0m: [1mCheckpoint 135: 
-----------------------------------
Train ACCURACY: 0.9250
Train Loss: 0.3289
ID Validation ACCURACY: 0.9303
ID Validation Loss: 0.3194
ID Test ACCURACY: 0.9213
ID Test Loss: 0.3502
OOD Validation ACCURACY: 0.9307
OOD Validation Loss: 0.3665
OOD Test ACCURACY: 0.6453
OOD Test Loss: 0.9689

[0m[1;37mINFO[0m: [1mChartInfo 0.9260 0.6850 0.9213 0.6453 0.9303 0.9307[0mGOODMotif2(3000)
Data example from id_test: Data(edge_index=[2, 56], x=[16, 1], node_gt=[16], edge_gt=[56], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=16)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([ 988,  973, 1039]))

Gold ratio (id_test) =  tensor(0.3032) +- tensor(0.1592)
F1 for r=0.3 = 0.690
WIoU for r=0.3 = 0.574
F1 for r=0.6 = 0.567
WIoU for r=0.6 = 0.452
F1 for r=0.9 = 0.446
WIoU for r=0.9 = 0.329
F1 for r=1.0 = 0.444
WIoU for r=1.0 = 0.324
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.710
WIoU for r=0.3 = 0.593
F1 for r=0.6 = 0.508
WIoU for r=0.6 = 0.375
F1 for r=0.9 = 0.396
WIoU for r=0.9 = 0.271
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.266


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.42
Model XAI F1 of binarized graphs for r=0.3 =  0.69025875
Model XAI WIoU of binarized graphs for r=0.3 =  0.57438625
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.439
SUFF++ for r=0.3 class 0 = 0.459 +- 0.254 (in-sample avg dev_std = 0.431)
SUFF++ for r=0.3 class 1 = 0.511 +- 0.254 (in-sample avg dev_std = 0.431)
SUFF++ for r=0.3 class 2 = 0.555 +- 0.254 (in-sample avg dev_std = 0.431)
SUFF++ for r=0.3 all KL = 0.57 +- 0.254 (in-sample avg dev_std = 0.431)
SUFF++ for r=0.3 all L1 = 0.509 +- 0.161 (in-sample avg dev_std = 0.431)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.639
Model XAI F1 of binarized graphs for r=0.6 =  0.5670525
Model XAI WIoU of binarized graphs for r=0.6 =  0.45217375000000004
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.613
SUFF++ for r=0.6 class 0 = 0.469 +- 0.258 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 class 1 = 0.668 +- 0.258 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 class 2 = 0.663 +- 0.258 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 all KL = 0.651 +- 0.258 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 all L1 = 0.601 +- 0.191 (in-sample avg dev_std = 0.417)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.924
Model XAI F1 of binarized graphs for r=0.9 =  0.44626125
Model XAI WIoU of binarized graphs for r=0.9 =  0.32876374999999997
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.818
SUFF++ for r=0.9 class 0 = 0.602 +- 0.191 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.9 class 1 = 0.825 +- 0.191 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.9 class 2 = 0.874 +- 0.191 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.9 all KL = 0.84 +- 0.191 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.9 all L1 = 0.769 +- 0.189 (in-sample avg dev_std = 0.297)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.444
Model XAI F1 of binarized graphs for r=0.3 =  0.7095375
Model XAI WIoU of binarized graphs for r=0.3 =  0.5925024999999999
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.508
SUFF++ for r=0.3 class 0 = 0.519 +- 0.286 (in-sample avg dev_std = 0.442)
SUFF++ for r=0.3 class 1 = 0.578 +- 0.286 (in-sample avg dev_std = 0.442)
SUFF++ for r=0.3 class 2 = 0.644 +- 0.286 (in-sample avg dev_std = 0.442)
SUFF++ for r=0.3 all KL = 0.603 +- 0.286 (in-sample avg dev_std = 0.442)
SUFF++ for r=0.3 all L1 = 0.581 +- 0.185 (in-sample avg dev_std = 0.442)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.741
Model XAI F1 of binarized graphs for r=0.6 =  0.508355
Model XAI WIoU of binarized graphs for r=0.6 =  0.37451375
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.703
SUFF++ for r=0.6 class 0 = 0.432 +- 0.258 (in-sample avg dev_std = 0.349)
SUFF++ for r=0.6 class 1 = 0.7 +- 0.258 (in-sample avg dev_std = 0.349)
SUFF++ for r=0.6 class 2 = 0.735 +- 0.258 (in-sample avg dev_std = 0.349)
SUFF++ for r=0.6 all KL = 0.699 +- 0.258 (in-sample avg dev_std = 0.349)
SUFF++ for r=0.6 all L1 = 0.625 +- 0.194 (in-sample avg dev_std = 0.349)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.644
Model XAI F1 of binarized graphs for r=0.9 =  0.39575125
Model XAI WIoU of binarized graphs for r=0.9 =  0.27060125
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.687
SUFF++ for r=0.9 class 0 = 0.608 +- 0.246 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 class 1 = 0.756 +- 0.246 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 class 2 = 0.88 +- 0.246 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 all KL = 0.817 +- 0.246 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 all L1 = 0.749 +- 0.198 (in-sample avg dev_std = 0.257)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.419
Model XAI F1 of binarized graphs for r=0.3 =  0.69025875
Model XAI WIoU of binarized graphs for r=0.3 =  0.57438625
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.295
NEC for r=0.3 class 0 = 0.592 +- 0.278 (in-sample avg dev_std = 0.376)
NEC for r=0.3 class 1 = 0.523 +- 0.278 (in-sample avg dev_std = 0.376)
NEC for r=0.3 class 2 = 0.583 +- 0.278 (in-sample avg dev_std = 0.376)
NEC for r=0.3 all KL = 0.523 +- 0.278 (in-sample avg dev_std = 0.376)
NEC for r=0.3 all L1 = 0.567 +- 0.169 (in-sample avg dev_std = 0.376)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.639
Model XAI F1 of binarized graphs for r=0.6 =  0.5670525
Model XAI WIoU of binarized graphs for r=0.6 =  0.45217375000000004
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.378
NEC for r=0.6 class 0 = 0.6 +- 0.266 (in-sample avg dev_std = 0.458)
NEC for r=0.6 class 1 = 0.523 +- 0.266 (in-sample avg dev_std = 0.458)
NEC for r=0.6 class 2 = 0.645 +- 0.266 (in-sample avg dev_std = 0.458)
NEC for r=0.6 all KL = 0.59 +- 0.266 (in-sample avg dev_std = 0.458)
NEC for r=0.6 all L1 = 0.591 +- 0.154 (in-sample avg dev_std = 0.458)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.924
Model XAI F1 of binarized graphs for r=0.9 =  0.44626125
Model XAI WIoU of binarized graphs for r=0.9 =  0.32876374999999997
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.491
NEC for r=0.9 class 0 = 0.622 +- 0.217 (in-sample avg dev_std = 0.556)
NEC for r=0.9 class 1 = 0.493 +- 0.217 (in-sample avg dev_std = 0.556)
NEC for r=0.9 class 2 = 0.529 +- 0.217 (in-sample avg dev_std = 0.556)
NEC for r=0.9 all KL = 0.566 +- 0.217 (in-sample avg dev_std = 0.556)
NEC for r=0.9 all L1 = 0.548 +- 0.150 (in-sample avg dev_std = 0.556)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.935
Model XAI F1 of binarized graphs for r=1.0 =  0.44384
Model XAI WIoU of binarized graphs for r=1.0 =  0.32384
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.528
NEC for r=1.0 class 0 = 0.594 +- 0.229 (in-sample avg dev_std = 0.609)
NEC for r=1.0 class 1 = 0.442 +- 0.229 (in-sample avg dev_std = 0.609)
NEC for r=1.0 class 2 = 0.537 +- 0.229 (in-sample avg dev_std = 0.609)
NEC for r=1.0 all KL = 0.565 +- 0.229 (in-sample avg dev_std = 0.609)
NEC for r=1.0 all L1 = 0.525 +- 0.164 (in-sample avg dev_std = 0.609)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.442
Model XAI F1 of binarized graphs for r=0.3 =  0.7095375
Model XAI WIoU of binarized graphs for r=0.3 =  0.5925024999999999
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.347
NEC for r=0.3 class 0 = 0.508 +- 0.276 (in-sample avg dev_std = 0.418)
NEC for r=0.3 class 1 = 0.522 +- 0.276 (in-sample avg dev_std = 0.418)
NEC for r=0.3 class 2 = 0.675 +- 0.276 (in-sample avg dev_std = 0.418)
NEC for r=0.3 all KL = 0.568 +- 0.276 (in-sample avg dev_std = 0.418)
NEC for r=0.3 all L1 = 0.568 +- 0.148 (in-sample avg dev_std = 0.418)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.743
Model XAI F1 of binarized graphs for r=0.6 =  0.508355
Model XAI WIoU of binarized graphs for r=0.6 =  0.37451375
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.433
NEC for r=0.6 class 0 = 0.637 +- 0.242 (in-sample avg dev_std = 0.496)
NEC for r=0.6 class 1 = 0.504 +- 0.242 (in-sample avg dev_std = 0.496)
NEC for r=0.6 class 2 = 0.603 +- 0.242 (in-sample avg dev_std = 0.496)
NEC for r=0.6 all KL = 0.582 +- 0.242 (in-sample avg dev_std = 0.496)
NEC for r=0.6 all L1 = 0.58 +- 0.139 (in-sample avg dev_std = 0.496)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.644
Model XAI F1 of binarized graphs for r=0.9 =  0.39575125
Model XAI WIoU of binarized graphs for r=0.9 =  0.27060125
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.542
NEC for r=0.9 class 0 = 0.532 +- 0.293 (in-sample avg dev_std = 0.494)
NEC for r=0.9 class 1 = 0.428 +- 0.293 (in-sample avg dev_std = 0.494)
NEC for r=0.9 class 2 = 0.392 +- 0.293 (in-sample avg dev_std = 0.494)
NEC for r=0.9 all KL = 0.48 +- 0.293 (in-sample avg dev_std = 0.494)
NEC for r=0.9 all L1 = 0.45 +- 0.159 (in-sample avg dev_std = 0.494)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.706
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.26572250000000003
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.587
NEC for r=1.0 class 0 = 0.487 +- 0.281 (in-sample avg dev_std = 0.493)
NEC for r=1.0 class 1 = 0.385 +- 0.281 (in-sample avg dev_std = 0.493)
NEC for r=1.0 class 2 = 0.342 +- 0.281 (in-sample avg dev_std = 0.493)
NEC for r=1.0 all KL = 0.418 +- 0.281 (in-sample avg dev_std = 0.493)
NEC for r=1.0 all L1 = 0.404 +- 0.169 (in-sample avg dev_std = 0.493)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 11 14:20:58 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/11/2024 02:20:58 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/11/2024 02:20:58 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/11/2024 02:20:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 02:20:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 02:20:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 02:20:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 02:20:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 02:20:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 02:20:58 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 05/11/2024 02:20:58 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 182...
[0m[1;37mINFO[0m: [1mCheckpoint 182: 
-----------------------------------
Train ACCURACY: 0.9313
Train Loss: 0.3197
ID Validation ACCURACY: 0.9367
ID Validation Loss: 0.3118
ID Test ACCURACY: 0.9260
ID Test Loss: 0.3429
OOD Validation ACCURACY: 0.9310
OOD Validation Loss: 0.3727
OOD Test ACCURACY: 0.7160
OOD Test Loss: 0.9099

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 194...
[0m[1;37mINFO[0m: [1mCheckpoint 194: 
-----------------------------------
Train ACCURACY: 0.9302
Train Loss: 0.3212
ID Validation ACCURACY: 0.9347
ID Validation Loss: 0.3115
ID Test ACCURACY: 0.9257
ID Test Loss: 0.3419
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.3812
OOD Test ACCURACY: 0.6987
OOD Test Loss: 0.8929

[0m[1;37mINFO[0m: [1mChartInfo 0.9260 0.7160 0.9257 0.6987 0.9347 0.9317[0mGOODMotif2(3000)
Data example from id_test: Data(edge_index=[2, 56], x=[16, 1], node_gt=[16], edge_gt=[56], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=16)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([ 988,  973, 1039]))

Gold ratio (id_test) =  tensor(0.3032) +- tensor(0.1592)
F1 for r=0.3 = 0.666
WIoU for r=0.3 = 0.543
F1 for r=0.6 = 0.551
WIoU for r=0.6 = 0.426
F1 for r=0.9 = 0.440
WIoU for r=0.9 = 0.318
F1 for r=1.0 = 0.444
WIoU for r=1.0 = 0.319
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.615
WIoU for r=0.3 = 0.491
F1 for r=0.6 = 0.462
WIoU for r=0.6 = 0.329
F1 for r=0.9 = 0.397
WIoU for r=0.9 = 0.266
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.261


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.451
Model XAI F1 of binarized graphs for r=0.3 =  0.6663175
Model XAI WIoU of binarized graphs for r=0.3 =  0.5426475000000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.45
SUFF++ for r=0.3 class 0 = 0.468 +- 0.253 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 class 1 = 0.543 +- 0.253 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 class 2 = 0.531 +- 0.253 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 all KL = 0.566 +- 0.253 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 all L1 = 0.514 +- 0.155 (in-sample avg dev_std = 0.475)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.618
Model XAI F1 of binarized graphs for r=0.6 =  0.550685
Model XAI WIoU of binarized graphs for r=0.6 =  0.42572625000000003
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.619
SUFF++ for r=0.6 class 0 = 0.503 +- 0.210 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.6 class 1 = 0.684 +- 0.210 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.6 class 2 = 0.641 +- 0.210 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.6 all KL = 0.66 +- 0.210 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.6 all L1 = 0.61 +- 0.172 (in-sample avg dev_std = 0.425)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.914
Model XAI F1 of binarized graphs for r=0.9 =  0.44006625
Model XAI WIoU of binarized graphs for r=0.9 =  0.31771499999999997
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.837
SUFF++ for r=0.9 class 0 = 0.645 +- 0.167 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.9 class 1 = 0.8 +- 0.167 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.9 class 2 = 0.802 +- 0.167 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.9 all KL = 0.829 +- 0.167 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.9 all L1 = 0.75 +- 0.154 (in-sample avg dev_std = 0.354)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.525
Model XAI F1 of binarized graphs for r=0.3 =  0.61499875
Model XAI WIoU of binarized graphs for r=0.3 =  0.4905575
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.533
SUFF++ for r=0.3 class 0 = 0.531 +- 0.270 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.3 class 1 = 0.58 +- 0.270 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.3 class 2 = 0.576 +- 0.270 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.3 all KL = 0.592 +- 0.270 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.3 all L1 = 0.563 +- 0.171 (in-sample avg dev_std = 0.455)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.619
Model XAI F1 of binarized graphs for r=0.6 =  0.46240624999999996
Model XAI WIoU of binarized graphs for r=0.6 =  0.32880250000000005
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.637
SUFF++ for r=0.6 class 0 = 0.467 +- 0.244 (in-sample avg dev_std = 0.408)
SUFF++ for r=0.6 class 1 = 0.692 +- 0.244 (in-sample avg dev_std = 0.408)
SUFF++ for r=0.6 class 2 = 0.619 +- 0.244 (in-sample avg dev_std = 0.408)
SUFF++ for r=0.6 all KL = 0.683 +- 0.244 (in-sample avg dev_std = 0.408)
SUFF++ for r=0.6 all L1 = 0.595 +- 0.178 (in-sample avg dev_std = 0.408)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.754
Model XAI F1 of binarized graphs for r=0.9 =  0.39749375
Model XAI WIoU of binarized graphs for r=0.9 =  0.26595125000000003
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.724
SUFF++ for r=0.9 class 0 = 0.638 +- 0.153 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 1 = 0.827 +- 0.153 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 2 = 0.826 +- 0.153 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 all KL = 0.836 +- 0.153 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 all L1 = 0.765 +- 0.131 (in-sample avg dev_std = 0.276)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.45
Model XAI F1 of binarized graphs for r=0.3 =  0.6663175
Model XAI WIoU of binarized graphs for r=0.3 =  0.5426475000000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.32
NEC for r=0.3 class 0 = 0.565 +- 0.291 (in-sample avg dev_std = 0.400)
NEC for r=0.3 class 1 = 0.434 +- 0.291 (in-sample avg dev_std = 0.400)
NEC for r=0.3 class 2 = 0.625 +- 0.291 (in-sample avg dev_std = 0.400)
NEC for r=0.3 all KL = 0.499 +- 0.291 (in-sample avg dev_std = 0.400)
NEC for r=0.3 all L1 = 0.544 +- 0.189 (in-sample avg dev_std = 0.400)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.618
Model XAI F1 of binarized graphs for r=0.6 =  0.550685
Model XAI WIoU of binarized graphs for r=0.6 =  0.42572625000000003
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.375
NEC for r=0.6 class 0 = 0.569 +- 0.278 (in-sample avg dev_std = 0.444)
NEC for r=0.6 class 1 = 0.438 +- 0.278 (in-sample avg dev_std = 0.444)
NEC for r=0.6 class 2 = 0.625 +- 0.278 (in-sample avg dev_std = 0.444)
NEC for r=0.6 all KL = 0.543 +- 0.278 (in-sample avg dev_std = 0.444)
NEC for r=0.6 all L1 = 0.546 +- 0.180 (in-sample avg dev_std = 0.444)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.914
Model XAI F1 of binarized graphs for r=0.9 =  0.44006625
Model XAI WIoU of binarized graphs for r=0.9 =  0.31771499999999997
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.501
NEC for r=0.9 class 0 = 0.594 +- 0.229 (in-sample avg dev_std = 0.545)
NEC for r=0.9 class 1 = 0.465 +- 0.229 (in-sample avg dev_std = 0.545)
NEC for r=0.9 class 2 = 0.563 +- 0.229 (in-sample avg dev_std = 0.545)
NEC for r=0.9 all KL = 0.539 +- 0.229 (in-sample avg dev_std = 0.545)
NEC for r=0.9 all L1 = 0.541 +- 0.154 (in-sample avg dev_std = 0.545)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.936
Model XAI F1 of binarized graphs for r=1.0 =  0.44384
Model XAI WIoU of binarized graphs for r=1.0 =  0.31931
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.535
NEC for r=1.0 class 0 = 0.576 +- 0.222 (in-sample avg dev_std = 0.595)
NEC for r=1.0 class 1 = 0.417 +- 0.222 (in-sample avg dev_std = 0.595)
NEC for r=1.0 class 2 = 0.551 +- 0.222 (in-sample avg dev_std = 0.595)
NEC for r=1.0 all KL = 0.536 +- 0.222 (in-sample avg dev_std = 0.595)
NEC for r=1.0 all L1 = 0.516 +- 0.171 (in-sample avg dev_std = 0.595)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.53
Model XAI F1 of binarized graphs for r=0.3 =  0.61499875
Model XAI WIoU of binarized graphs for r=0.3 =  0.4905575
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.332
NEC for r=0.3 class 0 = 0.587 +- 0.235 (in-sample avg dev_std = 0.503)
NEC for r=0.3 class 1 = 0.593 +- 0.235 (in-sample avg dev_std = 0.503)
NEC for r=0.3 class 2 = 0.659 +- 0.235 (in-sample avg dev_std = 0.503)
NEC for r=0.3 all KL = 0.638 +- 0.235 (in-sample avg dev_std = 0.503)
NEC for r=0.3 all L1 = 0.613 +- 0.120 (in-sample avg dev_std = 0.503)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.629
Model XAI F1 of binarized graphs for r=0.6 =  0.46240624999999996
Model XAI WIoU of binarized graphs for r=0.6 =  0.32880250000000005
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.445
NEC for r=0.6 class 0 = 0.625 +- 0.242 (in-sample avg dev_std = 0.487)
NEC for r=0.6 class 1 = 0.489 +- 0.242 (in-sample avg dev_std = 0.487)
NEC for r=0.6 class 2 = 0.566 +- 0.242 (in-sample avg dev_std = 0.487)
NEC for r=0.6 all KL = 0.543 +- 0.242 (in-sample avg dev_std = 0.487)
NEC for r=0.6 all L1 = 0.559 +- 0.141 (in-sample avg dev_std = 0.487)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.755
Model XAI F1 of binarized graphs for r=0.9 =  0.39749375
Model XAI WIoU of binarized graphs for r=0.9 =  0.26595125000000003
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.557
NEC for r=0.9 class 0 = 0.556 +- 0.308 (in-sample avg dev_std = 0.527)
NEC for r=0.9 class 1 = 0.401 +- 0.308 (in-sample avg dev_std = 0.527)
NEC for r=0.9 class 2 = 0.468 +- 0.308 (in-sample avg dev_std = 0.527)
NEC for r=0.9 all KL = 0.474 +- 0.308 (in-sample avg dev_std = 0.527)
NEC for r=0.9 all L1 = 0.474 +- 0.182 (in-sample avg dev_std = 0.527)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.715
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.26119749999999997
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.598
NEC for r=1.0 class 0 = 0.462 +- 0.265 (in-sample avg dev_std = 0.471)
NEC for r=1.0 class 1 = 0.374 +- 0.265 (in-sample avg dev_std = 0.471)
NEC for r=1.0 class 2 = 0.433 +- 0.265 (in-sample avg dev_std = 0.471)
NEC for r=1.0 all KL = 0.39 +- 0.265 (in-sample avg dev_std = 0.471)
NEC for r=1.0 all L1 = 0.422 +- 0.152 (in-sample avg dev_std = 0.471)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 11 14:23:54 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/11/2024 02:23:54 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/11/2024 02:23:54 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/11/2024 02:23:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 02:23:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 02:23:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 02:23:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 02:23:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 02:23:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 02:23:54 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 05/11/2024 02:23:54 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 125...
[0m[1;37mINFO[0m: [1mCheckpoint 125: 
-----------------------------------
Train ACCURACY: 0.9305
Train Loss: 0.3203
ID Validation ACCURACY: 0.9370
ID Validation Loss: 0.3167
ID Test ACCURACY: 0.9260
ID Test Loss: 0.3450
OOD Validation ACCURACY: 0.7720
OOD Validation Loss: 0.5765
OOD Test ACCURACY: 0.5833
OOD Test Loss: 1.5578

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 96...
[0m[1;37mINFO[0m: [1mCheckpoint 96: 
-----------------------------------
Train ACCURACY: 0.9248
Train Loss: 0.3355
ID Validation ACCURACY: 0.9310
ID Validation Loss: 0.3225
ID Test ACCURACY: 0.9200
ID Test Loss: 0.3594
OOD Validation ACCURACY: 0.9307
OOD Validation Loss: 0.3760
OOD Test ACCURACY: 0.7793
OOD Test Loss: 0.9678

[0m[1;37mINFO[0m: [1mChartInfo 0.9260 0.5833 0.9200 0.7793 0.9310 0.9307[0mGOODMotif2(3000)
Data example from id_test: Data(edge_index=[2, 56], x=[16, 1], node_gt=[16], edge_gt=[56], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=16)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([ 988,  973, 1039]))

Gold ratio (id_test) =  tensor(0.3032) +- tensor(0.1592)
F1 for r=0.3 = 0.665
WIoU for r=0.3 = 0.540
F1 for r=0.6 = 0.560
WIoU for r=0.6 = 0.434
F1 for r=0.9 = 0.452
WIoU for r=0.9 = 0.326
F1 for r=1.0 = 0.444
WIoU for r=1.0 = 0.318
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.712
WIoU for r=0.3 = 0.590
F1 for r=0.6 = 0.514
WIoU for r=0.6 = 0.373
F1 for r=0.9 = 0.392
WIoU for r=0.9 = 0.263
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.263


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.411
Model XAI F1 of binarized graphs for r=0.3 =  0.66515625
Model XAI WIoU of binarized graphs for r=0.3 =  0.5395862499999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.441
SUFF++ for r=0.3 class 0 = 0.478 +- 0.244 (in-sample avg dev_std = 0.418)
SUFF++ for r=0.3 class 1 = 0.564 +- 0.244 (in-sample avg dev_std = 0.418)
SUFF++ for r=0.3 class 2 = 0.586 +- 0.244 (in-sample avg dev_std = 0.418)
SUFF++ for r=0.3 all KL = 0.635 +- 0.244 (in-sample avg dev_std = 0.418)
SUFF++ for r=0.3 all L1 = 0.543 +- 0.150 (in-sample avg dev_std = 0.418)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.491
Model XAI F1 of binarized graphs for r=0.6 =  0.560235
Model XAI WIoU of binarized graphs for r=0.6 =  0.43432874999999993
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.593
SUFF++ for r=0.6 class 0 = 0.474 +- 0.229 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.6 class 1 = 0.625 +- 0.229 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.6 class 2 = 0.619 +- 0.229 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.6 all KL = 0.665 +- 0.229 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.6 all L1 = 0.573 +- 0.179 (in-sample avg dev_std = 0.355)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.846
Model XAI F1 of binarized graphs for r=0.9 =  0.45163875000000003
Model XAI WIoU of binarized graphs for r=0.9 =  0.32559875
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.778
SUFF++ for r=0.9 class 0 = 0.62 +- 0.136 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.9 class 1 = 0.836 +- 0.136 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.9 class 2 = 0.804 +- 0.136 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.9 all KL = 0.866 +- 0.136 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.9 all L1 = 0.754 +- 0.159 (in-sample avg dev_std = 0.247)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.389
Model XAI F1 of binarized graphs for r=0.3 =  0.712365
Model XAI WIoU of binarized graphs for r=0.3 =  0.5902762500000001
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.47
SUFF++ for r=0.3 class 0 = 0.544 +- 0.282 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.3 class 1 = 0.54 +- 0.282 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.3 class 2 = 0.58 +- 0.282 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.3 all KL = 0.607 +- 0.282 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.3 all L1 = 0.555 +- 0.176 (in-sample avg dev_std = 0.428)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.575
Model XAI F1 of binarized graphs for r=0.6 =  0.5140325000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.37252
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.639
SUFF++ for r=0.6 class 0 = 0.41 +- 0.246 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.6 class 1 = 0.707 +- 0.246 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.6 class 2 = 0.524 +- 0.246 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.6 all KL = 0.649 +- 0.246 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.6 all L1 = 0.55 +- 0.192 (in-sample avg dev_std = 0.330)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.584
Model XAI F1 of binarized graphs for r=0.9 =  0.39194875
Model XAI WIoU of binarized graphs for r=0.9 =  0.2633175
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.601
SUFF++ for r=0.9 class 0 = 0.603 +- 0.237 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.9 class 1 = 0.745 +- 0.237 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.9 class 2 = 0.792 +- 0.237 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.9 all KL = 0.766 +- 0.237 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.9 all L1 = 0.715 +- 0.164 (in-sample avg dev_std = 0.292)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.411
Model XAI F1 of binarized graphs for r=0.3 =  0.66515625
Model XAI WIoU of binarized graphs for r=0.3 =  0.5395862499999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.332
NEC for r=0.3 class 0 = 0.571 +- 0.280 (in-sample avg dev_std = 0.379)
NEC for r=0.3 class 1 = 0.392 +- 0.280 (in-sample avg dev_std = 0.379)
NEC for r=0.3 class 2 = 0.601 +- 0.280 (in-sample avg dev_std = 0.379)
NEC for r=0.3 all KL = 0.451 +- 0.280 (in-sample avg dev_std = 0.379)
NEC for r=0.3 all L1 = 0.523 +- 0.186 (in-sample avg dev_std = 0.379)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.491
Model XAI F1 of binarized graphs for r=0.6 =  0.560235
Model XAI WIoU of binarized graphs for r=0.6 =  0.43432874999999993
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.361
NEC for r=0.6 class 0 = 0.531 +- 0.252 (in-sample avg dev_std = 0.392)
NEC for r=0.6 class 1 = 0.474 +- 0.252 (in-sample avg dev_std = 0.392)
NEC for r=0.6 class 2 = 0.609 +- 0.252 (in-sample avg dev_std = 0.392)
NEC for r=0.6 all KL = 0.479 +- 0.252 (in-sample avg dev_std = 0.392)
NEC for r=0.6 all L1 = 0.54 +- 0.156 (in-sample avg dev_std = 0.392)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.845
Model XAI F1 of binarized graphs for r=0.9 =  0.45163875000000003
Model XAI WIoU of binarized graphs for r=0.9 =  0.32559875
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.477
NEC for r=0.9 class 0 = 0.558 +- 0.187 (in-sample avg dev_std = 0.459)
NEC for r=0.9 class 1 = 0.458 +- 0.187 (in-sample avg dev_std = 0.459)
NEC for r=0.9 class 2 = 0.518 +- 0.187 (in-sample avg dev_std = 0.459)
NEC for r=0.9 all KL = 0.446 +- 0.187 (in-sample avg dev_std = 0.459)
NEC for r=0.9 all L1 = 0.512 +- 0.140 (in-sample avg dev_std = 0.459)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.935
Model XAI F1 of binarized graphs for r=1.0 =  0.44384
Model XAI WIoU of binarized graphs for r=1.0 =  0.31765499999999997
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.531
NEC for r=1.0 class 0 = 0.592 +- 0.230 (in-sample avg dev_std = 0.562)
NEC for r=1.0 class 1 = 0.424 +- 0.230 (in-sample avg dev_std = 0.562)
NEC for r=1.0 class 2 = 0.522 +- 0.230 (in-sample avg dev_std = 0.562)
NEC for r=1.0 all KL = 0.513 +- 0.230 (in-sample avg dev_std = 0.562)
NEC for r=1.0 all L1 = 0.513 +- 0.172 (in-sample avg dev_std = 0.562)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.389
Model XAI F1 of binarized graphs for r=0.3 =  0.712365
Model XAI WIoU of binarized graphs for r=0.3 =  0.5902762500000001
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.447
NEC for r=0.3 class 0 = 0.569 +- 0.242 (in-sample avg dev_std = 0.443)
NEC for r=0.3 class 1 = 0.571 +- 0.242 (in-sample avg dev_std = 0.443)
NEC for r=0.3 class 2 = 0.643 +- 0.242 (in-sample avg dev_std = 0.443)
NEC for r=0.3 all KL = 0.579 +- 0.242 (in-sample avg dev_std = 0.443)
NEC for r=0.3 all L1 = 0.594 +- 0.124 (in-sample avg dev_std = 0.443)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.58
Model XAI F1 of binarized graphs for r=0.6 =  0.5140325000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.37252
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.424
NEC for r=0.6 class 0 = 0.64 +- 0.218 (in-sample avg dev_std = 0.454)
NEC for r=0.6 class 1 = 0.478 +- 0.218 (in-sample avg dev_std = 0.454)
NEC for r=0.6 class 2 = 0.511 +- 0.218 (in-sample avg dev_std = 0.454)
NEC for r=0.6 all KL = 0.51 +- 0.218 (in-sample avg dev_std = 0.454)
NEC for r=0.6 all L1 = 0.541 +- 0.135 (in-sample avg dev_std = 0.454)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.584
Model XAI F1 of binarized graphs for r=0.9 =  0.39194875
Model XAI WIoU of binarized graphs for r=0.9 =  0.2633175
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.472
NEC for r=0.9 class 0 = 0.556 +- 0.294 (in-sample avg dev_std = 0.519)
NEC for r=0.9 class 1 = 0.403 +- 0.294 (in-sample avg dev_std = 0.519)
NEC for r=0.9 class 2 = 0.463 +- 0.294 (in-sample avg dev_std = 0.519)
NEC for r=0.9 all KL = 0.488 +- 0.294 (in-sample avg dev_std = 0.519)
NEC for r=0.9 all L1 = 0.473 +- 0.159 (in-sample avg dev_std = 0.519)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.608
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.26294125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.517
NEC for r=1.0 class 0 = 0.53 +- 0.247 (in-sample avg dev_std = 0.484)
NEC for r=1.0 class 1 = 0.44 +- 0.247 (in-sample avg dev_std = 0.484)
NEC for r=1.0 class 2 = 0.339 +- 0.247 (in-sample avg dev_std = 0.484)
NEC for r=1.0 all KL = 0.471 +- 0.247 (in-sample avg dev_std = 0.484)
NEC for r=1.0 all L1 = 0.435 +- 0.165 (in-sample avg dev_std = 0.484)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 11 14:26:53 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/11/2024 02:26:53 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/11/2024 02:26:53 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/11/2024 02:26:53 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 02:26:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 02:26:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 02:26:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 02:26:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 02:26:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 02:26:53 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 05/11/2024 02:26:53 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 103...
[0m[1;37mINFO[0m: [1mCheckpoint 103: 
-----------------------------------
Train ACCURACY: 0.9313
Train Loss: 0.3175
ID Validation ACCURACY: 0.9363
ID Validation Loss: 0.3091
ID Test ACCURACY: 0.9260
ID Test Loss: 0.3417
OOD Validation ACCURACY: 0.9290
OOD Validation Loss: 0.3763
OOD Test ACCURACY: 0.6370
OOD Test Loss: 1.3612

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 91...
[0m[1;37mINFO[0m: [1mCheckpoint 91: 
-----------------------------------
Train ACCURACY: 0.9214
Train Loss: 0.3499
ID Validation ACCURACY: 0.9247
ID Validation Loss: 0.3441
ID Test ACCURACY: 0.9190
ID Test Loss: 0.3725
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.4342
OOD Test ACCURACY: 0.6417
OOD Test Loss: 1.3495

[0m[1;37mINFO[0m: [1mChartInfo 0.9260 0.6370 0.9190 0.6417 0.9247 0.9317[0mGOODMotif2(3000)
Data example from id_test: Data(edge_index=[2, 56], x=[16, 1], node_gt=[16], edge_gt=[56], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=16)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([ 988,  973, 1039]))

Gold ratio (id_test) =  tensor(0.3032) +- tensor(0.1592)
F1 for r=0.3 = 0.653
WIoU for r=0.3 = 0.527
F1 for r=0.6 = 0.568
WIoU for r=0.6 = 0.448
F1 for r=0.9 = 0.448
WIoU for r=0.9 = 0.324
F1 for r=1.0 = 0.444
WIoU for r=1.0 = 0.319
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.492
WIoU for r=0.3 = 0.374
F1 for r=0.6 = 0.408
WIoU for r=0.6 = 0.291
F1 for r=0.9 = 0.364
WIoU for r=0.9 = 0.242
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.258


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.416
Model XAI F1 of binarized graphs for r=0.3 =  0.6534174999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.52699375
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.443
SUFF++ for r=0.3 class 0 = 0.435 +- 0.265 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.3 class 1 = 0.528 +- 0.265 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.3 class 2 = 0.554 +- 0.265 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.3 all KL = 0.549 +- 0.265 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.3 all L1 = 0.506 +- 0.165 (in-sample avg dev_std = 0.490)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.65
Model XAI F1 of binarized graphs for r=0.6 =  0.56778375
Model XAI WIoU of binarized graphs for r=0.6 =  0.44836624999999997
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.601
SUFF++ for r=0.6 class 0 = 0.501 +- 0.249 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 class 1 = 0.574 +- 0.249 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 class 2 = 0.649 +- 0.249 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 all KL = 0.579 +- 0.249 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 all L1 = 0.576 +- 0.165 (in-sample avg dev_std = 0.483)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.921
Model XAI F1 of binarized graphs for r=0.9 =  0.447675
Model XAI WIoU of binarized graphs for r=0.9 =  0.32446624999999996
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.827
SUFF++ for r=0.9 class 0 = 0.608 +- 0.178 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.9 class 1 = 0.813 +- 0.178 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.9 class 2 = 0.812 +- 0.178 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.9 all KL = 0.826 +- 0.178 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.9 all L1 = 0.745 +- 0.166 (in-sample avg dev_std = 0.321)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.425
Model XAI F1 of binarized graphs for r=0.3 =  0.49179624999999993
Model XAI WIoU of binarized graphs for r=0.3 =  0.3739937499999999
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.487
SUFF++ for r=0.3 class 0 = 0.505 +- 0.262 (in-sample avg dev_std = 0.502)
SUFF++ for r=0.3 class 1 = 0.526 +- 0.262 (in-sample avg dev_std = 0.502)
SUFF++ for r=0.3 class 2 = 0.542 +- 0.262 (in-sample avg dev_std = 0.502)
SUFF++ for r=0.3 all KL = 0.553 +- 0.262 (in-sample avg dev_std = 0.502)
SUFF++ for r=0.3 all L1 = 0.525 +- 0.174 (in-sample avg dev_std = 0.502)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.757
Model XAI F1 of binarized graphs for r=0.6 =  0.40788874999999997
Model XAI WIoU of binarized graphs for r=0.6 =  0.291045
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.59
SUFF++ for r=0.6 class 0 = 0.455 +- 0.182 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.6 class 1 = 0.601 +- 0.182 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.6 class 2 = 0.68 +- 0.182 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.6 all KL = 0.688 +- 0.182 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.6 all L1 = 0.58 +- 0.168 (in-sample avg dev_std = 0.337)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.489
Model XAI F1 of binarized graphs for r=0.9 =  0.36401125
Model XAI WIoU of binarized graphs for r=0.9 =  0.24168125000000004
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.58
SUFF++ for r=0.9 class 0 = 0.675 +- 0.147 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.9 class 1 = 0.74 +- 0.147 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.9 class 2 = 0.828 +- 0.147 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.9 all KL = 0.852 +- 0.147 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.9 all L1 = 0.748 +- 0.182 (in-sample avg dev_std = 0.232)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.42
Model XAI F1 of binarized graphs for r=0.3 =  0.6534174999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.52699375
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.318
NEC for r=0.3 class 0 = 0.575 +- 0.272 (in-sample avg dev_std = 0.449)
NEC for r=0.3 class 1 = 0.521 +- 0.272 (in-sample avg dev_std = 0.449)
NEC for r=0.3 class 2 = 0.632 +- 0.272 (in-sample avg dev_std = 0.449)
NEC for r=0.3 all KL = 0.536 +- 0.272 (in-sample avg dev_std = 0.449)
NEC for r=0.3 all L1 = 0.577 +- 0.156 (in-sample avg dev_std = 0.449)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.654
Model XAI F1 of binarized graphs for r=0.6 =  0.56778375
Model XAI WIoU of binarized graphs for r=0.6 =  0.44836624999999997
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.371
NEC for r=0.6 class 0 = 0.567 +- 0.277 (in-sample avg dev_std = 0.477)
NEC for r=0.6 class 1 = 0.563 +- 0.277 (in-sample avg dev_std = 0.477)
NEC for r=0.6 class 2 = 0.669 +- 0.277 (in-sample avg dev_std = 0.477)
NEC for r=0.6 all KL = 0.633 +- 0.277 (in-sample avg dev_std = 0.477)
NEC for r=0.6 all L1 = 0.601 +- 0.166 (in-sample avg dev_std = 0.477)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.924
Model XAI F1 of binarized graphs for r=0.9 =  0.447675
Model XAI WIoU of binarized graphs for r=0.9 =  0.32446624999999996
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.473
NEC for r=0.9 class 0 = 0.604 +- 0.203 (in-sample avg dev_std = 0.541)
NEC for r=0.9 class 1 = 0.51 +- 0.203 (in-sample avg dev_std = 0.541)
NEC for r=0.9 class 2 = 0.548 +- 0.203 (in-sample avg dev_std = 0.541)
NEC for r=0.9 all KL = 0.563 +- 0.203 (in-sample avg dev_std = 0.541)
NEC for r=0.9 all L1 = 0.554 +- 0.153 (in-sample avg dev_std = 0.541)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.936
Model XAI F1 of binarized graphs for r=1.0 =  0.44384
Model XAI WIoU of binarized graphs for r=1.0 =  0.31917124999999996
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.528
NEC for r=1.0 class 0 = 0.592 +- 0.227 (in-sample avg dev_std = 0.625)
NEC for r=1.0 class 1 = 0.455 +- 0.227 (in-sample avg dev_std = 0.625)
NEC for r=1.0 class 2 = 0.55 +- 0.227 (in-sample avg dev_std = 0.625)
NEC for r=1.0 all KL = 0.581 +- 0.227 (in-sample avg dev_std = 0.625)
NEC for r=1.0 all L1 = 0.533 +- 0.169 (in-sample avg dev_std = 0.625)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.425
Model XAI F1 of binarized graphs for r=0.3 =  0.49179624999999993
Model XAI WIoU of binarized graphs for r=0.3 =  0.3739937499999999
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.281
NEC for r=0.3 class 0 = 0.607 +- 0.277 (in-sample avg dev_std = 0.484)
NEC for r=0.3 class 1 = 0.566 +- 0.277 (in-sample avg dev_std = 0.484)
NEC for r=0.3 class 2 = 0.707 +- 0.277 (in-sample avg dev_std = 0.484)
NEC for r=0.3 all KL = 0.641 +- 0.277 (in-sample avg dev_std = 0.484)
NEC for r=0.3 all L1 = 0.626 +- 0.157 (in-sample avg dev_std = 0.484)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.756
Model XAI F1 of binarized graphs for r=0.6 =  0.40788874999999997
Model XAI WIoU of binarized graphs for r=0.6 =  0.291045
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.413
NEC for r=0.6 class 0 = 0.519 +- 0.229 (in-sample avg dev_std = 0.444)
NEC for r=0.6 class 1 = 0.491 +- 0.229 (in-sample avg dev_std = 0.444)
NEC for r=0.6 class 2 = 0.55 +- 0.229 (in-sample avg dev_std = 0.444)
NEC for r=0.6 all KL = 0.443 +- 0.229 (in-sample avg dev_std = 0.444)
NEC for r=0.6 all L1 = 0.52 +- 0.124 (in-sample avg dev_std = 0.444)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.489
Model XAI F1 of binarized graphs for r=0.9 =  0.36401125
Model XAI WIoU of binarized graphs for r=0.9 =  0.24168125000000004
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.493
NEC for r=0.9 class 0 = 0.54 +- 0.289 (in-sample avg dev_std = 0.501)
NEC for r=0.9 class 1 = 0.455 +- 0.289 (in-sample avg dev_std = 0.501)
NEC for r=0.9 class 2 = 0.437 +- 0.289 (in-sample avg dev_std = 0.501)
NEC for r=0.9 all KL = 0.476 +- 0.289 (in-sample avg dev_std = 0.501)
NEC for r=0.9 all L1 = 0.477 +- 0.161 (in-sample avg dev_std = 0.501)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.66
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.25778875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.53
NEC for r=1.0 class 0 = 0.48 +- 0.268 (in-sample avg dev_std = 0.480)
NEC for r=1.0 class 1 = 0.399 +- 0.268 (in-sample avg dev_std = 0.480)
NEC for r=1.0 class 2 = 0.355 +- 0.268 (in-sample avg dev_std = 0.480)
NEC for r=1.0 all KL = 0.405 +- 0.268 (in-sample avg dev_std = 0.480)
NEC for r=1.0 all L1 = 0.411 +- 0.158 (in-sample avg dev_std = 0.480)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 11 14:29:48 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/11/2024 02:29:48 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/11/2024 02:29:48 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/11/2024 02:29:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 02:29:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 02:29:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 02:29:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 02:29:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 02:29:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 02:29:48 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 05/11/2024 02:29:48 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 160...
[0m[1;37mINFO[0m: [1mCheckpoint 160: 
-----------------------------------
Train ACCURACY: 0.9314
Train Loss: 0.3115
ID Validation ACCURACY: 0.9367
ID Validation Loss: 0.3032
ID Test ACCURACY: 0.9260
ID Test Loss: 0.3364
OOD Validation ACCURACY: 0.9037
OOD Validation Loss: 0.4375
OOD Test ACCURACY: 0.5013
OOD Test Loss: 1.2586

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 114...
[0m[1;37mINFO[0m: [1mCheckpoint 114: 
-----------------------------------
Train ACCURACY: 0.9304
Train Loss: 0.3218
ID Validation ACCURACY: 0.9363
ID Validation Loss: 0.3115
ID Test ACCURACY: 0.9260
ID Test Loss: 0.3512
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.4025
OOD Test ACCURACY: 0.6150
OOD Test Loss: 1.1616

[0m[1;37mINFO[0m: [1mChartInfo 0.9260 0.5013 0.9260 0.6150 0.9363 0.9317[0mGOODMotif2(3000)
Data example from id_test: Data(edge_index=[2, 56], x=[16, 1], node_gt=[16], edge_gt=[56], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=16)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([ 988,  973, 1039]))

Gold ratio (id_test) =  tensor(0.3032) +- tensor(0.1592)
F1 for r=0.3 = 0.671
WIoU for r=0.3 = 0.546
F1 for r=0.6 = 0.572
WIoU for r=0.6 = 0.448
F1 for r=0.9 = 0.459
WIoU for r=0.9 = 0.335
F1 for r=1.0 = 0.444
WIoU for r=1.0 = 0.320
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.575
WIoU for r=0.3 = 0.454
F1 for r=0.6 = 0.438
WIoU for r=0.6 = 0.311
F1 for r=0.9 = 0.385
WIoU for r=0.9 = 0.253
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.257


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.429
Model XAI F1 of binarized graphs for r=0.3 =  0.67144375
Model XAI WIoU of binarized graphs for r=0.3 =  0.5457975
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.438
SUFF++ for r=0.3 class 0 = 0.451 +- 0.248 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.3 class 1 = 0.533 +- 0.248 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.3 class 2 = 0.552 +- 0.248 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.3 all KL = 0.562 +- 0.248 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.3 all L1 = 0.512 +- 0.153 (in-sample avg dev_std = 0.463)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.705
Model XAI F1 of binarized graphs for r=0.6 =  0.57189375
Model XAI WIoU of binarized graphs for r=0.6 =  0.4480475
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.636
SUFF++ for r=0.6 class 0 = 0.471 +- 0.236 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.6 class 1 = 0.626 +- 0.236 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.6 class 2 = 0.666 +- 0.236 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.6 all KL = 0.636 +- 0.236 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.6 all L1 = 0.589 +- 0.177 (in-sample avg dev_std = 0.420)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.908
Model XAI F1 of binarized graphs for r=0.9 =  0.45879
Model XAI WIoU of binarized graphs for r=0.9 =  0.33479125
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.859
SUFF++ for r=0.9 class 0 = 0.683 +- 0.180 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 1 = 0.836 +- 0.180 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 2 = 0.828 +- 0.180 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 all KL = 0.85 +- 0.180 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 all L1 = 0.783 +- 0.168 (in-sample avg dev_std = 0.303)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.439
Model XAI F1 of binarized graphs for r=0.3 =  0.57546
Model XAI WIoU of binarized graphs for r=0.3 =  0.45364375
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.496
SUFF++ for r=0.3 class 0 = 0.526 +- 0.270 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.3 class 1 = 0.551 +- 0.270 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.3 class 2 = 0.599 +- 0.270 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.3 all KL = 0.59 +- 0.270 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.3 all L1 = 0.559 +- 0.166 (in-sample avg dev_std = 0.482)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.664
Model XAI F1 of binarized graphs for r=0.6 =  0.43777125000000006
Model XAI WIoU of binarized graphs for r=0.6 =  0.31076
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.685
SUFF++ for r=0.6 class 0 = 0.454 +- 0.267 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 class 1 = 0.662 +- 0.267 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 class 2 = 0.692 +- 0.267 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 all KL = 0.663 +- 0.267 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 all L1 = 0.605 +- 0.190 (in-sample avg dev_std = 0.379)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.683
Model XAI F1 of binarized graphs for r=0.9 =  0.38537750000000004
Model XAI WIoU of binarized graphs for r=0.9 =  0.2533775
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.64
SUFF++ for r=0.9 class 0 = 0.667 +- 0.145 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.9 class 1 = 0.829 +- 0.145 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.9 class 2 = 0.862 +- 0.145 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.9 all KL = 0.857 +- 0.145 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.9 all L1 = 0.788 +- 0.166 (in-sample avg dev_std = 0.242)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.43
Model XAI F1 of binarized graphs for r=0.3 =  0.67144375
Model XAI WIoU of binarized graphs for r=0.3 =  0.5457975
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.32
NEC for r=0.3 class 0 = 0.572 +- 0.293 (in-sample avg dev_std = 0.380)
NEC for r=0.3 class 1 = 0.427 +- 0.293 (in-sample avg dev_std = 0.380)
NEC for r=0.3 class 2 = 0.582 +- 0.293 (in-sample avg dev_std = 0.380)
NEC for r=0.3 all KL = 0.474 +- 0.293 (in-sample avg dev_std = 0.380)
NEC for r=0.3 all L1 = 0.528 +- 0.179 (in-sample avg dev_std = 0.380)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.705
Model XAI F1 of binarized graphs for r=0.6 =  0.57189375
Model XAI WIoU of binarized graphs for r=0.6 =  0.4480475
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.377
NEC for r=0.6 class 0 = 0.589 +- 0.289 (in-sample avg dev_std = 0.436)
NEC for r=0.6 class 1 = 0.483 +- 0.289 (in-sample avg dev_std = 0.436)
NEC for r=0.6 class 2 = 0.644 +- 0.289 (in-sample avg dev_std = 0.436)
NEC for r=0.6 all KL = 0.57 +- 0.289 (in-sample avg dev_std = 0.436)
NEC for r=0.6 all L1 = 0.574 +- 0.170 (in-sample avg dev_std = 0.436)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.909
Model XAI F1 of binarized graphs for r=0.9 =  0.45879
Model XAI WIoU of binarized graphs for r=0.9 =  0.33479125
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.498
NEC for r=0.9 class 0 = 0.619 +- 0.225 (in-sample avg dev_std = 0.585)
NEC for r=0.9 class 1 = 0.497 +- 0.225 (in-sample avg dev_std = 0.585)
NEC for r=0.9 class 2 = 0.545 +- 0.225 (in-sample avg dev_std = 0.585)
NEC for r=0.9 all KL = 0.598 +- 0.225 (in-sample avg dev_std = 0.585)
NEC for r=0.9 all L1 = 0.554 +- 0.155 (in-sample avg dev_std = 0.585)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.935
Model XAI F1 of binarized graphs for r=1.0 =  0.44384
Model XAI WIoU of binarized graphs for r=1.0 =  0.32042000000000004
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.535
NEC for r=1.0 class 0 = 0.577 +- 0.219 (in-sample avg dev_std = 0.627)
NEC for r=1.0 class 1 = 0.446 +- 0.219 (in-sample avg dev_std = 0.627)
NEC for r=1.0 class 2 = 0.564 +- 0.219 (in-sample avg dev_std = 0.627)
NEC for r=1.0 all KL = 0.579 +- 0.219 (in-sample avg dev_std = 0.627)
NEC for r=1.0 all L1 = 0.53 +- 0.164 (in-sample avg dev_std = 0.627)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.439
Model XAI F1 of binarized graphs for r=0.3 =  0.57546
Model XAI WIoU of binarized graphs for r=0.3 =  0.45364375
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.394
NEC for r=0.3 class 0 = 0.586 +- 0.253 (in-sample avg dev_std = 0.484)
NEC for r=0.3 class 1 = 0.564 +- 0.253 (in-sample avg dev_std = 0.484)
NEC for r=0.3 class 2 = 0.655 +- 0.253 (in-sample avg dev_std = 0.484)
NEC for r=0.3 all KL = 0.611 +- 0.253 (in-sample avg dev_std = 0.484)
NEC for r=0.3 all L1 = 0.601 +- 0.133 (in-sample avg dev_std = 0.484)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.664
Model XAI F1 of binarized graphs for r=0.6 =  0.43777125000000006
Model XAI WIoU of binarized graphs for r=0.6 =  0.31076
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.451
NEC for r=0.6 class 0 = 0.605 +- 0.291 (in-sample avg dev_std = 0.515)
NEC for r=0.6 class 1 = 0.512 +- 0.291 (in-sample avg dev_std = 0.515)
NEC for r=0.6 class 2 = 0.599 +- 0.291 (in-sample avg dev_std = 0.515)
NEC for r=0.6 all KL = 0.563 +- 0.291 (in-sample avg dev_std = 0.515)
NEC for r=0.6 all L1 = 0.571 +- 0.159 (in-sample avg dev_std = 0.515)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.683
Model XAI F1 of binarized graphs for r=0.9 =  0.38537750000000004
Model XAI WIoU of binarized graphs for r=0.9 =  0.2533775
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.556
NEC for r=0.9 class 0 = 0.556 +- 0.282 (in-sample avg dev_std = 0.588)
NEC for r=0.9 class 1 = 0.426 +- 0.282 (in-sample avg dev_std = 0.588)
NEC for r=0.9 class 2 = 0.469 +- 0.282 (in-sample avg dev_std = 0.588)
NEC for r=0.9 all KL = 0.535 +- 0.282 (in-sample avg dev_std = 0.588)
NEC for r=0.9 all L1 = 0.482 +- 0.166 (in-sample avg dev_std = 0.588)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.509
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.2574
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.563
NEC for r=1.0 class 0 = 0.509 +- 0.246 (in-sample avg dev_std = 0.504)
NEC for r=1.0 class 1 = 0.421 +- 0.246 (in-sample avg dev_std = 0.504)
NEC for r=1.0 class 2 = 0.379 +- 0.246 (in-sample avg dev_std = 0.504)
NEC for r=1.0 all KL = 0.441 +- 0.246 (in-sample avg dev_std = 0.504)
NEC for r=1.0 all L1 = 0.435 +- 0.147 (in-sample avg dev_std = 0.504)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.57, 0.651, 0.84, 1.0], 'all_L1': [0.509, 0.601, 0.769, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.566, 0.66, 0.829, 1.0], 'all_L1': [0.514, 0.61, 0.75, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.635, 0.665, 0.866, 1.0], 'all_L1': [0.543, 0.573, 0.754, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.549, 0.579, 0.826, 1.0], 'all_L1': [0.506, 0.576, 0.745, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.562, 0.636, 0.85, 1.0], 'all_L1': [0.512, 0.589, 0.783, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.523, 0.59, 0.566, 0.565], 'all_L1': [0.567, 0.591, 0.548, 0.525]}), defaultdict(<class 'list'>, {'all_KL': [0.499, 0.543, 0.539, 0.536], 'all_L1': [0.544, 0.546, 0.541, 0.516]}), defaultdict(<class 'list'>, {'all_KL': [0.451, 0.479, 0.446, 0.513], 'all_L1': [0.523, 0.54, 0.512, 0.513]}), defaultdict(<class 'list'>, {'all_KL': [0.536, 0.633, 0.563, 0.581], 'all_L1': [0.577, 0.601, 0.554, 0.533]}), defaultdict(<class 'list'>, {'all_KL': [0.474, 0.57, 0.598, 0.579], 'all_L1': [0.528, 0.574, 0.554, 0.53]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.603, 0.699, 0.817, 1.0], 'all_L1': [0.581, 0.625, 0.749, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.592, 0.683, 0.836, 1.0], 'all_L1': [0.563, 0.595, 0.765, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.607, 0.649, 0.766, 1.0], 'all_L1': [0.555, 0.55, 0.715, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.553, 0.688, 0.852, 1.0], 'all_L1': [0.525, 0.58, 0.748, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.59, 0.663, 0.857, 1.0], 'all_L1': [0.559, 0.605, 0.788, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.568, 0.582, 0.48, 0.418], 'all_L1': [0.568, 0.58, 0.45, 0.404]}), defaultdict(<class 'list'>, {'all_KL': [0.638, 0.543, 0.474, 0.39], 'all_L1': [0.613, 0.559, 0.474, 0.422]}), defaultdict(<class 'list'>, {'all_KL': [0.579, 0.51, 0.488, 0.471], 'all_L1': [0.594, 0.541, 0.473, 0.435]}), defaultdict(<class 'list'>, {'all_KL': [0.641, 0.443, 0.476, 0.405], 'all_L1': [0.626, 0.52, 0.477, 0.411]}), defaultdict(<class 'list'>, {'all_KL': [0.611, 0.563, 0.535, 0.441], 'all_L1': [0.601, 0.571, 0.482, 0.435]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_test
suff++ class all_L1  =  0.517 +- 0.013, 0.590 +- 0.014, 0.760 +- 0.014, 1.000 +- 0.000
suff++ class all_KL  =  0.576 +- 0.030, 0.638 +- 0.031, 0.842 +- 0.015, 1.000 +- 0.000
suff++_acc_int  =  0.442 +- 0.004, 0.613 +- 0.015, 0.824 +- 0.027
nec class all_L1  =  0.548 +- 0.021, 0.570 +- 0.024, 0.542 +- 0.016, 0.523 +- 0.008
nec class all_KL  =  0.497 +- 0.031, 0.563 +- 0.051, 0.542 +- 0.052, 0.555 +- 0.026
nec_acc_int  =  0.317 +- 0.012, 0.373 +- 0.006, 0.488 +- 0.011, 0.531 +- 0.003

Eval split test
suff++ class all_L1  =  0.557 +- 0.018, 0.591 +- 0.025, 0.753 +- 0.024, 1.000 +- 0.000
suff++ class all_KL  =  0.589 +- 0.019, 0.676 +- 0.018, 0.826 +- 0.033, 1.000 +- 0.000
suff++_acc_int  =  0.499 +- 0.021, 0.651 +- 0.040, 0.646 +- 0.053
nec class all_L1  =  0.600 +- 0.020, 0.554 +- 0.022, 0.471 +- 0.011, 0.421 +- 0.012
nec class all_KL  =  0.607 +- 0.030, 0.528 +- 0.049, 0.491 +- 0.023, 0.425 +- 0.028
nec_acc_int  =  0.360 +- 0.056, 0.433 +- 0.014, 0.524 +- 0.035, 0.559 +- 0.032


 -------------------------------------------------- 
Computing faithfulness

Eval split id_test
Faith. Aritm (L1)= 		  =  0.532 +- 0.007, 0.580 +- 0.013, 0.651 +- 0.012, 0.762 +- 0.004
Faith. Armon (L1)= 		  =  0.531 +- 0.007, 0.580 +- 0.014, 0.633 +- 0.013, 0.687 +- 0.007
Faith. GMean (L1)= 	  =  0.532 +- 0.007, 0.580 +- 0.013, 0.642 +- 0.012, 0.723 +- 0.005
Faith. Aritm (KL)= 		  =  0.536 +- 0.010, 0.601 +- 0.016, 0.692 +- 0.022, 0.777 +- 0.013
Faith. Armon (KL)= 		  =  0.532 +- 0.011, 0.596 +- 0.021, 0.658 +- 0.038, 0.713 +- 0.022
Faith. GMean (KL)= 	  =  0.534 +- 0.010, 0.598 +- 0.018, 0.675 +- 0.030, 0.745 +- 0.018

Eval split test
Faith. Aritm (L1)= 		  =  0.578 +- 0.005, 0.573 +- 0.022, 0.612 +- 0.015, 0.711 +- 0.006
Faith. Armon (L1)= 		  =  0.577 +- 0.006, 0.572 +- 0.022, 0.580 +- 0.013, 0.593 +- 0.012
Faith. GMean (L1)= 	  =  0.578 +- 0.005, 0.572 +- 0.022, 0.596 +- 0.013, 0.649 +- 0.010
Faith. Aritm (KL)= 		  =  0.598 +- 0.010, 0.602 +- 0.027, 0.658 +- 0.023, 0.712 +- 0.014
Faith. Armon (KL)= 		  =  0.597 +- 0.010, 0.592 +- 0.033, 0.615 +- 0.022, 0.596 +- 0.028
Faith. GMean (KL)= 	  =  0.598 +- 0.010, 0.597 +- 0.030, 0.636 +- 0.022, 0.652 +- 0.022
Computed for split load_split = id



Completed in  0:14:56.550462  for GSATGIN GOODMotif2/basis



DONE GSAT GOODMotif2/basis nov

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 11 14:33:05 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 05/11/2024 02:33:06 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 02:33:07 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 02:33:07 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 02:33:07 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 02:33:07 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 02:33:07 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/11/2024 02:33:07 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/11/2024 02:33:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 02:33:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 02:33:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 02:33:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 02:33:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 02:33:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 02:33:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 02:33:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 02:33:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 02:33:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 02:33:07 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 05/11/2024 02:33:07 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 168...
[0m[1;37mINFO[0m: [1mCheckpoint 168: 
-----------------------------------
Train ACCURACY: 0.9710
Train Loss: 0.0888
ID Validation ACCURACY: 0.8913
ID Validation Loss: 0.3578
ID Test ACCURACY: 0.8891
ID Test Loss: 0.3689
OOD Validation ACCURACY: 0.7710
OOD Validation Loss: 0.8283
OOD Test ACCURACY: 0.2787
OOD Test Loss: 5.7327

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 175...
[0m[1;37mINFO[0m: [1mCheckpoint 175: 
-----------------------------------
Train ACCURACY: 0.9678
Train Loss: 0.0980
ID Validation ACCURACY: 0.8826
ID Validation Loss: 0.3955
ID Test ACCURACY: 0.8830
ID Test Loss: 0.3916
OOD Validation ACCURACY: 0.7823
OOD Validation Loss: 0.8443
OOD Test ACCURACY: 0.3099
OOD Test Loss: 7.0050

[0m[1;37mINFO[0m: [1mChartInfo 0.8891 0.2787 0.8830 0.3099 0.8826 0.7823[0mGOODCMNIST(7000)
Data example from id_test: Data(x=[75, 3], edge_index=[2, 1351], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1351], node_perm=[75])
Label distribution from id_test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([657, 814, 676, 706, 676, 663, 688, 748, 702, 670]))
[1;31mERROR[0m: 05/11/2024 02:33:10 PM - utils.py - line 52 : [1mCUDA out of memory. Tried to allocate 1.60 GiB. GPU 1 has a total capacty of 11.77 GiB of which 894.25 MiB is free. Process 1717750 has 6.71 GiB memory in use. Including non-PyTorch memory, this process has 4.19 GiB memory in use. Of the allocated memory 3.25 GiB is allocated by PyTorch, and 41.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0m
  File "/mnt/cimec-storage6/users/steve.azzolin/venv/leci/bin/goodtg", line 33, in <module>
    sys.exit(load_entry_point('graph-ood', 'console_scripts', 'goodtg')())
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/kernel/main.py", line 639, in goodtg
    print(f'#E#{e}')
Time to compute metrics!
The PID of this script is: 1737468

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 11 14:47:03 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 05/11/2024 02:47:03 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 02:47:04 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 02:47:04 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 02:47:04 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 02:47:04 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/11/2024 02:47:04 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/11/2024 02:47:04 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/11/2024 02:47:04 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/11/2024 02:47:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 02:47:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 02:47:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 02:47:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 02:47:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 02:47:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 02:47:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 02:47:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/11/2024 02:47:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/11/2024 02:47:04 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 05/11/2024 02:47:04 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 168...
[0m[1;37mINFO[0m: [1mCheckpoint 168: 
-----------------------------------
Train ACCURACY: 0.9710
Train Loss: 0.0888
ID Validation ACCURACY: 0.8913
ID Validation Loss: 0.3578
ID Test ACCURACY: 0.8891
ID Test Loss: 0.3689
OOD Validation ACCURACY: 0.7710
OOD Validation Loss: 0.8283
OOD Test ACCURACY: 0.2787
OOD Test Loss: 5.7327

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 175...
[0m[1;37mINFO[0m: [1mCheckpoint 175: 
-----------------------------------
Train ACCURACY: 0.9678
Train Loss: 0.0980
ID Validation ACCURACY: 0.8826
ID Validation Loss: 0.3955
ID Test ACCURACY: 0.8830
ID Test Loss: 0.3916
OOD Validation ACCURACY: 0.7823
OOD Validation Loss: 0.8443
OOD Test ACCURACY: 0.3099
OOD Test Loss: 7.0050

[0m[1;37mINFO[0m: [1mChartInfo 0.8891 0.2787 0.8830 0.3099 0.8826 0.7823[0mGOODCMNIST(7000)
Data example from id_test: Data(x=[75, 3], edge_index=[2, 1351], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1351], node_perm=[75])
Label distribution from id_test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([657, 814, 676, 706, 676, 663, 688, 748, 702, 670]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking
[1;31mERROR[0m: 05/11/2024 02:50:09 PM - utils.py - line 52 : [1mCUDA out of memory. Tried to allocate 1.59 GiB. GPU 1 has a total capacty of 11.77 GiB of which 534.25 MiB is free. Process 1717750 has 6.71 GiB memory in use. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 3.24 GiB is allocated by PyTorch, and 418.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0m
  File "/mnt/cimec-storage6/users/steve.azzolin/venv/leci/bin/goodtg", line 33, in <module>
    sys.exit(load_entry_point('graph-ood', 'console_scripts', 'goodtg')())
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/kernel/main.py", line 639, in goodtg
    print(f'#E#{e}')
\n\nTime to compute metrics!
The PID of this script is: 1821284

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun May 12 13:27:39 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/12/2024 01:27:39 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/12/2024 01:28:22 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/12/2024 01:28:38 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/12/2024 01:28:55 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/12/2024 01:29:12 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/12/2024 01:29:33 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/12/2024 01:29:33 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/12/2024 01:29:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/12/2024 01:29:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/12/2024 01:29:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 01:29:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/12/2024 01:29:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 01:29:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/12/2024 01:29:33 PM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 05/12/2024 01:29:33 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 197...
[0m[1;37mINFO[0m: [1mCheckpoint 197: 
-----------------------------------
Train ROC-AUC: 0.9575
Train Loss: 0.1735
ID Validation ROC-AUC: 0.9126
ID Validation Loss: 0.2431
ID Test ROC-AUC: 0.9180
ID Test Loss: 0.2370
OOD Validation ROC-AUC: 0.6443
OOD Validation Loss: 0.5116
OOD Test ROC-AUC: 0.6826
OOD Test Loss: 0.6087

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 54...
[0m[1;37mINFO[0m: [1mCheckpoint 54: 
-----------------------------------
Train ROC-AUC: 0.9308
Train Loss: 0.2188
ID Validation ROC-AUC: 0.9073
ID Validation Loss: 0.2593
ID Test ROC-AUC: 0.9108
ID Test Loss: 0.2562
OOD Validation ROC-AUC: 0.6898
OOD Validation Loss: 0.3322
OOD Test ROC-AUC: 0.7117
OOD Test Loss: 0.5314

[0m[1;37mINFO[0m: [1mChartInfo 0.9180 0.6826 0.9108 0.7117 0.9073 0.6898[0mLBAPcore(11683)
Data example from id_test: Data(x=[33, 39], edge_index=[2, 72], edge_attr=[72, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 72], node_perm=[33])
Label distribution from id_test: (tensor([0., 1.]), tensor([ 1386, 10297]))
[1;34mDEBUG[0m: 05/12/2024 01:29:34 PM : [1mUnbalanced warning for LBAPcore (id_test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 05/12/2024 01:29:43 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.604
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.593
SUFF++ for r=0.3 class 0.0 = 0.699 +- 0.187 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.3 class 1.0 = 0.788 +- 0.187 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.3 all KL = 0.787 +- 0.187 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.3 all L1 = 0.777 +- 0.167 (in-sample avg dev_std = 0.316)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.658
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.662
SUFF++ for r=0.6 class 0.0 = 0.722 +- 0.143 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.6 class 1.0 = 0.801 +- 0.143 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.6 all KL = 0.853 +- 0.143 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.6 all L1 = 0.792 +- 0.144 (in-sample avg dev_std = 0.266)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.714
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.669
SUFF++ for r=0.9 class 0.0 = 0.814 +- 0.101 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.9 class 1.0 = 0.856 +- 0.101 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.9 all KL = 0.93 +- 0.101 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.9 all L1 = 0.851 +- 0.130 (in-sample avg dev_std = 0.168)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.578
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.548
SUFF++ for r=0.3 class 0.0 = 0.73 +- 0.188 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.3 class 1.0 = 0.777 +- 0.188 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.3 all KL = 0.778 +- 0.188 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.3 all L1 = 0.769 +- 0.171 (in-sample avg dev_std = 0.327)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.597
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.566
SUFF++ for r=0.6 class 0.0 = 0.737 +- 0.139 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.6 class 1.0 = 0.779 +- 0.139 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.6 all KL = 0.845 +- 0.139 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.6 all L1 = 0.772 +- 0.147 (in-sample avg dev_std = 0.283)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.575
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.58
SUFF++ for r=0.9 class 0.0 = 0.823 +- 0.084 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.9 class 1.0 = 0.849 +- 0.084 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.9 all KL = 0.936 +- 0.084 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.9 all L1 = 0.845 +- 0.124 (in-sample avg dev_std = 0.164)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.604
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.662
NEC for r=0.3 class 0.0 = 0.293 +- 0.185 (in-sample avg dev_std = 0.263)
NEC for r=0.3 class 1.0 = 0.183 +- 0.185 (in-sample avg dev_std = 0.263)
NEC for r=0.3 all KL = 0.164 +- 0.185 (in-sample avg dev_std = 0.263)
NEC for r=0.3 all L1 = 0.196 +- 0.180 (in-sample avg dev_std = 0.263)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.658
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.691
NEC for r=0.6 class 0.0 = 0.297 +- 0.138 (in-sample avg dev_std = 0.249)
NEC for r=0.6 class 1.0 = 0.178 +- 0.138 (in-sample avg dev_std = 0.249)
NEC for r=0.6 all KL = 0.123 +- 0.138 (in-sample avg dev_std = 0.249)
NEC for r=0.6 all L1 = 0.192 +- 0.149 (in-sample avg dev_std = 0.249)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.715
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.69
NEC for r=0.9 class 0.0 = 0.217 +- 0.089 (in-sample avg dev_std = 0.185)
NEC for r=0.9 class 1.0 = 0.146 +- 0.089 (in-sample avg dev_std = 0.185)
NEC for r=0.9 all KL = 0.074 +- 0.089 (in-sample avg dev_std = 0.185)
NEC for r=0.9 all L1 = 0.155 +- 0.123 (in-sample avg dev_std = 0.185)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.731
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.701
NEC for r=1.0 class 0.0 = 0.186 +- 0.072 (in-sample avg dev_std = 0.165)
NEC for r=1.0 class 1.0 = 0.12 +- 0.072 (in-sample avg dev_std = 0.165)
NEC for r=1.0 all KL = 0.056 +- 0.072 (in-sample avg dev_std = 0.165)
NEC for r=1.0 all L1 = 0.128 +- 0.106 (in-sample avg dev_std = 0.165)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.577
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.578
NEC for r=0.3 class 0.0 = 0.272 +- 0.216 (in-sample avg dev_std = 0.305)
NEC for r=0.3 class 1.0 = 0.207 +- 0.216 (in-sample avg dev_std = 0.305)
NEC for r=0.3 all KL = 0.197 +- 0.216 (in-sample avg dev_std = 0.305)
NEC for r=0.3 all L1 = 0.218 +- 0.189 (in-sample avg dev_std = 0.305)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.598
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.596
NEC for r=0.6 class 0.0 = 0.272 +- 0.147 (in-sample avg dev_std = 0.270)
NEC for r=0.6 class 1.0 = 0.214 +- 0.147 (in-sample avg dev_std = 0.270)
NEC for r=0.6 all KL = 0.148 +- 0.147 (in-sample avg dev_std = 0.270)
NEC for r=0.6 all L1 = 0.224 +- 0.158 (in-sample avg dev_std = 0.270)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.574
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.589
NEC for r=0.9 class 0.0 = 0.22 +- 0.091 (in-sample avg dev_std = 0.212)
NEC for r=0.9 class 1.0 = 0.172 +- 0.091 (in-sample avg dev_std = 0.212)
NEC for r=0.9 all KL = 0.085 +- 0.091 (in-sample avg dev_std = 0.212)
NEC for r=0.9 all L1 = 0.18 +- 0.125 (in-sample avg dev_std = 0.212)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.573
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.584
NEC for r=1.0 class 0.0 = 0.197 +- 0.088 (in-sample avg dev_std = 0.194)
NEC for r=1.0 class 1.0 = 0.149 +- 0.088 (in-sample avg dev_std = 0.194)
NEC for r=1.0 all KL = 0.073 +- 0.088 (in-sample avg dev_std = 0.194)
NEC for r=1.0 all L1 = 0.157 +- 0.118 (in-sample avg dev_std = 0.194)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun May 12 13:33:00 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/12/2024 01:33:00 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/12/2024 01:33:41 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/12/2024 01:33:56 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/12/2024 01:34:11 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/12/2024 01:34:28 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/12/2024 01:34:50 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/12/2024 01:34:50 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/12/2024 01:34:50 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/12/2024 01:34:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/12/2024 01:34:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 01:34:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/12/2024 01:34:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 01:34:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/12/2024 01:34:50 PM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 05/12/2024 01:34:51 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 187...
[0m[1;37mINFO[0m: [1mCheckpoint 187: 
-----------------------------------
Train ROC-AUC: 0.9581
Train Loss: 0.1675
ID Validation ROC-AUC: 0.9155
ID Validation Loss: 0.2388
ID Test ROC-AUC: 0.9181
ID Test Loss: 0.2360
OOD Validation ROC-AUC: 0.6422
OOD Validation Loss: 0.5090
OOD Test ROC-AUC: 0.6891
OOD Test Loss: 0.6078

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 43...
[0m[1;37mINFO[0m: [1mCheckpoint 43: 
-----------------------------------
Train ROC-AUC: 0.9226
Train Loss: 0.2146
ID Validation ROC-AUC: 0.8997
ID Validation Loss: 0.2460
ID Test ROC-AUC: 0.9051
ID Test Loss: 0.2424
OOD Validation ROC-AUC: 0.6819
OOD Validation Loss: 0.3340
OOD Test ROC-AUC: 0.6983
OOD Test Loss: 0.4973

[0m[1;37mINFO[0m: [1mChartInfo 0.9181 0.6891 0.9051 0.6983 0.8997 0.6819[0mLBAPcore(11683)
Data example from id_test: Data(x=[33, 39], edge_index=[2, 72], edge_attr=[72, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 72], node_perm=[33])
Label distribution from id_test: (tensor([0., 1.]), tensor([ 1386, 10297]))
[1;34mDEBUG[0m: 05/12/2024 01:34:51 PM : [1mUnbalanced warning for LBAPcore (id_test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 05/12/2024 01:34:58 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.645
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.595
SUFF++ for r=0.3 class 0.0 = 0.746 +- 0.209 (in-sample avg dev_std = 0.306)
SUFF++ for r=0.3 class 1.0 = 0.828 +- 0.209 (in-sample avg dev_std = 0.306)
SUFF++ for r=0.3 all KL = 0.799 +- 0.209 (in-sample avg dev_std = 0.306)
SUFF++ for r=0.3 all L1 = 0.818 +- 0.178 (in-sample avg dev_std = 0.306)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.676
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.613
SUFF++ for r=0.6 class 0.0 = 0.722 +- 0.165 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.6 class 1.0 = 0.792 +- 0.165 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.6 all KL = 0.833 +- 0.165 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.6 all L1 = 0.783 +- 0.162 (in-sample avg dev_std = 0.283)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.664
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.647
SUFF++ for r=0.9 class 0.0 = 0.812 +- 0.140 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.9 class 1.0 = 0.805 +- 0.140 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.9 all KL = 0.897 +- 0.140 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.9 all L1 = 0.806 +- 0.157 (in-sample avg dev_std = 0.221)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.517
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.53
SUFF++ for r=0.3 class 0.0 = 0.781 +- 0.227 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.3 class 1.0 = 0.781 +- 0.227 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.3 all KL = 0.766 +- 0.227 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.3 all L1 = 0.781 +- 0.192 (in-sample avg dev_std = 0.339)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.527
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.53
SUFF++ for r=0.6 class 0.0 = 0.748 +- 0.180 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.6 class 1.0 = 0.754 +- 0.180 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.6 all KL = 0.809 +- 0.180 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.6 all L1 = 0.753 +- 0.175 (in-sample avg dev_std = 0.311)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.531
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.549
SUFF++ for r=0.9 class 0.0 = 0.797 +- 0.130 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.9 class 1.0 = 0.794 +- 0.130 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.9 all KL = 0.9 +- 0.130 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.9 all L1 = 0.794 +- 0.156 (in-sample avg dev_std = 0.219)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.645
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.662
NEC for r=0.3 class 0.0 = 0.304 +- 0.212 (in-sample avg dev_std = 0.278)
NEC for r=0.3 class 1.0 = 0.159 +- 0.212 (in-sample avg dev_std = 0.278)
NEC for r=0.3 all KL = 0.177 +- 0.212 (in-sample avg dev_std = 0.278)
NEC for r=0.3 all L1 = 0.176 +- 0.183 (in-sample avg dev_std = 0.278)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.675
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.65
NEC for r=0.6 class 0.0 = 0.3 +- 0.156 (in-sample avg dev_std = 0.268)
NEC for r=0.6 class 1.0 = 0.199 +- 0.156 (in-sample avg dev_std = 0.268)
NEC for r=0.6 all KL = 0.153 +- 0.156 (in-sample avg dev_std = 0.268)
NEC for r=0.6 all L1 = 0.211 +- 0.159 (in-sample avg dev_std = 0.268)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.664
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.636
NEC for r=0.9 class 0.0 = 0.238 +- 0.123 (in-sample avg dev_std = 0.237)
NEC for r=0.9 class 1.0 = 0.192 +- 0.123 (in-sample avg dev_std = 0.237)
NEC for r=0.9 all KL = 0.106 +- 0.123 (in-sample avg dev_std = 0.237)
NEC for r=0.9 all L1 = 0.198 +- 0.142 (in-sample avg dev_std = 0.237)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.678
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.638
NEC for r=1.0 class 0.0 = 0.21 +- 0.121 (in-sample avg dev_std = 0.225)
NEC for r=1.0 class 1.0 = 0.171 +- 0.121 (in-sample avg dev_std = 0.225)
NEC for r=1.0 all KL = 0.089 +- 0.121 (in-sample avg dev_std = 0.225)
NEC for r=1.0 all L1 = 0.175 +- 0.140 (in-sample avg dev_std = 0.225)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.517
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.567
NEC for r=0.3 class 0.0 = 0.26 +- 0.249 (in-sample avg dev_std = 0.314)
NEC for r=0.3 class 1.0 = 0.219 +- 0.249 (in-sample avg dev_std = 0.314)
NEC for r=0.3 all KL = 0.231 +- 0.249 (in-sample avg dev_std = 0.314)
NEC for r=0.3 all L1 = 0.226 +- 0.207 (in-sample avg dev_std = 0.314)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.528
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.567
NEC for r=0.6 class 0.0 = 0.272 +- 0.192 (in-sample avg dev_std = 0.301)
NEC for r=0.6 class 1.0 = 0.245 +- 0.192 (in-sample avg dev_std = 0.301)
NEC for r=0.6 all KL = 0.189 +- 0.192 (in-sample avg dev_std = 0.301)
NEC for r=0.6 all L1 = 0.25 +- 0.172 (in-sample avg dev_std = 0.301)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.531
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.57
NEC for r=0.9 class 0.0 = 0.241 +- 0.137 (in-sample avg dev_std = 0.264)
NEC for r=0.9 class 1.0 = 0.231 +- 0.137 (in-sample avg dev_std = 0.264)
NEC for r=0.9 all KL = 0.125 +- 0.137 (in-sample avg dev_std = 0.264)
NEC for r=0.9 all L1 = 0.232 +- 0.148 (in-sample avg dev_std = 0.264)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.53
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.563
NEC for r=1.0 class 0.0 = 0.215 +- 0.123 (in-sample avg dev_std = 0.243)
NEC for r=1.0 class 1.0 = 0.204 +- 0.123 (in-sample avg dev_std = 0.243)
NEC for r=1.0 all KL = 0.101 +- 0.123 (in-sample avg dev_std = 0.243)
NEC for r=1.0 all L1 = 0.206 +- 0.142 (in-sample avg dev_std = 0.243)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun May 12 13:38:09 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/12/2024 01:38:09 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/12/2024 01:38:47 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/12/2024 01:39:01 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/12/2024 01:39:19 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/12/2024 01:39:38 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/12/2024 01:39:57 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/12/2024 01:39:57 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/12/2024 01:39:57 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/12/2024 01:39:57 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/12/2024 01:39:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 01:39:57 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/12/2024 01:39:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 01:39:57 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/12/2024 01:39:57 PM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 05/12/2024 01:39:57 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 172...
[0m[1;37mINFO[0m: [1mCheckpoint 172: 
-----------------------------------
Train ROC-AUC: 0.9565
Train Loss: 0.1673
ID Validation ROC-AUC: 0.9166
ID Validation Loss: 0.2335
ID Test ROC-AUC: 0.9184
ID Test Loss: 0.2312
OOD Validation ROC-AUC: 0.6443
OOD Validation Loss: 0.4868
OOD Test ROC-AUC: 0.6885
OOD Test Loss: 0.5753

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 13...
[0m[1;37mINFO[0m: [1mCheckpoint 13: 
-----------------------------------
Train ROC-AUC: 0.8916
Train Loss: 0.2426
ID Validation ROC-AUC: 0.8768
ID Validation Loss: 0.2559
ID Test ROC-AUC: 0.8832
ID Test Loss: 0.2531
OOD Validation ROC-AUC: 0.6829
OOD Validation Loss: 0.2941
OOD Test ROC-AUC: 0.6934
OOD Test Loss: 0.4478

[0m[1;37mINFO[0m: [1mChartInfo 0.9184 0.6885 0.8832 0.6934 0.8768 0.6829[0mLBAPcore(11683)
Data example from id_test: Data(x=[33, 39], edge_index=[2, 72], edge_attr=[72, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 72], node_perm=[33])
Label distribution from id_test: (tensor([0., 1.]), tensor([ 1386, 10297]))
[1;34mDEBUG[0m: 05/12/2024 01:39:57 PM : [1mUnbalanced warning for LBAPcore (id_test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 05/12/2024 01:40:07 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.49
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.529
SUFF++ for r=0.3 class 0.0 = 0.572 +- 0.219 (in-sample avg dev_std = 0.527)
SUFF++ for r=0.3 class 1.0 = 0.575 +- 0.219 (in-sample avg dev_std = 0.527)
SUFF++ for r=0.3 all KL = 0.623 +- 0.219 (in-sample avg dev_std = 0.527)
SUFF++ for r=0.3 all L1 = 0.575 +- 0.145 (in-sample avg dev_std = 0.527)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.524
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.509
SUFF++ for r=0.6 class 0.0 = 0.693 +- 0.185 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.6 class 1.0 = 0.648 +- 0.185 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.6 all KL = 0.76 +- 0.185 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.6 all L1 = 0.654 +- 0.158 (in-sample avg dev_std = 0.416)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.57
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.561
SUFF++ for r=0.9 class 0.0 = 0.811 +- 0.122 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 class 1.0 = 0.746 +- 0.122 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 all KL = 0.893 +- 0.122 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 all L1 = 0.753 +- 0.140 (in-sample avg dev_std = 0.255)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.526
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.531
SUFF++ for r=0.3 class 0.0 = 0.582 +- 0.216 (in-sample avg dev_std = 0.499)
SUFF++ for r=0.3 class 1.0 = 0.589 +- 0.216 (in-sample avg dev_std = 0.499)
SUFF++ for r=0.3 all KL = 0.654 +- 0.216 (in-sample avg dev_std = 0.499)
SUFF++ for r=0.3 all L1 = 0.588 +- 0.150 (in-sample avg dev_std = 0.499)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.529
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.525
SUFF++ for r=0.6 class 0.0 = 0.686 +- 0.184 (in-sample avg dev_std = 0.395)
SUFF++ for r=0.6 class 1.0 = 0.664 +- 0.184 (in-sample avg dev_std = 0.395)
SUFF++ for r=0.6 all KL = 0.773 +- 0.184 (in-sample avg dev_std = 0.395)
SUFF++ for r=0.6 all L1 = 0.668 +- 0.159 (in-sample avg dev_std = 0.395)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.562
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.537
SUFF++ for r=0.9 class 0.0 = 0.81 +- 0.100 (in-sample avg dev_std = 0.215)
SUFF++ for r=0.9 class 1.0 = 0.788 +- 0.100 (in-sample avg dev_std = 0.215)
SUFF++ for r=0.9 all KL = 0.919 +- 0.100 (in-sample avg dev_std = 0.215)
SUFF++ for r=0.9 all L1 = 0.792 +- 0.132 (in-sample avg dev_std = 0.215)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.488
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.576
NEC for r=0.3 class 0.0 = 0.388 +- 0.247 (in-sample avg dev_std = 0.440)
NEC for r=0.3 class 1.0 = 0.339 +- 0.247 (in-sample avg dev_std = 0.440)
NEC for r=0.3 all KL = 0.278 +- 0.247 (in-sample avg dev_std = 0.440)
NEC for r=0.3 all L1 = 0.344 +- 0.194 (in-sample avg dev_std = 0.440)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.524
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.605
NEC for r=0.6 class 0.0 = 0.318 +- 0.189 (in-sample avg dev_std = 0.366)
NEC for r=0.6 class 1.0 = 0.274 +- 0.189 (in-sample avg dev_std = 0.366)
NEC for r=0.6 all KL = 0.18 +- 0.189 (in-sample avg dev_std = 0.366)
NEC for r=0.6 all L1 = 0.28 +- 0.165 (in-sample avg dev_std = 0.366)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.57
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.591
NEC for r=0.9 class 0.0 = 0.231 +- 0.114 (in-sample avg dev_std = 0.255)
NEC for r=0.9 class 1.0 = 0.219 +- 0.114 (in-sample avg dev_std = 0.255)
NEC for r=0.9 all KL = 0.094 +- 0.114 (in-sample avg dev_std = 0.255)
NEC for r=0.9 all L1 = 0.22 +- 0.132 (in-sample avg dev_std = 0.255)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.591
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.61
NEC for r=1.0 class 0.0 = 0.195 +- 0.092 (in-sample avg dev_std = 0.230)
NEC for r=1.0 class 1.0 = 0.194 +- 0.092 (in-sample avg dev_std = 0.230)
NEC for r=1.0 all KL = 0.071 +- 0.092 (in-sample avg dev_std = 0.230)
NEC for r=1.0 all L1 = 0.194 +- 0.114 (in-sample avg dev_std = 0.230)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.526
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.557
NEC for r=0.3 class 0.0 = 0.384 +- 0.246 (in-sample avg dev_std = 0.432)
NEC for r=0.3 class 1.0 = 0.368 +- 0.246 (in-sample avg dev_std = 0.432)
NEC for r=0.3 all KL = 0.296 +- 0.246 (in-sample avg dev_std = 0.432)
NEC for r=0.3 all L1 = 0.37 +- 0.184 (in-sample avg dev_std = 0.432)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.53
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.576
NEC for r=0.6 class 0.0 = 0.32 +- 0.197 (in-sample avg dev_std = 0.358)
NEC for r=0.6 class 1.0 = 0.293 +- 0.197 (in-sample avg dev_std = 0.358)
NEC for r=0.6 all KL = 0.195 +- 0.197 (in-sample avg dev_std = 0.358)
NEC for r=0.6 all L1 = 0.298 +- 0.178 (in-sample avg dev_std = 0.358)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.562
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.572
NEC for r=0.9 class 0.0 = 0.229 +- 0.127 (in-sample avg dev_std = 0.260)
NEC for r=0.9 class 1.0 = 0.23 +- 0.127 (in-sample avg dev_std = 0.260)
NEC for r=0.9 all KL = 0.104 +- 0.127 (in-sample avg dev_std = 0.260)
NEC for r=0.9 all L1 = 0.23 +- 0.140 (in-sample avg dev_std = 0.260)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.565
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.582
NEC for r=1.0 class 0.0 = 0.21 +- 0.106 (in-sample avg dev_std = 0.235)
NEC for r=1.0 class 1.0 = 0.205 +- 0.106 (in-sample avg dev_std = 0.235)
NEC for r=1.0 all KL = 0.082 +- 0.106 (in-sample avg dev_std = 0.235)
NEC for r=1.0 all L1 = 0.205 +- 0.126 (in-sample avg dev_std = 0.235)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun May 12 13:43:26 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/12/2024 01:43:27 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/12/2024 01:44:09 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/12/2024 01:44:19 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/12/2024 01:44:35 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/12/2024 01:44:57 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/12/2024 01:45:15 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/12/2024 01:45:15 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/12/2024 01:45:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/12/2024 01:45:15 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/12/2024 01:45:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 01:45:15 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/12/2024 01:45:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 01:45:15 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/12/2024 01:45:15 PM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 05/12/2024 01:45:15 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 185...
[0m[1;37mINFO[0m: [1mCheckpoint 185: 
-----------------------------------
Train ROC-AUC: 0.9582
Train Loss: 0.1732
ID Validation ROC-AUC: 0.9167
ID Validation Loss: 0.2422
ID Test ROC-AUC: 0.9192
ID Test Loss: 0.2373
OOD Validation ROC-AUC: 0.6602
OOD Validation Loss: 0.5268
OOD Test ROC-AUC: 0.6848
OOD Test Loss: 0.6351

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 15...
[0m[1;37mINFO[0m: [1mCheckpoint 15: 
-----------------------------------
Train ROC-AUC: 0.8939
Train Loss: 0.2644
ID Validation ROC-AUC: 0.8796
ID Validation Loss: 0.2781
ID Test ROC-AUC: 0.8853
ID Test Loss: 0.2732
OOD Validation ROC-AUC: 0.6941
OOD Validation Loss: 0.3916
OOD Test ROC-AUC: 0.6881
OOD Test Loss: 0.4866

[0m[1;37mINFO[0m: [1mChartInfo 0.9192 0.6848 0.8853 0.6881 0.8796 0.6941[0mLBAPcore(11683)
Data example from id_test: Data(x=[33, 39], edge_index=[2, 72], edge_attr=[72, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 72], node_perm=[33])
Label distribution from id_test: (tensor([0., 1.]), tensor([ 1386, 10297]))
[1;34mDEBUG[0m: 05/12/2024 01:45:15 PM : [1mUnbalanced warning for LBAPcore (id_test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 05/12/2024 01:45:25 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.458
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.457
SUFF++ for r=0.3 class 0.0 = 0.649 +- 0.246 (in-sample avg dev_std = 0.552)
SUFF++ for r=0.3 class 1.0 = 0.601 +- 0.246 (in-sample avg dev_std = 0.552)
SUFF++ for r=0.3 all KL = 0.572 +- 0.246 (in-sample avg dev_std = 0.552)
SUFF++ for r=0.3 all L1 = 0.607 +- 0.164 (in-sample avg dev_std = 0.552)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.458
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.462
SUFF++ for r=0.6 class 0.0 = 0.718 +- 0.186 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.6 class 1.0 = 0.672 +- 0.186 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.6 all KL = 0.747 +- 0.186 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.6 all L1 = 0.678 +- 0.149 (in-sample avg dev_std = 0.401)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.445
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.444
SUFF++ for r=0.9 class 0.0 = 0.774 +- 0.164 (in-sample avg dev_std = 0.302)
SUFF++ for r=0.9 class 1.0 = 0.741 +- 0.164 (in-sample avg dev_std = 0.302)
SUFF++ for r=0.9 all KL = 0.848 +- 0.164 (in-sample avg dev_std = 0.302)
SUFF++ for r=0.9 all L1 = 0.745 +- 0.158 (in-sample avg dev_std = 0.302)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.493
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.45
SUFF++ for r=0.3 class 0.0 = 0.657 +- 0.246 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.3 class 1.0 = 0.621 +- 0.246 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.3 all KL = 0.596 +- 0.246 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.3 all L1 = 0.627 +- 0.173 (in-sample avg dev_std = 0.532)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.474
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.459
SUFF++ for r=0.6 class 0.0 = 0.701 +- 0.188 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.6 class 1.0 = 0.671 +- 0.188 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.6 all KL = 0.754 +- 0.188 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.6 all L1 = 0.676 +- 0.153 (in-sample avg dev_std = 0.397)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.428
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.462
SUFF++ for r=0.9 class 0.0 = 0.801 +- 0.150 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.9 class 1.0 = 0.753 +- 0.150 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.9 all KL = 0.87 +- 0.150 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.9 all L1 = 0.761 +- 0.156 (in-sample avg dev_std = 0.272)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.459
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.474
NEC for r=0.3 class 0.0 = 0.331 +- 0.253 (in-sample avg dev_std = 0.414)
NEC for r=0.3 class 1.0 = 0.31 +- 0.253 (in-sample avg dev_std = 0.414)
NEC for r=0.3 all KL = 0.298 +- 0.253 (in-sample avg dev_std = 0.414)
NEC for r=0.3 all L1 = 0.312 +- 0.200 (in-sample avg dev_std = 0.414)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.459
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.476
NEC for r=0.6 class 0.0 = 0.275 +- 0.182 (in-sample avg dev_std = 0.350)
NEC for r=0.6 class 1.0 = 0.273 +- 0.182 (in-sample avg dev_std = 0.350)
NEC for r=0.6 all KL = 0.196 +- 0.182 (in-sample avg dev_std = 0.350)
NEC for r=0.6 all L1 = 0.273 +- 0.155 (in-sample avg dev_std = 0.350)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.445
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.459
NEC for r=0.9 class 0.0 = 0.258 +- 0.158 (in-sample avg dev_std = 0.325)
NEC for r=0.9 class 1.0 = 0.259 +- 0.158 (in-sample avg dev_std = 0.325)
NEC for r=0.9 all KL = 0.16 +- 0.158 (in-sample avg dev_std = 0.325)
NEC for r=0.9 all L1 = 0.259 +- 0.143 (in-sample avg dev_std = 0.325)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.441
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.454
NEC for r=1.0 class 0.0 = 0.233 +- 0.140 (in-sample avg dev_std = 0.316)
NEC for r=1.0 class 1.0 = 0.249 +- 0.140 (in-sample avg dev_std = 0.316)
NEC for r=1.0 all KL = 0.145 +- 0.140 (in-sample avg dev_std = 0.316)
NEC for r=1.0 all L1 = 0.247 +- 0.131 (in-sample avg dev_std = 0.316)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.493
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.49
NEC for r=0.3 class 0.0 = 0.337 +- 0.258 (in-sample avg dev_std = 0.416)
NEC for r=0.3 class 1.0 = 0.32 +- 0.258 (in-sample avg dev_std = 0.416)
NEC for r=0.3 all KL = 0.319 +- 0.258 (in-sample avg dev_std = 0.416)
NEC for r=0.3 all L1 = 0.323 +- 0.201 (in-sample avg dev_std = 0.416)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.475
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.455
NEC for r=0.6 class 0.0 = 0.284 +- 0.183 (in-sample avg dev_std = 0.349)
NEC for r=0.6 class 1.0 = 0.29 +- 0.183 (in-sample avg dev_std = 0.349)
NEC for r=0.6 all KL = 0.203 +- 0.183 (in-sample avg dev_std = 0.349)
NEC for r=0.6 all L1 = 0.289 +- 0.155 (in-sample avg dev_std = 0.349)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.428
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.438
NEC for r=0.9 class 0.0 = 0.236 +- 0.152 (in-sample avg dev_std = 0.320)
NEC for r=0.9 class 1.0 = 0.281 +- 0.152 (in-sample avg dev_std = 0.320)
NEC for r=0.9 all KL = 0.163 +- 0.152 (in-sample avg dev_std = 0.320)
NEC for r=0.9 all L1 = 0.273 +- 0.149 (in-sample avg dev_std = 0.320)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.418
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.428
NEC for r=1.0 class 0.0 = 0.22 +- 0.144 (in-sample avg dev_std = 0.309)
NEC for r=1.0 class 1.0 = 0.264 +- 0.144 (in-sample avg dev_std = 0.309)
NEC for r=1.0 all KL = 0.148 +- 0.144 (in-sample avg dev_std = 0.309)
NEC for r=1.0 all L1 = 0.257 +- 0.144 (in-sample avg dev_std = 0.309)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun May 12 13:48:49 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/12/2024 01:48:49 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/12/2024 01:49:29 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/12/2024 01:49:39 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/12/2024 01:49:53 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/12/2024 01:50:16 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/12/2024 01:50:34 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/12/2024 01:50:34 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/12/2024 01:50:34 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/12/2024 01:50:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/12/2024 01:50:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 01:50:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/12/2024 01:50:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 01:50:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/12/2024 01:50:34 PM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 05/12/2024 01:50:34 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 173...
[0m[1;37mINFO[0m: [1mCheckpoint 173: 
-----------------------------------
Train ROC-AUC: 0.9582
Train Loss: 0.1714
ID Validation ROC-AUC: 0.9187
ID Validation Loss: 0.2342
ID Test ROC-AUC: 0.9179
ID Test Loss: 0.2354
OOD Validation ROC-AUC: 0.6444
OOD Validation Loss: 0.5164
OOD Test ROC-AUC: 0.6886
OOD Test Loss: 0.5929

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 43...
[0m[1;37mINFO[0m: [1mCheckpoint 43: 
-----------------------------------
Train ROC-AUC: 0.9287
Train Loss: 0.2120
ID Validation ROC-AUC: 0.9078
ID Validation Loss: 0.2413
ID Test ROC-AUC: 0.9121
ID Test Loss: 0.2387
OOD Validation ROC-AUC: 0.6847
OOD Validation Loss: 0.3180
OOD Test ROC-AUC: 0.7131
OOD Test Loss: 0.4739

[0m[1;37mINFO[0m: [1mChartInfo 0.9179 0.6886 0.9121 0.7131 0.9078 0.6847[0mLBAPcore(11683)
Data example from id_test: Data(x=[33, 39], edge_index=[2, 72], edge_attr=[72, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 72], node_perm=[33])
Label distribution from id_test: (tensor([0., 1.]), tensor([ 1386, 10297]))
[1;34mDEBUG[0m: 05/12/2024 01:50:34 PM : [1mUnbalanced warning for LBAPcore (id_test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 05/12/2024 01:50:39 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.548
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.542
SUFF++ for r=0.3 class 0.0 = 0.723 +- 0.217 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.3 class 1.0 = 0.763 +- 0.217 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.3 all KL = 0.757 +- 0.217 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.3 all L1 = 0.759 +- 0.196 (in-sample avg dev_std = 0.351)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.604
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.564
SUFF++ for r=0.6 class 0.0 = 0.772 +- 0.148 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.6 class 1.0 = 0.825 +- 0.148 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.6 all KL = 0.866 +- 0.148 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.6 all L1 = 0.819 +- 0.149 (in-sample avg dev_std = 0.258)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.644
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.594
SUFF++ for r=0.9 class 0.0 = 0.857 +- 0.110 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.9 class 1.0 = 0.891 +- 0.110 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.9 all KL = 0.939 +- 0.110 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.9 all L1 = 0.887 +- 0.125 (in-sample avg dev_std = 0.156)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.507
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.505
SUFF++ for r=0.3 class 0.0 = 0.718 +- 0.236 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.3 class 1.0 = 0.724 +- 0.236 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.3 all KL = 0.716 +- 0.236 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.3 all L1 = 0.723 +- 0.195 (in-sample avg dev_std = 0.396)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.517
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.519
SUFF++ for r=0.6 class 0.0 = 0.787 +- 0.165 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.6 class 1.0 = 0.797 +- 0.165 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.6 all KL = 0.849 +- 0.165 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.6 all L1 = 0.795 +- 0.161 (in-sample avg dev_std = 0.289)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.554
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.531
SUFF++ for r=0.9 class 0.0 = 0.878 +- 0.108 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.9 class 1.0 = 0.877 +- 0.108 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.9 all KL = 0.94 +- 0.108 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.9 all L1 = 0.877 +- 0.131 (in-sample avg dev_std = 0.169)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.548
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.564
NEC for r=0.3 class 0.0 = 0.285 +- 0.221 (in-sample avg dev_std = 0.308)
NEC for r=0.3 class 1.0 = 0.202 +- 0.221 (in-sample avg dev_std = 0.308)
NEC for r=0.3 all KL = 0.194 +- 0.221 (in-sample avg dev_std = 0.308)
NEC for r=0.3 all L1 = 0.212 +- 0.199 (in-sample avg dev_std = 0.308)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.604
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.608
NEC for r=0.6 class 0.0 = 0.218 +- 0.142 (in-sample avg dev_std = 0.224)
NEC for r=0.6 class 1.0 = 0.151 +- 0.142 (in-sample avg dev_std = 0.224)
NEC for r=0.6 all KL = 0.109 +- 0.142 (in-sample avg dev_std = 0.224)
NEC for r=0.6 all L1 = 0.159 +- 0.142 (in-sample avg dev_std = 0.224)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.644
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.61
NEC for r=0.9 class 0.0 = 0.152 +- 0.103 (in-sample avg dev_std = 0.182)
NEC for r=0.9 class 1.0 = 0.109 +- 0.103 (in-sample avg dev_std = 0.182)
NEC for r=0.9 all KL = 0.065 +- 0.103 (in-sample avg dev_std = 0.182)
NEC for r=0.9 all L1 = 0.114 +- 0.113 (in-sample avg dev_std = 0.182)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.655
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.621
NEC for r=1.0 class 0.0 = 0.134 +- 0.082 (in-sample avg dev_std = 0.158)
NEC for r=1.0 class 1.0 = 0.095 +- 0.082 (in-sample avg dev_std = 0.158)
NEC for r=1.0 all KL = 0.051 +- 0.082 (in-sample avg dev_std = 0.158)
NEC for r=1.0 all L1 = 0.099 +- 0.099 (in-sample avg dev_std = 0.158)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.506
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.525
NEC for r=0.3 class 0.0 = 0.245 +- 0.224 (in-sample avg dev_std = 0.318)
NEC for r=0.3 class 1.0 = 0.24 +- 0.224 (in-sample avg dev_std = 0.318)
NEC for r=0.3 all KL = 0.222 +- 0.224 (in-sample avg dev_std = 0.318)
NEC for r=0.3 all L1 = 0.241 +- 0.197 (in-sample avg dev_std = 0.318)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.516
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.548
NEC for r=0.6 class 0.0 = 0.218 +- 0.154 (in-sample avg dev_std = 0.251)
NEC for r=0.6 class 1.0 = 0.187 +- 0.154 (in-sample avg dev_std = 0.251)
NEC for r=0.6 all KL = 0.132 +- 0.154 (in-sample avg dev_std = 0.251)
NEC for r=0.6 all L1 = 0.192 +- 0.157 (in-sample avg dev_std = 0.251)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.554
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.549
NEC for r=0.9 class 0.0 = 0.151 +- 0.110 (in-sample avg dev_std = 0.200)
NEC for r=0.9 class 1.0 = 0.141 +- 0.110 (in-sample avg dev_std = 0.200)
NEC for r=0.9 all KL = 0.078 +- 0.110 (in-sample avg dev_std = 0.200)
NEC for r=0.9 all L1 = 0.142 +- 0.127 (in-sample avg dev_std = 0.200)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.554
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.539
NEC for r=1.0 class 0.0 = 0.136 +- 0.106 (in-sample avg dev_std = 0.186)
NEC for r=1.0 class 1.0 = 0.124 +- 0.106 (in-sample avg dev_std = 0.186)
NEC for r=1.0 all KL = 0.068 +- 0.106 (in-sample avg dev_std = 0.186)
NEC for r=1.0 all L1 = 0.126 +- 0.124 (in-sample avg dev_std = 0.186)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.787, 0.853, 0.93, 1.0], 'all_L1': [0.777, 0.792, 0.851, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.799, 0.833, 0.897, 1.0], 'all_L1': [0.818, 0.783, 0.806, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.623, 0.76, 0.893, 1.0], 'all_L1': [0.575, 0.654, 0.753, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.572, 0.747, 0.848, 1.0], 'all_L1': [0.607, 0.678, 0.745, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.757, 0.866, 0.939, 1.0], 'all_L1': [0.759, 0.819, 0.887, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.164, 0.123, 0.074, 0.056], 'all_L1': [0.196, 0.192, 0.155, 0.128]}), defaultdict(<class 'list'>, {'all_KL': [0.177, 0.153, 0.106, 0.089], 'all_L1': [0.176, 0.211, 0.198, 0.175]}), defaultdict(<class 'list'>, {'all_KL': [0.278, 0.18, 0.094, 0.071], 'all_L1': [0.344, 0.28, 0.22, 0.194]}), defaultdict(<class 'list'>, {'all_KL': [0.298, 0.196, 0.16, 0.145], 'all_L1': [0.312, 0.273, 0.259, 0.247]}), defaultdict(<class 'list'>, {'all_KL': [0.194, 0.109, 0.065, 0.051], 'all_L1': [0.212, 0.159, 0.114, 0.099]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.778, 0.845, 0.936, 1.0], 'all_L1': [0.769, 0.772, 0.845, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.766, 0.809, 0.9, 1.0], 'all_L1': [0.781, 0.753, 0.794, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.654, 0.773, 0.919, 1.0], 'all_L1': [0.588, 0.668, 0.792, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.596, 0.754, 0.87, 1.0], 'all_L1': [0.627, 0.676, 0.761, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.716, 0.849, 0.94, 1.0], 'all_L1': [0.723, 0.795, 0.877, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.197, 0.148, 0.085, 0.073], 'all_L1': [0.218, 0.224, 0.18, 0.157]}), defaultdict(<class 'list'>, {'all_KL': [0.231, 0.189, 0.125, 0.101], 'all_L1': [0.226, 0.25, 0.232, 0.206]}), defaultdict(<class 'list'>, {'all_KL': [0.296, 0.195, 0.104, 0.082], 'all_L1': [0.37, 0.298, 0.23, 0.205]}), defaultdict(<class 'list'>, {'all_KL': [0.319, 0.203, 0.163, 0.148], 'all_L1': [0.323, 0.289, 0.273, 0.257]}), defaultdict(<class 'list'>, {'all_KL': [0.222, 0.132, 0.078, 0.068], 'all_L1': [0.241, 0.192, 0.142, 0.126]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_test
suff++ class all_L1  =  0.707 +- 0.097, 0.745 +- 0.066, 0.808 +- 0.055, 1.000 +- 0.000
suff++ class all_KL  =  0.708 +- 0.092, 0.812 +- 0.049, 0.901 +- 0.032, 1.000 +- 0.000
suff++_acc_int  =  0.543 +- 0.051, 0.562 +- 0.071, 0.583 +- 0.079
nec class all_L1  =  0.248 +- 0.067, 0.223 +- 0.047, 0.189 +- 0.050, 0.169 +- 0.052
nec class all_KL  =  0.222 +- 0.055, 0.152 +- 0.033, 0.100 +- 0.033, 0.082 +- 0.034
nec_acc_int  =  0.588 +- 0.070, 0.606 +- 0.072, 0.597 +- 0.077, 0.605 +- 0.082

Eval split test
suff++ class all_L1  =  0.698 +- 0.077, 0.733 +- 0.051, 0.814 +- 0.042, 1.000 +- 0.000
suff++ class all_KL  =  0.702 +- 0.069, 0.806 +- 0.038, 0.913 +- 0.026, 1.000 +- 0.000
suff++_acc_int  =  0.513 +- 0.034, 0.520 +- 0.034, 0.532 +- 0.039
nec class all_L1  =  0.276 +- 0.060, 0.251 +- 0.040, 0.211 +- 0.046, 0.190 +- 0.045
nec class all_KL  =  0.253 +- 0.046, 0.173 +- 0.028, 0.111 +- 0.031, 0.094 +- 0.029
nec_acc_int  =  0.543 +- 0.032, 0.548 +- 0.049, 0.543 +- 0.054, 0.539 +- 0.058


 -------------------------------------------------- 
Computing faithfulness

Eval split id_test
Faith. Aritm (L1)= 		  =  0.478 +- 0.015, 0.484 +- 0.011, 0.499 +- 0.006, 0.584 +- 0.026
Faith. Armon (L1)= 		  =  0.355 +- 0.056, 0.338 +- 0.048, 0.301 +- 0.063, 0.285 +- 0.075
Faith. GMean (L1)= 	  =  0.410 +- 0.025, 0.403 +- 0.026, 0.385 +- 0.041, 0.406 +- 0.064
Faith. Aritm (KL)= 		  =  0.465 +- 0.019, 0.482 +- 0.009, 0.501 +- 0.004, 0.541 +- 0.017
Faith. Armon (KL)= 		  =  0.329 +- 0.050, 0.254 +- 0.044, 0.178 +- 0.052, 0.150 +- 0.056
Faith. GMean (KL)= 	  =  0.390 +- 0.022, 0.348 +- 0.028, 0.295 +- 0.042, 0.282 +- 0.056

Eval split test
Faith. Aritm (L1)= 		  =  0.487 +- 0.010, 0.492 +- 0.008, 0.513 +- 0.003, 0.595 +- 0.023
Faith. Armon (L1)= 		  =  0.386 +- 0.045, 0.370 +- 0.038, 0.332 +- 0.055, 0.317 +- 0.064
Faith. GMean (L1)= 	  =  0.433 +- 0.022, 0.426 +- 0.020, 0.411 +- 0.036, 0.433 +- 0.052
Faith. Aritm (KL)= 		  =  0.478 +- 0.014, 0.490 +- 0.008, 0.512 +- 0.003, 0.547 +- 0.015
Faith. Armon (KL)= 		  =  0.366 +- 0.039, 0.284 +- 0.036, 0.196 +- 0.047, 0.171 +- 0.047
Faith. GMean (KL)= 	  =  0.417 +- 0.019, 0.372 +- 0.023, 0.315 +- 0.038, 0.304 +- 0.045
Computed for split load_split = id



Completed in  0:25:51.227516  for GSATGIN LBAPcore/assay



DONE GSAT LBAPcore/assay hard

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun May 12 13:53:41 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 05/12/2024 01:53:42 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/12/2024 01:53:42 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/12/2024 01:53:42 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/12/2024 01:53:42 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/12/2024 01:53:42 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/12/2024 01:53:42 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/12/2024 01:53:42 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/12/2024 01:53:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/12/2024 01:53:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 01:53:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/12/2024 01:53:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 01:53:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/12/2024 01:53:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 01:53:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/12/2024 01:53:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 01:53:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/12/2024 01:53:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 01:53:42 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 05/12/2024 01:53:42 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 168...
[0m[1;37mINFO[0m: [1mCheckpoint 168: 
-----------------------------------
Train ACCURACY: 0.9710
Train Loss: 0.0888
ID Validation ACCURACY: 0.8913
ID Validation Loss: 0.3578
ID Test ACCURACY: 0.8891
ID Test Loss: 0.3689
OOD Validation ACCURACY: 0.7710
OOD Validation Loss: 0.8283
OOD Test ACCURACY: 0.2787
OOD Test Loss: 5.7327

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 175...
[0m[1;37mINFO[0m: [1mCheckpoint 175: 
-----------------------------------
Train ACCURACY: 0.9678
Train Loss: 0.0980
ID Validation ACCURACY: 0.8826
ID Validation Loss: 0.3955
ID Test ACCURACY: 0.8830
ID Test Loss: 0.3916
OOD Validation ACCURACY: 0.7823
OOD Validation Loss: 0.8443
OOD Test ACCURACY: 0.3099
OOD Test Loss: 7.0050

[0m[1;37mINFO[0m: [1mChartInfo 0.8891 0.2787 0.8830 0.3099 0.8826 0.7823[0mGOODCMNIST(7000)
Data example from id_test: Data(x=[75, 3], edge_index=[2, 1351], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1351], node_perm=[75])
Label distribution from id_test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([657, 814, 676, 706, 676, 663, 688, 748, 702, 670]))
[1;31mERROR[0m: 05/12/2024 01:53:46 PM - utils.py - line 52 : [1mCUDA out of memory. Tried to allocate 1.60 GiB. GPU 1 has a total capacty of 11.77 GiB of which 984.25 MiB is free. Process 1821311 has 5.02 GiB memory in use. Including non-PyTorch memory, this process has 5.79 GiB memory in use. Of the allocated memory 4.85 GiB is allocated by PyTorch, and 43.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0m
  File "/mnt/cimec-storage6/users/steve.azzolin/venv/leci/bin/goodtg", line 33, in <module>
    sys.exit(load_entry_point('graph-ood', 'console_scripts', 'goodtg')())
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/kernel/main.py", line 639, in goodtg
    print(f'#E#{e}')
\n\nTime to compute metrics!
The PID of this script is: 1829738

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun May 12 15:14:28 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 05/12/2024 03:14:29 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/12/2024 03:14:29 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/12/2024 03:14:30 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/12/2024 03:14:30 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/12/2024 03:14:30 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/12/2024 03:14:30 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/12/2024 03:14:30 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/12/2024 03:14:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/12/2024 03:14:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:14:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/12/2024 03:14:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:14:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/12/2024 03:14:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:14:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/12/2024 03:14:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:14:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/12/2024 03:14:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:14:30 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 05/12/2024 03:14:30 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 168...
[0m[1;37mINFO[0m: [1mCheckpoint 168: 
-----------------------------------
Train ACCURACY: 0.9710
Train Loss: 0.0888
ID Validation ACCURACY: 0.8913
ID Validation Loss: 0.3578
ID Test ACCURACY: 0.8891
ID Test Loss: 0.3689
OOD Validation ACCURACY: 0.7710
OOD Validation Loss: 0.8283
OOD Test ACCURACY: 0.2787
OOD Test Loss: 5.7327

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 175...
[0m[1;37mINFO[0m: [1mCheckpoint 175: 
-----------------------------------
Train ACCURACY: 0.9678
Train Loss: 0.0980
ID Validation ACCURACY: 0.8826
ID Validation Loss: 0.3955
ID Test ACCURACY: 0.8830
ID Test Loss: 0.3916
OOD Validation ACCURACY: 0.7823
OOD Validation Loss: 0.8443
OOD Test ACCURACY: 0.3099
OOD Test Loss: 7.0050

[0m[1;37mINFO[0m: [1mChartInfo 0.8891 0.2787 0.8830 0.3099 0.8826 0.7823[0mGOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.114
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.101
SUFF++ for r=0.3 class 0 = 0.618 +- 0.337 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.3 class 1 = 0.552 +- 0.337 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.3 class 2 = 0.6 +- 0.337 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.3 class 3 = 0.662 +- 0.337 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.3 class 4 = 0.658 +- 0.337 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.3 class 5 = 0.628 +- 0.337 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.3 class 6 = 0.683 +- 0.337 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.3 class 7 = 0.667 +- 0.337 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.3 class 8 = 0.672 +- 0.337 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.3 class 9 = 0.727 +- 0.337 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.3 all KL = 0.521 +- 0.337 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.3 all L1 = 0.645 +- 0.281 (in-sample avg dev_std = 0.371)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.159
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.121
SUFF++ for r=0.6 class 0 = 0.391 +- 0.257 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 class 1 = 0.243 +- 0.257 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 class 2 = 0.377 +- 0.257 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 class 3 = 0.355 +- 0.257 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 class 4 = 0.326 +- 0.257 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 class 5 = 0.38 +- 0.257 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 class 6 = 0.355 +- 0.257 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 class 7 = 0.387 +- 0.257 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 class 8 = 0.434 +- 0.257 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 class 9 = 0.339 +- 0.257 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 all KL = 0.223 +- 0.257 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 all L1 = 0.358 +- 0.201 (in-sample avg dev_std = 0.468)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.194
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.171
SUFF++ for r=0.9 class 0 = 0.412 +- 0.285 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 class 1 = 0.56 +- 0.285 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 class 2 = 0.442 +- 0.285 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 class 3 = 0.368 +- 0.285 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 class 4 = 0.382 +- 0.285 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 class 5 = 0.382 +- 0.285 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 class 6 = 0.366 +- 0.285 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 class 7 = 0.414 +- 0.285 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 class 8 = 0.382 +- 0.285 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 class 9 = 0.347 +- 0.285 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 all KL = 0.286 +- 0.285 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 all L1 = 0.408 +- 0.227 (in-sample avg dev_std = 0.421)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.114
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.107
NEC for r=0.3 class 0 = 0.376 +- 0.334 (in-sample avg dev_std = 0.382)
NEC for r=0.3 class 1 = 0.407 +- 0.334 (in-sample avg dev_std = 0.382)
NEC for r=0.3 class 2 = 0.485 +- 0.334 (in-sample avg dev_std = 0.382)
NEC for r=0.3 class 3 = 0.37 +- 0.334 (in-sample avg dev_std = 0.382)
NEC for r=0.3 class 4 = 0.367 +- 0.334 (in-sample avg dev_std = 0.382)
NEC for r=0.3 class 5 = 0.435 +- 0.334 (in-sample avg dev_std = 0.382)
NEC for r=0.3 class 6 = 0.35 +- 0.334 (in-sample avg dev_std = 0.382)
NEC for r=0.3 class 7 = 0.35 +- 0.334 (in-sample avg dev_std = 0.382)
NEC for r=0.3 class 8 = 0.328 +- 0.334 (in-sample avg dev_std = 0.382)
NEC for r=0.3 class 9 = 0.265 +- 0.334 (in-sample avg dev_std = 0.382)
NEC for r=0.3 all KL = 0.492 +- 0.334 (in-sample avg dev_std = 0.382)
NEC for r=0.3 all L1 = 0.374 +- 0.271 (in-sample avg dev_std = 0.382)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.159
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.13
NEC for r=0.6 class 0 = 0.576 +- 0.281 (in-sample avg dev_std = 0.419)
NEC for r=0.6 class 1 = 0.733 +- 0.281 (in-sample avg dev_std = 0.419)
NEC for r=0.6 class 2 = 0.558 +- 0.281 (in-sample avg dev_std = 0.419)
NEC for r=0.6 class 3 = 0.634 +- 0.281 (in-sample avg dev_std = 0.419)
NEC for r=0.6 class 4 = 0.662 +- 0.281 (in-sample avg dev_std = 0.419)
NEC for r=0.6 class 5 = 0.58 +- 0.281 (in-sample avg dev_std = 0.419)
NEC for r=0.6 class 6 = 0.586 +- 0.281 (in-sample avg dev_std = 0.419)
NEC for r=0.6 class 7 = 0.559 +- 0.281 (in-sample avg dev_std = 0.419)
NEC for r=0.6 class 8 = 0.534 +- 0.281 (in-sample avg dev_std = 0.419)
NEC for r=0.6 class 9 = 0.677 +- 0.281 (in-sample avg dev_std = 0.419)
NEC for r=0.6 all KL = 0.729 +- 0.281 (in-sample avg dev_std = 0.419)
NEC for r=0.6 all L1 = 0.611 +- 0.231 (in-sample avg dev_std = 0.419)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.194
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.237
NEC for r=0.9 class 0 = 0.678 +- 0.229 (in-sample avg dev_std = 0.419)
NEC for r=0.9 class 1 = 0.764 +- 0.229 (in-sample avg dev_std = 0.419)
NEC for r=0.9 class 2 = 0.594 +- 0.229 (in-sample avg dev_std = 0.419)
NEC for r=0.9 class 3 = 0.634 +- 0.229 (in-sample avg dev_std = 0.419)
NEC for r=0.9 class 4 = 0.7 +- 0.229 (in-sample avg dev_std = 0.419)
NEC for r=0.9 class 5 = 0.647 +- 0.229 (in-sample avg dev_std = 0.419)
NEC for r=0.9 class 6 = 0.677 +- 0.229 (in-sample avg dev_std = 0.419)
NEC for r=0.9 class 7 = 0.644 +- 0.229 (in-sample avg dev_std = 0.419)
NEC for r=0.9 class 8 = 0.679 +- 0.229 (in-sample avg dev_std = 0.419)
NEC for r=0.9 class 9 = 0.732 +- 0.229 (in-sample avg dev_std = 0.419)
NEC for r=0.9 all KL = 0.817 +- 0.229 (in-sample avg dev_std = 0.419)
NEC for r=0.9 all L1 = 0.675 +- 0.183 (in-sample avg dev_std = 0.419)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.281
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.367
NEC for r=1.0 class 0 = 0.599 +- 0.276 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 1 = 0.665 +- 0.276 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 2 = 0.558 +- 0.276 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 3 = 0.608 +- 0.276 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 4 = 0.646 +- 0.276 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 5 = 0.604 +- 0.276 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 6 = 0.702 +- 0.276 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 7 = 0.561 +- 0.276 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 8 = 0.686 +- 0.276 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 9 = 0.71 +- 0.276 (in-sample avg dev_std = 0.374)
NEC for r=1.0 all KL = 0.735 +- 0.276 (in-sample avg dev_std = 0.374)
NEC for r=1.0 all L1 = 0.633 +- 0.215 (in-sample avg dev_std = 0.374)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun May 12 15:22:25 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 05/12/2024 03:22:26 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/12/2024 03:22:26 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/12/2024 03:22:26 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/12/2024 03:22:27 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/12/2024 03:22:27 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/12/2024 03:22:27 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/12/2024 03:22:27 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/12/2024 03:22:27 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/12/2024 03:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:22:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/12/2024 03:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:22:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/12/2024 03:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:22:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/12/2024 03:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:22:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/12/2024 03:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:22:27 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 05/12/2024 03:22:27 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 184...
[0m[1;37mINFO[0m: [1mCheckpoint 184: 
-----------------------------------
Train ACCURACY: 0.9697
Train Loss: 0.0910
ID Validation ACCURACY: 0.8901
ID Validation Loss: 0.3680
ID Test ACCURACY: 0.8897
ID Test Loss: 0.3824
OOD Validation ACCURACY: 0.7509
OOD Validation Loss: 1.0322
OOD Test ACCURACY: 0.2683
OOD Test Loss: 5.3981

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 168...
[0m[1;37mINFO[0m: [1mCheckpoint 168: 
-----------------------------------
Train ACCURACY: 0.9635
Train Loss: 0.1083
ID Validation ACCURACY: 0.8834
ID Validation Loss: 0.3827
ID Test ACCURACY: 0.8824
ID Test Loss: 0.3845
OOD Validation ACCURACY: 0.7814
OOD Validation Loss: 0.9042
OOD Test ACCURACY: 0.3949
OOD Test Loss: 2.9563

[0m[1;37mINFO[0m: [1mChartInfo 0.8897 0.2683 0.8824 0.3949 0.8834 0.7814[0mGOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.13
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.112
SUFF++ for r=0.3 class 0 = 0.667 +- 0.362 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.3 class 1 = 0.361 +- 0.362 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.3 class 2 = 0.63 +- 0.362 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.3 class 3 = 0.635 +- 0.362 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.3 class 4 = 0.657 +- 0.362 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.3 class 5 = 0.699 +- 0.362 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.3 class 6 = 0.687 +- 0.362 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.3 class 7 = 0.815 +- 0.362 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.3 class 8 = 0.72 +- 0.362 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.3 class 9 = 0.612 +- 0.362 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.3 all KL = 0.522 +- 0.362 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.3 all L1 = 0.644 +- 0.295 (in-sample avg dev_std = 0.416)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.13
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.114
SUFF++ for r=0.6 class 0 = 0.456 +- 0.302 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.6 class 1 = 0.242 +- 0.302 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.6 class 2 = 0.389 +- 0.302 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.6 class 3 = 0.44 +- 0.302 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.6 class 4 = 0.463 +- 0.302 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.6 class 5 = 0.447 +- 0.302 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.6 class 6 = 0.476 +- 0.302 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.6 class 7 = 0.487 +- 0.302 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.6 class 8 = 0.591 +- 0.302 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.6 class 9 = 0.428 +- 0.302 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.6 all KL = 0.28 +- 0.302 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.6 all L1 = 0.439 +- 0.265 (in-sample avg dev_std = 0.476)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.225
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.156
SUFF++ for r=0.9 class 0 = 0.32 +- 0.182 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.9 class 1 = 0.235 +- 0.182 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.9 class 2 = 0.333 +- 0.182 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.9 class 3 = 0.294 +- 0.182 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.9 class 4 = 0.294 +- 0.182 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.9 class 5 = 0.3 +- 0.182 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.9 class 6 = 0.314 +- 0.182 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.9 class 7 = 0.334 +- 0.182 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.9 class 8 = 0.259 +- 0.182 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.9 class 9 = 0.247 +- 0.182 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.9 all KL = 0.129 +- 0.182 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.9 all L1 = 0.293 +- 0.154 (in-sample avg dev_std = 0.424)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.13
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.105
NEC for r=0.3 class 0 = 0.322 +- 0.356 (in-sample avg dev_std = 0.364)
NEC for r=0.3 class 1 = 0.628 +- 0.356 (in-sample avg dev_std = 0.364)
NEC for r=0.3 class 2 = 0.36 +- 0.356 (in-sample avg dev_std = 0.364)
NEC for r=0.3 class 3 = 0.315 +- 0.356 (in-sample avg dev_std = 0.364)
NEC for r=0.3 class 4 = 0.395 +- 0.356 (in-sample avg dev_std = 0.364)
NEC for r=0.3 class 5 = 0.335 +- 0.356 (in-sample avg dev_std = 0.364)
NEC for r=0.3 class 6 = 0.326 +- 0.356 (in-sample avg dev_std = 0.364)
NEC for r=0.3 class 7 = 0.196 +- 0.356 (in-sample avg dev_std = 0.364)
NEC for r=0.3 class 8 = 0.285 +- 0.356 (in-sample avg dev_std = 0.364)
NEC for r=0.3 class 9 = 0.439 +- 0.356 (in-sample avg dev_std = 0.364)
NEC for r=0.3 all KL = 0.483 +- 0.356 (in-sample avg dev_std = 0.364)
NEC for r=0.3 all L1 = 0.363 +- 0.302 (in-sample avg dev_std = 0.364)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.13
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.122
NEC for r=0.6 class 0 = 0.559 +- 0.312 (in-sample avg dev_std = 0.435)
NEC for r=0.6 class 1 = 0.741 +- 0.312 (in-sample avg dev_std = 0.435)
NEC for r=0.6 class 2 = 0.595 +- 0.312 (in-sample avg dev_std = 0.435)
NEC for r=0.6 class 3 = 0.566 +- 0.312 (in-sample avg dev_std = 0.435)
NEC for r=0.6 class 4 = 0.56 +- 0.312 (in-sample avg dev_std = 0.435)
NEC for r=0.6 class 5 = 0.554 +- 0.312 (in-sample avg dev_std = 0.435)
NEC for r=0.6 class 6 = 0.502 +- 0.312 (in-sample avg dev_std = 0.435)
NEC for r=0.6 class 7 = 0.525 +- 0.312 (in-sample avg dev_std = 0.435)
NEC for r=0.6 class 8 = 0.404 +- 0.312 (in-sample avg dev_std = 0.435)
NEC for r=0.6 class 9 = 0.57 +- 0.312 (in-sample avg dev_std = 0.435)
NEC for r=0.6 all KL = 0.709 +- 0.312 (in-sample avg dev_std = 0.435)
NEC for r=0.6 all L1 = 0.56 +- 0.272 (in-sample avg dev_std = 0.435)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.225
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.252
NEC for r=0.9 class 0 = 0.706 +- 0.205 (in-sample avg dev_std = 0.417)
NEC for r=0.9 class 1 = 0.54 +- 0.205 (in-sample avg dev_std = 0.417)
NEC for r=0.9 class 2 = 0.684 +- 0.205 (in-sample avg dev_std = 0.417)
NEC for r=0.9 class 3 = 0.716 +- 0.205 (in-sample avg dev_std = 0.417)
NEC for r=0.9 class 4 = 0.711 +- 0.205 (in-sample avg dev_std = 0.417)
NEC for r=0.9 class 5 = 0.705 +- 0.205 (in-sample avg dev_std = 0.417)
NEC for r=0.9 class 6 = 0.73 +- 0.205 (in-sample avg dev_std = 0.417)
NEC for r=0.9 class 7 = 0.72 +- 0.205 (in-sample avg dev_std = 0.417)
NEC for r=0.9 class 8 = 0.76 +- 0.205 (in-sample avg dev_std = 0.417)
NEC for r=0.9 class 9 = 0.749 +- 0.205 (in-sample avg dev_std = 0.417)
NEC for r=0.9 all KL = 0.87 +- 0.205 (in-sample avg dev_std = 0.417)
NEC for r=0.9 all L1 = 0.7 +- 0.178 (in-sample avg dev_std = 0.417)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.281
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.369
NEC for r=1.0 class 0 = 0.652 +- 0.286 (in-sample avg dev_std = 0.360)
NEC for r=1.0 class 1 = 0.426 +- 0.286 (in-sample avg dev_std = 0.360)
NEC for r=1.0 class 2 = 0.618 +- 0.286 (in-sample avg dev_std = 0.360)
NEC for r=1.0 class 3 = 0.684 +- 0.286 (in-sample avg dev_std = 0.360)
NEC for r=1.0 class 4 = 0.719 +- 0.286 (in-sample avg dev_std = 0.360)
NEC for r=1.0 class 5 = 0.594 +- 0.286 (in-sample avg dev_std = 0.360)
NEC for r=1.0 class 6 = 0.732 +- 0.286 (in-sample avg dev_std = 0.360)
NEC for r=1.0 class 7 = 0.617 +- 0.286 (in-sample avg dev_std = 0.360)
NEC for r=1.0 class 8 = 0.682 +- 0.286 (in-sample avg dev_std = 0.360)
NEC for r=1.0 class 9 = 0.697 +- 0.286 (in-sample avg dev_std = 0.360)
NEC for r=1.0 all KL = 0.777 +- 0.286 (in-sample avg dev_std = 0.360)
NEC for r=1.0 all L1 = 0.639 +- 0.243 (in-sample avg dev_std = 0.360)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun May 12 15:30:16 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 05/12/2024 03:30:17 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/12/2024 03:30:17 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/12/2024 03:30:18 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/12/2024 03:30:18 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/12/2024 03:30:18 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/12/2024 03:30:18 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/12/2024 03:30:18 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/12/2024 03:30:18 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/12/2024 03:30:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:30:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/12/2024 03:30:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:30:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/12/2024 03:30:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:30:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/12/2024 03:30:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:30:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/12/2024 03:30:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:30:18 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 05/12/2024 03:30:18 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 158...
[0m[1;37mINFO[0m: [1mCheckpoint 158: 
-----------------------------------
Train ACCURACY: 0.9624
Train Loss: 0.1081
ID Validation ACCURACY: 0.8889
ID Validation Loss: 0.3704
ID Test ACCURACY: 0.8846
ID Test Loss: 0.3894
OOD Validation ACCURACY: 0.7016
OOD Validation Loss: 1.3742
OOD Test ACCURACY: 0.3063
OOD Test Loss: 4.9057

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 166...
[0m[1;37mINFO[0m: [1mCheckpoint 166: 
-----------------------------------
Train ACCURACY: 0.9646
Train Loss: 0.1029
ID Validation ACCURACY: 0.8820
ID Validation Loss: 0.3984
ID Test ACCURACY: 0.8826
ID Test Loss: 0.4026
OOD Validation ACCURACY: 0.7703
OOD Validation Loss: 0.9501
OOD Test ACCURACY: 0.2739
OOD Test Loss: 7.1712

[0m[1;37mINFO[0m: [1mChartInfo 0.8846 0.3063 0.8826 0.2739 0.8820 0.7703[0mGOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.119
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.114
SUFF++ for r=0.3 class 0 = 0.318 +- 0.177 (in-sample avg dev_std = 0.705)
SUFF++ for r=0.3 class 1 = 0.306 +- 0.177 (in-sample avg dev_std = 0.705)
SUFF++ for r=0.3 class 2 = 0.349 +- 0.177 (in-sample avg dev_std = 0.705)
SUFF++ for r=0.3 class 3 = 0.32 +- 0.177 (in-sample avg dev_std = 0.705)
SUFF++ for r=0.3 class 4 = 0.338 +- 0.177 (in-sample avg dev_std = 0.705)
SUFF++ for r=0.3 class 5 = 0.324 +- 0.177 (in-sample avg dev_std = 0.705)
SUFF++ for r=0.3 class 6 = 0.346 +- 0.177 (in-sample avg dev_std = 0.705)
SUFF++ for r=0.3 class 7 = 0.359 +- 0.177 (in-sample avg dev_std = 0.705)
SUFF++ for r=0.3 class 8 = 0.299 +- 0.177 (in-sample avg dev_std = 0.705)
SUFF++ for r=0.3 class 9 = 0.323 +- 0.177 (in-sample avg dev_std = 0.705)
SUFF++ for r=0.3 all KL = 0.14 +- 0.177 (in-sample avg dev_std = 0.705)
SUFF++ for r=0.3 all L1 = 0.328 +- 0.118 (in-sample avg dev_std = 0.705)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.126
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.114
SUFF++ for r=0.6 class 0 = 0.297 +- 0.197 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.6 class 1 = 0.246 +- 0.197 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.6 class 2 = 0.294 +- 0.197 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.6 class 3 = 0.33 +- 0.197 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.6 class 4 = 0.262 +- 0.197 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.6 class 5 = 0.335 +- 0.197 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.6 class 6 = 0.387 +- 0.197 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.6 class 7 = 0.364 +- 0.197 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.6 class 8 = 0.348 +- 0.197 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.6 class 9 = 0.337 +- 0.197 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.6 all KL = 0.151 +- 0.197 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.6 all L1 = 0.319 +- 0.179 (in-sample avg dev_std = 0.490)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.231
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.203
SUFF++ for r=0.9 class 0 = 0.281 +- 0.199 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.9 class 1 = 0.477 +- 0.199 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.9 class 2 = 0.289 +- 0.199 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.9 class 3 = 0.281 +- 0.199 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.9 class 4 = 0.272 +- 0.199 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.9 class 5 = 0.287 +- 0.199 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.9 class 6 = 0.316 +- 0.199 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.9 class 7 = 0.364 +- 0.199 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.9 class 8 = 0.269 +- 0.199 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.9 class 9 = 0.268 +- 0.199 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.9 all KL = 0.151 +- 0.199 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.9 all L1 = 0.312 +- 0.172 (in-sample avg dev_std = 0.438)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.119
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.123
NEC for r=0.3 class 0 = 0.714 +- 0.302 (in-sample avg dev_std = 0.470)
NEC for r=0.3 class 1 = 0.597 +- 0.302 (in-sample avg dev_std = 0.470)
NEC for r=0.3 class 2 = 0.621 +- 0.302 (in-sample avg dev_std = 0.470)
NEC for r=0.3 class 3 = 0.644 +- 0.302 (in-sample avg dev_std = 0.470)
NEC for r=0.3 class 4 = 0.555 +- 0.302 (in-sample avg dev_std = 0.470)
NEC for r=0.3 class 5 = 0.63 +- 0.302 (in-sample avg dev_std = 0.470)
NEC for r=0.3 class 6 = 0.564 +- 0.302 (in-sample avg dev_std = 0.470)
NEC for r=0.3 class 7 = 0.521 +- 0.302 (in-sample avg dev_std = 0.470)
NEC for r=0.3 class 8 = 0.6 +- 0.302 (in-sample avg dev_std = 0.470)
NEC for r=0.3 class 9 = 0.552 +- 0.302 (in-sample avg dev_std = 0.470)
NEC for r=0.3 all KL = 0.742 +- 0.302 (in-sample avg dev_std = 0.470)
NEC for r=0.3 all L1 = 0.6 +- 0.245 (in-sample avg dev_std = 0.470)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.126
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.125
NEC for r=0.6 class 0 = 0.705 +- 0.304 (in-sample avg dev_std = 0.385)
NEC for r=0.6 class 1 = 0.69 +- 0.304 (in-sample avg dev_std = 0.385)
NEC for r=0.6 class 2 = 0.689 +- 0.304 (in-sample avg dev_std = 0.385)
NEC for r=0.6 class 3 = 0.634 +- 0.304 (in-sample avg dev_std = 0.385)
NEC for r=0.6 class 4 = 0.683 +- 0.304 (in-sample avg dev_std = 0.385)
NEC for r=0.6 class 5 = 0.619 +- 0.304 (in-sample avg dev_std = 0.385)
NEC for r=0.6 class 6 = 0.54 +- 0.304 (in-sample avg dev_std = 0.385)
NEC for r=0.6 class 7 = 0.601 +- 0.304 (in-sample avg dev_std = 0.385)
NEC for r=0.6 class 8 = 0.588 +- 0.304 (in-sample avg dev_std = 0.385)
NEC for r=0.6 class 9 = 0.577 +- 0.304 (in-sample avg dev_std = 0.385)
NEC for r=0.6 all KL = 0.771 +- 0.304 (in-sample avg dev_std = 0.385)
NEC for r=0.6 all L1 = 0.634 +- 0.256 (in-sample avg dev_std = 0.385)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.231
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.291
NEC for r=0.9 class 0 = 0.747 +- 0.220 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 1 = 0.451 +- 0.220 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 2 = 0.701 +- 0.220 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 3 = 0.729 +- 0.220 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 4 = 0.744 +- 0.220 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 5 = 0.711 +- 0.220 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 6 = 0.732 +- 0.220 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 7 = 0.684 +- 0.220 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 8 = 0.759 +- 0.220 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 9 = 0.752 +- 0.220 (in-sample avg dev_std = 0.393)
NEC for r=0.9 all KL = 0.849 +- 0.220 (in-sample avg dev_std = 0.393)
NEC for r=0.9 all L1 = 0.698 +- 0.189 (in-sample avg dev_std = 0.393)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.311
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.389
NEC for r=1.0 class 0 = 0.726 +- 0.293 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 1 = 0.385 +- 0.293 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 2 = 0.577 +- 0.293 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 3 = 0.666 +- 0.293 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 4 = 0.697 +- 0.293 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 5 = 0.599 +- 0.293 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 6 = 0.675 +- 0.293 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 7 = 0.549 +- 0.293 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 8 = 0.662 +- 0.293 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 9 = 0.634 +- 0.293 (in-sample avg dev_std = 0.354)
NEC for r=1.0 all KL = 0.711 +- 0.293 (in-sample avg dev_std = 0.354)
NEC for r=1.0 all L1 = 0.614 +- 0.239 (in-sample avg dev_std = 0.354)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun May 12 15:38:08 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 05/12/2024 03:38:09 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/12/2024 03:38:09 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/12/2024 03:38:09 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/12/2024 03:38:09 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/12/2024 03:38:09 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/12/2024 03:38:09 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/12/2024 03:38:09 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/12/2024 03:38:09 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/12/2024 03:38:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:38:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/12/2024 03:38:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:38:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/12/2024 03:38:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:38:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/12/2024 03:38:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:38:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/12/2024 03:38:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:38:09 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 05/12/2024 03:38:09 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 196...
[0m[1;37mINFO[0m: [1mCheckpoint 196: 
-----------------------------------
Train ACCURACY: 0.9730
Train Loss: 0.0837
ID Validation ACCURACY: 0.8894
ID Validation Loss: 0.3769
ID Test ACCURACY: 0.8864
ID Test Loss: 0.3922
OOD Validation ACCURACY: 0.6770
OOD Validation Loss: 1.7135
OOD Test ACCURACY: 0.2230
OOD Test Loss: 8.2497

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 143...
[0m[1;37mINFO[0m: [1mCheckpoint 143: 
-----------------------------------
Train ACCURACY: 0.9545
Train Loss: 0.1347
ID Validation ACCURACY: 0.8867
ID Validation Loss: 0.3741
ID Test ACCURACY: 0.8890
ID Test Loss: 0.3766
OOD Validation ACCURACY: 0.7774
OOD Validation Loss: 0.7987
OOD Test ACCURACY: 0.3824
OOD Test Loss: 2.9937

[0m[1;37mINFO[0m: [1mChartInfo 0.8864 0.2230 0.8890 0.3824 0.8867 0.7774[0mGOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.094
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.093
SUFF++ for r=0.3 class 0 = 0.447 +- 0.226 (in-sample avg dev_std = 0.587)
SUFF++ for r=0.3 class 1 = 0.264 +- 0.226 (in-sample avg dev_std = 0.587)
SUFF++ for r=0.3 class 2 = 0.406 +- 0.226 (in-sample avg dev_std = 0.587)
SUFF++ for r=0.3 class 3 = 0.395 +- 0.226 (in-sample avg dev_std = 0.587)
SUFF++ for r=0.3 class 4 = 0.352 +- 0.226 (in-sample avg dev_std = 0.587)
SUFF++ for r=0.3 class 5 = 0.355 +- 0.226 (in-sample avg dev_std = 0.587)
SUFF++ for r=0.3 class 6 = 0.377 +- 0.226 (in-sample avg dev_std = 0.587)
SUFF++ for r=0.3 class 7 = 0.371 +- 0.226 (in-sample avg dev_std = 0.587)
SUFF++ for r=0.3 class 8 = 0.308 +- 0.226 (in-sample avg dev_std = 0.587)
SUFF++ for r=0.3 class 9 = 0.371 +- 0.226 (in-sample avg dev_std = 0.587)
SUFF++ for r=0.3 all KL = 0.169 +- 0.226 (in-sample avg dev_std = 0.587)
SUFF++ for r=0.3 all L1 = 0.364 +- 0.187 (in-sample avg dev_std = 0.587)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.094
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.095
SUFF++ for r=0.6 class 0 = 0.269 +- 0.111 (in-sample avg dev_std = 0.524)
SUFF++ for r=0.6 class 1 = 0.305 +- 0.111 (in-sample avg dev_std = 0.524)
SUFF++ for r=0.6 class 2 = 0.245 +- 0.111 (in-sample avg dev_std = 0.524)
SUFF++ for r=0.6 class 3 = 0.261 +- 0.111 (in-sample avg dev_std = 0.524)
SUFF++ for r=0.6 class 4 = 0.237 +- 0.111 (in-sample avg dev_std = 0.524)
SUFF++ for r=0.6 class 5 = 0.239 +- 0.111 (in-sample avg dev_std = 0.524)
SUFF++ for r=0.6 class 6 = 0.202 +- 0.111 (in-sample avg dev_std = 0.524)
SUFF++ for r=0.6 class 7 = 0.217 +- 0.111 (in-sample avg dev_std = 0.524)
SUFF++ for r=0.6 class 8 = 0.238 +- 0.111 (in-sample avg dev_std = 0.524)
SUFF++ for r=0.6 class 9 = 0.24 +- 0.111 (in-sample avg dev_std = 0.524)
SUFF++ for r=0.6 all KL = 0.041 +- 0.111 (in-sample avg dev_std = 0.524)
SUFF++ for r=0.6 all L1 = 0.247 +- 0.124 (in-sample avg dev_std = 0.524)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.121
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.123
SUFF++ for r=0.9 class 0 = 0.317 +- 0.296 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.9 class 1 = 0.475 +- 0.296 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.9 class 2 = 0.449 +- 0.296 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.9 class 3 = 0.408 +- 0.296 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.9 class 4 = 0.409 +- 0.296 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.9 class 5 = 0.367 +- 0.296 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.9 class 6 = 0.442 +- 0.296 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.9 class 7 = 0.492 +- 0.296 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.9 class 8 = 0.345 +- 0.296 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.9 class 9 = 0.378 +- 0.296 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.9 all KL = 0.236 +- 0.296 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.9 all L1 = 0.41 +- 0.241 (in-sample avg dev_std = 0.427)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.094
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.097
NEC for r=0.3 class 0 = 0.602 +- 0.355 (in-sample avg dev_std = 0.443)
NEC for r=0.3 class 1 = 0.643 +- 0.355 (in-sample avg dev_std = 0.443)
NEC for r=0.3 class 2 = 0.549 +- 0.355 (in-sample avg dev_std = 0.443)
NEC for r=0.3 class 3 = 0.52 +- 0.355 (in-sample avg dev_std = 0.443)
NEC for r=0.3 class 4 = 0.411 +- 0.355 (in-sample avg dev_std = 0.443)
NEC for r=0.3 class 5 = 0.549 +- 0.355 (in-sample avg dev_std = 0.443)
NEC for r=0.3 class 6 = 0.454 +- 0.355 (in-sample avg dev_std = 0.443)
NEC for r=0.3 class 7 = 0.533 +- 0.355 (in-sample avg dev_std = 0.443)
NEC for r=0.3 class 8 = 0.46 +- 0.355 (in-sample avg dev_std = 0.443)
NEC for r=0.3 class 9 = 0.377 +- 0.355 (in-sample avg dev_std = 0.443)
NEC for r=0.3 all KL = 0.624 +- 0.355 (in-sample avg dev_std = 0.443)
NEC for r=0.3 all L1 = 0.512 +- 0.287 (in-sample avg dev_std = 0.443)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.094
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.088
NEC for r=0.6 class 0 = 0.715 +- 0.243 (in-sample avg dev_std = 0.473)
NEC for r=0.6 class 1 = 0.65 +- 0.243 (in-sample avg dev_std = 0.473)
NEC for r=0.6 class 2 = 0.615 +- 0.243 (in-sample avg dev_std = 0.473)
NEC for r=0.6 class 3 = 0.675 +- 0.243 (in-sample avg dev_std = 0.473)
NEC for r=0.6 class 4 = 0.594 +- 0.243 (in-sample avg dev_std = 0.473)
NEC for r=0.6 class 5 = 0.642 +- 0.243 (in-sample avg dev_std = 0.473)
NEC for r=0.6 class 6 = 0.669 +- 0.243 (in-sample avg dev_std = 0.473)
NEC for r=0.6 class 7 = 0.58 +- 0.243 (in-sample avg dev_std = 0.473)
NEC for r=0.6 class 8 = 0.662 +- 0.243 (in-sample avg dev_std = 0.473)
NEC for r=0.6 class 9 = 0.593 +- 0.243 (in-sample avg dev_std = 0.473)
NEC for r=0.6 all KL = 0.825 +- 0.243 (in-sample avg dev_std = 0.473)
NEC for r=0.6 all L1 = 0.64 +- 0.190 (in-sample avg dev_std = 0.473)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.121
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.14
NEC for r=0.9 class 0 = 0.685 +- 0.263 (in-sample avg dev_std = 0.466)
NEC for r=0.9 class 1 = 0.601 +- 0.263 (in-sample avg dev_std = 0.466)
NEC for r=0.9 class 2 = 0.581 +- 0.263 (in-sample avg dev_std = 0.466)
NEC for r=0.9 class 3 = 0.608 +- 0.263 (in-sample avg dev_std = 0.466)
NEC for r=0.9 class 4 = 0.579 +- 0.263 (in-sample avg dev_std = 0.466)
NEC for r=0.9 class 5 = 0.643 +- 0.263 (in-sample avg dev_std = 0.466)
NEC for r=0.9 class 6 = 0.659 +- 0.263 (in-sample avg dev_std = 0.466)
NEC for r=0.9 class 7 = 0.583 +- 0.263 (in-sample avg dev_std = 0.466)
NEC for r=0.9 class 8 = 0.672 +- 0.263 (in-sample avg dev_std = 0.466)
NEC for r=0.9 class 9 = 0.632 +- 0.263 (in-sample avg dev_std = 0.466)
NEC for r=0.9 all KL = 0.799 +- 0.263 (in-sample avg dev_std = 0.466)
NEC for r=0.9 all L1 = 0.624 +- 0.214 (in-sample avg dev_std = 0.466)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.231
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.303
NEC for r=1.0 class 0 = 0.646 +- 0.254 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 1 = 0.523 +- 0.254 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 2 = 0.675 +- 0.254 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 3 = 0.621 +- 0.254 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 4 = 0.726 +- 0.254 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 5 = 0.698 +- 0.254 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 6 = 0.735 +- 0.254 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 7 = 0.709 +- 0.254 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 8 = 0.654 +- 0.254 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 9 = 0.677 +- 0.254 (in-sample avg dev_std = 0.397)
NEC for r=1.0 all KL = 0.839 +- 0.254 (in-sample avg dev_std = 0.397)
NEC for r=1.0 all L1 = 0.664 +- 0.233 (in-sample avg dev_std = 0.397)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun May 12 15:45:51 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 05/12/2024 03:45:52 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/12/2024 03:45:52 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/12/2024 03:45:52 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/12/2024 03:45:52 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/12/2024 03:45:52 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/12/2024 03:45:52 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/12/2024 03:45:52 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/12/2024 03:45:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/12/2024 03:45:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:45:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/12/2024 03:45:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:45:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/12/2024 03:45:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:45:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/12/2024 03:45:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:45:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/12/2024 03:45:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:45:52 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 05/12/2024 03:45:52 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 194...
[0m[1;37mINFO[0m: [1mCheckpoint 194: 
-----------------------------------
Train ACCURACY: 0.9739
Train Loss: 0.0800
ID Validation ACCURACY: 0.8936
ID Validation Loss: 0.3724
ID Test ACCURACY: 0.8870
ID Test Loss: 0.3904
OOD Validation ACCURACY: 0.8023
OOD Validation Loss: 0.7265
OOD Test ACCURACY: 0.2739
OOD Test Loss: 4.8281

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 97...
[0m[1;37mINFO[0m: [1mCheckpoint 97: 
-----------------------------------
Train ACCURACY: 0.9201
Train Loss: 0.2337
ID Validation ACCURACY: 0.8701
ID Validation Loss: 0.4056
ID Test ACCURACY: 0.8727
ID Test Loss: 0.4148
OOD Validation ACCURACY: 0.8056
OOD Validation Loss: 0.6300
OOD Test ACCURACY: 0.4093
OOD Test Loss: 2.5019

[0m[1;37mINFO[0m: [1mChartInfo 0.8870 0.2739 0.8727 0.4093 0.8701 0.8056[0mGOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.096
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.091
SUFF++ for r=0.3 class 0 = 0.339 +- 0.195 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.3 class 1 = 0.268 +- 0.195 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.3 class 2 = 0.381 +- 0.195 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.3 class 3 = 0.362 +- 0.195 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.3 class 4 = 0.346 +- 0.195 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.3 class 5 = 0.381 +- 0.195 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.3 class 6 = 0.355 +- 0.195 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.3 class 7 = 0.364 +- 0.195 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.3 class 8 = 0.374 +- 0.195 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.3 class 9 = 0.338 +- 0.195 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.3 all KL = 0.156 +- 0.195 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.3 all L1 = 0.35 +- 0.169 (in-sample avg dev_std = 0.554)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.134
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.112
SUFF++ for r=0.6 class 0 = 0.311 +- 0.157 (in-sample avg dev_std = 0.525)
SUFF++ for r=0.6 class 1 = 0.217 +- 0.157 (in-sample avg dev_std = 0.525)
SUFF++ for r=0.6 class 2 = 0.279 +- 0.157 (in-sample avg dev_std = 0.525)
SUFF++ for r=0.6 class 3 = 0.309 +- 0.157 (in-sample avg dev_std = 0.525)
SUFF++ for r=0.6 class 4 = 0.253 +- 0.157 (in-sample avg dev_std = 0.525)
SUFF++ for r=0.6 class 5 = 0.295 +- 0.157 (in-sample avg dev_std = 0.525)
SUFF++ for r=0.6 class 6 = 0.26 +- 0.157 (in-sample avg dev_std = 0.525)
SUFF++ for r=0.6 class 7 = 0.286 +- 0.157 (in-sample avg dev_std = 0.525)
SUFF++ for r=0.6 class 8 = 0.336 +- 0.157 (in-sample avg dev_std = 0.525)
SUFF++ for r=0.6 class 9 = 0.251 +- 0.157 (in-sample avg dev_std = 0.525)
SUFF++ for r=0.6 all KL = 0.092 +- 0.157 (in-sample avg dev_std = 0.525)
SUFF++ for r=0.6 all L1 = 0.279 +- 0.142 (in-sample avg dev_std = 0.525)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.2
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.156
SUFF++ for r=0.9 class 0 = 0.401 +- 0.227 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 class 1 = 0.265 +- 0.227 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 class 2 = 0.35 +- 0.227 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 class 3 = 0.329 +- 0.227 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 class 4 = 0.307 +- 0.227 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 class 5 = 0.325 +- 0.227 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 class 6 = 0.313 +- 0.227 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 class 7 = 0.348 +- 0.227 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 class 8 = 0.299 +- 0.227 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 class 9 = 0.298 +- 0.227 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 all KL = 0.177 +- 0.227 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 all L1 = 0.324 +- 0.195 (in-sample avg dev_std = 0.421)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.096
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.097
NEC for r=0.3 class 0 = 0.636 +- 0.251 (in-sample avg dev_std = 0.510)
NEC for r=0.3 class 1 = 0.706 +- 0.251 (in-sample avg dev_std = 0.510)
NEC for r=0.3 class 2 = 0.587 +- 0.251 (in-sample avg dev_std = 0.510)
NEC for r=0.3 class 3 = 0.607 +- 0.251 (in-sample avg dev_std = 0.510)
NEC for r=0.3 class 4 = 0.65 +- 0.251 (in-sample avg dev_std = 0.510)
NEC for r=0.3 class 5 = 0.604 +- 0.251 (in-sample avg dev_std = 0.510)
NEC for r=0.3 class 6 = 0.582 +- 0.251 (in-sample avg dev_std = 0.510)
NEC for r=0.3 class 7 = 0.617 +- 0.251 (in-sample avg dev_std = 0.510)
NEC for r=0.3 class 8 = 0.552 +- 0.251 (in-sample avg dev_std = 0.510)
NEC for r=0.3 class 9 = 0.634 +- 0.251 (in-sample avg dev_std = 0.510)
NEC for r=0.3 all KL = 0.773 +- 0.251 (in-sample avg dev_std = 0.510)
NEC for r=0.3 all L1 = 0.618 +- 0.202 (in-sample avg dev_std = 0.510)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.134
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.108
NEC for r=0.6 class 0 = 0.659 +- 0.237 (in-sample avg dev_std = 0.497)
NEC for r=0.6 class 1 = 0.732 +- 0.237 (in-sample avg dev_std = 0.497)
NEC for r=0.6 class 2 = 0.668 +- 0.237 (in-sample avg dev_std = 0.497)
NEC for r=0.6 class 3 = 0.64 +- 0.237 (in-sample avg dev_std = 0.497)
NEC for r=0.6 class 4 = 0.656 +- 0.237 (in-sample avg dev_std = 0.497)
NEC for r=0.6 class 5 = 0.616 +- 0.237 (in-sample avg dev_std = 0.497)
NEC for r=0.6 class 6 = 0.651 +- 0.237 (in-sample avg dev_std = 0.497)
NEC for r=0.6 class 7 = 0.649 +- 0.237 (in-sample avg dev_std = 0.497)
NEC for r=0.6 class 8 = 0.58 +- 0.237 (in-sample avg dev_std = 0.497)
NEC for r=0.6 class 9 = 0.654 +- 0.237 (in-sample avg dev_std = 0.497)
NEC for r=0.6 all KL = 0.817 +- 0.237 (in-sample avg dev_std = 0.497)
NEC for r=0.6 all L1 = 0.652 +- 0.200 (in-sample avg dev_std = 0.497)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.2
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.209
NEC for r=0.9 class 0 = 0.637 +- 0.234 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 1 = 0.588 +- 0.234 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 2 = 0.64 +- 0.234 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 3 = 0.647 +- 0.234 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 4 = 0.71 +- 0.234 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 5 = 0.697 +- 0.234 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 6 = 0.677 +- 0.234 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 7 = 0.678 +- 0.234 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 8 = 0.716 +- 0.234 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 9 = 0.692 +- 0.234 (in-sample avg dev_std = 0.432)
NEC for r=0.9 all KL = 0.825 +- 0.234 (in-sample avg dev_std = 0.432)
NEC for r=0.9 all L1 = 0.667 +- 0.208 (in-sample avg dev_std = 0.432)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.265
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.341
NEC for r=1.0 class 0 = 0.631 +- 0.297 (in-sample avg dev_std = 0.358)
NEC for r=1.0 class 1 = 0.442 +- 0.297 (in-sample avg dev_std = 0.358)
NEC for r=1.0 class 2 = 0.665 +- 0.297 (in-sample avg dev_std = 0.358)
NEC for r=1.0 class 3 = 0.676 +- 0.297 (in-sample avg dev_std = 0.358)
NEC for r=1.0 class 4 = 0.682 +- 0.297 (in-sample avg dev_std = 0.358)
NEC for r=1.0 class 5 = 0.637 +- 0.297 (in-sample avg dev_std = 0.358)
NEC for r=1.0 class 6 = 0.644 +- 0.297 (in-sample avg dev_std = 0.358)
NEC for r=1.0 class 7 = 0.568 +- 0.297 (in-sample avg dev_std = 0.358)
NEC for r=1.0 class 8 = 0.692 +- 0.297 (in-sample avg dev_std = 0.358)
NEC for r=1.0 class 9 = 0.637 +- 0.297 (in-sample avg dev_std = 0.358)
NEC for r=1.0 all KL = 0.737 +- 0.297 (in-sample avg dev_std = 0.358)
NEC for r=1.0 all L1 = 0.625 +- 0.244 (in-sample avg dev_std = 0.358)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.521, 0.223, 0.286, 1.0], 'all_L1': [0.645, 0.358, 0.408, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.522, 0.28, 0.129, 1.0], 'all_L1': [0.644, 0.439, 0.293, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.14, 0.151, 0.151, 1.0], 'all_L1': [0.328, 0.319, 0.312, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.169, 0.041, 0.236, 1.0], 'all_L1': [0.364, 0.247, 0.41, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.156, 0.092, 0.177, 1.0], 'all_L1': [0.35, 0.279, 0.324, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.492, 0.729, 0.817, 0.735], 'all_L1': [0.374, 0.611, 0.675, 0.633]}), defaultdict(<class 'list'>, {'all_KL': [0.483, 0.709, 0.87, 0.777], 'all_L1': [0.363, 0.56, 0.7, 0.639]}), defaultdict(<class 'list'>, {'all_KL': [0.742, 0.771, 0.849, 0.711], 'all_L1': [0.6, 0.634, 0.698, 0.614]}), defaultdict(<class 'list'>, {'all_KL': [0.624, 0.825, 0.799, 0.839], 'all_L1': [0.512, 0.64, 0.624, 0.664]}), defaultdict(<class 'list'>, {'all_KL': [0.773, 0.817, 0.825, 0.737], 'all_L1': [0.618, 0.652, 0.667, 0.625]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split test
suff++ class all_L1  =  0.466 +- 0.146, 0.328 +- 0.067, 0.349 +- 0.050, 1.000 +- 0.000
suff++ class all_KL  =  0.302 +- 0.180, 0.157 +- 0.086, 0.196 +- 0.058, 1.000 +- 0.000
suff++_acc_int  =  0.102 +- 0.010, 0.111 +- 0.008, 0.162 +- 0.026
nec class all_L1  =  0.493 +- 0.108, 0.619 +- 0.033, 0.673 +- 0.028, 0.635 +- 0.017
nec class all_KL  =  0.623 +- 0.121, 0.770 +- 0.046, 0.832 +- 0.025, 0.760 +- 0.045
nec_acc_int  =  0.106 +- 0.009, 0.115 +- 0.015, 0.226 +- 0.051, 0.354 +- 0.029


 -------------------------------------------------- 
Computing faithfulness

Eval split test
Faith. Aritm (L1)= 		  =  0.480 +- 0.026, 0.474 +- 0.019, 0.511 +- 0.017, 0.817 +- 0.008
Faith. Armon (L1)= 		  =  0.447 +- 0.020, 0.423 +- 0.047, 0.457 +- 0.038, 0.777 +- 0.012
Faith. GMean (L1)= 	  =  0.463 +- 0.023, 0.447 +- 0.034, 0.483 +- 0.027, 0.797 +- 0.010
Faith. Aritm (KL)= 		  =  0.462 +- 0.041, 0.464 +- 0.021, 0.514 +- 0.020, 0.880 +- 0.022
Faith. Armon (KL)= 		  =  0.354 +- 0.123, 0.248 +- 0.117, 0.312 +- 0.073, 0.863 +- 0.028
Faith. GMean (KL)= 	  =  0.401 +- 0.085, 0.330 +- 0.093, 0.399 +- 0.054, 0.871 +- 0.025
Computed for split load_split = id



Completed in  0:39:11.770448  for GSATGIN GOODCMNIST/color



DONE GSAT GOODCMNIST/color nov

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun May 12 15:53:53 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/12/2024 03:53:54 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/12/2024 03:53:54 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/12/2024 03:53:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/12/2024 03:53:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:53:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/12/2024 03:53:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:53:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/12/2024 03:53:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:53:54 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 05/12/2024 03:53:54 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 171...
[0m[1;37mINFO[0m: [1mCheckpoint 171: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.9108
ID Validation Loss: 0.6777
ID Test ACCURACY: 0.9070
ID Test Loss: 0.7678
OOD Validation ACCURACY: 0.8696
OOD Validation Loss: 0.8953
OOD Test ACCURACY: 0.8189
OOD Test Loss: 1.1731

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 172...
[0m[1;37mINFO[0m: [1mCheckpoint 172: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.9085
ID Validation Loss: 0.6426
ID Test ACCURACY: 0.9093
ID Test Loss: 0.7163
OOD Validation ACCURACY: 0.8700
OOD Validation Loss: 0.8695
OOD Test ACCURACY: 0.8171
OOD Test Loss: 1.1992

[0m[1;37mINFO[0m: [1mChartInfo 0.9070 0.8189 0.9093 0.8171 0.9085 0.8700[0mGOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.734
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.671
SUFF++ for r=0.3 class 0.0 = 0.951 +- 0.340 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.3 class 1.0 = 0.715 +- 0.340 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.3 all KL = 0.735 +- 0.340 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.3 all L1 = 0.829 +- 0.214 (in-sample avg dev_std = 0.459)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.829
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.783
SUFF++ for r=0.6 class 0.0 = 0.903 +- 0.287 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.6 class 1.0 = 0.791 +- 0.287 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.6 all KL = 0.759 +- 0.287 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.6 all L1 = 0.845 +- 0.183 (in-sample avg dev_std = 0.397)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.85
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.844
SUFF++ for r=0.9 class 0.0 = 0.92 +- 0.123 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.9 class 1.0 = 0.934 +- 0.123 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.9 all KL = 0.942 +- 0.123 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.9 all L1 = 0.927 +- 0.142 (in-sample avg dev_std = 0.182)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.734
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.748
NEC for r=0.3 class 0.0 = 0.039 +- 0.207 (in-sample avg dev_std = 0.202)
NEC for r=0.3 class 1.0 = 0.144 +- 0.207 (in-sample avg dev_std = 0.202)
NEC for r=0.3 all KL = 0.093 +- 0.207 (in-sample avg dev_std = 0.202)
NEC for r=0.3 all L1 = 0.093 +- 0.186 (in-sample avg dev_std = 0.202)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.829
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.82
NEC for r=0.6 class 0.0 = 0.067 +- 0.167 (in-sample avg dev_std = 0.184)
NEC for r=0.6 class 1.0 = 0.101 +- 0.167 (in-sample avg dev_std = 0.184)
NEC for r=0.6 all KL = 0.072 +- 0.167 (in-sample avg dev_std = 0.184)
NEC for r=0.6 all L1 = 0.085 +- 0.168 (in-sample avg dev_std = 0.184)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.85
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.839
NEC for r=0.9 class 0.0 = 0.068 +- 0.113 (in-sample avg dev_std = 0.135)
NEC for r=0.9 class 1.0 = 0.049 +- 0.113 (in-sample avg dev_std = 0.135)
NEC for r=0.9 all KL = 0.043 +- 0.113 (in-sample avg dev_std = 0.135)
NEC for r=0.9 all L1 = 0.058 +- 0.125 (in-sample avg dev_std = 0.135)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.849
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.839
NEC for r=1.0 class 0.0 = 0.067 +- 0.122 (in-sample avg dev_std = 0.132)
NEC for r=1.0 class 1.0 = 0.039 +- 0.122 (in-sample avg dev_std = 0.132)
NEC for r=1.0 all KL = 0.043 +- 0.122 (in-sample avg dev_std = 0.132)
NEC for r=1.0 all L1 = 0.053 +- 0.125 (in-sample avg dev_std = 0.132)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun May 12 15:55:34 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/12/2024 03:55:35 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/12/2024 03:55:35 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/12/2024 03:55:35 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/12/2024 03:55:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:55:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/12/2024 03:55:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:55:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/12/2024 03:55:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:55:35 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 05/12/2024 03:55:36 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 189...
[0m[1;37mINFO[0m: [1mCheckpoint 189: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.9106
ID Validation Loss: 0.6509
ID Test ACCURACY: 0.9106
ID Test Loss: 0.7601
OOD Validation ACCURACY: 0.8655
OOD Validation Loss: 0.9153
OOD Test ACCURACY: 0.8004
OOD Test Loss: 1.3538

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 196...
[0m[1;37mINFO[0m: [1mCheckpoint 196: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.9081
ID Validation Loss: 0.6904
ID Test ACCURACY: 0.9102
ID Test Loss: 0.8084
OOD Validation ACCURACY: 0.8689
OOD Validation Loss: 1.0019
OOD Test ACCURACY: 0.8170
OOD Test Loss: 1.3197

[0m[1;37mINFO[0m: [1mChartInfo 0.9106 0.8004 0.9102 0.8170 0.9081 0.8689[0mGOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.824
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.749
SUFF++ for r=0.3 class 0.0 = 0.692 +- 0.370 (in-sample avg dev_std = 0.624)
SUFF++ for r=0.3 class 1.0 = 0.796 +- 0.370 (in-sample avg dev_std = 0.624)
SUFF++ for r=0.3 all KL = 0.454 +- 0.370 (in-sample avg dev_std = 0.624)
SUFF++ for r=0.3 all L1 = 0.746 +- 0.205 (in-sample avg dev_std = 0.624)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.853
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.801
SUFF++ for r=0.6 class 0.0 = 0.789 +- 0.315 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.6 class 1.0 = 0.882 +- 0.315 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.6 all KL = 0.708 +- 0.315 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.6 all L1 = 0.837 +- 0.183 (in-sample avg dev_std = 0.433)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.829
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.823
SUFF++ for r=0.9 class 0.0 = 0.899 +- 0.135 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.9 class 1.0 = 0.959 +- 0.135 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.9 all KL = 0.936 +- 0.135 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.9 all L1 = 0.93 +- 0.136 (in-sample avg dev_std = 0.190)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.824
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.825
NEC for r=0.3 class 0.0 = 0.153 +- 0.296 (in-sample avg dev_std = 0.290)
NEC for r=0.3 class 1.0 = 0.086 +- 0.296 (in-sample avg dev_std = 0.290)
NEC for r=0.3 all KL = 0.167 +- 0.296 (in-sample avg dev_std = 0.290)
NEC for r=0.3 all L1 = 0.118 +- 0.218 (in-sample avg dev_std = 0.290)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.853
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.837
NEC for r=0.6 class 0.0 = 0.108 +- 0.177 (in-sample avg dev_std = 0.198)
NEC for r=0.6 class 1.0 = 0.06 +- 0.177 (in-sample avg dev_std = 0.198)
NEC for r=0.6 all KL = 0.082 +- 0.177 (in-sample avg dev_std = 0.198)
NEC for r=0.6 all L1 = 0.083 +- 0.166 (in-sample avg dev_std = 0.198)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.829
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.825
NEC for r=0.9 class 0.0 = 0.089 +- 0.115 (in-sample avg dev_std = 0.139)
NEC for r=0.9 class 1.0 = 0.038 +- 0.115 (in-sample avg dev_std = 0.139)
NEC for r=0.9 all KL = 0.045 +- 0.115 (in-sample avg dev_std = 0.139)
NEC for r=0.9 all L1 = 0.063 +- 0.137 (in-sample avg dev_std = 0.139)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.83
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.82
NEC for r=1.0 class 0.0 = 0.086 +- 0.128 (in-sample avg dev_std = 0.147)
NEC for r=1.0 class 1.0 = 0.038 +- 0.128 (in-sample avg dev_std = 0.147)
NEC for r=1.0 all KL = 0.046 +- 0.128 (in-sample avg dev_std = 0.147)
NEC for r=1.0 all L1 = 0.061 +- 0.140 (in-sample avg dev_std = 0.147)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun May 12 15:57:13 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/12/2024 03:57:15 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/12/2024 03:57:15 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/12/2024 03:57:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/12/2024 03:57:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:57:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/12/2024 03:57:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:57:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/12/2024 03:57:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:57:15 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 05/12/2024 03:57:15 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 181...
[0m[1;37mINFO[0m: [1mCheckpoint 181: 
-----------------------------------
Train ACCURACY: 0.9999
Train Loss: 0.0003
ID Validation ACCURACY: 0.9083
ID Validation Loss: 0.6573
ID Test ACCURACY: 0.9010
ID Test Loss: 0.7687
OOD Validation ACCURACY: 0.8624
OOD Validation Loss: 0.9332
OOD Test ACCURACY: 0.7946
OOD Test Loss: 1.4098

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 144...
[0m[1;37mINFO[0m: [1mCheckpoint 144: 
-----------------------------------
Train ACCURACY: 0.9986
Train Loss: 0.0061
ID Validation ACCURACY: 0.9002
ID Validation Loss: 0.5441
ID Test ACCURACY: 0.9019
ID Test Loss: 0.6312
OOD Validation ACCURACY: 0.8690
OOD Validation Loss: 0.7354
OOD Test ACCURACY: 0.8188
OOD Test Loss: 0.9821

[0m[1;37mINFO[0m: [1mChartInfo 0.9010 0.7946 0.9019 0.8188 0.9002 0.8690[0mGOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.634
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.585
SUFF++ for r=0.3 class 0.0 = 0.783 +- 0.291 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.3 class 1.0 = 0.968 +- 0.291 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.3 all KL = 0.836 +- 0.291 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.3 all L1 = 0.879 +- 0.210 (in-sample avg dev_std = 0.350)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.714
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.649
SUFF++ for r=0.6 class 0.0 = 0.751 +- 0.289 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.6 class 1.0 = 0.976 +- 0.289 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.6 all KL = 0.827 +- 0.289 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.6 all L1 = 0.867 +- 0.207 (in-sample avg dev_std = 0.364)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.809
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.8
SUFF++ for r=0.9 class 0.0 = 0.876 +- 0.163 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.9 class 1.0 = 0.964 +- 0.163 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.9 all KL = 0.92 +- 0.163 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.9 all L1 = 0.921 +- 0.149 (in-sample avg dev_std = 0.213)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.634
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.636
NEC for r=0.3 class 0.0 = 0.159 +- 0.215 (in-sample avg dev_std = 0.214)
NEC for r=0.3 class 1.0 = 0.026 +- 0.215 (in-sample avg dev_std = 0.214)
NEC for r=0.3 all KL = 0.098 +- 0.215 (in-sample avg dev_std = 0.214)
NEC for r=0.3 all L1 = 0.09 +- 0.186 (in-sample avg dev_std = 0.214)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.714
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.706
NEC for r=0.6 class 0.0 = 0.143 +- 0.151 (in-sample avg dev_std = 0.165)
NEC for r=0.6 class 1.0 = 0.015 +- 0.151 (in-sample avg dev_std = 0.165)
NEC for r=0.6 all KL = 0.064 +- 0.151 (in-sample avg dev_std = 0.165)
NEC for r=0.6 all L1 = 0.077 +- 0.156 (in-sample avg dev_std = 0.165)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.809
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.8
NEC for r=0.9 class 0.0 = 0.121 +- 0.157 (in-sample avg dev_std = 0.173)
NEC for r=0.9 class 1.0 = 0.028 +- 0.157 (in-sample avg dev_std = 0.173)
NEC for r=0.9 all KL = 0.063 +- 0.157 (in-sample avg dev_std = 0.173)
NEC for r=0.9 all L1 = 0.073 +- 0.155 (in-sample avg dev_std = 0.173)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.824
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.811
NEC for r=1.0 class 0.0 = 0.095 +- 0.136 (in-sample avg dev_std = 0.152)
NEC for r=1.0 class 1.0 = 0.03 +- 0.136 (in-sample avg dev_std = 0.152)
NEC for r=1.0 all KL = 0.049 +- 0.136 (in-sample avg dev_std = 0.152)
NEC for r=1.0 all L1 = 0.061 +- 0.141 (in-sample avg dev_std = 0.152)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun May 12 15:58:52 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/12/2024 03:58:53 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/12/2024 03:58:53 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/12/2024 03:58:53 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/12/2024 03:58:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:58:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/12/2024 03:58:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:58:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/12/2024 03:58:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 03:58:53 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 05/12/2024 03:58:53 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 189...
[0m[1;37mINFO[0m: [1mCheckpoint 189: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.9123
ID Validation Loss: 0.7334
ID Test ACCURACY: 0.9047
ID Test Loss: 0.8153
OOD Validation ACCURACY: 0.8584
OOD Validation Loss: 1.0858
OOD Test ACCURACY: 0.8021
OOD Test Loss: 1.6001

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 192...
[0m[1;37mINFO[0m: [1mCheckpoint 192: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.9091
ID Validation Loss: 0.7365
ID Test ACCURACY: 0.9076
ID Test Loss: 0.8317
OOD Validation ACCURACY: 0.8656
OOD Validation Loss: 1.0826
OOD Test ACCURACY: 0.8208
OOD Test Loss: 1.3300

[0m[1;37mINFO[0m: [1mChartInfo 0.9047 0.8021 0.9076 0.8208 0.9091 0.8656[0mGOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.79
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.694
SUFF++ for r=0.3 class 0.0 = 0.661 +- 0.403 (in-sample avg dev_std = 0.570)
SUFF++ for r=0.3 class 1.0 = 0.872 +- 0.403 (in-sample avg dev_std = 0.570)
SUFF++ for r=0.3 all KL = 0.549 +- 0.403 (in-sample avg dev_std = 0.570)
SUFF++ for r=0.3 all L1 = 0.77 +- 0.233 (in-sample avg dev_std = 0.570)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.788
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.745
SUFF++ for r=0.6 class 0.0 = 0.769 +- 0.339 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 class 1.0 = 0.938 +- 0.339 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 all KL = 0.742 +- 0.339 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 all L1 = 0.856 +- 0.207 (in-sample avg dev_std = 0.417)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.809
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.791
SUFF++ for r=0.9 class 0.0 = 0.874 +- 0.205 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 class 1.0 = 0.965 +- 0.205 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 all KL = 0.904 +- 0.205 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 all L1 = 0.921 +- 0.165 (in-sample avg dev_std = 0.244)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.79
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.758
NEC for r=0.3 class 0.0 = 0.227 +- 0.336 (in-sample avg dev_std = 0.322)
NEC for r=0.3 class 1.0 = 0.054 +- 0.336 (in-sample avg dev_std = 0.322)
NEC for r=0.3 all KL = 0.202 +- 0.336 (in-sample avg dev_std = 0.322)
NEC for r=0.3 all L1 = 0.138 +- 0.232 (in-sample avg dev_std = 0.322)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.788
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.774
NEC for r=0.6 class 0.0 = 0.172 +- 0.271 (in-sample avg dev_std = 0.271)
NEC for r=0.6 class 1.0 = 0.039 +- 0.271 (in-sample avg dev_std = 0.271)
NEC for r=0.6 all KL = 0.132 +- 0.271 (in-sample avg dev_std = 0.271)
NEC for r=0.6 all L1 = 0.104 +- 0.208 (in-sample avg dev_std = 0.271)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.809
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.803
NEC for r=0.9 class 0.0 = 0.121 +- 0.198 (in-sample avg dev_std = 0.201)
NEC for r=0.9 class 1.0 = 0.03 +- 0.198 (in-sample avg dev_std = 0.201)
NEC for r=0.9 all KL = 0.08 +- 0.198 (in-sample avg dev_std = 0.201)
NEC for r=0.9 all L1 = 0.074 +- 0.172 (in-sample avg dev_std = 0.201)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.821
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.819
NEC for r=1.0 class 0.0 = 0.08 +- 0.145 (in-sample avg dev_std = 0.146)
NEC for r=1.0 class 1.0 = 0.03 +- 0.145 (in-sample avg dev_std = 0.146)
NEC for r=1.0 all KL = 0.049 +- 0.145 (in-sample avg dev_std = 0.146)
NEC for r=1.0 all L1 = 0.055 +- 0.143 (in-sample avg dev_std = 0.146)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun May 12 16:00:31 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/12/2024 04:00:32 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/12/2024 04:00:32 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/12/2024 04:00:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/12/2024 04:00:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 04:00:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/12/2024 04:00:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 04:00:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/12/2024 04:00:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/12/2024 04:00:32 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 05/12/2024 04:00:33 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 179...
[0m[1;37mINFO[0m: [1mCheckpoint 179: 
-----------------------------------
Train ACCURACY: 0.9999
Train Loss: 0.0002
ID Validation ACCURACY: 0.9125
ID Validation Loss: 0.6781
ID Test ACCURACY: 0.9078
ID Test Loss: 0.7621
OOD Validation ACCURACY: 0.8649
OOD Validation Loss: 0.8836
OOD Test ACCURACY: 0.8196
OOD Test Loss: 1.0439

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 141...
[0m[1;37mINFO[0m: [1mCheckpoint 141: 
-----------------------------------
Train ACCURACY: 0.9983
Train Loss: 0.0070
ID Validation ACCURACY: 0.9044
ID Validation Loss: 0.4896
ID Test ACCURACY: 0.9053
ID Test Loss: 0.5898
OOD Validation ACCURACY: 0.8681
OOD Validation Loss: 0.7049
OOD Test ACCURACY: 0.8276
OOD Test Loss: 0.8462

[0m[1;37mINFO[0m: [1mChartInfo 0.9078 0.8196 0.9053 0.8276 0.9044 0.8681[0mGOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.801
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.711
SUFF++ for r=0.3 class 0.0 = 0.644 +- 0.299 (in-sample avg dev_std = 0.591)
SUFF++ for r=0.3 class 1.0 = 0.737 +- 0.299 (in-sample avg dev_std = 0.591)
SUFF++ for r=0.3 all KL = 0.497 +- 0.299 (in-sample avg dev_std = 0.591)
SUFF++ for r=0.3 all L1 = 0.692 +- 0.192 (in-sample avg dev_std = 0.591)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.788
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.73
SUFF++ for r=0.6 class 0.0 = 0.674 +- 0.289 (in-sample avg dev_std = 0.457)
SUFF++ for r=0.6 class 1.0 = 0.877 +- 0.289 (in-sample avg dev_std = 0.457)
SUFF++ for r=0.6 all KL = 0.687 +- 0.289 (in-sample avg dev_std = 0.457)
SUFF++ for r=0.6 all L1 = 0.779 +- 0.206 (in-sample avg dev_std = 0.457)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.831
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.819
SUFF++ for r=0.9 class 0.0 = 0.867 +- 0.149 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.9 class 1.0 = 0.941 +- 0.149 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.9 all KL = 0.911 +- 0.149 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.9 all L1 = 0.905 +- 0.154 (in-sample avg dev_std = 0.211)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.801
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.786
NEC for r=0.3 class 0.0 = 0.192 +- 0.254 (in-sample avg dev_std = 0.286)
NEC for r=0.3 class 1.0 = 0.141 +- 0.254 (in-sample avg dev_std = 0.286)
NEC for r=0.3 all KL = 0.17 +- 0.254 (in-sample avg dev_std = 0.286)
NEC for r=0.3 all L1 = 0.166 +- 0.223 (in-sample avg dev_std = 0.286)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.788
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.778
NEC for r=0.6 class 0.0 = 0.18 +- 0.187 (in-sample avg dev_std = 0.223)
NEC for r=0.6 class 1.0 = 0.076 +- 0.187 (in-sample avg dev_std = 0.223)
NEC for r=0.6 all KL = 0.107 +- 0.187 (in-sample avg dev_std = 0.223)
NEC for r=0.6 all L1 = 0.126 +- 0.192 (in-sample avg dev_std = 0.223)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.831
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.825
NEC for r=0.9 class 0.0 = 0.106 +- 0.135 (in-sample avg dev_std = 0.163)
NEC for r=0.9 class 1.0 = 0.05 +- 0.135 (in-sample avg dev_std = 0.163)
NEC for r=0.9 all KL = 0.057 +- 0.135 (in-sample avg dev_std = 0.163)
NEC for r=0.9 all L1 = 0.077 +- 0.154 (in-sample avg dev_std = 0.163)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.854
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.841
NEC for r=1.0 class 0.0 = 0.069 +- 0.111 (in-sample avg dev_std = 0.130)
NEC for r=1.0 class 1.0 = 0.042 +- 0.111 (in-sample avg dev_std = 0.130)
NEC for r=1.0 all KL = 0.039 +- 0.111 (in-sample avg dev_std = 0.130)
NEC for r=1.0 all L1 = 0.055 +- 0.125 (in-sample avg dev_std = 0.130)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.735, 0.759, 0.942, 1.0], 'all_L1': [0.829, 0.845, 0.927, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.454, 0.708, 0.936, 1.0], 'all_L1': [0.746, 0.837, 0.93, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.836, 0.827, 0.92, 1.0], 'all_L1': [0.879, 0.867, 0.921, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.549, 0.742, 0.904, 1.0], 'all_L1': [0.77, 0.856, 0.921, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.497, 0.687, 0.911, 1.0], 'all_L1': [0.692, 0.779, 0.905, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.093, 0.072, 0.043, 0.043], 'all_L1': [0.093, 0.085, 0.058, 0.053]}), defaultdict(<class 'list'>, {'all_KL': [0.167, 0.082, 0.045, 0.046], 'all_L1': [0.118, 0.083, 0.063, 0.061]}), defaultdict(<class 'list'>, {'all_KL': [0.098, 0.064, 0.063, 0.049], 'all_L1': [0.09, 0.077, 0.073, 0.061]}), defaultdict(<class 'list'>, {'all_KL': [0.202, 0.132, 0.08, 0.049], 'all_L1': [0.138, 0.104, 0.074, 0.055]}), defaultdict(<class 'list'>, {'all_KL': [0.17, 0.107, 0.057, 0.039], 'all_L1': [0.166, 0.126, 0.077, 0.055]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split test
suff++ class all_L1  =  0.783 +- 0.065, 0.837 +- 0.031, 0.921 +- 0.009, 1.000 +- 0.000
suff++ class all_KL  =  0.614 +- 0.147, 0.745 +- 0.048, 0.923 +- 0.014, 1.000 +- 0.000
suff++_acc_int  =  0.682 +- 0.055, 0.741 +- 0.053, 0.815 +- 0.019
nec class all_L1  =  0.121 +- 0.029, 0.095 +- 0.018, 0.069 +- 0.007, 0.057 +- 0.003
nec class all_KL  =  0.146 +- 0.043, 0.091 +- 0.025, 0.058 +- 0.013, 0.045 +- 0.004
nec_acc_int  =  0.751 +- 0.063, 0.783 +- 0.045, 0.818 +- 0.015, 0.826 +- 0.012


 -------------------------------------------------- 
Computing faithfulness

Eval split test
Faith. Aritm (L1)= 		  =  0.452 +- 0.020, 0.466 +- 0.009, 0.495 +- 0.003, 0.528 +- 0.002
Faith. Armon (L1)= 		  =  0.207 +- 0.040, 0.170 +- 0.028, 0.128 +- 0.013, 0.108 +- 0.006
Faith. GMean (L1)= 	  =  0.304 +- 0.024, 0.280 +- 0.022, 0.252 +- 0.013, 0.239 +- 0.007
Faith. Aritm (KL)= 		  =  0.380 +- 0.056, 0.418 +- 0.020, 0.490 +- 0.003, 0.523 +- 0.002
Faith. Armon (KL)= 		  =  0.227 +- 0.049, 0.161 +- 0.039, 0.108 +- 0.024, 0.086 +- 0.007
Faith. GMean (KL)= 	  =  0.289 +- 0.024, 0.258 +- 0.031, 0.229 +- 0.025, 0.212 +- 0.009
Computed for split load_split = id



Completed in  0:08:19.663312  for GSATGIN GOODSST2/length



DONE GSAT GOODSST2/length nov
DONE all :)
