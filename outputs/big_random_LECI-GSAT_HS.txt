nohup: ignoring input
Time to compute metrics for random explanations!
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 13:50:56 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:56 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 199...
[0m[1;37mINFO[0m: [1mCheckpoint 199: 
-----------------------------------
Train ACCURACY: 0.8919
Train Loss: 0.4402
ID Validation ACCURACY: 0.8920
ID Validation Loss: 0.4334
ID Test ACCURACY: 0.8870
ID Test Loss: 0.4639
OOD Validation ACCURACY: 0.7780
OOD Validation Loss: 0.6049
OOD Test ACCURACY: 0.7937
OOD Test Loss: 0.6760

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 135...
[0m[1;37mINFO[0m: [1mCheckpoint 135: 
-----------------------------------
Train ACCURACY: 0.8381
Train Loss: 0.5254
ID Validation ACCURACY: 0.8367
ID Validation Loss: 0.5281
ID Test ACCURACY: 0.8403
ID Test Loss: 0.5399
OOD Validation ACCURACY: 0.9063
OOD Validation Loss: 0.5418
OOD Test ACCURACY: 0.8933
OOD Test Loss: 0.4537

[0m[1;37mINFO[0m: [1mChartInfo 0.8870 0.7937 0.8403 0.8933 0.8367 0.9063[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.080
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.242
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.298
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.311
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.121
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.211
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.248
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.252


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.567
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.079995
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.37
SUFF++ for r=0.3 class 0 = 0.543 +- 0.317 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.3 class 1 = 0.586 +- 0.317 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.3 class 2 = 0.463 +- 0.317 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.3 all KL = 0.579 +- 0.317 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.3 all L1 = 0.531 +- 0.186 (in-sample avg dev_std = 0.383)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.676
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.24204499999999998
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.426
SUFF++ for r=0.6 class 0 = 0.535 +- 0.286 (in-sample avg dev_std = 0.440)
SUFF++ for r=0.6 class 1 = 0.58 +- 0.286 (in-sample avg dev_std = 0.440)
SUFF++ for r=0.6 class 2 = 0.44 +- 0.286 (in-sample avg dev_std = 0.440)
SUFF++ for r=0.6 all KL = 0.56 +- 0.286 (in-sample avg dev_std = 0.440)
SUFF++ for r=0.6 all L1 = 0.519 +- 0.186 (in-sample avg dev_std = 0.440)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.873
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.29784125
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.515
SUFF++ for r=0.9 class 0 = 0.588 +- 0.303 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.9 class 1 = 0.658 +- 0.303 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.9 class 2 = 0.42 +- 0.303 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.9 all KL = 0.603 +- 0.303 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.9 all L1 = 0.556 +- 0.228 (in-sample avg dev_std = 0.371)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.565
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.12057999999999999
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.39
SUFF++ for r=0.3 class 0 = 0.497 +- 0.238 (in-sample avg dev_std = 0.422)
SUFF++ for r=0.3 class 1 = 0.588 +- 0.238 (in-sample avg dev_std = 0.422)
SUFF++ for r=0.3 class 2 = 0.495 +- 0.238 (in-sample avg dev_std = 0.422)
SUFF++ for r=0.3 all KL = 0.622 +- 0.238 (in-sample avg dev_std = 0.422)
SUFF++ for r=0.3 all L1 = 0.527 +- 0.126 (in-sample avg dev_std = 0.422)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.846
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.21075875
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.459
SUFF++ for r=0.6 class 0 = 0.381 +- 0.283 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.6 class 1 = 0.478 +- 0.283 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.6 class 2 = 0.362 +- 0.283 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.6 all KL = 0.369 +- 0.283 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.6 all L1 = 0.408 +- 0.147 (in-sample avg dev_std = 0.519)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.798
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.24755624999999998
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.548
SUFF++ for r=0.9 class 0 = 0.501 +- 0.291 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.9 class 1 = 0.524 +- 0.291 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.9 class 2 = 0.488 +- 0.291 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.9 all KL = 0.487 +- 0.291 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.9 all L1 = 0.505 +- 0.187 (in-sample avg dev_std = 0.428)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.567
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.079995
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.417
NEC for r=0.3 class 0 = 0.405 +- 0.297 (in-sample avg dev_std = 0.396)
NEC for r=0.3 class 1 = 0.375 +- 0.297 (in-sample avg dev_std = 0.396)
NEC for r=0.3 class 2 = 0.479 +- 0.297 (in-sample avg dev_std = 0.396)
NEC for r=0.3 all KL = 0.376 +- 0.297 (in-sample avg dev_std = 0.396)
NEC for r=0.3 all L1 = 0.419 +- 0.194 (in-sample avg dev_std = 0.396)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.676
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.24204499999999998
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.543
NEC for r=0.6 class 0 = 0.385 +- 0.272 (in-sample avg dev_std = 0.469)
NEC for r=0.6 class 1 = 0.385 +- 0.272 (in-sample avg dev_std = 0.469)
NEC for r=0.6 class 2 = 0.443 +- 0.272 (in-sample avg dev_std = 0.469)
NEC for r=0.6 all KL = 0.364 +- 0.272 (in-sample avg dev_std = 0.469)
NEC for r=0.6 all L1 = 0.404 +- 0.177 (in-sample avg dev_std = 0.469)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.873
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.29784125
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.618
NEC for r=0.9 class 0 = 0.447 +- 0.263 (in-sample avg dev_std = 0.470)
NEC for r=0.9 class 1 = 0.388 +- 0.263 (in-sample avg dev_std = 0.470)
NEC for r=0.9 class 2 = 0.494 +- 0.263 (in-sample avg dev_std = 0.470)
NEC for r=0.9 all KL = 0.41 +- 0.263 (in-sample avg dev_std = 0.470)
NEC for r=0.9 all L1 = 0.443 +- 0.167 (in-sample avg dev_std = 0.470)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.913
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.31081875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.632
NEC for r=1.0 class 0 = 0.431 +- 0.258 (in-sample avg dev_std = 0.493)
NEC for r=1.0 class 1 = 0.384 +- 0.258 (in-sample avg dev_std = 0.493)
NEC for r=1.0 class 2 = 0.527 +- 0.258 (in-sample avg dev_std = 0.493)
NEC for r=1.0 all KL = 0.425 +- 0.258 (in-sample avg dev_std = 0.493)
NEC for r=1.0 all L1 = 0.447 +- 0.153 (in-sample avg dev_std = 0.493)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.565
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.12057999999999999
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.475
NEC for r=0.3 class 0 = 0.422 +- 0.210 (in-sample avg dev_std = 0.432)
NEC for r=0.3 class 1 = 0.334 +- 0.210 (in-sample avg dev_std = 0.432)
NEC for r=0.3 class 2 = 0.464 +- 0.210 (in-sample avg dev_std = 0.432)
NEC for r=0.3 all KL = 0.319 +- 0.210 (in-sample avg dev_std = 0.432)
NEC for r=0.3 all L1 = 0.406 +- 0.147 (in-sample avg dev_std = 0.432)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.846
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.21075875
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.574
NEC for r=0.6 class 0 = 0.487 +- 0.368 (in-sample avg dev_std = 0.538)
NEC for r=0.6 class 1 = 0.466 +- 0.368 (in-sample avg dev_std = 0.538)
NEC for r=0.6 class 2 = 0.506 +- 0.368 (in-sample avg dev_std = 0.538)
NEC for r=0.6 all KL = 0.519 +- 0.368 (in-sample avg dev_std = 0.538)
NEC for r=0.6 all L1 = 0.486 +- 0.218 (in-sample avg dev_std = 0.538)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.798
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.24755624999999998
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.634
NEC for r=0.9 class 0 = 0.496 +- 0.292 (in-sample avg dev_std = 0.557)
NEC for r=0.9 class 1 = 0.484 +- 0.292 (in-sample avg dev_std = 0.557)
NEC for r=0.9 class 2 = 0.404 +- 0.292 (in-sample avg dev_std = 0.557)
NEC for r=0.9 all KL = 0.514 +- 0.292 (in-sample avg dev_std = 0.557)
NEC for r=0.9 all L1 = 0.461 +- 0.155 (in-sample avg dev_std = 0.557)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.799
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.25213624999999995
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.63
NEC for r=1.0 class 0 = 0.484 +- 0.283 (in-sample avg dev_std = 0.559)
NEC for r=1.0 class 1 = 0.487 +- 0.283 (in-sample avg dev_std = 0.559)
NEC for r=1.0 class 2 = 0.424 +- 0.283 (in-sample avg dev_std = 0.559)
NEC for r=1.0 all KL = 0.516 +- 0.283 (in-sample avg dev_std = 0.559)
NEC for r=1.0 all L1 = 0.465 +- 0.149 (in-sample avg dev_std = 0.559)
model_dirname= repr_LECIGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 13:53:38 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:38 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 107...
[0m[1;37mINFO[0m: [1mCheckpoint 107: 
-----------------------------------
Train ACCURACY: 0.8941
Train Loss: 0.4387
ID Validation ACCURACY: 0.8933
ID Validation Loss: 0.4199
ID Test ACCURACY: 0.8857
ID Test Loss: 0.4740
OOD Validation ACCURACY: 0.9263
OOD Validation Loss: 0.4243
OOD Test ACCURACY: 0.9167
OOD Test Loss: 0.3882

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 107...
[0m[1;37mINFO[0m: [1mCheckpoint 107: 
-----------------------------------
Train ACCURACY: 0.8941
Train Loss: 0.4387
ID Validation ACCURACY: 0.8933
ID Validation Loss: 0.4199
ID Test ACCURACY: 0.8857
ID Test Loss: 0.4740
OOD Validation ACCURACY: 0.9263
OOD Validation Loss: 0.4243
OOD Test ACCURACY: 0.9167
OOD Test Loss: 0.3882

[0m[1;37mINFO[0m: [1mChartInfo 0.8857 0.9167 0.8857 0.9167 0.8933 0.9263[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.149
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.235
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.305
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.311
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.119
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.214
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.249
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.255


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.452
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.14871375
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.343
SUFF++ for r=0.3 class 0 = 0.527 +- 0.255 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.3 class 1 = 0.555 +- 0.255 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.3 class 2 = 0.462 +- 0.255 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.3 all KL = 0.632 +- 0.255 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.3 all L1 = 0.515 +- 0.136 (in-sample avg dev_std = 0.350)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.79
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.23511125
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.401
SUFF++ for r=0.6 class 0 = 0.413 +- 0.268 (in-sample avg dev_std = 0.512)
SUFF++ for r=0.6 class 1 = 0.503 +- 0.268 (in-sample avg dev_std = 0.512)
SUFF++ for r=0.6 class 2 = 0.34 +- 0.268 (in-sample avg dev_std = 0.512)
SUFF++ for r=0.6 all KL = 0.392 +- 0.268 (in-sample avg dev_std = 0.512)
SUFF++ for r=0.6 all L1 = 0.419 +- 0.144 (in-sample avg dev_std = 0.512)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.896
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.30470125
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.563
SUFF++ for r=0.9 class 0 = 0.554 +- 0.309 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.9 class 1 = 0.636 +- 0.309 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.9 class 2 = 0.484 +- 0.309 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.9 all KL = 0.552 +- 0.309 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.9 all L1 = 0.558 +- 0.232 (in-sample avg dev_std = 0.427)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.576
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.11890999999999999
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.466
SUFF++ for r=0.3 class 0 = 0.458 +- 0.233 (in-sample avg dev_std = 0.552)
SUFF++ for r=0.3 class 1 = 0.438 +- 0.233 (in-sample avg dev_std = 0.552)
SUFF++ for r=0.3 class 2 = 0.385 +- 0.233 (in-sample avg dev_std = 0.552)
SUFF++ for r=0.3 all KL = 0.396 +- 0.233 (in-sample avg dev_std = 0.552)
SUFF++ for r=0.3 all L1 = 0.427 +- 0.118 (in-sample avg dev_std = 0.552)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.841
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.21444000000000002
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.405
SUFF++ for r=0.6 class 0 = 0.389 +- 0.283 (in-sample avg dev_std = 0.536)
SUFF++ for r=0.6 class 1 = 0.452 +- 0.283 (in-sample avg dev_std = 0.536)
SUFF++ for r=0.6 class 2 = 0.32 +- 0.283 (in-sample avg dev_std = 0.536)
SUFF++ for r=0.6 all KL = 0.342 +- 0.283 (in-sample avg dev_std = 0.536)
SUFF++ for r=0.6 all L1 = 0.388 +- 0.140 (in-sample avg dev_std = 0.536)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.913
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.24853999999999998
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.442
SUFF++ for r=0.9 class 0 = 0.433 +- 0.276 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.9 class 1 = 0.425 +- 0.276 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.9 class 2 = 0.462 +- 0.276 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.9 all KL = 0.423 +- 0.276 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.9 all L1 = 0.44 +- 0.191 (in-sample avg dev_std = 0.444)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.452
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.14871375
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.367
NEC for r=0.3 class 0 = 0.455 +- 0.259 (in-sample avg dev_std = 0.345)
NEC for r=0.3 class 1 = 0.409 +- 0.259 (in-sample avg dev_std = 0.345)
NEC for r=0.3 class 2 = 0.491 +- 0.259 (in-sample avg dev_std = 0.345)
NEC for r=0.3 all KL = 0.337 +- 0.259 (in-sample avg dev_std = 0.345)
NEC for r=0.3 all L1 = 0.452 +- 0.160 (in-sample avg dev_std = 0.345)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.79
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.23511125
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.533
NEC for r=0.6 class 0 = 0.512 +- 0.290 (in-sample avg dev_std = 0.557)
NEC for r=0.6 class 1 = 0.497 +- 0.290 (in-sample avg dev_std = 0.557)
NEC for r=0.6 class 2 = 0.527 +- 0.290 (in-sample avg dev_std = 0.557)
NEC for r=0.6 all KL = 0.55 +- 0.290 (in-sample avg dev_std = 0.557)
NEC for r=0.6 all L1 = 0.512 +- 0.168 (in-sample avg dev_std = 0.557)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.896
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.30470125
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.57
NEC for r=0.9 class 0 = 0.486 +- 0.293 (in-sample avg dev_std = 0.560)
NEC for r=0.9 class 1 = 0.502 +- 0.293 (in-sample avg dev_std = 0.560)
NEC for r=0.9 class 2 = 0.518 +- 0.293 (in-sample avg dev_std = 0.560)
NEC for r=0.9 all KL = 0.545 +- 0.293 (in-sample avg dev_std = 0.560)
NEC for r=0.9 all L1 = 0.502 +- 0.170 (in-sample avg dev_std = 0.560)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.909
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.310685
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.565
NEC for r=1.0 class 0 = 0.496 +- 0.275 (in-sample avg dev_std = 0.558)
NEC for r=1.0 class 1 = 0.495 +- 0.275 (in-sample avg dev_std = 0.558)
NEC for r=1.0 class 2 = 0.525 +- 0.275 (in-sample avg dev_std = 0.558)
NEC for r=1.0 all KL = 0.547 +- 0.275 (in-sample avg dev_std = 0.558)
NEC for r=1.0 all L1 = 0.505 +- 0.153 (in-sample avg dev_std = 0.558)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.576
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.11890999999999999
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.605
NEC for r=0.3 class 0 = 0.376 +- 0.295 (in-sample avg dev_std = 0.450)
NEC for r=0.3 class 1 = 0.417 +- 0.295 (in-sample avg dev_std = 0.450)
NEC for r=0.3 class 2 = 0.399 +- 0.295 (in-sample avg dev_std = 0.450)
NEC for r=0.3 all KL = 0.401 +- 0.295 (in-sample avg dev_std = 0.450)
NEC for r=0.3 all L1 = 0.398 +- 0.242 (in-sample avg dev_std = 0.450)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.841
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.21444000000000002
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.602
NEC for r=0.6 class 0 = 0.355 +- 0.390 (in-sample avg dev_std = 0.457)
NEC for r=0.6 class 1 = 0.391 +- 0.390 (in-sample avg dev_std = 0.457)
NEC for r=0.6 class 2 = 0.434 +- 0.390 (in-sample avg dev_std = 0.457)
NEC for r=0.6 all KL = 0.438 +- 0.390 (in-sample avg dev_std = 0.457)
NEC for r=0.6 all L1 = 0.394 +- 0.261 (in-sample avg dev_std = 0.457)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.913
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.24853999999999998
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.655
NEC for r=0.9 class 0 = 0.379 +- 0.358 (in-sample avg dev_std = 0.535)
NEC for r=0.9 class 1 = 0.402 +- 0.358 (in-sample avg dev_std = 0.535)
NEC for r=0.9 class 2 = 0.351 +- 0.358 (in-sample avg dev_std = 0.535)
NEC for r=0.9 all KL = 0.431 +- 0.358 (in-sample avg dev_std = 0.535)
NEC for r=0.9 all L1 = 0.377 +- 0.234 (in-sample avg dev_std = 0.535)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.913
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.25542000000000004
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.64
NEC for r=1.0 class 0 = 0.41 +- 0.314 (in-sample avg dev_std = 0.565)
NEC for r=1.0 class 1 = 0.428 +- 0.314 (in-sample avg dev_std = 0.565)
NEC for r=1.0 class 2 = 0.387 +- 0.314 (in-sample avg dev_std = 0.565)
NEC for r=1.0 all KL = 0.455 +- 0.314 (in-sample avg dev_std = 0.565)
NEC for r=1.0 all L1 = 0.408 +- 0.193 (in-sample avg dev_std = 0.565)
model_dirname= repr_LECIGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 13:56:28 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:56:28 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 109...
[0m[1;37mINFO[0m: [1mCheckpoint 109: 
-----------------------------------
Train ACCURACY: 0.8840
Train Loss: 0.4621
ID Validation ACCURACY: 0.8847
ID Validation Loss: 0.4565
ID Test ACCURACY: 0.8710
ID Test Loss: 0.4904
OOD Validation ACCURACY: 0.8557
OOD Validation Loss: 0.5559
OOD Test ACCURACY: 0.8713
OOD Test Loss: 0.4670

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 118...
[0m[1;37mINFO[0m: [1mCheckpoint 118: 
-----------------------------------
Train ACCURACY: 0.8378
Train Loss: 0.5626
ID Validation ACCURACY: 0.8373
ID Validation Loss: 0.5631
ID Test ACCURACY: 0.8380
ID Test Loss: 0.5713
OOD Validation ACCURACY: 0.9187
OOD Validation Loss: 0.5173
OOD Test ACCURACY: 0.8860
OOD Test Loss: 0.4481

[0m[1;37mINFO[0m: [1mChartInfo 0.8710 0.8713 0.8380 0.8860 0.8373 0.9187[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.167
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.264
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.313
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.316
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.123
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.215
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.247
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.250


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.539
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.16733374999999998
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.343
SUFF++ for r=0.3 class 0 = 0.482 +- 0.262 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.3 class 1 = 0.521 +- 0.262 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.3 class 2 = 0.468 +- 0.262 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.3 all KL = 0.552 +- 0.262 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.3 all L1 = 0.491 +- 0.139 (in-sample avg dev_std = 0.429)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.839
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.26411
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.402
SUFF++ for r=0.6 class 0 = 0.421 +- 0.281 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 class 1 = 0.479 +- 0.281 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 class 2 = 0.358 +- 0.281 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 all KL = 0.421 +- 0.281 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 all L1 = 0.42 +- 0.141 (in-sample avg dev_std = 0.483)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.896
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.3126525
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.501
SUFF++ for r=0.9 class 0 = 0.543 +- 0.305 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.9 class 1 = 0.59 +- 0.305 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.9 class 2 = 0.42 +- 0.305 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.9 all KL = 0.552 +- 0.305 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.9 all L1 = 0.518 +- 0.219 (in-sample avg dev_std = 0.411)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.605
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.12317249999999999
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.406
SUFF++ for r=0.3 class 0 = 0.443 +- 0.252 (in-sample avg dev_std = 0.529)
SUFF++ for r=0.3 class 1 = 0.525 +- 0.252 (in-sample avg dev_std = 0.529)
SUFF++ for r=0.3 class 2 = 0.444 +- 0.252 (in-sample avg dev_std = 0.529)
SUFF++ for r=0.3 all KL = 0.434 +- 0.252 (in-sample avg dev_std = 0.529)
SUFF++ for r=0.3 all L1 = 0.471 +- 0.120 (in-sample avg dev_std = 0.529)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.798
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.21548125
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.42
SUFF++ for r=0.6 class 0 = 0.41 +- 0.260 (in-sample avg dev_std = 0.496)
SUFF++ for r=0.6 class 1 = 0.531 +- 0.260 (in-sample avg dev_std = 0.496)
SUFF++ for r=0.6 class 2 = 0.441 +- 0.260 (in-sample avg dev_std = 0.496)
SUFF++ for r=0.6 all KL = 0.498 +- 0.260 (in-sample avg dev_std = 0.496)
SUFF++ for r=0.6 all L1 = 0.462 +- 0.144 (in-sample avg dev_std = 0.496)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.874
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.24655375
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.465
SUFF++ for r=0.9 class 0 = 0.478 +- 0.282 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.9 class 1 = 0.554 +- 0.282 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.9 class 2 = 0.448 +- 0.282 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.9 all KL = 0.537 +- 0.282 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.9 all L1 = 0.494 +- 0.204 (in-sample avg dev_std = 0.385)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.539
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.16733374999999998
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.355
NEC for r=0.3 class 0 = 0.47 +- 0.258 (in-sample avg dev_std = 0.406)
NEC for r=0.3 class 1 = 0.458 +- 0.258 (in-sample avg dev_std = 0.406)
NEC for r=0.3 class 2 = 0.487 +- 0.258 (in-sample avg dev_std = 0.406)
NEC for r=0.3 all KL = 0.401 +- 0.258 (in-sample avg dev_std = 0.406)
NEC for r=0.3 all L1 = 0.471 +- 0.169 (in-sample avg dev_std = 0.406)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.839
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.26411
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.513
NEC for r=0.6 class 0 = 0.478 +- 0.304 (in-sample avg dev_std = 0.511)
NEC for r=0.6 class 1 = 0.518 +- 0.304 (in-sample avg dev_std = 0.511)
NEC for r=0.6 class 2 = 0.512 +- 0.304 (in-sample avg dev_std = 0.511)
NEC for r=0.6 all KL = 0.51 +- 0.304 (in-sample avg dev_std = 0.511)
NEC for r=0.6 all L1 = 0.503 +- 0.183 (in-sample avg dev_std = 0.511)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.896
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.3126525
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.54
NEC for r=0.9 class 0 = 0.485 +- 0.288 (in-sample avg dev_std = 0.497)
NEC for r=0.9 class 1 = 0.492 +- 0.288 (in-sample avg dev_std = 0.497)
NEC for r=0.9 class 2 = 0.512 +- 0.288 (in-sample avg dev_std = 0.497)
NEC for r=0.9 all KL = 0.483 +- 0.288 (in-sample avg dev_std = 0.497)
NEC for r=0.9 all L1 = 0.496 +- 0.174 (in-sample avg dev_std = 0.497)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.9
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.3155875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.53
NEC for r=1.0 class 0 = 0.485 +- 0.275 (in-sample avg dev_std = 0.509)
NEC for r=1.0 class 1 = 0.499 +- 0.275 (in-sample avg dev_std = 0.509)
NEC for r=1.0 class 2 = 0.519 +- 0.275 (in-sample avg dev_std = 0.509)
NEC for r=1.0 all KL = 0.487 +- 0.275 (in-sample avg dev_std = 0.509)
NEC for r=1.0 all L1 = 0.501 +- 0.154 (in-sample avg dev_std = 0.509)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.605
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.12317249999999999
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.547
NEC for r=0.3 class 0 = 0.346 +- 0.274 (in-sample avg dev_std = 0.417)
NEC for r=0.3 class 1 = 0.349 +- 0.274 (in-sample avg dev_std = 0.417)
NEC for r=0.3 class 2 = 0.357 +- 0.274 (in-sample avg dev_std = 0.417)
NEC for r=0.3 all KL = 0.353 +- 0.274 (in-sample avg dev_std = 0.417)
NEC for r=0.3 all L1 = 0.351 +- 0.180 (in-sample avg dev_std = 0.417)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.798
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.21548125
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.616
NEC for r=0.6 class 0 = 0.432 +- 0.328 (in-sample avg dev_std = 0.506)
NEC for r=0.6 class 1 = 0.408 +- 0.328 (in-sample avg dev_std = 0.506)
NEC for r=0.6 class 2 = 0.416 +- 0.328 (in-sample avg dev_std = 0.506)
NEC for r=0.6 all KL = 0.399 +- 0.328 (in-sample avg dev_std = 0.506)
NEC for r=0.6 all L1 = 0.419 +- 0.221 (in-sample avg dev_std = 0.506)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.874
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.24655375
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.627
NEC for r=0.9 class 0 = 0.414 +- 0.326 (in-sample avg dev_std = 0.550)
NEC for r=0.9 class 1 = 0.368 +- 0.326 (in-sample avg dev_std = 0.550)
NEC for r=0.9 class 2 = 0.399 +- 0.326 (in-sample avg dev_std = 0.550)
NEC for r=0.9 all KL = 0.403 +- 0.326 (in-sample avg dev_std = 0.550)
NEC for r=0.9 all L1 = 0.393 +- 0.201 (in-sample avg dev_std = 0.550)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.874
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.25015
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.606
NEC for r=1.0 class 0 = 0.439 +- 0.302 (in-sample avg dev_std = 0.561)
NEC for r=1.0 class 1 = 0.399 +- 0.302 (in-sample avg dev_std = 0.561)
NEC for r=1.0 class 2 = 0.42 +- 0.302 (in-sample avg dev_std = 0.561)
NEC for r=1.0 all KL = 0.419 +- 0.302 (in-sample avg dev_std = 0.561)
NEC for r=1.0 all L1 = 0.419 +- 0.174 (in-sample avg dev_std = 0.561)
model_dirname= repr_LECIGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 13:59:12 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:59:12 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 131...
[0m[1;37mINFO[0m: [1mCheckpoint 131: 
-----------------------------------
Train ACCURACY: 0.8867
Train Loss: 0.4438
ID Validation ACCURACY: 0.8937
ID Validation Loss: 0.4262
ID Test ACCURACY: 0.8900
ID Test Loss: 0.4573
OOD Validation ACCURACY: 0.8703
OOD Validation Loss: 0.5403
OOD Test ACCURACY: 0.8920
OOD Test Loss: 0.4081

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 151...
[0m[1;37mINFO[0m: [1mCheckpoint 151: 
-----------------------------------
Train ACCURACY: 0.8267
Train Loss: 0.5441
ID Validation ACCURACY: 0.8370
ID Validation Loss: 0.5474
ID Test ACCURACY: 0.8303
ID Test Loss: 0.5671
OOD Validation ACCURACY: 0.8900
OOD Validation Loss: 0.5611
OOD Test ACCURACY: 0.7843
OOD Test Loss: 0.6018

[0m[1;37mINFO[0m: [1mChartInfo 0.8900 0.8920 0.8303 0.7843 0.8370 0.8900[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.110
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.235
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.301
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.311
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.141
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.212
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.244
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.249


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.526
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.11045875000000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.366
SUFF++ for r=0.3 class 0 = 0.506 +- 0.282 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.3 class 1 = 0.569 +- 0.282 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.3 class 2 = 0.451 +- 0.282 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.3 all KL = 0.597 +- 0.282 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.3 all L1 = 0.509 +- 0.154 (in-sample avg dev_std = 0.382)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.774
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.23489625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.404
SUFF++ for r=0.6 class 0 = 0.46 +- 0.280 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.6 class 1 = 0.543 +- 0.280 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.6 class 2 = 0.343 +- 0.280 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.6 all KL = 0.494 +- 0.280 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.6 all L1 = 0.449 +- 0.169 (in-sample avg dev_std = 0.416)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.882
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.3005775
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.475
SUFF++ for r=0.9 class 0 = 0.576 +- 0.307 (in-sample avg dev_std = 0.335)
SUFF++ for r=0.9 class 1 = 0.633 +- 0.307 (in-sample avg dev_std = 0.335)
SUFF++ for r=0.9 class 2 = 0.412 +- 0.307 (in-sample avg dev_std = 0.335)
SUFF++ for r=0.9 all KL = 0.599 +- 0.307 (in-sample avg dev_std = 0.335)
SUFF++ for r=0.9 all L1 = 0.541 +- 0.240 (in-sample avg dev_std = 0.335)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.609
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.140845
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.416
SUFF++ for r=0.3 class 0 = 0.48 +- 0.286 (in-sample avg dev_std = 0.537)
SUFF++ for r=0.3 class 1 = 0.53 +- 0.286 (in-sample avg dev_std = 0.537)
SUFF++ for r=0.3 class 2 = 0.405 +- 0.286 (in-sample avg dev_std = 0.537)
SUFF++ for r=0.3 all KL = 0.428 +- 0.286 (in-sample avg dev_std = 0.537)
SUFF++ for r=0.3 all L1 = 0.472 +- 0.141 (in-sample avg dev_std = 0.537)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.21176375
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.39
SUFF++ for r=0.6 class 0 = 0.421 +- 0.305 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.6 class 1 = 0.572 +- 0.305 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.6 class 2 = 0.267 +- 0.305 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.6 all KL = 0.443 +- 0.305 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.6 all L1 = 0.421 +- 0.189 (in-sample avg dev_std = 0.423)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.884
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.24416374999999998
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.429
SUFF++ for r=0.9 class 0 = 0.493 +- 0.304 (in-sample avg dev_std = 0.340)
SUFF++ for r=0.9 class 1 = 0.593 +- 0.304 (in-sample avg dev_std = 0.340)
SUFF++ for r=0.9 class 2 = 0.358 +- 0.304 (in-sample avg dev_std = 0.340)
SUFF++ for r=0.9 all KL = 0.516 +- 0.304 (in-sample avg dev_std = 0.340)
SUFF++ for r=0.9 all L1 = 0.482 +- 0.234 (in-sample avg dev_std = 0.340)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.526
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.11045875000000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.417
NEC for r=0.3 class 0 = 0.456 +- 0.268 (in-sample avg dev_std = 0.395)
NEC for r=0.3 class 1 = 0.413 +- 0.268 (in-sample avg dev_std = 0.395)
NEC for r=0.3 class 2 = 0.507 +- 0.268 (in-sample avg dev_std = 0.395)
NEC for r=0.3 all KL = 0.375 +- 0.268 (in-sample avg dev_std = 0.395)
NEC for r=0.3 all L1 = 0.458 +- 0.168 (in-sample avg dev_std = 0.395)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.774
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.23489625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.508
NEC for r=0.6 class 0 = 0.474 +- 0.283 (in-sample avg dev_std = 0.473)
NEC for r=0.6 class 1 = 0.422 +- 0.283 (in-sample avg dev_std = 0.473)
NEC for r=0.6 class 2 = 0.544 +- 0.283 (in-sample avg dev_std = 0.473)
NEC for r=0.6 all KL = 0.441 +- 0.283 (in-sample avg dev_std = 0.473)
NEC for r=0.6 all L1 = 0.48 +- 0.183 (in-sample avg dev_std = 0.473)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.882
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.3005775
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.585
NEC for r=0.9 class 0 = 0.486 +- 0.270 (in-sample avg dev_std = 0.512)
NEC for r=0.9 class 1 = 0.386 +- 0.270 (in-sample avg dev_std = 0.512)
NEC for r=0.9 class 2 = 0.509 +- 0.270 (in-sample avg dev_std = 0.512)
NEC for r=0.9 all KL = 0.424 +- 0.270 (in-sample avg dev_std = 0.512)
NEC for r=0.9 all L1 = 0.46 +- 0.170 (in-sample avg dev_std = 0.512)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.905
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.3109225
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.578
NEC for r=1.0 class 0 = 0.509 +- 0.280 (in-sample avg dev_std = 0.539)
NEC for r=1.0 class 1 = 0.4 +- 0.280 (in-sample avg dev_std = 0.539)
NEC for r=1.0 class 2 = 0.538 +- 0.280 (in-sample avg dev_std = 0.539)
NEC for r=1.0 all KL = 0.472 +- 0.280 (in-sample avg dev_std = 0.539)
NEC for r=1.0 all L1 = 0.482 +- 0.165 (in-sample avg dev_std = 0.539)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.609
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.140845
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.52
NEC for r=0.3 class 0 = 0.372 +- 0.318 (in-sample avg dev_std = 0.453)
NEC for r=0.3 class 1 = 0.385 +- 0.318 (in-sample avg dev_std = 0.453)
NEC for r=0.3 class 2 = 0.387 +- 0.318 (in-sample avg dev_std = 0.453)
NEC for r=0.3 all KL = 0.415 +- 0.318 (in-sample avg dev_std = 0.453)
NEC for r=0.3 all L1 = 0.381 +- 0.216 (in-sample avg dev_std = 0.453)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.21176375
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.633
NEC for r=0.6 class 0 = 0.399 +- 0.355 (in-sample avg dev_std = 0.523)
NEC for r=0.6 class 1 = 0.274 +- 0.355 (in-sample avg dev_std = 0.523)
NEC for r=0.6 class 2 = 0.465 +- 0.355 (in-sample avg dev_std = 0.523)
NEC for r=0.6 all KL = 0.39 +- 0.355 (in-sample avg dev_std = 0.523)
NEC for r=0.6 all L1 = 0.378 +- 0.250 (in-sample avg dev_std = 0.523)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.884
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.24416374999999998
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.641
NEC for r=0.9 class 0 = 0.387 +- 0.317 (in-sample avg dev_std = 0.531)
NEC for r=0.9 class 1 = 0.267 +- 0.317 (in-sample avg dev_std = 0.531)
NEC for r=0.9 class 2 = 0.431 +- 0.317 (in-sample avg dev_std = 0.531)
NEC for r=0.9 all KL = 0.368 +- 0.317 (in-sample avg dev_std = 0.531)
NEC for r=0.9 all L1 = 0.361 +- 0.224 (in-sample avg dev_std = 0.531)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.884
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.24943125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.602
NEC for r=1.0 class 0 = 0.422 +- 0.307 (in-sample avg dev_std = 0.562)
NEC for r=1.0 class 1 = 0.3 +- 0.307 (in-sample avg dev_std = 0.562)
NEC for r=1.0 class 2 = 0.494 +- 0.307 (in-sample avg dev_std = 0.562)
NEC for r=1.0 all KL = 0.407 +- 0.307 (in-sample avg dev_std = 0.562)
NEC for r=1.0 all L1 = 0.404 +- 0.207 (in-sample avg dev_std = 0.562)
model_dirname= repr_LECIGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:01:49 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:49 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 121...
[0m[1;37mINFO[0m: [1mCheckpoint 121: 
-----------------------------------
Train ACCURACY: 0.8653
Train Loss: 0.4841
ID Validation ACCURACY: 0.8673
ID Validation Loss: 0.4704
ID Test ACCURACY: 0.8673
ID Test Loss: 0.4934
OOD Validation ACCURACY: 0.8580
OOD Validation Loss: 0.5922
OOD Test ACCURACY: 0.8357
OOD Test Loss: 0.5047

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 117...
[0m[1;37mINFO[0m: [1mCheckpoint 117: 
-----------------------------------
Train ACCURACY: 0.8568
Train Loss: 0.4933
ID Validation ACCURACY: 0.8580
ID Validation Loss: 0.4774
ID Test ACCURACY: 0.8570
ID Test Loss: 0.5011
OOD Validation ACCURACY: 0.8980
OOD Validation Loss: 0.5087
OOD Test ACCURACY: 0.8823
OOD Test Loss: 0.4434

[0m[1;37mINFO[0m: [1mChartInfo 0.8673 0.8357 0.8570 0.8823 0.8580 0.8980[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.165
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.255
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.309
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.312
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.141
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.240
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.255
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.255


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.585
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.16466375
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.369
SUFF++ for r=0.3 class 0 = 0.506 +- 0.278 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.3 class 1 = 0.569 +- 0.278 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.3 class 2 = 0.451 +- 0.278 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.3 all KL = 0.514 +- 0.278 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.3 all L1 = 0.509 +- 0.174 (in-sample avg dev_std = 0.460)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.853
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.25516
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.415
SUFF++ for r=0.6 class 0 = 0.433 +- 0.292 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.6 class 1 = 0.546 +- 0.292 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.6 class 2 = 0.345 +- 0.292 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.6 all KL = 0.466 +- 0.292 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.6 all L1 = 0.442 +- 0.163 (in-sample avg dev_std = 0.445)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.875
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.30893875000000004
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.526
SUFF++ for r=0.9 class 0 = 0.572 +- 0.292 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.9 class 1 = 0.639 +- 0.292 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.9 class 2 = 0.444 +- 0.292 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.9 all KL = 0.601 +- 0.292 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.9 all L1 = 0.552 +- 0.215 (in-sample avg dev_std = 0.350)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.554
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.1414125
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.401
SUFF++ for r=0.3 class 0 = 0.507 +- 0.268 (in-sample avg dev_std = 0.517)
SUFF++ for r=0.3 class 1 = 0.611 +- 0.268 (in-sample avg dev_std = 0.517)
SUFF++ for r=0.3 class 2 = 0.471 +- 0.268 (in-sample avg dev_std = 0.517)
SUFF++ for r=0.3 all KL = 0.505 +- 0.268 (in-sample avg dev_std = 0.517)
SUFF++ for r=0.3 all L1 = 0.53 +- 0.154 (in-sample avg dev_std = 0.517)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.84
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.23957124999999999
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.433
SUFF++ for r=0.6 class 0 = 0.439 +- 0.325 (in-sample avg dev_std = 0.440)
SUFF++ for r=0.6 class 1 = 0.597 +- 0.325 (in-sample avg dev_std = 0.440)
SUFF++ for r=0.6 class 2 = 0.372 +- 0.325 (in-sample avg dev_std = 0.440)
SUFF++ for r=0.6 all KL = 0.499 +- 0.325 (in-sample avg dev_std = 0.440)
SUFF++ for r=0.6 all L1 = 0.471 +- 0.188 (in-sample avg dev_std = 0.440)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.84
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.2546875
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.45
SUFF++ for r=0.9 class 0 = 0.471 +- 0.308 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.9 class 1 = 0.57 +- 0.308 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.9 class 2 = 0.396 +- 0.308 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.9 all KL = 0.533 +- 0.308 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.9 all L1 = 0.48 +- 0.192 (in-sample avg dev_std = 0.342)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.585
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.16466375
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.434
NEC for r=0.3 class 0 = 0.416 +- 0.277 (in-sample avg dev_std = 0.444)
NEC for r=0.3 class 1 = 0.404 +- 0.277 (in-sample avg dev_std = 0.444)
NEC for r=0.3 class 2 = 0.458 +- 0.277 (in-sample avg dev_std = 0.444)
NEC for r=0.3 all KL = 0.413 +- 0.277 (in-sample avg dev_std = 0.444)
NEC for r=0.3 all L1 = 0.426 +- 0.196 (in-sample avg dev_std = 0.444)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.853
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.25516
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.593
NEC for r=0.6 class 0 = 0.441 +- 0.286 (in-sample avg dev_std = 0.508)
NEC for r=0.6 class 1 = 0.424 +- 0.286 (in-sample avg dev_std = 0.508)
NEC for r=0.6 class 2 = 0.499 +- 0.286 (in-sample avg dev_std = 0.508)
NEC for r=0.6 all KL = 0.445 +- 0.286 (in-sample avg dev_std = 0.508)
NEC for r=0.6 all L1 = 0.454 +- 0.177 (in-sample avg dev_std = 0.508)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.875
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.30893875000000004
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.613
NEC for r=0.9 class 0 = 0.436 +- 0.277 (in-sample avg dev_std = 0.504)
NEC for r=0.9 class 1 = 0.421 +- 0.277 (in-sample avg dev_std = 0.504)
NEC for r=0.9 class 2 = 0.481 +- 0.277 (in-sample avg dev_std = 0.504)
NEC for r=0.9 all KL = 0.421 +- 0.277 (in-sample avg dev_std = 0.504)
NEC for r=0.9 all L1 = 0.446 +- 0.158 (in-sample avg dev_std = 0.504)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.879
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.31169375000000005
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.585
NEC for r=1.0 class 0 = 0.456 +- 0.278 (in-sample avg dev_std = 0.492)
NEC for r=1.0 class 1 = 0.426 +- 0.278 (in-sample avg dev_std = 0.492)
NEC for r=1.0 class 2 = 0.506 +- 0.278 (in-sample avg dev_std = 0.492)
NEC for r=1.0 all KL = 0.434 +- 0.278 (in-sample avg dev_std = 0.492)
NEC for r=1.0 all L1 = 0.462 +- 0.157 (in-sample avg dev_std = 0.492)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.554
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.1414125
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.488
NEC for r=0.3 class 0 = 0.354 +- 0.254 (in-sample avg dev_std = 0.486)
NEC for r=0.3 class 1 = 0.298 +- 0.254 (in-sample avg dev_std = 0.486)
NEC for r=0.3 class 2 = 0.39 +- 0.254 (in-sample avg dev_std = 0.486)
NEC for r=0.3 all KL = 0.359 +- 0.254 (in-sample avg dev_std = 0.486)
NEC for r=0.3 all L1 = 0.347 +- 0.154 (in-sample avg dev_std = 0.486)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.84
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.23957124999999999
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.584
NEC for r=0.6 class 0 = 0.434 +- 0.344 (in-sample avg dev_std = 0.501)
NEC for r=0.6 class 1 = 0.349 +- 0.344 (in-sample avg dev_std = 0.501)
NEC for r=0.6 class 2 = 0.506 +- 0.344 (in-sample avg dev_std = 0.501)
NEC for r=0.6 all KL = 0.414 +- 0.344 (in-sample avg dev_std = 0.501)
NEC for r=0.6 all L1 = 0.429 +- 0.209 (in-sample avg dev_std = 0.501)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.84
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.2546875
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.647
NEC for r=0.9 class 0 = 0.365 +- 0.301 (in-sample avg dev_std = 0.502)
NEC for r=0.9 class 1 = 0.321 +- 0.301 (in-sample avg dev_std = 0.502)
NEC for r=0.9 class 2 = 0.428 +- 0.301 (in-sample avg dev_std = 0.502)
NEC for r=0.9 all KL = 0.345 +- 0.301 (in-sample avg dev_std = 0.502)
NEC for r=0.9 all L1 = 0.371 +- 0.172 (in-sample avg dev_std = 0.502)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.84
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.25475375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.613
NEC for r=1.0 class 0 = 0.399 +- 0.288 (in-sample avg dev_std = 0.520)
NEC for r=1.0 class 1 = 0.346 +- 0.288 (in-sample avg dev_std = 0.520)
NEC for r=1.0 class 2 = 0.456 +- 0.288 (in-sample avg dev_std = 0.520)
NEC for r=1.0 all KL = 0.372 +- 0.288 (in-sample avg dev_std = 0.520)
NEC for r=1.0 all L1 = 0.4 +- 0.157 (in-sample avg dev_std = 0.520)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.579, 0.56, 0.603, 1.0], 'all_L1': [0.531, 0.519, 0.556, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.632, 0.392, 0.552, 1.0], 'all_L1': [0.515, 0.419, 0.558, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.552, 0.421, 0.552, 1.0], 'all_L1': [0.491, 0.42, 0.518, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.597, 0.494, 0.599, 1.0], 'all_L1': [0.509, 0.449, 0.541, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.514, 0.466, 0.601, 1.0], 'all_L1': [0.509, 0.442, 0.552, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.376, 0.364, 0.41, 0.425], 'all_L1': [0.419, 0.404, 0.443, 0.447]}), defaultdict(<class 'list'>, {'all_KL': [0.337, 0.55, 0.545, 0.547], 'all_L1': [0.452, 0.512, 0.502, 0.505]}), defaultdict(<class 'list'>, {'all_KL': [0.401, 0.51, 0.483, 0.487], 'all_L1': [0.471, 0.503, 0.496, 0.501]}), defaultdict(<class 'list'>, {'all_KL': [0.375, 0.441, 0.424, 0.472], 'all_L1': [0.458, 0.48, 0.46, 0.482]}), defaultdict(<class 'list'>, {'all_KL': [0.413, 0.445, 0.421, 0.434], 'all_L1': [0.426, 0.454, 0.446, 0.462]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.622, 0.369, 0.487, 1.0], 'all_L1': [0.527, 0.408, 0.505, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.396, 0.342, 0.423, 1.0], 'all_L1': [0.427, 0.388, 0.44, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.434, 0.498, 0.537, 1.0], 'all_L1': [0.471, 0.462, 0.494, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.428, 0.443, 0.516, 1.0], 'all_L1': [0.472, 0.421, 0.482, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.505, 0.499, 0.533, 1.0], 'all_L1': [0.53, 0.471, 0.48, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.319, 0.519, 0.514, 0.516], 'all_L1': [0.406, 0.486, 0.461, 0.465]}), defaultdict(<class 'list'>, {'all_KL': [0.401, 0.438, 0.431, 0.455], 'all_L1': [0.398, 0.394, 0.377, 0.408]}), defaultdict(<class 'list'>, {'all_KL': [0.353, 0.399, 0.403, 0.419], 'all_L1': [0.351, 0.419, 0.393, 0.419]}), defaultdict(<class 'list'>, {'all_KL': [0.415, 0.39, 0.368, 0.407], 'all_L1': [0.381, 0.378, 0.361, 0.404]}), defaultdict(<class 'list'>, {'all_KL': [0.359, 0.414, 0.345, 0.372], 'all_L1': [0.347, 0.429, 0.371, 0.4]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.511 +- 0.013, 0.450 +- 0.037, 0.545 +- 0.015, 1.000 +- 0.000
suff++ class all_KL  =  0.575 +- 0.040, 0.467 +- 0.059, 0.581 +- 0.024, 1.000 +- 0.000
suff++_acc_int  =  0.358 +- 0.013, 0.410 +- 0.010, 0.516 +- 0.029
nec class all_L1  =  0.445 +- 0.020, 0.471 +- 0.039, 0.469 +- 0.025, 0.479 +- 0.022
nec class all_KL  =  0.380 +- 0.026, 0.462 +- 0.064, 0.457 +- 0.051, 0.473 +- 0.044
nec_acc_int  =  0.398 +- 0.031, 0.538 +- 0.030, 0.585 +- 0.029, 0.578 +- 0.033

Eval split test
suff++ class all_L1  =  0.485 +- 0.039, 0.430 +- 0.032, 0.480 +- 0.022, 1.000 +- 0.000
suff++ class all_KL  =  0.477 +- 0.081, 0.430 +- 0.065, 0.499 +- 0.042, 1.000 +- 0.000
suff++_acc_int  =  0.416 +- 0.026, 0.421 +- 0.023, 0.467 +- 0.042
nec class all_L1  =  0.377 +- 0.024, 0.421 +- 0.037, 0.393 +- 0.036, 0.419 +- 0.024
nec class all_KL  =  0.369 +- 0.035, 0.432 +- 0.046, 0.412 +- 0.059, 0.434 +- 0.049
nec_acc_int  =  0.527 +- 0.047, 0.602 +- 0.021, 0.641 +- 0.010, 0.618 +- 0.015


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.478 +- 0.006, 0.460 +- 0.006, 0.507 +- 0.012, 0.740 +- 0.011
Faith. Armon (L1)= 		  =  0.475 +- 0.008, 0.457 +- 0.006, 0.504 +- 0.013, 0.648 +- 0.020
Faith. GMean (L1)= 	  =  0.477 +- 0.007, 0.459 +- 0.006, 0.505 +- 0.013, 0.692 +- 0.016
Faith. Aritm (KL)= 		  =  0.478 +- 0.008, 0.464 +- 0.005, 0.519 +- 0.015, 0.736 +- 0.022
Faith. Armon (KL)= 		  =  0.456 +- 0.009, 0.456 +- 0.008, 0.509 +- 0.022, 0.641 +- 0.040
Faith. GMean (KL)= 	  =  0.466 +- 0.005, 0.460 +- 0.006, 0.514 +- 0.018, 0.687 +- 0.031

Eval split test
Faith. Aritm (L1)= 		  =  0.431 +- 0.020, 0.426 +- 0.025, 0.436 +- 0.026, 0.710 +- 0.012
Faith. Armon (L1)= 		  =  0.423 +- 0.019, 0.424 +- 0.024, 0.431 +- 0.027, 0.590 +- 0.023
Faith. GMean (L1)= 	  =  0.427 +- 0.020, 0.425 +- 0.025, 0.434 +- 0.027, 0.647 +- 0.018
Faith. Aritm (KL)= 		  =  0.423 +- 0.028, 0.431 +- 0.025, 0.456 +- 0.026, 0.717 +- 0.024
Faith. Armon (KL)= 		  =  0.410 +- 0.014, 0.425 +- 0.024, 0.447 +- 0.030, 0.604 +- 0.047
Faith. GMean (KL)= 	  =  0.417 +- 0.020, 0.428 +- 0.024, 0.451 +- 0.028, 0.658 +- 0.037
Computed for split load_split = id



Completed in  0:13:33.851468  for LECIGIN GOODMotif2/basis



DONE LECI GOODMotif2/basis
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:04:38 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/29/2024 02:04:38 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:04:38 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:04:38 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:04:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:04:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:04:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:04:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:04:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:04:38 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 02:04:38 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 33...
[0m[1;37mINFO[0m: [1mCheckpoint 33: 
-----------------------------------
Train ACCURACY: 0.7656
Train Loss: 0.7545
ID Validation ACCURACY: 0.7657
ID Validation Loss: 0.7469
ID Test ACCURACY: 0.7817
ID Test Loss: 0.7465
OOD Validation ACCURACY: 0.6070
OOD Validation Loss: 0.9462
OOD Test ACCURACY: 0.8360
OOD Test Loss: 0.7339

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 22...
[0m[1;37mINFO[0m: [1mCheckpoint 22: 
-----------------------------------
Train ACCURACY: 0.5745
Train Loss: 0.9397
ID Validation ACCURACY: 0.5747
ID Validation Loss: 0.9386
ID Test ACCURACY: 0.5733
ID Test Loss: 0.9379
OOD Validation ACCURACY: 0.6700
OOD Validation Loss: 1.0144
OOD Test ACCURACY: 0.6513
OOD Test Loss: 0.9243

[0m[1;37mINFO[0m: [1mChartInfo 0.7817 0.8360 0.5733 0.6513 0.5747 0.6700[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.000
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.040
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.226
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.310
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.000
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.000
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.157
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.251


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.364
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.0
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.34
SUFF++ for r=0.3 class 0 = 0.68 +- 0.166 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.3 class 1 = 0.681 +- 0.166 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.3 class 2 = 0.688 +- 0.166 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.3 all KL = 0.83 +- 0.166 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.3 all L1 = 0.683 +- 0.136 (in-sample avg dev_std = 0.313)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.345
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.040497500000000006
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.364
SUFF++ for r=0.6 class 0 = 0.839 +- 0.046 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.6 class 1 = 0.788 +- 0.046 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.6 class 2 = 0.825 +- 0.046 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.6 all KL = 0.954 +- 0.046 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.6 all L1 = 0.817 +- 0.093 (in-sample avg dev_std = 0.139)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.329
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.22576875000000002
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.353
SUFF++ for r=0.9 class 0 = 0.859 +- 0.029 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.9 class 1 = 0.887 +- 0.029 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.9 class 2 = 0.854 +- 0.029 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.9 all KL = 0.971 +- 0.029 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.9 all L1 = 0.867 +- 0.061 (in-sample avg dev_std = 0.155)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.299
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.0
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.375
SUFF++ for r=0.3 class 0 = 0.716 +- 0.207 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.3 class 1 = 0.689 +- 0.207 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.3 class 2 = 0.696 +- 0.207 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.3 all KL = 0.818 +- 0.207 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.3 all L1 = 0.7 +- 0.195 (in-sample avg dev_std = 0.346)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.334
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.0
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.328
SUFF++ for r=0.6 class 0 = 0.883 +- 0.025 (in-sample avg dev_std = 0.104)
SUFF++ for r=0.6 class 1 = 0.858 +- 0.025 (in-sample avg dev_std = 0.104)
SUFF++ for r=0.6 class 2 = 0.874 +- 0.025 (in-sample avg dev_std = 0.104)
SUFF++ for r=0.6 all KL = 0.977 +- 0.025 (in-sample avg dev_std = 0.104)
SUFF++ for r=0.6 all L1 = 0.872 +- 0.048 (in-sample avg dev_std = 0.104)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.324
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.15704875000000001
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.354
SUFF++ for r=0.9 class 0 = 0.884 +- 0.035 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.9 class 1 = 0.893 +- 0.035 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.9 class 2 = 0.818 +- 0.035 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.9 all KL = 0.972 +- 0.035 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.9 all L1 = 0.865 +- 0.075 (in-sample avg dev_std = 0.106)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.364
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.0
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.384
NEC for r=0.3 class 0 = 0.381 +- 0.213 (in-sample avg dev_std = 0.286)
NEC for r=0.3 class 1 = 0.309 +- 0.213 (in-sample avg dev_std = 0.286)
NEC for r=0.3 class 2 = 0.383 +- 0.213 (in-sample avg dev_std = 0.286)
NEC for r=0.3 all KL = 0.213 +- 0.213 (in-sample avg dev_std = 0.286)
NEC for r=0.3 all L1 = 0.357 +- 0.188 (in-sample avg dev_std = 0.286)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.345
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.040497500000000006
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.334
NEC for r=0.6 class 0 = 0.228 +- 0.064 (in-sample avg dev_std = 0.182)
NEC for r=0.6 class 1 = 0.246 +- 0.064 (in-sample avg dev_std = 0.182)
NEC for r=0.6 class 2 = 0.225 +- 0.064 (in-sample avg dev_std = 0.182)
NEC for r=0.6 all KL = 0.074 +- 0.064 (in-sample avg dev_std = 0.182)
NEC for r=0.6 all L1 = 0.233 +- 0.115 (in-sample avg dev_std = 0.182)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.329
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.22576875000000002
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.34
NEC for r=0.9 class 0 = 0.214 +- 0.076 (in-sample avg dev_std = 0.166)
NEC for r=0.9 class 1 = 0.204 +- 0.076 (in-sample avg dev_std = 0.166)
NEC for r=0.9 class 2 = 0.231 +- 0.076 (in-sample avg dev_std = 0.166)
NEC for r=0.9 all KL = 0.067 +- 0.076 (in-sample avg dev_std = 0.166)
NEC for r=0.9 all L1 = 0.216 +- 0.110 (in-sample avg dev_std = 0.166)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.795
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.30991375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.584
NEC for r=1.0 class 0 = 0.245 +- 0.102 (in-sample avg dev_std = 0.204)
NEC for r=1.0 class 1 = 0.259 +- 0.102 (in-sample avg dev_std = 0.204)
NEC for r=1.0 class 2 = 0.259 +- 0.102 (in-sample avg dev_std = 0.204)
NEC for r=1.0 all KL = 0.098 +- 0.102 (in-sample avg dev_std = 0.204)
NEC for r=1.0 all L1 = 0.254 +- 0.119 (in-sample avg dev_std = 0.204)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.299
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.0
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.357
NEC for r=0.3 class 0 = 0.296 +- 0.141 (in-sample avg dev_std = 0.273)
NEC for r=0.3 class 1 = 0.323 +- 0.141 (in-sample avg dev_std = 0.273)
NEC for r=0.3 class 2 = 0.307 +- 0.141 (in-sample avg dev_std = 0.273)
NEC for r=0.3 all KL = 0.149 +- 0.141 (in-sample avg dev_std = 0.273)
NEC for r=0.3 all L1 = 0.309 +- 0.146 (in-sample avg dev_std = 0.273)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.334
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.0
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.328
NEC for r=0.6 class 0 = 0.172 +- 0.043 (in-sample avg dev_std = 0.123)
NEC for r=0.6 class 1 = 0.188 +- 0.043 (in-sample avg dev_std = 0.123)
NEC for r=0.6 class 2 = 0.174 +- 0.043 (in-sample avg dev_std = 0.123)
NEC for r=0.6 all KL = 0.041 +- 0.043 (in-sample avg dev_std = 0.123)
NEC for r=0.6 all L1 = 0.178 +- 0.081 (in-sample avg dev_std = 0.123)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.324
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.15704875000000001
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.341
NEC for r=0.9 class 0 = 0.144 +- 0.026 (in-sample avg dev_std = 0.099)
NEC for r=0.9 class 1 = 0.136 +- 0.026 (in-sample avg dev_std = 0.099)
NEC for r=0.9 class 2 = 0.141 +- 0.026 (in-sample avg dev_std = 0.099)
NEC for r=0.9 all KL = 0.025 +- 0.026 (in-sample avg dev_std = 0.099)
NEC for r=0.9 all L1 = 0.14 +- 0.078 (in-sample avg dev_std = 0.099)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.848
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.25132374999999996
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.638
NEC for r=1.0 class 0 = 0.187 +- 0.068 (in-sample avg dev_std = 0.187)
NEC for r=1.0 class 1 = 0.205 +- 0.068 (in-sample avg dev_std = 0.187)
NEC for r=1.0 class 2 = 0.212 +- 0.068 (in-sample avg dev_std = 0.187)
NEC for r=1.0 all KL = 0.07 +- 0.068 (in-sample avg dev_std = 0.187)
NEC for r=1.0 all L1 = 0.202 +- 0.109 (in-sample avg dev_std = 0.187)
model_dirname= repr_GSATGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:07:15 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/29/2024 02:07:15 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:07:15 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:07:15 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:07:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:07:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:07:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:07:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:07:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:07:15 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 02:07:15 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 103...
[0m[1;37mINFO[0m: [1mCheckpoint 103: 
-----------------------------------
Train ACCURACY: 0.7892
Train Loss: 0.6717
ID Validation ACCURACY: 0.8000
ID Validation Loss: 0.6636
ID Test ACCURACY: 0.8067
ID Test Loss: 0.6692
OOD Validation ACCURACY: 0.6537
OOD Validation Loss: 0.8354
OOD Test ACCURACY: 0.8513
OOD Test Loss: 0.6416

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 41...
[0m[1;37mINFO[0m: [1mCheckpoint 41: 
-----------------------------------
Train ACCURACY: 0.6977
Train Loss: 0.7785
ID Validation ACCURACY: 0.6943
ID Validation Loss: 0.7788
ID Test ACCURACY: 0.7023
ID Test Loss: 0.7842
OOD Validation ACCURACY: 0.6677
OOD Validation Loss: 0.8649
OOD Test ACCURACY: 0.7867
OOD Test Loss: 0.6970

[0m[1;37mINFO[0m: [1mChartInfo 0.8067 0.8513 0.7023 0.7867 0.6943 0.6677[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.002
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.054
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.232
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.310
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.000
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.000
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.157
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.251


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.391
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.0016637499999999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.341
SUFF++ for r=0.3 class 0 = 0.686 +- 0.183 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.3 class 1 = 0.679 +- 0.183 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.3 class 2 = 0.674 +- 0.183 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.3 all KL = 0.818 +- 0.183 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.3 all L1 = 0.679 +- 0.157 (in-sample avg dev_std = 0.323)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.365
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.053515
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.348
SUFF++ for r=0.6 class 0 = 0.721 +- 0.153 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.6 class 1 = 0.722 +- 0.153 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.6 class 2 = 0.661 +- 0.153 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.6 all KL = 0.855 +- 0.153 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.6 all L1 = 0.701 +- 0.149 (in-sample avg dev_std = 0.250)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.43
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.23243124999999998
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.42
SUFF++ for r=0.9 class 0 = 0.769 +- 0.078 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 class 1 = 0.789 +- 0.078 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 class 2 = 0.73 +- 0.078 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 all KL = 0.907 +- 0.078 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 all L1 = 0.763 +- 0.096 (in-sample avg dev_std = 0.248)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.343
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.0
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.322
SUFF++ for r=0.3 class 0 = 0.69 +- 0.129 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.3 class 1 = 0.667 +- 0.129 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.3 class 2 = 0.682 +- 0.129 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.3 all KL = 0.791 +- 0.129 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.3 all L1 = 0.679 +- 0.129 (in-sample avg dev_std = 0.409)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.326
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.0
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.338
SUFF++ for r=0.6 class 0 = 0.678 +- 0.187 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 class 1 = 0.62 +- 0.187 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 class 2 = 0.641 +- 0.187 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 all KL = 0.804 +- 0.187 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 all L1 = 0.646 +- 0.170 (in-sample avg dev_std = 0.348)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.375
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.15704875000000001
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.334
SUFF++ for r=0.9 class 0 = 0.799 +- 0.086 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.9 class 1 = 0.787 +- 0.086 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.9 class 2 = 0.681 +- 0.086 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.9 all KL = 0.912 +- 0.086 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.9 all L1 = 0.755 +- 0.131 (in-sample avg dev_std = 0.197)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.391
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.0016637499999999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.365
NEC for r=0.3 class 0 = 0.352 +- 0.185 (in-sample avg dev_std = 0.304)
NEC for r=0.3 class 1 = 0.346 +- 0.185 (in-sample avg dev_std = 0.304)
NEC for r=0.3 class 2 = 0.352 +- 0.185 (in-sample avg dev_std = 0.304)
NEC for r=0.3 all KL = 0.197 +- 0.185 (in-sample avg dev_std = 0.304)
NEC for r=0.3 all L1 = 0.35 +- 0.162 (in-sample avg dev_std = 0.304)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.365
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.053515
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.349
NEC for r=0.6 class 0 = 0.339 +- 0.169 (in-sample avg dev_std = 0.255)
NEC for r=0.6 class 1 = 0.358 +- 0.169 (in-sample avg dev_std = 0.255)
NEC for r=0.6 class 2 = 0.383 +- 0.169 (in-sample avg dev_std = 0.255)
NEC for r=0.6 all KL = 0.19 +- 0.169 (in-sample avg dev_std = 0.255)
NEC for r=0.6 all L1 = 0.36 +- 0.144 (in-sample avg dev_std = 0.255)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.43
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.23243124999999998
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.391
NEC for r=0.9 class 0 = 0.285 +- 0.131 (in-sample avg dev_std = 0.237)
NEC for r=0.9 class 1 = 0.286 +- 0.131 (in-sample avg dev_std = 0.237)
NEC for r=0.9 class 2 = 0.344 +- 0.131 (in-sample avg dev_std = 0.237)
NEC for r=0.9 all KL = 0.14 +- 0.131 (in-sample avg dev_std = 0.237)
NEC for r=0.9 all L1 = 0.305 +- 0.126 (in-sample avg dev_std = 0.237)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.814
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.310075
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.622
NEC for r=1.0 class 0 = 0.31 +- 0.128 (in-sample avg dev_std = 0.292)
NEC for r=1.0 class 1 = 0.298 +- 0.128 (in-sample avg dev_std = 0.292)
NEC for r=1.0 class 2 = 0.301 +- 0.128 (in-sample avg dev_std = 0.292)
NEC for r=1.0 all KL = 0.157 +- 0.128 (in-sample avg dev_std = 0.292)
NEC for r=1.0 all L1 = 0.303 +- 0.114 (in-sample avg dev_std = 0.292)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.343
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.0
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.354
NEC for r=0.3 class 0 = 0.286 +- 0.141 (in-sample avg dev_std = 0.296)
NEC for r=0.3 class 1 = 0.289 +- 0.141 (in-sample avg dev_std = 0.296)
NEC for r=0.3 class 2 = 0.299 +- 0.141 (in-sample avg dev_std = 0.296)
NEC for r=0.3 all KL = 0.152 +- 0.141 (in-sample avg dev_std = 0.296)
NEC for r=0.3 all L1 = 0.291 +- 0.139 (in-sample avg dev_std = 0.296)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.326
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.0
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.337
NEC for r=0.6 class 0 = 0.247 +- 0.154 (in-sample avg dev_std = 0.246)
NEC for r=0.6 class 1 = 0.31 +- 0.154 (in-sample avg dev_std = 0.246)
NEC for r=0.6 class 2 = 0.284 +- 0.154 (in-sample avg dev_std = 0.246)
NEC for r=0.6 all KL = 0.131 +- 0.154 (in-sample avg dev_std = 0.246)
NEC for r=0.6 all L1 = 0.281 +- 0.168 (in-sample avg dev_std = 0.246)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.375
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.15704875000000001
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.394
NEC for r=0.9 class 0 = 0.248 +- 0.080 (in-sample avg dev_std = 0.172)
NEC for r=0.9 class 1 = 0.237 +- 0.080 (in-sample avg dev_std = 0.172)
NEC for r=0.9 class 2 = 0.294 +- 0.080 (in-sample avg dev_std = 0.172)
NEC for r=0.9 all KL = 0.089 +- 0.080 (in-sample avg dev_std = 0.172)
NEC for r=0.9 all L1 = 0.259 +- 0.116 (in-sample avg dev_std = 0.172)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.858
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.25132374999999996
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.654
NEC for r=1.0 class 0 = 0.273 +- 0.105 (in-sample avg dev_std = 0.255)
NEC for r=1.0 class 1 = 0.259 +- 0.105 (in-sample avg dev_std = 0.255)
NEC for r=1.0 class 2 = 0.235 +- 0.105 (in-sample avg dev_std = 0.255)
NEC for r=1.0 all KL = 0.113 +- 0.105 (in-sample avg dev_std = 0.255)
NEC for r=1.0 all L1 = 0.255 +- 0.112 (in-sample avg dev_std = 0.255)
model_dirname= repr_GSATGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:09:46 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/29/2024 02:09:46 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:09:46 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:09:46 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:09:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:09:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:09:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:09:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:09:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:09:46 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 02:09:46 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 80...
[0m[1;37mINFO[0m: [1mCheckpoint 80: 
-----------------------------------
Train ACCURACY: 0.8201
Train Loss: 0.6557
ID Validation ACCURACY: 0.8250
ID Validation Loss: 0.6490
ID Test ACCURACY: 0.8313
ID Test Loss: 0.6510
OOD Validation ACCURACY: 0.4197
OOD Validation Loss: 1.1161
OOD Test ACCURACY: 0.8480
OOD Test Loss: 0.6248

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 114...
[0m[1;37mINFO[0m: [1mCheckpoint 114: 
-----------------------------------
Train ACCURACY: 0.7688
Train Loss: 0.7245
ID Validation ACCURACY: 0.7693
ID Validation Loss: 0.7213
ID Test ACCURACY: 0.7710
ID Test Loss: 0.7270
OOD Validation ACCURACY: 0.7960
OOD Validation Loss: 0.7677
OOD Test ACCURACY: 0.8163
OOD Test Loss: 0.6391

[0m[1;37mINFO[0m: [1mChartInfo 0.8313 0.8480 0.7710 0.8163 0.7693 0.7960[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.024
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.095
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.249
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.310
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.005
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.014
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.170
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.251


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.315
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.024088750000000003
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.373
SUFF++ for r=0.3 class 0 = 0.649 +- 0.132 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.3 class 1 = 0.609 +- 0.132 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.3 class 2 = 0.644 +- 0.132 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.3 all KL = 0.8 +- 0.132 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.3 all L1 = 0.634 +- 0.145 (in-sample avg dev_std = 0.293)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.279
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.09521625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.349
SUFF++ for r=0.6 class 0 = 0.656 +- 0.138 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.6 class 1 = 0.685 +- 0.138 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.6 class 2 = 0.698 +- 0.138 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.6 all KL = 0.839 +- 0.138 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.6 all L1 = 0.68 +- 0.129 (in-sample avg dev_std = 0.250)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.454
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.2486125
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.42
SUFF++ for r=0.9 class 0 = 0.75 +- 0.191 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 class 1 = 0.739 +- 0.191 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 class 2 = 0.675 +- 0.191 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 all KL = 0.843 +- 0.191 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 all L1 = 0.722 +- 0.141 (in-sample avg dev_std = 0.268)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.376
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.0049475000000000005
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.329
SUFF++ for r=0.3 class 0 = 0.652 +- 0.109 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.3 class 1 = 0.666 +- 0.109 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.3 class 2 = 0.625 +- 0.109 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.3 all KL = 0.796 +- 0.109 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.3 all L1 = 0.648 +- 0.131 (in-sample avg dev_std = 0.387)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.389
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.01432375
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.339
SUFF++ for r=0.6 class 0 = 0.675 +- 0.092 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.6 class 1 = 0.68 +- 0.092 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.6 class 2 = 0.687 +- 0.092 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.6 all KL = 0.858 +- 0.092 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.6 all L1 = 0.681 +- 0.100 (in-sample avg dev_std = 0.304)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.229
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.16987499999999997
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.378
SUFF++ for r=0.9 class 0 = 0.792 +- 0.127 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 class 1 = 0.753 +- 0.127 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 class 2 = 0.677 +- 0.127 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 all KL = 0.875 +- 0.127 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 all L1 = 0.74 +- 0.143 (in-sample avg dev_std = 0.248)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.315
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.024088750000000003
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.373
NEC for r=0.3 class 0 = 0.386 +- 0.127 (in-sample avg dev_std = 0.295)
NEC for r=0.3 class 1 = 0.411 +- 0.127 (in-sample avg dev_std = 0.295)
NEC for r=0.3 class 2 = 0.4 +- 0.127 (in-sample avg dev_std = 0.295)
NEC for r=0.3 all KL = 0.223 +- 0.127 (in-sample avg dev_std = 0.295)
NEC for r=0.3 all L1 = 0.399 +- 0.129 (in-sample avg dev_std = 0.295)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.279
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.09521625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.346
NEC for r=0.6 class 0 = 0.383 +- 0.164 (in-sample avg dev_std = 0.284)
NEC for r=0.6 class 1 = 0.354 +- 0.164 (in-sample avg dev_std = 0.284)
NEC for r=0.6 class 2 = 0.331 +- 0.164 (in-sample avg dev_std = 0.284)
NEC for r=0.6 all KL = 0.195 +- 0.164 (in-sample avg dev_std = 0.284)
NEC for r=0.6 all L1 = 0.356 +- 0.132 (in-sample avg dev_std = 0.284)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.454
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.2486125
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.368
NEC for r=0.9 class 0 = 0.318 +- 0.244 (in-sample avg dev_std = 0.333)
NEC for r=0.9 class 1 = 0.335 +- 0.244 (in-sample avg dev_std = 0.333)
NEC for r=0.9 class 2 = 0.394 +- 0.244 (in-sample avg dev_std = 0.333)
NEC for r=0.9 all KL = 0.238 +- 0.244 (in-sample avg dev_std = 0.333)
NEC for r=0.9 all L1 = 0.349 +- 0.160 (in-sample avg dev_std = 0.333)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.85
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.30964624999999996
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.576
NEC for r=1.0 class 0 = 0.318 +- 0.244 (in-sample avg dev_std = 0.336)
NEC for r=1.0 class 1 = 0.327 +- 0.244 (in-sample avg dev_std = 0.336)
NEC for r=1.0 class 2 = 0.414 +- 0.244 (in-sample avg dev_std = 0.336)
NEC for r=1.0 all KL = 0.248 +- 0.244 (in-sample avg dev_std = 0.336)
NEC for r=1.0 all L1 = 0.353 +- 0.158 (in-sample avg dev_std = 0.336)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.376
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.0049475000000000005
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.316
NEC for r=0.3 class 0 = 0.454 +- 0.100 (in-sample avg dev_std = 0.461)
NEC for r=0.3 class 1 = 0.395 +- 0.100 (in-sample avg dev_std = 0.461)
NEC for r=0.3 class 2 = 0.463 +- 0.100 (in-sample avg dev_std = 0.461)
NEC for r=0.3 all KL = 0.281 +- 0.100 (in-sample avg dev_std = 0.461)
NEC for r=0.3 all L1 = 0.437 +- 0.114 (in-sample avg dev_std = 0.461)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.389
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.01432375
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.336
NEC for r=0.6 class 0 = 0.298 +- 0.098 (in-sample avg dev_std = 0.238)
NEC for r=0.6 class 1 = 0.29 +- 0.098 (in-sample avg dev_std = 0.238)
NEC for r=0.6 class 2 = 0.299 +- 0.098 (in-sample avg dev_std = 0.238)
NEC for r=0.6 all KL = 0.124 +- 0.098 (in-sample avg dev_std = 0.238)
NEC for r=0.6 all L1 = 0.296 +- 0.114 (in-sample avg dev_std = 0.238)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.229
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.16987499999999997
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.417
NEC for r=0.9 class 0 = 0.248 +- 0.105 (in-sample avg dev_std = 0.256)
NEC for r=0.9 class 1 = 0.225 +- 0.105 (in-sample avg dev_std = 0.256)
NEC for r=0.9 class 2 = 0.305 +- 0.105 (in-sample avg dev_std = 0.256)
NEC for r=0.9 all KL = 0.115 +- 0.105 (in-sample avg dev_std = 0.256)
NEC for r=0.9 all L1 = 0.259 +- 0.114 (in-sample avg dev_std = 0.256)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.851
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.2513275
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.655
NEC for r=1.0 class 0 = 0.257 +- 0.156 (in-sample avg dev_std = 0.319)
NEC for r=1.0 class 1 = 0.225 +- 0.156 (in-sample avg dev_std = 0.319)
NEC for r=1.0 class 2 = 0.331 +- 0.156 (in-sample avg dev_std = 0.319)
NEC for r=1.0 all KL = 0.157 +- 0.156 (in-sample avg dev_std = 0.319)
NEC for r=1.0 all L1 = 0.27 +- 0.137 (in-sample avg dev_std = 0.319)
model_dirname= repr_GSATGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:12:20 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/29/2024 02:12:20 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:12:20 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:12:20 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:12:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:12:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:12:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:12:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:12:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:12:20 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 02:12:20 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 130...
[0m[1;37mINFO[0m: [1mCheckpoint 130: 
-----------------------------------
Train ACCURACY: 0.8441
Train Loss: 0.6340
ID Validation ACCURACY: 0.8467
ID Validation Loss: 0.6291
ID Test ACCURACY: 0.8547
ID Test Loss: 0.6398
OOD Validation ACCURACY: 0.6660
OOD Validation Loss: 0.8084
OOD Test ACCURACY: 0.8703
OOD Test Loss: 0.5986

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 131...
[0m[1;37mINFO[0m: [1mCheckpoint 131: 
-----------------------------------
Train ACCURACY: 0.8076
Train Loss: 0.6277
ID Validation ACCURACY: 0.8130
ID Validation Loss: 0.6141
ID Test ACCURACY: 0.8140
ID Test Loss: 0.6263
OOD Validation ACCURACY: 0.7153
OOD Validation Loss: 0.8128
OOD Test ACCURACY: 0.8550
OOD Test Loss: 0.6499

[0m[1;37mINFO[0m: [1mChartInfo 0.8547 0.8703 0.8140 0.8550 0.8130 0.7153[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.031
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.133
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.256
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.309
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.002
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.051
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.176
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.251


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.393
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.030898750000000003
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.341
SUFF++ for r=0.3 class 0 = 0.589 +- 0.185 (in-sample avg dev_std = 0.325)
SUFF++ for r=0.3 class 1 = 0.633 +- 0.185 (in-sample avg dev_std = 0.325)
SUFF++ for r=0.3 class 2 = 0.592 +- 0.185 (in-sample avg dev_std = 0.325)
SUFF++ for r=0.3 all KL = 0.753 +- 0.185 (in-sample avg dev_std = 0.325)
SUFF++ for r=0.3 all L1 = 0.605 +- 0.155 (in-sample avg dev_std = 0.325)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.363
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.13309749999999998
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.367
SUFF++ for r=0.6 class 0 = 0.681 +- 0.212 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.6 class 1 = 0.653 +- 0.212 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.6 class 2 = 0.614 +- 0.212 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.6 all KL = 0.792 +- 0.212 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.6 all L1 = 0.649 +- 0.174 (in-sample avg dev_std = 0.274)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.585
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.25618124999999997
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.476
SUFF++ for r=0.9 class 0 = 0.726 +- 0.184 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 class 1 = 0.768 +- 0.184 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 class 2 = 0.652 +- 0.184 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 all KL = 0.839 +- 0.184 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 all L1 = 0.715 +- 0.158 (in-sample avg dev_std = 0.268)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.341
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.0019874999999999997
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.352
SUFF++ for r=0.3 class 0 = 0.674 +- 0.138 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.3 class 1 = 0.65 +- 0.138 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.3 class 2 = 0.646 +- 0.138 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.3 all KL = 0.794 +- 0.138 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.3 all L1 = 0.657 +- 0.121 (in-sample avg dev_std = 0.399)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.324
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.05114375
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.348
SUFF++ for r=0.6 class 0 = 0.753 +- 0.080 (in-sample avg dev_std = 0.215)
SUFF++ for r=0.6 class 1 = 0.761 +- 0.080 (in-sample avg dev_std = 0.215)
SUFF++ for r=0.6 class 2 = 0.75 +- 0.080 (in-sample avg dev_std = 0.215)
SUFF++ for r=0.6 all KL = 0.913 +- 0.080 (in-sample avg dev_std = 0.215)
SUFF++ for r=0.6 all L1 = 0.755 +- 0.116 (in-sample avg dev_std = 0.215)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.387
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.17630125
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.371
SUFF++ for r=0.9 class 0 = 0.775 +- 0.273 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.9 class 1 = 0.804 +- 0.273 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.9 class 2 = 0.65 +- 0.273 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.9 all KL = 0.837 +- 0.273 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.9 all L1 = 0.743 +- 0.185 (in-sample avg dev_std = 0.236)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.393
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.030898750000000003
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.335
NEC for r=0.3 class 0 = 0.411 +- 0.206 (in-sample avg dev_std = 0.305)
NEC for r=0.3 class 1 = 0.395 +- 0.206 (in-sample avg dev_std = 0.305)
NEC for r=0.3 class 2 = 0.427 +- 0.206 (in-sample avg dev_std = 0.305)
NEC for r=0.3 all KL = 0.259 +- 0.206 (in-sample avg dev_std = 0.305)
NEC for r=0.3 all L1 = 0.411 +- 0.175 (in-sample avg dev_std = 0.305)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.363
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.13309749999999998
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.375
NEC for r=0.6 class 0 = 0.347 +- 0.224 (in-sample avg dev_std = 0.319)
NEC for r=0.6 class 1 = 0.373 +- 0.224 (in-sample avg dev_std = 0.319)
NEC for r=0.6 class 2 = 0.42 +- 0.224 (in-sample avg dev_std = 0.319)
NEC for r=0.6 all KL = 0.242 +- 0.224 (in-sample avg dev_std = 0.319)
NEC for r=0.6 all L1 = 0.38 +- 0.175 (in-sample avg dev_std = 0.319)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.585
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.25618124999999997
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.429
NEC for r=0.9 class 0 = 0.346 +- 0.221 (in-sample avg dev_std = 0.317)
NEC for r=0.9 class 1 = 0.313 +- 0.221 (in-sample avg dev_std = 0.317)
NEC for r=0.9 class 2 = 0.423 +- 0.221 (in-sample avg dev_std = 0.317)
NEC for r=0.9 all KL = 0.236 +- 0.221 (in-sample avg dev_std = 0.317)
NEC for r=0.9 all L1 = 0.36 +- 0.166 (in-sample avg dev_std = 0.317)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.876
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.30856875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.616
NEC for r=1.0 class 0 = 0.345 +- 0.184 (in-sample avg dev_std = 0.328)
NEC for r=1.0 class 1 = 0.344 +- 0.184 (in-sample avg dev_std = 0.328)
NEC for r=1.0 class 2 = 0.343 +- 0.184 (in-sample avg dev_std = 0.328)
NEC for r=1.0 all KL = 0.232 +- 0.184 (in-sample avg dev_std = 0.328)
NEC for r=1.0 all L1 = 0.344 +- 0.141 (in-sample avg dev_std = 0.328)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.341
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.0019874999999999997
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.343
NEC for r=0.3 class 0 = 0.281 +- 0.179 (in-sample avg dev_std = 0.316)
NEC for r=0.3 class 1 = 0.286 +- 0.179 (in-sample avg dev_std = 0.316)
NEC for r=0.3 class 2 = 0.337 +- 0.179 (in-sample avg dev_std = 0.316)
NEC for r=0.3 all KL = 0.174 +- 0.179 (in-sample avg dev_std = 0.316)
NEC for r=0.3 all L1 = 0.301 +- 0.171 (in-sample avg dev_std = 0.316)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.324
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.05114375
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.295
NEC for r=0.6 class 0 = 0.294 +- 0.104 (in-sample avg dev_std = 0.211)
NEC for r=0.6 class 1 = 0.247 +- 0.104 (in-sample avg dev_std = 0.211)
NEC for r=0.6 class 2 = 0.254 +- 0.104 (in-sample avg dev_std = 0.211)
NEC for r=0.6 all KL = 0.102 +- 0.104 (in-sample avg dev_std = 0.211)
NEC for r=0.6 all L1 = 0.264 +- 0.140 (in-sample avg dev_std = 0.211)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.387
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.17630125
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.388
NEC for r=0.9 class 0 = 0.269 +- 0.246 (in-sample avg dev_std = 0.327)
NEC for r=0.9 class 1 = 0.205 +- 0.246 (in-sample avg dev_std = 0.327)
NEC for r=0.9 class 2 = 0.32 +- 0.246 (in-sample avg dev_std = 0.327)
NEC for r=0.9 all KL = 0.172 +- 0.246 (in-sample avg dev_std = 0.327)
NEC for r=0.9 all L1 = 0.264 +- 0.147 (in-sample avg dev_std = 0.327)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.88
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.25126375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.658
NEC for r=1.0 class 0 = 0.275 +- 0.153 (in-sample avg dev_std = 0.288)
NEC for r=1.0 class 1 = 0.28 +- 0.153 (in-sample avg dev_std = 0.288)
NEC for r=1.0 class 2 = 0.266 +- 0.153 (in-sample avg dev_std = 0.288)
NEC for r=1.0 all KL = 0.163 +- 0.153 (in-sample avg dev_std = 0.288)
NEC for r=1.0 all L1 = 0.274 +- 0.136 (in-sample avg dev_std = 0.288)
model_dirname= repr_GSATGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:15:02 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/29/2024 02:15:02 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:15:02 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:15:02 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:15:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:15:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:15:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:15:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:15:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:15:02 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 02:15:02 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 122...
[0m[1;37mINFO[0m: [1mCheckpoint 122: 
-----------------------------------
Train ACCURACY: 0.7998
Train Loss: 0.6279
ID Validation ACCURACY: 0.8040
ID Validation Loss: 0.6271
ID Test ACCURACY: 0.8117
ID Test Loss: 0.6297
OOD Validation ACCURACY: 0.6173
OOD Validation Loss: 0.8511
OOD Test ACCURACY: 0.8783
OOD Test Loss: 0.6018

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 85...
[0m[1;37mINFO[0m: [1mCheckpoint 85: 
-----------------------------------
Train ACCURACY: 0.7921
Train Loss: 0.6909
ID Validation ACCURACY: 0.7927
ID Validation Loss: 0.6927
ID Test ACCURACY: 0.7893
ID Test Loss: 0.7012
OOD Validation ACCURACY: 0.6963
OOD Validation Loss: 0.8042
OOD Test ACCURACY: 0.8473
OOD Test Loss: 0.6105

[0m[1;37mINFO[0m: [1mChartInfo 0.8117 0.8783 0.7893 0.8473 0.7927 0.6963[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.002
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.067
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.241
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.310
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.000
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.024
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.173
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.251


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.36
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.00217125
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.363
SUFF++ for r=0.3 class 0 = 0.656 +- 0.152 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.3 class 1 = 0.658 +- 0.152 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.3 class 2 = 0.671 +- 0.152 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.3 all KL = 0.802 +- 0.152 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.3 all L1 = 0.661 +- 0.139 (in-sample avg dev_std = 0.341)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.354
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.06677875
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.345
SUFF++ for r=0.6 class 0 = 0.683 +- 0.146 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.6 class 1 = 0.671 +- 0.146 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.6 class 2 = 0.685 +- 0.146 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.6 all KL = 0.84 +- 0.146 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.6 all L1 = 0.679 +- 0.130 (in-sample avg dev_std = 0.264)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.374
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.240545
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.4
SUFF++ for r=0.9 class 0 = 0.74 +- 0.165 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 class 1 = 0.739 +- 0.165 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 class 2 = 0.673 +- 0.165 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 all KL = 0.847 +- 0.165 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 all L1 = 0.717 +- 0.146 (in-sample avg dev_std = 0.300)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.319
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.0
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.341
SUFF++ for r=0.3 class 0 = 0.672 +- 0.103 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.3 class 1 = 0.654 +- 0.103 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.3 class 2 = 0.674 +- 0.103 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.3 all KL = 0.789 +- 0.103 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.3 all L1 = 0.666 +- 0.105 (in-sample avg dev_std = 0.432)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.218
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.024001250000000002
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.319
SUFF++ for r=0.6 class 0 = 0.671 +- 0.129 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.6 class 1 = 0.688 +- 0.129 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.6 class 2 = 0.672 +- 0.129 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.6 all KL = 0.848 +- 0.129 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.6 all L1 = 0.677 +- 0.124 (in-sample avg dev_std = 0.317)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.434
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.17321375000000003
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.423
SUFF++ for r=0.9 class 0 = 0.735 +- 0.141 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.9 class 1 = 0.738 +- 0.141 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.9 class 2 = 0.678 +- 0.141 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.9 all KL = 0.876 +- 0.141 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.9 all L1 = 0.717 +- 0.155 (in-sample avg dev_std = 0.203)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.36
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.00217125
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.361
NEC for r=0.3 class 0 = 0.376 +- 0.161 (in-sample avg dev_std = 0.314)
NEC for r=0.3 class 1 = 0.347 +- 0.161 (in-sample avg dev_std = 0.314)
NEC for r=0.3 class 2 = 0.383 +- 0.161 (in-sample avg dev_std = 0.314)
NEC for r=0.3 all KL = 0.217 +- 0.161 (in-sample avg dev_std = 0.314)
NEC for r=0.3 all L1 = 0.368 +- 0.147 (in-sample avg dev_std = 0.314)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.354
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.06677875
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.331
NEC for r=0.6 class 0 = 0.352 +- 0.137 (in-sample avg dev_std = 0.280)
NEC for r=0.6 class 1 = 0.351 +- 0.137 (in-sample avg dev_std = 0.280)
NEC for r=0.6 class 2 = 0.346 +- 0.137 (in-sample avg dev_std = 0.280)
NEC for r=0.6 all KL = 0.179 +- 0.137 (in-sample avg dev_std = 0.280)
NEC for r=0.6 all L1 = 0.35 +- 0.116 (in-sample avg dev_std = 0.280)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.374
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.240545
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.37
NEC for r=0.9 class 0 = 0.344 +- 0.184 (in-sample avg dev_std = 0.317)
NEC for r=0.9 class 1 = 0.332 +- 0.184 (in-sample avg dev_std = 0.317)
NEC for r=0.9 class 2 = 0.381 +- 0.184 (in-sample avg dev_std = 0.317)
NEC for r=0.9 all KL = 0.212 +- 0.184 (in-sample avg dev_std = 0.317)
NEC for r=0.9 all L1 = 0.352 +- 0.151 (in-sample avg dev_std = 0.317)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.829
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.3100575
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.612
NEC for r=1.0 class 0 = 0.328 +- 0.168 (in-sample avg dev_std = 0.323)
NEC for r=1.0 class 1 = 0.339 +- 0.168 (in-sample avg dev_std = 0.323)
NEC for r=1.0 class 2 = 0.365 +- 0.168 (in-sample avg dev_std = 0.323)
NEC for r=1.0 all KL = 0.215 +- 0.168 (in-sample avg dev_std = 0.323)
NEC for r=1.0 all L1 = 0.344 +- 0.132 (in-sample avg dev_std = 0.323)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.319
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.0
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.348
NEC for r=0.3 class 0 = 0.197 +- 0.099 (in-sample avg dev_std = 0.183)
NEC for r=0.3 class 1 = 0.231 +- 0.099 (in-sample avg dev_std = 0.183)
NEC for r=0.3 class 2 = 0.2 +- 0.099 (in-sample avg dev_std = 0.183)
NEC for r=0.3 all KL = 0.111 +- 0.099 (in-sample avg dev_std = 0.183)
NEC for r=0.3 all L1 = 0.21 +- 0.130 (in-sample avg dev_std = 0.183)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.218
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.024001250000000002
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.321
NEC for r=0.6 class 0 = 0.306 +- 0.119 (in-sample avg dev_std = 0.228)
NEC for r=0.6 class 1 = 0.288 +- 0.119 (in-sample avg dev_std = 0.228)
NEC for r=0.6 class 2 = 0.294 +- 0.119 (in-sample avg dev_std = 0.228)
NEC for r=0.6 all KL = 0.127 +- 0.119 (in-sample avg dev_std = 0.228)
NEC for r=0.6 all L1 = 0.296 +- 0.139 (in-sample avg dev_std = 0.228)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.434
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.17321375000000003
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.429
NEC for r=0.9 class 0 = 0.286 +- 0.148 (in-sample avg dev_std = 0.200)
NEC for r=0.9 class 1 = 0.257 +- 0.148 (in-sample avg dev_std = 0.200)
NEC for r=0.9 class 2 = 0.279 +- 0.148 (in-sample avg dev_std = 0.200)
NEC for r=0.9 all KL = 0.12 +- 0.148 (in-sample avg dev_std = 0.200)
NEC for r=0.9 all L1 = 0.274 +- 0.158 (in-sample avg dev_std = 0.200)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.88
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.251015
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.674
NEC for r=1.0 class 0 = 0.258 +- 0.154 (in-sample avg dev_std = 0.328)
NEC for r=1.0 class 1 = 0.257 +- 0.154 (in-sample avg dev_std = 0.328)
NEC for r=1.0 class 2 = 0.31 +- 0.154 (in-sample avg dev_std = 0.328)
NEC for r=1.0 all KL = 0.159 +- 0.154 (in-sample avg dev_std = 0.328)
NEC for r=1.0 all L1 = 0.275 +- 0.144 (in-sample avg dev_std = 0.328)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.83, 0.954, 0.971, 1.0], 'all_L1': [0.683, 0.817, 0.867, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.818, 0.855, 0.907, 1.0], 'all_L1': [0.679, 0.701, 0.763, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.8, 0.839, 0.843, 1.0], 'all_L1': [0.634, 0.68, 0.722, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.753, 0.792, 0.839, 1.0], 'all_L1': [0.605, 0.649, 0.715, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.802, 0.84, 0.847, 1.0], 'all_L1': [0.661, 0.679, 0.717, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.213, 0.074, 0.067, 0.098], 'all_L1': [0.357, 0.233, 0.216, 0.254]}), defaultdict(<class 'list'>, {'all_KL': [0.197, 0.19, 0.14, 0.157], 'all_L1': [0.35, 0.36, 0.305, 0.303]}), defaultdict(<class 'list'>, {'all_KL': [0.223, 0.195, 0.238, 0.248], 'all_L1': [0.399, 0.356, 0.349, 0.353]}), defaultdict(<class 'list'>, {'all_KL': [0.259, 0.242, 0.236, 0.232], 'all_L1': [0.411, 0.38, 0.36, 0.344]}), defaultdict(<class 'list'>, {'all_KL': [0.217, 0.179, 0.212, 0.215], 'all_L1': [0.368, 0.35, 0.352, 0.344]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.818, 0.977, 0.972, 1.0], 'all_L1': [0.7, 0.872, 0.865, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.791, 0.804, 0.912, 1.0], 'all_L1': [0.679, 0.646, 0.755, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.796, 0.858, 0.875, 1.0], 'all_L1': [0.648, 0.681, 0.74, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.794, 0.913, 0.837, 1.0], 'all_L1': [0.657, 0.755, 0.743, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.789, 0.848, 0.876, 1.0], 'all_L1': [0.666, 0.677, 0.717, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.149, 0.041, 0.025, 0.07], 'all_L1': [0.309, 0.178, 0.14, 0.202]}), defaultdict(<class 'list'>, {'all_KL': [0.152, 0.131, 0.089, 0.113], 'all_L1': [0.291, 0.281, 0.259, 0.255]}), defaultdict(<class 'list'>, {'all_KL': [0.281, 0.124, 0.115, 0.157], 'all_L1': [0.437, 0.296, 0.259, 0.27]}), defaultdict(<class 'list'>, {'all_KL': [0.174, 0.102, 0.172, 0.163], 'all_L1': [0.301, 0.264, 0.264, 0.274]}), defaultdict(<class 'list'>, {'all_KL': [0.111, 0.127, 0.12, 0.159], 'all_L1': [0.21, 0.296, 0.274, 0.275]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.652 +- 0.029, 0.705 +- 0.058, 0.757 +- 0.058, 1.000 +- 0.000
suff++ class all_KL  =  0.801 +- 0.026, 0.856 +- 0.053, 0.881 +- 0.051, 1.000 +- 0.000
suff++_acc_int  =  0.352 +- 0.014, 0.355 +- 0.009, 0.414 +- 0.040
nec class all_L1  =  0.377 +- 0.024, 0.336 +- 0.052, 0.316 +- 0.054, 0.320 +- 0.037
nec class all_KL  =  0.222 +- 0.020, 0.176 +- 0.055, 0.179 +- 0.066, 0.190 +- 0.055
nec_acc_int  =  0.364 +- 0.016, 0.347 +- 0.016, 0.380 +- 0.030, 0.602 +- 0.018

Eval split test
suff++ class all_L1  =  0.670 +- 0.018, 0.726 +- 0.081, 0.764 +- 0.052, 1.000 +- 0.000
suff++ class all_KL  =  0.798 +- 0.010, 0.880 +- 0.060, 0.894 +- 0.045, 1.000 +- 0.000
suff++_acc_int  =  0.344 +- 0.019, 0.334 +- 0.010, 0.372 +- 0.030
nec class all_L1  =  0.310 +- 0.073, 0.263 +- 0.044, 0.239 +- 0.050, 0.255 +- 0.028
nec class all_KL  =  0.173 +- 0.057, 0.105 +- 0.034, 0.104 +- 0.048, 0.132 +- 0.036
nec_acc_int  =  0.343 +- 0.014, 0.324 +- 0.015, 0.394 +- 0.030, 0.656 +- 0.011


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.515 +- 0.004, 0.521 +- 0.006, 0.537 +- 0.003, 0.660 +- 0.019
Faith. Armon (L1)= 		  =  0.477 +- 0.011, 0.449 +- 0.044, 0.441 +- 0.050, 0.483 +- 0.044
Faith. GMean (L1)= 	  =  0.495 +- 0.005, 0.483 +- 0.024, 0.485 +- 0.028, 0.564 +- 0.034
Faith. Aritm (KL)= 		  =  0.511 +- 0.005, 0.516 +- 0.004, 0.530 +- 0.008, 0.595 +- 0.028
Faith. Armon (KL)= 		  =  0.346 +- 0.022, 0.286 +- 0.079, 0.289 +- 0.094, 0.316 +- 0.081
Faith. GMean (KL)= 	  =  0.421 +- 0.013, 0.380 +- 0.059, 0.386 +- 0.073, 0.431 +- 0.068

Eval split test
Faith. Aritm (L1)= 		  =  0.490 +- 0.034, 0.495 +- 0.021, 0.502 +- 0.004, 0.628 +- 0.014
Faith. Armon (L1)= 		  =  0.418 +- 0.065, 0.381 +- 0.043, 0.359 +- 0.059, 0.406 +- 0.036
Faith. GMean (L1)= 	  =  0.452 +- 0.051, 0.433 +- 0.021, 0.423 +- 0.037, 0.504 +- 0.028
Faith. Aritm (KL)= 		  =  0.486 +- 0.029, 0.492 +- 0.015, 0.499 +- 0.003, 0.566 +- 0.018
Faith. Armon (KL)= 		  =  0.281 +- 0.074, 0.185 +- 0.055, 0.182 +- 0.078, 0.232 +- 0.058
Faith. GMean (KL)= 	  =  0.367 +- 0.058, 0.297 +- 0.049, 0.292 +- 0.075, 0.360 +- 0.054
Computed for split load_split = id



Completed in  0:12:58.939714  for GSATGIN GOODMotif2/basis



DONE GSAT GOODMotif2/basis
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:17:48 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:17:50 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 161...
[0m[1;37mINFO[0m: [1mCheckpoint 161: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0003
ID Validation ACCURACY: 0.9232
ID Validation Loss: 0.4071
ID Test ACCURACY: 0.9138
ID Test Loss: 0.4704
OOD Validation ACCURACY: 0.8802
OOD Validation Loss: 0.6430
OOD Test ACCURACY: 0.8284
OOD Test Loss: 1.3885

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 191...
[0m[1;37mINFO[0m: [1mCheckpoint 191: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.9219
ID Validation Loss: 0.4384
ID Test ACCURACY: 0.9176
ID Test Loss: 0.5121
OOD Validation ACCURACY: 0.8828
OOD Validation Loss: 0.6819
OOD Test ACCURACY: 0.8285
OOD Test Loss: 1.4679

[0m[1;37mINFO[0m: [1mChartInfo 0.9138 0.8284 0.9176 0.8285 0.9219 0.8828[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/29/2024 02:17:53 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.874
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.838
SUFF++ for r=0.6 class 0.0 = 0.883 +- 0.305 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.6 class 1.0 = 0.908 +- 0.305 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.6 all KL = 0.805 +- 0.305 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.6 all L1 = 0.898 +- 0.172 (in-sample avg dev_std = 0.351)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.883
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.883
SUFF++ for r=0.9 class 0.0 = 0.954 +- 0.126 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.9 class 1.0 = 0.985 +- 0.126 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.9 all KL = 0.975 +- 0.126 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.9 all L1 = 0.971 +- 0.111 (in-sample avg dev_std = 0.132)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.801
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.743
SUFF++ for r=0.3 class 0.0 = 0.697 +- 0.324 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.3 class 1.0 = 0.841 +- 0.324 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.3 all KL = 0.621 +- 0.324 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.3 all L1 = 0.771 +- 0.211 (in-sample avg dev_std = 0.519)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.821
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.786
SUFF++ for r=0.6 class 0.0 = 0.808 +- 0.299 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.6 class 1.0 = 0.887 +- 0.299 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.6 all KL = 0.765 +- 0.299 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.6 all L1 = 0.849 +- 0.208 (in-sample avg dev_std = 0.393)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.842
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.833
SUFF++ for r=0.9 class 0.0 = 0.92 +- 0.173 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 class 1.0 = 0.952 +- 0.173 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 all KL = 0.927 +- 0.173 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 all L1 = 0.937 +- 0.143 (in-sample avg dev_std = 0.222)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.874
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.874
NEC for r=0.6 class 0.0 = 0.072 +- 0.199 (in-sample avg dev_std = 0.179)
NEC for r=0.6 class 1.0 = 0.045 +- 0.199 (in-sample avg dev_std = 0.179)
NEC for r=0.6 all KL = 0.067 +- 0.199 (in-sample avg dev_std = 0.179)
NEC for r=0.6 all L1 = 0.056 +- 0.154 (in-sample avg dev_std = 0.179)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.884
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.874
NEC for r=0.9 class 0.0 = 0.04 +- 0.135 (in-sample avg dev_std = 0.110)
NEC for r=0.9 class 1.0 = 0.022 +- 0.135 (in-sample avg dev_std = 0.110)
NEC for r=0.9 all KL = 0.027 +- 0.135 (in-sample avg dev_std = 0.110)
NEC for r=0.9 all L1 = 0.029 +- 0.121 (in-sample avg dev_std = 0.110)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.888
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.874
NEC for r=1.0 class 0.0 = 0.04 +- 0.136 (in-sample avg dev_std = 0.110)
NEC for r=1.0 class 1.0 = 0.021 +- 0.136 (in-sample avg dev_std = 0.110)
NEC for r=1.0 all KL = 0.027 +- 0.136 (in-sample avg dev_std = 0.110)
NEC for r=1.0 all L1 = 0.029 +- 0.121 (in-sample avg dev_std = 0.110)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.801
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.767
NEC for r=0.3 class 0.0 = 0.197 +- 0.294 (in-sample avg dev_std = 0.322)
NEC for r=0.3 class 1.0 = 0.109 +- 0.294 (in-sample avg dev_std = 0.322)
NEC for r=0.3 all KL = 0.181 +- 0.294 (in-sample avg dev_std = 0.322)
NEC for r=0.3 all L1 = 0.151 +- 0.228 (in-sample avg dev_std = 0.322)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.821
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.812
NEC for r=0.6 class 0.0 = 0.13 +- 0.229 (in-sample avg dev_std = 0.256)
NEC for r=0.6 class 1.0 = 0.074 +- 0.229 (in-sample avg dev_std = 0.256)
NEC for r=0.6 all KL = 0.111 +- 0.229 (in-sample avg dev_std = 0.256)
NEC for r=0.6 all L1 = 0.101 +- 0.193 (in-sample avg dev_std = 0.256)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.842
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.834
NEC for r=0.9 class 0.0 = 0.055 +- 0.126 (in-sample avg dev_std = 0.143)
NEC for r=0.9 class 1.0 = 0.036 +- 0.126 (in-sample avg dev_std = 0.143)
NEC for r=0.9 all KL = 0.037 +- 0.126 (in-sample avg dev_std = 0.143)
NEC for r=0.9 all L1 = 0.045 +- 0.122 (in-sample avg dev_std = 0.143)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.848
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.841
NEC for r=1.0 class 0.0 = 0.033 +- 0.089 (in-sample avg dev_std = 0.104)
NEC for r=1.0 class 1.0 = 0.029 +- 0.089 (in-sample avg dev_std = 0.104)
NEC for r=1.0 all KL = 0.022 +- 0.089 (in-sample avg dev_std = 0.104)
NEC for r=1.0 all L1 = 0.031 +- 0.093 (in-sample avg dev_std = 0.104)
model_dirname= repr_LECIvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:20:16 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:20:17 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 180...
[0m[1;37mINFO[0m: [1mCheckpoint 180: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0002
ID Validation ACCURACY: 0.9215
ID Validation Loss: 0.4292
ID Test ACCURACY: 0.9138
ID Test Loss: 0.4908
OOD Validation ACCURACY: 0.8802
OOD Validation Loss: 0.6680
OOD Test ACCURACY: 0.8261
OOD Test Loss: 1.4346

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 90...
[0m[1;37mINFO[0m: [1mCheckpoint 90: 
-----------------------------------
Train ACCURACY: 0.9990
Train Loss: 0.0057
ID Validation ACCURACY: 0.9157
ID Validation Loss: 0.2928
ID Test ACCURACY: 0.9127
ID Test Loss: 0.3309
OOD Validation ACCURACY: 0.8829
OOD Validation Loss: 0.4550
OOD Test ACCURACY: 0.8361
OOD Test Loss: 0.9548

[0m[1;37mINFO[0m: [1mChartInfo 0.9138 0.8261 0.9127 0.8361 0.9157 0.8829[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/29/2024 02:20:19 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.895
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.851
SUFF++ for r=0.6 class 0.0 = 0.847 +- 0.315 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.6 class 1.0 = 0.914 +- 0.315 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.6 all KL = 0.784 +- 0.315 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.6 all L1 = 0.886 +- 0.177 (in-sample avg dev_std = 0.380)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.9
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.883
SUFF++ for r=0.9 class 0.0 = 0.963 +- 0.105 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.9 class 1.0 = 0.988 +- 0.105 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.9 all KL = 0.982 +- 0.105 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.9 all L1 = 0.977 +- 0.091 (in-sample avg dev_std = 0.108)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.769
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.735
SUFF++ for r=0.3 class 0.0 = 0.826 +- 0.304 (in-sample avg dev_std = 0.400)
SUFF++ for r=0.3 class 1.0 = 0.895 +- 0.304 (in-sample avg dev_std = 0.400)
SUFF++ for r=0.3 all KL = 0.768 +- 0.304 (in-sample avg dev_std = 0.400)
SUFF++ for r=0.3 all L1 = 0.862 +- 0.187 (in-sample avg dev_std = 0.400)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.81
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.791
SUFF++ for r=0.6 class 0.0 = 0.86 +- 0.257 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.6 class 1.0 = 0.925 +- 0.257 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.6 all KL = 0.843 +- 0.257 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.6 all L1 = 0.894 +- 0.183 (in-sample avg dev_std = 0.310)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.844
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.835
SUFF++ for r=0.9 class 0.0 = 0.941 +- 0.159 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.9 class 1.0 = 0.959 +- 0.159 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.9 all KL = 0.938 +- 0.159 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.9 all L1 = 0.95 +- 0.123 (in-sample avg dev_std = 0.208)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.895
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.88
NEC for r=0.6 class 0.0 = 0.073 +- 0.179 (in-sample avg dev_std = 0.168)
NEC for r=0.6 class 1.0 = 0.032 +- 0.179 (in-sample avg dev_std = 0.168)
NEC for r=0.6 all KL = 0.054 +- 0.179 (in-sample avg dev_std = 0.168)
NEC for r=0.6 all L1 = 0.049 +- 0.141 (in-sample avg dev_std = 0.168)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.902
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.879
NEC for r=0.9 class 0.0 = 0.044 +- 0.124 (in-sample avg dev_std = 0.082)
NEC for r=0.9 class 1.0 = 0.016 +- 0.124 (in-sample avg dev_std = 0.082)
NEC for r=0.9 all KL = 0.024 +- 0.124 (in-sample avg dev_std = 0.082)
NEC for r=0.9 all L1 = 0.028 +- 0.108 (in-sample avg dev_std = 0.082)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.902
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.879
NEC for r=1.0 class 0.0 = 0.044 +- 0.124 (in-sample avg dev_std = 0.082)
NEC for r=1.0 class 1.0 = 0.016 +- 0.124 (in-sample avg dev_std = 0.082)
NEC for r=1.0 all KL = 0.024 +- 0.124 (in-sample avg dev_std = 0.082)
NEC for r=1.0 all L1 = 0.028 +- 0.108 (in-sample avg dev_std = 0.082)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.769
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.772
NEC for r=0.3 class 0.0 = 0.113 +- 0.215 (in-sample avg dev_std = 0.202)
NEC for r=0.3 class 1.0 = 0.057 +- 0.215 (in-sample avg dev_std = 0.202)
NEC for r=0.3 all KL = 0.086 +- 0.215 (in-sample avg dev_std = 0.202)
NEC for r=0.3 all L1 = 0.084 +- 0.181 (in-sample avg dev_std = 0.202)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.81
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.807
NEC for r=0.6 class 0.0 = 0.076 +- 0.162 (in-sample avg dev_std = 0.163)
NEC for r=0.6 class 1.0 = 0.043 +- 0.162 (in-sample avg dev_std = 0.163)
NEC for r=0.6 all KL = 0.053 +- 0.162 (in-sample avg dev_std = 0.163)
NEC for r=0.6 all L1 = 0.059 +- 0.152 (in-sample avg dev_std = 0.163)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.844
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.84
NEC for r=0.9 class 0.0 = 0.042 +- 0.104 (in-sample avg dev_std = 0.119)
NEC for r=0.9 class 1.0 = 0.023 +- 0.104 (in-sample avg dev_std = 0.119)
NEC for r=0.9 all KL = 0.026 +- 0.104 (in-sample avg dev_std = 0.119)
NEC for r=0.9 all L1 = 0.032 +- 0.103 (in-sample avg dev_std = 0.119)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.846
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.845
NEC for r=1.0 class 0.0 = 0.021 +- 0.066 (in-sample avg dev_std = 0.091)
NEC for r=1.0 class 1.0 = 0.016 +- 0.066 (in-sample avg dev_std = 0.091)
NEC for r=1.0 all KL = 0.012 +- 0.066 (in-sample avg dev_std = 0.091)
NEC for r=1.0 all L1 = 0.019 +- 0.070 (in-sample avg dev_std = 0.091)
model_dirname= repr_LECIvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:22:31 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:22:32 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 80...
[0m[1;37mINFO[0m: [1mCheckpoint 80: 
-----------------------------------
Train ACCURACY: 0.9991
Train Loss: 0.0067
ID Validation ACCURACY: 0.9191
ID Validation Loss: 0.3068
ID Test ACCURACY: 0.9104
ID Test Loss: 0.3679
OOD Validation ACCURACY: 0.8770
OOD Validation Loss: 0.5744
OOD Test ACCURACY: 0.8208
OOD Test Loss: 1.4759

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 194...
[0m[1;37mINFO[0m: [1mCheckpoint 194: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.9187
ID Validation Loss: 0.4818
ID Test ACCURACY: 0.9189
ID Test Loss: 0.5496
OOD Validation ACCURACY: 0.8843
OOD Validation Loss: 0.6971
OOD Test ACCURACY: 0.8280
OOD Test Loss: 1.3584

[0m[1;37mINFO[0m: [1mChartInfo 0.9104 0.8208 0.9189 0.8280 0.9187 0.8843[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/29/2024 02:22:34 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.842
SUFF++ for r=0.6 class 0.0 = 0.859 +- 0.267 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.6 class 1.0 = 0.903 +- 0.267 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.6 all KL = 0.82 +- 0.267 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.6 all L1 = 0.884 +- 0.170 (in-sample avg dev_std = 0.332)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.889
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.871
SUFF++ for r=0.9 class 0.0 = 0.952 +- 0.098 (in-sample avg dev_std = 0.110)
SUFF++ for r=0.9 class 1.0 = 0.972 +- 0.098 (in-sample avg dev_std = 0.110)
SUFF++ for r=0.9 all KL = 0.977 +- 0.098 (in-sample avg dev_std = 0.110)
SUFF++ for r=0.9 all L1 = 0.963 +- 0.109 (in-sample avg dev_std = 0.110)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.783
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.75
SUFF++ for r=0.3 class 0.0 = 0.824 +- 0.246 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.3 class 1.0 = 0.881 +- 0.246 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.3 all KL = 0.808 +- 0.246 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.3 all L1 = 0.854 +- 0.172 (in-sample avg dev_std = 0.360)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.822
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.801
SUFF++ for r=0.6 class 0.0 = 0.874 +- 0.229 (in-sample avg dev_std = 0.290)
SUFF++ for r=0.6 class 1.0 = 0.908 +- 0.229 (in-sample avg dev_std = 0.290)
SUFF++ for r=0.6 all KL = 0.855 +- 0.229 (in-sample avg dev_std = 0.290)
SUFF++ for r=0.6 all L1 = 0.891 +- 0.165 (in-sample avg dev_std = 0.290)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.841
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.834
SUFF++ for r=0.9 class 0.0 = 0.946 +- 0.131 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.9 class 1.0 = 0.943 +- 0.131 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.9 all KL = 0.941 +- 0.131 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.9 all L1 = 0.945 +- 0.116 (in-sample avg dev_std = 0.198)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.871
NEC for r=0.6 class 0.0 = 0.085 +- 0.166 (in-sample avg dev_std = 0.171)
NEC for r=0.6 class 1.0 = 0.048 +- 0.166 (in-sample avg dev_std = 0.171)
NEC for r=0.6 all KL = 0.06 +- 0.166 (in-sample avg dev_std = 0.171)
NEC for r=0.6 all L1 = 0.063 +- 0.145 (in-sample avg dev_std = 0.171)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.891
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.875
NEC for r=0.9 class 0.0 = 0.045 +- 0.088 (in-sample avg dev_std = 0.101)
NEC for r=0.9 class 1.0 = 0.027 +- 0.088 (in-sample avg dev_std = 0.101)
NEC for r=0.9 all KL = 0.021 +- 0.088 (in-sample avg dev_std = 0.101)
NEC for r=0.9 all L1 = 0.034 +- 0.102 (in-sample avg dev_std = 0.101)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.891
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.875
NEC for r=1.0 class 0.0 = 0.045 +- 0.088 (in-sample avg dev_std = 0.101)
NEC for r=1.0 class 1.0 = 0.027 +- 0.088 (in-sample avg dev_std = 0.101)
NEC for r=1.0 all KL = 0.021 +- 0.088 (in-sample avg dev_std = 0.101)
NEC for r=1.0 all L1 = 0.034 +- 0.102 (in-sample avg dev_std = 0.101)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.783
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.786
NEC for r=0.3 class 0.0 = 0.124 +- 0.161 (in-sample avg dev_std = 0.178)
NEC for r=0.3 class 1.0 = 0.072 +- 0.161 (in-sample avg dev_std = 0.178)
NEC for r=0.3 all KL = 0.073 +- 0.161 (in-sample avg dev_std = 0.178)
NEC for r=0.3 all L1 = 0.097 +- 0.169 (in-sample avg dev_std = 0.178)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.822
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.819
NEC for r=0.6 class 0.0 = 0.08 +- 0.140 (in-sample avg dev_std = 0.139)
NEC for r=0.6 class 1.0 = 0.049 +- 0.140 (in-sample avg dev_std = 0.139)
NEC for r=0.6 all KL = 0.05 +- 0.140 (in-sample avg dev_std = 0.139)
NEC for r=0.6 all L1 = 0.064 +- 0.140 (in-sample avg dev_std = 0.139)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.841
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.837
NEC for r=0.9 class 0.0 = 0.037 +- 0.086 (in-sample avg dev_std = 0.101)
NEC for r=0.9 class 1.0 = 0.035 +- 0.086 (in-sample avg dev_std = 0.101)
NEC for r=0.9 all KL = 0.023 +- 0.086 (in-sample avg dev_std = 0.101)
NEC for r=0.9 all L1 = 0.036 +- 0.099 (in-sample avg dev_std = 0.101)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.842
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.84
NEC for r=1.0 class 0.0 = 0.028 +- 0.061 (in-sample avg dev_std = 0.088)
NEC for r=1.0 class 1.0 = 0.024 +- 0.061 (in-sample avg dev_std = 0.088)
NEC for r=1.0 all KL = 0.013 +- 0.061 (in-sample avg dev_std = 0.088)
NEC for r=1.0 all L1 = 0.026 +- 0.080 (in-sample avg dev_std = 0.088)
model_dirname= repr_LECIvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:24:56 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:57 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:57 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:57 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:24:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:57 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:24:57 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:24:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:57 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:24:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:57 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:24:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:57 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:24:58 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 193...
[0m[1;37mINFO[0m: [1mCheckpoint 193: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0002
ID Validation ACCURACY: 0.9194
ID Validation Loss: 0.4390
ID Test ACCURACY: 0.9162
ID Test Loss: 0.5246
OOD Validation ACCURACY: 0.8849
OOD Validation Loss: 0.6551
OOD Test ACCURACY: 0.8289
OOD Test Loss: 1.3384

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 194...
[0m[1;37mINFO[0m: [1mCheckpoint 194: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.9178
ID Validation Loss: 0.4486
ID Test ACCURACY: 0.9172
ID Test Loss: 0.5292
OOD Validation ACCURACY: 0.8852
OOD Validation Loss: 0.6477
OOD Test ACCURACY: 0.8321
OOD Test Loss: 1.2473

[0m[1;37mINFO[0m: [1mChartInfo 0.9162 0.8289 0.9172 0.8321 0.9178 0.8852[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/29/2024 02:24:59 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.898
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.853
SUFF++ for r=0.6 class 0.0 = 0.87 +- 0.315 (in-sample avg dev_std = 0.361)
SUFF++ for r=0.6 class 1.0 = 0.914 +- 0.315 (in-sample avg dev_std = 0.361)
SUFF++ for r=0.6 all KL = 0.795 +- 0.315 (in-sample avg dev_std = 0.361)
SUFF++ for r=0.6 all L1 = 0.896 +- 0.181 (in-sample avg dev_std = 0.361)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.889
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.876
SUFF++ for r=0.9 class 0.0 = 0.959 +- 0.121 (in-sample avg dev_std = 0.110)
SUFF++ for r=0.9 class 1.0 = 0.988 +- 0.121 (in-sample avg dev_std = 0.110)
SUFF++ for r=0.9 all KL = 0.978 +- 0.121 (in-sample avg dev_std = 0.110)
SUFF++ for r=0.9 all L1 = 0.975 +- 0.107 (in-sample avg dev_std = 0.110)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.785
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.748
SUFF++ for r=0.3 class 0.0 = 0.807 +- 0.301 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.3 class 1.0 = 0.896 +- 0.301 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.3 all KL = 0.764 +- 0.301 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.3 all L1 = 0.853 +- 0.188 (in-sample avg dev_std = 0.409)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.827
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.806
SUFF++ for r=0.6 class 0.0 = 0.867 +- 0.256 (in-sample avg dev_std = 0.302)
SUFF++ for r=0.6 class 1.0 = 0.924 +- 0.256 (in-sample avg dev_std = 0.302)
SUFF++ for r=0.6 all KL = 0.847 +- 0.256 (in-sample avg dev_std = 0.302)
SUFF++ for r=0.6 all L1 = 0.897 +- 0.173 (in-sample avg dev_std = 0.302)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.831
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.828
SUFF++ for r=0.9 class 0.0 = 0.944 +- 0.147 (in-sample avg dev_std = 0.199)
SUFF++ for r=0.9 class 1.0 = 0.958 +- 0.147 (in-sample avg dev_std = 0.199)
SUFF++ for r=0.9 all KL = 0.941 +- 0.147 (in-sample avg dev_std = 0.199)
SUFF++ for r=0.9 all L1 = 0.951 +- 0.115 (in-sample avg dev_std = 0.199)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.898
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.881
NEC for r=0.6 class 0.0 = 0.062 +- 0.181 (in-sample avg dev_std = 0.146)
NEC for r=0.6 class 1.0 = 0.033 +- 0.181 (in-sample avg dev_std = 0.146)
NEC for r=0.6 all KL = 0.053 +- 0.181 (in-sample avg dev_std = 0.146)
NEC for r=0.6 all L1 = 0.045 +- 0.143 (in-sample avg dev_std = 0.146)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.891
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.874
NEC for r=0.9 class 0.0 = 0.038 +- 0.128 (in-sample avg dev_std = 0.085)
NEC for r=0.9 class 1.0 = 0.014 +- 0.128 (in-sample avg dev_std = 0.085)
NEC for r=0.9 all KL = 0.024 +- 0.128 (in-sample avg dev_std = 0.085)
NEC for r=0.9 all L1 = 0.024 +- 0.110 (in-sample avg dev_std = 0.085)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.891
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.874
NEC for r=1.0 class 0.0 = 0.038 +- 0.128 (in-sample avg dev_std = 0.085)
NEC for r=1.0 class 1.0 = 0.014 +- 0.128 (in-sample avg dev_std = 0.085)
NEC for r=1.0 all KL = 0.024 +- 0.128 (in-sample avg dev_std = 0.085)
NEC for r=1.0 all L1 = 0.024 +- 0.110 (in-sample avg dev_std = 0.085)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.785
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.782
NEC for r=0.3 class 0.0 = 0.124 +- 0.213 (in-sample avg dev_std = 0.196)
NEC for r=0.3 class 1.0 = 0.06 +- 0.213 (in-sample avg dev_std = 0.196)
NEC for r=0.3 all KL = 0.087 +- 0.213 (in-sample avg dev_std = 0.196)
NEC for r=0.3 all L1 = 0.091 +- 0.187 (in-sample avg dev_std = 0.196)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.827
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.814
NEC for r=0.6 class 0.0 = 0.075 +- 0.167 (in-sample avg dev_std = 0.169)
NEC for r=0.6 class 1.0 = 0.048 +- 0.167 (in-sample avg dev_std = 0.169)
NEC for r=0.6 all KL = 0.056 +- 0.167 (in-sample avg dev_std = 0.169)
NEC for r=0.6 all L1 = 0.061 +- 0.151 (in-sample avg dev_std = 0.169)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.831
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.836
NEC for r=0.9 class 0.0 = 0.035 +- 0.097 (in-sample avg dev_std = 0.110)
NEC for r=0.9 class 1.0 = 0.029 +- 0.097 (in-sample avg dev_std = 0.110)
NEC for r=0.9 all KL = 0.024 +- 0.097 (in-sample avg dev_std = 0.110)
NEC for r=0.9 all L1 = 0.032 +- 0.104 (in-sample avg dev_std = 0.110)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.84
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.837
NEC for r=1.0 class 0.0 = 0.024 +- 0.069 (in-sample avg dev_std = 0.088)
NEC for r=1.0 class 1.0 = 0.018 +- 0.069 (in-sample avg dev_std = 0.088)
NEC for r=1.0 all KL = 0.013 +- 0.069 (in-sample avg dev_std = 0.088)
NEC for r=1.0 all L1 = 0.021 +- 0.076 (in-sample avg dev_std = 0.088)
model_dirname= repr_LECIvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:27:11 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:27:13 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 155...
[0m[1;37mINFO[0m: [1mCheckpoint 155: 
-----------------------------------
Train ACCURACY: 0.9999
Train Loss: 0.0005
ID Validation ACCURACY: 0.9202
ID Validation Loss: 0.3844
ID Test ACCURACY: 0.9149
ID Test Loss: 0.4498
OOD Validation ACCURACY: 0.8829
OOD Validation Loss: 0.5759
OOD Test ACCURACY: 0.8366
OOD Test Loss: 0.9989

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 172...
[0m[1;37mINFO[0m: [1mCheckpoint 172: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0003
ID Validation ACCURACY: 0.9170
ID Validation Loss: 0.4333
ID Test ACCURACY: 0.9164
ID Test Loss: 0.5038
OOD Validation ACCURACY: 0.8868
OOD Validation Loss: 0.6171
OOD Test ACCURACY: 0.8387
OOD Test Loss: 1.0809

[0m[1;37mINFO[0m: [1mChartInfo 0.9149 0.8366 0.9164 0.8387 0.9170 0.8868[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/29/2024 02:27:15 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.843
SUFF++ for r=0.6 class 0.0 = 0.857 +- 0.299 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.6 class 1.0 = 0.914 +- 0.299 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.6 all KL = 0.795 +- 0.299 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.6 all L1 = 0.89 +- 0.173 (in-sample avg dev_std = 0.341)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.878
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.865
SUFF++ for r=0.9 class 0.0 = 0.947 +- 0.128 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.9 class 1.0 = 0.982 +- 0.128 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.9 all KL = 0.974 +- 0.128 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.9 all L1 = 0.967 +- 0.114 (in-sample avg dev_std = 0.105)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.783
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.742
SUFF++ for r=0.3 class 0.0 = 0.807 +- 0.270 (in-sample avg dev_std = 0.370)
SUFF++ for r=0.3 class 1.0 = 0.902 +- 0.270 (in-sample avg dev_std = 0.370)
SUFF++ for r=0.3 all KL = 0.789 +- 0.270 (in-sample avg dev_std = 0.370)
SUFF++ for r=0.3 all L1 = 0.856 +- 0.185 (in-sample avg dev_std = 0.370)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.814
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.792
SUFF++ for r=0.6 class 0.0 = 0.857 +- 0.226 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.6 class 1.0 = 0.915 +- 0.226 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.6 all KL = 0.862 +- 0.226 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.6 all L1 = 0.887 +- 0.178 (in-sample avg dev_std = 0.275)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.844
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.836
SUFF++ for r=0.9 class 0.0 = 0.932 +- 0.140 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.9 class 1.0 = 0.955 +- 0.140 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.9 all KL = 0.941 +- 0.140 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.9 all L1 = 0.944 +- 0.118 (in-sample avg dev_std = 0.195)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.87
NEC for r=0.6 class 0.0 = 0.081 +- 0.189 (in-sample avg dev_std = 0.174)
NEC for r=0.6 class 1.0 = 0.04 +- 0.189 (in-sample avg dev_std = 0.174)
NEC for r=0.6 all KL = 0.061 +- 0.189 (in-sample avg dev_std = 0.174)
NEC for r=0.6 all L1 = 0.057 +- 0.152 (in-sample avg dev_std = 0.174)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.888
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.872
NEC for r=0.9 class 0.0 = 0.053 +- 0.130 (in-sample avg dev_std = 0.102)
NEC for r=0.9 class 1.0 = 0.02 +- 0.130 (in-sample avg dev_std = 0.102)
NEC for r=0.9 all KL = 0.028 +- 0.130 (in-sample avg dev_std = 0.102)
NEC for r=0.9 all L1 = 0.033 +- 0.117 (in-sample avg dev_std = 0.102)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.888
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.872
NEC for r=1.0 class 0.0 = 0.053 +- 0.130 (in-sample avg dev_std = 0.102)
NEC for r=1.0 class 1.0 = 0.02 +- 0.130 (in-sample avg dev_std = 0.102)
NEC for r=1.0 all KL = 0.028 +- 0.130 (in-sample avg dev_std = 0.102)
NEC for r=1.0 all L1 = 0.033 +- 0.117 (in-sample avg dev_std = 0.102)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.783
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.773
NEC for r=0.3 class 0.0 = 0.134 +- 0.197 (in-sample avg dev_std = 0.180)
NEC for r=0.3 class 1.0 = 0.056 +- 0.197 (in-sample avg dev_std = 0.180)
NEC for r=0.3 all KL = 0.086 +- 0.197 (in-sample avg dev_std = 0.180)
NEC for r=0.3 all L1 = 0.094 +- 0.178 (in-sample avg dev_std = 0.180)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.814
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.813
NEC for r=0.6 class 0.0 = 0.089 +- 0.137 (in-sample avg dev_std = 0.145)
NEC for r=0.6 class 1.0 = 0.053 +- 0.137 (in-sample avg dev_std = 0.145)
NEC for r=0.6 all KL = 0.051 +- 0.137 (in-sample avg dev_std = 0.145)
NEC for r=0.6 all L1 = 0.07 +- 0.148 (in-sample avg dev_std = 0.145)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.844
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.837
NEC for r=0.9 class 0.0 = 0.049 +- 0.084 (in-sample avg dev_std = 0.089)
NEC for r=0.9 class 1.0 = 0.025 +- 0.084 (in-sample avg dev_std = 0.089)
NEC for r=0.9 all KL = 0.021 +- 0.084 (in-sample avg dev_std = 0.089)
NEC for r=0.9 all L1 = 0.037 +- 0.103 (in-sample avg dev_std = 0.089)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.845
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.842
NEC for r=1.0 class 0.0 = 0.038 +- 0.071 (in-sample avg dev_std = 0.078)
NEC for r=1.0 class 1.0 = 0.021 +- 0.071 (in-sample avg dev_std = 0.078)
NEC for r=1.0 all KL = 0.015 +- 0.071 (in-sample avg dev_std = 0.078)
NEC for r=1.0 all L1 = 0.029 +- 0.091 (in-sample avg dev_std = 0.078)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.805, 0.975, 1.0], 'all_L1': [0.898, 0.971, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.784, 0.982, 1.0], 'all_L1': [0.886, 0.977, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.82, 0.977, 1.0], 'all_L1': [0.884, 0.963, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.795, 0.978, 1.0], 'all_L1': [0.896, 0.975, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.795, 0.974, 1.0], 'all_L1': [0.89, 0.967, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.067, 0.027, 0.027], 'all_L1': [0.056, 0.029, 0.029]}), defaultdict(<class 'list'>, {'all_KL': [0.054, 0.024, 0.024], 'all_L1': [0.049, 0.028, 0.028]}), defaultdict(<class 'list'>, {'all_KL': [0.06, 0.021, 0.021], 'all_L1': [0.063, 0.034, 0.034]}), defaultdict(<class 'list'>, {'all_KL': [0.053, 0.024, 0.024], 'all_L1': [0.045, 0.024, 0.024]}), defaultdict(<class 'list'>, {'all_KL': [0.061, 0.028, 0.028], 'all_L1': [0.057, 0.033, 0.033]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.621, 0.765, 0.927, 1.0], 'all_L1': [0.771, 0.849, 0.937, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.768, 0.843, 0.938, 1.0], 'all_L1': [0.862, 0.894, 0.95, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.808, 0.855, 0.941, 1.0], 'all_L1': [0.854, 0.891, 0.945, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.764, 0.847, 0.941, 1.0], 'all_L1': [0.853, 0.897, 0.951, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.789, 0.862, 0.941, 1.0], 'all_L1': [0.856, 0.887, 0.944, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.181, 0.111, 0.037, 0.022], 'all_L1': [0.151, 0.101, 0.045, 0.031]}), defaultdict(<class 'list'>, {'all_KL': [0.086, 0.053, 0.026, 0.012], 'all_L1': [0.084, 0.059, 0.032, 0.019]}), defaultdict(<class 'list'>, {'all_KL': [0.073, 0.05, 0.023, 0.013], 'all_L1': [0.097, 0.064, 0.036, 0.026]}), defaultdict(<class 'list'>, {'all_KL': [0.087, 0.056, 0.024, 0.013], 'all_L1': [0.091, 0.061, 0.032, 0.021]}), defaultdict(<class 'list'>, {'all_KL': [0.086, 0.051, 0.021, 0.015], 'all_L1': [0.094, 0.07, 0.037, 0.029]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.891 +- 0.005, 0.971 +- 0.005, 1.000 +- 0.000
suff++ class all_KL  =  0.800 +- 0.012, 0.977 +- 0.003, 1.000 +- 0.000
suff++_acc_int  =  0.846 +- 0.006, 0.876 +- 0.007
nec class all_L1  =  0.054 +- 0.006, 0.030 +- 0.004, 0.030 +- 0.004
nec class all_KL  =  0.059 +- 0.005, 0.025 +- 0.002, 0.025 +- 0.002
nec_acc_int  =  0.875 +- 0.004, 0.875 +- 0.002, 0.875 +- 0.002

Eval split test
suff++ class all_L1  =  0.839 +- 0.034, 0.884 +- 0.018, 0.945 +- 0.005, 1.000 +- 0.000
suff++ class all_KL  =  0.750 +- 0.066, 0.834 +- 0.035, 0.938 +- 0.005, 1.000 +- 0.000
suff++_acc_int  =  0.743 +- 0.005, 0.795 +- 0.007, 0.833 +- 0.003
nec class all_L1  =  0.103 +- 0.024, 0.071 +- 0.015, 0.036 +- 0.005, 0.025 +- 0.005
nec class all_KL  =  0.103 +- 0.040, 0.064 +- 0.023, 0.026 +- 0.006, 0.015 +- 0.004
nec_acc_int  =  0.776 +- 0.007, 0.813 +- 0.004, 0.837 +- 0.002, 0.841 +- 0.003


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.472 +- 0.003, 0.500 +- 0.001, 0.515 +- 0.002
Faith. Armon (L1)= 		  =  0.102 +- 0.011, 0.057 +- 0.007, 0.057 +- 0.007
Faith. GMean (L1)= 	  =  0.219 +- 0.013, 0.169 +- 0.010, 0.172 +- 0.011
Faith. Aritm (KL)= 		  =  0.429 +- 0.008, 0.501 +- 0.001, 0.512 +- 0.001
Faith. Armon (KL)= 		  =  0.110 +- 0.009, 0.048 +- 0.005, 0.048 +- 0.005
Faith. GMean (KL)= 	  =  0.217 +- 0.010, 0.155 +- 0.008, 0.157 +- 0.008

Eval split test
Faith. Aritm (L1)= 		  =  0.471 +- 0.005, 0.477 +- 0.001, 0.491 +- 0.000, 0.513 +- 0.002
Faith. Armon (L1)= 		  =  0.183 +- 0.036, 0.131 +- 0.026, 0.070 +- 0.009, 0.049 +- 0.009
Faith. GMean (L1)= 	  =  0.292 +- 0.025, 0.249 +- 0.023, 0.185 +- 0.011, 0.158 +- 0.015
Faith. Aritm (KL)= 		  =  0.426 +- 0.014, 0.449 +- 0.006, 0.482 +- 0.000, 0.507 +- 0.002
Faith. Armon (KL)= 		  =  0.176 +- 0.053, 0.118 +- 0.038, 0.051 +- 0.011, 0.030 +- 0.007
Faith. GMean (KL)= 	  =  0.271 +- 0.033, 0.227 +- 0.032, 0.156 +- 0.016, 0.122 +- 0.014
Computed for split load_split = id



Completed in  0:11:41.952912  for LECIvGIN GOODSST2/length



DONE LECI GOODSST2/length
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:29:38 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/29/2024 02:29:40 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:29:40 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:29:40 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:29:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:29:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:29:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:29:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:29:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:29:40 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 02:29:40 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:29:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:29:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:29:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:29:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:29:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:29:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:29:40 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:29:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:29:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:29:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:29:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:29:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:29:40 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:29:40 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 199...
[0m[1;37mINFO[0m: [1mCheckpoint 199: 
-----------------------------------
Train ACCURACY: 0.8701
Train Loss: 0.3128
ID Validation ACCURACY: 0.8608
ID Validation Loss: 0.3274
ID Test ACCURACY: 0.8583
ID Test Loss: 0.3380
OOD Validation ACCURACY: 0.8347
OOD Validation Loss: 0.3757
OOD Test ACCURACY: 0.7644
OOD Test Loss: 0.5115

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 183...
[0m[1;37mINFO[0m: [1mCheckpoint 183: 
-----------------------------------
Train ACCURACY: 0.8610
Train Loss: 0.3273
ID Validation ACCURACY: 0.8544
ID Validation Loss: 0.3376
ID Test ACCURACY: 0.8517
ID Test Loss: 0.3499
OOD Validation ACCURACY: 0.8398
OOD Validation Loss: 0.3668
OOD Test ACCURACY: 0.7856
OOD Test Loss: 0.4713

[0m[1;37mINFO[0m: [1mChartInfo 0.8583 0.7644 0.8517 0.7856 0.8544 0.8398[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/29/2024 02:29:41 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.849
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.846
SUFF++ for r=0.6 class 0.0 = 0.903 +- 0.047 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.6 class 1.0 = 0.942 +- 0.047 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.6 all KL = 0.976 +- 0.047 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.6 all L1 = 0.925 +- 0.084 (in-sample avg dev_std = 0.125)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.867
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.869
SUFF++ for r=0.9 class 0.0 = 0.931 +- 0.019 (in-sample avg dev_std = 0.059)
SUFF++ for r=0.9 class 1.0 = 0.955 +- 0.019 (in-sample avg dev_std = 0.059)
SUFF++ for r=0.9 all KL = 0.991 +- 0.019 (in-sample avg dev_std = 0.059)
SUFF++ for r=0.9 all L1 = 0.944 +- 0.068 (in-sample avg dev_std = 0.059)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.719
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.705
SUFF++ for r=0.3 class 0.0 = 0.873 +- 0.049 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.3 class 1.0 = 0.922 +- 0.049 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.3 all KL = 0.964 +- 0.049 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.3 all L1 = 0.898 +- 0.091 (in-sample avg dev_std = 0.160)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.776
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.756
SUFF++ for r=0.6 class 0.0 = 0.901 +- 0.030 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.6 class 1.0 = 0.932 +- 0.030 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.6 all KL = 0.98 +- 0.030 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.6 all L1 = 0.917 +- 0.075 (in-sample avg dev_std = 0.111)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.789
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.79
SUFF++ for r=0.9 class 0.0 = 0.958 +- 0.006 (in-sample avg dev_std = 0.051)
SUFF++ for r=0.9 class 1.0 = 0.971 +- 0.006 (in-sample avg dev_std = 0.051)
SUFF++ for r=0.9 all KL = 0.996 +- 0.006 (in-sample avg dev_std = 0.051)
SUFF++ for r=0.9 all L1 = 0.965 +- 0.033 (in-sample avg dev_std = 0.051)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.849
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.864
NEC for r=0.6 class 0.0 = 0.082 +- 0.025 (in-sample avg dev_std = 0.063)
NEC for r=0.6 class 1.0 = 0.053 +- 0.025 (in-sample avg dev_std = 0.063)
NEC for r=0.6 all KL = 0.013 +- 0.025 (in-sample avg dev_std = 0.063)
NEC for r=0.6 all L1 = 0.065 +- 0.072 (in-sample avg dev_std = 0.063)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.87
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.862
NEC for r=0.9 class 0.0 = 0.071 +- 0.022 (in-sample avg dev_std = 0.055)
NEC for r=0.9 class 1.0 = 0.049 +- 0.022 (in-sample avg dev_std = 0.055)
NEC for r=0.9 all KL = 0.01 +- 0.022 (in-sample avg dev_std = 0.055)
NEC for r=0.9 all L1 = 0.058 +- 0.072 (in-sample avg dev_std = 0.055)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.863
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.861
NEC for r=1.0 class 0.0 = 0.076 +- 0.021 (in-sample avg dev_std = 0.054)
NEC for r=1.0 class 1.0 = 0.046 +- 0.021 (in-sample avg dev_std = 0.054)
NEC for r=1.0 all KL = 0.01 +- 0.021 (in-sample avg dev_std = 0.054)
NEC for r=1.0 all L1 = 0.059 +- 0.072 (in-sample avg dev_std = 0.054)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.719
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.738
NEC for r=0.3 class 0.0 = 0.114 +- 0.038 (in-sample avg dev_std = 0.081)
NEC for r=0.3 class 1.0 = 0.063 +- 0.038 (in-sample avg dev_std = 0.081)
NEC for r=0.3 all KL = 0.019 +- 0.038 (in-sample avg dev_std = 0.081)
NEC for r=0.3 all L1 = 0.087 +- 0.093 (in-sample avg dev_std = 0.081)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.776
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.78
NEC for r=0.6 class 0.0 = 0.078 +- 0.016 (in-sample avg dev_std = 0.060)
NEC for r=0.6 class 1.0 = 0.052 +- 0.016 (in-sample avg dev_std = 0.060)
NEC for r=0.6 all KL = 0.009 +- 0.016 (in-sample avg dev_std = 0.060)
NEC for r=0.6 all L1 = 0.065 +- 0.064 (in-sample avg dev_std = 0.060)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.789
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.79
NEC for r=0.9 class 0.0 = 0.064 +- 0.010 (in-sample avg dev_std = 0.047)
NEC for r=0.9 class 1.0 = 0.044 +- 0.010 (in-sample avg dev_std = 0.047)
NEC for r=0.9 all KL = 0.006 +- 0.010 (in-sample avg dev_std = 0.047)
NEC for r=0.9 all L1 = 0.053 +- 0.050 (in-sample avg dev_std = 0.047)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.767
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.777
NEC for r=1.0 class 0.0 = 0.068 +- 0.010 (in-sample avg dev_std = 0.042)
NEC for r=1.0 class 1.0 = 0.041 +- 0.010 (in-sample avg dev_std = 0.042)
NEC for r=1.0 all KL = 0.006 +- 0.010 (in-sample avg dev_std = 0.042)
NEC for r=1.0 all L1 = 0.054 +- 0.050 (in-sample avg dev_std = 0.042)
model_dirname= repr_GSATvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:32:04 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/29/2024 02:32:04 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:32:04 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:32:04 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:32:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:32:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:32:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:32:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:32:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:32:04 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 02:32:04 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:32:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:32:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:32:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:32:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:32:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:32:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:32:04 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:32:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:32:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:32:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:32:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:32:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:32:04 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:32:05 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 199...
[0m[1;37mINFO[0m: [1mCheckpoint 199: 
-----------------------------------
Train ACCURACY: 0.8706
Train Loss: 0.3077
ID Validation ACCURACY: 0.8581
ID Validation Loss: 0.3276
ID Test ACCURACY: 0.8561
ID Test Loss: 0.3387
OOD Validation ACCURACY: 0.8283
OOD Validation Loss: 0.3850
OOD Test ACCURACY: 0.7998
OOD Test Loss: 0.4921

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 195...
[0m[1;37mINFO[0m: [1mCheckpoint 195: 
-----------------------------------
Train ACCURACY: 0.8631
Train Loss: 0.3177
ID Validation ACCURACY: 0.8521
ID Validation Loss: 0.3384
ID Test ACCURACY: 0.8474
ID Test Loss: 0.3501
OOD Validation ACCURACY: 0.8407
OOD Validation Loss: 0.3613
OOD Test ACCURACY: 0.8130
OOD Test Loss: 0.4207

[0m[1;37mINFO[0m: [1mChartInfo 0.8561 0.7998 0.8474 0.8130 0.8521 0.8407[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/29/2024 02:32:05 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.863
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.848
SUFF++ for r=0.6 class 0.0 = 0.902 +- 0.046 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.6 class 1.0 = 0.941 +- 0.046 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.6 all KL = 0.976 +- 0.046 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.6 all L1 = 0.924 +- 0.082 (in-sample avg dev_std = 0.125)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.85
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.863
SUFF++ for r=0.9 class 0.0 = 0.941 +- 0.013 (in-sample avg dev_std = 0.044)
SUFF++ for r=0.9 class 1.0 = 0.96 +- 0.013 (in-sample avg dev_std = 0.044)
SUFF++ for r=0.9 all KL = 0.994 +- 0.013 (in-sample avg dev_std = 0.044)
SUFF++ for r=0.9 all L1 = 0.952 +- 0.053 (in-sample avg dev_std = 0.044)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.694
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.676
SUFF++ for r=0.3 class 0.0 = 0.887 +- 0.046 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.3 class 1.0 = 0.942 +- 0.046 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.3 all KL = 0.972 +- 0.046 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.3 all L1 = 0.915 +- 0.085 (in-sample avg dev_std = 0.149)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.762
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.736
SUFF++ for r=0.6 class 0.0 = 0.9 +- 0.031 (in-sample avg dev_std = 0.110)
SUFF++ for r=0.6 class 1.0 = 0.947 +- 0.031 (in-sample avg dev_std = 0.110)
SUFF++ for r=0.6 all KL = 0.981 +- 0.031 (in-sample avg dev_std = 0.110)
SUFF++ for r=0.6 all L1 = 0.924 +- 0.077 (in-sample avg dev_std = 0.110)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.808
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.8
SUFF++ for r=0.9 class 0.0 = 0.953 +- 0.010 (in-sample avg dev_std = 0.062)
SUFF++ for r=0.9 class 1.0 = 0.97 +- 0.010 (in-sample avg dev_std = 0.062)
SUFF++ for r=0.9 all KL = 0.995 +- 0.010 (in-sample avg dev_std = 0.062)
SUFF++ for r=0.9 all L1 = 0.962 +- 0.043 (in-sample avg dev_std = 0.062)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.863
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.856
NEC for r=0.6 class 0.0 = 0.083 +- 0.024 (in-sample avg dev_std = 0.055)
NEC for r=0.6 class 1.0 = 0.049 +- 0.024 (in-sample avg dev_std = 0.055)
NEC for r=0.6 all KL = 0.011 +- 0.024 (in-sample avg dev_std = 0.055)
NEC for r=0.6 all L1 = 0.063 +- 0.069 (in-sample avg dev_std = 0.055)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.846
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.851
NEC for r=0.9 class 0.0 = 0.067 +- 0.015 (in-sample avg dev_std = 0.048)
NEC for r=0.9 class 1.0 = 0.046 +- 0.015 (in-sample avg dev_std = 0.048)
NEC for r=0.9 all KL = 0.008 +- 0.015 (in-sample avg dev_std = 0.048)
NEC for r=0.9 all L1 = 0.055 +- 0.062 (in-sample avg dev_std = 0.048)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.849
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.848
NEC for r=1.0 class 0.0 = 0.07 +- 0.015 (in-sample avg dev_std = 0.048)
NEC for r=1.0 class 1.0 = 0.045 +- 0.015 (in-sample avg dev_std = 0.048)
NEC for r=1.0 all KL = 0.009 +- 0.015 (in-sample avg dev_std = 0.048)
NEC for r=1.0 all L1 = 0.055 +- 0.062 (in-sample avg dev_std = 0.048)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.694
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.697
NEC for r=0.3 class 0.0 = 0.102 +- 0.032 (in-sample avg dev_std = 0.070)
NEC for r=0.3 class 1.0 = 0.04 +- 0.032 (in-sample avg dev_std = 0.070)
NEC for r=0.3 all KL = 0.014 +- 0.032 (in-sample avg dev_std = 0.070)
NEC for r=0.3 all L1 = 0.07 +- 0.085 (in-sample avg dev_std = 0.070)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.762
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.754
NEC for r=0.6 class 0.0 = 0.075 +- 0.014 (in-sample avg dev_std = 0.056)
NEC for r=0.6 class 1.0 = 0.037 +- 0.014 (in-sample avg dev_std = 0.056)
NEC for r=0.6 all KL = 0.008 +- 0.014 (in-sample avg dev_std = 0.056)
NEC for r=0.6 all L1 = 0.055 +- 0.061 (in-sample avg dev_std = 0.056)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.808
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.803
NEC for r=0.9 class 0.0 = 0.062 +- 0.017 (in-sample avg dev_std = 0.057)
NEC for r=0.9 class 1.0 = 0.04 +- 0.017 (in-sample avg dev_std = 0.057)
NEC for r=0.9 all KL = 0.007 +- 0.017 (in-sample avg dev_std = 0.057)
NEC for r=0.9 all L1 = 0.051 +- 0.062 (in-sample avg dev_std = 0.057)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.81
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.808
NEC for r=1.0 class 0.0 = 0.054 +- 0.014 (in-sample avg dev_std = 0.053)
NEC for r=1.0 class 1.0 = 0.036 +- 0.014 (in-sample avg dev_std = 0.053)
NEC for r=1.0 all KL = 0.006 +- 0.014 (in-sample avg dev_std = 0.053)
NEC for r=1.0 all L1 = 0.045 +- 0.054 (in-sample avg dev_std = 0.053)
model_dirname= repr_GSATvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:34:26 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/29/2024 02:34:27 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:34:27 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:34:27 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:34:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:34:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:34:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:34:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:34:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:34:27 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 02:34:27 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:34:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:34:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:34:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:34:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:34:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:34:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:34:27 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:34:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:34:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:34:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:34:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:34:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:34:27 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:34:27 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 197...
[0m[1;37mINFO[0m: [1mCheckpoint 197: 
-----------------------------------
Train ACCURACY: 0.8923
Train Loss: 0.2675
ID Validation ACCURACY: 0.8704
ID Validation Loss: 0.3044
ID Test ACCURACY: 0.8696
ID Test Loss: 0.3098
OOD Validation ACCURACY: 0.8475
OOD Validation Loss: 0.3537
OOD Test ACCURACY: 0.8113
OOD Test Loss: 0.4881

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 199...
[0m[1;37mINFO[0m: [1mCheckpoint 199: 
-----------------------------------
Train ACCURACY: 0.8913
Train Loss: 0.2703
ID Validation ACCURACY: 0.8657
ID Validation Loss: 0.3071
ID Test ACCURACY: 0.8676
ID Test Loss: 0.3133
OOD Validation ACCURACY: 0.8539
OOD Validation Loss: 0.3455
OOD Test ACCURACY: 0.8248
OOD Test Loss: 0.4413

[0m[1;37mINFO[0m: [1mChartInfo 0.8696 0.8113 0.8676 0.8248 0.8657 0.8539[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/29/2024 02:34:27 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.856
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.829
SUFF++ for r=0.6 class 0.0 = 0.826 +- 0.111 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.6 class 1.0 = 0.857 +- 0.111 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.6 all KL = 0.906 +- 0.111 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.6 all L1 = 0.844 +- 0.119 (in-sample avg dev_std = 0.262)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.867
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.867
SUFF++ for r=0.9 class 0.0 = 0.923 +- 0.019 (in-sample avg dev_std = 0.047)
SUFF++ for r=0.9 class 1.0 = 0.961 +- 0.019 (in-sample avg dev_std = 0.047)
SUFF++ for r=0.9 all KL = 0.991 +- 0.019 (in-sample avg dev_std = 0.047)
SUFF++ for r=0.9 all L1 = 0.944 +- 0.066 (in-sample avg dev_std = 0.047)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.767
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.749
SUFF++ for r=0.3 class 0.0 = 0.785 +- 0.117 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.3 class 1.0 = 0.866 +- 0.117 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.3 all KL = 0.894 +- 0.117 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.3 all L1 = 0.827 +- 0.135 (in-sample avg dev_std = 0.284)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.793
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.771
SUFF++ for r=0.6 class 0.0 = 0.793 +- 0.095 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.6 class 1.0 = 0.887 +- 0.095 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.6 all KL = 0.91 +- 0.095 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.6 all L1 = 0.842 +- 0.128 (in-sample avg dev_std = 0.264)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.811
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.813
SUFF++ for r=0.9 class 0.0 = 0.912 +- 0.023 (in-sample avg dev_std = 0.103)
SUFF++ for r=0.9 class 1.0 = 0.953 +- 0.023 (in-sample avg dev_std = 0.103)
SUFF++ for r=0.9 all KL = 0.984 +- 0.023 (in-sample avg dev_std = 0.103)
SUFF++ for r=0.9 all L1 = 0.933 +- 0.072 (in-sample avg dev_std = 0.103)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.856
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.86
NEC for r=0.6 class 0.0 = 0.13 +- 0.053 (in-sample avg dev_std = 0.086)
NEC for r=0.6 class 1.0 = 0.068 +- 0.053 (in-sample avg dev_std = 0.086)
NEC for r=0.6 all KL = 0.026 +- 0.053 (in-sample avg dev_std = 0.086)
NEC for r=0.6 all L1 = 0.094 +- 0.105 (in-sample avg dev_std = 0.086)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.874
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.865
NEC for r=0.9 class 0.0 = 0.08 +- 0.023 (in-sample avg dev_std = 0.049)
NEC for r=0.9 class 1.0 = 0.043 +- 0.023 (in-sample avg dev_std = 0.049)
NEC for r=0.9 all KL = 0.01 +- 0.023 (in-sample avg dev_std = 0.049)
NEC for r=0.9 all L1 = 0.059 +- 0.074 (in-sample avg dev_std = 0.049)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.874
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.866
NEC for r=1.0 class 0.0 = 0.081 +- 0.023 (in-sample avg dev_std = 0.050)
NEC for r=1.0 class 1.0 = 0.041 +- 0.023 (in-sample avg dev_std = 0.050)
NEC for r=1.0 all KL = 0.01 +- 0.023 (in-sample avg dev_std = 0.050)
NEC for r=1.0 all L1 = 0.058 +- 0.074 (in-sample avg dev_std = 0.050)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.767
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.769
NEC for r=0.3 class 0.0 = 0.143 +- 0.070 (in-sample avg dev_std = 0.133)
NEC for r=0.3 class 1.0 = 0.073 +- 0.070 (in-sample avg dev_std = 0.133)
NEC for r=0.3 all KL = 0.037 +- 0.070 (in-sample avg dev_std = 0.133)
NEC for r=0.3 all L1 = 0.107 +- 0.120 (in-sample avg dev_std = 0.133)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.793
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.796
NEC for r=0.6 class 0.0 = 0.115 +- 0.043 (in-sample avg dev_std = 0.099)
NEC for r=0.6 class 1.0 = 0.058 +- 0.043 (in-sample avg dev_std = 0.099)
NEC for r=0.6 all KL = 0.024 +- 0.043 (in-sample avg dev_std = 0.099)
NEC for r=0.6 all L1 = 0.085 +- 0.098 (in-sample avg dev_std = 0.099)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.811
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.82
NEC for r=0.9 class 0.0 = 0.072 +- 0.022 (in-sample avg dev_std = 0.057)
NEC for r=0.9 class 1.0 = 0.042 +- 0.022 (in-sample avg dev_std = 0.057)
NEC for r=0.9 all KL = 0.01 +- 0.022 (in-sample avg dev_std = 0.057)
NEC for r=0.9 all L1 = 0.056 +- 0.071 (in-sample avg dev_std = 0.057)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.815
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.821
NEC for r=1.0 class 0.0 = 0.068 +- 0.019 (in-sample avg dev_std = 0.053)
NEC for r=1.0 class 1.0 = 0.04 +- 0.019 (in-sample avg dev_std = 0.053)
NEC for r=1.0 all KL = 0.009 +- 0.019 (in-sample avg dev_std = 0.053)
NEC for r=1.0 all L1 = 0.053 +- 0.068 (in-sample avg dev_std = 0.053)
model_dirname= repr_GSATvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:36:54 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/29/2024 02:36:55 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:36:55 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:36:55 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:36:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:36:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:36:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:36:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:36:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:36:55 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 02:36:55 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:36:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:36:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:36:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:36:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:36:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:36:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:36:55 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:36:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:36:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:36:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:36:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:36:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:36:55 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:36:55 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 199...
[0m[1;37mINFO[0m: [1mCheckpoint 199: 
-----------------------------------
Train ACCURACY: 0.8692
Train Loss: 0.3185
ID Validation ACCURACY: 0.8596
ID Validation Loss: 0.3352
ID Test ACCURACY: 0.8561
ID Test Loss: 0.3461
OOD Validation ACCURACY: 0.8368
OOD Validation Loss: 0.3737
OOD Test ACCURACY: 0.7961
OOD Test Loss: 0.4490

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 198...
[0m[1;37mINFO[0m: [1mCheckpoint 198: 
-----------------------------------
Train ACCURACY: 0.8720
Train Loss: 0.3178
ID Validation ACCURACY: 0.8572
ID Validation Loss: 0.3330
ID Test ACCURACY: 0.8585
ID Test Loss: 0.3459
OOD Validation ACCURACY: 0.8375
OOD Validation Loss: 0.3704
OOD Test ACCURACY: 0.7994
OOD Test Loss: 0.4454

[0m[1;37mINFO[0m: [1mChartInfo 0.8561 0.7961 0.8585 0.7994 0.8572 0.8375[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/29/2024 02:36:56 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.83
SUFF++ for r=0.6 class 0.0 = 0.856 +- 0.089 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.6 class 1.0 = 0.86 +- 0.089 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.6 all KL = 0.928 +- 0.089 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.6 all L1 = 0.858 +- 0.103 (in-sample avg dev_std = 0.230)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.856
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.856
SUFF++ for r=0.9 class 0.0 = 0.919 +- 0.027 (in-sample avg dev_std = 0.058)
SUFF++ for r=0.9 class 1.0 = 0.953 +- 0.027 (in-sample avg dev_std = 0.058)
SUFF++ for r=0.9 all KL = 0.99 +- 0.027 (in-sample avg dev_std = 0.058)
SUFF++ for r=0.9 all L1 = 0.938 +- 0.071 (in-sample avg dev_std = 0.058)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.749
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.709
SUFF++ for r=0.3 class 0.0 = 0.823 +- 0.111 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.3 class 1.0 = 0.806 +- 0.111 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.3 all KL = 0.903 +- 0.111 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.3 all L1 = 0.814 +- 0.101 (in-sample avg dev_std = 0.273)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.772
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.754
SUFF++ for r=0.6 class 0.0 = 0.846 +- 0.088 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.6 class 1.0 = 0.825 +- 0.088 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.6 all KL = 0.922 +- 0.088 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.6 all L1 = 0.835 +- 0.095 (in-sample avg dev_std = 0.247)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.8
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.797
SUFF++ for r=0.9 class 0.0 = 0.926 +- 0.020 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.9 class 1.0 = 0.939 +- 0.020 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.9 all KL = 0.988 +- 0.020 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.9 all L1 = 0.933 +- 0.058 (in-sample avg dev_std = 0.089)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.857
NEC for r=0.6 class 0.0 = 0.106 +- 0.047 (in-sample avg dev_std = 0.079)
NEC for r=0.6 class 1.0 = 0.077 +- 0.047 (in-sample avg dev_std = 0.079)
NEC for r=0.6 all KL = 0.022 +- 0.047 (in-sample avg dev_std = 0.079)
NEC for r=0.6 all L1 = 0.089 +- 0.098 (in-sample avg dev_std = 0.079)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.863
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.852
NEC for r=0.9 class 0.0 = 0.092 +- 0.031 (in-sample avg dev_std = 0.053)
NEC for r=0.9 class 1.0 = 0.05 +- 0.031 (in-sample avg dev_std = 0.053)
NEC for r=0.9 all KL = 0.012 +- 0.031 (in-sample avg dev_std = 0.053)
NEC for r=0.9 all L1 = 0.068 +- 0.081 (in-sample avg dev_std = 0.053)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.874
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.85
NEC for r=1.0 class 0.0 = 0.095 +- 0.032 (in-sample avg dev_std = 0.051)
NEC for r=1.0 class 1.0 = 0.049 +- 0.032 (in-sample avg dev_std = 0.051)
NEC for r=1.0 all KL = 0.013 +- 0.032 (in-sample avg dev_std = 0.051)
NEC for r=1.0 all L1 = 0.068 +- 0.083 (in-sample avg dev_std = 0.051)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.749
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.755
NEC for r=0.3 class 0.0 = 0.125 +- 0.046 (in-sample avg dev_std = 0.110)
NEC for r=0.3 class 1.0 = 0.097 +- 0.046 (in-sample avg dev_std = 0.110)
NEC for r=0.3 all KL = 0.027 +- 0.046 (in-sample avg dev_std = 0.110)
NEC for r=0.3 all L1 = 0.11 +- 0.098 (in-sample avg dev_std = 0.110)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.772
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.778
NEC for r=0.6 class 0.0 = 0.099 +- 0.040 (in-sample avg dev_std = 0.095)
NEC for r=0.6 class 1.0 = 0.076 +- 0.040 (in-sample avg dev_std = 0.095)
NEC for r=0.6 all KL = 0.018 +- 0.040 (in-sample avg dev_std = 0.095)
NEC for r=0.6 all L1 = 0.087 +- 0.081 (in-sample avg dev_std = 0.095)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.8
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.803
NEC for r=0.9 class 0.0 = 0.065 +- 0.014 (in-sample avg dev_std = 0.053)
NEC for r=0.9 class 1.0 = 0.046 +- 0.014 (in-sample avg dev_std = 0.053)
NEC for r=0.9 all KL = 0.007 +- 0.014 (in-sample avg dev_std = 0.053)
NEC for r=0.9 all L1 = 0.055 +- 0.058 (in-sample avg dev_std = 0.053)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.809
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.803
NEC for r=1.0 class 0.0 = 0.056 +- 0.013 (in-sample avg dev_std = 0.047)
NEC for r=1.0 class 1.0 = 0.041 +- 0.013 (in-sample avg dev_std = 0.047)
NEC for r=1.0 all KL = 0.006 +- 0.013 (in-sample avg dev_std = 0.047)
NEC for r=1.0 all L1 = 0.048 +- 0.052 (in-sample avg dev_std = 0.047)
model_dirname= repr_GSATvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:39:29 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/29/2024 02:39:30 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:39:30 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:39:30 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:39:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:39:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:39:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:39:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:39:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:39:30 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 02:39:30 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:39:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:39:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:39:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:39:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:39:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:39:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:39:30 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:39:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:39:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:39:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:39:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:39:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:39:30 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:39:30 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 194...
[0m[1;37mINFO[0m: [1mCheckpoint 194: 
-----------------------------------
Train ACCURACY: 0.8797
Train Loss: 0.2932
ID Validation ACCURACY: 0.8661
ID Validation Loss: 0.3182
ID Test ACCURACY: 0.8578
ID Test Loss: 0.3285
OOD Validation ACCURACY: 0.8431
OOD Validation Loss: 0.3553
OOD Test ACCURACY: 0.8156
OOD Test Loss: 0.4109

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 184...
[0m[1;37mINFO[0m: [1mCheckpoint 184: 
-----------------------------------
Train ACCURACY: 0.8770
Train Loss: 0.3027
ID Validation ACCURACY: 0.8638
ID Validation Loss: 0.3244
ID Test ACCURACY: 0.8585
ID Test Loss: 0.3336
OOD Validation ACCURACY: 0.8460
OOD Validation Loss: 0.3531
OOD Test ACCURACY: 0.8182
OOD Test Loss: 0.4038

[0m[1;37mINFO[0m: [1mChartInfo 0.8578 0.8156 0.8585 0.8182 0.8638 0.8460[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/29/2024 02:39:30 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.874
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.864
SUFF++ for r=0.6 class 0.0 = 0.903 +- 0.064 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.6 class 1.0 = 0.93 +- 0.064 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.6 all KL = 0.969 +- 0.064 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.6 all L1 = 0.919 +- 0.093 (in-sample avg dev_std = 0.151)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.872
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.879
SUFF++ for r=0.9 class 0.0 = 0.932 +- 0.021 (in-sample avg dev_std = 0.054)
SUFF++ for r=0.9 class 1.0 = 0.953 +- 0.021 (in-sample avg dev_std = 0.054)
SUFF++ for r=0.9 all KL = 0.99 +- 0.021 (in-sample avg dev_std = 0.054)
SUFF++ for r=0.9 all L1 = 0.943 +- 0.074 (in-sample avg dev_std = 0.054)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.745
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.73
SUFF++ for r=0.3 class 0.0 = 0.871 +- 0.063 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.3 class 1.0 = 0.917 +- 0.063 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.3 all KL = 0.959 +- 0.063 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.3 all L1 = 0.895 +- 0.101 (in-sample avg dev_std = 0.184)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.786
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.766
SUFF++ for r=0.6 class 0.0 = 0.888 +- 0.045 (in-sample avg dev_std = 0.142)
SUFF++ for r=0.6 class 1.0 = 0.929 +- 0.045 (in-sample avg dev_std = 0.142)
SUFF++ for r=0.6 all KL = 0.973 +- 0.045 (in-sample avg dev_std = 0.142)
SUFF++ for r=0.6 all L1 = 0.909 +- 0.091 (in-sample avg dev_std = 0.142)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.825
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.818
SUFF++ for r=0.9 class 0.0 = 0.946 +- 0.015 (in-sample avg dev_std = 0.078)
SUFF++ for r=0.9 class 1.0 = 0.961 +- 0.015 (in-sample avg dev_std = 0.078)
SUFF++ for r=0.9 all KL = 0.992 +- 0.015 (in-sample avg dev_std = 0.078)
SUFF++ for r=0.9 all L1 = 0.954 +- 0.052 (in-sample avg dev_std = 0.078)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.874
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.875
NEC for r=0.6 class 0.0 = 0.074 +- 0.039 (in-sample avg dev_std = 0.064)
NEC for r=0.6 class 1.0 = 0.062 +- 0.039 (in-sample avg dev_std = 0.064)
NEC for r=0.6 all KL = 0.015 +- 0.039 (in-sample avg dev_std = 0.064)
NEC for r=0.6 all L1 = 0.067 +- 0.090 (in-sample avg dev_std = 0.064)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.874
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.88
NEC for r=0.9 class 0.0 = 0.069 +- 0.029 (in-sample avg dev_std = 0.059)
NEC for r=0.9 class 1.0 = 0.058 +- 0.029 (in-sample avg dev_std = 0.059)
NEC for r=0.9 all KL = 0.013 +- 0.029 (in-sample avg dev_std = 0.059)
NEC for r=0.9 all L1 = 0.062 +- 0.083 (in-sample avg dev_std = 0.059)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.881
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.882
NEC for r=1.0 class 0.0 = 0.069 +- 0.029 (in-sample avg dev_std = 0.056)
NEC for r=1.0 class 1.0 = 0.051 +- 0.029 (in-sample avg dev_std = 0.056)
NEC for r=1.0 all KL = 0.012 +- 0.029 (in-sample avg dev_std = 0.056)
NEC for r=1.0 all L1 = 0.059 +- 0.080 (in-sample avg dev_std = 0.056)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.745
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.749
NEC for r=0.3 class 0.0 = 0.114 +- 0.040 (in-sample avg dev_std = 0.080)
NEC for r=0.3 class 1.0 = 0.058 +- 0.040 (in-sample avg dev_std = 0.080)
NEC for r=0.3 all KL = 0.019 +- 0.040 (in-sample avg dev_std = 0.080)
NEC for r=0.3 all L1 = 0.085 +- 0.099 (in-sample avg dev_std = 0.080)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.786
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.781
NEC for r=0.6 class 0.0 = 0.076 +- 0.021 (in-sample avg dev_std = 0.067)
NEC for r=0.6 class 1.0 = 0.05 +- 0.021 (in-sample avg dev_std = 0.067)
NEC for r=0.6 all KL = 0.01 +- 0.021 (in-sample avg dev_std = 0.067)
NEC for r=0.6 all L1 = 0.062 +- 0.072 (in-sample avg dev_std = 0.067)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.825
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.825
NEC for r=0.9 class 0.0 = 0.061 +- 0.025 (in-sample avg dev_std = 0.061)
NEC for r=0.9 class 1.0 = 0.043 +- 0.025 (in-sample avg dev_std = 0.061)
NEC for r=0.9 all KL = 0.008 +- 0.025 (in-sample avg dev_std = 0.061)
NEC for r=0.9 all L1 = 0.052 +- 0.065 (in-sample avg dev_std = 0.061)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.832
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.832
NEC for r=1.0 class 0.0 = 0.051 +- 0.020 (in-sample avg dev_std = 0.053)
NEC for r=1.0 class 1.0 = 0.04 +- 0.020 (in-sample avg dev_std = 0.053)
NEC for r=1.0 all KL = 0.006 +- 0.020 (in-sample avg dev_std = 0.053)
NEC for r=1.0 all L1 = 0.046 +- 0.058 (in-sample avg dev_std = 0.053)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.976, 0.991, 1.0], 'all_L1': [0.925, 0.944, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.976, 0.994, 1.0], 'all_L1': [0.924, 0.952, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.906, 0.991, 1.0], 'all_L1': [0.844, 0.944, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.928, 0.99, 1.0], 'all_L1': [0.858, 0.938, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.969, 0.99, 1.0], 'all_L1': [0.919, 0.943, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.013, 0.01, 0.01], 'all_L1': [0.065, 0.058, 0.059]}), defaultdict(<class 'list'>, {'all_KL': [0.011, 0.008, 0.009], 'all_L1': [0.063, 0.055, 0.055]}), defaultdict(<class 'list'>, {'all_KL': [0.026, 0.01, 0.01], 'all_L1': [0.094, 0.059, 0.058]}), defaultdict(<class 'list'>, {'all_KL': [0.022, 0.012, 0.013], 'all_L1': [0.089, 0.068, 0.068]}), defaultdict(<class 'list'>, {'all_KL': [0.015, 0.013, 0.012], 'all_L1': [0.067, 0.062, 0.059]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.964, 0.98, 0.996, 1.0], 'all_L1': [0.898, 0.917, 0.965, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.972, 0.981, 0.995, 1.0], 'all_L1': [0.915, 0.924, 0.962, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.894, 0.91, 0.984, 1.0], 'all_L1': [0.827, 0.842, 0.933, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.903, 0.922, 0.988, 1.0], 'all_L1': [0.814, 0.835, 0.933, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.959, 0.973, 0.992, 1.0], 'all_L1': [0.895, 0.909, 0.954, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.019, 0.009, 0.006, 0.006], 'all_L1': [0.087, 0.065, 0.053, 0.054]}), defaultdict(<class 'list'>, {'all_KL': [0.014, 0.008, 0.007, 0.006], 'all_L1': [0.07, 0.055, 0.051, 0.045]}), defaultdict(<class 'list'>, {'all_KL': [0.037, 0.024, 0.01, 0.009], 'all_L1': [0.107, 0.085, 0.056, 0.053]}), defaultdict(<class 'list'>, {'all_KL': [0.027, 0.018, 0.007, 0.006], 'all_L1': [0.11, 0.087, 0.055, 0.048]}), defaultdict(<class 'list'>, {'all_KL': [0.019, 0.01, 0.008, 0.006], 'all_L1': [0.085, 0.062, 0.052, 0.046]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.894 +- 0.035, 0.944 +- 0.004, 1.000 +- 0.000
suff++ class all_KL  =  0.951 +- 0.029, 0.991 +- 0.001, 1.000 +- 0.000
suff++_acc_int  =  0.843 +- 0.013, 0.867 +- 0.008
nec class all_L1  =  0.076 +- 0.013, 0.060 +- 0.004, 0.060 +- 0.004
nec class all_KL  =  0.017 +- 0.006, 0.011 +- 0.002, 0.011 +- 0.001
nec_acc_int  =  0.863 +- 0.007, 0.862 +- 0.010, 0.862 +- 0.012

Eval split test
suff++ class all_L1  =  0.870 +- 0.041, 0.885 +- 0.039, 0.949 +- 0.014, 1.000 +- 0.000
suff++ class all_KL  =  0.938 +- 0.033, 0.953 +- 0.031, 0.991 +- 0.004, 1.000 +- 0.000
suff++_acc_int  =  0.714 +- 0.025, 0.757 +- 0.012, 0.803 +- 0.011
nec class all_L1  =  0.092 +- 0.015, 0.071 +- 0.013, 0.053 +- 0.002, 0.049 +- 0.004
nec class all_KL  =  0.023 +- 0.008, 0.014 +- 0.006, 0.008 +- 0.001, 0.007 +- 0.001
nec_acc_int  =  0.742 +- 0.024, 0.778 +- 0.014, 0.808 +- 0.012, 0.808 +- 0.018


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.485 +- 0.011, 0.502 +- 0.001, 0.530 +- 0.002
Faith. Armon (L1)= 		  =  0.139 +- 0.022, 0.113 +- 0.008, 0.113 +- 0.008
Faith. GMean (L1)= 	  =  0.259 +- 0.017, 0.239 +- 0.008, 0.244 +- 0.009
Faith. Aritm (KL)= 		  =  0.484 +- 0.012, 0.501 +- 0.000, 0.505 +- 0.001
Faith. Armon (KL)= 		  =  0.034 +- 0.011, 0.021 +- 0.003, 0.021 +- 0.003
Faith. GMean (KL)= 	  =  0.127 +- 0.019, 0.102 +- 0.008, 0.104 +- 0.007

Eval split test
Faith. Aritm (L1)= 		  =  0.481 +- 0.013, 0.478 +- 0.013, 0.501 +- 0.006, 0.525 +- 0.002
Faith. Armon (L1)= 		  =  0.165 +- 0.024, 0.131 +- 0.021, 0.101 +- 0.003, 0.094 +- 0.007
Faith. GMean (L1)= 	  =  0.281 +- 0.017, 0.249 +- 0.017, 0.225 +- 0.003, 0.222 +- 0.008
Faith. Aritm (KL)= 		  =  0.481 +- 0.013, 0.484 +- 0.012, 0.499 +- 0.002, 0.503 +- 0.001
Faith. Armon (KL)= 		  =  0.045 +- 0.015, 0.027 +- 0.012, 0.015 +- 0.003, 0.013 +- 0.002
Faith. GMean (KL)= 	  =  0.145 +- 0.022, 0.112 +- 0.023, 0.086 +- 0.007, 0.081 +- 0.007
Computed for split load_split = id



Completed in  0:12:06.309990  for GSATvGIN GOODSST2/length



DONE GSAT GOODSST2/length
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:41:54 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/29/2024 02:41:54 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:26 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:36 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:47 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:04 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:43:21 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 110...
[0m[1;37mINFO[0m: [1mCheckpoint 110: 
-----------------------------------
Train ROC-AUC: 0.9405
Train Loss: 0.1942
ID Validation ROC-AUC: 0.9147
ID Validation Loss: 0.2335
ID Test ROC-AUC: 0.9139
ID Test Loss: 0.2386
OOD Validation ROC-AUC: 0.6753
OOD Validation Loss: 0.3634
OOD Test ROC-AUC: 0.7237
OOD Test Loss: 0.5074

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 32...
[0m[1;37mINFO[0m: [1mCheckpoint 32: 
-----------------------------------
Train ROC-AUC: 0.9080
Train Loss: 0.2574
ID Validation ROC-AUC: 0.8953
ID Validation Loss: 0.2724
ID Test ROC-AUC: 0.8989
ID Test Loss: 0.2750
OOD Validation ROC-AUC: 0.6820
OOD Validation Loss: 0.3270
OOD Test ROC-AUC: 0.7152
OOD Test Loss: 0.5211

[0m[1;37mINFO[0m: [1mChartInfo 0.9139 0.7237 0.8989 0.7152 0.8953 0.6820[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/29/2024 02:43:22 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/29/2024 02:43:27 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.81
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 789
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.677
SUFF++ for r=0.3 class 0.0 = 0.793 +- 0.176 (in-sample avg dev_std = 0.340)
SUFF++ for r=0.3 class 1.0 = 0.74 +- 0.176 (in-sample avg dev_std = 0.340)
SUFF++ for r=0.3 all KL = 0.823 +- 0.176 (in-sample avg dev_std = 0.340)
SUFF++ for r=0.3 all L1 = 0.746 +- 0.121 (in-sample avg dev_std = 0.340)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.888
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.829
SUFF++ for r=0.6 class 0.0 = 0.826 +- 0.124 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.6 class 1.0 = 0.874 +- 0.124 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.6 all KL = 0.906 +- 0.124 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.6 all L1 = 0.868 +- 0.119 (in-sample avg dev_std = 0.205)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.913
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.907
SUFF++ for r=0.9 class 0.0 = 0.927 +- 0.021 (in-sample avg dev_std = 0.066)
SUFF++ for r=0.9 class 1.0 = 0.981 +- 0.021 (in-sample avg dev_std = 0.066)
SUFF++ for r=0.9 all KL = 0.993 +- 0.021 (in-sample avg dev_std = 0.066)
SUFF++ for r=0.9 all L1 = 0.975 +- 0.047 (in-sample avg dev_std = 0.066)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.657
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 781
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.588
SUFF++ for r=0.3 class 0.0 = 0.79 +- 0.149 (in-sample avg dev_std = 0.306)
SUFF++ for r=0.3 class 1.0 = 0.755 +- 0.149 (in-sample avg dev_std = 0.306)
SUFF++ for r=0.3 all KL = 0.867 +- 0.149 (in-sample avg dev_std = 0.306)
SUFF++ for r=0.3 all L1 = 0.761 +- 0.120 (in-sample avg dev_std = 0.306)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.715
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.69
SUFF++ for r=0.6 class 0.0 = 0.82 +- 0.111 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 class 1.0 = 0.85 +- 0.111 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 all KL = 0.92 +- 0.111 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 all L1 = 0.845 +- 0.117 (in-sample avg dev_std = 0.195)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.729
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.725
SUFF++ for r=0.9 class 0.0 = 0.939 +- 0.029 (in-sample avg dev_std = 0.091)
SUFF++ for r=0.9 class 1.0 = 0.957 +- 0.029 (in-sample avg dev_std = 0.091)
SUFF++ for r=0.9 all KL = 0.988 +- 0.029 (in-sample avg dev_std = 0.091)
SUFF++ for r=0.9 all L1 = 0.954 +- 0.059 (in-sample avg dev_std = 0.091)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.801
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.792
NEC for r=0.3 class 0.0 = 0.131 +- 0.057 (in-sample avg dev_std = 0.133)
NEC for r=0.3 class 1.0 = 0.131 +- 0.057 (in-sample avg dev_std = 0.133)
NEC for r=0.3 all KL = 0.04 +- 0.057 (in-sample avg dev_std = 0.133)
NEC for r=0.3 all L1 = 0.131 +- 0.097 (in-sample avg dev_std = 0.133)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.888
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.878
NEC for r=0.6 class 0.0 = 0.135 +- 0.045 (in-sample avg dev_std = 0.102)
NEC for r=0.6 class 1.0 = 0.055 +- 0.045 (in-sample avg dev_std = 0.102)
NEC for r=0.6 all KL = 0.022 +- 0.045 (in-sample avg dev_std = 0.102)
NEC for r=0.6 all L1 = 0.064 +- 0.079 (in-sample avg dev_std = 0.102)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.913
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.894
NEC for r=0.9 class 0.0 = 0.15 +- 0.054 (in-sample avg dev_std = 0.102)
NEC for r=0.9 class 1.0 = 0.042 +- 0.054 (in-sample avg dev_std = 0.102)
NEC for r=0.9 all KL = 0.023 +- 0.054 (in-sample avg dev_std = 0.102)
NEC for r=0.9 all L1 = 0.055 +- 0.087 (in-sample avg dev_std = 0.102)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.923
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.904
NEC for r=1.0 class 0.0 = 0.172 +- 0.063 (in-sample avg dev_std = 0.109)
NEC for r=1.0 class 1.0 = 0.041 +- 0.063 (in-sample avg dev_std = 0.109)
NEC for r=1.0 all KL = 0.025 +- 0.063 (in-sample avg dev_std = 0.109)
NEC for r=1.0 all L1 = 0.056 +- 0.090 (in-sample avg dev_std = 0.109)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.661
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.661
NEC for r=0.3 class 0.0 = 0.142 +- 0.054 (in-sample avg dev_std = 0.134)
NEC for r=0.3 class 1.0 = 0.143 +- 0.054 (in-sample avg dev_std = 0.134)
NEC for r=0.3 all KL = 0.039 +- 0.054 (in-sample avg dev_std = 0.134)
NEC for r=0.3 all L1 = 0.143 +- 0.098 (in-sample avg dev_std = 0.134)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.715
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.7
NEC for r=0.6 class 0.0 = 0.129 +- 0.055 (in-sample avg dev_std = 0.120)
NEC for r=0.6 class 1.0 = 0.095 +- 0.055 (in-sample avg dev_std = 0.120)
NEC for r=0.6 all KL = 0.031 +- 0.055 (in-sample avg dev_std = 0.120)
NEC for r=0.6 all L1 = 0.101 +- 0.095 (in-sample avg dev_std = 0.120)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.729
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.728
NEC for r=0.9 class 0.0 = 0.121 +- 0.060 (in-sample avg dev_std = 0.120)
NEC for r=0.9 class 1.0 = 0.084 +- 0.060 (in-sample avg dev_std = 0.120)
NEC for r=0.9 all KL = 0.032 +- 0.060 (in-sample avg dev_std = 0.120)
NEC for r=0.9 all L1 = 0.091 +- 0.102 (in-sample avg dev_std = 0.120)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.749
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.731
NEC for r=1.0 class 0.0 = 0.132 +- 0.064 (in-sample avg dev_std = 0.125)
NEC for r=1.0 class 1.0 = 0.087 +- 0.064 (in-sample avg dev_std = 0.125)
NEC for r=1.0 all KL = 0.035 +- 0.064 (in-sample avg dev_std = 0.125)
NEC for r=1.0 all L1 = 0.095 +- 0.106 (in-sample avg dev_std = 0.125)
model_dirname= repr_LECIvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:46:27 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/29/2024 02:46:27 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/29/2024 02:46:57 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:07 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:18 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:34 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:51 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:47:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:51 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:47:51 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:47:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:51 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:47:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:51 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:47:51 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 109...
[0m[1;37mINFO[0m: [1mCheckpoint 109: 
-----------------------------------
Train ROC-AUC: 0.9425
Train Loss: 0.2003
ID Validation ROC-AUC: 0.9150
ID Validation Loss: 0.2409
ID Test ROC-AUC: 0.9183
ID Test Loss: 0.2410
OOD Validation ROC-AUC: 0.6828
OOD Validation Loss: 0.3429
OOD Test ROC-AUC: 0.7205
OOD Test Loss: 0.5074

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 62...
[0m[1;37mINFO[0m: [1mCheckpoint 62: 
-----------------------------------
Train ROC-AUC: 0.9245
Train Loss: 0.2217
ID Validation ROC-AUC: 0.9060
ID Validation Loss: 0.2463
ID Test ROC-AUC: 0.9075
ID Test Loss: 0.2497
OOD Validation ROC-AUC: 0.6846
OOD Validation Loss: 0.3341
OOD Test ROC-AUC: 0.7191
OOD Test Loss: 0.5035

[0m[1;37mINFO[0m: [1mChartInfo 0.9183 0.7205 0.9075 0.7191 0.9060 0.6846[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/29/2024 02:47:51 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/29/2024 02:47:55 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.788
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 786
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.651
SUFF++ for r=0.3 class 0.0 = 0.804 +- 0.184 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.3 class 1.0 = 0.717 +- 0.184 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.3 all KL = 0.811 +- 0.184 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.3 all L1 = 0.727 +- 0.129 (in-sample avg dev_std = 0.355)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.895
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.826
SUFF++ for r=0.6 class 0.0 = 0.834 +- 0.146 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.6 class 1.0 = 0.851 +- 0.146 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.6 all KL = 0.888 +- 0.146 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.6 all L1 = 0.849 +- 0.130 (in-sample avg dev_std = 0.229)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.909
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.896
SUFF++ for r=0.9 class 0.0 = 0.931 +- 0.034 (in-sample avg dev_std = 0.077)
SUFF++ for r=0.9 class 1.0 = 0.973 +- 0.034 (in-sample avg dev_std = 0.077)
SUFF++ for r=0.9 all KL = 0.99 +- 0.034 (in-sample avg dev_std = 0.077)
SUFF++ for r=0.9 all L1 = 0.968 +- 0.053 (in-sample avg dev_std = 0.077)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.637
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 783
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.578
SUFF++ for r=0.3 class 0.0 = 0.788 +- 0.175 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.3 class 1.0 = 0.742 +- 0.175 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.3 all KL = 0.851 +- 0.175 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.3 all L1 = 0.749 +- 0.129 (in-sample avg dev_std = 0.326)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.73
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.691
SUFF++ for r=0.6 class 0.0 = 0.832 +- 0.133 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.6 class 1.0 = 0.818 +- 0.133 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.6 all KL = 0.9 +- 0.133 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.6 all L1 = 0.82 +- 0.130 (in-sample avg dev_std = 0.235)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.742
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.736
SUFF++ for r=0.9 class 0.0 = 0.935 +- 0.045 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 class 1.0 = 0.943 +- 0.045 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 all KL = 0.983 +- 0.045 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 all L1 = 0.942 +- 0.068 (in-sample avg dev_std = 0.113)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.79
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.769
NEC for r=0.3 class 0.0 = 0.134 +- 0.055 (in-sample avg dev_std = 0.146)
NEC for r=0.3 class 1.0 = 0.145 +- 0.055 (in-sample avg dev_std = 0.146)
NEC for r=0.3 all KL = 0.046 +- 0.055 (in-sample avg dev_std = 0.146)
NEC for r=0.3 all L1 = 0.144 +- 0.097 (in-sample avg dev_std = 0.146)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.895
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.876
NEC for r=0.6 class 0.0 = 0.137 +- 0.075 (in-sample avg dev_std = 0.129)
NEC for r=0.6 class 1.0 = 0.075 +- 0.075 (in-sample avg dev_std = 0.129)
NEC for r=0.6 all KL = 0.035 +- 0.075 (in-sample avg dev_std = 0.129)
NEC for r=0.6 all L1 = 0.082 +- 0.097 (in-sample avg dev_std = 0.129)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.909
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.884
NEC for r=0.9 class 0.0 = 0.158 +- 0.094 (in-sample avg dev_std = 0.142)
NEC for r=0.9 class 1.0 = 0.066 +- 0.094 (in-sample avg dev_std = 0.142)
NEC for r=0.9 all KL = 0.041 +- 0.094 (in-sample avg dev_std = 0.142)
NEC for r=0.9 all L1 = 0.076 +- 0.108 (in-sample avg dev_std = 0.142)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.919
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.893
NEC for r=1.0 class 0.0 = 0.162 +- 0.111 (in-sample avg dev_std = 0.149)
NEC for r=1.0 class 1.0 = 0.067 +- 0.111 (in-sample avg dev_std = 0.149)
NEC for r=1.0 all KL = 0.046 +- 0.111 (in-sample avg dev_std = 0.149)
NEC for r=1.0 all L1 = 0.078 +- 0.112 (in-sample avg dev_std = 0.149)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.643
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.648
NEC for r=0.3 class 0.0 = 0.143 +- 0.063 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 1.0 = 0.15 +- 0.063 (in-sample avg dev_std = 0.145)
NEC for r=0.3 all KL = 0.044 +- 0.063 (in-sample avg dev_std = 0.145)
NEC for r=0.3 all L1 = 0.149 +- 0.100 (in-sample avg dev_std = 0.145)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.73
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.712
NEC for r=0.6 class 0.0 = 0.124 +- 0.072 (in-sample avg dev_std = 0.147)
NEC for r=0.6 class 1.0 = 0.116 +- 0.072 (in-sample avg dev_std = 0.147)
NEC for r=0.6 all KL = 0.041 +- 0.072 (in-sample avg dev_std = 0.147)
NEC for r=0.6 all L1 = 0.117 +- 0.102 (in-sample avg dev_std = 0.147)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.742
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.72
NEC for r=0.9 class 0.0 = 0.155 +- 0.084 (in-sample avg dev_std = 0.167)
NEC for r=0.9 class 1.0 = 0.116 +- 0.084 (in-sample avg dev_std = 0.167)
NEC for r=0.9 all KL = 0.051 +- 0.084 (in-sample avg dev_std = 0.167)
NEC for r=0.9 all L1 = 0.123 +- 0.113 (in-sample avg dev_std = 0.167)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.74
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.724
NEC for r=1.0 class 0.0 = 0.162 +- 0.090 (in-sample avg dev_std = 0.175)
NEC for r=1.0 class 1.0 = 0.121 +- 0.090 (in-sample avg dev_std = 0.175)
NEC for r=1.0 all KL = 0.056 +- 0.090 (in-sample avg dev_std = 0.175)
NEC for r=1.0 all L1 = 0.128 +- 0.121 (in-sample avg dev_std = 0.175)
model_dirname= repr_LECIvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:50:55 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/29/2024 02:50:56 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:27 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:37 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:47 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:03 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 167...
[0m[1;37mINFO[0m: [1mCheckpoint 167: 
-----------------------------------
Train ROC-AUC: 0.9569
Train Loss: 0.1864
ID Validation ROC-AUC: 0.9175
ID Validation Loss: 0.2713
ID Test ROC-AUC: 0.9203
ID Test Loss: 0.2713
OOD Validation ROC-AUC: 0.6411
OOD Validation Loss: 0.4568
OOD Test ROC-AUC: 0.7036
OOD Test Loss: 0.6502

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 27...
[0m[1;37mINFO[0m: [1mCheckpoint 27: 
-----------------------------------
Train ROC-AUC: 0.9073
Train Loss: 0.2446
ID Validation ROC-AUC: 0.8959
ID Validation Loss: 0.2560
ID Test ROC-AUC: 0.8982
ID Test Loss: 0.2587
OOD Validation ROC-AUC: 0.6940
OOD Validation Loss: 0.2990
OOD Test ROC-AUC: 0.7231
OOD Test Loss: 0.4718

[0m[1;37mINFO[0m: [1mChartInfo 0.9203 0.7036 0.8982 0.7231 0.8959 0.6940[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/29/2024 02:52:20 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/29/2024 02:52:25 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.755
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 785
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.653
SUFF++ for r=0.3 class 0.0 = 0.754 +- 0.234 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.3 class 1.0 = 0.692 +- 0.234 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.3 all KL = 0.745 +- 0.234 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.3 all L1 = 0.699 +- 0.153 (in-sample avg dev_std = 0.421)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.894
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.825
SUFF++ for r=0.6 class 0.0 = 0.776 +- 0.202 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.6 class 1.0 = 0.837 +- 0.202 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.6 all KL = 0.847 +- 0.202 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.6 all L1 = 0.83 +- 0.166 (in-sample avg dev_std = 0.284)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.92
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.914
SUFF++ for r=0.9 class 0.0 = 0.911 +- 0.049 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.9 class 1.0 = 0.969 +- 0.049 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.9 all KL = 0.985 +- 0.049 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.9 all L1 = 0.962 +- 0.074 (in-sample avg dev_std = 0.108)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.655
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 776
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.585
SUFF++ for r=0.3 class 0.0 = 0.751 +- 0.204 (in-sample avg dev_std = 0.386)
SUFF++ for r=0.3 class 1.0 = 0.709 +- 0.204 (in-sample avg dev_std = 0.386)
SUFF++ for r=0.3 all KL = 0.804 +- 0.204 (in-sample avg dev_std = 0.386)
SUFF++ for r=0.3 all L1 = 0.716 +- 0.147 (in-sample avg dev_std = 0.386)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.721
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.675
SUFF++ for r=0.6 class 0.0 = 0.788 +- 0.188 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.6 class 1.0 = 0.8 +- 0.188 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.6 all KL = 0.851 +- 0.188 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.6 all L1 = 0.798 +- 0.156 (in-sample avg dev_std = 0.294)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.729
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.723
SUFF++ for r=0.9 class 0.0 = 0.906 +- 0.060 (in-sample avg dev_std = 0.140)
SUFF++ for r=0.9 class 1.0 = 0.943 +- 0.060 (in-sample avg dev_std = 0.140)
SUFF++ for r=0.9 all KL = 0.975 +- 0.060 (in-sample avg dev_std = 0.140)
SUFF++ for r=0.9 all L1 = 0.937 +- 0.088 (in-sample avg dev_std = 0.140)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.756
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.756
NEC for r=0.3 class 0.0 = 0.171 +- 0.111 (in-sample avg dev_std = 0.197)
NEC for r=0.3 class 1.0 = 0.171 +- 0.111 (in-sample avg dev_std = 0.197)
NEC for r=0.3 all KL = 0.078 +- 0.111 (in-sample avg dev_std = 0.197)
NEC for r=0.3 all L1 = 0.171 +- 0.138 (in-sample avg dev_std = 0.197)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.894
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.883
NEC for r=0.6 class 0.0 = 0.197 +- 0.092 (in-sample avg dev_std = 0.156)
NEC for r=0.6 class 1.0 = 0.08 +- 0.092 (in-sample avg dev_std = 0.156)
NEC for r=0.6 all KL = 0.047 +- 0.092 (in-sample avg dev_std = 0.156)
NEC for r=0.6 all L1 = 0.094 +- 0.126 (in-sample avg dev_std = 0.156)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.92
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.898
NEC for r=0.9 class 0.0 = 0.221 +- 0.112 (in-sample avg dev_std = 0.171)
NEC for r=0.9 class 1.0 = 0.062 +- 0.112 (in-sample avg dev_std = 0.171)
NEC for r=0.9 all KL = 0.05 +- 0.112 (in-sample avg dev_std = 0.171)
NEC for r=0.9 all L1 = 0.08 +- 0.131 (in-sample avg dev_std = 0.171)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.914
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.898
NEC for r=1.0 class 0.0 = 0.236 +- 0.117 (in-sample avg dev_std = 0.181)
NEC for r=1.0 class 1.0 = 0.061 +- 0.117 (in-sample avg dev_std = 0.181)
NEC for r=1.0 all KL = 0.053 +- 0.117 (in-sample avg dev_std = 0.181)
NEC for r=1.0 all L1 = 0.082 +- 0.136 (in-sample avg dev_std = 0.181)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.654
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.642
NEC for r=0.3 class 0.0 = 0.184 +- 0.107 (in-sample avg dev_std = 0.205)
NEC for r=0.3 class 1.0 = 0.182 +- 0.107 (in-sample avg dev_std = 0.205)
NEC for r=0.3 all KL = 0.076 +- 0.107 (in-sample avg dev_std = 0.205)
NEC for r=0.3 all L1 = 0.183 +- 0.128 (in-sample avg dev_std = 0.205)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.721
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.702
NEC for r=0.6 class 0.0 = 0.2 +- 0.113 (in-sample avg dev_std = 0.211)
NEC for r=0.6 class 1.0 = 0.129 +- 0.113 (in-sample avg dev_std = 0.211)
NEC for r=0.6 all KL = 0.07 +- 0.113 (in-sample avg dev_std = 0.211)
NEC for r=0.6 all L1 = 0.141 +- 0.140 (in-sample avg dev_std = 0.211)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.729
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.705
NEC for r=0.9 class 0.0 = 0.203 +- 0.104 (in-sample avg dev_std = 0.212)
NEC for r=0.9 class 1.0 = 0.118 +- 0.104 (in-sample avg dev_std = 0.212)
NEC for r=0.9 all KL = 0.069 +- 0.104 (in-sample avg dev_std = 0.212)
NEC for r=0.9 all L1 = 0.132 +- 0.146 (in-sample avg dev_std = 0.212)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.73
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.705
NEC for r=1.0 class 0.0 = 0.215 +- 0.125 (in-sample avg dev_std = 0.224)
NEC for r=1.0 class 1.0 = 0.121 +- 0.125 (in-sample avg dev_std = 0.224)
NEC for r=1.0 all KL = 0.077 +- 0.125 (in-sample avg dev_std = 0.224)
NEC for r=1.0 all L1 = 0.137 +- 0.159 (in-sample avg dev_std = 0.224)
model_dirname= repr_LECIvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:55:26 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/29/2024 02:55:26 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/29/2024 02:55:57 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:07 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:18 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:35 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:51 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:51 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:51 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:56:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 116...
[0m[1;37mINFO[0m: [1mCheckpoint 116: 
-----------------------------------
Train ROC-AUC: 0.9447
Train Loss: 0.1827
ID Validation ROC-AUC: 0.9169
ID Validation Loss: 0.2215
ID Test ROC-AUC: 0.9158
ID Test Loss: 0.2272
OOD Validation ROC-AUC: 0.6674
OOD Validation Loss: 0.3692
OOD Test ROC-AUC: 0.7147
OOD Test Loss: 0.4982

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 26...
[0m[1;37mINFO[0m: [1mCheckpoint 26: 
-----------------------------------
Train ROC-AUC: 0.9068
Train Loss: 0.2273
ID Validation ROC-AUC: 0.8970
ID Validation Loss: 0.2363
ID Test ROC-AUC: 0.8980
ID Test Loss: 0.2379
OOD Validation ROC-AUC: 0.6903
OOD Validation Loss: 0.3044
OOD Test ROC-AUC: 0.7198
OOD Test Loss: 0.4398

[0m[1;37mINFO[0m: [1mChartInfo 0.9158 0.7147 0.8980 0.7198 0.8970 0.6903[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/29/2024 02:56:52 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/29/2024 02:56:57 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.778
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 784
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.654
SUFF++ for r=0.3 class 0.0 = 0.832 +- 0.145 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.3 class 1.0 = 0.754 +- 0.145 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.3 all KL = 0.862 +- 0.145 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.3 all L1 = 0.763 +- 0.114 (in-sample avg dev_std = 0.292)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.885
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.812
SUFF++ for r=0.6 class 0.0 = 0.848 +- 0.127 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.6 class 1.0 = 0.861 +- 0.127 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.6 all KL = 0.906 +- 0.127 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.6 all L1 = 0.86 +- 0.116 (in-sample avg dev_std = 0.198)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.908
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.899
SUFF++ for r=0.9 class 0.0 = 0.933 +- 0.025 (in-sample avg dev_std = 0.072)
SUFF++ for r=0.9 class 1.0 = 0.974 +- 0.025 (in-sample avg dev_std = 0.072)
SUFF++ for r=0.9 all KL = 0.991 +- 0.025 (in-sample avg dev_std = 0.072)
SUFF++ for r=0.9 all L1 = 0.969 +- 0.051 (in-sample avg dev_std = 0.072)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.655
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 781
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.617
SUFF++ for r=0.3 class 0.0 = 0.812 +- 0.124 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.3 class 1.0 = 0.789 +- 0.124 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.3 all KL = 0.902 +- 0.124 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.3 all L1 = 0.793 +- 0.113 (in-sample avg dev_std = 0.260)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.723
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.687
SUFF++ for r=0.6 class 0.0 = 0.851 +- 0.106 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.6 class 1.0 = 0.853 +- 0.106 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.6 all KL = 0.931 +- 0.106 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.6 all L1 = 0.852 +- 0.104 (in-sample avg dev_std = 0.182)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.739
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.736
SUFF++ for r=0.9 class 0.0 = 0.94 +- 0.025 (in-sample avg dev_std = 0.092)
SUFF++ for r=0.9 class 1.0 = 0.953 +- 0.025 (in-sample avg dev_std = 0.092)
SUFF++ for r=0.9 all KL = 0.989 +- 0.025 (in-sample avg dev_std = 0.092)
SUFF++ for r=0.9 all L1 = 0.951 +- 0.056 (in-sample avg dev_std = 0.092)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.778
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.763
NEC for r=0.3 class 0.0 = 0.126 +- 0.051 (in-sample avg dev_std = 0.125)
NEC for r=0.3 class 1.0 = 0.124 +- 0.051 (in-sample avg dev_std = 0.125)
NEC for r=0.3 all KL = 0.034 +- 0.051 (in-sample avg dev_std = 0.125)
NEC for r=0.3 all L1 = 0.124 +- 0.086 (in-sample avg dev_std = 0.125)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.885
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.867
NEC for r=0.6 class 0.0 = 0.131 +- 0.053 (in-sample avg dev_std = 0.102)
NEC for r=0.6 class 1.0 = 0.066 +- 0.053 (in-sample avg dev_std = 0.102)
NEC for r=0.6 all KL = 0.025 +- 0.053 (in-sample avg dev_std = 0.102)
NEC for r=0.6 all L1 = 0.073 +- 0.084 (in-sample avg dev_std = 0.102)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.908
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.892
NEC for r=0.9 class 0.0 = 0.169 +- 0.069 (in-sample avg dev_std = 0.120)
NEC for r=0.9 class 1.0 = 0.057 +- 0.069 (in-sample avg dev_std = 0.120)
NEC for r=0.9 all KL = 0.031 +- 0.069 (in-sample avg dev_std = 0.120)
NEC for r=0.9 all L1 = 0.07 +- 0.098 (in-sample avg dev_std = 0.120)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.915
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.896
NEC for r=1.0 class 0.0 = 0.184 +- 0.077 (in-sample avg dev_std = 0.133)
NEC for r=1.0 class 1.0 = 0.055 +- 0.077 (in-sample avg dev_std = 0.133)
NEC for r=1.0 all KL = 0.034 +- 0.077 (in-sample avg dev_std = 0.133)
NEC for r=1.0 all L1 = 0.07 +- 0.099 (in-sample avg dev_std = 0.133)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.651
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.649
NEC for r=0.3 class 0.0 = 0.126 +- 0.048 (in-sample avg dev_std = 0.122)
NEC for r=0.3 class 1.0 = 0.131 +- 0.048 (in-sample avg dev_std = 0.122)
NEC for r=0.3 all KL = 0.032 +- 0.048 (in-sample avg dev_std = 0.122)
NEC for r=0.3 all L1 = 0.131 +- 0.090 (in-sample avg dev_std = 0.122)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.723
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.709
NEC for r=0.6 class 0.0 = 0.12 +- 0.043 (in-sample avg dev_std = 0.121)
NEC for r=0.6 class 1.0 = 0.093 +- 0.043 (in-sample avg dev_std = 0.121)
NEC for r=0.6 all KL = 0.027 +- 0.043 (in-sample avg dev_std = 0.121)
NEC for r=0.6 all L1 = 0.098 +- 0.083 (in-sample avg dev_std = 0.121)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.739
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.724
NEC for r=0.9 class 0.0 = 0.142 +- 0.057 (in-sample avg dev_std = 0.143)
NEC for r=0.9 class 1.0 = 0.096 +- 0.057 (in-sample avg dev_std = 0.143)
NEC for r=0.9 all KL = 0.036 +- 0.057 (in-sample avg dev_std = 0.143)
NEC for r=0.9 all L1 = 0.104 +- 0.101 (in-sample avg dev_std = 0.143)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.74
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.733
NEC for r=1.0 class 0.0 = 0.156 +- 0.067 (in-sample avg dev_std = 0.148)
NEC for r=1.0 class 1.0 = 0.103 +- 0.067 (in-sample avg dev_std = 0.148)
NEC for r=1.0 all KL = 0.041 +- 0.067 (in-sample avg dev_std = 0.148)
NEC for r=1.0 all L1 = 0.112 +- 0.109 (in-sample avg dev_std = 0.148)
model_dirname= repr_LECIvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:59:59 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:00 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:30 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:40 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:50 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:08 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 03:01:24 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:01:25 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:25 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:25 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:25 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:01:25 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:25 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:25 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:01:25 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 03:01:25 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 117...
[0m[1;37mINFO[0m: [1mCheckpoint 117: 
-----------------------------------
Train ROC-AUC: 0.9466
Train Loss: 0.1891
ID Validation ROC-AUC: 0.9179
ID Validation Loss: 0.2351
ID Test ROC-AUC: 0.9179
ID Test Loss: 0.2392
OOD Validation ROC-AUC: 0.6628
OOD Validation Loss: 0.3930
OOD Test ROC-AUC: 0.7160
OOD Test Loss: 0.5238

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 26...
[0m[1;37mINFO[0m: [1mCheckpoint 26: 
-----------------------------------
Train ROC-AUC: 0.9058
Train Loss: 0.2379
ID Validation ROC-AUC: 0.8966
ID Validation Loss: 0.2461
ID Test ROC-AUC: 0.8970
ID Test Loss: 0.2496
OOD Validation ROC-AUC: 0.6940
OOD Validation Loss: 0.2886
OOD Test ROC-AUC: 0.7178
OOD Test Loss: 0.4448

[0m[1;37mINFO[0m: [1mChartInfo 0.9179 0.7160 0.8970 0.7178 0.8966 0.6940[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/29/2024 03:01:25 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/29/2024 03:01:29 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.771
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 781
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.678
SUFF++ for r=0.3 class 0.0 = 0.803 +- 0.167 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.3 class 1.0 = 0.748 +- 0.167 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.3 all KL = 0.852 +- 0.167 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.3 all L1 = 0.755 +- 0.117 (in-sample avg dev_std = 0.287)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.888
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.818
SUFF++ for r=0.6 class 0.0 = 0.815 +- 0.169 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.6 class 1.0 = 0.848 +- 0.169 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.6 all KL = 0.874 +- 0.169 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.6 all L1 = 0.844 +- 0.135 (in-sample avg dev_std = 0.230)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.917
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.909
SUFF++ for r=0.9 class 0.0 = 0.911 +- 0.027 (in-sample avg dev_std = 0.084)
SUFF++ for r=0.9 class 1.0 = 0.977 +- 0.027 (in-sample avg dev_std = 0.084)
SUFF++ for r=0.9 all KL = 0.99 +- 0.027 (in-sample avg dev_std = 0.084)
SUFF++ for r=0.9 all L1 = 0.969 +- 0.054 (in-sample avg dev_std = 0.084)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.648
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 785
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.587
SUFF++ for r=0.3 class 0.0 = 0.819 +- 0.127 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.3 class 1.0 = 0.774 +- 0.127 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.3 all KL = 0.902 +- 0.127 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.3 all L1 = 0.781 +- 0.115 (in-sample avg dev_std = 0.253)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.723
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.661
SUFF++ for r=0.6 class 0.0 = 0.841 +- 0.140 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.6 class 1.0 = 0.817 +- 0.140 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.6 all KL = 0.894 +- 0.140 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.6 all L1 = 0.821 +- 0.124 (in-sample avg dev_std = 0.221)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.728
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.723
SUFF++ for r=0.9 class 0.0 = 0.92 +- 0.057 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.9 class 1.0 = 0.948 +- 0.057 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.9 all KL = 0.98 +- 0.057 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.9 all L1 = 0.943 +- 0.077 (in-sample avg dev_std = 0.119)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.772
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.763
NEC for r=0.3 class 0.0 = 0.126 +- 0.067 (in-sample avg dev_std = 0.147)
NEC for r=0.3 class 1.0 = 0.154 +- 0.067 (in-sample avg dev_std = 0.147)
NEC for r=0.3 all KL = 0.047 +- 0.067 (in-sample avg dev_std = 0.147)
NEC for r=0.3 all L1 = 0.15 +- 0.100 (in-sample avg dev_std = 0.147)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.888
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.87
NEC for r=0.6 class 0.0 = 0.153 +- 0.076 (in-sample avg dev_std = 0.130)
NEC for r=0.6 class 1.0 = 0.078 +- 0.076 (in-sample avg dev_std = 0.130)
NEC for r=0.6 all KL = 0.039 +- 0.076 (in-sample avg dev_std = 0.130)
NEC for r=0.6 all L1 = 0.086 +- 0.100 (in-sample avg dev_std = 0.130)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.917
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.899
NEC for r=0.9 class 0.0 = 0.167 +- 0.078 (in-sample avg dev_std = 0.120)
NEC for r=0.9 class 1.0 = 0.049 +- 0.078 (in-sample avg dev_std = 0.120)
NEC for r=0.9 all KL = 0.032 +- 0.078 (in-sample avg dev_std = 0.120)
NEC for r=0.9 all L1 = 0.063 +- 0.098 (in-sample avg dev_std = 0.120)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.924
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.905
NEC for r=1.0 class 0.0 = 0.185 +- 0.075 (in-sample avg dev_std = 0.122)
NEC for r=1.0 class 1.0 = 0.044 +- 0.075 (in-sample avg dev_std = 0.122)
NEC for r=1.0 all KL = 0.031 +- 0.075 (in-sample avg dev_std = 0.122)
NEC for r=1.0 all L1 = 0.06 +- 0.098 (in-sample avg dev_std = 0.122)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.645
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.636
NEC for r=0.3 class 0.0 = 0.15 +- 0.055 (in-sample avg dev_std = 0.144)
NEC for r=0.3 class 1.0 = 0.159 +- 0.055 (in-sample avg dev_std = 0.144)
NEC for r=0.3 all KL = 0.042 +- 0.055 (in-sample avg dev_std = 0.144)
NEC for r=0.3 all L1 = 0.158 +- 0.098 (in-sample avg dev_std = 0.144)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.723
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.7
NEC for r=0.6 class 0.0 = 0.139 +- 0.074 (in-sample avg dev_std = 0.147)
NEC for r=0.6 class 1.0 = 0.116 +- 0.074 (in-sample avg dev_std = 0.147)
NEC for r=0.6 all KL = 0.044 +- 0.074 (in-sample avg dev_std = 0.147)
NEC for r=0.6 all L1 = 0.12 +- 0.104 (in-sample avg dev_std = 0.147)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.728
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.715
NEC for r=0.9 class 0.0 = 0.153 +- 0.090 (in-sample avg dev_std = 0.159)
NEC for r=0.9 class 1.0 = 0.106 +- 0.090 (in-sample avg dev_std = 0.159)
NEC for r=0.9 all KL = 0.052 +- 0.090 (in-sample avg dev_std = 0.159)
NEC for r=0.9 all L1 = 0.114 +- 0.119 (in-sample avg dev_std = 0.159)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.736
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.724
NEC for r=1.0 class 0.0 = 0.155 +- 0.101 (in-sample avg dev_std = 0.164)
NEC for r=1.0 class 1.0 = 0.101 +- 0.101 (in-sample avg dev_std = 0.164)
NEC for r=1.0 all KL = 0.053 +- 0.101 (in-sample avg dev_std = 0.164)
NEC for r=1.0 all L1 = 0.11 +- 0.127 (in-sample avg dev_std = 0.164)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.823, 0.906, 0.993, 1.0], 'all_L1': [0.746, 0.868, 0.975, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.811, 0.888, 0.99, 1.0], 'all_L1': [0.727, 0.849, 0.968, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.745, 0.847, 0.985, 1.0], 'all_L1': [0.699, 0.83, 0.962, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.862, 0.906, 0.991, 1.0], 'all_L1': [0.763, 0.86, 0.969, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.852, 0.874, 0.99, 1.0], 'all_L1': [0.755, 0.844, 0.969, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.04, 0.022, 0.023, 0.025], 'all_L1': [0.131, 0.064, 0.055, 0.056]}), defaultdict(<class 'list'>, {'all_KL': [0.046, 0.035, 0.041, 0.046], 'all_L1': [0.144, 0.082, 0.076, 0.078]}), defaultdict(<class 'list'>, {'all_KL': [0.078, 0.047, 0.05, 0.053], 'all_L1': [0.171, 0.094, 0.08, 0.082]}), defaultdict(<class 'list'>, {'all_KL': [0.034, 0.025, 0.031, 0.034], 'all_L1': [0.124, 0.073, 0.07, 0.07]}), defaultdict(<class 'list'>, {'all_KL': [0.047, 0.039, 0.032, 0.031], 'all_L1': [0.15, 0.086, 0.063, 0.06]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.867, 0.92, 0.988, 1.0], 'all_L1': [0.761, 0.845, 0.954, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.851, 0.9, 0.983, 1.0], 'all_L1': [0.749, 0.82, 0.942, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.804, 0.851, 0.975, 1.0], 'all_L1': [0.716, 0.798, 0.937, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.902, 0.931, 0.989, 1.0], 'all_L1': [0.793, 0.852, 0.951, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.902, 0.894, 0.98, 1.0], 'all_L1': [0.781, 0.821, 0.943, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.039, 0.031, 0.032, 0.035], 'all_L1': [0.143, 0.101, 0.091, 0.095]}), defaultdict(<class 'list'>, {'all_KL': [0.044, 0.041, 0.051, 0.056], 'all_L1': [0.149, 0.117, 0.123, 0.128]}), defaultdict(<class 'list'>, {'all_KL': [0.076, 0.07, 0.069, 0.077], 'all_L1': [0.183, 0.141, 0.132, 0.137]}), defaultdict(<class 'list'>, {'all_KL': [0.032, 0.027, 0.036, 0.041], 'all_L1': [0.131, 0.098, 0.104, 0.112]}), defaultdict(<class 'list'>, {'all_KL': [0.042, 0.044, 0.052, 0.053], 'all_L1': [0.158, 0.12, 0.114, 0.11]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.738 +- 0.023, 0.850 +- 0.013, 0.969 +- 0.004, 1.000 +- 0.000
suff++ class all_KL  =  0.819 +- 0.041, 0.884 +- 0.022, 0.990 +- 0.003, 1.000 +- 0.000
suff++_acc_int  =  0.662 +- 0.012, 0.822 +- 0.006, 0.905 +- 0.007
nec class all_L1  =  0.144 +- 0.016, 0.080 +- 0.010, 0.069 +- 0.009, 0.069 +- 0.010
nec class all_KL  =  0.049 +- 0.015, 0.034 +- 0.009, 0.035 +- 0.009, 0.038 +- 0.010
nec_acc_int  =  0.769 +- 0.013, 0.875 +- 0.006, 0.893 +- 0.005, 0.899 +- 0.005

Eval split test
suff++ class all_L1  =  0.760 +- 0.027, 0.827 +- 0.019, 0.945 +- 0.006, 1.000 +- 0.000
suff++ class all_KL  =  0.865 +- 0.036, 0.899 +- 0.028, 0.983 +- 0.005, 1.000 +- 0.000
suff++_acc_int  =  0.591 +- 0.013, 0.681 +- 0.011, 0.729 +- 0.006
nec class all_L1  =  0.153 +- 0.017, 0.115 +- 0.015, 0.113 +- 0.014, 0.116 +- 0.015
nec class all_KL  =  0.047 +- 0.015, 0.043 +- 0.015, 0.048 +- 0.013, 0.052 +- 0.014
nec_acc_int  =  0.647 +- 0.008, 0.705 +- 0.005, 0.718 +- 0.008, 0.723 +- 0.010


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.441 +- 0.006, 0.465 +- 0.002, 0.519 +- 0.003, 0.535 +- 0.005
Faith. Armon (L1)= 		  =  0.240 +- 0.022, 0.146 +- 0.017, 0.128 +- 0.016, 0.129 +- 0.018
Faith. GMean (L1)= 	  =  0.325 +- 0.014, 0.260 +- 0.015, 0.258 +- 0.017, 0.262 +- 0.019
Faith. Aritm (KL)= 		  =  0.434 +- 0.014, 0.459 +- 0.007, 0.513 +- 0.003, 0.519 +- 0.005
Faith. Armon (KL)= 		  =  0.092 +- 0.026, 0.065 +- 0.017, 0.068 +- 0.017, 0.073 +- 0.019
Faith. GMean (KL)= 	  =  0.197 +- 0.024, 0.170 +- 0.022, 0.186 +- 0.024, 0.193 +- 0.026

Eval split test
Faith. Aritm (L1)= 		  =  0.456 +- 0.008, 0.471 +- 0.002, 0.529 +- 0.004, 0.558 +- 0.007
Faith. Armon (L1)= 		  =  0.254 +- 0.023, 0.202 +- 0.023, 0.201 +- 0.023, 0.208 +- 0.024
Faith. GMean (L1)= 	  =  0.340 +- 0.015, 0.308 +- 0.017, 0.326 +- 0.020, 0.340 +- 0.022
Faith. Aritm (KL)= 		  =  0.456 +- 0.012, 0.471 +- 0.006, 0.516 +- 0.004, 0.526 +- 0.007
Faith. Armon (KL)= 		  =  0.088 +- 0.027, 0.081 +- 0.027, 0.091 +- 0.024, 0.099 +- 0.026
Faith. GMean (KL)= 	  =  0.198 +- 0.026, 0.192 +- 0.030, 0.215 +- 0.029, 0.227 +- 0.031
Computed for split load_split = id



Completed in  0:22:38.897318  for LECIvGIN LBAPcore/assay



DONE LECI LBAPcore/assay
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 15:04:41 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/29/2024 03:04:41 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/29/2024 03:05:12 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/29/2024 03:05:22 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/29/2024 03:05:32 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/29/2024 03:05:49 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/29/2024 03:06:04 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/29/2024 03:06:04 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 03:06:04 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:06:04 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:06:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:06:04 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:06:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:06:04 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:06:04 PM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 03:06:04 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:06:04 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:06:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:06:04 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:06:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:06:04 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:06:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:06:04 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:06:04 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:06:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:06:04 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:06:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:06:04 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:06:04 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 03:06:04 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 188...
[0m[1;37mINFO[0m: [1mCheckpoint 188: 
-----------------------------------
Train ROC-AUC: 0.9592
Train Loss: 0.1717
ID Validation ROC-AUC: 0.9166
ID Validation Loss: 0.2698
ID Test ROC-AUC: 0.9161
ID Test Loss: 0.2754
OOD Validation ROC-AUC: 0.6464
OOD Validation Loss: 0.4730
OOD Test ROC-AUC: 0.7003
OOD Test Loss: 0.6570

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 6...
[0m[1;37mINFO[0m: [1mCheckpoint 6: 
-----------------------------------
Train ROC-AUC: 0.8590
Train Loss: 0.2838
ID Validation ROC-AUC: 0.8567
ID Validation Loss: 0.2868
ID Test ROC-AUC: 0.8583
ID Test Loss: 0.2889
OOD Validation ROC-AUC: 0.7021
OOD Validation Loss: 0.2707
OOD Test ROC-AUC: 0.7215
OOD Test Loss: 0.4387

[0m[1;37mINFO[0m: [1mChartInfo 0.9161 0.7003 0.8583 0.7215 0.8567 0.7021[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/29/2024 03:06:05 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/29/2024 03:06:10 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.704
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 790
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.631
SUFF++ for r=0.3 class 0.0 = 0.749 +- 0.211 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.3 class 1.0 = 0.702 +- 0.211 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.3 all KL = 0.788 +- 0.211 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.3 all L1 = 0.707 +- 0.144 (in-sample avg dev_std = 0.388)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.787
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.711
SUFF++ for r=0.6 class 0.0 = 0.818 +- 0.219 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.6 class 1.0 = 0.761 +- 0.219 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.6 all KL = 0.814 +- 0.219 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.6 all L1 = 0.768 +- 0.175 (in-sample avg dev_std = 0.355)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.79
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.784
SUFF++ for r=0.9 class 0.0 = 0.896 +- 0.100 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 class 1.0 = 0.89 +- 0.100 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 all KL = 0.937 +- 0.100 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 all L1 = 0.891 +- 0.117 (in-sample avg dev_std = 0.244)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.602
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 782
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.559
SUFF++ for r=0.3 class 0.0 = 0.755 +- 0.173 (in-sample avg dev_std = 0.352)
SUFF++ for r=0.3 class 1.0 = 0.731 +- 0.173 (in-sample avg dev_std = 0.352)
SUFF++ for r=0.3 all KL = 0.838 +- 0.173 (in-sample avg dev_std = 0.352)
SUFF++ for r=0.3 all L1 = 0.735 +- 0.132 (in-sample avg dev_std = 0.352)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.654
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.607
SUFF++ for r=0.6 class 0.0 = 0.81 +- 0.193 (in-sample avg dev_std = 0.314)
SUFF++ for r=0.6 class 1.0 = 0.774 +- 0.193 (in-sample avg dev_std = 0.314)
SUFF++ for r=0.6 all KL = 0.856 +- 0.193 (in-sample avg dev_std = 0.314)
SUFF++ for r=0.6 all L1 = 0.78 +- 0.168 (in-sample avg dev_std = 0.314)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.654
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.644
SUFF++ for r=0.9 class 0.0 = 0.889 +- 0.111 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 1.0 = 0.882 +- 0.111 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 all KL = 0.931 +- 0.111 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 all L1 = 0.883 +- 0.115 (in-sample avg dev_std = 0.260)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.696
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.684
NEC for r=0.3 class 0.0 = 0.18 +- 0.100 (in-sample avg dev_std = 0.205)
NEC for r=0.3 class 1.0 = 0.191 +- 0.100 (in-sample avg dev_std = 0.205)
NEC for r=0.3 all KL = 0.08 +- 0.100 (in-sample avg dev_std = 0.205)
NEC for r=0.3 all L1 = 0.19 +- 0.135 (in-sample avg dev_std = 0.205)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.787
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.779
NEC for r=0.6 class 0.0 = 0.144 +- 0.112 (in-sample avg dev_std = 0.215)
NEC for r=0.6 class 1.0 = 0.146 +- 0.112 (in-sample avg dev_std = 0.215)
NEC for r=0.6 all KL = 0.073 +- 0.112 (in-sample avg dev_std = 0.215)
NEC for r=0.6 all L1 = 0.146 +- 0.141 (in-sample avg dev_std = 0.215)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.79
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.781
NEC for r=0.9 class 0.0 = 0.12 +- 0.141 (in-sample avg dev_std = 0.245)
NEC for r=0.9 class 1.0 = 0.148 +- 0.141 (in-sample avg dev_std = 0.245)
NEC for r=0.9 all KL = 0.086 +- 0.141 (in-sample avg dev_std = 0.245)
NEC for r=0.9 all L1 = 0.145 +- 0.154 (in-sample avg dev_std = 0.245)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.797
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.791
NEC for r=1.0 class 0.0 = 0.117 +- 0.147 (in-sample avg dev_std = 0.249)
NEC for r=1.0 class 1.0 = 0.151 +- 0.147 (in-sample avg dev_std = 0.249)
NEC for r=1.0 all KL = 0.087 +- 0.147 (in-sample avg dev_std = 0.249)
NEC for r=1.0 all L1 = 0.148 +- 0.156 (in-sample avg dev_std = 0.249)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.605
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.62
NEC for r=0.3 class 0.0 = 0.154 +- 0.096 (in-sample avg dev_std = 0.195)
NEC for r=0.3 class 1.0 = 0.189 +- 0.096 (in-sample avg dev_std = 0.195)
NEC for r=0.3 all KL = 0.069 +- 0.096 (in-sample avg dev_std = 0.195)
NEC for r=0.3 all L1 = 0.183 +- 0.123 (in-sample avg dev_std = 0.195)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.654
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.652
NEC for r=0.6 class 0.0 = 0.136 +- 0.118 (in-sample avg dev_std = 0.211)
NEC for r=0.6 class 1.0 = 0.164 +- 0.118 (in-sample avg dev_std = 0.211)
NEC for r=0.6 all KL = 0.074 +- 0.118 (in-sample avg dev_std = 0.211)
NEC for r=0.6 all L1 = 0.159 +- 0.138 (in-sample avg dev_std = 0.211)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.654
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.646
NEC for r=0.9 class 0.0 = 0.14 +- 0.148 (in-sample avg dev_std = 0.246)
NEC for r=0.9 class 1.0 = 0.165 +- 0.148 (in-sample avg dev_std = 0.246)
NEC for r=0.9 all KL = 0.09 +- 0.148 (in-sample avg dev_std = 0.246)
NEC for r=0.9 all L1 = 0.161 +- 0.155 (in-sample avg dev_std = 0.246)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.647
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.644
NEC for r=1.0 class 0.0 = 0.133 +- 0.150 (in-sample avg dev_std = 0.247)
NEC for r=1.0 class 1.0 = 0.165 +- 0.150 (in-sample avg dev_std = 0.247)
NEC for r=1.0 all KL = 0.091 +- 0.150 (in-sample avg dev_std = 0.247)
NEC for r=1.0 all L1 = 0.16 +- 0.157 (in-sample avg dev_std = 0.247)
model_dirname= repr_GSATvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 15:08:57 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/29/2024 03:08:58 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/29/2024 03:09:28 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/29/2024 03:09:38 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/29/2024 03:09:49 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/29/2024 03:10:05 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/29/2024 03:10:20 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/29/2024 03:10:20 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 03:10:20 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:10:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:10:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:10:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:10:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:10:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:10:20 PM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 03:10:20 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:10:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:10:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:10:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:10:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:10:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:10:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:10:20 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:10:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:10:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:10:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:10:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:10:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:10:20 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 03:10:21 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 167...
[0m[1;37mINFO[0m: [1mCheckpoint 167: 
-----------------------------------
Train ROC-AUC: 0.9566
Train Loss: 0.1802
ID Validation ROC-AUC: 0.9171
ID Validation Loss: 0.2689
ID Test ROC-AUC: 0.9180
ID Test Loss: 0.2715
OOD Validation ROC-AUC: 0.6551
OOD Validation Loss: 0.4431
OOD Test ROC-AUC: 0.7114
OOD Test Loss: 0.6346

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 6...
[0m[1;37mINFO[0m: [1mCheckpoint 6: 
-----------------------------------
Train ROC-AUC: 0.8569
Train Loss: 0.3319
ID Validation ROC-AUC: 0.8575
ID Validation Loss: 0.3327
ID Test ROC-AUC: 0.8552
ID Test Loss: 0.3388
OOD Validation ROC-AUC: 0.6998
OOD Validation Loss: 0.2925
OOD Test ROC-AUC: 0.7252
OOD Test Loss: 0.5111

[0m[1;37mINFO[0m: [1mChartInfo 0.9180 0.7114 0.8552 0.7252 0.8575 0.6998[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/29/2024 03:10:21 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/29/2024 03:10:25 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.72
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 786
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.619
SUFF++ for r=0.3 class 0.0 = 0.743 +- 0.199 (in-sample avg dev_std = 0.359)
SUFF++ for r=0.3 class 1.0 = 0.714 +- 0.199 (in-sample avg dev_std = 0.359)
SUFF++ for r=0.3 all KL = 0.785 +- 0.199 (in-sample avg dev_std = 0.359)
SUFF++ for r=0.3 all L1 = 0.718 +- 0.117 (in-sample avg dev_std = 0.359)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.808
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.761
SUFF++ for r=0.6 class 0.0 = 0.761 +- 0.182 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.6 class 1.0 = 0.865 +- 0.182 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.6 all KL = 0.866 +- 0.182 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.6 all L1 = 0.853 +- 0.149 (in-sample avg dev_std = 0.248)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.8
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.776
SUFF++ for r=0.9 class 0.0 = 0.866 +- 0.072 (in-sample avg dev_std = 0.141)
SUFF++ for r=0.9 class 1.0 = 0.962 +- 0.072 (in-sample avg dev_std = 0.141)
SUFF++ for r=0.9 all KL = 0.973 +- 0.072 (in-sample avg dev_std = 0.141)
SUFF++ for r=0.9 all L1 = 0.95 +- 0.097 (in-sample avg dev_std = 0.141)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.675
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 786
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.62
SUFF++ for r=0.3 class 0.0 = 0.743 +- 0.185 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.3 class 1.0 = 0.71 +- 0.185 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.3 all KL = 0.818 +- 0.185 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.3 all L1 = 0.716 +- 0.117 (in-sample avg dev_std = 0.338)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.711
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.683
SUFF++ for r=0.6 class 0.0 = 0.735 +- 0.187 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.6 class 1.0 = 0.819 +- 0.187 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.6 all KL = 0.845 +- 0.187 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.6 all L1 = 0.805 +- 0.159 (in-sample avg dev_std = 0.280)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.697
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.676
SUFF++ for r=0.9 class 0.0 = 0.862 +- 0.099 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.9 class 1.0 = 0.934 +- 0.099 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.9 all KL = 0.956 +- 0.099 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.9 all L1 = 0.922 +- 0.123 (in-sample avg dev_std = 0.176)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.719
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.719
NEC for r=0.3 class 0.0 = 0.169 +- 0.105 (in-sample avg dev_std = 0.203)
NEC for r=0.3 class 1.0 = 0.181 +- 0.105 (in-sample avg dev_std = 0.203)
NEC for r=0.3 all KL = 0.08 +- 0.105 (in-sample avg dev_std = 0.203)
NEC for r=0.3 all L1 = 0.179 +- 0.128 (in-sample avg dev_std = 0.203)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.808
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.813
NEC for r=0.6 class 0.0 = 0.194 +- 0.116 (in-sample avg dev_std = 0.177)
NEC for r=0.6 class 1.0 = 0.086 +- 0.116 (in-sample avg dev_std = 0.177)
NEC for r=0.6 all KL = 0.058 +- 0.116 (in-sample avg dev_std = 0.177)
NEC for r=0.6 all L1 = 0.098 +- 0.134 (in-sample avg dev_std = 0.177)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.8
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.815
NEC for r=0.9 class 0.0 = 0.19 +- 0.124 (in-sample avg dev_std = 0.164)
NEC for r=0.9 class 1.0 = 0.062 +- 0.124 (in-sample avg dev_std = 0.164)
NEC for r=0.9 all KL = 0.055 +- 0.124 (in-sample avg dev_std = 0.164)
NEC for r=0.9 all L1 = 0.077 +- 0.129 (in-sample avg dev_std = 0.164)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.78
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.8
NEC for r=1.0 class 0.0 = 0.191 +- 0.131 (in-sample avg dev_std = 0.166)
NEC for r=1.0 class 1.0 = 0.059 +- 0.131 (in-sample avg dev_std = 0.166)
NEC for r=1.0 all KL = 0.055 +- 0.131 (in-sample avg dev_std = 0.166)
NEC for r=1.0 all L1 = 0.074 +- 0.128 (in-sample avg dev_std = 0.166)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.674
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.667
NEC for r=0.3 class 0.0 = 0.185 +- 0.113 (in-sample avg dev_std = 0.202)
NEC for r=0.3 class 1.0 = 0.197 +- 0.113 (in-sample avg dev_std = 0.202)
NEC for r=0.3 all KL = 0.081 +- 0.113 (in-sample avg dev_std = 0.202)
NEC for r=0.3 all L1 = 0.195 +- 0.129 (in-sample avg dev_std = 0.202)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.711
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.704
NEC for r=0.6 class 0.0 = 0.197 +- 0.129 (in-sample avg dev_std = 0.199)
NEC for r=0.6 class 1.0 = 0.127 +- 0.129 (in-sample avg dev_std = 0.199)
NEC for r=0.6 all KL = 0.079 +- 0.129 (in-sample avg dev_std = 0.199)
NEC for r=0.6 all L1 = 0.139 +- 0.146 (in-sample avg dev_std = 0.199)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.697
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.691
NEC for r=0.9 class 0.0 = 0.174 +- 0.168 (in-sample avg dev_std = 0.209)
NEC for r=0.9 class 1.0 = 0.109 +- 0.168 (in-sample avg dev_std = 0.209)
NEC for r=0.9 all KL = 0.088 +- 0.168 (in-sample avg dev_std = 0.209)
NEC for r=0.9 all L1 = 0.12 +- 0.155 (in-sample avg dev_std = 0.209)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.682
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.689
NEC for r=1.0 class 0.0 = 0.177 +- 0.169 (in-sample avg dev_std = 0.205)
NEC for r=1.0 class 1.0 = 0.107 +- 0.169 (in-sample avg dev_std = 0.205)
NEC for r=1.0 all KL = 0.092 +- 0.169 (in-sample avg dev_std = 0.205)
NEC for r=1.0 all L1 = 0.118 +- 0.161 (in-sample avg dev_std = 0.205)
model_dirname= repr_GSATvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 15:13:10 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/29/2024 03:13:11 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/29/2024 03:13:41 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/29/2024 03:13:51 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/29/2024 03:14:02 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/29/2024 03:14:18 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/29/2024 03:14:33 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/29/2024 03:14:33 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 03:14:33 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:14:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:14:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:14:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:14:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:14:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:14:33 PM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 03:14:33 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:14:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:14:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:14:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:14:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:14:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:14:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:14:33 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:14:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:14:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:14:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:14:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:14:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:14:33 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 03:14:33 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 166...
[0m[1;37mINFO[0m: [1mCheckpoint 166: 
-----------------------------------
Train ROC-AUC: 0.9551
Train Loss: 0.1708
ID Validation ROC-AUC: 0.9151
ID Validation Loss: 0.2417
ID Test ROC-AUC: 0.9172
ID Test Loss: 0.2422
OOD Validation ROC-AUC: 0.6470
OOD Validation Loss: 0.4100
OOD Test ROC-AUC: 0.7128
OOD Test Loss: 0.5516

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 1...
[0m[1;37mINFO[0m: [1mCheckpoint 1: 
-----------------------------------
Train ROC-AUC: 0.8336
Train Loss: 0.3183
ID Validation ROC-AUC: 0.8303
ID Validation Loss: 0.3208
ID Test ROC-AUC: 0.8340
ID Test Loss: 0.3235
OOD Validation ROC-AUC: 0.6952
OOD Validation Loss: 0.2706
OOD Test ROC-AUC: 0.7081
OOD Test Loss: 0.4476

[0m[1;37mINFO[0m: [1mChartInfo 0.9172 0.7128 0.8340 0.7081 0.8303 0.6952[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/29/2024 03:14:33 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/29/2024 03:14:37 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.777
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 788
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.656
SUFF++ for r=0.3 class 0.0 = 0.754 +- 0.251 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.3 class 1.0 = 0.675 +- 0.251 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.3 all KL = 0.72 +- 0.251 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.3 all L1 = 0.684 +- 0.136 (in-sample avg dev_std = 0.432)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.878
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.825
SUFF++ for r=0.6 class 0.0 = 0.783 +- 0.197 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.6 class 1.0 = 0.837 +- 0.197 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.6 all KL = 0.846 +- 0.197 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.6 all L1 = 0.83 +- 0.160 (in-sample avg dev_std = 0.294)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.871
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.868
SUFF++ for r=0.9 class 0.0 = 0.865 +- 0.107 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.9 class 1.0 = 0.927 +- 0.107 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.9 all KL = 0.953 +- 0.107 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.9 all L1 = 0.92 +- 0.132 (in-sample avg dev_std = 0.186)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.668
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 778
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.575
SUFF++ for r=0.3 class 0.0 = 0.75 +- 0.231 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.3 class 1.0 = 0.692 +- 0.231 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.3 all KL = 0.78 +- 0.231 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.3 all L1 = 0.701 +- 0.143 (in-sample avg dev_std = 0.397)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.697
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.668
SUFF++ for r=0.6 class 0.0 = 0.772 +- 0.203 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.6 class 1.0 = 0.791 +- 0.203 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.6 all KL = 0.834 +- 0.203 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.6 all L1 = 0.788 +- 0.169 (in-sample avg dev_std = 0.315)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.71
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.701
SUFF++ for r=0.9 class 0.0 = 0.846 +- 0.117 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 class 1.0 = 0.89 +- 0.117 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 all KL = 0.93 +- 0.117 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 all L1 = 0.883 +- 0.143 (in-sample avg dev_std = 0.240)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.777
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.772
NEC for r=0.3 class 0.0 = 0.169 +- 0.115 (in-sample avg dev_std = 0.205)
NEC for r=0.3 class 1.0 = 0.18 +- 0.115 (in-sample avg dev_std = 0.205)
NEC for r=0.3 all KL = 0.087 +- 0.115 (in-sample avg dev_std = 0.205)
NEC for r=0.3 all L1 = 0.178 +- 0.139 (in-sample avg dev_std = 0.205)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.878
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.865
NEC for r=0.6 class 0.0 = 0.153 +- 0.121 (in-sample avg dev_std = 0.187)
NEC for r=0.6 class 1.0 = 0.102 +- 0.121 (in-sample avg dev_std = 0.187)
NEC for r=0.6 all KL = 0.065 +- 0.121 (in-sample avg dev_std = 0.187)
NEC for r=0.6 all L1 = 0.108 +- 0.134 (in-sample avg dev_std = 0.187)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.871
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.86
NEC for r=0.9 class 0.0 = 0.166 +- 0.128 (in-sample avg dev_std = 0.197)
NEC for r=0.9 class 1.0 = 0.088 +- 0.128 (in-sample avg dev_std = 0.197)
NEC for r=0.9 all KL = 0.064 +- 0.128 (in-sample avg dev_std = 0.197)
NEC for r=0.9 all L1 = 0.097 +- 0.138 (in-sample avg dev_std = 0.197)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.861
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.853
NEC for r=1.0 class 0.0 = 0.17 +- 0.144 (in-sample avg dev_std = 0.208)
NEC for r=1.0 class 1.0 = 0.093 +- 0.144 (in-sample avg dev_std = 0.208)
NEC for r=1.0 all KL = 0.073 +- 0.144 (in-sample avg dev_std = 0.208)
NEC for r=1.0 all L1 = 0.102 +- 0.146 (in-sample avg dev_std = 0.208)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.661
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.657
NEC for r=0.3 class 0.0 = 0.166 +- 0.113 (in-sample avg dev_std = 0.203)
NEC for r=0.3 class 1.0 = 0.187 +- 0.113 (in-sample avg dev_std = 0.203)
NEC for r=0.3 all KL = 0.08 +- 0.113 (in-sample avg dev_std = 0.203)
NEC for r=0.3 all L1 = 0.183 +- 0.131 (in-sample avg dev_std = 0.203)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.697
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.69
NEC for r=0.6 class 0.0 = 0.165 +- 0.122 (in-sample avg dev_std = 0.202)
NEC for r=0.6 class 1.0 = 0.138 +- 0.122 (in-sample avg dev_std = 0.202)
NEC for r=0.6 all KL = 0.075 +- 0.122 (in-sample avg dev_std = 0.202)
NEC for r=0.6 all L1 = 0.142 +- 0.141 (in-sample avg dev_std = 0.202)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.71
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.706
NEC for r=0.9 class 0.0 = 0.163 +- 0.133 (in-sample avg dev_std = 0.217)
NEC for r=0.9 class 1.0 = 0.125 +- 0.133 (in-sample avg dev_std = 0.217)
NEC for r=0.9 all KL = 0.077 +- 0.133 (in-sample avg dev_std = 0.217)
NEC for r=0.9 all L1 = 0.131 +- 0.149 (in-sample avg dev_std = 0.217)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.71
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.703
NEC for r=1.0 class 0.0 = 0.174 +- 0.140 (in-sample avg dev_std = 0.229)
NEC for r=1.0 class 1.0 = 0.126 +- 0.140 (in-sample avg dev_std = 0.229)
NEC for r=1.0 all KL = 0.081 +- 0.140 (in-sample avg dev_std = 0.229)
NEC for r=1.0 all L1 = 0.134 +- 0.156 (in-sample avg dev_std = 0.229)
model_dirname= repr_GSATvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 15:17:24 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/29/2024 03:17:24 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/29/2024 03:17:54 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/29/2024 03:18:04 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/29/2024 03:18:15 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/29/2024 03:18:31 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/29/2024 03:18:46 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/29/2024 03:18:46 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 03:18:46 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:18:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:18:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:18:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:18:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:18:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:18:46 PM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 03:18:46 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:18:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:18:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:18:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:18:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:18:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:18:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:18:46 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:18:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:18:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:18:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:18:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:18:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:18:46 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 03:18:46 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 174...
[0m[1;37mINFO[0m: [1mCheckpoint 174: 
-----------------------------------
Train ROC-AUC: 0.9635
Train Loss: 0.1524
ID Validation ROC-AUC: 0.9206
ID Validation Loss: 0.2376
ID Test ROC-AUC: 0.9209
ID Test Loss: 0.2392
OOD Validation ROC-AUC: 0.6549
OOD Validation Loss: 0.4547
OOD Test ROC-AUC: 0.7098
OOD Test Loss: 0.5886

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 6...
[0m[1;37mINFO[0m: [1mCheckpoint 6: 
-----------------------------------
Train ROC-AUC: 0.8622
Train Loss: 0.3372
ID Validation ROC-AUC: 0.8620
ID Validation Loss: 0.3386
ID Test ROC-AUC: 0.8625
ID Test Loss: 0.3424
OOD Validation ROC-AUC: 0.7010
OOD Validation Loss: 0.2931
OOD Test ROC-AUC: 0.7238
OOD Test Loss: 0.5132

[0m[1;37mINFO[0m: [1mChartInfo 0.9209 0.7098 0.8625 0.7238 0.8620 0.7010[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/29/2024 03:18:46 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/29/2024 03:18:50 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.713
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 793
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.619
SUFF++ for r=0.3 class 0.0 = 0.74 +- 0.186 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.3 class 1.0 = 0.706 +- 0.186 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.3 all KL = 0.812 +- 0.186 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.3 all L1 = 0.71 +- 0.116 (in-sample avg dev_std = 0.346)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.811
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.762
SUFF++ for r=0.6 class 0.0 = 0.729 +- 0.161 (in-sample avg dev_std = 0.302)
SUFF++ for r=0.6 class 1.0 = 0.803 +- 0.161 (in-sample avg dev_std = 0.302)
SUFF++ for r=0.6 all KL = 0.851 +- 0.161 (in-sample avg dev_std = 0.302)
SUFF++ for r=0.6 all L1 = 0.794 +- 0.157 (in-sample avg dev_std = 0.302)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.803
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.801
SUFF++ for r=0.9 class 0.0 = 0.831 +- 0.118 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.9 class 1.0 = 0.884 +- 0.118 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.9 all KL = 0.929 +- 0.118 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.9 all L1 = 0.878 +- 0.146 (in-sample avg dev_std = 0.221)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.621
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 798
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.58
SUFF++ for r=0.3 class 0.0 = 0.747 +- 0.152 (in-sample avg dev_std = 0.309)
SUFF++ for r=0.3 class 1.0 = 0.724 +- 0.152 (in-sample avg dev_std = 0.309)
SUFF++ for r=0.3 all KL = 0.856 +- 0.152 (in-sample avg dev_std = 0.309)
SUFF++ for r=0.3 all L1 = 0.728 +- 0.115 (in-sample avg dev_std = 0.309)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.669
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.635
SUFF++ for r=0.6 class 0.0 = 0.716 +- 0.142 (in-sample avg dev_std = 0.325)
SUFF++ for r=0.6 class 1.0 = 0.747 +- 0.142 (in-sample avg dev_std = 0.325)
SUFF++ for r=0.6 all KL = 0.842 +- 0.142 (in-sample avg dev_std = 0.325)
SUFF++ for r=0.6 all L1 = 0.742 +- 0.149 (in-sample avg dev_std = 0.325)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.672
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.678
SUFF++ for r=0.9 class 0.0 = 0.808 +- 0.131 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.9 class 1.0 = 0.834 +- 0.131 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.9 all KL = 0.904 +- 0.131 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.9 all L1 = 0.83 +- 0.156 (in-sample avg dev_std = 0.262)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.711
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.672
NEC for r=0.3 class 0.0 = 0.181 +- 0.103 (in-sample avg dev_std = 0.200)
NEC for r=0.3 class 1.0 = 0.195 +- 0.103 (in-sample avg dev_std = 0.200)
NEC for r=0.3 all KL = 0.079 +- 0.103 (in-sample avg dev_std = 0.200)
NEC for r=0.3 all L1 = 0.194 +- 0.121 (in-sample avg dev_std = 0.200)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.811
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.807
NEC for r=0.6 class 0.0 = 0.192 +- 0.105 (in-sample avg dev_std = 0.198)
NEC for r=0.6 class 1.0 = 0.137 +- 0.105 (in-sample avg dev_std = 0.198)
NEC for r=0.6 all KL = 0.074 +- 0.105 (in-sample avg dev_std = 0.198)
NEC for r=0.6 all L1 = 0.144 +- 0.133 (in-sample avg dev_std = 0.198)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.803
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.809
NEC for r=0.9 class 0.0 = 0.189 +- 0.133 (in-sample avg dev_std = 0.228)
NEC for r=0.9 class 1.0 = 0.128 +- 0.133 (in-sample avg dev_std = 0.228)
NEC for r=0.9 all KL = 0.08 +- 0.133 (in-sample avg dev_std = 0.228)
NEC for r=0.9 all L1 = 0.135 +- 0.153 (in-sample avg dev_std = 0.228)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.811
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.805
NEC for r=1.0 class 0.0 = 0.182 +- 0.130 (in-sample avg dev_std = 0.227)
NEC for r=1.0 class 1.0 = 0.116 +- 0.130 (in-sample avg dev_std = 0.227)
NEC for r=1.0 all KL = 0.073 +- 0.130 (in-sample avg dev_std = 0.227)
NEC for r=1.0 all L1 = 0.123 +- 0.152 (in-sample avg dev_std = 0.227)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.62
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.613
NEC for r=0.3 class 0.0 = 0.177 +- 0.102 (in-sample avg dev_std = 0.196)
NEC for r=0.3 class 1.0 = 0.202 +- 0.102 (in-sample avg dev_std = 0.196)
NEC for r=0.3 all KL = 0.074 +- 0.102 (in-sample avg dev_std = 0.196)
NEC for r=0.3 all L1 = 0.198 +- 0.122 (in-sample avg dev_std = 0.196)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.669
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.663
NEC for r=0.6 class 0.0 = 0.199 +- 0.109 (in-sample avg dev_std = 0.228)
NEC for r=0.6 class 1.0 = 0.188 +- 0.109 (in-sample avg dev_std = 0.228)
NEC for r=0.6 all KL = 0.088 +- 0.109 (in-sample avg dev_std = 0.228)
NEC for r=0.6 all L1 = 0.19 +- 0.139 (in-sample avg dev_std = 0.228)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.672
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.667
NEC for r=0.9 class 0.0 = 0.213 +- 0.147 (in-sample avg dev_std = 0.268)
NEC for r=0.9 class 1.0 = 0.181 +- 0.147 (in-sample avg dev_std = 0.268)
NEC for r=0.9 all KL = 0.106 +- 0.147 (in-sample avg dev_std = 0.268)
NEC for r=0.9 all L1 = 0.186 +- 0.162 (in-sample avg dev_std = 0.268)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.669
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.662
NEC for r=1.0 class 0.0 = 0.211 +- 0.143 (in-sample avg dev_std = 0.262)
NEC for r=1.0 class 1.0 = 0.161 +- 0.143 (in-sample avg dev_std = 0.262)
NEC for r=1.0 all KL = 0.095 +- 0.143 (in-sample avg dev_std = 0.262)
NEC for r=1.0 all L1 = 0.169 +- 0.158 (in-sample avg dev_std = 0.262)
model_dirname= repr_GSATvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 15:21:41 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/29/2024 03:21:41 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/29/2024 03:22:12 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/29/2024 03:22:22 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/29/2024 03:22:33 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/29/2024 03:22:48 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/29/2024 03:23:03 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/29/2024 03:23:03 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 03:23:03 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:23:03 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:23:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:23:03 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:23:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:23:03 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:23:03 PM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 03:23:03 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:23:03 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:23:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:23:03 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:23:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:23:03 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:23:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:23:03 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:23:03 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:23:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:23:03 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:23:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:23:03 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:23:03 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 03:23:03 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 164...
[0m[1;37mINFO[0m: [1mCheckpoint 164: 
-----------------------------------
Train ROC-AUC: 0.9498
Train Loss: 0.1899
ID Validation ROC-AUC: 0.9123
ID Validation Loss: 0.2808
ID Test ROC-AUC: 0.9116
ID Test Loss: 0.2822
OOD Validation ROC-AUC: 0.6522
OOD Validation Loss: 0.4741
OOD Test ROC-AUC: 0.7124
OOD Test Loss: 0.6518

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 5...
[0m[1;37mINFO[0m: [1mCheckpoint 5: 
-----------------------------------
Train ROC-AUC: 0.8515
Train Loss: 0.2964
ID Validation ROC-AUC: 0.8481
ID Validation Loss: 0.2995
ID Test ROC-AUC: 0.8531
ID Test Loss: 0.3007
OOD Validation ROC-AUC: 0.6981
OOD Validation Loss: 0.2812
OOD Test ROC-AUC: 0.7146
OOD Test Loss: 0.4668

[0m[1;37mINFO[0m: [1mChartInfo 0.9116 0.7124 0.8531 0.7146 0.8481 0.6981[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/29/2024 03:23:03 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/29/2024 03:23:07 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.761
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 782
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.674
SUFF++ for r=0.3 class 0.0 = 0.773 +- 0.211 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.3 class 1.0 = 0.705 +- 0.211 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.3 all KL = 0.776 +- 0.211 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.3 all L1 = 0.712 +- 0.127 (in-sample avg dev_std = 0.366)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.838
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.774
SUFF++ for r=0.6 class 0.0 = 0.775 +- 0.215 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.6 class 1.0 = 0.823 +- 0.215 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.6 all KL = 0.825 +- 0.215 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.6 all L1 = 0.818 +- 0.167 (in-sample avg dev_std = 0.296)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.853
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.845
SUFF++ for r=0.9 class 0.0 = 0.878 +- 0.062 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.9 class 1.0 = 0.956 +- 0.062 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.9 all KL = 0.975 +- 0.062 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.9 all L1 = 0.947 +- 0.089 (in-sample avg dev_std = 0.145)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.645
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 790
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.573
SUFF++ for r=0.3 class 0.0 = 0.761 +- 0.192 (in-sample avg dev_std = 0.344)
SUFF++ for r=0.3 class 1.0 = 0.717 +- 0.192 (in-sample avg dev_std = 0.344)
SUFF++ for r=0.3 all KL = 0.821 +- 0.192 (in-sample avg dev_std = 0.344)
SUFF++ for r=0.3 all L1 = 0.724 +- 0.130 (in-sample avg dev_std = 0.344)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.695
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.645
SUFF++ for r=0.6 class 0.0 = 0.772 +- 0.200 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.6 class 1.0 = 0.779 +- 0.200 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.6 all KL = 0.83 +- 0.200 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.6 all L1 = 0.777 +- 0.162 (in-sample avg dev_std = 0.311)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.692
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.677
SUFF++ for r=0.9 class 0.0 = 0.878 +- 0.090 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.9 class 1.0 = 0.919 +- 0.090 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.9 all KL = 0.956 +- 0.090 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.9 all L1 = 0.912 +- 0.115 (in-sample avg dev_std = 0.182)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.761
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.765
NEC for r=0.3 class 0.0 = 0.174 +- 0.098 (in-sample avg dev_std = 0.191)
NEC for r=0.3 class 1.0 = 0.17 +- 0.098 (in-sample avg dev_std = 0.191)
NEC for r=0.3 all KL = 0.071 +- 0.098 (in-sample avg dev_std = 0.191)
NEC for r=0.3 all L1 = 0.171 +- 0.131 (in-sample avg dev_std = 0.191)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.838
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.832
NEC for r=0.6 class 0.0 = 0.173 +- 0.110 (in-sample avg dev_std = 0.174)
NEC for r=0.6 class 1.0 = 0.091 +- 0.110 (in-sample avg dev_std = 0.174)
NEC for r=0.6 all KL = 0.054 +- 0.110 (in-sample avg dev_std = 0.174)
NEC for r=0.6 all L1 = 0.101 +- 0.135 (in-sample avg dev_std = 0.174)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.853
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.846
NEC for r=0.9 class 0.0 = 0.172 +- 0.121 (in-sample avg dev_std = 0.175)
NEC for r=0.9 class 1.0 = 0.071 +- 0.121 (in-sample avg dev_std = 0.175)
NEC for r=0.9 all KL = 0.05 +- 0.121 (in-sample avg dev_std = 0.175)
NEC for r=0.9 all L1 = 0.083 +- 0.128 (in-sample avg dev_std = 0.175)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.852
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.847
NEC for r=1.0 class 0.0 = 0.162 +- 0.114 (in-sample avg dev_std = 0.175)
NEC for r=1.0 class 1.0 = 0.067 +- 0.114 (in-sample avg dev_std = 0.175)
NEC for r=1.0 all KL = 0.048 +- 0.114 (in-sample avg dev_std = 0.175)
NEC for r=1.0 all L1 = 0.078 +- 0.121 (in-sample avg dev_std = 0.175)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.642
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.634
NEC for r=0.3 class 0.0 = 0.172 +- 0.094 (in-sample avg dev_std = 0.175)
NEC for r=0.3 class 1.0 = 0.172 +- 0.094 (in-sample avg dev_std = 0.175)
NEC for r=0.3 all KL = 0.063 +- 0.094 (in-sample avg dev_std = 0.175)
NEC for r=0.3 all L1 = 0.172 +- 0.128 (in-sample avg dev_std = 0.175)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.695
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.674
NEC for r=0.6 class 0.0 = 0.181 +- 0.132 (in-sample avg dev_std = 0.213)
NEC for r=0.6 class 1.0 = 0.141 +- 0.132 (in-sample avg dev_std = 0.213)
NEC for r=0.6 all KL = 0.075 +- 0.132 (in-sample avg dev_std = 0.213)
NEC for r=0.6 all L1 = 0.148 +- 0.151 (in-sample avg dev_std = 0.213)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.692
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.675
NEC for r=0.9 class 0.0 = 0.158 +- 0.135 (in-sample avg dev_std = 0.209)
NEC for r=0.9 class 1.0 = 0.116 +- 0.135 (in-sample avg dev_std = 0.209)
NEC for r=0.9 all KL = 0.069 +- 0.135 (in-sample avg dev_std = 0.209)
NEC for r=0.9 all L1 = 0.123 +- 0.148 (in-sample avg dev_std = 0.209)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.696
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.674
NEC for r=1.0 class 0.0 = 0.155 +- 0.128 (in-sample avg dev_std = 0.214)
NEC for r=1.0 class 1.0 = 0.112 +- 0.128 (in-sample avg dev_std = 0.214)
NEC for r=1.0 all KL = 0.069 +- 0.128 (in-sample avg dev_std = 0.214)
NEC for r=1.0 all L1 = 0.119 +- 0.142 (in-sample avg dev_std = 0.214)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.788, 0.814, 0.937, 1.0], 'all_L1': [0.707, 0.768, 0.891, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.785, 0.866, 0.973, 1.0], 'all_L1': [0.718, 0.853, 0.95, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.72, 0.846, 0.953, 1.0], 'all_L1': [0.684, 0.83, 0.92, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.812, 0.851, 0.929, 1.0], 'all_L1': [0.71, 0.794, 0.878, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.776, 0.825, 0.975, 1.0], 'all_L1': [0.712, 0.818, 0.947, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.08, 0.073, 0.086, 0.087], 'all_L1': [0.19, 0.146, 0.145, 0.148]}), defaultdict(<class 'list'>, {'all_KL': [0.08, 0.058, 0.055, 0.055], 'all_L1': [0.179, 0.098, 0.077, 0.074]}), defaultdict(<class 'list'>, {'all_KL': [0.087, 0.065, 0.064, 0.073], 'all_L1': [0.178, 0.108, 0.097, 0.102]}), defaultdict(<class 'list'>, {'all_KL': [0.079, 0.074, 0.08, 0.073], 'all_L1': [0.194, 0.144, 0.135, 0.123]}), defaultdict(<class 'list'>, {'all_KL': [0.071, 0.054, 0.05, 0.048], 'all_L1': [0.171, 0.101, 0.083, 0.078]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.838, 0.856, 0.931, 1.0], 'all_L1': [0.735, 0.78, 0.883, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.818, 0.845, 0.956, 1.0], 'all_L1': [0.716, 0.805, 0.922, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.78, 0.834, 0.93, 1.0], 'all_L1': [0.701, 0.788, 0.883, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.856, 0.842, 0.904, 1.0], 'all_L1': [0.728, 0.742, 0.83, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.821, 0.83, 0.956, 1.0], 'all_L1': [0.724, 0.777, 0.912, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.069, 0.074, 0.09, 0.091], 'all_L1': [0.183, 0.159, 0.161, 0.16]}), defaultdict(<class 'list'>, {'all_KL': [0.081, 0.079, 0.088, 0.092], 'all_L1': [0.195, 0.139, 0.12, 0.118]}), defaultdict(<class 'list'>, {'all_KL': [0.08, 0.075, 0.077, 0.081], 'all_L1': [0.183, 0.142, 0.131, 0.134]}), defaultdict(<class 'list'>, {'all_KL': [0.074, 0.088, 0.106, 0.095], 'all_L1': [0.198, 0.19, 0.186, 0.169]}), defaultdict(<class 'list'>, {'all_KL': [0.063, 0.075, 0.069, 0.069], 'all_L1': [0.172, 0.148, 0.123, 0.119]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.706 +- 0.012, 0.813 +- 0.029, 0.917 +- 0.029, 1.000 +- 0.000
suff++ class all_KL  =  0.776 +- 0.031, 0.840 +- 0.019, 0.953 +- 0.019, 1.000 +- 0.000
suff++_acc_int  =  0.640 +- 0.022, 0.767 +- 0.037, 0.815 +- 0.036
nec class all_L1  =  0.182 +- 0.008, 0.119 +- 0.021, 0.107 +- 0.028, 0.105 +- 0.028
nec class all_KL  =  0.079 +- 0.005, 0.065 +- 0.008, 0.067 +- 0.014, 0.067 +- 0.014
nec_acc_int  =  0.722 +- 0.040, 0.819 +- 0.029, 0.822 +- 0.028, 0.819 +- 0.026

Eval split test
suff++ class all_L1  =  0.721 +- 0.012, 0.778 +- 0.021, 0.886 +- 0.032, 1.000 +- 0.000
suff++ class all_KL  =  0.823 +- 0.025, 0.841 +- 0.009, 0.935 +- 0.019, 1.000 +- 0.000
suff++_acc_int  =  0.582 +- 0.021, 0.648 +- 0.026, 0.675 +- 0.018
nec class all_L1  =  0.186 +- 0.009, 0.156 +- 0.019, 0.144 +- 0.025, 0.140 +- 0.021
nec class all_KL  =  0.073 +- 0.007, 0.078 +- 0.005, 0.086 +- 0.013, 0.086 +- 0.010
nec_acc_int  =  0.638 +- 0.021, 0.677 +- 0.019, 0.677 +- 0.020, 0.674 +- 0.020


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.444 +- 0.007, 0.466 +- 0.007, 0.512 +- 0.004, 0.553 +- 0.014
Faith. Armon (L1)= 		  =  0.290 +- 0.011, 0.207 +- 0.031, 0.191 +- 0.043, 0.189 +- 0.045
Faith. GMean (L1)= 	  =  0.359 +- 0.009, 0.310 +- 0.022, 0.311 +- 0.035, 0.321 +- 0.043
Faith. Aritm (KL)= 		  =  0.428 +- 0.014, 0.453 +- 0.009, 0.510 +- 0.003, 0.534 +- 0.007
Faith. Armon (KL)= 		  =  0.144 +- 0.008, 0.120 +- 0.014, 0.125 +- 0.024, 0.126 +- 0.025
Faith. GMean (KL)= 	  =  0.248 +- 0.007, 0.233 +- 0.014, 0.251 +- 0.024, 0.258 +- 0.027

Eval split test
Faith. Aritm (L1)= 		  =  0.453 +- 0.008, 0.467 +- 0.003, 0.515 +- 0.006, 0.570 +- 0.010
Faith. Armon (L1)= 		  =  0.296 +- 0.012, 0.259 +- 0.024, 0.247 +- 0.036, 0.245 +- 0.032
Faith. GMean (L1)= 	  =  0.366 +- 0.010, 0.347 +- 0.016, 0.356 +- 0.025, 0.373 +- 0.028
Faith. Aritm (KL)= 		  =  0.448 +- 0.012, 0.460 +- 0.005, 0.511 +- 0.007, 0.543 +- 0.005
Faith. Armon (KL)= 		  =  0.135 +- 0.011, 0.143 +- 0.009, 0.157 +- 0.021, 0.158 +- 0.016
Faith. GMean (KL)= 	  =  0.245 +- 0.010, 0.256 +- 0.009, 0.283 +- 0.019, 0.292 +- 0.017
Computed for split load_split = id



Completed in  0:21:15.339977  for GSATvGIN LBAPcore/assay



DONE GSAT LBAPcore/assay
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 15:26:07 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 03:26:08 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 160...
[0m[1;37mINFO[0m: [1mCheckpoint 160: 
-----------------------------------
Train ACCURACY: 0.9865
Train Loss: 0.0496
ID Validation ACCURACY: 0.9023
ID Validation Loss: 0.3348
ID Test ACCURACY: 0.8950
ID Test Loss: 0.3490
OOD Validation ACCURACY: 0.8601
OOD Validation Loss: 0.5178
OOD Test ACCURACY: 0.5090
OOD Test Loss: 2.2948

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 152...
[0m[1;37mINFO[0m: [1mCheckpoint 152: 
-----------------------------------
Train ACCURACY: 0.9802
Train Loss: 0.0672
ID Validation ACCURACY: 0.8973
ID Validation Loss: 0.3395
ID Test ACCURACY: 0.8970
ID Test Loss: 0.3382
OOD Validation ACCURACY: 0.8766
OOD Validation Loss: 0.4130
OOD Test ACCURACY: 0.7004
OOD Test Loss: 1.1259

[0m[1;37mINFO[0m: [1mChartInfo 0.8950 0.5090 0.8970 0.7004 0.8973 0.8766[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.11
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.105
SUFF++ for r=0.3 class 0 = 0.636 +- 0.153 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.3 class 1 = 0.594 +- 0.153 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.3 class 2 = 0.629 +- 0.153 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.3 class 3 = 0.641 +- 0.153 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.3 class 4 = 0.639 +- 0.153 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.3 class 5 = 0.606 +- 0.153 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.3 class 6 = 0.634 +- 0.153 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.3 class 7 = 0.618 +- 0.153 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.3 class 8 = 0.615 +- 0.153 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.3 class 9 = 0.64 +- 0.153 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.3 all KL = 0.785 +- 0.153 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.3 all L1 = 0.625 +- 0.112 (in-sample avg dev_std = 0.266)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.32
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.237
SUFF++ for r=0.6 class 0 = 0.402 +- 0.211 (in-sample avg dev_std = 0.314)
SUFF++ for r=0.6 class 1 = 0.573 +- 0.211 (in-sample avg dev_std = 0.314)
SUFF++ for r=0.6 class 2 = 0.444 +- 0.211 (in-sample avg dev_std = 0.314)
SUFF++ for r=0.6 class 3 = 0.47 +- 0.211 (in-sample avg dev_std = 0.314)
SUFF++ for r=0.6 class 4 = 0.489 +- 0.211 (in-sample avg dev_std = 0.314)
SUFF++ for r=0.6 class 5 = 0.465 +- 0.211 (in-sample avg dev_std = 0.314)
SUFF++ for r=0.6 class 6 = 0.46 +- 0.211 (in-sample avg dev_std = 0.314)
SUFF++ for r=0.6 class 7 = 0.449 +- 0.211 (in-sample avg dev_std = 0.314)
SUFF++ for r=0.6 class 8 = 0.486 +- 0.211 (in-sample avg dev_std = 0.314)
SUFF++ for r=0.6 class 9 = 0.467 +- 0.211 (in-sample avg dev_std = 0.314)
SUFF++ for r=0.6 all KL = 0.527 +- 0.211 (in-sample avg dev_std = 0.314)
SUFF++ for r=0.6 all L1 = 0.472 +- 0.131 (in-sample avg dev_std = 0.314)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.817
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.786
SUFF++ for r=0.9 class 0 = 0.962 +- 0.201 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.9 class 1 = 0.979 +- 0.201 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.9 class 2 = 0.781 +- 0.201 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.9 class 3 = 0.79 +- 0.201 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.9 class 4 = 0.855 +- 0.201 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.9 class 5 = 0.778 +- 0.201 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.9 class 6 = 0.787 +- 0.201 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.9 class 7 = 0.778 +- 0.201 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.9 class 8 = 0.845 +- 0.201 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.9 class 9 = 0.773 +- 0.201 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.9 all KL = 0.864 +- 0.201 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.9 all L1 = 0.835 +- 0.188 (in-sample avg dev_std = 0.228)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.132
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.112
SUFF++ for r=0.3 class 0 = 0.59 +- 0.153 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.3 class 1 = 0.536 +- 0.153 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.3 class 2 = 0.596 +- 0.153 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.3 class 3 = 0.595 +- 0.153 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.3 class 4 = 0.6 +- 0.153 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.3 class 5 = 0.606 +- 0.153 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.3 class 6 = 0.606 +- 0.153 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.3 class 7 = 0.581 +- 0.153 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.3 class 8 = 0.592 +- 0.153 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.3 class 9 = 0.581 +- 0.153 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.3 all KL = 0.754 +- 0.153 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.3 all L1 = 0.588 +- 0.103 (in-sample avg dev_std = 0.296)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.24
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.191
SUFF++ for r=0.6 class 0 = 0.466 +- 0.195 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.6 class 1 = 0.539 +- 0.195 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.6 class 2 = 0.483 +- 0.195 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.6 class 3 = 0.498 +- 0.195 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.6 class 4 = 0.465 +- 0.195 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.6 class 5 = 0.471 +- 0.195 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.6 class 6 = 0.448 +- 0.195 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.6 class 7 = 0.507 +- 0.195 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.6 class 8 = 0.481 +- 0.195 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.6 class 9 = 0.47 +- 0.195 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.6 all KL = 0.543 +- 0.195 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.6 all L1 = 0.484 +- 0.125 (in-sample avg dev_std = 0.297)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.451
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.433
SUFF++ for r=0.9 class 0 = 0.721 +- 0.188 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 class 1 = 0.736 +- 0.188 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 class 2 = 0.699 +- 0.188 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 class 3 = 0.706 +- 0.188 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 class 4 = 0.734 +- 0.188 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 class 5 = 0.716 +- 0.188 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 class 6 = 0.725 +- 0.188 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 class 7 = 0.725 +- 0.188 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 class 8 = 0.673 +- 0.188 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 class 9 = 0.721 +- 0.188 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 all KL = 0.791 +- 0.188 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 all L1 = 0.716 +- 0.173 (in-sample avg dev_std = 0.300)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.11
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.106
NEC for r=0.3 class 0 = 0.308 +- 0.126 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 1 = 0.305 +- 0.126 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 2 = 0.32 +- 0.126 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 3 = 0.306 +- 0.126 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 4 = 0.303 +- 0.126 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 5 = 0.325 +- 0.126 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 6 = 0.31 +- 0.126 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 7 = 0.297 +- 0.126 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 8 = 0.334 +- 0.126 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 9 = 0.308 +- 0.126 (in-sample avg dev_std = 0.145)
NEC for r=0.3 all KL = 0.139 +- 0.126 (in-sample avg dev_std = 0.145)
NEC for r=0.3 all L1 = 0.311 +- 0.116 (in-sample avg dev_std = 0.145)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.32
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.271
NEC for r=0.6 class 0 = 0.424 +- 0.201 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 1 = 0.239 +- 0.201 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 2 = 0.421 +- 0.201 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 3 = 0.439 +- 0.201 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 4 = 0.401 +- 0.201 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 5 = 0.416 +- 0.201 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 6 = 0.467 +- 0.201 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 7 = 0.459 +- 0.201 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 8 = 0.416 +- 0.201 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 9 = 0.438 +- 0.201 (in-sample avg dev_std = 0.237)
NEC for r=0.6 all KL = 0.299 +- 0.201 (in-sample avg dev_std = 0.237)
NEC for r=0.6 all L1 = 0.41 +- 0.147 (in-sample avg dev_std = 0.237)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.817
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.676
NEC for r=0.9 class 0 = 0.16 +- 0.304 (in-sample avg dev_std = 0.387)
NEC for r=0.9 class 1 = 0.05 +- 0.304 (in-sample avg dev_std = 0.387)
NEC for r=0.9 class 2 = 0.429 +- 0.304 (in-sample avg dev_std = 0.387)
NEC for r=0.9 class 3 = 0.469 +- 0.304 (in-sample avg dev_std = 0.387)
NEC for r=0.9 class 4 = 0.327 +- 0.304 (in-sample avg dev_std = 0.387)
NEC for r=0.9 class 5 = 0.456 +- 0.304 (in-sample avg dev_std = 0.387)
NEC for r=0.9 class 6 = 0.431 +- 0.304 (in-sample avg dev_std = 0.387)
NEC for r=0.9 class 7 = 0.43 +- 0.304 (in-sample avg dev_std = 0.387)
NEC for r=0.9 class 8 = 0.388 +- 0.304 (in-sample avg dev_std = 0.387)
NEC for r=0.9 class 9 = 0.457 +- 0.304 (in-sample avg dev_std = 0.387)
NEC for r=0.9 all KL = 0.454 +- 0.304 (in-sample avg dev_std = 0.387)
NEC for r=0.9 all L1 = 0.355 +- 0.246 (in-sample avg dev_std = 0.387)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.957
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.853
NEC for r=1.0 class 0 = 0.063 +- 0.302 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 1 = 0.013 +- 0.302 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 2 = 0.288 +- 0.302 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 3 = 0.288 +- 0.302 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 4 = 0.172 +- 0.302 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 5 = 0.304 +- 0.302 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 6 = 0.308 +- 0.302 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 7 = 0.211 +- 0.302 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 8 = 0.23 +- 0.302 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 9 = 0.336 +- 0.302 (in-sample avg dev_std = 0.345)
NEC for r=1.0 all KL = 0.316 +- 0.302 (in-sample avg dev_std = 0.345)
NEC for r=1.0 all L1 = 0.217 +- 0.228 (in-sample avg dev_std = 0.345)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.132
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.119
NEC for r=0.3 class 0 = 0.321 +- 0.108 (in-sample avg dev_std = 0.153)
NEC for r=0.3 class 1 = 0.336 +- 0.108 (in-sample avg dev_std = 0.153)
NEC for r=0.3 class 2 = 0.322 +- 0.108 (in-sample avg dev_std = 0.153)
NEC for r=0.3 class 3 = 0.334 +- 0.108 (in-sample avg dev_std = 0.153)
NEC for r=0.3 class 4 = 0.319 +- 0.108 (in-sample avg dev_std = 0.153)
NEC for r=0.3 class 5 = 0.308 +- 0.108 (in-sample avg dev_std = 0.153)
NEC for r=0.3 class 6 = 0.331 +- 0.108 (in-sample avg dev_std = 0.153)
NEC for r=0.3 class 7 = 0.335 +- 0.108 (in-sample avg dev_std = 0.153)
NEC for r=0.3 class 8 = 0.329 +- 0.108 (in-sample avg dev_std = 0.153)
NEC for r=0.3 class 9 = 0.337 +- 0.108 (in-sample avg dev_std = 0.153)
NEC for r=0.3 all KL = 0.143 +- 0.108 (in-sample avg dev_std = 0.153)
NEC for r=0.3 all L1 = 0.327 +- 0.101 (in-sample avg dev_std = 0.153)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.24
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.221
NEC for r=0.6 class 0 = 0.393 +- 0.204 (in-sample avg dev_std = 0.217)
NEC for r=0.6 class 1 = 0.304 +- 0.204 (in-sample avg dev_std = 0.217)
NEC for r=0.6 class 2 = 0.427 +- 0.204 (in-sample avg dev_std = 0.217)
NEC for r=0.6 class 3 = 0.393 +- 0.204 (in-sample avg dev_std = 0.217)
NEC for r=0.6 class 4 = 0.463 +- 0.204 (in-sample avg dev_std = 0.217)
NEC for r=0.6 class 5 = 0.407 +- 0.204 (in-sample avg dev_std = 0.217)
NEC for r=0.6 class 6 = 0.435 +- 0.204 (in-sample avg dev_std = 0.217)
NEC for r=0.6 class 7 = 0.406 +- 0.204 (in-sample avg dev_std = 0.217)
NEC for r=0.6 class 8 = 0.407 +- 0.204 (in-sample avg dev_std = 0.217)
NEC for r=0.6 class 9 = 0.457 +- 0.204 (in-sample avg dev_std = 0.217)
NEC for r=0.6 all KL = 0.288 +- 0.204 (in-sample avg dev_std = 0.217)
NEC for r=0.6 all L1 = 0.408 +- 0.156 (in-sample avg dev_std = 0.217)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.451
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.361
NEC for r=0.9 class 0 = 0.515 +- 0.246 (in-sample avg dev_std = 0.359)
NEC for r=0.9 class 1 = 0.447 +- 0.246 (in-sample avg dev_std = 0.359)
NEC for r=0.9 class 2 = 0.475 +- 0.246 (in-sample avg dev_std = 0.359)
NEC for r=0.9 class 3 = 0.506 +- 0.246 (in-sample avg dev_std = 0.359)
NEC for r=0.9 class 4 = 0.417 +- 0.246 (in-sample avg dev_std = 0.359)
NEC for r=0.9 class 5 = 0.48 +- 0.246 (in-sample avg dev_std = 0.359)
NEC for r=0.9 class 6 = 0.543 +- 0.246 (in-sample avg dev_std = 0.359)
NEC for r=0.9 class 7 = 0.399 +- 0.246 (in-sample avg dev_std = 0.359)
NEC for r=0.9 class 8 = 0.556 +- 0.246 (in-sample avg dev_std = 0.359)
NEC for r=0.9 class 9 = 0.489 +- 0.246 (in-sample avg dev_std = 0.359)
NEC for r=0.9 all KL = 0.491 +- 0.246 (in-sample avg dev_std = 0.359)
NEC for r=0.9 all L1 = 0.482 +- 0.194 (in-sample avg dev_std = 0.359)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.504
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.45
NEC for r=1.0 class 0 = 0.501 +- 0.254 (in-sample avg dev_std = 0.357)
NEC for r=1.0 class 1 = 0.309 +- 0.254 (in-sample avg dev_std = 0.357)
NEC for r=1.0 class 2 = 0.424 +- 0.254 (in-sample avg dev_std = 0.357)
NEC for r=1.0 class 3 = 0.416 +- 0.254 (in-sample avg dev_std = 0.357)
NEC for r=1.0 class 4 = 0.352 +- 0.254 (in-sample avg dev_std = 0.357)
NEC for r=1.0 class 5 = 0.372 +- 0.254 (in-sample avg dev_std = 0.357)
NEC for r=1.0 class 6 = 0.508 +- 0.254 (in-sample avg dev_std = 0.357)
NEC for r=1.0 class 7 = 0.385 +- 0.254 (in-sample avg dev_std = 0.357)
NEC for r=1.0 class 8 = 0.497 +- 0.254 (in-sample avg dev_std = 0.357)
NEC for r=1.0 class 9 = 0.452 +- 0.254 (in-sample avg dev_std = 0.357)
NEC for r=1.0 all KL = 0.439 +- 0.254 (in-sample avg dev_std = 0.357)
NEC for r=1.0 all L1 = 0.421 +- 0.215 (in-sample avg dev_std = 0.357)
model_dirname= repr_LECIvGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 15:38:45 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:46 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:38:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:47 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 03:38:47 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:38:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:47 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:38:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:47 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 03:38:47 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 170...
[0m[1;37mINFO[0m: [1mCheckpoint 170: 
-----------------------------------
Train ACCURACY: 0.9906
Train Loss: 0.0371
ID Validation ACCURACY: 0.9056
ID Validation Loss: 0.3352
ID Test ACCURACY: 0.9003
ID Test Loss: 0.3439
OOD Validation ACCURACY: 0.8774
OOD Validation Loss: 0.4662
OOD Test ACCURACY: 0.3624
OOD Test Loss: 5.2321

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 98...
[0m[1;37mINFO[0m: [1mCheckpoint 98: 
-----------------------------------
Train ACCURACY: 0.9487
Train Loss: 0.1558
ID Validation ACCURACY: 0.8891
ID Validation Loss: 0.3358
ID Test ACCURACY: 0.8887
ID Test Loss: 0.3454
OOD Validation ACCURACY: 0.8904
OOD Validation Loss: 0.3545
OOD Test ACCURACY: 0.5050
OOD Test Loss: 2.1260

[0m[1;37mINFO[0m: [1mChartInfo 0.9003 0.3624 0.8887 0.5050 0.8891 0.8904[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.124
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.116
SUFF++ for r=0.3 class 0 = 0.591 +- 0.146 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.3 class 1 = 0.527 +- 0.146 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.3 class 2 = 0.589 +- 0.146 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.3 class 3 = 0.579 +- 0.146 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.3 class 4 = 0.546 +- 0.146 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.3 class 5 = 0.578 +- 0.146 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.3 class 6 = 0.567 +- 0.146 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.3 class 7 = 0.56 +- 0.146 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.3 class 8 = 0.566 +- 0.146 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.3 class 9 = 0.562 +- 0.146 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.3 all KL = 0.712 +- 0.146 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.3 all L1 = 0.566 +- 0.097 (in-sample avg dev_std = 0.276)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.321
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.271
SUFF++ for r=0.6 class 0 = 0.532 +- 0.226 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.6 class 1 = 0.674 +- 0.226 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.6 class 2 = 0.527 +- 0.226 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.6 class 3 = 0.503 +- 0.226 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.6 class 4 = 0.517 +- 0.226 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.6 class 5 = 0.506 +- 0.226 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.6 class 6 = 0.454 +- 0.226 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.6 class 7 = 0.461 +- 0.226 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.6 class 8 = 0.522 +- 0.226 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.6 class 9 = 0.474 +- 0.226 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.6 all KL = 0.577 +- 0.226 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.6 all L1 = 0.519 +- 0.158 (in-sample avg dev_std = 0.202)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.84
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.796
SUFF++ for r=0.9 class 0 = 0.958 +- 0.224 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 1 = 0.984 +- 0.224 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 2 = 0.793 +- 0.224 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 3 = 0.766 +- 0.224 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 4 = 0.792 +- 0.224 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 5 = 0.747 +- 0.224 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 6 = 0.789 +- 0.224 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 7 = 0.819 +- 0.224 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 8 = 0.841 +- 0.224 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 9 = 0.802 +- 0.224 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 all KL = 0.847 +- 0.224 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 all L1 = 0.832 +- 0.196 (in-sample avg dev_std = 0.261)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.144
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.116
SUFF++ for r=0.3 class 0 = 0.588 +- 0.158 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.3 class 1 = 0.481 +- 0.158 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.3 class 2 = 0.577 +- 0.158 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.3 class 3 = 0.56 +- 0.158 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.3 class 4 = 0.536 +- 0.158 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.3 class 5 = 0.559 +- 0.158 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.3 class 6 = 0.543 +- 0.158 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.3 class 7 = 0.534 +- 0.158 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.3 class 8 = 0.527 +- 0.158 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.3 class 9 = 0.529 +- 0.158 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.3 all KL = 0.66 +- 0.158 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.3 all L1 = 0.543 +- 0.096 (in-sample avg dev_std = 0.321)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.189
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.16
SUFF++ for r=0.6 class 0 = 0.464 +- 0.245 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.6 class 1 = 0.622 +- 0.245 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.6 class 2 = 0.491 +- 0.245 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.6 class 3 = 0.496 +- 0.245 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.6 class 4 = 0.481 +- 0.245 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.6 class 5 = 0.545 +- 0.245 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.6 class 6 = 0.487 +- 0.245 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.6 class 7 = 0.554 +- 0.245 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.6 class 8 = 0.546 +- 0.245 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.6 class 9 = 0.459 +- 0.245 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.6 all KL = 0.553 +- 0.245 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.6 all L1 = 0.515 +- 0.175 (in-sample avg dev_std = 0.234)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.384
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.388
SUFF++ for r=0.9 class 0 = 0.719 +- 0.177 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 1 = 0.903 +- 0.177 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 2 = 0.703 +- 0.177 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 3 = 0.767 +- 0.177 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 4 = 0.735 +- 0.177 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 5 = 0.729 +- 0.177 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 6 = 0.699 +- 0.177 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 7 = 0.74 +- 0.177 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 8 = 0.731 +- 0.177 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 9 = 0.697 +- 0.177 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 all KL = 0.825 +- 0.177 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 all L1 = 0.744 +- 0.179 (in-sample avg dev_std = 0.260)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.124
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.136
NEC for r=0.3 class 0 = 0.365 +- 0.137 (in-sample avg dev_std = 0.190)
NEC for r=0.3 class 1 = 0.393 +- 0.137 (in-sample avg dev_std = 0.190)
NEC for r=0.3 class 2 = 0.373 +- 0.137 (in-sample avg dev_std = 0.190)
NEC for r=0.3 class 3 = 0.376 +- 0.137 (in-sample avg dev_std = 0.190)
NEC for r=0.3 class 4 = 0.408 +- 0.137 (in-sample avg dev_std = 0.190)
NEC for r=0.3 class 5 = 0.384 +- 0.137 (in-sample avg dev_std = 0.190)
NEC for r=0.3 class 6 = 0.397 +- 0.137 (in-sample avg dev_std = 0.190)
NEC for r=0.3 class 7 = 0.369 +- 0.137 (in-sample avg dev_std = 0.190)
NEC for r=0.3 class 8 = 0.395 +- 0.137 (in-sample avg dev_std = 0.190)
NEC for r=0.3 class 9 = 0.393 +- 0.137 (in-sample avg dev_std = 0.190)
NEC for r=0.3 all KL = 0.214 +- 0.137 (in-sample avg dev_std = 0.190)
NEC for r=0.3 all L1 = 0.385 +- 0.108 (in-sample avg dev_std = 0.190)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.321
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.282
NEC for r=0.6 class 0 = 0.451 +- 0.210 (in-sample avg dev_std = 0.265)
NEC for r=0.6 class 1 = 0.288 +- 0.210 (in-sample avg dev_std = 0.265)
NEC for r=0.6 class 2 = 0.424 +- 0.210 (in-sample avg dev_std = 0.265)
NEC for r=0.6 class 3 = 0.448 +- 0.210 (in-sample avg dev_std = 0.265)
NEC for r=0.6 class 4 = 0.453 +- 0.210 (in-sample avg dev_std = 0.265)
NEC for r=0.6 class 5 = 0.434 +- 0.210 (in-sample avg dev_std = 0.265)
NEC for r=0.6 class 6 = 0.506 +- 0.210 (in-sample avg dev_std = 0.265)
NEC for r=0.6 class 7 = 0.484 +- 0.210 (in-sample avg dev_std = 0.265)
NEC for r=0.6 class 8 = 0.451 +- 0.210 (in-sample avg dev_std = 0.265)
NEC for r=0.6 class 9 = 0.501 +- 0.210 (in-sample avg dev_std = 0.265)
NEC for r=0.6 all KL = 0.347 +- 0.210 (in-sample avg dev_std = 0.265)
NEC for r=0.6 all L1 = 0.442 +- 0.151 (in-sample avg dev_std = 0.265)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.84
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.715
NEC for r=0.9 class 0 = 0.155 +- 0.302 (in-sample avg dev_std = 0.385)
NEC for r=0.9 class 1 = 0.05 +- 0.302 (in-sample avg dev_std = 0.385)
NEC for r=0.9 class 2 = 0.359 +- 0.302 (in-sample avg dev_std = 0.385)
NEC for r=0.9 class 3 = 0.456 +- 0.302 (in-sample avg dev_std = 0.385)
NEC for r=0.9 class 4 = 0.372 +- 0.302 (in-sample avg dev_std = 0.385)
NEC for r=0.9 class 5 = 0.496 +- 0.302 (in-sample avg dev_std = 0.385)
NEC for r=0.9 class 6 = 0.414 +- 0.302 (in-sample avg dev_std = 0.385)
NEC for r=0.9 class 7 = 0.321 +- 0.302 (in-sample avg dev_std = 0.385)
NEC for r=0.9 class 8 = 0.363 +- 0.302 (in-sample avg dev_std = 0.385)
NEC for r=0.9 class 9 = 0.39 +- 0.302 (in-sample avg dev_std = 0.385)
NEC for r=0.9 all KL = 0.432 +- 0.302 (in-sample avg dev_std = 0.385)
NEC for r=0.9 all L1 = 0.331 +- 0.249 (in-sample avg dev_std = 0.385)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.956
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.864
NEC for r=1.0 class 0 = 0.051 +- 0.312 (in-sample avg dev_std = 0.347)
NEC for r=1.0 class 1 = 0.011 +- 0.312 (in-sample avg dev_std = 0.347)
NEC for r=1.0 class 2 = 0.241 +- 0.312 (in-sample avg dev_std = 0.347)
NEC for r=1.0 class 3 = 0.296 +- 0.312 (in-sample avg dev_std = 0.347)
NEC for r=1.0 class 4 = 0.199 +- 0.312 (in-sample avg dev_std = 0.347)
NEC for r=1.0 class 5 = 0.361 +- 0.312 (in-sample avg dev_std = 0.347)
NEC for r=1.0 class 6 = 0.267 +- 0.312 (in-sample avg dev_std = 0.347)
NEC for r=1.0 class 7 = 0.173 +- 0.312 (in-sample avg dev_std = 0.347)
NEC for r=1.0 class 8 = 0.203 +- 0.312 (in-sample avg dev_std = 0.347)
NEC for r=1.0 class 9 = 0.276 +- 0.312 (in-sample avg dev_std = 0.347)
NEC for r=1.0 all KL = 0.306 +- 0.312 (in-sample avg dev_std = 0.347)
NEC for r=1.0 all L1 = 0.203 +- 0.227 (in-sample avg dev_std = 0.347)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.144
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.136
NEC for r=0.3 class 0 = 0.363 +- 0.140 (in-sample avg dev_std = 0.205)
NEC for r=0.3 class 1 = 0.395 +- 0.140 (in-sample avg dev_std = 0.205)
NEC for r=0.3 class 2 = 0.375 +- 0.140 (in-sample avg dev_std = 0.205)
NEC for r=0.3 class 3 = 0.396 +- 0.140 (in-sample avg dev_std = 0.205)
NEC for r=0.3 class 4 = 0.418 +- 0.140 (in-sample avg dev_std = 0.205)
NEC for r=0.3 class 5 = 0.386 +- 0.140 (in-sample avg dev_std = 0.205)
NEC for r=0.3 class 6 = 0.416 +- 0.140 (in-sample avg dev_std = 0.205)
NEC for r=0.3 class 7 = 0.369 +- 0.140 (in-sample avg dev_std = 0.205)
NEC for r=0.3 class 8 = 0.403 +- 0.140 (in-sample avg dev_std = 0.205)
NEC for r=0.3 class 9 = 0.404 +- 0.140 (in-sample avg dev_std = 0.205)
NEC for r=0.3 all KL = 0.225 +- 0.140 (in-sample avg dev_std = 0.205)
NEC for r=0.3 all L1 = 0.392 +- 0.111 (in-sample avg dev_std = 0.205)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.189
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.163
NEC for r=0.6 class 0 = 0.46 +- 0.220 (in-sample avg dev_std = 0.288)
NEC for r=0.6 class 1 = 0.368 +- 0.220 (in-sample avg dev_std = 0.288)
NEC for r=0.6 class 2 = 0.443 +- 0.220 (in-sample avg dev_std = 0.288)
NEC for r=0.6 class 3 = 0.424 +- 0.220 (in-sample avg dev_std = 0.288)
NEC for r=0.6 class 4 = 0.482 +- 0.220 (in-sample avg dev_std = 0.288)
NEC for r=0.6 class 5 = 0.427 +- 0.220 (in-sample avg dev_std = 0.288)
NEC for r=0.6 class 6 = 0.481 +- 0.220 (in-sample avg dev_std = 0.288)
NEC for r=0.6 class 7 = 0.383 +- 0.220 (in-sample avg dev_std = 0.288)
NEC for r=0.6 class 8 = 0.413 +- 0.220 (in-sample avg dev_std = 0.288)
NEC for r=0.6 class 9 = 0.489 +- 0.220 (in-sample avg dev_std = 0.288)
NEC for r=0.6 all KL = 0.35 +- 0.220 (in-sample avg dev_std = 0.288)
NEC for r=0.6 all L1 = 0.436 +- 0.165 (in-sample avg dev_std = 0.288)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.384
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.337
NEC for r=0.9 class 0 = 0.545 +- 0.273 (in-sample avg dev_std = 0.316)
NEC for r=0.9 class 1 = 0.172 +- 0.273 (in-sample avg dev_std = 0.316)
NEC for r=0.9 class 2 = 0.484 +- 0.273 (in-sample avg dev_std = 0.316)
NEC for r=0.9 class 3 = 0.405 +- 0.273 (in-sample avg dev_std = 0.316)
NEC for r=0.9 class 4 = 0.482 +- 0.273 (in-sample avg dev_std = 0.316)
NEC for r=0.9 class 5 = 0.47 +- 0.273 (in-sample avg dev_std = 0.316)
NEC for r=0.9 class 6 = 0.526 +- 0.273 (in-sample avg dev_std = 0.316)
NEC for r=0.9 class 7 = 0.451 +- 0.273 (in-sample avg dev_std = 0.316)
NEC for r=0.9 class 8 = 0.466 +- 0.273 (in-sample avg dev_std = 0.316)
NEC for r=0.9 class 9 = 0.499 +- 0.273 (in-sample avg dev_std = 0.316)
NEC for r=0.9 all KL = 0.454 +- 0.273 (in-sample avg dev_std = 0.316)
NEC for r=0.9 all L1 = 0.446 +- 0.229 (in-sample avg dev_std = 0.316)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.352
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.372
NEC for r=1.0 class 0 = 0.575 +- 0.297 (in-sample avg dev_std = 0.328)
NEC for r=1.0 class 1 = 0.272 +- 0.297 (in-sample avg dev_std = 0.328)
NEC for r=1.0 class 2 = 0.448 +- 0.297 (in-sample avg dev_std = 0.328)
NEC for r=1.0 class 3 = 0.401 +- 0.297 (in-sample avg dev_std = 0.328)
NEC for r=1.0 class 4 = 0.451 +- 0.297 (in-sample avg dev_std = 0.328)
NEC for r=1.0 class 5 = 0.449 +- 0.297 (in-sample avg dev_std = 0.328)
NEC for r=1.0 class 6 = 0.553 +- 0.297 (in-sample avg dev_std = 0.328)
NEC for r=1.0 class 7 = 0.405 +- 0.297 (in-sample avg dev_std = 0.328)
NEC for r=1.0 class 8 = 0.475 +- 0.297 (in-sample avg dev_std = 0.328)
NEC for r=1.0 class 9 = 0.494 +- 0.297 (in-sample avg dev_std = 0.328)
NEC for r=1.0 all KL = 0.521 +- 0.297 (in-sample avg dev_std = 0.328)
NEC for r=1.0 all L1 = 0.45 +- 0.246 (in-sample avg dev_std = 0.328)
model_dirname= repr_LECIvGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 15:51:19 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 03:51:20 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 196...
[0m[1;37mINFO[0m: [1mCheckpoint 196: 
-----------------------------------
Train ACCURACY: 0.9966
Train Loss: 0.0179
ID Validation ACCURACY: 0.9039
ID Validation Loss: 0.3644
ID Test ACCURACY: 0.9053
ID Test Loss: 0.3586
OOD Validation ACCURACY: 0.7946
OOD Validation Loss: 0.9352
OOD Test ACCURACY: 0.2296
OOD Test Loss: 9.8341

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 91...
[0m[1;37mINFO[0m: [1mCheckpoint 91: 
-----------------------------------
Train ACCURACY: 0.9394
Train Loss: 0.1848
ID Validation ACCURACY: 0.8913
ID Validation Loss: 0.3438
ID Test ACCURACY: 0.8839
ID Test Loss: 0.3521
OOD Validation ACCURACY: 0.8734
OOD Validation Loss: 0.3847
OOD Test ACCURACY: 0.7427
OOD Test Loss: 0.8389

[0m[1;37mINFO[0m: [1mChartInfo 0.9053 0.2296 0.8839 0.7427 0.8913 0.8734[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.115
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.104
SUFF++ for r=0.3 class 0 = 0.587 +- 0.126 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.3 class 1 = 0.543 +- 0.126 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.3 class 2 = 0.613 +- 0.126 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.3 class 3 = 0.586 +- 0.126 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.3 class 4 = 0.588 +- 0.126 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.3 class 5 = 0.59 +- 0.126 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.3 class 6 = 0.586 +- 0.126 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.3 class 7 = 0.574 +- 0.126 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.3 class 8 = 0.606 +- 0.126 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.3 class 9 = 0.59 +- 0.126 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.3 all KL = 0.751 +- 0.126 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.3 all L1 = 0.586 +- 0.094 (in-sample avg dev_std = 0.256)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.299
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.239
SUFF++ for r=0.6 class 0 = 0.449 +- 0.211 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.6 class 1 = 0.564 +- 0.211 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.6 class 2 = 0.478 +- 0.211 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.6 class 3 = 0.461 +- 0.211 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.6 class 4 = 0.499 +- 0.211 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.6 class 5 = 0.477 +- 0.211 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.6 class 6 = 0.51 +- 0.211 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.6 class 7 = 0.472 +- 0.211 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.6 class 8 = 0.5 +- 0.211 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.6 class 9 = 0.485 +- 0.211 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.6 all KL = 0.546 +- 0.211 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.6 all L1 = 0.49 +- 0.136 (in-sample avg dev_std = 0.291)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.831
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.792
SUFF++ for r=0.9 class 0 = 0.934 +- 0.220 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.9 class 1 = 0.984 +- 0.220 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.9 class 2 = 0.794 +- 0.220 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.9 class 3 = 0.8 +- 0.220 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.9 class 4 = 0.827 +- 0.220 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.9 class 5 = 0.747 +- 0.220 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.9 class 6 = 0.8 +- 0.220 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.9 class 7 = 0.835 +- 0.220 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.9 class 8 = 0.832 +- 0.220 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.9 class 9 = 0.767 +- 0.220 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.9 all KL = 0.848 +- 0.220 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.9 all L1 = 0.836 +- 0.199 (in-sample avg dev_std = 0.241)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.116
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.103
SUFF++ for r=0.3 class 0 = 0.544 +- 0.138 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.3 class 1 = 0.502 +- 0.138 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.3 class 2 = 0.543 +- 0.138 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.3 class 3 = 0.546 +- 0.138 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.3 class 4 = 0.539 +- 0.138 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.3 class 5 = 0.546 +- 0.138 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.3 class 6 = 0.551 +- 0.138 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.3 class 7 = 0.527 +- 0.138 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.3 class 8 = 0.539 +- 0.138 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.3 class 9 = 0.535 +- 0.138 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.3 all KL = 0.663 +- 0.138 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.3 all L1 = 0.537 +- 0.085 (in-sample avg dev_std = 0.327)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.196
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.209
SUFF++ for r=0.6 class 0 = 0.446 +- 0.231 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.6 class 1 = 0.638 +- 0.231 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.6 class 2 = 0.502 +- 0.231 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.6 class 3 = 0.513 +- 0.231 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.6 class 4 = 0.476 +- 0.231 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.6 class 5 = 0.458 +- 0.231 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.6 class 6 = 0.492 +- 0.231 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.6 class 7 = 0.534 +- 0.231 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.6 class 8 = 0.518 +- 0.231 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.6 class 9 = 0.48 +- 0.231 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.6 all KL = 0.475 +- 0.231 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.6 all L1 = 0.508 +- 0.178 (in-sample avg dev_std = 0.339)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.294
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.304
SUFF++ for r=0.9 class 0 = 0.6 +- 0.260 (in-sample avg dev_std = 0.357)
SUFF++ for r=0.9 class 1 = 0.955 +- 0.260 (in-sample avg dev_std = 0.357)
SUFF++ for r=0.9 class 2 = 0.635 +- 0.260 (in-sample avg dev_std = 0.357)
SUFF++ for r=0.9 class 3 = 0.654 +- 0.260 (in-sample avg dev_std = 0.357)
SUFF++ for r=0.9 class 4 = 0.686 +- 0.260 (in-sample avg dev_std = 0.357)
SUFF++ for r=0.9 class 5 = 0.714 +- 0.260 (in-sample avg dev_std = 0.357)
SUFF++ for r=0.9 class 6 = 0.646 +- 0.260 (in-sample avg dev_std = 0.357)
SUFF++ for r=0.9 class 7 = 0.709 +- 0.260 (in-sample avg dev_std = 0.357)
SUFF++ for r=0.9 class 8 = 0.695 +- 0.260 (in-sample avg dev_std = 0.357)
SUFF++ for r=0.9 class 9 = 0.701 +- 0.260 (in-sample avg dev_std = 0.357)
SUFF++ for r=0.9 all KL = 0.731 +- 0.260 (in-sample avg dev_std = 0.357)
SUFF++ for r=0.9 all L1 = 0.702 +- 0.212 (in-sample avg dev_std = 0.357)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.115
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.106
NEC for r=0.3 class 0 = 0.349 +- 0.123 (in-sample avg dev_std = 0.172)
NEC for r=0.3 class 1 = 0.381 +- 0.123 (in-sample avg dev_std = 0.172)
NEC for r=0.3 class 2 = 0.36 +- 0.123 (in-sample avg dev_std = 0.172)
NEC for r=0.3 class 3 = 0.368 +- 0.123 (in-sample avg dev_std = 0.172)
NEC for r=0.3 class 4 = 0.347 +- 0.123 (in-sample avg dev_std = 0.172)
NEC for r=0.3 class 5 = 0.368 +- 0.123 (in-sample avg dev_std = 0.172)
NEC for r=0.3 class 6 = 0.375 +- 0.123 (in-sample avg dev_std = 0.172)
NEC for r=0.3 class 7 = 0.362 +- 0.123 (in-sample avg dev_std = 0.172)
NEC for r=0.3 class 8 = 0.376 +- 0.123 (in-sample avg dev_std = 0.172)
NEC for r=0.3 class 9 = 0.36 +- 0.123 (in-sample avg dev_std = 0.172)
NEC for r=0.3 all KL = 0.186 +- 0.123 (in-sample avg dev_std = 0.172)
NEC for r=0.3 all L1 = 0.365 +- 0.100 (in-sample avg dev_std = 0.172)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.299
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.264
NEC for r=0.6 class 0 = 0.429 +- 0.168 (in-sample avg dev_std = 0.218)
NEC for r=0.6 class 1 = 0.227 +- 0.168 (in-sample avg dev_std = 0.218)
NEC for r=0.6 class 2 = 0.407 +- 0.168 (in-sample avg dev_std = 0.218)
NEC for r=0.6 class 3 = 0.429 +- 0.168 (in-sample avg dev_std = 0.218)
NEC for r=0.6 class 4 = 0.436 +- 0.168 (in-sample avg dev_std = 0.218)
NEC for r=0.6 class 5 = 0.429 +- 0.168 (in-sample avg dev_std = 0.218)
NEC for r=0.6 class 6 = 0.427 +- 0.168 (in-sample avg dev_std = 0.218)
NEC for r=0.6 class 7 = 0.445 +- 0.168 (in-sample avg dev_std = 0.218)
NEC for r=0.6 class 8 = 0.412 +- 0.168 (in-sample avg dev_std = 0.218)
NEC for r=0.6 class 9 = 0.459 +- 0.168 (in-sample avg dev_std = 0.218)
NEC for r=0.6 all KL = 0.277 +- 0.168 (in-sample avg dev_std = 0.218)
NEC for r=0.6 all L1 = 0.407 +- 0.146 (in-sample avg dev_std = 0.218)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.831
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.68
NEC for r=0.9 class 0 = 0.303 +- 0.321 (in-sample avg dev_std = 0.401)
NEC for r=0.9 class 1 = 0.019 +- 0.321 (in-sample avg dev_std = 0.401)
NEC for r=0.9 class 2 = 0.389 +- 0.321 (in-sample avg dev_std = 0.401)
NEC for r=0.9 class 3 = 0.465 +- 0.321 (in-sample avg dev_std = 0.401)
NEC for r=0.9 class 4 = 0.343 +- 0.321 (in-sample avg dev_std = 0.401)
NEC for r=0.9 class 5 = 0.516 +- 0.321 (in-sample avg dev_std = 0.401)
NEC for r=0.9 class 6 = 0.419 +- 0.321 (in-sample avg dev_std = 0.401)
NEC for r=0.9 class 7 = 0.312 +- 0.321 (in-sample avg dev_std = 0.401)
NEC for r=0.9 class 8 = 0.448 +- 0.321 (in-sample avg dev_std = 0.401)
NEC for r=0.9 class 9 = 0.448 +- 0.321 (in-sample avg dev_std = 0.401)
NEC for r=0.9 all KL = 0.497 +- 0.321 (in-sample avg dev_std = 0.401)
NEC for r=0.9 all L1 = 0.359 +- 0.253 (in-sample avg dev_std = 0.401)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.956
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.859
NEC for r=1.0 class 0 = 0.098 +- 0.336 (in-sample avg dev_std = 0.362)
NEC for r=1.0 class 1 = 0.006 +- 0.336 (in-sample avg dev_std = 0.362)
NEC for r=1.0 class 2 = 0.258 +- 0.336 (in-sample avg dev_std = 0.362)
NEC for r=1.0 class 3 = 0.246 +- 0.336 (in-sample avg dev_std = 0.362)
NEC for r=1.0 class 4 = 0.154 +- 0.336 (in-sample avg dev_std = 0.362)
NEC for r=1.0 class 5 = 0.325 +- 0.336 (in-sample avg dev_std = 0.362)
NEC for r=1.0 class 6 = 0.313 +- 0.336 (in-sample avg dev_std = 0.362)
NEC for r=1.0 class 7 = 0.178 +- 0.336 (in-sample avg dev_std = 0.362)
NEC for r=1.0 class 8 = 0.229 +- 0.336 (in-sample avg dev_std = 0.362)
NEC for r=1.0 class 9 = 0.361 +- 0.336 (in-sample avg dev_std = 0.362)
NEC for r=1.0 all KL = 0.352 +- 0.336 (in-sample avg dev_std = 0.362)
NEC for r=1.0 all L1 = 0.211 +- 0.235 (in-sample avg dev_std = 0.362)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.116
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.105
NEC for r=0.3 class 0 = 0.357 +- 0.133 (in-sample avg dev_std = 0.176)
NEC for r=0.3 class 1 = 0.363 +- 0.133 (in-sample avg dev_std = 0.176)
NEC for r=0.3 class 2 = 0.373 +- 0.133 (in-sample avg dev_std = 0.176)
NEC for r=0.3 class 3 = 0.39 +- 0.133 (in-sample avg dev_std = 0.176)
NEC for r=0.3 class 4 = 0.394 +- 0.133 (in-sample avg dev_std = 0.176)
NEC for r=0.3 class 5 = 0.369 +- 0.133 (in-sample avg dev_std = 0.176)
NEC for r=0.3 class 6 = 0.397 +- 0.133 (in-sample avg dev_std = 0.176)
NEC for r=0.3 class 7 = 0.364 +- 0.133 (in-sample avg dev_std = 0.176)
NEC for r=0.3 class 8 = 0.368 +- 0.133 (in-sample avg dev_std = 0.176)
NEC for r=0.3 class 9 = 0.365 +- 0.133 (in-sample avg dev_std = 0.176)
NEC for r=0.3 all KL = 0.202 +- 0.133 (in-sample avg dev_std = 0.176)
NEC for r=0.3 all L1 = 0.374 +- 0.110 (in-sample avg dev_std = 0.176)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.196
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.207
NEC for r=0.6 class 0 = 0.417 +- 0.266 (in-sample avg dev_std = 0.280)
NEC for r=0.6 class 1 = 0.174 +- 0.266 (in-sample avg dev_std = 0.280)
NEC for r=0.6 class 2 = 0.391 +- 0.266 (in-sample avg dev_std = 0.280)
NEC for r=0.6 class 3 = 0.384 +- 0.266 (in-sample avg dev_std = 0.280)
NEC for r=0.6 class 4 = 0.424 +- 0.266 (in-sample avg dev_std = 0.280)
NEC for r=0.6 class 5 = 0.397 +- 0.266 (in-sample avg dev_std = 0.280)
NEC for r=0.6 class 6 = 0.411 +- 0.266 (in-sample avg dev_std = 0.280)
NEC for r=0.6 class 7 = 0.358 +- 0.266 (in-sample avg dev_std = 0.280)
NEC for r=0.6 class 8 = 0.392 +- 0.266 (in-sample avg dev_std = 0.280)
NEC for r=0.6 class 9 = 0.442 +- 0.266 (in-sample avg dev_std = 0.280)
NEC for r=0.6 all KL = 0.309 +- 0.266 (in-sample avg dev_std = 0.280)
NEC for r=0.6 all L1 = 0.376 +- 0.208 (in-sample avg dev_std = 0.280)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.294
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.279
NEC for r=0.9 class 0 = 0.615 +- 0.327 (in-sample avg dev_std = 0.355)
NEC for r=0.9 class 1 = 0.062 +- 0.327 (in-sample avg dev_std = 0.355)
NEC for r=0.9 class 2 = 0.578 +- 0.327 (in-sample avg dev_std = 0.355)
NEC for r=0.9 class 3 = 0.517 +- 0.327 (in-sample avg dev_std = 0.355)
NEC for r=0.9 class 4 = 0.506 +- 0.327 (in-sample avg dev_std = 0.355)
NEC for r=0.9 class 5 = 0.505 +- 0.327 (in-sample avg dev_std = 0.355)
NEC for r=0.9 class 6 = 0.654 +- 0.327 (in-sample avg dev_std = 0.355)
NEC for r=0.9 class 7 = 0.494 +- 0.327 (in-sample avg dev_std = 0.355)
NEC for r=0.9 class 8 = 0.575 +- 0.327 (in-sample avg dev_std = 0.355)
NEC for r=0.9 class 9 = 0.574 +- 0.327 (in-sample avg dev_std = 0.355)
NEC for r=0.9 all KL = 0.587 +- 0.327 (in-sample avg dev_std = 0.355)
NEC for r=0.9 all L1 = 0.503 +- 0.262 (in-sample avg dev_std = 0.355)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.226
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.27
NEC for r=1.0 class 0 = 0.552 +- 0.381 (in-sample avg dev_std = 0.350)
NEC for r=1.0 class 1 = 0.02 +- 0.381 (in-sample avg dev_std = 0.350)
NEC for r=1.0 class 2 = 0.585 +- 0.381 (in-sample avg dev_std = 0.350)
NEC for r=1.0 class 3 = 0.519 +- 0.381 (in-sample avg dev_std = 0.350)
NEC for r=1.0 class 4 = 0.43 +- 0.381 (in-sample avg dev_std = 0.350)
NEC for r=1.0 class 5 = 0.516 +- 0.381 (in-sample avg dev_std = 0.350)
NEC for r=1.0 class 6 = 0.515 +- 0.381 (in-sample avg dev_std = 0.350)
NEC for r=1.0 class 7 = 0.379 +- 0.381 (in-sample avg dev_std = 0.350)
NEC for r=1.0 class 8 = 0.47 +- 0.381 (in-sample avg dev_std = 0.350)
NEC for r=1.0 class 9 = 0.407 +- 0.381 (in-sample avg dev_std = 0.350)
NEC for r=1.0 all KL = 0.594 +- 0.381 (in-sample avg dev_std = 0.350)
NEC for r=1.0 all L1 = 0.435 +- 0.314 (in-sample avg dev_std = 0.350)
model_dirname= repr_LECIvGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 16:04:02 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 04:04:04 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 196...
[0m[1;37mINFO[0m: [1mCheckpoint 196: 
-----------------------------------
Train ACCURACY: 0.9944
Train Loss: 0.0239
ID Validation ACCURACY: 0.8983
ID Validation Loss: 0.3773
ID Test ACCURACY: 0.8936
ID Test Loss: 0.3920
OOD Validation ACCURACY: 0.8399
OOD Validation Loss: 0.6466
OOD Test ACCURACY: 0.2553
OOD Test Loss: 5.9224

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 110...
[0m[1;37mINFO[0m: [1mCheckpoint 110: 
-----------------------------------
Train ACCURACY: 0.9490
Train Loss: 0.1516
ID Validation ACCURACY: 0.8876
ID Validation Loss: 0.3446
ID Test ACCURACY: 0.8911
ID Test Loss: 0.3452
OOD Validation ACCURACY: 0.8807
OOD Validation Loss: 0.3782
OOD Test ACCURACY: 0.6684
OOD Test Loss: 1.1653

[0m[1;37mINFO[0m: [1mChartInfo 0.8936 0.2553 0.8911 0.6684 0.8876 0.8807[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.141
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.132
SUFF++ for r=0.3 class 0 = 0.56 +- 0.143 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.3 class 1 = 0.554 +- 0.143 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.3 class 2 = 0.579 +- 0.143 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.3 class 3 = 0.549 +- 0.143 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.3 class 4 = 0.554 +- 0.143 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.3 class 5 = 0.568 +- 0.143 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.3 class 6 = 0.56 +- 0.143 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.3 class 7 = 0.546 +- 0.143 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.3 class 8 = 0.575 +- 0.143 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.3 class 9 = 0.561 +- 0.143 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.3 all KL = 0.707 +- 0.143 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.3 all L1 = 0.56 +- 0.100 (in-sample avg dev_std = 0.269)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.308
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.243
SUFF++ for r=0.6 class 0 = 0.521 +- 0.257 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.6 class 1 = 0.799 +- 0.257 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.6 class 2 = 0.471 +- 0.257 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.6 class 3 = 0.456 +- 0.257 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.6 class 4 = 0.443 +- 0.257 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.6 class 5 = 0.445 +- 0.257 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.6 class 6 = 0.428 +- 0.257 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.6 class 7 = 0.464 +- 0.257 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.6 class 8 = 0.484 +- 0.257 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.6 class 9 = 0.427 +- 0.257 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.6 all KL = 0.492 +- 0.257 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.6 all L1 = 0.499 +- 0.193 (in-sample avg dev_std = 0.284)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.816
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.765
SUFF++ for r=0.9 class 0 = 0.962 +- 0.243 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 1 = 0.966 +- 0.243 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 2 = 0.819 +- 0.243 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 3 = 0.756 +- 0.243 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 4 = 0.8 +- 0.243 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 5 = 0.739 +- 0.243 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 6 = 0.751 +- 0.243 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 7 = 0.821 +- 0.243 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 8 = 0.834 +- 0.243 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 9 = 0.792 +- 0.243 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 all KL = 0.833 +- 0.243 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 all L1 = 0.827 +- 0.210 (in-sample avg dev_std = 0.261)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.147
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.128
SUFF++ for r=0.3 class 0 = 0.602 +- 0.116 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.3 class 1 = 0.582 +- 0.116 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.3 class 2 = 0.591 +- 0.116 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.3 class 3 = 0.604 +- 0.116 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.3 class 4 = 0.602 +- 0.116 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.3 class 5 = 0.608 +- 0.116 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.3 class 6 = 0.599 +- 0.116 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.3 class 7 = 0.613 +- 0.116 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.3 class 8 = 0.603 +- 0.116 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.3 class 9 = 0.604 +- 0.116 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.3 all KL = 0.765 +- 0.116 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.3 all L1 = 0.6 +- 0.097 (in-sample avg dev_std = 0.235)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.166
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.159
SUFF++ for r=0.6 class 0 = 0.48 +- 0.251 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.6 class 1 = 0.513 +- 0.251 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.6 class 2 = 0.513 +- 0.251 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.6 class 3 = 0.519 +- 0.251 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.6 class 4 = 0.5 +- 0.251 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.6 class 5 = 0.508 +- 0.251 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.6 class 6 = 0.461 +- 0.251 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.6 class 7 = 0.508 +- 0.251 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.6 class 8 = 0.528 +- 0.251 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.6 class 9 = 0.447 +- 0.251 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.6 all KL = 0.498 +- 0.251 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.6 all L1 = 0.498 +- 0.179 (in-sample avg dev_std = 0.266)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.274
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.288
SUFF++ for r=0.9 class 0 = 0.728 +- 0.194 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.9 class 1 = 0.832 +- 0.194 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.9 class 2 = 0.695 +- 0.194 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.9 class 3 = 0.706 +- 0.194 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.9 class 4 = 0.715 +- 0.194 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.9 class 5 = 0.706 +- 0.194 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.9 class 6 = 0.718 +- 0.194 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.9 class 7 = 0.8 +- 0.194 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.9 class 8 = 0.702 +- 0.194 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.9 class 9 = 0.773 +- 0.194 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.9 all KL = 0.804 +- 0.194 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.9 all L1 = 0.739 +- 0.188 (in-sample avg dev_std = 0.301)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.141
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.142
NEC for r=0.3 class 0 = 0.412 +- 0.161 (in-sample avg dev_std = 0.240)
NEC for r=0.3 class 1 = 0.392 +- 0.161 (in-sample avg dev_std = 0.240)
NEC for r=0.3 class 2 = 0.414 +- 0.161 (in-sample avg dev_std = 0.240)
NEC for r=0.3 class 3 = 0.43 +- 0.161 (in-sample avg dev_std = 0.240)
NEC for r=0.3 class 4 = 0.424 +- 0.161 (in-sample avg dev_std = 0.240)
NEC for r=0.3 class 5 = 0.432 +- 0.161 (in-sample avg dev_std = 0.240)
NEC for r=0.3 class 6 = 0.426 +- 0.161 (in-sample avg dev_std = 0.240)
NEC for r=0.3 class 7 = 0.409 +- 0.161 (in-sample avg dev_std = 0.240)
NEC for r=0.3 class 8 = 0.438 +- 0.161 (in-sample avg dev_std = 0.240)
NEC for r=0.3 class 9 = 0.408 +- 0.161 (in-sample avg dev_std = 0.240)
NEC for r=0.3 all KL = 0.269 +- 0.161 (in-sample avg dev_std = 0.240)
NEC for r=0.3 all L1 = 0.418 +- 0.122 (in-sample avg dev_std = 0.240)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.308
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.264
NEC for r=0.6 class 0 = 0.332 +- 0.242 (in-sample avg dev_std = 0.271)
NEC for r=0.6 class 1 = 0.157 +- 0.242 (in-sample avg dev_std = 0.271)
NEC for r=0.6 class 2 = 0.454 +- 0.242 (in-sample avg dev_std = 0.271)
NEC for r=0.6 class 3 = 0.496 +- 0.242 (in-sample avg dev_std = 0.271)
NEC for r=0.6 class 4 = 0.489 +- 0.242 (in-sample avg dev_std = 0.271)
NEC for r=0.6 class 5 = 0.459 +- 0.242 (in-sample avg dev_std = 0.271)
NEC for r=0.6 class 6 = 0.466 +- 0.242 (in-sample avg dev_std = 0.271)
NEC for r=0.6 class 7 = 0.457 +- 0.242 (in-sample avg dev_std = 0.271)
NEC for r=0.6 class 8 = 0.457 +- 0.242 (in-sample avg dev_std = 0.271)
NEC for r=0.6 class 9 = 0.48 +- 0.242 (in-sample avg dev_std = 0.271)
NEC for r=0.6 all KL = 0.362 +- 0.242 (in-sample avg dev_std = 0.271)
NEC for r=0.6 all L1 = 0.421 +- 0.200 (in-sample avg dev_std = 0.271)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.816
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.652
NEC for r=0.9 class 0 = 0.147 +- 0.337 (in-sample avg dev_std = 0.418)
NEC for r=0.9 class 1 = 0.107 +- 0.337 (in-sample avg dev_std = 0.418)
NEC for r=0.9 class 2 = 0.326 +- 0.337 (in-sample avg dev_std = 0.418)
NEC for r=0.9 class 3 = 0.541 +- 0.337 (in-sample avg dev_std = 0.418)
NEC for r=0.9 class 4 = 0.385 +- 0.337 (in-sample avg dev_std = 0.418)
NEC for r=0.9 class 5 = 0.526 +- 0.337 (in-sample avg dev_std = 0.418)
NEC for r=0.9 class 6 = 0.514 +- 0.337 (in-sample avg dev_std = 0.418)
NEC for r=0.9 class 7 = 0.341 +- 0.337 (in-sample avg dev_std = 0.418)
NEC for r=0.9 class 8 = 0.399 +- 0.337 (in-sample avg dev_std = 0.418)
NEC for r=0.9 class 9 = 0.432 +- 0.337 (in-sample avg dev_std = 0.418)
NEC for r=0.9 all KL = 0.511 +- 0.337 (in-sample avg dev_std = 0.418)
NEC for r=0.9 all L1 = 0.366 +- 0.268 (in-sample avg dev_std = 0.418)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.95
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.838
NEC for r=1.0 class 0 = 0.061 +- 0.345 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 1 = 0.022 +- 0.345 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 2 = 0.188 +- 0.345 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 3 = 0.35 +- 0.345 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 4 = 0.187 +- 0.345 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 5 = 0.383 +- 0.345 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 6 = 0.343 +- 0.345 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 7 = 0.227 +- 0.345 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 8 = 0.217 +- 0.345 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 9 = 0.317 +- 0.345 (in-sample avg dev_std = 0.385)
NEC for r=1.0 all KL = 0.363 +- 0.345 (in-sample avg dev_std = 0.385)
NEC for r=1.0 all L1 = 0.225 +- 0.247 (in-sample avg dev_std = 0.385)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.147
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.134
NEC for r=0.3 class 0 = 0.348 +- 0.117 (in-sample avg dev_std = 0.199)
NEC for r=0.3 class 1 = 0.361 +- 0.117 (in-sample avg dev_std = 0.199)
NEC for r=0.3 class 2 = 0.378 +- 0.117 (in-sample avg dev_std = 0.199)
NEC for r=0.3 class 3 = 0.374 +- 0.117 (in-sample avg dev_std = 0.199)
NEC for r=0.3 class 4 = 0.363 +- 0.117 (in-sample avg dev_std = 0.199)
NEC for r=0.3 class 5 = 0.367 +- 0.117 (in-sample avg dev_std = 0.199)
NEC for r=0.3 class 6 = 0.418 +- 0.117 (in-sample avg dev_std = 0.199)
NEC for r=0.3 class 7 = 0.361 +- 0.117 (in-sample avg dev_std = 0.199)
NEC for r=0.3 class 8 = 0.386 +- 0.117 (in-sample avg dev_std = 0.199)
NEC for r=0.3 class 9 = 0.373 +- 0.117 (in-sample avg dev_std = 0.199)
NEC for r=0.3 all KL = 0.192 +- 0.117 (in-sample avg dev_std = 0.199)
NEC for r=0.3 all L1 = 0.373 +- 0.109 (in-sample avg dev_std = 0.199)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.166
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.157
NEC for r=0.6 class 0 = 0.412 +- 0.248 (in-sample avg dev_std = 0.297)
NEC for r=0.6 class 1 = 0.411 +- 0.248 (in-sample avg dev_std = 0.297)
NEC for r=0.6 class 2 = 0.443 +- 0.248 (in-sample avg dev_std = 0.297)
NEC for r=0.6 class 3 = 0.451 +- 0.248 (in-sample avg dev_std = 0.297)
NEC for r=0.6 class 4 = 0.485 +- 0.248 (in-sample avg dev_std = 0.297)
NEC for r=0.6 class 5 = 0.435 +- 0.248 (in-sample avg dev_std = 0.297)
NEC for r=0.6 class 6 = 0.491 +- 0.248 (in-sample avg dev_std = 0.297)
NEC for r=0.6 class 7 = 0.431 +- 0.248 (in-sample avg dev_std = 0.297)
NEC for r=0.6 class 8 = 0.447 +- 0.248 (in-sample avg dev_std = 0.297)
NEC for r=0.6 class 9 = 0.495 +- 0.248 (in-sample avg dev_std = 0.297)
NEC for r=0.6 all KL = 0.409 +- 0.248 (in-sample avg dev_std = 0.297)
NEC for r=0.6 all L1 = 0.449 +- 0.184 (in-sample avg dev_std = 0.297)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.274
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.276
NEC for r=0.9 class 0 = 0.491 +- 0.278 (in-sample avg dev_std = 0.351)
NEC for r=0.9 class 1 = 0.282 +- 0.278 (in-sample avg dev_std = 0.351)
NEC for r=0.9 class 2 = 0.486 +- 0.278 (in-sample avg dev_std = 0.351)
NEC for r=0.9 class 3 = 0.519 +- 0.278 (in-sample avg dev_std = 0.351)
NEC for r=0.9 class 4 = 0.505 +- 0.278 (in-sample avg dev_std = 0.351)
NEC for r=0.9 class 5 = 0.567 +- 0.278 (in-sample avg dev_std = 0.351)
NEC for r=0.9 class 6 = 0.577 +- 0.278 (in-sample avg dev_std = 0.351)
NEC for r=0.9 class 7 = 0.412 +- 0.278 (in-sample avg dev_std = 0.351)
NEC for r=0.9 class 8 = 0.525 +- 0.278 (in-sample avg dev_std = 0.351)
NEC for r=0.9 class 9 = 0.452 +- 0.278 (in-sample avg dev_std = 0.351)
NEC for r=0.9 all KL = 0.516 +- 0.278 (in-sample avg dev_std = 0.351)
NEC for r=0.9 all L1 = 0.478 +- 0.227 (in-sample avg dev_std = 0.351)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.261
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.296
NEC for r=1.0 class 0 = 0.549 +- 0.314 (in-sample avg dev_std = 0.347)
NEC for r=1.0 class 1 = 0.28 +- 0.314 (in-sample avg dev_std = 0.347)
NEC for r=1.0 class 2 = 0.525 +- 0.314 (in-sample avg dev_std = 0.347)
NEC for r=1.0 class 3 = 0.463 +- 0.314 (in-sample avg dev_std = 0.347)
NEC for r=1.0 class 4 = 0.404 +- 0.314 (in-sample avg dev_std = 0.347)
NEC for r=1.0 class 5 = 0.546 +- 0.314 (in-sample avg dev_std = 0.347)
NEC for r=1.0 class 6 = 0.473 +- 0.314 (in-sample avg dev_std = 0.347)
NEC for r=1.0 class 7 = 0.201 +- 0.314 (in-sample avg dev_std = 0.347)
NEC for r=1.0 class 8 = 0.471 +- 0.314 (in-sample avg dev_std = 0.347)
NEC for r=1.0 class 9 = 0.448 +- 0.314 (in-sample avg dev_std = 0.347)
NEC for r=1.0 all KL = 0.507 +- 0.314 (in-sample avg dev_std = 0.347)
NEC for r=1.0 all L1 = 0.434 +- 0.259 (in-sample avg dev_std = 0.347)
model_dirname= repr_LECIvGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 16:16:48 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 04:16:49 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 181...
[0m[1;37mINFO[0m: [1mCheckpoint 181: 
-----------------------------------
Train ACCURACY: 0.9917
Train Loss: 0.0313
ID Validation ACCURACY: 0.9021
ID Validation Loss: 0.3555
ID Test ACCURACY: 0.8964
ID Test Loss: 0.3775
OOD Validation ACCURACY: 0.8617
OOD Validation Loss: 0.5250
OOD Test ACCURACY: 0.3239
OOD Test Loss: 6.1359

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 97...
[0m[1;37mINFO[0m: [1mCheckpoint 97: 
-----------------------------------
Train ACCURACY: 0.9405
Train Loss: 0.1783
ID Validation ACCURACY: 0.8880
ID Validation Loss: 0.3388
ID Test ACCURACY: 0.8861
ID Test Loss: 0.3539
OOD Validation ACCURACY: 0.8879
OOD Validation Loss: 0.3554
OOD Test ACCURACY: 0.7159
OOD Test Loss: 1.1142

[0m[1;37mINFO[0m: [1mChartInfo 0.8964 0.3239 0.8861 0.7159 0.8880 0.8879[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.121
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.111
SUFF++ for r=0.3 class 0 = 0.641 +- 0.102 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.3 class 1 = 0.612 +- 0.102 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.3 class 2 = 0.638 +- 0.102 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.3 class 3 = 0.65 +- 0.102 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.3 class 4 = 0.617 +- 0.102 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.3 class 5 = 0.615 +- 0.102 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.3 class 6 = 0.628 +- 0.102 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.3 class 7 = 0.611 +- 0.102 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.3 class 8 = 0.647 +- 0.102 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.3 class 9 = 0.627 +- 0.102 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.3 all KL = 0.809 +- 0.102 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.3 all L1 = 0.629 +- 0.085 (in-sample avg dev_std = 0.198)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.279
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.221
SUFF++ for r=0.6 class 0 = 0.564 +- 0.226 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.6 class 1 = 0.459 +- 0.226 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.6 class 2 = 0.53 +- 0.226 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.6 class 3 = 0.491 +- 0.226 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.6 class 4 = 0.51 +- 0.226 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.6 class 5 = 0.494 +- 0.226 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.6 class 6 = 0.465 +- 0.226 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.6 class 7 = 0.5 +- 0.226 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.6 class 8 = 0.505 +- 0.226 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.6 class 9 = 0.453 +- 0.226 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.6 all KL = 0.575 +- 0.226 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.6 all L1 = 0.497 +- 0.147 (in-sample avg dev_std = 0.229)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.834
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.796
SUFF++ for r=0.9 class 0 = 0.971 +- 0.210 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 class 1 = 0.969 +- 0.210 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 class 2 = 0.792 +- 0.210 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 class 3 = 0.815 +- 0.210 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 class 4 = 0.851 +- 0.210 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 class 5 = 0.759 +- 0.210 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 class 6 = 0.821 +- 0.210 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 class 7 = 0.816 +- 0.210 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 class 8 = 0.834 +- 0.210 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 class 9 = 0.787 +- 0.210 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 all KL = 0.858 +- 0.210 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 all L1 = 0.844 +- 0.191 (in-sample avg dev_std = 0.237)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.144
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.12
SUFF++ for r=0.3 class 0 = 0.639 +- 0.116 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.3 class 1 = 0.554 +- 0.116 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.3 class 2 = 0.629 +- 0.116 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.3 class 3 = 0.632 +- 0.116 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.3 class 4 = 0.605 +- 0.116 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.3 class 5 = 0.636 +- 0.116 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.3 class 6 = 0.615 +- 0.116 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.3 class 7 = 0.604 +- 0.116 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.3 class 8 = 0.631 +- 0.116 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.3 class 9 = 0.621 +- 0.116 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.3 all KL = 0.789 +- 0.116 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.3 all L1 = 0.616 +- 0.095 (in-sample avg dev_std = 0.207)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.235
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.238
SUFF++ for r=0.6 class 0 = 0.513 +- 0.225 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.6 class 1 = 0.526 +- 0.225 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.6 class 2 = 0.554 +- 0.225 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.6 class 3 = 0.545 +- 0.225 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.6 class 4 = 0.527 +- 0.225 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.6 class 5 = 0.542 +- 0.225 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.6 class 6 = 0.555 +- 0.225 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.6 class 7 = 0.557 +- 0.225 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.6 class 8 = 0.566 +- 0.225 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.6 class 9 = 0.485 +- 0.225 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.6 all KL = 0.578 +- 0.225 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.6 all L1 = 0.537 +- 0.167 (in-sample avg dev_std = 0.223)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.339
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.332
SUFF++ for r=0.9 class 0 = 0.734 +- 0.202 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.9 class 1 = 0.748 +- 0.202 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.9 class 2 = 0.751 +- 0.202 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.9 class 3 = 0.69 +- 0.202 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.9 class 4 = 0.708 +- 0.202 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.9 class 5 = 0.663 +- 0.202 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.9 class 6 = 0.703 +- 0.202 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.9 class 7 = 0.775 +- 0.202 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.9 class 8 = 0.677 +- 0.202 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.9 class 9 = 0.678 +- 0.202 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.9 all KL = 0.778 +- 0.202 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.9 all L1 = 0.714 +- 0.178 (in-sample avg dev_std = 0.310)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.121
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.119
NEC for r=0.3 class 0 = 0.336 +- 0.109 (in-sample avg dev_std = 0.161)
NEC for r=0.3 class 1 = 0.367 +- 0.109 (in-sample avg dev_std = 0.161)
NEC for r=0.3 class 2 = 0.344 +- 0.109 (in-sample avg dev_std = 0.161)
NEC for r=0.3 class 3 = 0.329 +- 0.109 (in-sample avg dev_std = 0.161)
NEC for r=0.3 class 4 = 0.339 +- 0.109 (in-sample avg dev_std = 0.161)
NEC for r=0.3 class 5 = 0.356 +- 0.109 (in-sample avg dev_std = 0.161)
NEC for r=0.3 class 6 = 0.354 +- 0.109 (in-sample avg dev_std = 0.161)
NEC for r=0.3 class 7 = 0.34 +- 0.109 (in-sample avg dev_std = 0.161)
NEC for r=0.3 class 8 = 0.356 +- 0.109 (in-sample avg dev_std = 0.161)
NEC for r=0.3 class 9 = 0.346 +- 0.109 (in-sample avg dev_std = 0.161)
NEC for r=0.3 all KL = 0.161 +- 0.109 (in-sample avg dev_std = 0.161)
NEC for r=0.3 all L1 = 0.347 +- 0.099 (in-sample avg dev_std = 0.161)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.279
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.252
NEC for r=0.6 class 0 = 0.364 +- 0.199 (in-sample avg dev_std = 0.246)
NEC for r=0.6 class 1 = 0.411 +- 0.199 (in-sample avg dev_std = 0.246)
NEC for r=0.6 class 2 = 0.41 +- 0.199 (in-sample avg dev_std = 0.246)
NEC for r=0.6 class 3 = 0.448 +- 0.199 (in-sample avg dev_std = 0.246)
NEC for r=0.6 class 4 = 0.472 +- 0.199 (in-sample avg dev_std = 0.246)
NEC for r=0.6 class 5 = 0.443 +- 0.199 (in-sample avg dev_std = 0.246)
NEC for r=0.6 class 6 = 0.465 +- 0.199 (in-sample avg dev_std = 0.246)
NEC for r=0.6 class 7 = 0.459 +- 0.199 (in-sample avg dev_std = 0.246)
NEC for r=0.6 class 8 = 0.46 +- 0.199 (in-sample avg dev_std = 0.246)
NEC for r=0.6 class 9 = 0.502 +- 0.199 (in-sample avg dev_std = 0.246)
NEC for r=0.6 all KL = 0.33 +- 0.199 (in-sample avg dev_std = 0.246)
NEC for r=0.6 all L1 = 0.442 +- 0.141 (in-sample avg dev_std = 0.246)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.834
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.681
NEC for r=0.9 class 0 = 0.21 +- 0.304 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 1 = 0.105 +- 0.304 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 2 = 0.436 +- 0.304 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 3 = 0.43 +- 0.304 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 4 = 0.361 +- 0.304 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 5 = 0.462 +- 0.304 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 6 = 0.405 +- 0.304 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 7 = 0.386 +- 0.304 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 8 = 0.389 +- 0.304 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 9 = 0.456 +- 0.304 (in-sample avg dev_std = 0.429)
NEC for r=0.9 all KL = 0.508 +- 0.304 (in-sample avg dev_std = 0.429)
NEC for r=0.9 all L1 = 0.359 +- 0.243 (in-sample avg dev_std = 0.429)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.957
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.855
NEC for r=1.0 class 0 = 0.062 +- 0.325 (in-sample avg dev_std = 0.355)
NEC for r=1.0 class 1 = 0.027 +- 0.325 (in-sample avg dev_std = 0.355)
NEC for r=1.0 class 2 = 0.252 +- 0.325 (in-sample avg dev_std = 0.355)
NEC for r=1.0 class 3 = 0.244 +- 0.325 (in-sample avg dev_std = 0.355)
NEC for r=1.0 class 4 = 0.168 +- 0.325 (in-sample avg dev_std = 0.355)
NEC for r=1.0 class 5 = 0.333 +- 0.325 (in-sample avg dev_std = 0.355)
NEC for r=1.0 class 6 = 0.243 +- 0.325 (in-sample avg dev_std = 0.355)
NEC for r=1.0 class 7 = 0.233 +- 0.325 (in-sample avg dev_std = 0.355)
NEC for r=1.0 class 8 = 0.204 +- 0.325 (in-sample avg dev_std = 0.355)
NEC for r=1.0 class 9 = 0.35 +- 0.325 (in-sample avg dev_std = 0.355)
NEC for r=1.0 all KL = 0.329 +- 0.325 (in-sample avg dev_std = 0.355)
NEC for r=1.0 all L1 = 0.207 +- 0.237 (in-sample avg dev_std = 0.355)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.144
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.125
NEC for r=0.3 class 0 = 0.331 +- 0.116 (in-sample avg dev_std = 0.164)
NEC for r=0.3 class 1 = 0.397 +- 0.116 (in-sample avg dev_std = 0.164)
NEC for r=0.3 class 2 = 0.347 +- 0.116 (in-sample avg dev_std = 0.164)
NEC for r=0.3 class 3 = 0.342 +- 0.116 (in-sample avg dev_std = 0.164)
NEC for r=0.3 class 4 = 0.387 +- 0.116 (in-sample avg dev_std = 0.164)
NEC for r=0.3 class 5 = 0.35 +- 0.116 (in-sample avg dev_std = 0.164)
NEC for r=0.3 class 6 = 0.37 +- 0.116 (in-sample avg dev_std = 0.164)
NEC for r=0.3 class 7 = 0.381 +- 0.116 (in-sample avg dev_std = 0.164)
NEC for r=0.3 class 8 = 0.354 +- 0.116 (in-sample avg dev_std = 0.164)
NEC for r=0.3 class 9 = 0.35 +- 0.116 (in-sample avg dev_std = 0.164)
NEC for r=0.3 all KL = 0.175 +- 0.116 (in-sample avg dev_std = 0.164)
NEC for r=0.3 all L1 = 0.361 +- 0.102 (in-sample avg dev_std = 0.164)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.235
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.244
NEC for r=0.6 class 0 = 0.391 +- 0.204 (in-sample avg dev_std = 0.244)
NEC for r=0.6 class 1 = 0.383 +- 0.204 (in-sample avg dev_std = 0.244)
NEC for r=0.6 class 2 = 0.382 +- 0.204 (in-sample avg dev_std = 0.244)
NEC for r=0.6 class 3 = 0.395 +- 0.204 (in-sample avg dev_std = 0.244)
NEC for r=0.6 class 4 = 0.403 +- 0.204 (in-sample avg dev_std = 0.244)
NEC for r=0.6 class 5 = 0.397 +- 0.204 (in-sample avg dev_std = 0.244)
NEC for r=0.6 class 6 = 0.398 +- 0.204 (in-sample avg dev_std = 0.244)
NEC for r=0.6 class 7 = 0.401 +- 0.204 (in-sample avg dev_std = 0.244)
NEC for r=0.6 class 8 = 0.379 +- 0.204 (in-sample avg dev_std = 0.244)
NEC for r=0.6 class 9 = 0.447 +- 0.204 (in-sample avg dev_std = 0.244)
NEC for r=0.6 all KL = 0.298 +- 0.204 (in-sample avg dev_std = 0.244)
NEC for r=0.6 all L1 = 0.397 +- 0.154 (in-sample avg dev_std = 0.244)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.339
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.283
NEC for r=0.9 class 0 = 0.362 +- 0.267 (in-sample avg dev_std = 0.334)
NEC for r=0.9 class 1 = 0.5 +- 0.267 (in-sample avg dev_std = 0.334)
NEC for r=0.9 class 2 = 0.385 +- 0.267 (in-sample avg dev_std = 0.334)
NEC for r=0.9 class 3 = 0.488 +- 0.267 (in-sample avg dev_std = 0.334)
NEC for r=0.9 class 4 = 0.506 +- 0.267 (in-sample avg dev_std = 0.334)
NEC for r=0.9 class 5 = 0.488 +- 0.267 (in-sample avg dev_std = 0.334)
NEC for r=0.9 class 6 = 0.51 +- 0.267 (in-sample avg dev_std = 0.334)
NEC for r=0.9 class 7 = 0.361 +- 0.267 (in-sample avg dev_std = 0.334)
NEC for r=0.9 class 8 = 0.557 +- 0.267 (in-sample avg dev_std = 0.334)
NEC for r=0.9 class 9 = 0.516 +- 0.267 (in-sample avg dev_std = 0.334)
NEC for r=0.9 all KL = 0.47 +- 0.267 (in-sample avg dev_std = 0.334)
NEC for r=0.9 all L1 = 0.466 +- 0.212 (in-sample avg dev_std = 0.334)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.334
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.327
NEC for r=1.0 class 0 = 0.452 +- 0.313 (in-sample avg dev_std = 0.356)
NEC for r=1.0 class 1 = 0.507 +- 0.313 (in-sample avg dev_std = 0.356)
NEC for r=1.0 class 2 = 0.455 +- 0.313 (in-sample avg dev_std = 0.356)
NEC for r=1.0 class 3 = 0.499 +- 0.313 (in-sample avg dev_std = 0.356)
NEC for r=1.0 class 4 = 0.445 +- 0.313 (in-sample avg dev_std = 0.356)
NEC for r=1.0 class 5 = 0.501 +- 0.313 (in-sample avg dev_std = 0.356)
NEC for r=1.0 class 6 = 0.56 +- 0.313 (in-sample avg dev_std = 0.356)
NEC for r=1.0 class 7 = 0.412 +- 0.313 (in-sample avg dev_std = 0.356)
NEC for r=1.0 class 8 = 0.578 +- 0.313 (in-sample avg dev_std = 0.356)
NEC for r=1.0 class 9 = 0.505 +- 0.313 (in-sample avg dev_std = 0.356)
NEC for r=1.0 all KL = 0.557 +- 0.313 (in-sample avg dev_std = 0.356)
NEC for r=1.0 all L1 = 0.491 +- 0.247 (in-sample avg dev_std = 0.356)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.785, 0.527, 0.864, 1.0], 'all_L1': [0.625, 0.472, 0.835, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.712, 0.577, 0.847, 1.0], 'all_L1': [0.566, 0.519, 0.832, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.751, 0.546, 0.848, 1.0], 'all_L1': [0.586, 0.49, 0.836, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.707, 0.492, 0.833, 1.0], 'all_L1': [0.56, 0.499, 0.827, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.809, 0.575, 0.858, 1.0], 'all_L1': [0.629, 0.497, 0.844, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.139, 0.299, 0.454, 0.316], 'all_L1': [0.311, 0.41, 0.355, 0.217]}), defaultdict(<class 'list'>, {'all_KL': [0.214, 0.347, 0.432, 0.306], 'all_L1': [0.385, 0.442, 0.331, 0.203]}), defaultdict(<class 'list'>, {'all_KL': [0.186, 0.277, 0.497, 0.352], 'all_L1': [0.365, 0.407, 0.359, 0.211]}), defaultdict(<class 'list'>, {'all_KL': [0.269, 0.362, 0.511, 0.363], 'all_L1': [0.418, 0.421, 0.366, 0.225]}), defaultdict(<class 'list'>, {'all_KL': [0.161, 0.33, 0.508, 0.329], 'all_L1': [0.347, 0.442, 0.359, 0.207]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.754, 0.543, 0.791, 1.0], 'all_L1': [0.588, 0.484, 0.716, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.66, 0.553, 0.825, 1.0], 'all_L1': [0.543, 0.515, 0.744, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.663, 0.475, 0.731, 1.0], 'all_L1': [0.537, 0.508, 0.702, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.765, 0.498, 0.804, 1.0], 'all_L1': [0.6, 0.498, 0.739, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.789, 0.578, 0.778, 1.0], 'all_L1': [0.616, 0.537, 0.714, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.143, 0.288, 0.491, 0.439], 'all_L1': [0.327, 0.408, 0.482, 0.421]}), defaultdict(<class 'list'>, {'all_KL': [0.225, 0.35, 0.454, 0.521], 'all_L1': [0.392, 0.436, 0.446, 0.45]}), defaultdict(<class 'list'>, {'all_KL': [0.202, 0.309, 0.587, 0.594], 'all_L1': [0.374, 0.376, 0.503, 0.435]}), defaultdict(<class 'list'>, {'all_KL': [0.192, 0.409, 0.516, 0.507], 'all_L1': [0.373, 0.449, 0.478, 0.434]}), defaultdict(<class 'list'>, {'all_KL': [0.175, 0.298, 0.47, 0.557], 'all_L1': [0.361, 0.397, 0.466, 0.491]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.593 +- 0.029, 0.495 +- 0.015, 0.835 +- 0.006, 1.000 +- 0.000
suff++ class all_KL  =  0.753 +- 0.040, 0.543 +- 0.032, 0.850 +- 0.011, 1.000 +- 0.000
suff++_acc_int  =  0.114 +- 0.010, 0.242 +- 0.016, 0.787 +- 0.012
nec class all_L1  =  0.365 +- 0.036, 0.424 +- 0.015, 0.354 +- 0.012, 0.213 +- 0.008
nec class all_KL  =  0.194 +- 0.045, 0.323 +- 0.031, 0.480 +- 0.032, 0.333 +- 0.021
nec_acc_int  =  0.122 +- 0.015, 0.266 +- 0.010, 0.681 +- 0.020, 0.854 +- 0.009

Eval split test
suff++ class all_L1  =  0.577 +- 0.031, 0.508 +- 0.018, 0.723 +- 0.016, 1.000 +- 0.000
suff++ class all_KL  =  0.726 +- 0.054, 0.529 +- 0.038, 0.786 +- 0.031, 1.000 +- 0.000
suff++_acc_int  =  0.116 +- 0.008, 0.191 +- 0.030, 0.349 +- 0.054
nec class all_L1  =  0.365 +- 0.022, 0.413 +- 0.026, 0.475 +- 0.019, 0.446 +- 0.024
nec class all_KL  =  0.187 +- 0.027, 0.331 +- 0.044, 0.504 +- 0.047, 0.524 +- 0.052
nec_acc_int  =  0.124 +- 0.012, 0.199 +- 0.033, 0.307 +- 0.035, 0.343 +- 0.063


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.479 +- 0.008, 0.460 +- 0.014, 0.594 +- 0.007, 0.606 +- 0.004
Faith. Armon (L1)= 		  =  0.450 +- 0.020, 0.457 +- 0.014, 0.497 +- 0.012, 0.351 +- 0.010
Faith. GMean (L1)= 	  =  0.464 +- 0.014, 0.458 +- 0.014, 0.544 +- 0.010, 0.461 +- 0.008
Faith. Aritm (KL)= 		  =  0.473 +- 0.011, 0.433 +- 0.021, 0.665 +- 0.015, 0.667 +- 0.011
Faith. Armon (KL)= 		  =  0.304 +- 0.053, 0.404 +- 0.025, 0.613 +- 0.025, 0.499 +- 0.024
Faith. GMean (KL)= 	  =  0.378 +- 0.035, 0.418 +- 0.022, 0.639 +- 0.020, 0.577 +- 0.019

Eval split test
Faith. Aritm (L1)= 		  =  0.471 +- 0.014, 0.461 +- 0.014, 0.599 +- 0.006, 0.723 +- 0.012
Faith. Armon (L1)= 		  =  0.446 +- 0.015, 0.455 +- 0.016, 0.573 +- 0.011, 0.617 +- 0.023
Faith. GMean (L1)= 	  =  0.459 +- 0.013, 0.458 +- 0.015, 0.586 +- 0.008, 0.668 +- 0.018
Faith. Aritm (KL)= 		  =  0.457 +- 0.020, 0.430 +- 0.023, 0.645 +- 0.013, 0.762 +- 0.026
Faith. Armon (KL)= 		  =  0.296 +- 0.032, 0.404 +- 0.030, 0.611 +- 0.025, 0.686 +- 0.045
Faith. GMean (KL)= 	  =  0.367 +- 0.021, 0.417 +- 0.026, 0.628 +- 0.019, 0.723 +- 0.036
Computed for split load_split = id



Completed in  1:03:35.122800  for LECIvGIN GOODCMNIST/color



DONE LECI GOODCMNIST/color
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 16:30:00 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 04:30:01 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 104...
[0m[1;37mINFO[0m: [1mCheckpoint 104: 
-----------------------------------
Train ACCURACY: 0.3737
Train Loss: 2.7351
ID Validation ACCURACY: 0.3853
ID Validation Loss: 2.7063
ID Test ACCURACY: 0.3826
ID Test Loss: 2.7083
OOD Validation ACCURACY: 0.2491
OOD Validation Loss: 3.9212
OOD Test ACCURACY: 0.1309
OOD Test Loss: 6.8643

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 159...
[0m[1;37mINFO[0m: [1mCheckpoint 159: 
-----------------------------------
Train ACCURACY: 0.2226
Train Loss: 5.6222
ID Validation ACCURACY: 0.2277
ID Validation Loss: 5.6033
ID Test ACCURACY: 0.2184
ID Test Loss: 5.6135
OOD Validation ACCURACY: 0.3167
OOD Validation Loss: 3.6853
OOD Test ACCURACY: 0.0937
OOD Test Loss: 11.9726

[0m[1;37mINFO[0m: [1mChartInfo 0.3826 0.1309 0.2184 0.0937 0.2277 0.3167[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.095
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.092
SUFF++ for r=0.3 class 0 = 0.406 +- 0.205 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.3 class 1 = 0.415 +- 0.205 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.3 class 2 = 0.42 +- 0.205 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.3 class 3 = 0.427 +- 0.205 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.3 class 4 = 0.419 +- 0.205 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.3 class 5 = 0.439 +- 0.205 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.3 class 6 = 0.445 +- 0.205 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.3 class 7 = 0.431 +- 0.205 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.3 class 8 = 0.441 +- 0.205 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.3 class 9 = 0.481 +- 0.205 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.3 all KL = 0.512 +- 0.205 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.3 all L1 = 0.432 +- 0.125 (in-sample avg dev_std = 0.481)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.365
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.238
SUFF++ for r=0.6 class 0 = 0.286 +- 0.209 (in-sample avg dev_std = 0.543)
SUFF++ for r=0.6 class 1 = 0.327 +- 0.209 (in-sample avg dev_std = 0.543)
SUFF++ for r=0.6 class 2 = 0.296 +- 0.209 (in-sample avg dev_std = 0.543)
SUFF++ for r=0.6 class 3 = 0.264 +- 0.209 (in-sample avg dev_std = 0.543)
SUFF++ for r=0.6 class 4 = 0.437 +- 0.209 (in-sample avg dev_std = 0.543)
SUFF++ for r=0.6 class 5 = 0.291 +- 0.209 (in-sample avg dev_std = 0.543)
SUFF++ for r=0.6 class 6 = 0.319 +- 0.209 (in-sample avg dev_std = 0.543)
SUFF++ for r=0.6 class 7 = 0.35 +- 0.209 (in-sample avg dev_std = 0.543)
SUFF++ for r=0.6 class 8 = 0.268 +- 0.209 (in-sample avg dev_std = 0.543)
SUFF++ for r=0.6 class 9 = 0.345 +- 0.209 (in-sample avg dev_std = 0.543)
SUFF++ for r=0.6 all KL = 0.213 +- 0.209 (in-sample avg dev_std = 0.543)
SUFF++ for r=0.6 all L1 = 0.318 +- 0.111 (in-sample avg dev_std = 0.543)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.376
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.284
SUFF++ for r=0.9 class 0 = 0.342 +- 0.213 (in-sample avg dev_std = 0.613)
SUFF++ for r=0.9 class 1 = 0.394 +- 0.213 (in-sample avg dev_std = 0.613)
SUFF++ for r=0.9 class 2 = 0.331 +- 0.213 (in-sample avg dev_std = 0.613)
SUFF++ for r=0.9 class 3 = 0.3 +- 0.213 (in-sample avg dev_std = 0.613)
SUFF++ for r=0.9 class 4 = 0.45 +- 0.213 (in-sample avg dev_std = 0.613)
SUFF++ for r=0.9 class 5 = 0.313 +- 0.213 (in-sample avg dev_std = 0.613)
SUFF++ for r=0.9 class 6 = 0.35 +- 0.213 (in-sample avg dev_std = 0.613)
SUFF++ for r=0.9 class 7 = 0.387 +- 0.213 (in-sample avg dev_std = 0.613)
SUFF++ for r=0.9 class 8 = 0.311 +- 0.213 (in-sample avg dev_std = 0.613)
SUFF++ for r=0.9 class 9 = 0.38 +- 0.213 (in-sample avg dev_std = 0.613)
SUFF++ for r=0.9 all KL = 0.225 +- 0.213 (in-sample avg dev_std = 0.613)
SUFF++ for r=0.9 all L1 = 0.356 +- 0.126 (in-sample avg dev_std = 0.613)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.097
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.097
SUFF++ for r=0.3 class 0 = 0.364 +- 0.149 (in-sample avg dev_std = 0.708)
SUFF++ for r=0.3 class 1 = 0.367 +- 0.149 (in-sample avg dev_std = 0.708)
SUFF++ for r=0.3 class 2 = 0.354 +- 0.149 (in-sample avg dev_std = 0.708)
SUFF++ for r=0.3 class 3 = 0.365 +- 0.149 (in-sample avg dev_std = 0.708)
SUFF++ for r=0.3 class 4 = 0.358 +- 0.149 (in-sample avg dev_std = 0.708)
SUFF++ for r=0.3 class 5 = 0.352 +- 0.149 (in-sample avg dev_std = 0.708)
SUFF++ for r=0.3 class 6 = 0.365 +- 0.149 (in-sample avg dev_std = 0.708)
SUFF++ for r=0.3 class 7 = 0.366 +- 0.149 (in-sample avg dev_std = 0.708)
SUFF++ for r=0.3 class 8 = 0.362 +- 0.149 (in-sample avg dev_std = 0.708)
SUFF++ for r=0.3 class 9 = 0.367 +- 0.149 (in-sample avg dev_std = 0.708)
SUFF++ for r=0.3 all KL = 0.278 +- 0.149 (in-sample avg dev_std = 0.708)
SUFF++ for r=0.3 all L1 = 0.362 +- 0.061 (in-sample avg dev_std = 0.708)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.205
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.137
SUFF++ for r=0.6 class 0 = 0.247 +- 0.089 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.6 class 1 = 0.264 +- 0.089 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.6 class 2 = 0.257 +- 0.089 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.6 class 3 = 0.255 +- 0.089 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.6 class 4 = 0.272 +- 0.089 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.6 class 5 = 0.258 +- 0.089 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.6 class 6 = 0.261 +- 0.089 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.6 class 7 = 0.274 +- 0.089 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.6 class 8 = 0.262 +- 0.089 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.6 class 9 = 0.266 +- 0.089 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.6 all KL = 0.094 +- 0.089 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.6 all L1 = 0.262 +- 0.052 (in-sample avg dev_std = 0.604)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.125
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.142
SUFF++ for r=0.9 class 0 = 0.306 +- 0.072 (in-sample avg dev_std = 0.815)
SUFF++ for r=0.9 class 1 = 0.492 +- 0.072 (in-sample avg dev_std = 0.815)
SUFF++ for r=0.9 class 2 = 0.331 +- 0.072 (in-sample avg dev_std = 0.815)
SUFF++ for r=0.9 class 3 = 0.324 +- 0.072 (in-sample avg dev_std = 0.815)
SUFF++ for r=0.9 class 4 = 0.38 +- 0.072 (in-sample avg dev_std = 0.815)
SUFF++ for r=0.9 class 5 = 0.32 +- 0.072 (in-sample avg dev_std = 0.815)
SUFF++ for r=0.9 class 6 = 0.385 +- 0.072 (in-sample avg dev_std = 0.815)
SUFF++ for r=0.9 class 7 = 0.37 +- 0.072 (in-sample avg dev_std = 0.815)
SUFF++ for r=0.9 class 8 = 0.349 +- 0.072 (in-sample avg dev_std = 0.815)
SUFF++ for r=0.9 class 9 = 0.402 +- 0.072 (in-sample avg dev_std = 0.815)
SUFF++ for r=0.9 all KL = 0.062 +- 0.072 (in-sample avg dev_std = 0.815)
SUFF++ for r=0.9 all L1 = 0.367 +- 0.112 (in-sample avg dev_std = 0.815)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.095
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.09
NEC for r=0.3 class 0 = 0.372 +- 0.153 (in-sample avg dev_std = 0.226)
NEC for r=0.3 class 1 = 0.402 +- 0.153 (in-sample avg dev_std = 0.226)
NEC for r=0.3 class 2 = 0.399 +- 0.153 (in-sample avg dev_std = 0.226)
NEC for r=0.3 class 3 = 0.395 +- 0.153 (in-sample avg dev_std = 0.226)
NEC for r=0.3 class 4 = 0.427 +- 0.153 (in-sample avg dev_std = 0.226)
NEC for r=0.3 class 5 = 0.396 +- 0.153 (in-sample avg dev_std = 0.226)
NEC for r=0.3 class 6 = 0.415 +- 0.153 (in-sample avg dev_std = 0.226)
NEC for r=0.3 class 7 = 0.434 +- 0.153 (in-sample avg dev_std = 0.226)
NEC for r=0.3 class 8 = 0.386 +- 0.153 (in-sample avg dev_std = 0.226)
NEC for r=0.3 class 9 = 0.398 +- 0.153 (in-sample avg dev_std = 0.226)
NEC for r=0.3 all KL = 0.244 +- 0.153 (in-sample avg dev_std = 0.226)
NEC for r=0.3 all L1 = 0.403 +- 0.130 (in-sample avg dev_std = 0.226)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.365
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.382
NEC for r=0.6 class 0 = 0.53 +- 0.255 (in-sample avg dev_std = 0.350)
NEC for r=0.6 class 1 = 0.367 +- 0.255 (in-sample avg dev_std = 0.350)
NEC for r=0.6 class 2 = 0.614 +- 0.255 (in-sample avg dev_std = 0.350)
NEC for r=0.6 class 3 = 0.645 +- 0.255 (in-sample avg dev_std = 0.350)
NEC for r=0.6 class 4 = 0.516 +- 0.255 (in-sample avg dev_std = 0.350)
NEC for r=0.6 class 5 = 0.607 +- 0.255 (in-sample avg dev_std = 0.350)
NEC for r=0.6 class 6 = 0.472 +- 0.255 (in-sample avg dev_std = 0.350)
NEC for r=0.6 class 7 = 0.416 +- 0.255 (in-sample avg dev_std = 0.350)
NEC for r=0.6 class 8 = 0.647 +- 0.255 (in-sample avg dev_std = 0.350)
NEC for r=0.6 class 9 = 0.534 +- 0.255 (in-sample avg dev_std = 0.350)
NEC for r=0.6 all KL = 0.525 +- 0.255 (in-sample avg dev_std = 0.350)
NEC for r=0.6 all L1 = 0.532 +- 0.185 (in-sample avg dev_std = 0.350)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.376
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.476
NEC for r=0.9 class 0 = 0.51 +- 0.296 (in-sample avg dev_std = 0.368)
NEC for r=0.9 class 1 = 0.071 +- 0.296 (in-sample avg dev_std = 0.368)
NEC for r=0.9 class 2 = 0.633 +- 0.296 (in-sample avg dev_std = 0.368)
NEC for r=0.9 class 3 = 0.646 +- 0.296 (in-sample avg dev_std = 0.368)
NEC for r=0.9 class 4 = 0.526 +- 0.296 (in-sample avg dev_std = 0.368)
NEC for r=0.9 class 5 = 0.607 +- 0.296 (in-sample avg dev_std = 0.368)
NEC for r=0.9 class 6 = 0.395 +- 0.296 (in-sample avg dev_std = 0.368)
NEC for r=0.9 class 7 = 0.457 +- 0.296 (in-sample avg dev_std = 0.368)
NEC for r=0.9 class 8 = 0.645 +- 0.296 (in-sample avg dev_std = 0.368)
NEC for r=0.9 class 9 = 0.536 +- 0.296 (in-sample avg dev_std = 0.368)
NEC for r=0.9 all KL = 0.503 +- 0.296 (in-sample avg dev_std = 0.368)
NEC for r=0.9 all L1 = 0.496 +- 0.237 (in-sample avg dev_std = 0.368)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.37
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.477
NEC for r=1.0 class 0 = 0.506 +- 0.297 (in-sample avg dev_std = 0.365)
NEC for r=1.0 class 1 = 0.064 +- 0.297 (in-sample avg dev_std = 0.365)
NEC for r=1.0 class 2 = 0.637 +- 0.297 (in-sample avg dev_std = 0.365)
NEC for r=1.0 class 3 = 0.632 +- 0.297 (in-sample avg dev_std = 0.365)
NEC for r=1.0 class 4 = 0.535 +- 0.297 (in-sample avg dev_std = 0.365)
NEC for r=1.0 class 5 = 0.607 +- 0.297 (in-sample avg dev_std = 0.365)
NEC for r=1.0 class 6 = 0.406 +- 0.297 (in-sample avg dev_std = 0.365)
NEC for r=1.0 class 7 = 0.462 +- 0.297 (in-sample avg dev_std = 0.365)
NEC for r=1.0 class 8 = 0.653 +- 0.297 (in-sample avg dev_std = 0.365)
NEC for r=1.0 class 9 = 0.53 +- 0.297 (in-sample avg dev_std = 0.365)
NEC for r=1.0 all KL = 0.505 +- 0.297 (in-sample avg dev_std = 0.365)
NEC for r=1.0 all L1 = 0.497 +- 0.239 (in-sample avg dev_std = 0.365)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.097
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.096
NEC for r=0.3 class 0 = 0.326 +- 0.147 (in-sample avg dev_std = 0.166)
NEC for r=0.3 class 1 = 0.34 +- 0.147 (in-sample avg dev_std = 0.166)
NEC for r=0.3 class 2 = 0.32 +- 0.147 (in-sample avg dev_std = 0.166)
NEC for r=0.3 class 3 = 0.319 +- 0.147 (in-sample avg dev_std = 0.166)
NEC for r=0.3 class 4 = 0.314 +- 0.147 (in-sample avg dev_std = 0.166)
NEC for r=0.3 class 5 = 0.332 +- 0.147 (in-sample avg dev_std = 0.166)
NEC for r=0.3 class 6 = 0.332 +- 0.147 (in-sample avg dev_std = 0.166)
NEC for r=0.3 class 7 = 0.298 +- 0.147 (in-sample avg dev_std = 0.166)
NEC for r=0.3 class 8 = 0.338 +- 0.147 (in-sample avg dev_std = 0.166)
NEC for r=0.3 class 9 = 0.332 +- 0.147 (in-sample avg dev_std = 0.166)
NEC for r=0.3 all KL = 0.197 +- 0.147 (in-sample avg dev_std = 0.166)
NEC for r=0.3 all L1 = 0.325 +- 0.147 (in-sample avg dev_std = 0.166)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.205
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.2
NEC for r=0.6 class 0 = 0.619 +- 0.234 (in-sample avg dev_std = 0.332)
NEC for r=0.6 class 1 = 0.416 +- 0.234 (in-sample avg dev_std = 0.332)
NEC for r=0.6 class 2 = 0.578 +- 0.234 (in-sample avg dev_std = 0.332)
NEC for r=0.6 class 3 = 0.592 +- 0.234 (in-sample avg dev_std = 0.332)
NEC for r=0.6 class 4 = 0.541 +- 0.234 (in-sample avg dev_std = 0.332)
NEC for r=0.6 class 5 = 0.581 +- 0.234 (in-sample avg dev_std = 0.332)
NEC for r=0.6 class 6 = 0.544 +- 0.234 (in-sample avg dev_std = 0.332)
NEC for r=0.6 class 7 = 0.515 +- 0.234 (in-sample avg dev_std = 0.332)
NEC for r=0.6 class 8 = 0.579 +- 0.234 (in-sample avg dev_std = 0.332)
NEC for r=0.6 class 9 = 0.532 +- 0.234 (in-sample avg dev_std = 0.332)
NEC for r=0.6 all KL = 0.533 +- 0.234 (in-sample avg dev_std = 0.332)
NEC for r=0.6 all L1 = 0.548 +- 0.159 (in-sample avg dev_std = 0.332)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.125
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.159
NEC for r=0.9 class 0 = 0.547 +- 0.376 (in-sample avg dev_std = 0.270)
NEC for r=0.9 class 1 = 0.025 +- 0.376 (in-sample avg dev_std = 0.270)
NEC for r=0.9 class 2 = 0.502 +- 0.376 (in-sample avg dev_std = 0.270)
NEC for r=0.9 class 3 = 0.452 +- 0.376 (in-sample avg dev_std = 0.270)
NEC for r=0.9 class 4 = 0.228 +- 0.376 (in-sample avg dev_std = 0.270)
NEC for r=0.9 class 5 = 0.446 +- 0.376 (in-sample avg dev_std = 0.270)
NEC for r=0.9 class 6 = 0.258 +- 0.376 (in-sample avg dev_std = 0.270)
NEC for r=0.9 class 7 = 0.253 +- 0.376 (in-sample avg dev_std = 0.270)
NEC for r=0.9 class 8 = 0.323 +- 0.376 (in-sample avg dev_std = 0.270)
NEC for r=0.9 class 9 = 0.141 +- 0.376 (in-sample avg dev_std = 0.270)
NEC for r=0.9 all KL = 0.35 +- 0.376 (in-sample avg dev_std = 0.270)
NEC for r=0.9 all L1 = 0.316 +- 0.317 (in-sample avg dev_std = 0.270)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.125
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.154
NEC for r=1.0 class 0 = 0.512 +- 0.374 (in-sample avg dev_std = 0.280)
NEC for r=1.0 class 1 = 0.027 +- 0.374 (in-sample avg dev_std = 0.280)
NEC for r=1.0 class 2 = 0.476 +- 0.374 (in-sample avg dev_std = 0.280)
NEC for r=1.0 class 3 = 0.428 +- 0.374 (in-sample avg dev_std = 0.280)
NEC for r=1.0 class 4 = 0.201 +- 0.374 (in-sample avg dev_std = 0.280)
NEC for r=1.0 class 5 = 0.433 +- 0.374 (in-sample avg dev_std = 0.280)
NEC for r=1.0 class 6 = 0.22 +- 0.374 (in-sample avg dev_std = 0.280)
NEC for r=1.0 class 7 = 0.222 +- 0.374 (in-sample avg dev_std = 0.280)
NEC for r=1.0 class 8 = 0.303 +- 0.374 (in-sample avg dev_std = 0.280)
NEC for r=1.0 class 9 = 0.13 +- 0.374 (in-sample avg dev_std = 0.280)
NEC for r=1.0 all KL = 0.324 +- 0.374 (in-sample avg dev_std = 0.280)
NEC for r=1.0 all L1 = 0.293 +- 0.313 (in-sample avg dev_std = 0.280)
model_dirname= repr_GSATvGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 16:44:19 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:19 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 04:44:20 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 122...
[0m[1;37mINFO[0m: [1mCheckpoint 122: 
-----------------------------------
Train ACCURACY: 0.3702
Train Loss: 2.3948
ID Validation ACCURACY: 0.3736
ID Validation Loss: 2.4069
ID Test ACCURACY: 0.3700
ID Test Loss: 2.3785
OOD Validation ACCURACY: 0.3041
OOD Validation Loss: 3.5447
OOD Test ACCURACY: 0.1954
OOD Test Loss: 4.7312

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 89...
[0m[1;37mINFO[0m: [1mCheckpoint 89: 
-----------------------------------
Train ACCURACY: 0.3683
Train Loss: 2.2729
ID Validation ACCURACY: 0.3709
ID Validation Loss: 2.2640
ID Test ACCURACY: 0.3723
ID Test Loss: 2.2745
OOD Validation ACCURACY: 0.3600
OOD Validation Loss: 2.5562
OOD Test ACCURACY: 0.2007
OOD Test Loss: 5.9838

[0m[1;37mINFO[0m: [1mChartInfo 0.3700 0.1954 0.3723 0.2007 0.3709 0.3600[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.099
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.092
SUFF++ for r=0.3 class 0 = 0.455 +- 0.195 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.3 class 1 = 0.386 +- 0.195 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.3 class 2 = 0.444 +- 0.195 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.3 class 3 = 0.432 +- 0.195 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.3 class 4 = 0.419 +- 0.195 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.3 class 5 = 0.471 +- 0.195 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.3 class 6 = 0.428 +- 0.195 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.3 class 7 = 0.413 +- 0.195 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.3 class 8 = 0.432 +- 0.195 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.3 class 9 = 0.421 +- 0.195 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.3 all KL = 0.379 +- 0.195 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.3 all L1 = 0.429 +- 0.101 (in-sample avg dev_std = 0.507)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.329
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.198
SUFF++ for r=0.6 class 0 = 0.291 +- 0.182 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.6 class 1 = 0.273 +- 0.182 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.6 class 2 = 0.271 +- 0.182 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.6 class 3 = 0.26 +- 0.182 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.6 class 4 = 0.344 +- 0.182 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.6 class 5 = 0.284 +- 0.182 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.6 class 6 = 0.287 +- 0.182 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.6 class 7 = 0.288 +- 0.182 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.6 class 8 = 0.287 +- 0.182 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.6 class 9 = 0.309 +- 0.182 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.6 all KL = 0.189 +- 0.182 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.6 all L1 = 0.288 +- 0.099 (in-sample avg dev_std = 0.503)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.37
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.264
SUFF++ for r=0.9 class 0 = 0.303 +- 0.282 (in-sample avg dev_std = 0.538)
SUFF++ for r=0.9 class 1 = 0.354 +- 0.282 (in-sample avg dev_std = 0.538)
SUFF++ for r=0.9 class 2 = 0.374 +- 0.282 (in-sample avg dev_std = 0.538)
SUFF++ for r=0.9 class 3 = 0.321 +- 0.282 (in-sample avg dev_std = 0.538)
SUFF++ for r=0.9 class 4 = 0.58 +- 0.282 (in-sample avg dev_std = 0.538)
SUFF++ for r=0.9 class 5 = 0.381 +- 0.282 (in-sample avg dev_std = 0.538)
SUFF++ for r=0.9 class 6 = 0.41 +- 0.282 (in-sample avg dev_std = 0.538)
SUFF++ for r=0.9 class 7 = 0.424 +- 0.282 (in-sample avg dev_std = 0.538)
SUFF++ for r=0.9 class 8 = 0.361 +- 0.282 (in-sample avg dev_std = 0.538)
SUFF++ for r=0.9 class 9 = 0.47 +- 0.282 (in-sample avg dev_std = 0.538)
SUFF++ for r=0.9 all KL = 0.334 +- 0.282 (in-sample avg dev_std = 0.538)
SUFF++ for r=0.9 all L1 = 0.396 +- 0.183 (in-sample avg dev_std = 0.538)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.087
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.094
SUFF++ for r=0.3 class 0 = 0.512 +- 0.177 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.3 class 1 = 0.427 +- 0.177 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.3 class 2 = 0.507 +- 0.177 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.3 class 3 = 0.494 +- 0.177 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.3 class 4 = 0.495 +- 0.177 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.3 class 5 = 0.482 +- 0.177 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.3 class 6 = 0.505 +- 0.177 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.3 class 7 = 0.52 +- 0.177 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.3 class 8 = 0.479 +- 0.177 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.3 class 9 = 0.468 +- 0.177 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.3 all KL = 0.386 +- 0.177 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.3 all L1 = 0.488 +- 0.119 (in-sample avg dev_std = 0.509)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.145
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.129
SUFF++ for r=0.6 class 0 = 0.254 +- 0.091 (in-sample avg dev_std = 0.638)
SUFF++ for r=0.6 class 1 = 0.268 +- 0.091 (in-sample avg dev_std = 0.638)
SUFF++ for r=0.6 class 2 = 0.258 +- 0.091 (in-sample avg dev_std = 0.638)
SUFF++ for r=0.6 class 3 = 0.263 +- 0.091 (in-sample avg dev_std = 0.638)
SUFF++ for r=0.6 class 4 = 0.28 +- 0.091 (in-sample avg dev_std = 0.638)
SUFF++ for r=0.6 class 5 = 0.269 +- 0.091 (in-sample avg dev_std = 0.638)
SUFF++ for r=0.6 class 6 = 0.273 +- 0.091 (in-sample avg dev_std = 0.638)
SUFF++ for r=0.6 class 7 = 0.277 +- 0.091 (in-sample avg dev_std = 0.638)
SUFF++ for r=0.6 class 8 = 0.267 +- 0.091 (in-sample avg dev_std = 0.638)
SUFF++ for r=0.6 class 9 = 0.273 +- 0.091 (in-sample avg dev_std = 0.638)
SUFF++ for r=0.6 all KL = 0.105 +- 0.091 (in-sample avg dev_std = 0.638)
SUFF++ for r=0.6 all L1 = 0.268 +- 0.046 (in-sample avg dev_std = 0.638)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.204
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.13
SUFF++ for r=0.9 class 0 = 0.282 +- 0.066 (in-sample avg dev_std = 0.723)
SUFF++ for r=0.9 class 1 = 0.363 +- 0.066 (in-sample avg dev_std = 0.723)
SUFF++ for r=0.9 class 2 = 0.27 +- 0.066 (in-sample avg dev_std = 0.723)
SUFF++ for r=0.9 class 3 = 0.272 +- 0.066 (in-sample avg dev_std = 0.723)
SUFF++ for r=0.9 class 4 = 0.286 +- 0.066 (in-sample avg dev_std = 0.723)
SUFF++ for r=0.9 class 5 = 0.282 +- 0.066 (in-sample avg dev_std = 0.723)
SUFF++ for r=0.9 class 6 = 0.299 +- 0.066 (in-sample avg dev_std = 0.723)
SUFF++ for r=0.9 class 7 = 0.291 +- 0.066 (in-sample avg dev_std = 0.723)
SUFF++ for r=0.9 class 8 = 0.299 +- 0.066 (in-sample avg dev_std = 0.723)
SUFF++ for r=0.9 class 9 = 0.311 +- 0.066 (in-sample avg dev_std = 0.723)
SUFF++ for r=0.9 all KL = 0.049 +- 0.066 (in-sample avg dev_std = 0.723)
SUFF++ for r=0.9 all L1 = 0.296 +- 0.071 (in-sample avg dev_std = 0.723)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.099
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.085
NEC for r=0.3 class 0 = 0.366 +- 0.180 (in-sample avg dev_std = 0.207)
NEC for r=0.3 class 1 = 0.429 +- 0.180 (in-sample avg dev_std = 0.207)
NEC for r=0.3 class 2 = 0.365 +- 0.180 (in-sample avg dev_std = 0.207)
NEC for r=0.3 class 3 = 0.355 +- 0.180 (in-sample avg dev_std = 0.207)
NEC for r=0.3 class 4 = 0.425 +- 0.180 (in-sample avg dev_std = 0.207)
NEC for r=0.3 class 5 = 0.364 +- 0.180 (in-sample avg dev_std = 0.207)
NEC for r=0.3 class 6 = 0.427 +- 0.180 (in-sample avg dev_std = 0.207)
NEC for r=0.3 class 7 = 0.416 +- 0.180 (in-sample avg dev_std = 0.207)
NEC for r=0.3 class 8 = 0.354 +- 0.180 (in-sample avg dev_std = 0.207)
NEC for r=0.3 class 9 = 0.436 +- 0.180 (in-sample avg dev_std = 0.207)
NEC for r=0.3 all KL = 0.28 +- 0.180 (in-sample avg dev_std = 0.207)
NEC for r=0.3 all L1 = 0.394 +- 0.163 (in-sample avg dev_std = 0.207)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.329
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.32
NEC for r=0.6 class 0 = 0.628 +- 0.219 (in-sample avg dev_std = 0.356)
NEC for r=0.6 class 1 = 0.489 +- 0.219 (in-sample avg dev_std = 0.356)
NEC for r=0.6 class 2 = 0.628 +- 0.219 (in-sample avg dev_std = 0.356)
NEC for r=0.6 class 3 = 0.64 +- 0.219 (in-sample avg dev_std = 0.356)
NEC for r=0.6 class 4 = 0.561 +- 0.219 (in-sample avg dev_std = 0.356)
NEC for r=0.6 class 5 = 0.622 +- 0.219 (in-sample avg dev_std = 0.356)
NEC for r=0.6 class 6 = 0.649 +- 0.219 (in-sample avg dev_std = 0.356)
NEC for r=0.6 class 7 = 0.611 +- 0.219 (in-sample avg dev_std = 0.356)
NEC for r=0.6 class 8 = 0.619 +- 0.219 (in-sample avg dev_std = 0.356)
NEC for r=0.6 class 9 = 0.617 +- 0.219 (in-sample avg dev_std = 0.356)
NEC for r=0.6 all KL = 0.62 +- 0.219 (in-sample avg dev_std = 0.356)
NEC for r=0.6 all L1 = 0.605 +- 0.142 (in-sample avg dev_std = 0.356)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.37
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.438
NEC for r=0.9 class 0 = 0.579 +- 0.282 (in-sample avg dev_std = 0.372)
NEC for r=0.9 class 1 = 0.157 +- 0.282 (in-sample avg dev_std = 0.372)
NEC for r=0.9 class 2 = 0.592 +- 0.282 (in-sample avg dev_std = 0.372)
NEC for r=0.9 class 3 = 0.64 +- 0.282 (in-sample avg dev_std = 0.372)
NEC for r=0.9 class 4 = 0.428 +- 0.282 (in-sample avg dev_std = 0.372)
NEC for r=0.9 class 5 = 0.594 +- 0.282 (in-sample avg dev_std = 0.372)
NEC for r=0.9 class 6 = 0.653 +- 0.282 (in-sample avg dev_std = 0.372)
NEC for r=0.9 class 7 = 0.583 +- 0.282 (in-sample avg dev_std = 0.372)
NEC for r=0.9 class 8 = 0.65 +- 0.282 (in-sample avg dev_std = 0.372)
NEC for r=0.9 class 9 = 0.553 +- 0.282 (in-sample avg dev_std = 0.372)
NEC for r=0.9 all KL = 0.558 +- 0.282 (in-sample avg dev_std = 0.372)
NEC for r=0.9 all L1 = 0.538 +- 0.224 (in-sample avg dev_std = 0.372)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.373
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.442
NEC for r=1.0 class 0 = 0.558 +- 0.286 (in-sample avg dev_std = 0.377)
NEC for r=1.0 class 1 = 0.113 +- 0.286 (in-sample avg dev_std = 0.377)
NEC for r=1.0 class 2 = 0.596 +- 0.286 (in-sample avg dev_std = 0.377)
NEC for r=1.0 class 3 = 0.651 +- 0.286 (in-sample avg dev_std = 0.377)
NEC for r=1.0 class 4 = 0.405 +- 0.286 (in-sample avg dev_std = 0.377)
NEC for r=1.0 class 5 = 0.597 +- 0.286 (in-sample avg dev_std = 0.377)
NEC for r=1.0 class 6 = 0.635 +- 0.286 (in-sample avg dev_std = 0.377)
NEC for r=1.0 class 7 = 0.578 +- 0.286 (in-sample avg dev_std = 0.377)
NEC for r=1.0 class 8 = 0.655 +- 0.286 (in-sample avg dev_std = 0.377)
NEC for r=1.0 class 9 = 0.566 +- 0.286 (in-sample avg dev_std = 0.377)
NEC for r=1.0 all KL = 0.549 +- 0.286 (in-sample avg dev_std = 0.377)
NEC for r=1.0 all L1 = 0.53 +- 0.231 (in-sample avg dev_std = 0.377)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.087
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.094
NEC for r=0.3 class 0 = 0.266 +- 0.144 (in-sample avg dev_std = 0.140)
NEC for r=0.3 class 1 = 0.356 +- 0.144 (in-sample avg dev_std = 0.140)
NEC for r=0.3 class 2 = 0.255 +- 0.144 (in-sample avg dev_std = 0.140)
NEC for r=0.3 class 3 = 0.287 +- 0.144 (in-sample avg dev_std = 0.140)
NEC for r=0.3 class 4 = 0.3 +- 0.144 (in-sample avg dev_std = 0.140)
NEC for r=0.3 class 5 = 0.312 +- 0.144 (in-sample avg dev_std = 0.140)
NEC for r=0.3 class 6 = 0.259 +- 0.144 (in-sample avg dev_std = 0.140)
NEC for r=0.3 class 7 = 0.269 +- 0.144 (in-sample avg dev_std = 0.140)
NEC for r=0.3 class 8 = 0.285 +- 0.144 (in-sample avg dev_std = 0.140)
NEC for r=0.3 class 9 = 0.345 +- 0.144 (in-sample avg dev_std = 0.140)
NEC for r=0.3 all KL = 0.168 +- 0.144 (in-sample avg dev_std = 0.140)
NEC for r=0.3 all L1 = 0.293 +- 0.168 (in-sample avg dev_std = 0.140)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.145
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.159
NEC for r=0.6 class 0 = 0.573 +- 0.217 (in-sample avg dev_std = 0.307)
NEC for r=0.6 class 1 = 0.47 +- 0.217 (in-sample avg dev_std = 0.307)
NEC for r=0.6 class 2 = 0.565 +- 0.217 (in-sample avg dev_std = 0.307)
NEC for r=0.6 class 3 = 0.557 +- 0.217 (in-sample avg dev_std = 0.307)
NEC for r=0.6 class 4 = 0.524 +- 0.217 (in-sample avg dev_std = 0.307)
NEC for r=0.6 class 5 = 0.541 +- 0.217 (in-sample avg dev_std = 0.307)
NEC for r=0.6 class 6 = 0.526 +- 0.217 (in-sample avg dev_std = 0.307)
NEC for r=0.6 class 7 = 0.501 +- 0.217 (in-sample avg dev_std = 0.307)
NEC for r=0.6 class 8 = 0.549 +- 0.217 (in-sample avg dev_std = 0.307)
NEC for r=0.6 class 9 = 0.539 +- 0.217 (in-sample avg dev_std = 0.307)
NEC for r=0.6 all KL = 0.478 +- 0.217 (in-sample avg dev_std = 0.307)
NEC for r=0.6 all L1 = 0.534 +- 0.131 (in-sample avg dev_std = 0.307)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.204
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.196
NEC for r=0.9 class 0 = 0.554 +- 0.277 (in-sample avg dev_std = 0.363)
NEC for r=0.9 class 1 = 0.394 +- 0.277 (in-sample avg dev_std = 0.363)
NEC for r=0.9 class 2 = 0.649 +- 0.277 (in-sample avg dev_std = 0.363)
NEC for r=0.9 class 3 = 0.585 +- 0.277 (in-sample avg dev_std = 0.363)
NEC for r=0.9 class 4 = 0.556 +- 0.277 (in-sample avg dev_std = 0.363)
NEC for r=0.9 class 5 = 0.584 +- 0.277 (in-sample avg dev_std = 0.363)
NEC for r=0.9 class 6 = 0.522 +- 0.277 (in-sample avg dev_std = 0.363)
NEC for r=0.9 class 7 = 0.532 +- 0.277 (in-sample avg dev_std = 0.363)
NEC for r=0.9 class 8 = 0.499 +- 0.277 (in-sample avg dev_std = 0.363)
NEC for r=0.9 class 9 = 0.451 +- 0.277 (in-sample avg dev_std = 0.363)
NEC for r=0.9 all KL = 0.533 +- 0.277 (in-sample avg dev_std = 0.363)
NEC for r=0.9 all L1 = 0.531 +- 0.207 (in-sample avg dev_std = 0.363)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.203
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.206
NEC for r=1.0 class 0 = 0.545 +- 0.277 (in-sample avg dev_std = 0.366)
NEC for r=1.0 class 1 = 0.399 +- 0.277 (in-sample avg dev_std = 0.366)
NEC for r=1.0 class 2 = 0.637 +- 0.277 (in-sample avg dev_std = 0.366)
NEC for r=1.0 class 3 = 0.591 +- 0.277 (in-sample avg dev_std = 0.366)
NEC for r=1.0 class 4 = 0.563 +- 0.277 (in-sample avg dev_std = 0.366)
NEC for r=1.0 class 5 = 0.58 +- 0.277 (in-sample avg dev_std = 0.366)
NEC for r=1.0 class 6 = 0.542 +- 0.277 (in-sample avg dev_std = 0.366)
NEC for r=1.0 class 7 = 0.54 +- 0.277 (in-sample avg dev_std = 0.366)
NEC for r=1.0 class 8 = 0.47 +- 0.277 (in-sample avg dev_std = 0.366)
NEC for r=1.0 class 9 = 0.449 +- 0.277 (in-sample avg dev_std = 0.366)
NEC for r=1.0 all KL = 0.535 +- 0.277 (in-sample avg dev_std = 0.366)
NEC for r=1.0 all L1 = 0.53 +- 0.207 (in-sample avg dev_std = 0.366)
model_dirname= repr_GSATvGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 16:58:51 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:52 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:52 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:52 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 04:58:53 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 117...
[0m[1;37mINFO[0m: [1mCheckpoint 117: 
-----------------------------------
Train ACCURACY: 0.3583
Train Loss: 2.8367
ID Validation ACCURACY: 0.3623
ID Validation Loss: 2.7968
ID Test ACCURACY: 0.3581
ID Test Loss: 2.8314
OOD Validation ACCURACY: 0.2664
OOD Validation Loss: 3.6291
OOD Test ACCURACY: 0.0890
OOD Test Loss: 8.5138

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 92...
[0m[1;37mINFO[0m: [1mCheckpoint 92: 
-----------------------------------
Train ACCURACY: 0.3441
Train Loss: 2.6872
ID Validation ACCURACY: 0.3500
ID Validation Loss: 2.6571
ID Test ACCURACY: 0.3510
ID Test Loss: 2.7061
OOD Validation ACCURACY: 0.3161
OOD Validation Loss: 2.9417
OOD Test ACCURACY: 0.1553
OOD Test Loss: 3.9643

[0m[1;37mINFO[0m: [1mChartInfo 0.3581 0.0890 0.3510 0.1553 0.3500 0.3161[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.083
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.082
SUFF++ for r=0.3 class 0 = 0.415 +- 0.193 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.3 class 1 = 0.457 +- 0.193 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.3 class 2 = 0.453 +- 0.193 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.3 class 3 = 0.469 +- 0.193 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.3 class 4 = 0.472 +- 0.193 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.3 class 5 = 0.473 +- 0.193 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.3 class 6 = 0.501 +- 0.193 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.3 class 7 = 0.482 +- 0.193 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.3 class 8 = 0.477 +- 0.193 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.3 class 9 = 0.505 +- 0.193 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.3 all KL = 0.528 +- 0.193 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.3 all L1 = 0.47 +- 0.114 (in-sample avg dev_std = 0.448)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.31
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.207
SUFF++ for r=0.6 class 0 = 0.293 +- 0.216 (in-sample avg dev_std = 0.528)
SUFF++ for r=0.6 class 1 = 0.283 +- 0.216 (in-sample avg dev_std = 0.528)
SUFF++ for r=0.6 class 2 = 0.334 +- 0.216 (in-sample avg dev_std = 0.528)
SUFF++ for r=0.6 class 3 = 0.31 +- 0.216 (in-sample avg dev_std = 0.528)
SUFF++ for r=0.6 class 4 = 0.4 +- 0.216 (in-sample avg dev_std = 0.528)
SUFF++ for r=0.6 class 5 = 0.365 +- 0.216 (in-sample avg dev_std = 0.528)
SUFF++ for r=0.6 class 6 = 0.34 +- 0.216 (in-sample avg dev_std = 0.528)
SUFF++ for r=0.6 class 7 = 0.314 +- 0.216 (in-sample avg dev_std = 0.528)
SUFF++ for r=0.6 class 8 = 0.326 +- 0.216 (in-sample avg dev_std = 0.528)
SUFF++ for r=0.6 class 9 = 0.345 +- 0.216 (in-sample avg dev_std = 0.528)
SUFF++ for r=0.6 all KL = 0.273 +- 0.216 (in-sample avg dev_std = 0.528)
SUFF++ for r=0.6 all L1 = 0.329 +- 0.114 (in-sample avg dev_std = 0.528)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.349
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.268
SUFF++ for r=0.9 class 0 = 0.355 +- 0.260 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.9 class 1 = 0.335 +- 0.260 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.9 class 2 = 0.354 +- 0.260 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.9 class 3 = 0.386 +- 0.260 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.9 class 4 = 0.398 +- 0.260 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.9 class 5 = 0.394 +- 0.260 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.9 class 6 = 0.438 +- 0.260 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.9 class 7 = 0.375 +- 0.260 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.9 class 8 = 0.427 +- 0.260 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.9 class 9 = 0.544 +- 0.260 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.9 all KL = 0.33 +- 0.260 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.9 all L1 = 0.398 +- 0.158 (in-sample avg dev_std = 0.542)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.105
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.092
SUFF++ for r=0.3 class 0 = 0.461 +- 0.233 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.3 class 1 = 0.554 +- 0.233 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.3 class 2 = 0.421 +- 0.233 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.3 class 3 = 0.419 +- 0.233 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.3 class 4 = 0.42 +- 0.233 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.3 class 5 = 0.427 +- 0.233 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.3 class 6 = 0.45 +- 0.233 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.3 class 7 = 0.421 +- 0.233 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.3 class 8 = 0.44 +- 0.233 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.3 class 9 = 0.458 +- 0.233 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.3 all KL = 0.519 +- 0.233 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.3 all L1 = 0.449 +- 0.150 (in-sample avg dev_std = 0.365)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.279
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.145
SUFF++ for r=0.6 class 0 = 0.236 +- 0.128 (in-sample avg dev_std = 0.526)
SUFF++ for r=0.6 class 1 = 0.271 +- 0.128 (in-sample avg dev_std = 0.526)
SUFF++ for r=0.6 class 2 = 0.256 +- 0.128 (in-sample avg dev_std = 0.526)
SUFF++ for r=0.6 class 3 = 0.254 +- 0.128 (in-sample avg dev_std = 0.526)
SUFF++ for r=0.6 class 4 = 0.257 +- 0.128 (in-sample avg dev_std = 0.526)
SUFF++ for r=0.6 class 5 = 0.242 +- 0.128 (in-sample avg dev_std = 0.526)
SUFF++ for r=0.6 class 6 = 0.243 +- 0.128 (in-sample avg dev_std = 0.526)
SUFF++ for r=0.6 class 7 = 0.25 +- 0.128 (in-sample avg dev_std = 0.526)
SUFF++ for r=0.6 class 8 = 0.229 +- 0.128 (in-sample avg dev_std = 0.526)
SUFF++ for r=0.6 class 9 = 0.239 +- 0.128 (in-sample avg dev_std = 0.526)
SUFF++ for r=0.6 all KL = 0.124 +- 0.128 (in-sample avg dev_std = 0.526)
SUFF++ for r=0.6 all L1 = 0.248 +- 0.065 (in-sample avg dev_std = 0.526)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.111
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.137
SUFF++ for r=0.9 class 0 = 0.23 +- 0.105 (in-sample avg dev_std = 0.511)
SUFF++ for r=0.9 class 1 = 0.298 +- 0.105 (in-sample avg dev_std = 0.511)
SUFF++ for r=0.9 class 2 = 0.228 +- 0.105 (in-sample avg dev_std = 0.511)
SUFF++ for r=0.9 class 3 = 0.258 +- 0.105 (in-sample avg dev_std = 0.511)
SUFF++ for r=0.9 class 4 = 0.261 +- 0.105 (in-sample avg dev_std = 0.511)
SUFF++ for r=0.9 class 5 = 0.253 +- 0.105 (in-sample avg dev_std = 0.511)
SUFF++ for r=0.9 class 6 = 0.249 +- 0.105 (in-sample avg dev_std = 0.511)
SUFF++ for r=0.9 class 7 = 0.249 +- 0.105 (in-sample avg dev_std = 0.511)
SUFF++ for r=0.9 class 8 = 0.253 +- 0.105 (in-sample avg dev_std = 0.511)
SUFF++ for r=0.9 class 9 = 0.268 +- 0.105 (in-sample avg dev_std = 0.511)
SUFF++ for r=0.9 all KL = 0.117 +- 0.105 (in-sample avg dev_std = 0.511)
SUFF++ for r=0.9 all L1 = 0.255 +- 0.079 (in-sample avg dev_std = 0.511)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.083
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.071
NEC for r=0.3 class 0 = 0.411 +- 0.164 (in-sample avg dev_std = 0.251)
NEC for r=0.3 class 1 = 0.39 +- 0.164 (in-sample avg dev_std = 0.251)
NEC for r=0.3 class 2 = 0.405 +- 0.164 (in-sample avg dev_std = 0.251)
NEC for r=0.3 class 3 = 0.377 +- 0.164 (in-sample avg dev_std = 0.251)
NEC for r=0.3 class 4 = 0.382 +- 0.164 (in-sample avg dev_std = 0.251)
NEC for r=0.3 class 5 = 0.406 +- 0.164 (in-sample avg dev_std = 0.251)
NEC for r=0.3 class 6 = 0.376 +- 0.164 (in-sample avg dev_std = 0.251)
NEC for r=0.3 class 7 = 0.387 +- 0.164 (in-sample avg dev_std = 0.251)
NEC for r=0.3 class 8 = 0.393 +- 0.164 (in-sample avg dev_std = 0.251)
NEC for r=0.3 class 9 = 0.398 +- 0.164 (in-sample avg dev_std = 0.251)
NEC for r=0.3 all KL = 0.251 +- 0.164 (in-sample avg dev_std = 0.251)
NEC for r=0.3 all L1 = 0.392 +- 0.142 (in-sample avg dev_std = 0.251)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.31
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.33
NEC for r=0.6 class 0 = 0.594 +- 0.228 (in-sample avg dev_std = 0.345)
NEC for r=0.6 class 1 = 0.456 +- 0.228 (in-sample avg dev_std = 0.345)
NEC for r=0.6 class 2 = 0.555 +- 0.228 (in-sample avg dev_std = 0.345)
NEC for r=0.6 class 3 = 0.563 +- 0.228 (in-sample avg dev_std = 0.345)
NEC for r=0.6 class 4 = 0.498 +- 0.228 (in-sample avg dev_std = 0.345)
NEC for r=0.6 class 5 = 0.522 +- 0.228 (in-sample avg dev_std = 0.345)
NEC for r=0.6 class 6 = 0.474 +- 0.228 (in-sample avg dev_std = 0.345)
NEC for r=0.6 class 7 = 0.54 +- 0.228 (in-sample avg dev_std = 0.345)
NEC for r=0.6 class 8 = 0.558 +- 0.228 (in-sample avg dev_std = 0.345)
NEC for r=0.6 class 9 = 0.458 +- 0.228 (in-sample avg dev_std = 0.345)
NEC for r=0.6 all KL = 0.486 +- 0.228 (in-sample avg dev_std = 0.345)
NEC for r=0.6 all L1 = 0.522 +- 0.172 (in-sample avg dev_std = 0.345)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.349
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.421
NEC for r=0.9 class 0 = 0.45 +- 0.267 (in-sample avg dev_std = 0.358)
NEC for r=0.9 class 1 = 0.215 +- 0.267 (in-sample avg dev_std = 0.358)
NEC for r=0.9 class 2 = 0.601 +- 0.267 (in-sample avg dev_std = 0.358)
NEC for r=0.9 class 3 = 0.561 +- 0.267 (in-sample avg dev_std = 0.358)
NEC for r=0.9 class 4 = 0.493 +- 0.267 (in-sample avg dev_std = 0.358)
NEC for r=0.9 class 5 = 0.545 +- 0.267 (in-sample avg dev_std = 0.358)
NEC for r=0.9 class 6 = 0.486 +- 0.267 (in-sample avg dev_std = 0.358)
NEC for r=0.9 class 7 = 0.569 +- 0.267 (in-sample avg dev_std = 0.358)
NEC for r=0.9 class 8 = 0.578 +- 0.267 (in-sample avg dev_std = 0.358)
NEC for r=0.9 class 9 = 0.44 +- 0.267 (in-sample avg dev_std = 0.358)
NEC for r=0.9 all KL = 0.482 +- 0.267 (in-sample avg dev_std = 0.358)
NEC for r=0.9 all L1 = 0.491 +- 0.227 (in-sample avg dev_std = 0.358)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.35
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.43
NEC for r=1.0 class 0 = 0.463 +- 0.272 (in-sample avg dev_std = 0.359)
NEC for r=1.0 class 1 = 0.214 +- 0.272 (in-sample avg dev_std = 0.359)
NEC for r=1.0 class 2 = 0.604 +- 0.272 (in-sample avg dev_std = 0.359)
NEC for r=1.0 class 3 = 0.569 +- 0.272 (in-sample avg dev_std = 0.359)
NEC for r=1.0 class 4 = 0.503 +- 0.272 (in-sample avg dev_std = 0.359)
NEC for r=1.0 class 5 = 0.549 +- 0.272 (in-sample avg dev_std = 0.359)
NEC for r=1.0 class 6 = 0.508 +- 0.272 (in-sample avg dev_std = 0.359)
NEC for r=1.0 class 7 = 0.564 +- 0.272 (in-sample avg dev_std = 0.359)
NEC for r=1.0 class 8 = 0.583 +- 0.272 (in-sample avg dev_std = 0.359)
NEC for r=1.0 class 9 = 0.436 +- 0.272 (in-sample avg dev_std = 0.359)
NEC for r=1.0 all KL = 0.49 +- 0.272 (in-sample avg dev_std = 0.359)
NEC for r=1.0 all L1 = 0.497 +- 0.229 (in-sample avg dev_std = 0.359)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.105
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.095
NEC for r=0.3 class 0 = 0.452 +- 0.211 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 1 = 0.358 +- 0.211 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 2 = 0.479 +- 0.211 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 3 = 0.459 +- 0.211 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 4 = 0.466 +- 0.211 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 5 = 0.458 +- 0.211 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 6 = 0.439 +- 0.211 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 7 = 0.472 +- 0.211 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 8 = 0.458 +- 0.211 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 9 = 0.429 +- 0.211 (in-sample avg dev_std = 0.232)
NEC for r=0.3 all KL = 0.306 +- 0.211 (in-sample avg dev_std = 0.232)
NEC for r=0.3 all L1 = 0.446 +- 0.165 (in-sample avg dev_std = 0.232)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.279
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.225
NEC for r=0.6 class 0 = 0.667 +- 0.239 (in-sample avg dev_std = 0.319)
NEC for r=0.6 class 1 = 0.338 +- 0.239 (in-sample avg dev_std = 0.319)
NEC for r=0.6 class 2 = 0.6 +- 0.239 (in-sample avg dev_std = 0.319)
NEC for r=0.6 class 3 = 0.617 +- 0.239 (in-sample avg dev_std = 0.319)
NEC for r=0.6 class 4 = 0.627 +- 0.239 (in-sample avg dev_std = 0.319)
NEC for r=0.6 class 5 = 0.632 +- 0.239 (in-sample avg dev_std = 0.319)
NEC for r=0.6 class 6 = 0.629 +- 0.239 (in-sample avg dev_std = 0.319)
NEC for r=0.6 class 7 = 0.61 +- 0.239 (in-sample avg dev_std = 0.319)
NEC for r=0.6 class 8 = 0.669 +- 0.239 (in-sample avg dev_std = 0.319)
NEC for r=0.6 class 9 = 0.624 +- 0.239 (in-sample avg dev_std = 0.319)
NEC for r=0.6 all KL = 0.621 +- 0.239 (in-sample avg dev_std = 0.319)
NEC for r=0.6 all L1 = 0.598 +- 0.175 (in-sample avg dev_std = 0.319)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.111
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.175
NEC for r=0.9 class 0 = 0.712 +- 0.216 (in-sample avg dev_std = 0.284)
NEC for r=0.9 class 1 = 0.542 +- 0.216 (in-sample avg dev_std = 0.284)
NEC for r=0.9 class 2 = 0.698 +- 0.216 (in-sample avg dev_std = 0.284)
NEC for r=0.9 class 3 = 0.687 +- 0.216 (in-sample avg dev_std = 0.284)
NEC for r=0.9 class 4 = 0.661 +- 0.216 (in-sample avg dev_std = 0.284)
NEC for r=0.9 class 5 = 0.662 +- 0.216 (in-sample avg dev_std = 0.284)
NEC for r=0.9 class 6 = 0.702 +- 0.216 (in-sample avg dev_std = 0.284)
NEC for r=0.9 class 7 = 0.69 +- 0.216 (in-sample avg dev_std = 0.284)
NEC for r=0.9 class 8 = 0.672 +- 0.216 (in-sample avg dev_std = 0.284)
NEC for r=0.9 class 9 = 0.655 +- 0.216 (in-sample avg dev_std = 0.284)
NEC for r=0.9 all KL = 0.753 +- 0.216 (in-sample avg dev_std = 0.284)
NEC for r=0.9 all L1 = 0.667 +- 0.167 (in-sample avg dev_std = 0.284)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.111
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.154
NEC for r=1.0 class 0 = 0.7 +- 0.269 (in-sample avg dev_std = 0.303)
NEC for r=1.0 class 1 = 0.4 +- 0.269 (in-sample avg dev_std = 0.303)
NEC for r=1.0 class 2 = 0.705 +- 0.269 (in-sample avg dev_std = 0.303)
NEC for r=1.0 class 3 = 0.69 +- 0.269 (in-sample avg dev_std = 0.303)
NEC for r=1.0 class 4 = 0.673 +- 0.269 (in-sample avg dev_std = 0.303)
NEC for r=1.0 class 5 = 0.685 +- 0.269 (in-sample avg dev_std = 0.303)
NEC for r=1.0 class 6 = 0.709 +- 0.269 (in-sample avg dev_std = 0.303)
NEC for r=1.0 class 7 = 0.684 +- 0.269 (in-sample avg dev_std = 0.303)
NEC for r=1.0 class 8 = 0.697 +- 0.269 (in-sample avg dev_std = 0.303)
NEC for r=1.0 class 9 = 0.605 +- 0.269 (in-sample avg dev_std = 0.303)
NEC for r=1.0 all KL = 0.778 +- 0.269 (in-sample avg dev_std = 0.303)
NEC for r=1.0 all L1 = 0.652 +- 0.227 (in-sample avg dev_std = 0.303)
model_dirname= repr_GSATvGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 17:13:19 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:20 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:20 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:20 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 05:13:21 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 132...
[0m[1;37mINFO[0m: [1mCheckpoint 132: 
-----------------------------------
Train ACCURACY: 0.4007
Train Loss: 2.3333
ID Validation ACCURACY: 0.4061
ID Validation Loss: 2.3309
ID Test ACCURACY: 0.4066
ID Test Loss: 2.3205
OOD Validation ACCURACY: 0.2917
OOD Validation Loss: 3.8199
OOD Test ACCURACY: 0.1750
OOD Test Loss: 5.7772

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 185...
[0m[1;37mINFO[0m: [1mCheckpoint 185: 
-----------------------------------
Train ACCURACY: 0.3655
Train Loss: 2.5974
ID Validation ACCURACY: 0.3697
ID Validation Loss: 2.5964
ID Test ACCURACY: 0.3650
ID Test Loss: 2.6426
OOD Validation ACCURACY: 0.3343
OOD Validation Loss: 3.2134
OOD Test ACCURACY: 0.1420
OOD Test Loss: 6.2589

[0m[1;37mINFO[0m: [1mChartInfo 0.4066 0.1750 0.3650 0.1420 0.3697 0.3343[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.095
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.087
SUFF++ for r=0.3 class 0 = 0.456 +- 0.215 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.3 class 1 = 0.455 +- 0.215 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.3 class 2 = 0.46 +- 0.215 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.3 class 3 = 0.487 +- 0.215 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.3 class 4 = 0.459 +- 0.215 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.3 class 5 = 0.495 +- 0.215 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.3 class 6 = 0.488 +- 0.215 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.3 class 7 = 0.479 +- 0.215 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.3 class 8 = 0.477 +- 0.215 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.3 class 9 = 0.483 +- 0.215 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.3 all KL = 0.505 +- 0.215 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.3 all L1 = 0.474 +- 0.129 (in-sample avg dev_std = 0.437)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.37
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.24
SUFF++ for r=0.6 class 0 = 0.254 +- 0.151 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.6 class 1 = 0.278 +- 0.151 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.6 class 2 = 0.272 +- 0.151 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.6 class 3 = 0.259 +- 0.151 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.6 class 4 = 0.287 +- 0.151 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.6 class 5 = 0.278 +- 0.151 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.6 class 6 = 0.299 +- 0.151 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.6 class 7 = 0.296 +- 0.151 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.6 class 8 = 0.273 +- 0.151 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.6 class 9 = 0.319 +- 0.151 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.6 all KL = 0.152 +- 0.151 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.6 all L1 = 0.281 +- 0.080 (in-sample avg dev_std = 0.555)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.391
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.284
SUFF++ for r=0.9 class 0 = 0.345 +- 0.198 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.9 class 1 = 0.366 +- 0.198 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.9 class 2 = 0.337 +- 0.198 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.9 class 3 = 0.301 +- 0.198 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.9 class 4 = 0.384 +- 0.198 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.9 class 5 = 0.333 +- 0.198 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.9 class 6 = 0.333 +- 0.198 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.9 class 7 = 0.419 +- 0.198 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.9 class 8 = 0.32 +- 0.198 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.9 class 9 = 0.365 +- 0.198 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.9 all KL = 0.24 +- 0.198 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.9 all L1 = 0.351 +- 0.109 (in-sample avg dev_std = 0.577)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.094
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.093
SUFF++ for r=0.3 class 0 = 0.533 +- 0.205 (in-sample avg dev_std = 0.376)
SUFF++ for r=0.3 class 1 = 0.557 +- 0.205 (in-sample avg dev_std = 0.376)
SUFF++ for r=0.3 class 2 = 0.52 +- 0.205 (in-sample avg dev_std = 0.376)
SUFF++ for r=0.3 class 3 = 0.482 +- 0.205 (in-sample avg dev_std = 0.376)
SUFF++ for r=0.3 class 4 = 0.521 +- 0.205 (in-sample avg dev_std = 0.376)
SUFF++ for r=0.3 class 5 = 0.516 +- 0.205 (in-sample avg dev_std = 0.376)
SUFF++ for r=0.3 class 6 = 0.538 +- 0.205 (in-sample avg dev_std = 0.376)
SUFF++ for r=0.3 class 7 = 0.527 +- 0.205 (in-sample avg dev_std = 0.376)
SUFF++ for r=0.3 class 8 = 0.507 +- 0.205 (in-sample avg dev_std = 0.376)
SUFF++ for r=0.3 class 9 = 0.509 +- 0.205 (in-sample avg dev_std = 0.376)
SUFF++ for r=0.3 all KL = 0.544 +- 0.205 (in-sample avg dev_std = 0.376)
SUFF++ for r=0.3 all L1 = 0.521 +- 0.155 (in-sample avg dev_std = 0.376)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.176
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.128
SUFF++ for r=0.6 class 0 = 0.244 +- 0.056 (in-sample avg dev_std = 0.638)
SUFF++ for r=0.6 class 1 = 0.273 +- 0.056 (in-sample avg dev_std = 0.638)
SUFF++ for r=0.6 class 2 = 0.248 +- 0.056 (in-sample avg dev_std = 0.638)
SUFF++ for r=0.6 class 3 = 0.252 +- 0.056 (in-sample avg dev_std = 0.638)
SUFF++ for r=0.6 class 4 = 0.258 +- 0.056 (in-sample avg dev_std = 0.638)
SUFF++ for r=0.6 class 5 = 0.242 +- 0.056 (in-sample avg dev_std = 0.638)
SUFF++ for r=0.6 class 6 = 0.256 +- 0.056 (in-sample avg dev_std = 0.638)
SUFF++ for r=0.6 class 7 = 0.254 +- 0.056 (in-sample avg dev_std = 0.638)
SUFF++ for r=0.6 class 8 = 0.241 +- 0.056 (in-sample avg dev_std = 0.638)
SUFF++ for r=0.6 class 9 = 0.268 +- 0.056 (in-sample avg dev_std = 0.638)
SUFF++ for r=0.6 all KL = 0.063 +- 0.056 (in-sample avg dev_std = 0.638)
SUFF++ for r=0.6 all L1 = 0.254 +- 0.049 (in-sample avg dev_std = 0.638)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.177
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.14
SUFF++ for r=0.9 class 0 = 0.353 +- 0.076 (in-sample avg dev_std = 0.587)
SUFF++ for r=0.9 class 1 = 0.352 +- 0.076 (in-sample avg dev_std = 0.587)
SUFF++ for r=0.9 class 2 = 0.322 +- 0.076 (in-sample avg dev_std = 0.587)
SUFF++ for r=0.9 class 3 = 0.307 +- 0.076 (in-sample avg dev_std = 0.587)
SUFF++ for r=0.9 class 4 = 0.313 +- 0.076 (in-sample avg dev_std = 0.587)
SUFF++ for r=0.9 class 5 = 0.326 +- 0.076 (in-sample avg dev_std = 0.587)
SUFF++ for r=0.9 class 6 = 0.305 +- 0.076 (in-sample avg dev_std = 0.587)
SUFF++ for r=0.9 class 7 = 0.323 +- 0.076 (in-sample avg dev_std = 0.587)
SUFF++ for r=0.9 class 8 = 0.301 +- 0.076 (in-sample avg dev_std = 0.587)
SUFF++ for r=0.9 class 9 = 0.299 +- 0.076 (in-sample avg dev_std = 0.587)
SUFF++ for r=0.9 all KL = 0.086 +- 0.076 (in-sample avg dev_std = 0.587)
SUFF++ for r=0.9 all L1 = 0.321 +- 0.083 (in-sample avg dev_std = 0.587)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.095
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.086
NEC for r=0.3 class 0 = 0.423 +- 0.215 (in-sample avg dev_std = 0.217)
NEC for r=0.3 class 1 = 0.369 +- 0.215 (in-sample avg dev_std = 0.217)
NEC for r=0.3 class 2 = 0.406 +- 0.215 (in-sample avg dev_std = 0.217)
NEC for r=0.3 class 3 = 0.35 +- 0.215 (in-sample avg dev_std = 0.217)
NEC for r=0.3 class 4 = 0.391 +- 0.215 (in-sample avg dev_std = 0.217)
NEC for r=0.3 class 5 = 0.378 +- 0.215 (in-sample avg dev_std = 0.217)
NEC for r=0.3 class 6 = 0.349 +- 0.215 (in-sample avg dev_std = 0.217)
NEC for r=0.3 class 7 = 0.358 +- 0.215 (in-sample avg dev_std = 0.217)
NEC for r=0.3 class 8 = 0.331 +- 0.215 (in-sample avg dev_std = 0.217)
NEC for r=0.3 class 9 = 0.354 +- 0.215 (in-sample avg dev_std = 0.217)
NEC for r=0.3 all KL = 0.253 +- 0.215 (in-sample avg dev_std = 0.217)
NEC for r=0.3 all L1 = 0.371 +- 0.193 (in-sample avg dev_std = 0.217)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.37
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.39
NEC for r=0.6 class 0 = 0.6 +- 0.235 (in-sample avg dev_std = 0.367)
NEC for r=0.6 class 1 = 0.391 +- 0.235 (in-sample avg dev_std = 0.367)
NEC for r=0.6 class 2 = 0.619 +- 0.235 (in-sample avg dev_std = 0.367)
NEC for r=0.6 class 3 = 0.643 +- 0.235 (in-sample avg dev_std = 0.367)
NEC for r=0.6 class 4 = 0.615 +- 0.235 (in-sample avg dev_std = 0.367)
NEC for r=0.6 class 5 = 0.625 +- 0.235 (in-sample avg dev_std = 0.367)
NEC for r=0.6 class 6 = 0.585 +- 0.235 (in-sample avg dev_std = 0.367)
NEC for r=0.6 class 7 = 0.522 +- 0.235 (in-sample avg dev_std = 0.367)
NEC for r=0.6 class 8 = 0.601 +- 0.235 (in-sample avg dev_std = 0.367)
NEC for r=0.6 class 9 = 0.573 +- 0.235 (in-sample avg dev_std = 0.367)
NEC for r=0.6 all KL = 0.59 +- 0.235 (in-sample avg dev_std = 0.367)
NEC for r=0.6 all L1 = 0.574 +- 0.174 (in-sample avg dev_std = 0.367)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.391
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.493
NEC for r=0.9 class 0 = 0.565 +- 0.295 (in-sample avg dev_std = 0.353)
NEC for r=0.9 class 1 = 0.017 +- 0.295 (in-sample avg dev_std = 0.353)
NEC for r=0.9 class 2 = 0.618 +- 0.295 (in-sample avg dev_std = 0.353)
NEC for r=0.9 class 3 = 0.638 +- 0.295 (in-sample avg dev_std = 0.353)
NEC for r=0.9 class 4 = 0.637 +- 0.295 (in-sample avg dev_std = 0.353)
NEC for r=0.9 class 5 = 0.621 +- 0.295 (in-sample avg dev_std = 0.353)
NEC for r=0.9 class 6 = 0.538 +- 0.295 (in-sample avg dev_std = 0.353)
NEC for r=0.9 class 7 = 0.488 +- 0.295 (in-sample avg dev_std = 0.353)
NEC for r=0.9 class 8 = 0.654 +- 0.295 (in-sample avg dev_std = 0.353)
NEC for r=0.9 class 9 = 0.597 +- 0.295 (in-sample avg dev_std = 0.353)
NEC for r=0.9 all KL = 0.543 +- 0.295 (in-sample avg dev_std = 0.353)
NEC for r=0.9 all L1 = 0.529 +- 0.248 (in-sample avg dev_std = 0.353)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.385
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.486
NEC for r=1.0 class 0 = 0.558 +- 0.294 (in-sample avg dev_std = 0.357)
NEC for r=1.0 class 1 = 0.011 +- 0.294 (in-sample avg dev_std = 0.357)
NEC for r=1.0 class 2 = 0.623 +- 0.294 (in-sample avg dev_std = 0.357)
NEC for r=1.0 class 3 = 0.643 +- 0.294 (in-sample avg dev_std = 0.357)
NEC for r=1.0 class 4 = 0.634 +- 0.294 (in-sample avg dev_std = 0.357)
NEC for r=1.0 class 5 = 0.623 +- 0.294 (in-sample avg dev_std = 0.357)
NEC for r=1.0 class 6 = 0.54 +- 0.294 (in-sample avg dev_std = 0.357)
NEC for r=1.0 class 7 = 0.492 +- 0.294 (in-sample avg dev_std = 0.357)
NEC for r=1.0 class 8 = 0.645 +- 0.294 (in-sample avg dev_std = 0.357)
NEC for r=1.0 class 9 = 0.582 +- 0.294 (in-sample avg dev_std = 0.357)
NEC for r=1.0 all KL = 0.541 +- 0.294 (in-sample avg dev_std = 0.357)
NEC for r=1.0 all L1 = 0.527 +- 0.247 (in-sample avg dev_std = 0.357)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.094
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.097
NEC for r=0.3 class 0 = 0.338 +- 0.209 (in-sample avg dev_std = 0.154)
NEC for r=0.3 class 1 = 0.274 +- 0.209 (in-sample avg dev_std = 0.154)
NEC for r=0.3 class 2 = 0.344 +- 0.209 (in-sample avg dev_std = 0.154)
NEC for r=0.3 class 3 = 0.376 +- 0.209 (in-sample avg dev_std = 0.154)
NEC for r=0.3 class 4 = 0.349 +- 0.209 (in-sample avg dev_std = 0.154)
NEC for r=0.3 class 5 = 0.356 +- 0.209 (in-sample avg dev_std = 0.154)
NEC for r=0.3 class 6 = 0.315 +- 0.209 (in-sample avg dev_std = 0.154)
NEC for r=0.3 class 7 = 0.342 +- 0.209 (in-sample avg dev_std = 0.154)
NEC for r=0.3 class 8 = 0.367 +- 0.209 (in-sample avg dev_std = 0.154)
NEC for r=0.3 class 9 = 0.338 +- 0.209 (in-sample avg dev_std = 0.154)
NEC for r=0.3 all KL = 0.21 +- 0.209 (in-sample avg dev_std = 0.154)
NEC for r=0.3 all L1 = 0.339 +- 0.207 (in-sample avg dev_std = 0.154)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.176
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.16
NEC for r=0.6 class 0 = 0.609 +- 0.242 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 1 = 0.469 +- 0.242 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 2 = 0.549 +- 0.242 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 3 = 0.575 +- 0.242 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 4 = 0.515 +- 0.242 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 5 = 0.595 +- 0.242 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 6 = 0.53 +- 0.242 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 7 = 0.556 +- 0.242 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 8 = 0.59 +- 0.242 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 9 = 0.507 +- 0.242 (in-sample avg dev_std = 0.334)
NEC for r=0.6 all KL = 0.526 +- 0.242 (in-sample avg dev_std = 0.334)
NEC for r=0.6 all L1 = 0.548 +- 0.162 (in-sample avg dev_std = 0.334)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.177
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.195
NEC for r=0.9 class 0 = 0.569 +- 0.268 (in-sample avg dev_std = 0.341)
NEC for r=0.9 class 1 = 0.196 +- 0.268 (in-sample avg dev_std = 0.341)
NEC for r=0.9 class 2 = 0.576 +- 0.268 (in-sample avg dev_std = 0.341)
NEC for r=0.9 class 3 = 0.603 +- 0.268 (in-sample avg dev_std = 0.341)
NEC for r=0.9 class 4 = 0.556 +- 0.268 (in-sample avg dev_std = 0.341)
NEC for r=0.9 class 5 = 0.546 +- 0.268 (in-sample avg dev_std = 0.341)
NEC for r=0.9 class 6 = 0.57 +- 0.268 (in-sample avg dev_std = 0.341)
NEC for r=0.9 class 7 = 0.54 +- 0.268 (in-sample avg dev_std = 0.341)
NEC for r=0.9 class 8 = 0.562 +- 0.268 (in-sample avg dev_std = 0.341)
NEC for r=0.9 class 9 = 0.512 +- 0.268 (in-sample avg dev_std = 0.341)
NEC for r=0.9 all KL = 0.523 +- 0.268 (in-sample avg dev_std = 0.341)
NEC for r=0.9 all L1 = 0.519 +- 0.210 (in-sample avg dev_std = 0.341)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.177
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.197
NEC for r=1.0 class 0 = 0.575 +- 0.271 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 1 = 0.191 +- 0.271 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 2 = 0.572 +- 0.271 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 3 = 0.594 +- 0.271 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 4 = 0.561 +- 0.271 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 5 = 0.566 +- 0.271 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 6 = 0.58 +- 0.271 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 7 = 0.536 +- 0.271 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 8 = 0.552 +- 0.271 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 9 = 0.497 +- 0.271 (in-sample avg dev_std = 0.354)
NEC for r=1.0 all KL = 0.525 +- 0.271 (in-sample avg dev_std = 0.354)
NEC for r=1.0 all L1 = 0.518 +- 0.210 (in-sample avg dev_std = 0.354)
model_dirname= repr_GSATvGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 17:28:15 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/29/2024 05:28:15 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 05:28:15 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 05:28:15 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/29/2024 05:28:16 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 83...
[0m[1;37mINFO[0m: [1mCheckpoint 83: 
-----------------------------------
Train ACCURACY: 0.4080
Train Loss: 1.9877
ID Validation ACCURACY: 0.4117
ID Validation Loss: 1.9768
ID Test ACCURACY: 0.4019
ID Test Loss: 2.0092
OOD Validation ACCURACY: 0.3249
OOD Validation Loss: 2.5128
OOD Test ACCURACY: 0.1226
OOD Test Loss: 5.8596

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 102...
[0m[1;37mINFO[0m: [1mCheckpoint 102: 
-----------------------------------
Train ACCURACY: 0.3509
Train Loss: 3.1230
ID Validation ACCURACY: 0.3564
ID Validation Loss: 3.0983
ID Test ACCURACY: 0.3456
ID Test Loss: 3.1507
OOD Validation ACCURACY: 0.3460
OOD Validation Loss: 3.1070
OOD Test ACCURACY: 0.1710
OOD Test Loss: 4.3751

[0m[1;37mINFO[0m: [1mChartInfo 0.4019 0.1226 0.3456 0.1710 0.3564 0.3460[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.085
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.092
SUFF++ for r=0.3 class 0 = 0.879 +- 0.098 (in-sample avg dev_std = 0.117)
SUFF++ for r=0.3 class 1 = 0.758 +- 0.098 (in-sample avg dev_std = 0.117)
SUFF++ for r=0.3 class 2 = 0.839 +- 0.098 (in-sample avg dev_std = 0.117)
SUFF++ for r=0.3 class 3 = 0.856 +- 0.098 (in-sample avg dev_std = 0.117)
SUFF++ for r=0.3 class 4 = 0.857 +- 0.098 (in-sample avg dev_std = 0.117)
SUFF++ for r=0.3 class 5 = 0.825 +- 0.098 (in-sample avg dev_std = 0.117)
SUFF++ for r=0.3 class 6 = 0.834 +- 0.098 (in-sample avg dev_std = 0.117)
SUFF++ for r=0.3 class 7 = 0.83 +- 0.098 (in-sample avg dev_std = 0.117)
SUFF++ for r=0.3 class 8 = 0.86 +- 0.098 (in-sample avg dev_std = 0.117)
SUFF++ for r=0.3 class 9 = 0.829 +- 0.098 (in-sample avg dev_std = 0.117)
SUFF++ for r=0.3 all KL = 0.911 +- 0.098 (in-sample avg dev_std = 0.117)
SUFF++ for r=0.3 all L1 = 0.836 +- 0.129 (in-sample avg dev_std = 0.117)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.365
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.221
SUFF++ for r=0.6 class 0 = 0.3 +- 0.215 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.6 class 1 = 0.293 +- 0.215 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.6 class 2 = 0.303 +- 0.215 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.6 class 3 = 0.308 +- 0.215 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.6 class 4 = 0.376 +- 0.215 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.6 class 5 = 0.331 +- 0.215 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.6 class 6 = 0.378 +- 0.215 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.6 class 7 = 0.368 +- 0.215 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.6 class 8 = 0.344 +- 0.215 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.6 class 9 = 0.44 +- 0.215 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.6 all KL = 0.293 +- 0.215 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.6 all L1 = 0.343 +- 0.119 (in-sample avg dev_std = 0.489)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.393
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.283
SUFF++ for r=0.9 class 0 = 0.313 +- 0.238 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.9 class 1 = 0.355 +- 0.238 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.9 class 2 = 0.316 +- 0.238 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.9 class 3 = 0.327 +- 0.238 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.9 class 4 = 0.522 +- 0.238 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.9 class 5 = 0.361 +- 0.238 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.9 class 6 = 0.37 +- 0.238 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.9 class 7 = 0.426 +- 0.238 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.9 class 8 = 0.393 +- 0.238 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.9 class 9 = 0.445 +- 0.238 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.9 all KL = 0.339 +- 0.238 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.9 all L1 = 0.381 +- 0.134 (in-sample avg dev_std = 0.542)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.096
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.098
SUFF++ for r=0.3 class 0 = 0.925 +- 0.101 (in-sample avg dev_std = 0.071)
SUFF++ for r=0.3 class 1 = 0.899 +- 0.101 (in-sample avg dev_std = 0.071)
SUFF++ for r=0.3 class 2 = 0.88 +- 0.101 (in-sample avg dev_std = 0.071)
SUFF++ for r=0.3 class 3 = 0.907 +- 0.101 (in-sample avg dev_std = 0.071)
SUFF++ for r=0.3 class 4 = 0.898 +- 0.101 (in-sample avg dev_std = 0.071)
SUFF++ for r=0.3 class 5 = 0.911 +- 0.101 (in-sample avg dev_std = 0.071)
SUFF++ for r=0.3 class 6 = 0.854 +- 0.101 (in-sample avg dev_std = 0.071)
SUFF++ for r=0.3 class 7 = 0.894 +- 0.101 (in-sample avg dev_std = 0.071)
SUFF++ for r=0.3 class 8 = 0.885 +- 0.101 (in-sample avg dev_std = 0.071)
SUFF++ for r=0.3 class 9 = 0.872 +- 0.101 (in-sample avg dev_std = 0.071)
SUFF++ for r=0.3 all KL = 0.934 +- 0.101 (in-sample avg dev_std = 0.071)
SUFF++ for r=0.3 all L1 = 0.892 +- 0.124 (in-sample avg dev_std = 0.071)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.25
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.151
SUFF++ for r=0.6 class 0 = 0.239 +- 0.163 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.6 class 1 = 0.262 +- 0.163 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.6 class 2 = 0.24 +- 0.163 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.6 class 3 = 0.245 +- 0.163 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.6 class 4 = 0.286 +- 0.163 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.6 class 5 = 0.254 +- 0.163 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.6 class 6 = 0.264 +- 0.163 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.6 class 7 = 0.24 +- 0.163 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.6 class 8 = 0.258 +- 0.163 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.6 class 9 = 0.305 +- 0.163 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.6 all KL = 0.181 +- 0.163 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.6 all L1 = 0.259 +- 0.086 (in-sample avg dev_std = 0.412)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.157
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.144
SUFF++ for r=0.9 class 0 = 0.287 +- 0.207 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.9 class 1 = 0.435 +- 0.207 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.9 class 2 = 0.267 +- 0.207 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.9 class 3 = 0.289 +- 0.207 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.9 class 4 = 0.369 +- 0.207 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.9 class 5 = 0.304 +- 0.207 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.9 class 6 = 0.363 +- 0.207 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.9 class 7 = 0.308 +- 0.207 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.9 class 8 = 0.3 +- 0.207 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.9 class 9 = 0.387 +- 0.207 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.9 all KL = 0.235 +- 0.207 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.9 all L1 = 0.332 +- 0.158 (in-sample avg dev_std = 0.486)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.085
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.092
NEC for r=0.3 class 0 = 0.085 +- 0.082 (in-sample avg dev_std = 0.099)
NEC for r=0.3 class 1 = 0.203 +- 0.082 (in-sample avg dev_std = 0.099)
NEC for r=0.3 class 2 = 0.156 +- 0.082 (in-sample avg dev_std = 0.099)
NEC for r=0.3 class 3 = 0.131 +- 0.082 (in-sample avg dev_std = 0.099)
NEC for r=0.3 class 4 = 0.149 +- 0.082 (in-sample avg dev_std = 0.099)
NEC for r=0.3 class 5 = 0.161 +- 0.082 (in-sample avg dev_std = 0.099)
NEC for r=0.3 class 6 = 0.149 +- 0.082 (in-sample avg dev_std = 0.099)
NEC for r=0.3 class 7 = 0.153 +- 0.082 (in-sample avg dev_std = 0.099)
NEC for r=0.3 class 8 = 0.133 +- 0.082 (in-sample avg dev_std = 0.099)
NEC for r=0.3 class 9 = 0.15 +- 0.082 (in-sample avg dev_std = 0.099)
NEC for r=0.3 all KL = 0.066 +- 0.082 (in-sample avg dev_std = 0.099)
NEC for r=0.3 all L1 = 0.147 +- 0.129 (in-sample avg dev_std = 0.099)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.365
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.363
NEC for r=0.6 class 0 = 0.562 +- 0.229 (in-sample avg dev_std = 0.327)
NEC for r=0.6 class 1 = 0.443 +- 0.229 (in-sample avg dev_std = 0.327)
NEC for r=0.6 class 2 = 0.601 +- 0.229 (in-sample avg dev_std = 0.327)
NEC for r=0.6 class 3 = 0.594 +- 0.229 (in-sample avg dev_std = 0.327)
NEC for r=0.6 class 4 = 0.542 +- 0.229 (in-sample avg dev_std = 0.327)
NEC for r=0.6 class 5 = 0.594 +- 0.229 (in-sample avg dev_std = 0.327)
NEC for r=0.6 class 6 = 0.521 +- 0.229 (in-sample avg dev_std = 0.327)
NEC for r=0.6 class 7 = 0.51 +- 0.229 (in-sample avg dev_std = 0.327)
NEC for r=0.6 class 8 = 0.567 +- 0.229 (in-sample avg dev_std = 0.327)
NEC for r=0.6 class 9 = 0.484 +- 0.229 (in-sample avg dev_std = 0.327)
NEC for r=0.6 all KL = 0.498 +- 0.229 (in-sample avg dev_std = 0.327)
NEC for r=0.6 all L1 = 0.54 +- 0.158 (in-sample avg dev_std = 0.327)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.393
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.473
NEC for r=0.9 class 0 = 0.489 +- 0.242 (in-sample avg dev_std = 0.313)
NEC for r=0.9 class 1 = 0.194 +- 0.242 (in-sample avg dev_std = 0.313)
NEC for r=0.9 class 2 = 0.596 +- 0.242 (in-sample avg dev_std = 0.313)
NEC for r=0.9 class 3 = 0.589 +- 0.242 (in-sample avg dev_std = 0.313)
NEC for r=0.9 class 4 = 0.453 +- 0.242 (in-sample avg dev_std = 0.313)
NEC for r=0.9 class 5 = 0.569 +- 0.242 (in-sample avg dev_std = 0.313)
NEC for r=0.9 class 6 = 0.538 +- 0.242 (in-sample avg dev_std = 0.313)
NEC for r=0.9 class 7 = 0.51 +- 0.242 (in-sample avg dev_std = 0.313)
NEC for r=0.9 class 8 = 0.591 +- 0.242 (in-sample avg dev_std = 0.313)
NEC for r=0.9 class 9 = 0.489 +- 0.242 (in-sample avg dev_std = 0.313)
NEC for r=0.9 all KL = 0.446 +- 0.242 (in-sample avg dev_std = 0.313)
NEC for r=0.9 all L1 = 0.498 +- 0.199 (in-sample avg dev_std = 0.313)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.382
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.466
NEC for r=1.0 class 0 = 0.502 +- 0.236 (in-sample avg dev_std = 0.314)
NEC for r=1.0 class 1 = 0.289 +- 0.236 (in-sample avg dev_std = 0.314)
NEC for r=1.0 class 2 = 0.595 +- 0.236 (in-sample avg dev_std = 0.314)
NEC for r=1.0 class 3 = 0.579 +- 0.236 (in-sample avg dev_std = 0.314)
NEC for r=1.0 class 4 = 0.456 +- 0.236 (in-sample avg dev_std = 0.314)
NEC for r=1.0 class 5 = 0.576 +- 0.236 (in-sample avg dev_std = 0.314)
NEC for r=1.0 class 6 = 0.546 +- 0.236 (in-sample avg dev_std = 0.314)
NEC for r=1.0 class 7 = 0.509 +- 0.236 (in-sample avg dev_std = 0.314)
NEC for r=1.0 class 8 = 0.589 +- 0.236 (in-sample avg dev_std = 0.314)
NEC for r=1.0 class 9 = 0.5 +- 0.236 (in-sample avg dev_std = 0.314)
NEC for r=1.0 all KL = 0.455 +- 0.236 (in-sample avg dev_std = 0.314)
NEC for r=1.0 all L1 = 0.511 +- 0.184 (in-sample avg dev_std = 0.314)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.096
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.098
NEC for r=0.3 class 0 = 0.053 +- 0.099 (in-sample avg dev_std = 0.053)
NEC for r=0.3 class 1 = 0.081 +- 0.099 (in-sample avg dev_std = 0.053)
NEC for r=0.3 class 2 = 0.095 +- 0.099 (in-sample avg dev_std = 0.053)
NEC for r=0.3 class 3 = 0.071 +- 0.099 (in-sample avg dev_std = 0.053)
NEC for r=0.3 class 4 = 0.085 +- 0.099 (in-sample avg dev_std = 0.053)
NEC for r=0.3 class 5 = 0.065 +- 0.099 (in-sample avg dev_std = 0.053)
NEC for r=0.3 class 6 = 0.123 +- 0.099 (in-sample avg dev_std = 0.053)
NEC for r=0.3 class 7 = 0.087 +- 0.099 (in-sample avg dev_std = 0.053)
NEC for r=0.3 class 8 = 0.102 +- 0.099 (in-sample avg dev_std = 0.053)
NEC for r=0.3 class 9 = 0.116 +- 0.099 (in-sample avg dev_std = 0.053)
NEC for r=0.3 all KL = 0.045 +- 0.099 (in-sample avg dev_std = 0.053)
NEC for r=0.3 all L1 = 0.088 +- 0.127 (in-sample avg dev_std = 0.053)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.25
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.228
NEC for r=0.6 class 0 = 0.648 +- 0.226 (in-sample avg dev_std = 0.309)
NEC for r=0.6 class 1 = 0.448 +- 0.226 (in-sample avg dev_std = 0.309)
NEC for r=0.6 class 2 = 0.671 +- 0.226 (in-sample avg dev_std = 0.309)
NEC for r=0.6 class 3 = 0.683 +- 0.226 (in-sample avg dev_std = 0.309)
NEC for r=0.6 class 4 = 0.62 +- 0.226 (in-sample avg dev_std = 0.309)
NEC for r=0.6 class 5 = 0.651 +- 0.226 (in-sample avg dev_std = 0.309)
NEC for r=0.6 class 6 = 0.647 +- 0.226 (in-sample avg dev_std = 0.309)
NEC for r=0.6 class 7 = 0.679 +- 0.226 (in-sample avg dev_std = 0.309)
NEC for r=0.6 class 8 = 0.655 +- 0.226 (in-sample avg dev_std = 0.309)
NEC for r=0.6 class 9 = 0.613 +- 0.226 (in-sample avg dev_std = 0.309)
NEC for r=0.6 all KL = 0.651 +- 0.226 (in-sample avg dev_std = 0.309)
NEC for r=0.6 all L1 = 0.63 +- 0.151 (in-sample avg dev_std = 0.309)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.157
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.23
NEC for r=0.9 class 0 = 0.661 +- 0.198 (in-sample avg dev_std = 0.288)
NEC for r=0.9 class 1 = 0.668 +- 0.198 (in-sample avg dev_std = 0.288)
NEC for r=0.9 class 2 = 0.723 +- 0.198 (in-sample avg dev_std = 0.288)
NEC for r=0.9 class 3 = 0.71 +- 0.198 (in-sample avg dev_std = 0.288)
NEC for r=0.9 class 4 = 0.715 +- 0.198 (in-sample avg dev_std = 0.288)
NEC for r=0.9 class 5 = 0.694 +- 0.198 (in-sample avg dev_std = 0.288)
NEC for r=0.9 class 6 = 0.711 +- 0.198 (in-sample avg dev_std = 0.288)
NEC for r=0.9 class 7 = 0.713 +- 0.198 (in-sample avg dev_std = 0.288)
NEC for r=0.9 class 8 = 0.723 +- 0.198 (in-sample avg dev_std = 0.288)
NEC for r=0.9 class 9 = 0.727 +- 0.198 (in-sample avg dev_std = 0.288)
NEC for r=0.9 all KL = 0.794 +- 0.198 (in-sample avg dev_std = 0.288)
NEC for r=0.9 all L1 = 0.704 +- 0.126 (in-sample avg dev_std = 0.288)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.138
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.204
NEC for r=1.0 class 0 = 0.664 +- 0.215 (in-sample avg dev_std = 0.319)
NEC for r=1.0 class 1 = 0.652 +- 0.215 (in-sample avg dev_std = 0.319)
NEC for r=1.0 class 2 = 0.728 +- 0.215 (in-sample avg dev_std = 0.319)
NEC for r=1.0 class 3 = 0.711 +- 0.215 (in-sample avg dev_std = 0.319)
NEC for r=1.0 class 4 = 0.696 +- 0.215 (in-sample avg dev_std = 0.319)
NEC for r=1.0 class 5 = 0.707 +- 0.215 (in-sample avg dev_std = 0.319)
NEC for r=1.0 class 6 = 0.683 +- 0.215 (in-sample avg dev_std = 0.319)
NEC for r=1.0 class 7 = 0.746 +- 0.215 (in-sample avg dev_std = 0.319)
NEC for r=1.0 class 8 = 0.731 +- 0.215 (in-sample avg dev_std = 0.319)
NEC for r=1.0 class 9 = 0.679 +- 0.215 (in-sample avg dev_std = 0.319)
NEC for r=1.0 all KL = 0.823 +- 0.215 (in-sample avg dev_std = 0.319)
NEC for r=1.0 all L1 = 0.699 +- 0.176 (in-sample avg dev_std = 0.319)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.512, 0.213, 0.225, 1.0], 'all_L1': [0.432, 0.318, 0.356, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.379, 0.189, 0.334, 1.0], 'all_L1': [0.429, 0.288, 0.396, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.528, 0.273, 0.33, 1.0], 'all_L1': [0.47, 0.329, 0.398, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.505, 0.152, 0.24, 1.0], 'all_L1': [0.474, 0.281, 0.351, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.911, 0.293, 0.339, 1.0], 'all_L1': [0.836, 0.343, 0.381, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.244, 0.525, 0.503, 0.505], 'all_L1': [0.403, 0.532, 0.496, 0.497]}), defaultdict(<class 'list'>, {'all_KL': [0.28, 0.62, 0.558, 0.549], 'all_L1': [0.394, 0.605, 0.538, 0.53]}), defaultdict(<class 'list'>, {'all_KL': [0.251, 0.486, 0.482, 0.49], 'all_L1': [0.392, 0.522, 0.491, 0.497]}), defaultdict(<class 'list'>, {'all_KL': [0.253, 0.59, 0.543, 0.541], 'all_L1': [0.371, 0.574, 0.529, 0.527]}), defaultdict(<class 'list'>, {'all_KL': [0.066, 0.498, 0.446, 0.455], 'all_L1': [0.147, 0.54, 0.498, 0.511]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.278, 0.094, 0.062, 1.0], 'all_L1': [0.362, 0.262, 0.367, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.386, 0.105, 0.049, 1.0], 'all_L1': [0.488, 0.268, 0.296, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.519, 0.124, 0.117, 1.0], 'all_L1': [0.449, 0.248, 0.255, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.544, 0.063, 0.086, 1.0], 'all_L1': [0.521, 0.254, 0.321, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.934, 0.181, 0.235, 1.0], 'all_L1': [0.892, 0.259, 0.332, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.197, 0.533, 0.35, 0.324], 'all_L1': [0.325, 0.548, 0.316, 0.293]}), defaultdict(<class 'list'>, {'all_KL': [0.168, 0.478, 0.533, 0.535], 'all_L1': [0.293, 0.534, 0.531, 0.53]}), defaultdict(<class 'list'>, {'all_KL': [0.306, 0.621, 0.753, 0.778], 'all_L1': [0.446, 0.598, 0.667, 0.652]}), defaultdict(<class 'list'>, {'all_KL': [0.21, 0.526, 0.523, 0.525], 'all_L1': [0.339, 0.548, 0.519, 0.518]}), defaultdict(<class 'list'>, {'all_KL': [0.045, 0.651, 0.794, 0.823], 'all_L1': [0.088, 0.63, 0.704, 0.699]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.528 +- 0.155, 0.312 +- 0.024, 0.376 +- 0.020, 1.000 +- 0.000
suff++ class all_KL  =  0.567 +- 0.180, 0.224 +- 0.052, 0.294 +- 0.050, 1.000 +- 0.000
suff++_acc_int  =  0.089 +- 0.004, 0.221 +- 0.017, 0.277 +- 0.009
nec class all_L1  =  0.341 +- 0.098, 0.555 +- 0.031, 0.510 +- 0.019, 0.512 +- 0.014
nec class all_KL  =  0.219 +- 0.077, 0.544 +- 0.052, 0.506 +- 0.041, 0.508 +- 0.034
nec_acc_int  =  0.085 +- 0.007, 0.357 +- 0.028, 0.460 +- 0.026, 0.460 +- 0.021

Eval split test
suff++ class all_L1  =  0.542 +- 0.183, 0.258 +- 0.007, 0.314 +- 0.037, 1.000 +- 0.000
suff++ class all_KL  =  0.532 +- 0.223, 0.113 +- 0.039, 0.110 +- 0.067, 1.000 +- 0.000
suff++_acc_int  =  0.095 +- 0.002, 0.138 +- 0.009, 0.139 +- 0.005
nec class all_L1  =  0.298 +- 0.117, 0.572 +- 0.036, 0.547 +- 0.137, 0.538 +- 0.141
nec class all_KL  =  0.185 +- 0.084, 0.562 +- 0.064, 0.591 +- 0.163, 0.597 +- 0.183
nec_acc_int  =  0.096 +- 0.001, 0.194 +- 0.030, 0.191 +- 0.024, 0.183 +- 0.024


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.435 +- 0.029, 0.433 +- 0.009, 0.443 +- 0.013, 0.756 +- 0.007
Faith. Armon (L1)= 		  =  0.384 +- 0.067, 0.398 +- 0.014, 0.433 +- 0.014, 0.677 +- 0.012
Faith. GMean (L1)= 	  =  0.406 +- 0.028, 0.415 +- 0.009, 0.438 +- 0.014, 0.716 +- 0.010
Faith. Aritm (KL)= 		  =  0.393 +- 0.052, 0.384 +- 0.014, 0.400 +- 0.027, 0.754 +- 0.017
Faith. Armon (KL)= 		  =  0.291 +- 0.084, 0.311 +- 0.045, 0.368 +- 0.040, 0.673 +- 0.030
Faith. GMean (KL)= 	  =  0.329 +- 0.044, 0.344 +- 0.028, 0.383 +- 0.033, 0.712 +- 0.024

Eval split test
Faith. Aritm (L1)= 		  =  0.420 +- 0.050, 0.415 +- 0.017, 0.431 +- 0.058, 0.769 +- 0.071
Faith. Armon (L1)= 		  =  0.345 +- 0.099, 0.355 +- 0.007, 0.387 +- 0.037, 0.688 +- 0.129
Faith. GMean (L1)= 	  =  0.374 +- 0.059, 0.384 +- 0.011, 0.408 +- 0.046, 0.727 +- 0.103
Faith. Aritm (KL)= 		  =  0.359 +- 0.091, 0.338 +- 0.049, 0.350 +- 0.110, 0.799 +- 0.091
Faith. Armon (KL)= 		  =  0.248 +- 0.099, 0.187 +- 0.057, 0.182 +- 0.099, 0.731 +- 0.149
Faith. GMean (KL)= 	  =  0.286 +- 0.072, 0.250 +- 0.056, 0.250 +- 0.105, 0.763 +- 0.122
Computed for split load_split = id



Completed in  1:12:24.650517  for GSATvGIN GOODCMNIST/color



DONE GSAT GOODCMNIST/color
DONE all :)
