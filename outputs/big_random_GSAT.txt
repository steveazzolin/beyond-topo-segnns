nohup: ignoring input
Time to compute metrics for random explanations!
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 11:50:25 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/28/2024 11:50:25 AM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 11:50:25 AM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 11:50:25 AM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 11:50:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:50:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:50:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:50:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:50:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:50:25 AM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 11:50:25 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 141...
[0m[1;37mINFO[0m: [1mCheckpoint 141: 
-----------------------------------
Train ACCURACY: 0.9305
Train Loss: 0.3185
ID Validation ACCURACY: 0.9363
ID Validation Loss: 0.3125
ID Test ACCURACY: 0.9260
ID Test Loss: 0.3441
OOD Validation ACCURACY: 0.8640
OOD Validation Loss: 0.4793
OOD Test ACCURACY: 0.6850
OOD Test Loss: 1.1140

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 135...
[0m[1;37mINFO[0m: [1mCheckpoint 135: 
-----------------------------------
Train ACCURACY: 0.9250
Train Loss: 0.3289
ID Validation ACCURACY: 0.9303
ID Validation Loss: 0.3194
ID Test ACCURACY: 0.9213
ID Test Loss: 0.3502
OOD Validation ACCURACY: 0.9307
OOD Validation Loss: 0.3665
OOD Test ACCURACY: 0.6453
OOD Test Loss: 0.9689

[0m[1;37mINFO[0m: [1mChartInfo 0.9260 0.6850 0.9213 0.6453 0.9303 0.9307[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.180
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.253
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.300
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.310
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.165
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.216
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.246
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.252


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.434
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.17956375000000002
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.356
SUFF++ for r=0.3 class 0 = 0.457 +- 0.261 (in-sample avg dev_std = 0.431)
SUFF++ for r=0.3 class 1 = 0.466 +- 0.261 (in-sample avg dev_std = 0.431)
SUFF++ for r=0.3 class 2 = 0.457 +- 0.261 (in-sample avg dev_std = 0.431)
SUFF++ for r=0.3 all KL = 0.511 +- 0.261 (in-sample avg dev_std = 0.431)
SUFF++ for r=0.3 all L1 = 0.46 +- 0.132 (in-sample avg dev_std = 0.431)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.68
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.25328500000000004
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.439
SUFF++ for r=0.6 class 0 = 0.416 +- 0.264 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.6 class 1 = 0.569 +- 0.264 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.6 class 2 = 0.387 +- 0.264 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.6 all KL = 0.473 +- 0.264 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.6 all L1 = 0.458 +- 0.157 (in-sample avg dev_std = 0.463)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.921
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.30011625000000003
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.721
SUFF++ for r=0.9 class 0 = 0.567 +- 0.271 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.9 class 1 = 0.695 +- 0.271 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.9 class 2 = 0.675 +- 0.271 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.9 all KL = 0.694 +- 0.271 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.9 all L1 = 0.646 +- 0.218 (in-sample avg dev_std = 0.380)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.444
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.16524124999999998
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.39
SUFF++ for r=0.3 class 0 = 0.49 +- 0.269 (in-sample avg dev_std = 0.487)
SUFF++ for r=0.3 class 1 = 0.483 +- 0.269 (in-sample avg dev_std = 0.487)
SUFF++ for r=0.3 class 2 = 0.41 +- 0.269 (in-sample avg dev_std = 0.487)
SUFF++ for r=0.3 all KL = 0.461 +- 0.269 (in-sample avg dev_std = 0.487)
SUFF++ for r=0.3 all L1 = 0.461 +- 0.119 (in-sample avg dev_std = 0.487)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.741
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.21628624999999999
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.482
SUFF++ for r=0.6 class 0 = 0.366 +- 0.245 (in-sample avg dev_std = 0.458)
SUFF++ for r=0.6 class 1 = 0.577 +- 0.245 (in-sample avg dev_std = 0.458)
SUFF++ for r=0.6 class 2 = 0.431 +- 0.245 (in-sample avg dev_std = 0.458)
SUFF++ for r=0.6 all KL = 0.488 +- 0.245 (in-sample avg dev_std = 0.458)
SUFF++ for r=0.6 all L1 = 0.46 +- 0.155 (in-sample avg dev_std = 0.458)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.644
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.2460725
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.584
SUFF++ for r=0.9 class 0 = 0.607 +- 0.283 (in-sample avg dev_std = 0.369)
SUFF++ for r=0.9 class 1 = 0.64 +- 0.283 (in-sample avg dev_std = 0.369)
SUFF++ for r=0.9 class 2 = 0.706 +- 0.283 (in-sample avg dev_std = 0.369)
SUFF++ for r=0.9 all KL = 0.675 +- 0.283 (in-sample avg dev_std = 0.369)
SUFF++ for r=0.9 all L1 = 0.651 +- 0.197 (in-sample avg dev_std = 0.369)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.433
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.17956375000000002
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.367
NEC for r=0.3 class 0 = 0.559 +- 0.278 (in-sample avg dev_std = 0.406)
NEC for r=0.3 class 1 = 0.475 +- 0.278 (in-sample avg dev_std = 0.406)
NEC for r=0.3 class 2 = 0.465 +- 0.278 (in-sample avg dev_std = 0.406)
NEC for r=0.3 all KL = 0.448 +- 0.278 (in-sample avg dev_std = 0.406)
NEC for r=0.3 all L1 = 0.5 +- 0.182 (in-sample avg dev_std = 0.406)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.678
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.25328500000000004
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.474
NEC for r=0.6 class 0 = 0.566 +- 0.254 (in-sample avg dev_std = 0.495)
NEC for r=0.6 class 1 = 0.471 +- 0.254 (in-sample avg dev_std = 0.495)
NEC for r=0.6 class 2 = 0.551 +- 0.254 (in-sample avg dev_std = 0.495)
NEC for r=0.6 all KL = 0.518 +- 0.254 (in-sample avg dev_std = 0.495)
NEC for r=0.6 all L1 = 0.529 +- 0.155 (in-sample avg dev_std = 0.495)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.921
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.30011625000000003
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.519
NEC for r=0.9 class 0 = 0.602 +- 0.229 (in-sample avg dev_std = 0.545)
NEC for r=0.9 class 1 = 0.475 +- 0.229 (in-sample avg dev_std = 0.545)
NEC for r=0.9 class 2 = 0.521 +- 0.229 (in-sample avg dev_std = 0.545)
NEC for r=0.9 all KL = 0.545 +- 0.229 (in-sample avg dev_std = 0.545)
NEC for r=0.9 all L1 = 0.532 +- 0.161 (in-sample avg dev_std = 0.545)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.942
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.3095675
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.524
NEC for r=1.0 class 0 = 0.592 +- 0.226 (in-sample avg dev_std = 0.611)
NEC for r=1.0 class 1 = 0.446 +- 0.226 (in-sample avg dev_std = 0.611)
NEC for r=1.0 class 2 = 0.551 +- 0.226 (in-sample avg dev_std = 0.611)
NEC for r=1.0 all KL = 0.569 +- 0.226 (in-sample avg dev_std = 0.611)
NEC for r=1.0 all L1 = 0.53 +- 0.162 (in-sample avg dev_std = 0.611)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.444
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.16524124999999998
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.426
NEC for r=0.3 class 0 = 0.512 +- 0.278 (in-sample avg dev_std = 0.480)
NEC for r=0.3 class 1 = 0.456 +- 0.278 (in-sample avg dev_std = 0.480)
NEC for r=0.3 class 2 = 0.47 +- 0.278 (in-sample avg dev_std = 0.480)
NEC for r=0.3 all KL = 0.472 +- 0.278 (in-sample avg dev_std = 0.480)
NEC for r=0.3 all L1 = 0.479 +- 0.175 (in-sample avg dev_std = 0.480)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.741
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.21628624999999999
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.534
NEC for r=0.6 class 0 = 0.595 +- 0.252 (in-sample avg dev_std = 0.505)
NEC for r=0.6 class 1 = 0.449 +- 0.252 (in-sample avg dev_std = 0.505)
NEC for r=0.6 class 2 = 0.506 +- 0.252 (in-sample avg dev_std = 0.505)
NEC for r=0.6 all KL = 0.495 +- 0.252 (in-sample avg dev_std = 0.505)
NEC for r=0.6 all L1 = 0.515 +- 0.156 (in-sample avg dev_std = 0.505)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.644
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.2460725
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.561
NEC for r=0.9 class 0 = 0.524 +- 0.299 (in-sample avg dev_std = 0.491)
NEC for r=0.9 class 1 = 0.407 +- 0.299 (in-sample avg dev_std = 0.491)
NEC for r=0.9 class 2 = 0.38 +- 0.299 (in-sample avg dev_std = 0.491)
NEC for r=0.9 all KL = 0.464 +- 0.299 (in-sample avg dev_std = 0.491)
NEC for r=0.9 all L1 = 0.436 +- 0.160 (in-sample avg dev_std = 0.491)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.706
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.2516675
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.587
NEC for r=1.0 class 0 = 0.487 +- 0.281 (in-sample avg dev_std = 0.493)
NEC for r=1.0 class 1 = 0.385 +- 0.281 (in-sample avg dev_std = 0.493)
NEC for r=1.0 class 2 = 0.342 +- 0.281 (in-sample avg dev_std = 0.493)
NEC for r=1.0 all KL = 0.418 +- 0.281 (in-sample avg dev_std = 0.493)
NEC for r=1.0 all L1 = 0.404 +- 0.169 (in-sample avg dev_std = 0.493)
model_dirname= repr_GSATGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 11:53:10 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/28/2024 11:53:10 AM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 11:53:10 AM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 11:53:10 AM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 11:53:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:53:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:53:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:53:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:53:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:53:10 AM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 11:53:10 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 182...
[0m[1;37mINFO[0m: [1mCheckpoint 182: 
-----------------------------------
Train ACCURACY: 0.9313
Train Loss: 0.3197
ID Validation ACCURACY: 0.9367
ID Validation Loss: 0.3118
ID Test ACCURACY: 0.9260
ID Test Loss: 0.3429
OOD Validation ACCURACY: 0.9310
OOD Validation Loss: 0.3727
OOD Test ACCURACY: 0.7160
OOD Test Loss: 0.9099

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 194...
[0m[1;37mINFO[0m: [1mCheckpoint 194: 
-----------------------------------
Train ACCURACY: 0.9302
Train Loss: 0.3212
ID Validation ACCURACY: 0.9347
ID Validation Loss: 0.3115
ID Test ACCURACY: 0.9257
ID Test Loss: 0.3419
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.3812
OOD Test ACCURACY: 0.6987
OOD Test Loss: 0.8929

[0m[1;37mINFO[0m: [1mChartInfo 0.9260 0.7160 0.9257 0.6987 0.9347 0.9317[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.183
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.254
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.299
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.310
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.166
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.216
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.245
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.252


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.454
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.18331
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.363
SUFF++ for r=0.3 class 0 = 0.45 +- 0.272 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.3 class 1 = 0.481 +- 0.272 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.3 class 2 = 0.423 +- 0.272 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.3 all KL = 0.493 +- 0.272 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.3 all L1 = 0.452 +- 0.140 (in-sample avg dev_std = 0.459)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.67
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.25377625000000004
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.414
SUFF++ for r=0.6 class 0 = 0.447 +- 0.257 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.6 class 1 = 0.574 +- 0.257 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.6 class 2 = 0.38 +- 0.257 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.6 all KL = 0.477 +- 0.257 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.6 all L1 = 0.468 +- 0.164 (in-sample avg dev_std = 0.467)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.93
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.29855
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.705
SUFF++ for r=0.9 class 0 = 0.582 +- 0.272 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.9 class 1 = 0.671 +- 0.272 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.9 class 2 = 0.604 +- 0.272 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.9 all KL = 0.673 +- 0.272 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.9 all L1 = 0.619 +- 0.218 (in-sample avg dev_std = 0.396)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.536
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.165565
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.414
SUFF++ for r=0.3 class 0 = 0.492 +- 0.247 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.3 class 1 = 0.463 +- 0.247 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.3 class 2 = 0.388 +- 0.247 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.3 all KL = 0.449 +- 0.247 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.3 all L1 = 0.447 +- 0.105 (in-sample avg dev_std = 0.504)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.619
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.21645
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.455
SUFF++ for r=0.6 class 0 = 0.385 +- 0.260 (in-sample avg dev_std = 0.435)
SUFF++ for r=0.6 class 1 = 0.584 +- 0.260 (in-sample avg dev_std = 0.435)
SUFF++ for r=0.6 class 2 = 0.469 +- 0.260 (in-sample avg dev_std = 0.435)
SUFF++ for r=0.6 all KL = 0.522 +- 0.260 (in-sample avg dev_std = 0.435)
SUFF++ for r=0.6 all L1 = 0.481 +- 0.155 (in-sample avg dev_std = 0.435)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.754
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.24491
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.641
SUFF++ for r=0.9 class 0 = 0.529 +- 0.265 (in-sample avg dev_std = 0.356)
SUFF++ for r=0.9 class 1 = 0.692 +- 0.265 (in-sample avg dev_std = 0.356)
SUFF++ for r=0.9 class 2 = 0.687 +- 0.265 (in-sample avg dev_std = 0.356)
SUFF++ for r=0.9 all KL = 0.688 +- 0.265 (in-sample avg dev_std = 0.356)
SUFF++ for r=0.9 all L1 = 0.637 +- 0.199 (in-sample avg dev_std = 0.356)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.454
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.18331
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.389
NEC for r=0.3 class 0 = 0.549 +- 0.292 (in-sample avg dev_std = 0.427)
NEC for r=0.3 class 1 = 0.44 +- 0.292 (in-sample avg dev_std = 0.427)
NEC for r=0.3 class 2 = 0.504 +- 0.292 (in-sample avg dev_std = 0.427)
NEC for r=0.3 all KL = 0.455 +- 0.292 (in-sample avg dev_std = 0.427)
NEC for r=0.3 all L1 = 0.498 +- 0.199 (in-sample avg dev_std = 0.427)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.67
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.25377625000000004
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.454
NEC for r=0.6 class 0 = 0.522 +- 0.270 (in-sample avg dev_std = 0.491)
NEC for r=0.6 class 1 = 0.392 +- 0.270 (in-sample avg dev_std = 0.491)
NEC for r=0.6 class 2 = 0.564 +- 0.270 (in-sample avg dev_std = 0.491)
NEC for r=0.6 all KL = 0.479 +- 0.270 (in-sample avg dev_std = 0.491)
NEC for r=0.6 all L1 = 0.492 +- 0.181 (in-sample avg dev_std = 0.491)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.929
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.29855
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.535
NEC for r=0.9 class 0 = 0.573 +- 0.221 (in-sample avg dev_std = 0.553)
NEC for r=0.9 class 1 = 0.46 +- 0.221 (in-sample avg dev_std = 0.553)
NEC for r=0.9 class 2 = 0.547 +- 0.221 (in-sample avg dev_std = 0.553)
NEC for r=0.9 all KL = 0.524 +- 0.221 (in-sample avg dev_std = 0.553)
NEC for r=0.9 all L1 = 0.526 +- 0.152 (in-sample avg dev_std = 0.553)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.944
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.30977000000000005
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.531
NEC for r=1.0 class 0 = 0.581 +- 0.208 (in-sample avg dev_std = 0.599)
NEC for r=1.0 class 1 = 0.446 +- 0.208 (in-sample avg dev_std = 0.599)
NEC for r=1.0 class 2 = 0.552 +- 0.208 (in-sample avg dev_std = 0.599)
NEC for r=1.0 all KL = 0.551 +- 0.208 (in-sample avg dev_std = 0.599)
NEC for r=1.0 all L1 = 0.526 +- 0.162 (in-sample avg dev_std = 0.599)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.536
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.165565
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.47
NEC for r=0.3 class 0 = 0.506 +- 0.262 (in-sample avg dev_std = 0.507)
NEC for r=0.3 class 1 = 0.461 +- 0.262 (in-sample avg dev_std = 0.507)
NEC for r=0.3 class 2 = 0.529 +- 0.262 (in-sample avg dev_std = 0.507)
NEC for r=0.3 all KL = 0.49 +- 0.262 (in-sample avg dev_std = 0.507)
NEC for r=0.3 all L1 = 0.498 +- 0.167 (in-sample avg dev_std = 0.507)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.627
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.21645
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.543
NEC for r=0.6 class 0 = 0.551 +- 0.257 (in-sample avg dev_std = 0.471)
NEC for r=0.6 class 1 = 0.4 +- 0.257 (in-sample avg dev_std = 0.471)
NEC for r=0.6 class 2 = 0.503 +- 0.257 (in-sample avg dev_std = 0.471)
NEC for r=0.6 all KL = 0.44 +- 0.257 (in-sample avg dev_std = 0.471)
NEC for r=0.6 all L1 = 0.483 +- 0.161 (in-sample avg dev_std = 0.471)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.755
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.24491
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.58
NEC for r=0.9 class 0 = 0.522 +- 0.298 (in-sample avg dev_std = 0.525)
NEC for r=0.9 class 1 = 0.373 +- 0.298 (in-sample avg dev_std = 0.525)
NEC for r=0.9 class 2 = 0.449 +- 0.298 (in-sample avg dev_std = 0.525)
NEC for r=0.9 all KL = 0.446 +- 0.298 (in-sample avg dev_std = 0.525)
NEC for r=0.9 all L1 = 0.447 +- 0.175 (in-sample avg dev_std = 0.525)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.715
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.25156625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.598
NEC for r=1.0 class 0 = 0.462 +- 0.265 (in-sample avg dev_std = 0.471)
NEC for r=1.0 class 1 = 0.374 +- 0.265 (in-sample avg dev_std = 0.471)
NEC for r=1.0 class 2 = 0.433 +- 0.265 (in-sample avg dev_std = 0.471)
NEC for r=1.0 all KL = 0.39 +- 0.265 (in-sample avg dev_std = 0.471)
NEC for r=1.0 all L1 = 0.422 +- 0.152 (in-sample avg dev_std = 0.471)
model_dirname= repr_GSATGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 11:55:49 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:49 AM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:49 AM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:49 AM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 11:55:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:49 AM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 11:55:49 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 125...
[0m[1;37mINFO[0m: [1mCheckpoint 125: 
-----------------------------------
Train ACCURACY: 0.9305
Train Loss: 0.3203
ID Validation ACCURACY: 0.9370
ID Validation Loss: 0.3167
ID Test ACCURACY: 0.9260
ID Test Loss: 0.3450
OOD Validation ACCURACY: 0.7720
OOD Validation Loss: 0.5765
OOD Test ACCURACY: 0.5833
OOD Test Loss: 1.5578

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 96...
[0m[1;37mINFO[0m: [1mCheckpoint 96: 
-----------------------------------
Train ACCURACY: 0.9248
Train Loss: 0.3355
ID Validation ACCURACY: 0.9310
ID Validation Loss: 0.3225
ID Test ACCURACY: 0.9200
ID Test Loss: 0.3594
OOD Validation ACCURACY: 0.9307
OOD Validation Loss: 0.3760
OOD Test ACCURACY: 0.7793
OOD Test Loss: 0.9678

[0m[1;37mINFO[0m: [1mChartInfo 0.9260 0.5833 0.9200 0.7793 0.9310 0.9307[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.192
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.263
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.303
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.310
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.166
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.217
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.244
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.252


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.423
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.19155625
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.342
SUFF++ for r=0.3 class 0 = 0.472 +- 0.272 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.3 class 1 = 0.52 +- 0.272 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.3 class 2 = 0.47 +- 0.272 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.3 all KL = 0.563 +- 0.272 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.3 all L1 = 0.487 +- 0.144 (in-sample avg dev_std = 0.412)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.525
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.26299500000000003
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.412
SUFF++ for r=0.6 class 0 = 0.456 +- 0.243 (in-sample avg dev_std = 0.400)
SUFF++ for r=0.6 class 1 = 0.57 +- 0.243 (in-sample avg dev_std = 0.400)
SUFF++ for r=0.6 class 2 = 0.404 +- 0.243 (in-sample avg dev_std = 0.400)
SUFF++ for r=0.6 all KL = 0.542 +- 0.243 (in-sample avg dev_std = 0.400)
SUFF++ for r=0.6 all L1 = 0.477 +- 0.157 (in-sample avg dev_std = 0.400)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.853
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.3034075
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.68
SUFF++ for r=0.9 class 0 = 0.559 +- 0.215 (in-sample avg dev_std = 0.345)
SUFF++ for r=0.9 class 1 = 0.726 +- 0.215 (in-sample avg dev_std = 0.345)
SUFF++ for r=0.9 class 2 = 0.615 +- 0.215 (in-sample avg dev_std = 0.345)
SUFF++ for r=0.9 all KL = 0.726 +- 0.215 (in-sample avg dev_std = 0.345)
SUFF++ for r=0.9 all L1 = 0.634 +- 0.187 (in-sample avg dev_std = 0.345)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.389
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.16585625
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.379
SUFF++ for r=0.3 class 0 = 0.509 +- 0.253 (in-sample avg dev_std = 0.458)
SUFF++ for r=0.3 class 1 = 0.473 +- 0.253 (in-sample avg dev_std = 0.458)
SUFF++ for r=0.3 class 2 = 0.397 +- 0.253 (in-sample avg dev_std = 0.458)
SUFF++ for r=0.3 all KL = 0.49 +- 0.253 (in-sample avg dev_std = 0.458)
SUFF++ for r=0.3 all L1 = 0.459 +- 0.116 (in-sample avg dev_std = 0.458)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.577
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.21731749999999997
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.433
SUFF++ for r=0.6 class 0 = 0.358 +- 0.230 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.6 class 1 = 0.591 +- 0.230 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.6 class 2 = 0.484 +- 0.230 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.6 all KL = 0.525 +- 0.230 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.6 all L1 = 0.48 +- 0.152 (in-sample avg dev_std = 0.387)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.585
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.24366875
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.54
SUFF++ for r=0.9 class 0 = 0.536 +- 0.283 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.9 class 1 = 0.659 +- 0.283 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.9 class 2 = 0.664 +- 0.283 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.9 all KL = 0.647 +- 0.283 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.9 all L1 = 0.621 +- 0.187 (in-sample avg dev_std = 0.385)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.42
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.19155625
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.357
NEC for r=0.3 class 0 = 0.557 +- 0.294 (in-sample avg dev_std = 0.398)
NEC for r=0.3 class 1 = 0.389 +- 0.294 (in-sample avg dev_std = 0.398)
NEC for r=0.3 class 2 = 0.464 +- 0.294 (in-sample avg dev_std = 0.398)
NEC for r=0.3 all KL = 0.402 +- 0.294 (in-sample avg dev_std = 0.398)
NEC for r=0.3 all L1 = 0.47 +- 0.197 (in-sample avg dev_std = 0.398)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.525
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.26299500000000003
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.432
NEC for r=0.6 class 0 = 0.52 +- 0.241 (in-sample avg dev_std = 0.435)
NEC for r=0.6 class 1 = 0.464 +- 0.241 (in-sample avg dev_std = 0.435)
NEC for r=0.6 class 2 = 0.561 +- 0.241 (in-sample avg dev_std = 0.435)
NEC for r=0.6 all KL = 0.453 +- 0.241 (in-sample avg dev_std = 0.435)
NEC for r=0.6 all L1 = 0.515 +- 0.153 (in-sample avg dev_std = 0.435)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.851
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.3034075
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.488
NEC for r=0.9 class 0 = 0.548 +- 0.195 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 1 = 0.453 +- 0.195 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 2 = 0.513 +- 0.195 (in-sample avg dev_std = 0.458)
NEC for r=0.9 all KL = 0.444 +- 0.195 (in-sample avg dev_std = 0.458)
NEC for r=0.9 all L1 = 0.505 +- 0.144 (in-sample avg dev_std = 0.458)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.944
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.310065
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.53
NEC for r=1.0 class 0 = 0.594 +- 0.222 (in-sample avg dev_std = 0.559)
NEC for r=1.0 class 1 = 0.421 +- 0.222 (in-sample avg dev_std = 0.559)
NEC for r=1.0 class 2 = 0.534 +- 0.222 (in-sample avg dev_std = 0.559)
NEC for r=1.0 all KL = 0.518 +- 0.222 (in-sample avg dev_std = 0.559)
NEC for r=1.0 all L1 = 0.516 +- 0.168 (in-sample avg dev_std = 0.559)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.389
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.16585625
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.431
NEC for r=0.3 class 0 = 0.497 +- 0.260 (in-sample avg dev_std = 0.480)
NEC for r=0.3 class 1 = 0.508 +- 0.260 (in-sample avg dev_std = 0.480)
NEC for r=0.3 class 2 = 0.512 +- 0.260 (in-sample avg dev_std = 0.480)
NEC for r=0.3 all KL = 0.468 +- 0.260 (in-sample avg dev_std = 0.480)
NEC for r=0.3 all L1 = 0.506 +- 0.162 (in-sample avg dev_std = 0.480)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.584
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.21731749999999997
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.498
NEC for r=0.6 class 0 = 0.608 +- 0.231 (in-sample avg dev_std = 0.434)
NEC for r=0.6 class 1 = 0.422 +- 0.231 (in-sample avg dev_std = 0.434)
NEC for r=0.6 class 2 = 0.505 +- 0.231 (in-sample avg dev_std = 0.434)
NEC for r=0.6 all KL = 0.463 +- 0.231 (in-sample avg dev_std = 0.434)
NEC for r=0.6 all L1 = 0.51 +- 0.155 (in-sample avg dev_std = 0.434)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.584
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.24366875
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.482
NEC for r=0.9 class 0 = 0.543 +- 0.291 (in-sample avg dev_std = 0.507)
NEC for r=0.9 class 1 = 0.387 +- 0.291 (in-sample avg dev_std = 0.507)
NEC for r=0.9 class 2 = 0.442 +- 0.291 (in-sample avg dev_std = 0.507)
NEC for r=0.9 all KL = 0.467 +- 0.291 (in-sample avg dev_std = 0.507)
NEC for r=0.9 all L1 = 0.456 +- 0.160 (in-sample avg dev_std = 0.507)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.608
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.25157125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.517
NEC for r=1.0 class 0 = 0.53 +- 0.247 (in-sample avg dev_std = 0.484)
NEC for r=1.0 class 1 = 0.44 +- 0.247 (in-sample avg dev_std = 0.484)
NEC for r=1.0 class 2 = 0.339 +- 0.247 (in-sample avg dev_std = 0.484)
NEC for r=1.0 all KL = 0.471 +- 0.247 (in-sample avg dev_std = 0.484)
NEC for r=1.0 all L1 = 0.435 +- 0.165 (in-sample avg dev_std = 0.484)
model_dirname= repr_GSATGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 11:58:22 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/28/2024 11:58:22 AM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 11:58:22 AM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 11:58:22 AM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 11:58:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:58:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:58:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:58:22 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:58:22 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:58:22 AM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 11:58:22 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 103...
[0m[1;37mINFO[0m: [1mCheckpoint 103: 
-----------------------------------
Train ACCURACY: 0.9313
Train Loss: 0.3175
ID Validation ACCURACY: 0.9363
ID Validation Loss: 0.3091
ID Test ACCURACY: 0.9260
ID Test Loss: 0.3417
OOD Validation ACCURACY: 0.9290
OOD Validation Loss: 0.3763
OOD Test ACCURACY: 0.6370
OOD Test Loss: 1.3612

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 91...
[0m[1;37mINFO[0m: [1mCheckpoint 91: 
-----------------------------------
Train ACCURACY: 0.9214
Train Loss: 0.3499
ID Validation ACCURACY: 0.9247
ID Validation Loss: 0.3441
ID Test ACCURACY: 0.9190
ID Test Loss: 0.3725
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.4342
OOD Test ACCURACY: 0.6417
OOD Test Loss: 1.3495

[0m[1;37mINFO[0m: [1mChartInfo 0.9260 0.6370 0.9190 0.6417 0.9247 0.9317[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.178
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.251
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.297
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.310
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.161
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.217
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.245
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.251


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.416
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.17810749999999997
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.352
SUFF++ for r=0.3 class 0 = 0.417 +- 0.283 (in-sample avg dev_std = 0.485)
SUFF++ for r=0.3 class 1 = 0.481 +- 0.283 (in-sample avg dev_std = 0.485)
SUFF++ for r=0.3 class 2 = 0.412 +- 0.283 (in-sample avg dev_std = 0.485)
SUFF++ for r=0.3 all KL = 0.469 +- 0.283 (in-sample avg dev_std = 0.485)
SUFF++ for r=0.3 all L1 = 0.437 +- 0.147 (in-sample avg dev_std = 0.485)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.674
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.25134
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.384
SUFF++ for r=0.6 class 0 = 0.443 +- 0.258 (in-sample avg dev_std = 0.491)
SUFF++ for r=0.6 class 1 = 0.466 +- 0.258 (in-sample avg dev_std = 0.491)
SUFF++ for r=0.6 class 2 = 0.35 +- 0.258 (in-sample avg dev_std = 0.491)
SUFF++ for r=0.6 all KL = 0.397 +- 0.258 (in-sample avg dev_std = 0.491)
SUFF++ for r=0.6 all L1 = 0.42 +- 0.145 (in-sample avg dev_std = 0.491)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.934
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.2965975
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.66
SUFF++ for r=0.9 class 0 = 0.567 +- 0.279 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.9 class 1 = 0.661 +- 0.279 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.9 class 2 = 0.586 +- 0.279 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.9 all KL = 0.65 +- 0.279 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.9 all L1 = 0.605 +- 0.226 (in-sample avg dev_std = 0.399)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.425
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.16055374999999997
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.374
SUFF++ for r=0.3 class 0 = 0.481 +- 0.256 (in-sample avg dev_std = 0.537)
SUFF++ for r=0.3 class 1 = 0.453 +- 0.256 (in-sample avg dev_std = 0.537)
SUFF++ for r=0.3 class 2 = 0.362 +- 0.256 (in-sample avg dev_std = 0.537)
SUFF++ for r=0.3 all KL = 0.437 +- 0.256 (in-sample avg dev_std = 0.537)
SUFF++ for r=0.3 all L1 = 0.431 +- 0.122 (in-sample avg dev_std = 0.537)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.756
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.21715125000000002
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.415
SUFF++ for r=0.6 class 0 = 0.467 +- 0.233 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 class 1 = 0.532 +- 0.233 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 class 2 = 0.45 +- 0.233 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 all KL = 0.56 +- 0.233 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 all L1 = 0.484 +- 0.119 (in-sample avg dev_std = 0.415)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.489
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.24486624999999995
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.543
SUFF++ for r=0.9 class 0 = 0.582 +- 0.260 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.9 class 1 = 0.626 +- 0.260 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.9 class 2 = 0.692 +- 0.260 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.9 all KL = 0.69 +- 0.260 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.9 all L1 = 0.634 +- 0.196 (in-sample avg dev_std = 0.348)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.416
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.17810749999999997
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.379
NEC for r=0.3 class 0 = 0.583 +- 0.305 (in-sample avg dev_std = 0.442)
NEC for r=0.3 class 1 = 0.438 +- 0.305 (in-sample avg dev_std = 0.442)
NEC for r=0.3 class 2 = 0.499 +- 0.305 (in-sample avg dev_std = 0.442)
NEC for r=0.3 all KL = 0.471 +- 0.305 (in-sample avg dev_std = 0.442)
NEC for r=0.3 all L1 = 0.506 +- 0.209 (in-sample avg dev_std = 0.442)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.675
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.25134
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.427
NEC for r=0.6 class 0 = 0.536 +- 0.273 (in-sample avg dev_std = 0.527)
NEC for r=0.6 class 1 = 0.53 +- 0.273 (in-sample avg dev_std = 0.527)
NEC for r=0.6 class 2 = 0.592 +- 0.273 (in-sample avg dev_std = 0.527)
NEC for r=0.6 all KL = 0.579 +- 0.273 (in-sample avg dev_std = 0.527)
NEC for r=0.6 all L1 = 0.552 +- 0.167 (in-sample avg dev_std = 0.527)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.933
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.2965975
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.502
NEC for r=0.9 class 0 = 0.571 +- 0.215 (in-sample avg dev_std = 0.543)
NEC for r=0.9 class 1 = 0.51 +- 0.215 (in-sample avg dev_std = 0.543)
NEC for r=0.9 class 2 = 0.535 +- 0.215 (in-sample avg dev_std = 0.543)
NEC for r=0.9 all KL = 0.543 +- 0.215 (in-sample avg dev_std = 0.543)
NEC for r=0.9 all L1 = 0.539 +- 0.155 (in-sample avg dev_std = 0.543)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.944
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.30950125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.526
NEC for r=1.0 class 0 = 0.595 +- 0.226 (in-sample avg dev_std = 0.626)
NEC for r=1.0 class 1 = 0.462 +- 0.226 (in-sample avg dev_std = 0.626)
NEC for r=1.0 class 2 = 0.551 +- 0.226 (in-sample avg dev_std = 0.626)
NEC for r=1.0 all KL = 0.585 +- 0.226 (in-sample avg dev_std = 0.626)
NEC for r=1.0 all L1 = 0.536 +- 0.171 (in-sample avg dev_std = 0.626)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.425
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.16055374999999997
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.421
NEC for r=0.3 class 0 = 0.539 +- 0.272 (in-sample avg dev_std = 0.535)
NEC for r=0.3 class 1 = 0.476 +- 0.272 (in-sample avg dev_std = 0.535)
NEC for r=0.3 class 2 = 0.529 +- 0.272 (in-sample avg dev_std = 0.535)
NEC for r=0.3 all KL = 0.506 +- 0.272 (in-sample avg dev_std = 0.535)
NEC for r=0.3 all L1 = 0.514 +- 0.181 (in-sample avg dev_std = 0.535)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.757
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.21715125000000002
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.474
NEC for r=0.6 class 0 = 0.531 +- 0.234 (in-sample avg dev_std = 0.433)
NEC for r=0.6 class 1 = 0.438 +- 0.234 (in-sample avg dev_std = 0.433)
NEC for r=0.6 class 2 = 0.499 +- 0.234 (in-sample avg dev_std = 0.433)
NEC for r=0.6 all KL = 0.412 +- 0.234 (in-sample avg dev_std = 0.433)
NEC for r=0.6 all L1 = 0.488 +- 0.137 (in-sample avg dev_std = 0.433)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.489
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.24486624999999995
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.5
NEC for r=0.9 class 0 = 0.534 +- 0.289 (in-sample avg dev_std = 0.493)
NEC for r=0.9 class 1 = 0.437 +- 0.289 (in-sample avg dev_std = 0.493)
NEC for r=0.9 class 2 = 0.431 +- 0.289 (in-sample avg dev_std = 0.493)
NEC for r=0.9 all KL = 0.464 +- 0.289 (in-sample avg dev_std = 0.493)
NEC for r=0.9 all L1 = 0.466 +- 0.161 (in-sample avg dev_std = 0.493)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.66
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.2514825
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.53
NEC for r=1.0 class 0 = 0.48 +- 0.268 (in-sample avg dev_std = 0.480)
NEC for r=1.0 class 1 = 0.399 +- 0.268 (in-sample avg dev_std = 0.480)
NEC for r=1.0 class 2 = 0.355 +- 0.268 (in-sample avg dev_std = 0.480)
NEC for r=1.0 all KL = 0.405 +- 0.268 (in-sample avg dev_std = 0.480)
NEC for r=1.0 all L1 = 0.411 +- 0.158 (in-sample avg dev_std = 0.480)
model_dirname= repr_GSATGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 12:00:58 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:58 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:58 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:58 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:58 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 12:00:58 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 160...
[0m[1;37mINFO[0m: [1mCheckpoint 160: 
-----------------------------------
Train ACCURACY: 0.9314
Train Loss: 0.3115
ID Validation ACCURACY: 0.9367
ID Validation Loss: 0.3032
ID Test ACCURACY: 0.9260
ID Test Loss: 0.3364
OOD Validation ACCURACY: 0.9037
OOD Validation Loss: 0.4375
OOD Test ACCURACY: 0.5013
OOD Test Loss: 1.2586

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 114...
[0m[1;37mINFO[0m: [1mCheckpoint 114: 
-----------------------------------
Train ACCURACY: 0.9304
Train Loss: 0.3218
ID Validation ACCURACY: 0.9363
ID Validation Loss: 0.3115
ID Test ACCURACY: 0.9260
ID Test Loss: 0.3512
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.4025
OOD Test ACCURACY: 0.6150
OOD Test Loss: 1.1616

[0m[1;37mINFO[0m: [1mChartInfo 0.9260 0.5013 0.9260 0.6150 0.9363 0.9317[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.187
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.261
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.300
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.310
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.168
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.217
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.243
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.252


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.435
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.1873825
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.359
SUFF++ for r=0.3 class 0 = 0.447 +- 0.270 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.3 class 1 = 0.495 +- 0.270 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.3 class 2 = 0.435 +- 0.270 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.3 all KL = 0.501 +- 0.270 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.3 all L1 = 0.459 +- 0.131 (in-sample avg dev_std = 0.452)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.724
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.26115625000000003
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.423
SUFF++ for r=0.6 class 0 = 0.404 +- 0.275 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 class 1 = 0.569 +- 0.275 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 class 2 = 0.385 +- 0.275 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 all KL = 0.453 +- 0.275 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 all L1 = 0.453 +- 0.166 (in-sample avg dev_std = 0.456)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.919
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.29983
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.732
SUFF++ for r=0.9 class 0 = 0.571 +- 0.292 (in-sample avg dev_std = 0.418)
SUFF++ for r=0.9 class 1 = 0.698 +- 0.292 (in-sample avg dev_std = 0.418)
SUFF++ for r=0.9 class 2 = 0.623 +- 0.292 (in-sample avg dev_std = 0.418)
SUFF++ for r=0.9 all KL = 0.655 +- 0.292 (in-sample avg dev_std = 0.418)
SUFF++ for r=0.9 all L1 = 0.631 +- 0.228 (in-sample avg dev_std = 0.418)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.439
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.16821625
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.385
SUFF++ for r=0.3 class 0 = 0.48 +- 0.268 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.3 class 1 = 0.507 +- 0.268 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.3 class 2 = 0.38 +- 0.268 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.3 all KL = 0.468 +- 0.268 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.3 all L1 = 0.456 +- 0.114 (in-sample avg dev_std = 0.519)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.664
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.21704374999999998
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.465
SUFF++ for r=0.6 class 0 = 0.396 +- 0.288 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.6 class 1 = 0.547 +- 0.288 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.6 class 2 = 0.41 +- 0.288 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.6 all KL = 0.472 +- 0.288 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.6 all L1 = 0.453 +- 0.159 (in-sample avg dev_std = 0.466)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.683
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.24345125
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.606
SUFF++ for r=0.9 class 0 = 0.548 +- 0.261 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.9 class 1 = 0.67 +- 0.261 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.9 class 2 = 0.711 +- 0.261 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.9 all KL = 0.669 +- 0.261 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.9 all L1 = 0.644 +- 0.216 (in-sample avg dev_std = 0.375)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.436
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.1873825
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.407
NEC for r=0.3 class 0 = 0.56 +- 0.285 (in-sample avg dev_std = 0.413)
NEC for r=0.3 class 1 = 0.431 +- 0.285 (in-sample avg dev_std = 0.413)
NEC for r=0.3 class 2 = 0.483 +- 0.285 (in-sample avg dev_std = 0.413)
NEC for r=0.3 all KL = 0.442 +- 0.285 (in-sample avg dev_std = 0.413)
NEC for r=0.3 all L1 = 0.491 +- 0.186 (in-sample avg dev_std = 0.413)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.726
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.26115625000000003
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.451
NEC for r=0.6 class 0 = 0.556 +- 0.269 (in-sample avg dev_std = 0.489)
NEC for r=0.6 class 1 = 0.474 +- 0.269 (in-sample avg dev_std = 0.489)
NEC for r=0.6 class 2 = 0.588 +- 0.269 (in-sample avg dev_std = 0.489)
NEC for r=0.6 all KL = 0.534 +- 0.269 (in-sample avg dev_std = 0.489)
NEC for r=0.6 all L1 = 0.539 +- 0.161 (in-sample avg dev_std = 0.489)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.919
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.29983
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.523
NEC for r=0.9 class 0 = 0.592 +- 0.214 (in-sample avg dev_std = 0.592)
NEC for r=0.9 class 1 = 0.48 +- 0.214 (in-sample avg dev_std = 0.592)
NEC for r=0.9 class 2 = 0.544 +- 0.214 (in-sample avg dev_std = 0.592)
NEC for r=0.9 all KL = 0.579 +- 0.214 (in-sample avg dev_std = 0.592)
NEC for r=0.9 all L1 = 0.538 +- 0.150 (in-sample avg dev_std = 0.592)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.944
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.310015
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.539
NEC for r=1.0 class 0 = 0.579 +- 0.233 (in-sample avg dev_std = 0.618)
NEC for r=1.0 class 1 = 0.428 +- 0.233 (in-sample avg dev_std = 0.618)
NEC for r=1.0 class 2 = 0.564 +- 0.233 (in-sample avg dev_std = 0.618)
NEC for r=1.0 all KL = 0.568 +- 0.233 (in-sample avg dev_std = 0.618)
NEC for r=1.0 all L1 = 0.524 +- 0.176 (in-sample avg dev_std = 0.618)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.439
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.16821625
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.428
NEC for r=0.3 class 0 = 0.524 +- 0.288 (in-sample avg dev_std = 0.534)
NEC for r=0.3 class 1 = 0.432 +- 0.288 (in-sample avg dev_std = 0.534)
NEC for r=0.3 class 2 = 0.537 +- 0.288 (in-sample avg dev_std = 0.534)
NEC for r=0.3 all KL = 0.485 +- 0.288 (in-sample avg dev_std = 0.534)
NEC for r=0.3 all L1 = 0.497 +- 0.174 (in-sample avg dev_std = 0.534)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.664
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.21704374999999998
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.536
NEC for r=0.6 class 0 = 0.565 +- 0.289 (in-sample avg dev_std = 0.517)
NEC for r=0.6 class 1 = 0.445 +- 0.289 (in-sample avg dev_std = 0.517)
NEC for r=0.6 class 2 = 0.527 +- 0.289 (in-sample avg dev_std = 0.517)
NEC for r=0.6 all KL = 0.5 +- 0.289 (in-sample avg dev_std = 0.517)
NEC for r=0.6 all L1 = 0.511 +- 0.165 (in-sample avg dev_std = 0.517)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.683
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.24345125
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.57
NEC for r=0.9 class 0 = 0.541 +- 0.279 (in-sample avg dev_std = 0.575)
NEC for r=0.9 class 1 = 0.408 +- 0.279 (in-sample avg dev_std = 0.575)
NEC for r=0.9 class 2 = 0.435 +- 0.279 (in-sample avg dev_std = 0.575)
NEC for r=0.9 all KL = 0.506 +- 0.279 (in-sample avg dev_std = 0.575)
NEC for r=0.9 all L1 = 0.46 +- 0.170 (in-sample avg dev_std = 0.575)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.509
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.25157125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.563
NEC for r=1.0 class 0 = 0.509 +- 0.246 (in-sample avg dev_std = 0.504)
NEC for r=1.0 class 1 = 0.421 +- 0.246 (in-sample avg dev_std = 0.504)
NEC for r=1.0 class 2 = 0.379 +- 0.246 (in-sample avg dev_std = 0.504)
NEC for r=1.0 all KL = 0.441 +- 0.246 (in-sample avg dev_std = 0.504)
NEC for r=1.0 all L1 = 0.435 +- 0.147 (in-sample avg dev_std = 0.504)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.511, 0.473, 0.694, 1.0], 'all_L1': [0.46, 0.458, 0.646, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.493, 0.477, 0.673, 1.0], 'all_L1': [0.452, 0.468, 0.619, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.563, 0.542, 0.726, 1.0], 'all_L1': [0.487, 0.477, 0.634, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.469, 0.397, 0.65, 1.0], 'all_L1': [0.437, 0.42, 0.605, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.501, 0.453, 0.655, 1.0], 'all_L1': [0.459, 0.453, 0.631, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.448, 0.518, 0.545, 0.569], 'all_L1': [0.5, 0.529, 0.532, 0.53]}), defaultdict(<class 'list'>, {'all_KL': [0.455, 0.479, 0.524, 0.551], 'all_L1': [0.498, 0.492, 0.526, 0.526]}), defaultdict(<class 'list'>, {'all_KL': [0.402, 0.453, 0.444, 0.518], 'all_L1': [0.47, 0.515, 0.505, 0.516]}), defaultdict(<class 'list'>, {'all_KL': [0.471, 0.579, 0.543, 0.585], 'all_L1': [0.506, 0.552, 0.539, 0.536]}), defaultdict(<class 'list'>, {'all_KL': [0.442, 0.534, 0.579, 0.568], 'all_L1': [0.491, 0.539, 0.538, 0.524]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.461, 0.488, 0.675, 1.0], 'all_L1': [0.461, 0.46, 0.651, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.449, 0.522, 0.688, 1.0], 'all_L1': [0.447, 0.481, 0.637, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.49, 0.525, 0.647, 1.0], 'all_L1': [0.459, 0.48, 0.621, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.437, 0.56, 0.69, 1.0], 'all_L1': [0.431, 0.484, 0.634, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.468, 0.472, 0.669, 1.0], 'all_L1': [0.456, 0.453, 0.644, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.472, 0.495, 0.464, 0.418], 'all_L1': [0.479, 0.515, 0.436, 0.404]}), defaultdict(<class 'list'>, {'all_KL': [0.49, 0.44, 0.446, 0.39], 'all_L1': [0.498, 0.483, 0.447, 0.422]}), defaultdict(<class 'list'>, {'all_KL': [0.468, 0.463, 0.467, 0.471], 'all_L1': [0.506, 0.51, 0.456, 0.435]}), defaultdict(<class 'list'>, {'all_KL': [0.506, 0.412, 0.464, 0.405], 'all_L1': [0.514, 0.488, 0.466, 0.411]}), defaultdict(<class 'list'>, {'all_KL': [0.485, 0.5, 0.506, 0.441], 'all_L1': [0.497, 0.511, 0.46, 0.435]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.459 +- 0.016, 0.455 +- 0.019, 0.627 +- 0.014, 1.000 +- 0.000
suff++ class all_KL  =  0.507 +- 0.031, 0.468 +- 0.047, 0.680 +- 0.028, 1.000 +- 0.000
suff++_acc_int  =  0.355 +- 0.007, 0.414 +- 0.018, 0.700 +- 0.026
nec class all_L1  =  0.493 +- 0.012, 0.525 +- 0.021, 0.528 +- 0.012, 0.526 +- 0.007
nec class all_KL  =  0.444 +- 0.023, 0.513 +- 0.044, 0.527 +- 0.045, 0.558 +- 0.023
nec_acc_int  =  0.380 +- 0.017, 0.448 +- 0.017, 0.514 +- 0.017, 0.530 +- 0.005

Eval split test
suff++ class all_L1  =  0.451 +- 0.011, 0.472 +- 0.013, 0.637 +- 0.010, 1.000 +- 0.000
suff++ class all_KL  =  0.461 +- 0.018, 0.513 +- 0.031, 0.674 +- 0.016, 1.000 +- 0.000
suff++_acc_int  =  0.388 +- 0.014, 0.450 +- 0.024, 0.583 +- 0.039
nec class all_L1  =  0.499 +- 0.012, 0.501 +- 0.013, 0.453 +- 0.011, 0.421 +- 0.012
nec class all_KL  =  0.484 +- 0.014, 0.462 +- 0.033, 0.469 +- 0.020, 0.425 +- 0.028
nec_acc_int  =  0.435 +- 0.018, 0.517 +- 0.027, 0.538 +- 0.040, 0.559 +- 0.032


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.476 +- 0.003, 0.490 +- 0.006, 0.577 +- 0.008, 0.763 +- 0.003
Faith. Armon (L1)= 		  =  0.475 +- 0.004, 0.487 +- 0.007, 0.573 +- 0.008, 0.690 +- 0.006
Faith. GMean (L1)= 	  =  0.475 +- 0.003, 0.489 +- 0.007, 0.575 +- 0.008, 0.726 +- 0.005
Faith. Aritm (KL)= 		  =  0.476 +- 0.005, 0.490 +- 0.007, 0.603 +- 0.013, 0.779 +- 0.011
Faith. Armon (KL)= 		  =  0.472 +- 0.003, 0.485 +- 0.009, 0.591 +- 0.023, 0.716 +- 0.019
Faith. GMean (KL)= 	  =  0.474 +- 0.003, 0.488 +- 0.008, 0.597 +- 0.018, 0.747 +- 0.015

Eval split test
Faith. Aritm (L1)= 		  =  0.475 +- 0.004, 0.486 +- 0.005, 0.545 +- 0.005, 0.711 +- 0.006
Faith. Armon (L1)= 		  =  0.473 +- 0.005, 0.486 +- 0.005, 0.529 +- 0.006, 0.593 +- 0.012
Faith. GMean (L1)= 	  =  0.474 +- 0.004, 0.486 +- 0.005, 0.537 +- 0.005, 0.649 +- 0.010
Faith. Aritm (KL)= 		  =  0.473 +- 0.005, 0.488 +- 0.005, 0.572 +- 0.010, 0.712 +- 0.014
Faith. Armon (KL)= 		  =  0.472 +- 0.005, 0.484 +- 0.007, 0.553 +- 0.013, 0.596 +- 0.028
Faith. GMean (KL)= 	  =  0.472 +- 0.005, 0.486 +- 0.006, 0.562 +- 0.011, 0.652 +- 0.022
Computed for split load_split = id



Completed in  0:13:25.314217  for GSATGIN GOODMotif2/basis



DONE GSAT GOODMotif2/basis
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 12:04:00 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/28/2024 12:04:01 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 12:04:01 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 12:04:01 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:04:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:04:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:04:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:04:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:04:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:04:01 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 12:04:01 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:04:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:04:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:04:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:04:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:04:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:04:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:04:01 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:04:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:04:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:04:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:04:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:04:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:04:01 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:04:01 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 109...
[0m[1;37mINFO[0m: [1mCheckpoint 109: 
-----------------------------------
Train ACCURACY: 0.9994
Train Loss: 0.0025
ID Validation ACCURACY: 0.9106
ID Validation Loss: 0.5101
ID Test ACCURACY: 0.8987
ID Test Loss: 0.6337
OOD Validation ACCURACY: 0.8501
OOD Validation Loss: 1.2162
OOD Test ACCURACY: 0.7241
OOD Test Loss: 5.9794

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 92...
[0m[1;37mINFO[0m: [1mCheckpoint 92: 
-----------------------------------
Train ACCURACY: 0.9918
Train Loss: 0.0210
ID Validation ACCURACY: 0.9013
ID Validation Loss: 0.3950
ID Test ACCURACY: 0.8921
ID Test Loss: 0.4835
OOD Validation ACCURACY: 0.8680
OOD Validation Loss: 0.6745
OOD Test ACCURACY: 0.7971
OOD Test Loss: 1.9556

[0m[1;37mINFO[0m: [1mChartInfo 0.8987 0.7241 0.8921 0.7971 0.9013 0.8680[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/28/2024 12:04:02 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.821
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.776
SUFF++ for r=0.6 class 0.0 = 0.676 +- 0.324 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 class 1.0 = 0.911 +- 0.324 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 all KL = 0.698 +- 0.324 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 all L1 = 0.813 +- 0.219 (in-sample avg dev_std = 0.452)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.85
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.855
SUFF++ for r=0.9 class 0.0 = 0.91 +- 0.174 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.9 class 1.0 = 0.954 +- 0.174 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.9 all KL = 0.937 +- 0.174 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.9 all L1 = 0.934 +- 0.158 (in-sample avg dev_std = 0.158)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.665
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.617
SUFF++ for r=0.3 class 0.0 = 0.638 +- 0.317 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.3 class 1.0 = 0.86 +- 0.317 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.3 all KL = 0.634 +- 0.317 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.3 all L1 = 0.753 +- 0.227 (in-sample avg dev_std = 0.476)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.705
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.657
SUFF++ for r=0.6 class 0.0 = 0.682 +- 0.327 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.6 class 1.0 = 0.947 +- 0.327 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.6 all KL = 0.748 +- 0.327 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.6 all L1 = 0.819 +- 0.234 (in-sample avg dev_std = 0.428)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.74
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.712
SUFF++ for r=0.9 class 0.0 = 0.827 +- 0.258 (in-sample avg dev_std = 0.302)
SUFF++ for r=0.9 class 1.0 = 0.979 +- 0.258 (in-sample avg dev_std = 0.302)
SUFF++ for r=0.9 all KL = 0.862 +- 0.258 (in-sample avg dev_std = 0.302)
SUFF++ for r=0.9 all L1 = 0.905 +- 0.178 (in-sample avg dev_std = 0.302)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.821
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.811
NEC for r=0.6 class 0.0 = 0.166 +- 0.225 (in-sample avg dev_std = 0.223)
NEC for r=0.6 class 1.0 = 0.052 +- 0.225 (in-sample avg dev_std = 0.223)
NEC for r=0.6 all KL = 0.102 +- 0.225 (in-sample avg dev_std = 0.223)
NEC for r=0.6 all L1 = 0.099 +- 0.190 (in-sample avg dev_std = 0.223)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.849
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.853
NEC for r=0.9 class 0.0 = 0.069 +- 0.138 (in-sample avg dev_std = 0.131)
NEC for r=0.9 class 1.0 = 0.031 +- 0.138 (in-sample avg dev_std = 0.131)
NEC for r=0.9 all KL = 0.044 +- 0.138 (in-sample avg dev_std = 0.131)
NEC for r=0.9 all L1 = 0.047 +- 0.127 (in-sample avg dev_std = 0.131)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.853
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.852
NEC for r=1.0 class 0.0 = 0.061 +- 0.127 (in-sample avg dev_std = 0.125)
NEC for r=1.0 class 1.0 = 0.028 +- 0.127 (in-sample avg dev_std = 0.125)
NEC for r=1.0 all KL = 0.037 +- 0.127 (in-sample avg dev_std = 0.125)
NEC for r=1.0 all L1 = 0.042 +- 0.116 (in-sample avg dev_std = 0.125)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.665
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.66
NEC for r=0.3 class 0.0 = 0.26 +- 0.239 (in-sample avg dev_std = 0.284)
NEC for r=0.3 class 1.0 = 0.069 +- 0.239 (in-sample avg dev_std = 0.284)
NEC for r=0.3 all KL = 0.155 +- 0.239 (in-sample avg dev_std = 0.284)
NEC for r=0.3 all L1 = 0.161 +- 0.222 (in-sample avg dev_std = 0.284)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.705
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.708
NEC for r=0.6 class 0.0 = 0.215 +- 0.231 (in-sample avg dev_std = 0.264)
NEC for r=0.6 class 1.0 = 0.039 +- 0.231 (in-sample avg dev_std = 0.264)
NEC for r=0.6 all KL = 0.131 +- 0.231 (in-sample avg dev_std = 0.264)
NEC for r=0.6 all L1 = 0.124 +- 0.204 (in-sample avg dev_std = 0.264)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.74
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.735
NEC for r=0.9 class 0.0 = 0.123 +- 0.190 (in-sample avg dev_std = 0.191)
NEC for r=0.9 class 1.0 = 0.018 +- 0.190 (in-sample avg dev_std = 0.191)
NEC for r=0.9 all KL = 0.076 +- 0.190 (in-sample avg dev_std = 0.191)
NEC for r=0.9 all L1 = 0.069 +- 0.161 (in-sample avg dev_std = 0.191)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.755
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.745
NEC for r=1.0 class 0.0 = 0.095 +- 0.174 (in-sample avg dev_std = 0.183)
NEC for r=1.0 class 1.0 = 0.023 +- 0.174 (in-sample avg dev_std = 0.183)
NEC for r=1.0 all KL = 0.061 +- 0.174 (in-sample avg dev_std = 0.183)
NEC for r=1.0 all L1 = 0.057 +- 0.145 (in-sample avg dev_std = 0.183)
model_dirname= repr_GSATvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 12:06:32 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/28/2024 12:06:33 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 12:06:33 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 12:06:33 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:06:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:06:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:06:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:06:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:06:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:06:33 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 12:06:33 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:06:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:06:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:06:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:06:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:06:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:06:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:06:33 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:06:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:06:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:06:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:06:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:06:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:06:34 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:06:34 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 197...
[0m[1;37mINFO[0m: [1mCheckpoint 197: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.9113
ID Validation Loss: 0.7707
ID Test ACCURACY: 0.9036
ID Test Loss: 0.8911
OOD Validation ACCURACY: 0.8742
OOD Validation Loss: 0.9645
OOD Test ACCURACY: 0.8288
OOD Test Loss: 1.5437

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 198...
[0m[1;37mINFO[0m: [1mCheckpoint 198: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.9087
ID Validation Loss: 0.6769
ID Test ACCURACY: 0.9010
ID Test Loss: 0.7782
OOD Validation ACCURACY: 0.8751
OOD Validation Loss: 0.7905
OOD Test ACCURACY: 0.8313
OOD Test Loss: 1.1097

[0m[1;37mINFO[0m: [1mChartInfo 0.9036 0.8288 0.9010 0.8313 0.9087 0.8751[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/28/2024 12:06:34 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.815
SUFF++ for r=0.6 class 0.0 = 0.691 +- 0.399 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.6 class 1.0 = 0.872 +- 0.399 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.6 all KL = 0.57 +- 0.399 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.6 all L1 = 0.796 +- 0.230 (in-sample avg dev_std = 0.520)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.872
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.87
SUFF++ for r=0.9 class 0.0 = 0.967 +- 0.068 (in-sample avg dev_std = 0.088)
SUFF++ for r=0.9 class 1.0 = 0.977 +- 0.068 (in-sample avg dev_std = 0.088)
SUFF++ for r=0.9 all KL = 0.981 +- 0.068 (in-sample avg dev_std = 0.088)
SUFF++ for r=0.9 all L1 = 0.972 +- 0.094 (in-sample avg dev_std = 0.088)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.767
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.676
SUFF++ for r=0.3 class 0.0 = 0.6 +- 0.395 (in-sample avg dev_std = 0.609)
SUFF++ for r=0.3 class 1.0 = 0.873 +- 0.395 (in-sample avg dev_std = 0.609)
SUFF++ for r=0.3 all KL = 0.493 +- 0.395 (in-sample avg dev_std = 0.609)
SUFF++ for r=0.3 all L1 = 0.741 +- 0.238 (in-sample avg dev_std = 0.609)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.836
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.776
SUFF++ for r=0.6 class 0.0 = 0.699 +- 0.364 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 1.0 = 0.885 +- 0.364 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 all KL = 0.611 +- 0.364 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 all L1 = 0.795 +- 0.223 (in-sample avg dev_std = 0.509)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.851
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.845
SUFF++ for r=0.9 class 0.0 = 0.914 +- 0.225 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 1.0 = 0.912 +- 0.225 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 all KL = 0.885 +- 0.225 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 all L1 = 0.913 +- 0.172 (in-sample avg dev_std = 0.260)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.866
NEC for r=0.6 class 0.0 = 0.14 +- 0.270 (in-sample avg dev_std = 0.198)
NEC for r=0.6 class 1.0 = 0.057 +- 0.270 (in-sample avg dev_std = 0.198)
NEC for r=0.6 all KL = 0.112 +- 0.270 (in-sample avg dev_std = 0.198)
NEC for r=0.6 all L1 = 0.091 +- 0.211 (in-sample avg dev_std = 0.198)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.877
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.879
NEC for r=0.9 class 0.0 = 0.028 +- 0.098 (in-sample avg dev_std = 0.094)
NEC for r=0.9 class 1.0 = 0.032 +- 0.098 (in-sample avg dev_std = 0.094)
NEC for r=0.9 all KL = 0.025 +- 0.098 (in-sample avg dev_std = 0.094)
NEC for r=0.9 all L1 = 0.03 +- 0.112 (in-sample avg dev_std = 0.094)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.881
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.876
NEC for r=1.0 class 0.0 = 0.025 +- 0.100 (in-sample avg dev_std = 0.092)
NEC for r=1.0 class 1.0 = 0.032 +- 0.100 (in-sample avg dev_std = 0.092)
NEC for r=1.0 all KL = 0.024 +- 0.100 (in-sample avg dev_std = 0.092)
NEC for r=1.0 all L1 = 0.029 +- 0.111 (in-sample avg dev_std = 0.092)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.767
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.751
NEC for r=0.3 class 0.0 = 0.205 +- 0.300 (in-sample avg dev_std = 0.318)
NEC for r=0.3 class 1.0 = 0.046 +- 0.300 (in-sample avg dev_std = 0.318)
NEC for r=0.3 all KL = 0.169 +- 0.300 (in-sample avg dev_std = 0.318)
NEC for r=0.3 all L1 = 0.123 +- 0.220 (in-sample avg dev_std = 0.318)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.836
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.817
NEC for r=0.6 class 0.0 = 0.162 +- 0.266 (in-sample avg dev_std = 0.292)
NEC for r=0.6 class 1.0 = 0.067 +- 0.266 (in-sample avg dev_std = 0.292)
NEC for r=0.6 all KL = 0.141 +- 0.266 (in-sample avg dev_std = 0.292)
NEC for r=0.6 all L1 = 0.113 +- 0.210 (in-sample avg dev_std = 0.292)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.851
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.851
NEC for r=0.9 class 0.0 = 0.069 +- 0.172 (in-sample avg dev_std = 0.183)
NEC for r=0.9 class 1.0 = 0.064 +- 0.172 (in-sample avg dev_std = 0.183)
NEC for r=0.9 all KL = 0.065 +- 0.172 (in-sample avg dev_std = 0.183)
NEC for r=0.9 all L1 = 0.066 +- 0.158 (in-sample avg dev_std = 0.183)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.863
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.851
NEC for r=1.0 class 0.0 = 0.055 +- 0.149 (in-sample avg dev_std = 0.159)
NEC for r=1.0 class 1.0 = 0.056 +- 0.149 (in-sample avg dev_std = 0.159)
NEC for r=1.0 all KL = 0.048 +- 0.149 (in-sample avg dev_std = 0.159)
NEC for r=1.0 all L1 = 0.055 +- 0.144 (in-sample avg dev_std = 0.159)
model_dirname= repr_GSATvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 12:08:56 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:57 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:57 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:57 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:08:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:57 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 12:08:57 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:08:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:57 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:08:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:57 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:08:57 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 176...
[0m[1;37mINFO[0m: [1mCheckpoint 176: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0002
ID Validation ACCURACY: 0.9070
ID Validation Loss: 0.6761
ID Test ACCURACY: 0.9085
ID Test Loss: 0.7858
OOD Validation ACCURACY: 0.8698
OOD Validation Loss: 0.7126
OOD Test ACCURACY: 0.8129
OOD Test Loss: 0.9194

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 176...
[0m[1;37mINFO[0m: [1mCheckpoint 176: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0002
ID Validation ACCURACY: 0.9070
ID Validation Loss: 0.6761
ID Test ACCURACY: 0.9085
ID Test Loss: 0.7858
OOD Validation ACCURACY: 0.8698
OOD Validation Loss: 0.7126
OOD Test ACCURACY: 0.8129
OOD Test Loss: 0.9194

[0m[1;37mINFO[0m: [1mChartInfo 0.9085 0.8129 0.9085 0.8129 0.9070 0.8698[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/28/2024 12:08:57 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.867
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.799
SUFF++ for r=0.6 class 0.0 = 0.877 +- 0.388 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.6 class 1.0 = 0.787 +- 0.388 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.6 all KL = 0.604 +- 0.388 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.6 all L1 = 0.825 +- 0.201 (in-sample avg dev_std = 0.489)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.856
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.858
SUFF++ for r=0.9 class 0.0 = 0.966 +- 0.103 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 class 1.0 = 0.959 +- 0.103 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 all KL = 0.97 +- 0.103 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 all L1 = 0.962 +- 0.117 (in-sample avg dev_std = 0.107)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.74
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.654
SUFF++ for r=0.3 class 0.0 = 0.905 +- 0.376 (in-sample avg dev_std = 0.566)
SUFF++ for r=0.3 class 1.0 = 0.627 +- 0.376 (in-sample avg dev_std = 0.566)
SUFF++ for r=0.3 all KL = 0.603 +- 0.376 (in-sample avg dev_std = 0.566)
SUFF++ for r=0.3 all L1 = 0.761 +- 0.238 (in-sample avg dev_std = 0.566)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.783
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.722
SUFF++ for r=0.6 class 0.0 = 0.895 +- 0.349 (in-sample avg dev_std = 0.474)
SUFF++ for r=0.6 class 1.0 = 0.704 +- 0.349 (in-sample avg dev_std = 0.474)
SUFF++ for r=0.6 all KL = 0.667 +- 0.349 (in-sample avg dev_std = 0.474)
SUFF++ for r=0.6 all L1 = 0.797 +- 0.208 (in-sample avg dev_std = 0.474)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.815
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.806
SUFF++ for r=0.9 class 0.0 = 0.92 +- 0.172 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.9 class 1.0 = 0.887 +- 0.172 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.9 all KL = 0.904 +- 0.172 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.9 all L1 = 0.903 +- 0.151 (in-sample avg dev_std = 0.221)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.867
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.838
NEC for r=0.6 class 0.0 = 0.077 +- 0.238 (in-sample avg dev_std = 0.205)
NEC for r=0.6 class 1.0 = 0.085 +- 0.238 (in-sample avg dev_std = 0.205)
NEC for r=0.6 all KL = 0.098 +- 0.238 (in-sample avg dev_std = 0.205)
NEC for r=0.6 all L1 = 0.082 +- 0.194 (in-sample avg dev_std = 0.205)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.849
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.86
NEC for r=0.9 class 0.0 = 0.041 +- 0.120 (in-sample avg dev_std = 0.109)
NEC for r=0.9 class 1.0 = 0.042 +- 0.120 (in-sample avg dev_std = 0.109)
NEC for r=0.9 all KL = 0.034 +- 0.120 (in-sample avg dev_std = 0.109)
NEC for r=0.9 all L1 = 0.042 +- 0.126 (in-sample avg dev_std = 0.109)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.86
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.861
NEC for r=1.0 class 0.0 = 0.047 +- 0.129 (in-sample avg dev_std = 0.104)
NEC for r=1.0 class 1.0 = 0.043 +- 0.129 (in-sample avg dev_std = 0.104)
NEC for r=1.0 all KL = 0.037 +- 0.129 (in-sample avg dev_std = 0.104)
NEC for r=1.0 all L1 = 0.045 +- 0.134 (in-sample avg dev_std = 0.104)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.74
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.723
NEC for r=0.3 class 0.0 = 0.046 +- 0.216 (in-sample avg dev_std = 0.227)
NEC for r=0.3 class 1.0 = 0.136 +- 0.216 (in-sample avg dev_std = 0.227)
NEC for r=0.3 all KL = 0.102 +- 0.216 (in-sample avg dev_std = 0.227)
NEC for r=0.3 all L1 = 0.093 +- 0.182 (in-sample avg dev_std = 0.227)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.783
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.781
NEC for r=0.6 class 0.0 = 0.055 +- 0.159 (in-sample avg dev_std = 0.182)
NEC for r=0.6 class 1.0 = 0.115 +- 0.159 (in-sample avg dev_std = 0.182)
NEC for r=0.6 all KL = 0.072 +- 0.159 (in-sample avg dev_std = 0.182)
NEC for r=0.6 all L1 = 0.086 +- 0.163 (in-sample avg dev_std = 0.182)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.815
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.815
NEC for r=0.9 class 0.0 = 0.07 +- 0.124 (in-sample avg dev_std = 0.163)
NEC for r=0.9 class 1.0 = 0.092 +- 0.124 (in-sample avg dev_std = 0.163)
NEC for r=0.9 all KL = 0.053 +- 0.124 (in-sample avg dev_std = 0.163)
NEC for r=0.9 all L1 = 0.081 +- 0.145 (in-sample avg dev_std = 0.163)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.83
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.826
NEC for r=1.0 class 0.0 = 0.07 +- 0.102 (in-sample avg dev_std = 0.141)
NEC for r=1.0 class 1.0 = 0.079 +- 0.102 (in-sample avg dev_std = 0.141)
NEC for r=1.0 all KL = 0.041 +- 0.102 (in-sample avg dev_std = 0.141)
NEC for r=1.0 all L1 = 0.075 +- 0.133 (in-sample avg dev_std = 0.141)
model_dirname= repr_GSATvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 12:11:20 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/28/2024 12:11:21 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 12:11:21 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 12:11:21 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:11:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:11:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:11:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:11:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:11:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:11:21 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 12:11:21 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:11:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:11:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:11:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:11:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:11:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:11:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:11:21 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:11:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:11:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:11:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:11:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:11:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:11:21 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:11:21 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 186...
[0m[1;37mINFO[0m: [1mCheckpoint 186: 
-----------------------------------
Train ACCURACY: 0.9999
Train Loss: 0.0001
ID Validation ACCURACY: 0.9147
ID Validation Loss: 0.6881
ID Test ACCURACY: 0.9072
ID Test Loss: 0.8292
OOD Validation ACCURACY: 0.8620
OOD Validation Loss: 1.4572
OOD Test ACCURACY: 0.8092
OOD Test Loss: 3.9476

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 194...
[0m[1;37mINFO[0m: [1mCheckpoint 194: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.9128
ID Validation Loss: 0.7432
ID Test ACCURACY: 0.9068
ID Test Loss: 0.8946
OOD Validation ACCURACY: 0.8693
OOD Validation Loss: 1.4169
OOD Test ACCURACY: 0.8193
OOD Test Loss: 3.6034

[0m[1;37mINFO[0m: [1mChartInfo 0.9072 0.8092 0.9068 0.8193 0.9128 0.8693[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/28/2024 12:11:21 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.849
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.795
SUFF++ for r=0.6 class 0.0 = 0.705 +- 0.389 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.6 class 1.0 = 0.935 +- 0.389 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.6 all KL = 0.697 +- 0.389 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.6 all L1 = 0.839 +- 0.232 (in-sample avg dev_std = 0.460)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.9
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.867
SUFF++ for r=0.9 class 0.0 = 0.921 +- 0.179 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.9 class 1.0 = 0.976 +- 0.179 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.9 all KL = 0.949 +- 0.179 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.9 all L1 = 0.952 +- 0.157 (in-sample avg dev_std = 0.144)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.686
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.629
SUFF++ for r=0.3 class 0.0 = 0.638 +- 0.380 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.3 class 1.0 = 0.865 +- 0.380 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.3 all KL = 0.561 +- 0.380 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.3 all L1 = 0.755 +- 0.248 (in-sample avg dev_std = 0.555)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.754
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.713
SUFF++ for r=0.6 class 0.0 = 0.693 +- 0.389 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.6 class 1.0 = 0.935 +- 0.389 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.6 all KL = 0.639 +- 0.389 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.6 all L1 = 0.818 +- 0.218 (in-sample avg dev_std = 0.494)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.829
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.826
SUFF++ for r=0.9 class 0.0 = 0.896 +- 0.214 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 class 1.0 = 0.963 +- 0.214 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 all KL = 0.894 +- 0.214 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 all L1 = 0.93 +- 0.150 (in-sample avg dev_std = 0.246)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.849
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.84
NEC for r=0.6 class 0.0 = 0.17 +- 0.260 (in-sample avg dev_std = 0.252)
NEC for r=0.6 class 1.0 = 0.024 +- 0.260 (in-sample avg dev_std = 0.252)
NEC for r=0.6 all KL = 0.105 +- 0.260 (in-sample avg dev_std = 0.252)
NEC for r=0.6 all L1 = 0.085 +- 0.207 (in-sample avg dev_std = 0.252)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.888
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.867
NEC for r=0.9 class 0.0 = 0.076 +- 0.172 (in-sample avg dev_std = 0.137)
NEC for r=0.9 class 1.0 = 0.019 +- 0.172 (in-sample avg dev_std = 0.137)
NEC for r=0.9 all KL = 0.045 +- 0.172 (in-sample avg dev_std = 0.137)
NEC for r=0.9 all L1 = 0.043 +- 0.149 (in-sample avg dev_std = 0.137)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.888
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.874
NEC for r=1.0 class 0.0 = 0.06 +- 0.158 (in-sample avg dev_std = 0.132)
NEC for r=1.0 class 1.0 = 0.018 +- 0.158 (in-sample avg dev_std = 0.132)
NEC for r=1.0 all KL = 0.037 +- 0.158 (in-sample avg dev_std = 0.132)
NEC for r=1.0 all L1 = 0.036 +- 0.134 (in-sample avg dev_std = 0.132)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.686
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.682
NEC for r=0.3 class 0.0 = 0.199 +- 0.316 (in-sample avg dev_std = 0.344)
NEC for r=0.3 class 1.0 = 0.09 +- 0.316 (in-sample avg dev_std = 0.344)
NEC for r=0.3 all KL = 0.201 +- 0.316 (in-sample avg dev_std = 0.344)
NEC for r=0.3 all L1 = 0.143 +- 0.232 (in-sample avg dev_std = 0.344)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.754
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.76
NEC for r=0.6 class 0.0 = 0.139 +- 0.235 (in-sample avg dev_std = 0.234)
NEC for r=0.6 class 1.0 = 0.029 +- 0.235 (in-sample avg dev_std = 0.234)
NEC for r=0.6 all KL = 0.113 +- 0.235 (in-sample avg dev_std = 0.234)
NEC for r=0.6 all L1 = 0.082 +- 0.174 (in-sample avg dev_std = 0.234)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.829
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.825
NEC for r=0.9 class 0.0 = 0.081 +- 0.170 (in-sample avg dev_std = 0.168)
NEC for r=0.9 class 1.0 = 0.03 +- 0.170 (in-sample avg dev_std = 0.168)
NEC for r=0.9 all KL = 0.06 +- 0.170 (in-sample avg dev_std = 0.168)
NEC for r=0.9 all L1 = 0.055 +- 0.147 (in-sample avg dev_std = 0.168)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.83
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.83
NEC for r=1.0 class 0.0 = 0.068 +- 0.169 (in-sample avg dev_std = 0.161)
NEC for r=1.0 class 1.0 = 0.032 +- 0.169 (in-sample avg dev_std = 0.161)
NEC for r=1.0 all KL = 0.057 +- 0.169 (in-sample avg dev_std = 0.161)
NEC for r=1.0 all L1 = 0.05 +- 0.140 (in-sample avg dev_std = 0.161)
model_dirname= repr_GSATvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 12:13:45 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:46 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:46 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:46 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:13:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:46 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 12:13:46 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:13:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:46 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:13:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:46 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:13:46 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 196...
[0m[1;37mINFO[0m: [1mCheckpoint 196: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.9085
ID Validation Loss: 0.7434
ID Test ACCURACY: 0.9083
ID Test Loss: 0.7942
OOD Validation ACCURACY: 0.8622
OOD Validation Loss: 1.0214
OOD Test ACCURACY: 0.7831
OOD Test Loss: 1.9072

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 198...
[0m[1;37mINFO[0m: [1mCheckpoint 198: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.9062
ID Validation Loss: 0.7432
ID Test ACCURACY: 0.9059
ID Test Loss: 0.8164
OOD Validation ACCURACY: 0.8689
OOD Validation Loss: 0.9364
OOD Test ACCURACY: 0.8087
OOD Test Loss: 1.4925

[0m[1;37mINFO[0m: [1mChartInfo 0.9083 0.7831 0.9059 0.8087 0.9062 0.8689[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/28/2024 12:13:46 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.849
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.811
SUFF++ for r=0.6 class 0.0 = 0.737 +- 0.392 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.6 class 1.0 = 0.874 +- 0.392 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.6 all KL = 0.613 +- 0.392 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.6 all L1 = 0.817 +- 0.220 (in-sample avg dev_std = 0.516)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.861
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.856
SUFF++ for r=0.9 class 0.0 = 0.915 +- 0.171 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 class 1.0 = 0.961 +- 0.171 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 all KL = 0.946 +- 0.171 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 all L1 = 0.94 +- 0.162 (in-sample avg dev_std = 0.152)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.719
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.658
SUFF++ for r=0.3 class 0.0 = 0.648 +- 0.422 (in-sample avg dev_std = 0.551)
SUFF++ for r=0.3 class 1.0 = 0.936 +- 0.422 (in-sample avg dev_std = 0.551)
SUFF++ for r=0.3 all KL = 0.606 +- 0.422 (in-sample avg dev_std = 0.551)
SUFF++ for r=0.3 all L1 = 0.797 +- 0.246 (in-sample avg dev_std = 0.551)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.762
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.705
SUFF++ for r=0.6 class 0.0 = 0.685 +- 0.369 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 class 1.0 = 0.949 +- 0.369 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 all KL = 0.696 +- 0.369 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 all L1 = 0.821 +- 0.228 (in-sample avg dev_std = 0.468)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.803
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.786
SUFF++ for r=0.9 class 0.0 = 0.854 +- 0.181 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.9 class 1.0 = 0.971 +- 0.181 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.9 all KL = 0.903 +- 0.181 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.9 all L1 = 0.914 +- 0.154 (in-sample avg dev_std = 0.247)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.849
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.836
NEC for r=0.6 class 0.0 = 0.14 +- 0.271 (in-sample avg dev_std = 0.222)
NEC for r=0.6 class 1.0 = 0.051 +- 0.271 (in-sample avg dev_std = 0.222)
NEC for r=0.6 all KL = 0.108 +- 0.271 (in-sample avg dev_std = 0.222)
NEC for r=0.6 all L1 = 0.088 +- 0.220 (in-sample avg dev_std = 0.222)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.86
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.85
NEC for r=0.9 class 0.0 = 0.081 +- 0.180 (in-sample avg dev_std = 0.149)
NEC for r=0.9 class 1.0 = 0.036 +- 0.180 (in-sample avg dev_std = 0.149)
NEC for r=0.9 all KL = 0.054 +- 0.180 (in-sample avg dev_std = 0.149)
NEC for r=0.9 all L1 = 0.055 +- 0.164 (in-sample avg dev_std = 0.149)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.874
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.853
NEC for r=1.0 class 0.0 = 0.076 +- 0.186 (in-sample avg dev_std = 0.156)
NEC for r=1.0 class 1.0 = 0.04 +- 0.186 (in-sample avg dev_std = 0.156)
NEC for r=1.0 all KL = 0.057 +- 0.186 (in-sample avg dev_std = 0.156)
NEC for r=1.0 all L1 = 0.055 +- 0.167 (in-sample avg dev_std = 0.156)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.719
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.709
NEC for r=0.3 class 0.0 = 0.187 +- 0.293 (in-sample avg dev_std = 0.299)
NEC for r=0.3 class 1.0 = 0.016 +- 0.293 (in-sample avg dev_std = 0.299)
NEC for r=0.3 all KL = 0.142 +- 0.293 (in-sample avg dev_std = 0.299)
NEC for r=0.3 all L1 = 0.099 +- 0.209 (in-sample avg dev_std = 0.299)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.762
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.765
NEC for r=0.6 class 0.0 = 0.154 +- 0.205 (in-sample avg dev_std = 0.227)
NEC for r=0.6 class 1.0 = 0.021 +- 0.205 (in-sample avg dev_std = 0.227)
NEC for r=0.6 all KL = 0.094 +- 0.205 (in-sample avg dev_std = 0.227)
NEC for r=0.6 all L1 = 0.085 +- 0.175 (in-sample avg dev_std = 0.227)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.803
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.799
NEC for r=0.9 class 0.0 = 0.104 +- 0.126 (in-sample avg dev_std = 0.150)
NEC for r=0.9 class 1.0 = 0.022 +- 0.126 (in-sample avg dev_std = 0.150)
NEC for r=0.9 all KL = 0.048 +- 0.126 (in-sample avg dev_std = 0.150)
NEC for r=0.9 all L1 = 0.062 +- 0.138 (in-sample avg dev_std = 0.150)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.804
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.804
NEC for r=1.0 class 0.0 = 0.095 +- 0.125 (in-sample avg dev_std = 0.144)
NEC for r=1.0 class 1.0 = 0.022 +- 0.125 (in-sample avg dev_std = 0.144)
NEC for r=1.0 all KL = 0.044 +- 0.125 (in-sample avg dev_std = 0.144)
NEC for r=1.0 all L1 = 0.058 +- 0.137 (in-sample avg dev_std = 0.144)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.698, 0.937, 1.0], 'all_L1': [0.813, 0.934, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.57, 0.981, 1.0], 'all_L1': [0.796, 0.972, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.604, 0.97, 1.0], 'all_L1': [0.825, 0.962, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.697, 0.949, 1.0], 'all_L1': [0.839, 0.952, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.613, 0.946, 1.0], 'all_L1': [0.817, 0.94, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.102, 0.044, 0.037], 'all_L1': [0.099, 0.047, 0.042]}), defaultdict(<class 'list'>, {'all_KL': [0.112, 0.025, 0.024], 'all_L1': [0.091, 0.03, 0.029]}), defaultdict(<class 'list'>, {'all_KL': [0.098, 0.034, 0.037], 'all_L1': [0.082, 0.042, 0.045]}), defaultdict(<class 'list'>, {'all_KL': [0.105, 0.045, 0.037], 'all_L1': [0.085, 0.043, 0.036]}), defaultdict(<class 'list'>, {'all_KL': [0.108, 0.054, 0.057], 'all_L1': [0.088, 0.055, 0.055]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.634, 0.748, 0.862, 1.0], 'all_L1': [0.753, 0.819, 0.905, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.493, 0.611, 0.885, 1.0], 'all_L1': [0.741, 0.795, 0.913, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.603, 0.667, 0.904, 1.0], 'all_L1': [0.761, 0.797, 0.903, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.561, 0.639, 0.894, 1.0], 'all_L1': [0.755, 0.818, 0.93, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.606, 0.696, 0.903, 1.0], 'all_L1': [0.797, 0.821, 0.914, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.155, 0.131, 0.076, 0.061], 'all_L1': [0.161, 0.124, 0.069, 0.057]}), defaultdict(<class 'list'>, {'all_KL': [0.169, 0.141, 0.065, 0.048], 'all_L1': [0.123, 0.113, 0.066, 0.055]}), defaultdict(<class 'list'>, {'all_KL': [0.102, 0.072, 0.053, 0.041], 'all_L1': [0.093, 0.086, 0.081, 0.075]}), defaultdict(<class 'list'>, {'all_KL': [0.201, 0.113, 0.06, 0.057], 'all_L1': [0.143, 0.082, 0.055, 0.05]}), defaultdict(<class 'list'>, {'all_KL': [0.142, 0.094, 0.048, 0.044], 'all_L1': [0.099, 0.085, 0.062, 0.058]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.818 +- 0.014, 0.952 +- 0.014, 1.000 +- 0.000
suff++ class all_KL  =  0.636 +- 0.052, 0.957 +- 0.016, 1.000 +- 0.000
suff++_acc_int  =  0.799 +- 0.014, 0.861 +- 0.006
nec class all_L1  =  0.089 +- 0.006, 0.043 +- 0.008, 0.041 +- 0.009
nec class all_KL  =  0.105 +- 0.005, 0.040 +- 0.010, 0.038 +- 0.011
nec_acc_int  =  0.838 +- 0.017, 0.862 +- 0.010, 0.863 +- 0.010

Eval split test
suff++ class all_L1  =  0.761 +- 0.019, 0.810 +- 0.011, 0.913 +- 0.010, 1.000 +- 0.000
suff++ class all_KL  =  0.579 +- 0.049, 0.672 +- 0.047, 0.890 +- 0.015, 1.000 +- 0.000
suff++_acc_int  =  0.647 +- 0.021, 0.715 +- 0.038, 0.795 +- 0.046
nec class all_L1  =  0.124 +- 0.026, 0.098 +- 0.017, 0.067 +- 0.009, 0.059 +- 0.008
nec class all_KL  =  0.154 +- 0.033, 0.110 +- 0.025, 0.060 +- 0.010, 0.050 +- 0.008
nec_acc_int  =  0.705 +- 0.032, 0.766 +- 0.035, 0.805 +- 0.039, 0.811 +- 0.036


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.453 +- 0.006, 0.498 +- 0.004, 0.521 +- 0.004
Faith. Armon (L1)= 		  =  0.160 +- 0.009, 0.083 +- 0.015, 0.079 +- 0.016
Faith. GMean (L1)= 	  =  0.270 +- 0.008, 0.202 +- 0.018, 0.202 +- 0.022
Faith. Aritm (KL)= 		  =  0.371 +- 0.025, 0.499 +- 0.004, 0.519 +- 0.005
Faith. Armon (KL)= 		  =  0.180 +- 0.006, 0.077 +- 0.018, 0.074 +- 0.020
Faith. GMean (KL)= 	  =  0.258 +- 0.010, 0.195 +- 0.024, 0.194 +- 0.027

Eval split test
Faith. Aritm (L1)= 		  =  0.443 +- 0.011, 0.454 +- 0.010, 0.490 +- 0.002, 0.530 +- 0.004
Faith. Armon (L1)= 		  =  0.212 +- 0.038, 0.174 +- 0.027, 0.124 +- 0.015, 0.111 +- 0.015
Faith. GMean (L1)= 	  =  0.305 +- 0.030, 0.281 +- 0.024, 0.246 +- 0.015, 0.242 +- 0.017
Faith. Aritm (KL)= 		  =  0.367 +- 0.022, 0.391 +- 0.026, 0.475 +- 0.003, 0.525 +- 0.004
Faith. Armon (KL)= 		  =  0.240 +- 0.039, 0.188 +- 0.037, 0.113 +- 0.017, 0.096 +- 0.014
Faith. GMean (KL)= 	  =  0.296 +- 0.029, 0.270 +- 0.032, 0.231 +- 0.017, 0.223 +- 0.017
Computed for split load_split = id



Completed in  0:12:10.207890  for GSATvGIN GOODSST2/length



DONE GSAT GOODSST2/length
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 12:16:19 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/28/2024 12:16:19 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/28/2024 12:16:52 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:02 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:13 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:30 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:47 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:47 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:47 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:17:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:47 PM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 12:17:47 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:17:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:47 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:17:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:47 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:17:47 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 187...
[0m[1;37mINFO[0m: [1mCheckpoint 187: 
-----------------------------------
Train ROC-AUC: 0.9769
Train Loss: 0.1241
ID Validation ROC-AUC: 0.9251
ID Validation Loss: 0.2646
ID Test ROC-AUC: 0.9244
ID Test Loss: 0.2693
OOD Validation ROC-AUC: 0.6274
OOD Validation Loss: 0.5719
OOD Test ROC-AUC: 0.7014
OOD Test Loss: 0.7027

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 3...
[0m[1;37mINFO[0m: [1mCheckpoint 3: 
-----------------------------------
Train ROC-AUC: 0.8627
Train Loss: 0.3460
ID Validation ROC-AUC: 0.8591
ID Validation Loss: 0.3495
ID Test ROC-AUC: 0.8621
ID Test Loss: 0.3525
OOD Validation ROC-AUC: 0.7045
OOD Validation Loss: 0.2921
OOD Test ROC-AUC: 0.7135
OOD Test Loss: 0.5263

[0m[1;37mINFO[0m: [1mChartInfo 0.9244 0.7014 0.8621 0.7135 0.8591 0.7045[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/28/2024 12:17:48 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/28/2024 12:17:53 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.634
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.584
SUFF++ for r=0.3 class 0.0 = 0.637 +- 0.200 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.3 class 1.0 = 0.62 +- 0.200 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.3 all KL = 0.668 +- 0.200 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.3 all L1 = 0.622 +- 0.137 (in-sample avg dev_std = 0.503)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.668
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.63
SUFF++ for r=0.6 class 0.0 = 0.673 +- 0.198 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 class 1.0 = 0.661 +- 0.198 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 all KL = 0.719 +- 0.198 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 all L1 = 0.662 +- 0.153 (in-sample avg dev_std = 0.468)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.671
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.665
SUFF++ for r=0.9 class 0.0 = 0.845 +- 0.130 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 1.0 = 0.785 +- 0.130 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 all KL = 0.892 +- 0.130 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 all L1 = 0.792 +- 0.149 (in-sample avg dev_std = 0.270)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.587
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.565
SUFF++ for r=0.3 class 0.0 = 0.639 +- 0.209 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.3 class 1.0 = 0.624 +- 0.209 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.3 all KL = 0.649 +- 0.209 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.3 all L1 = 0.626 +- 0.144 (in-sample avg dev_std = 0.504)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.591
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.567
SUFF++ for r=0.6 class 0.0 = 0.682 +- 0.192 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.6 class 1.0 = 0.653 +- 0.192 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.6 all KL = 0.707 +- 0.192 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.6 all L1 = 0.658 +- 0.150 (in-sample avg dev_std = 0.471)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.603
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.587
SUFF++ for r=0.9 class 0.0 = 0.822 +- 0.124 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 class 1.0 = 0.793 +- 0.124 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 all KL = 0.894 +- 0.124 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 all L1 = 0.797 +- 0.141 (in-sample avg dev_std = 0.271)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.633
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.619
NEC for r=0.3 class 0.0 = 0.205 +- 0.205 (in-sample avg dev_std = 0.342)
NEC for r=0.3 class 1.0 = 0.266 +- 0.205 (in-sample avg dev_std = 0.342)
NEC for r=0.3 all KL = 0.179 +- 0.205 (in-sample avg dev_std = 0.342)
NEC for r=0.3 all L1 = 0.259 +- 0.191 (in-sample avg dev_std = 0.342)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.667
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.639
NEC for r=0.6 class 0.0 = 0.186 +- 0.183 (in-sample avg dev_std = 0.322)
NEC for r=0.6 class 1.0 = 0.247 +- 0.183 (in-sample avg dev_std = 0.322)
NEC for r=0.6 all KL = 0.161 +- 0.183 (in-sample avg dev_std = 0.322)
NEC for r=0.6 all L1 = 0.24 +- 0.178 (in-sample avg dev_std = 0.322)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.671
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.66
NEC for r=0.9 class 0.0 = 0.167 +- 0.128 (in-sample avg dev_std = 0.262)
NEC for r=0.9 class 1.0 = 0.202 +- 0.128 (in-sample avg dev_std = 0.262)
NEC for r=0.9 all KL = 0.102 +- 0.128 (in-sample avg dev_std = 0.262)
NEC for r=0.9 all L1 = 0.198 +- 0.149 (in-sample avg dev_std = 0.262)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.68
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.669
NEC for r=1.0 class 0.0 = 0.162 +- 0.108 (in-sample avg dev_std = 0.241)
NEC for r=1.0 class 1.0 = 0.186 +- 0.108 (in-sample avg dev_std = 0.241)
NEC for r=1.0 all KL = 0.084 +- 0.108 (in-sample avg dev_std = 0.241)
NEC for r=1.0 all L1 = 0.183 +- 0.135 (in-sample avg dev_std = 0.241)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.587
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.579
NEC for r=0.3 class 0.0 = 0.225 +- 0.206 (in-sample avg dev_std = 0.312)
NEC for r=0.3 class 1.0 = 0.247 +- 0.206 (in-sample avg dev_std = 0.312)
NEC for r=0.3 all KL = 0.172 +- 0.206 (in-sample avg dev_std = 0.312)
NEC for r=0.3 all L1 = 0.244 +- 0.201 (in-sample avg dev_std = 0.312)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.591
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.588
NEC for r=0.6 class 0.0 = 0.191 +- 0.176 (in-sample avg dev_std = 0.301)
NEC for r=0.6 class 1.0 = 0.226 +- 0.176 (in-sample avg dev_std = 0.301)
NEC for r=0.6 all KL = 0.142 +- 0.176 (in-sample avg dev_std = 0.301)
NEC for r=0.6 all L1 = 0.22 +- 0.178 (in-sample avg dev_std = 0.301)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.603
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.581
NEC for r=0.9 class 0.0 = 0.167 +- 0.121 (in-sample avg dev_std = 0.248)
NEC for r=0.9 class 1.0 = 0.195 +- 0.121 (in-sample avg dev_std = 0.248)
NEC for r=0.9 all KL = 0.095 +- 0.121 (in-sample avg dev_std = 0.248)
NEC for r=0.9 all L1 = 0.19 +- 0.148 (in-sample avg dev_std = 0.248)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.599
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.583
NEC for r=1.0 class 0.0 = 0.161 +- 0.121 (in-sample avg dev_std = 0.237)
NEC for r=1.0 class 1.0 = 0.186 +- 0.121 (in-sample avg dev_std = 0.237)
NEC for r=1.0 all KL = 0.086 +- 0.121 (in-sample avg dev_std = 0.237)
NEC for r=1.0 all L1 = 0.182 +- 0.138 (in-sample avg dev_std = 0.237)
model_dirname= repr_GSATvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 12:21:19 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/28/2024 12:21:19 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/28/2024 12:21:50 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:01 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:12 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:28 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:47 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:47 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:47 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:22:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:47 PM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 12:22:47 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:22:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:47 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:22:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:47 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:22:47 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 120...
[0m[1;37mINFO[0m: [1mCheckpoint 120: 
-----------------------------------
Train ROC-AUC: 0.9559
Train Loss: 0.1818
ID Validation ROC-AUC: 0.9207
ID Validation Loss: 0.2309
ID Test ROC-AUC: 0.9188
ID Test Loss: 0.2372
OOD Validation ROC-AUC: 0.6575
OOD Validation Loss: 0.3564
OOD Test ROC-AUC: 0.7045
OOD Test Loss: 0.5081

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 6...
[0m[1;37mINFO[0m: [1mCheckpoint 6: 
-----------------------------------
Train ROC-AUC: 0.8717
Train Loss: 0.3292
ID Validation ROC-AUC: 0.8694
ID Validation Loss: 0.3314
ID Test ROC-AUC: 0.8710
ID Test Loss: 0.3354
OOD Validation ROC-AUC: 0.7102
OOD Validation Loss: 0.2911
OOD Test ROC-AUC: 0.7280
OOD Test Loss: 0.5120

[0m[1;37mINFO[0m: [1mChartInfo 0.9188 0.7045 0.8710 0.7280 0.8694 0.7102[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/28/2024 12:22:47 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/28/2024 12:22:52 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.73
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.664
SUFF++ for r=0.3 class 0.0 = 0.713 +- 0.088 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.3 class 1.0 = 0.764 +- 0.088 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.3 all KL = 0.891 +- 0.088 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.3 all L1 = 0.758 +- 0.118 (in-sample avg dev_std = 0.275)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.815
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.731
SUFF++ for r=0.6 class 0.0 = 0.658 +- 0.131 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.6 class 1.0 = 0.815 +- 0.131 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.6 all KL = 0.876 +- 0.131 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.6 all L1 = 0.797 +- 0.173 (in-sample avg dev_std = 0.289)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.841
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.831
SUFF++ for r=0.9 class 0.0 = 0.822 +- 0.069 (in-sample avg dev_std = 0.153)
SUFF++ for r=0.9 class 1.0 = 0.915 +- 0.069 (in-sample avg dev_std = 0.153)
SUFF++ for r=0.9 all KL = 0.96 +- 0.069 (in-sample avg dev_std = 0.153)
SUFF++ for r=0.9 all L1 = 0.904 +- 0.118 (in-sample avg dev_std = 0.153)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.677
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.604
SUFF++ for r=0.3 class 0.0 = 0.712 +- 0.085 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.3 class 1.0 = 0.744 +- 0.085 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.3 all KL = 0.888 +- 0.085 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.3 all L1 = 0.739 +- 0.108 (in-sample avg dev_std = 0.282)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.697
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.641
SUFF++ for r=0.6 class 0.0 = 0.699 +- 0.115 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.6 class 1.0 = 0.766 +- 0.115 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.6 all KL = 0.865 +- 0.115 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.6 all L1 = 0.755 +- 0.148 (in-sample avg dev_std = 0.303)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.711
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.702
SUFF++ for r=0.9 class 0.0 = 0.839 +- 0.067 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.9 class 1.0 = 0.877 +- 0.067 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.9 all KL = 0.952 +- 0.067 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.9 all L1 = 0.87 +- 0.118 (in-sample avg dev_std = 0.162)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.73
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.721
NEC for r=0.3 class 0.0 = 0.191 +- 0.054 (in-sample avg dev_std = 0.151)
NEC for r=0.3 class 1.0 = 0.147 +- 0.054 (in-sample avg dev_std = 0.151)
NEC for r=0.3 all KL = 0.042 +- 0.054 (in-sample avg dev_std = 0.151)
NEC for r=0.3 all L1 = 0.152 +- 0.098 (in-sample avg dev_std = 0.151)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.816
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.8
NEC for r=0.6 class 0.0 = 0.182 +- 0.083 (in-sample avg dev_std = 0.177)
NEC for r=0.6 class 1.0 = 0.13 +- 0.083 (in-sample avg dev_std = 0.177)
NEC for r=0.6 all KL = 0.059 +- 0.083 (in-sample avg dev_std = 0.177)
NEC for r=0.6 all L1 = 0.136 +- 0.122 (in-sample avg dev_std = 0.177)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.841
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.834
NEC for r=0.9 class 0.0 = 0.158 +- 0.064 (in-sample avg dev_std = 0.132)
NEC for r=0.9 class 1.0 = 0.077 +- 0.064 (in-sample avg dev_std = 0.132)
NEC for r=0.9 all KL = 0.034 +- 0.064 (in-sample avg dev_std = 0.132)
NEC for r=0.9 all L1 = 0.086 +- 0.101 (in-sample avg dev_std = 0.132)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.852
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.837
NEC for r=1.0 class 0.0 = 0.134 +- 0.043 (in-sample avg dev_std = 0.109)
NEC for r=1.0 class 1.0 = 0.06 +- 0.043 (in-sample avg dev_std = 0.109)
NEC for r=1.0 all KL = 0.023 +- 0.043 (in-sample avg dev_std = 0.109)
NEC for r=1.0 all L1 = 0.069 +- 0.083 (in-sample avg dev_std = 0.109)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.679
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.67
NEC for r=0.3 class 0.0 = 0.191 +- 0.068 (in-sample avg dev_std = 0.167)
NEC for r=0.3 class 1.0 = 0.171 +- 0.068 (in-sample avg dev_std = 0.167)
NEC for r=0.3 all KL = 0.051 +- 0.068 (in-sample avg dev_std = 0.167)
NEC for r=0.3 all L1 = 0.174 +- 0.108 (in-sample avg dev_std = 0.167)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.697
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.694
NEC for r=0.6 class 0.0 = 0.173 +- 0.088 (in-sample avg dev_std = 0.190)
NEC for r=0.6 class 1.0 = 0.167 +- 0.088 (in-sample avg dev_std = 0.190)
NEC for r=0.6 all KL = 0.067 +- 0.088 (in-sample avg dev_std = 0.190)
NEC for r=0.6 all L1 = 0.168 +- 0.117 (in-sample avg dev_std = 0.190)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.711
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.711
NEC for r=0.9 class 0.0 = 0.145 +- 0.063 (in-sample avg dev_std = 0.146)
NEC for r=0.9 class 1.0 = 0.114 +- 0.063 (in-sample avg dev_std = 0.146)
NEC for r=0.9 all KL = 0.042 +- 0.063 (in-sample avg dev_std = 0.146)
NEC for r=0.9 all L1 = 0.119 +- 0.103 (in-sample avg dev_std = 0.146)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.716
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.714
NEC for r=1.0 class 0.0 = 0.124 +- 0.049 (in-sample avg dev_std = 0.127)
NEC for r=1.0 class 1.0 = 0.094 +- 0.049 (in-sample avg dev_std = 0.127)
NEC for r=1.0 all KL = 0.031 +- 0.049 (in-sample avg dev_std = 0.127)
NEC for r=1.0 all L1 = 0.099 +- 0.090 (in-sample avg dev_std = 0.127)
model_dirname= repr_GSATvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 12:26:15 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/28/2024 12:26:15 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/28/2024 12:26:53 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:04 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:15 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:32 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:50 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:50 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:50 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:27:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:50 PM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 12:27:50 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:27:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:50 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:27:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:50 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:50 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:27:50 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 166...
[0m[1;37mINFO[0m: [1mCheckpoint 166: 
-----------------------------------
Train ROC-AUC: 0.9718
Train Loss: 0.1502
ID Validation ROC-AUC: 0.9222
ID Validation Loss: 0.2869
ID Test ROC-AUC: 0.9201
ID Test Loss: 0.2932
OOD Validation ROC-AUC: 0.6430
OOD Validation Loss: 0.5048
OOD Test ROC-AUC: 0.7020
OOD Test Loss: 0.7112

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 0...
[0m[1;37mINFO[0m: [1mCheckpoint 0: 
-----------------------------------
Train ROC-AUC: 0.8089
Train Loss: 0.4646
ID Validation ROC-AUC: 0.8084
ID Validation Loss: 0.4676
ID Test ROC-AUC: 0.8095
ID Test Loss: 0.4731
OOD Validation ROC-AUC: 0.6927
OOD Validation Loss: 0.3283
OOD Test ROC-AUC: 0.6938
OOD Test Loss: 0.4537

[0m[1;37mINFO[0m: [1mChartInfo 0.9201 0.7020 0.8095 0.6938 0.8084 0.6927[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/28/2024 12:27:50 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/28/2024 12:27:54 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.656
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.599
SUFF++ for r=0.3 class 0.0 = 0.575 +- 0.221 (in-sample avg dev_std = 0.602)
SUFF++ for r=0.3 class 1.0 = 0.561 +- 0.221 (in-sample avg dev_std = 0.602)
SUFF++ for r=0.3 all KL = 0.569 +- 0.221 (in-sample avg dev_std = 0.602)
SUFF++ for r=0.3 all L1 = 0.563 +- 0.147 (in-sample avg dev_std = 0.602)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.774
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.69
SUFF++ for r=0.6 class 0.0 = 0.546 +- 0.236 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 class 1.0 = 0.714 +- 0.236 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 all KL = 0.709 +- 0.236 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 all L1 = 0.694 +- 0.229 (in-sample avg dev_std = 0.452)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.805
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.78
SUFF++ for r=0.9 class 0.0 = 0.75 +- 0.149 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.9 class 1.0 = 0.888 +- 0.149 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.9 all KL = 0.915 +- 0.149 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.9 all L1 = 0.872 +- 0.170 (in-sample avg dev_std = 0.211)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.57
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.557
SUFF++ for r=0.3 class 0.0 = 0.606 +- 0.201 (in-sample avg dev_std = 0.566)
SUFF++ for r=0.3 class 1.0 = 0.589 +- 0.201 (in-sample avg dev_std = 0.566)
SUFF++ for r=0.3 all KL = 0.627 +- 0.201 (in-sample avg dev_std = 0.566)
SUFF++ for r=0.3 all L1 = 0.592 +- 0.141 (in-sample avg dev_std = 0.566)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.639
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.602
SUFF++ for r=0.6 class 0.0 = 0.587 +- 0.217 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.6 class 1.0 = 0.664 +- 0.217 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.6 all KL = 0.692 +- 0.217 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.6 all L1 = 0.651 +- 0.204 (in-sample avg dev_std = 0.488)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.667
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.651
SUFF++ for r=0.9 class 0.0 = 0.76 +- 0.160 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 class 1.0 = 0.829 +- 0.160 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 all KL = 0.882 +- 0.160 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 all L1 = 0.817 +- 0.183 (in-sample avg dev_std = 0.266)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.656
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.672
NEC for r=0.3 class 0.0 = 0.208 +- 0.229 (in-sample avg dev_std = 0.369)
NEC for r=0.3 class 1.0 = 0.305 +- 0.229 (in-sample avg dev_std = 0.369)
NEC for r=0.3 all KL = 0.23 +- 0.229 (in-sample avg dev_std = 0.369)
NEC for r=0.3 all L1 = 0.294 +- 0.192 (in-sample avg dev_std = 0.369)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.774
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.773
NEC for r=0.6 class 0.0 = 0.239 +- 0.208 (in-sample avg dev_std = 0.330)
NEC for r=0.6 class 1.0 = 0.227 +- 0.208 (in-sample avg dev_std = 0.330)
NEC for r=0.6 all KL = 0.182 +- 0.208 (in-sample avg dev_std = 0.330)
NEC for r=0.6 all L1 = 0.228 +- 0.199 (in-sample avg dev_std = 0.330)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.805
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.806
NEC for r=0.9 class 0.0 = 0.236 +- 0.147 (in-sample avg dev_std = 0.209)
NEC for r=0.9 class 1.0 = 0.113 +- 0.147 (in-sample avg dev_std = 0.209)
NEC for r=0.9 all KL = 0.089 +- 0.147 (in-sample avg dev_std = 0.209)
NEC for r=0.9 all L1 = 0.127 +- 0.158 (in-sample avg dev_std = 0.209)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.814
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.813
NEC for r=1.0 class 0.0 = 0.208 +- 0.119 (in-sample avg dev_std = 0.183)
NEC for r=1.0 class 1.0 = 0.091 +- 0.119 (in-sample avg dev_std = 0.183)
NEC for r=1.0 all KL = 0.067 +- 0.119 (in-sample avg dev_std = 0.183)
NEC for r=1.0 all L1 = 0.105 +- 0.142 (in-sample avg dev_std = 0.183)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.571
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.585
NEC for r=0.3 class 0.0 = 0.22 +- 0.201 (in-sample avg dev_std = 0.349)
NEC for r=0.3 class 1.0 = 0.288 +- 0.201 (in-sample avg dev_std = 0.349)
NEC for r=0.3 all KL = 0.195 +- 0.201 (in-sample avg dev_std = 0.349)
NEC for r=0.3 all L1 = 0.277 +- 0.180 (in-sample avg dev_std = 0.349)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.638
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.639
NEC for r=0.6 class 0.0 = 0.259 +- 0.204 (in-sample avg dev_std = 0.337)
NEC for r=0.6 class 1.0 = 0.253 +- 0.204 (in-sample avg dev_std = 0.337)
NEC for r=0.6 all KL = 0.187 +- 0.204 (in-sample avg dev_std = 0.337)
NEC for r=0.6 all L1 = 0.254 +- 0.190 (in-sample avg dev_std = 0.337)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.667
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.662
NEC for r=0.9 class 0.0 = 0.221 +- 0.173 (in-sample avg dev_std = 0.260)
NEC for r=0.9 class 1.0 = 0.175 +- 0.173 (in-sample avg dev_std = 0.260)
NEC for r=0.9 all KL = 0.123 +- 0.173 (in-sample avg dev_std = 0.260)
NEC for r=0.9 all L1 = 0.183 +- 0.179 (in-sample avg dev_std = 0.260)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.671
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.668
NEC for r=1.0 class 0.0 = 0.197 +- 0.159 (in-sample avg dev_std = 0.239)
NEC for r=1.0 class 1.0 = 0.147 +- 0.159 (in-sample avg dev_std = 0.239)
NEC for r=1.0 all KL = 0.103 +- 0.159 (in-sample avg dev_std = 0.239)
NEC for r=1.0 all L1 = 0.156 +- 0.168 (in-sample avg dev_std = 0.239)
model_dirname= repr_GSATvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 12:31:12 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/28/2024 12:31:12 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/28/2024 12:31:44 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/28/2024 12:31:54 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:27 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:43 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:43 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:43 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:32:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:44 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:44 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:44 PM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 12:32:44 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:32:44 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:44 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:44 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:44 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:32:44 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:44 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:44 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:44 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:32:44 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 127...
[0m[1;37mINFO[0m: [1mCheckpoint 127: 
-----------------------------------
Train ROC-AUC: 0.9605
Train Loss: 0.1572
ID Validation ROC-AUC: 0.9210
ID Validation Loss: 0.2207
ID Test ROC-AUC: 0.9206
ID Test Loss: 0.2229
OOD Validation ROC-AUC: 0.6437
OOD Validation Loss: 0.4343
OOD Test ROC-AUC: 0.7008
OOD Test Loss: 0.5543

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 3...
[0m[1;37mINFO[0m: [1mCheckpoint 3: 
-----------------------------------
Train ROC-AUC: 0.8643
Train Loss: 0.3237
ID Validation ROC-AUC: 0.8622
ID Validation Loss: 0.3271
ID Test ROC-AUC: 0.8643
ID Test Loss: 0.3301
OOD Validation ROC-AUC: 0.7009
OOD Validation Loss: 0.2819
OOD Test ROC-AUC: 0.7289
OOD Test Loss: 0.4908

[0m[1;37mINFO[0m: [1mChartInfo 0.9206 0.7008 0.8643 0.7289 0.8622 0.7009[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/28/2024 12:32:44 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/28/2024 12:32:48 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.527
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.549
SUFF++ for r=0.3 class 0.0 = 0.665 +- 0.153 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.3 class 1.0 = 0.628 +- 0.153 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.3 all KL = 0.78 +- 0.153 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.3 all L1 = 0.632 +- 0.123 (in-sample avg dev_std = 0.391)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.638
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.628
SUFF++ for r=0.6 class 0.0 = 0.702 +- 0.120 (in-sample avg dev_std = 0.335)
SUFF++ for r=0.6 class 1.0 = 0.666 +- 0.120 (in-sample avg dev_std = 0.335)
SUFF++ for r=0.6 all KL = 0.835 +- 0.120 (in-sample avg dev_std = 0.335)
SUFF++ for r=0.6 all L1 = 0.67 +- 0.118 (in-sample avg dev_std = 0.335)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.667
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.673
SUFF++ for r=0.9 class 0.0 = 0.851 +- 0.077 (in-sample avg dev_std = 0.200)
SUFF++ for r=0.9 class 1.0 = 0.799 +- 0.077 (in-sample avg dev_std = 0.200)
SUFF++ for r=0.9 all KL = 0.938 +- 0.077 (in-sample avg dev_std = 0.200)
SUFF++ for r=0.9 all L1 = 0.805 +- 0.112 (in-sample avg dev_std = 0.200)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.512
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.535
SUFF++ for r=0.3 class 0.0 = 0.649 +- 0.132 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.3 class 1.0 = 0.641 +- 0.132 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.3 all KL = 0.799 +- 0.132 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.3 all L1 = 0.642 +- 0.107 (in-sample avg dev_std = 0.387)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.561
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.57
SUFF++ for r=0.6 class 0.0 = 0.687 +- 0.113 (in-sample avg dev_std = 0.352)
SUFF++ for r=0.6 class 1.0 = 0.669 +- 0.113 (in-sample avg dev_std = 0.352)
SUFF++ for r=0.6 all KL = 0.834 +- 0.113 (in-sample avg dev_std = 0.352)
SUFF++ for r=0.6 all L1 = 0.672 +- 0.107 (in-sample avg dev_std = 0.352)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.6
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.618
SUFF++ for r=0.9 class 0.0 = 0.84 +- 0.061 (in-sample avg dev_std = 0.196)
SUFF++ for r=0.9 class 1.0 = 0.814 +- 0.061 (in-sample avg dev_std = 0.196)
SUFF++ for r=0.9 all KL = 0.946 +- 0.061 (in-sample avg dev_std = 0.196)
SUFF++ for r=0.9 all L1 = 0.818 +- 0.103 (in-sample avg dev_std = 0.196)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.526
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.532
NEC for r=0.3 class 0.0 = 0.238 +- 0.128 (in-sample avg dev_std = 0.273)
NEC for r=0.3 class 1.0 = 0.274 +- 0.128 (in-sample avg dev_std = 0.273)
NEC for r=0.3 all KL = 0.126 +- 0.128 (in-sample avg dev_std = 0.273)
NEC for r=0.3 all L1 = 0.27 +- 0.138 (in-sample avg dev_std = 0.273)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.639
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.65
NEC for r=0.6 class 0.0 = 0.183 +- 0.094 (in-sample avg dev_std = 0.253)
NEC for r=0.6 class 1.0 = 0.25 +- 0.094 (in-sample avg dev_std = 0.253)
NEC for r=0.6 all KL = 0.093 +- 0.094 (in-sample avg dev_std = 0.253)
NEC for r=0.6 all L1 = 0.243 +- 0.120 (in-sample avg dev_std = 0.253)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.667
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.681
NEC for r=0.9 class 0.0 = 0.127 +- 0.073 (in-sample avg dev_std = 0.208)
NEC for r=0.9 class 1.0 = 0.192 +- 0.073 (in-sample avg dev_std = 0.208)
NEC for r=0.9 all KL = 0.057 +- 0.073 (in-sample avg dev_std = 0.208)
NEC for r=0.9 all L1 = 0.184 +- 0.108 (in-sample avg dev_std = 0.208)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.689
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.696
NEC for r=1.0 class 0.0 = 0.124 +- 0.064 (in-sample avg dev_std = 0.197)
NEC for r=1.0 class 1.0 = 0.175 +- 0.064 (in-sample avg dev_std = 0.197)
NEC for r=1.0 all KL = 0.05 +- 0.064 (in-sample avg dev_std = 0.197)
NEC for r=1.0 all L1 = 0.169 +- 0.102 (in-sample avg dev_std = 0.197)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.51
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.536
NEC for r=0.3 class 0.0 = 0.235 +- 0.103 (in-sample avg dev_std = 0.251)
NEC for r=0.3 class 1.0 = 0.261 +- 0.103 (in-sample avg dev_std = 0.251)
NEC for r=0.3 all KL = 0.105 +- 0.103 (in-sample avg dev_std = 0.251)
NEC for r=0.3 all L1 = 0.256 +- 0.126 (in-sample avg dev_std = 0.251)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.561
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.578
NEC for r=0.6 class 0.0 = 0.195 +- 0.090 (in-sample avg dev_std = 0.240)
NEC for r=0.6 class 1.0 = 0.232 +- 0.090 (in-sample avg dev_std = 0.240)
NEC for r=0.6 all KL = 0.084 +- 0.090 (in-sample avg dev_std = 0.240)
NEC for r=0.6 all L1 = 0.225 +- 0.117 (in-sample avg dev_std = 0.240)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.601
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.612
NEC for r=0.9 class 0.0 = 0.15 +- 0.063 (in-sample avg dev_std = 0.196)
NEC for r=0.9 class 1.0 = 0.176 +- 0.063 (in-sample avg dev_std = 0.196)
NEC for r=0.9 all KL = 0.051 +- 0.063 (in-sample avg dev_std = 0.196)
NEC for r=0.9 all L1 = 0.172 +- 0.101 (in-sample avg dev_std = 0.196)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.607
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.622
NEC for r=1.0 class 0.0 = 0.137 +- 0.058 (in-sample avg dev_std = 0.179)
NEC for r=1.0 class 1.0 = 0.157 +- 0.058 (in-sample avg dev_std = 0.179)
NEC for r=1.0 all KL = 0.042 +- 0.058 (in-sample avg dev_std = 0.179)
NEC for r=1.0 all L1 = 0.153 +- 0.096 (in-sample avg dev_std = 0.179)
model_dirname= repr_GSATvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 12:36:05 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/28/2024 12:36:06 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/28/2024 12:36:39 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/28/2024 12:36:49 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:00 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:16 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:34 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:34 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:34 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:37:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:34 PM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 12:37:34 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:37:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:34 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:37:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:34 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:37:34 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 172...
[0m[1;37mINFO[0m: [1mCheckpoint 172: 
-----------------------------------
Train ROC-AUC: 0.9755
Train Loss: 0.1331
ID Validation ROC-AUC: 0.9228
ID Validation Loss: 0.2627
ID Test ROC-AUC: 0.9230
ID Test Loss: 0.2676
OOD Validation ROC-AUC: 0.6330
OOD Validation Loss: 0.4920
OOD Test ROC-AUC: 0.6956
OOD Test Loss: 0.6669

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 2...
[0m[1;37mINFO[0m: [1mCheckpoint 2: 
-----------------------------------
Train ROC-AUC: 0.8416
Train Loss: 0.7193
ID Validation ROC-AUC: 0.8417
ID Validation Loss: 0.7258
ID Test ROC-AUC: 0.8407
ID Test Loss: 0.7339
OOD Validation ROC-AUC: 0.7030
OOD Validation Loss: 0.4109
OOD Test ROC-AUC: 0.7172
OOD Test Loss: 0.4958

[0m[1;37mINFO[0m: [1mChartInfo 0.9230 0.6956 0.8407 0.7172 0.8417 0.7030[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/28/2024 12:37:34 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/28/2024 12:37:39 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.593
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.595
SUFF++ for r=0.3 class 0.0 = 0.774 +- 0.209 (in-sample avg dev_std = 0.505)
SUFF++ for r=0.3 class 1.0 = 0.712 +- 0.209 (in-sample avg dev_std = 0.505)
SUFF++ for r=0.3 all KL = 0.716 +- 0.209 (in-sample avg dev_std = 0.505)
SUFF++ for r=0.3 all L1 = 0.719 +- 0.164 (in-sample avg dev_std = 0.505)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.735
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.662
SUFF++ for r=0.6 class 0.0 = 0.675 +- 0.205 (in-sample avg dev_std = 0.541)
SUFF++ for r=0.6 class 1.0 = 0.626 +- 0.205 (in-sample avg dev_std = 0.541)
SUFF++ for r=0.6 all KL = 0.669 +- 0.205 (in-sample avg dev_std = 0.541)
SUFF++ for r=0.6 all L1 = 0.632 +- 0.169 (in-sample avg dev_std = 0.541)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.784
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.769
SUFF++ for r=0.9 class 0.0 = 0.808 +- 0.130 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 1.0 = 0.78 +- 0.130 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 all KL = 0.884 +- 0.130 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 all L1 = 0.783 +- 0.160 (in-sample avg dev_std = 0.260)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.591
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.561
SUFF++ for r=0.3 class 0.0 = 0.812 +- 0.187 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.3 class 1.0 = 0.775 +- 0.187 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.3 all KL = 0.79 +- 0.187 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.3 all L1 = 0.781 +- 0.145 (in-sample avg dev_std = 0.423)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.622
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.594
SUFF++ for r=0.6 class 0.0 = 0.726 +- 0.206 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.6 class 1.0 = 0.677 +- 0.206 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.6 all KL = 0.733 +- 0.206 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.6 all L1 = 0.685 +- 0.168 (in-sample avg dev_std = 0.488)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.662
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.657
SUFF++ for r=0.9 class 0.0 = 0.806 +- 0.122 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 1.0 = 0.774 +- 0.122 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 all KL = 0.893 +- 0.122 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 all L1 = 0.78 +- 0.155 (in-sample avg dev_std = 0.253)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.592
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.61
NEC for r=0.3 class 0.0 = 0.095 +- 0.167 (in-sample avg dev_std = 0.247)
NEC for r=0.3 class 1.0 = 0.162 +- 0.167 (in-sample avg dev_std = 0.247)
NEC for r=0.3 all KL = 0.107 +- 0.167 (in-sample avg dev_std = 0.247)
NEC for r=0.3 all L1 = 0.154 +- 0.158 (in-sample avg dev_std = 0.247)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.734
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.693
NEC for r=0.6 class 0.0 = 0.159 +- 0.187 (in-sample avg dev_std = 0.319)
NEC for r=0.6 class 1.0 = 0.234 +- 0.187 (in-sample avg dev_std = 0.319)
NEC for r=0.6 all KL = 0.15 +- 0.187 (in-sample avg dev_std = 0.319)
NEC for r=0.6 all L1 = 0.225 +- 0.179 (in-sample avg dev_std = 0.319)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.785
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.766
NEC for r=0.9 class 0.0 = 0.153 +- 0.138 (in-sample avg dev_std = 0.262)
NEC for r=0.9 class 1.0 = 0.216 +- 0.138 (in-sample avg dev_std = 0.262)
NEC for r=0.9 all KL = 0.112 +- 0.138 (in-sample avg dev_std = 0.262)
NEC for r=0.9 all L1 = 0.208 +- 0.150 (in-sample avg dev_std = 0.262)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.797
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.782
NEC for r=1.0 class 0.0 = 0.169 +- 0.119 (in-sample avg dev_std = 0.235)
NEC for r=1.0 class 1.0 = 0.177 +- 0.119 (in-sample avg dev_std = 0.235)
NEC for r=1.0 all KL = 0.089 +- 0.119 (in-sample avg dev_std = 0.235)
NEC for r=1.0 all L1 = 0.176 +- 0.138 (in-sample avg dev_std = 0.235)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.591
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.583
NEC for r=0.3 class 0.0 = 0.106 +- 0.124 (in-sample avg dev_std = 0.201)
NEC for r=0.3 class 1.0 = 0.129 +- 0.124 (in-sample avg dev_std = 0.201)
NEC for r=0.3 all KL = 0.08 +- 0.124 (in-sample avg dev_std = 0.201)
NEC for r=0.3 all L1 = 0.125 +- 0.131 (in-sample avg dev_std = 0.201)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.622
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.605
NEC for r=0.6 class 0.0 = 0.147 +- 0.170 (in-sample avg dev_std = 0.299)
NEC for r=0.6 class 1.0 = 0.209 +- 0.170 (in-sample avg dev_std = 0.299)
NEC for r=0.6 all KL = 0.126 +- 0.170 (in-sample avg dev_std = 0.299)
NEC for r=0.6 all L1 = 0.199 +- 0.171 (in-sample avg dev_std = 0.299)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.662
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.641
NEC for r=0.9 class 0.0 = 0.192 +- 0.136 (in-sample avg dev_std = 0.266)
NEC for r=0.9 class 1.0 = 0.227 +- 0.136 (in-sample avg dev_std = 0.266)
NEC for r=0.9 all KL = 0.112 +- 0.136 (in-sample avg dev_std = 0.266)
NEC for r=0.9 all L1 = 0.221 +- 0.148 (in-sample avg dev_std = 0.266)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.664
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.656
NEC for r=1.0 class 0.0 = 0.179 +- 0.128 (in-sample avg dev_std = 0.249)
NEC for r=1.0 class 1.0 = 0.196 +- 0.128 (in-sample avg dev_std = 0.249)
NEC for r=1.0 all KL = 0.094 +- 0.128 (in-sample avg dev_std = 0.249)
NEC for r=1.0 all L1 = 0.193 +- 0.144 (in-sample avg dev_std = 0.249)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.668, 0.719, 0.892, 1.0], 'all_L1': [0.622, 0.662, 0.792, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.891, 0.876, 0.96, 1.0], 'all_L1': [0.758, 0.797, 0.904, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.569, 0.709, 0.915, 1.0], 'all_L1': [0.563, 0.694, 0.872, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.78, 0.835, 0.938, 1.0], 'all_L1': [0.632, 0.67, 0.805, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.716, 0.669, 0.884, 1.0], 'all_L1': [0.719, 0.632, 0.783, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.179, 0.161, 0.102, 0.084], 'all_L1': [0.259, 0.24, 0.198, 0.183]}), defaultdict(<class 'list'>, {'all_KL': [0.042, 0.059, 0.034, 0.023], 'all_L1': [0.152, 0.136, 0.086, 0.069]}), defaultdict(<class 'list'>, {'all_KL': [0.23, 0.182, 0.089, 0.067], 'all_L1': [0.294, 0.228, 0.127, 0.105]}), defaultdict(<class 'list'>, {'all_KL': [0.126, 0.093, 0.057, 0.05], 'all_L1': [0.27, 0.243, 0.184, 0.169]}), defaultdict(<class 'list'>, {'all_KL': [0.107, 0.15, 0.112, 0.089], 'all_L1': [0.154, 0.225, 0.208, 0.176]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.649, 0.707, 0.894, 1.0], 'all_L1': [0.626, 0.658, 0.797, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.888, 0.865, 0.952, 1.0], 'all_L1': [0.739, 0.755, 0.87, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.627, 0.692, 0.882, 1.0], 'all_L1': [0.592, 0.651, 0.817, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.799, 0.834, 0.946, 1.0], 'all_L1': [0.642, 0.672, 0.818, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.79, 0.733, 0.893, 1.0], 'all_L1': [0.781, 0.685, 0.78, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.172, 0.142, 0.095, 0.086], 'all_L1': [0.244, 0.22, 0.19, 0.182]}), defaultdict(<class 'list'>, {'all_KL': [0.051, 0.067, 0.042, 0.031], 'all_L1': [0.174, 0.168, 0.119, 0.099]}), defaultdict(<class 'list'>, {'all_KL': [0.195, 0.187, 0.123, 0.103], 'all_L1': [0.277, 0.254, 0.183, 0.156]}), defaultdict(<class 'list'>, {'all_KL': [0.105, 0.084, 0.051, 0.042], 'all_L1': [0.256, 0.225, 0.172, 0.153]}), defaultdict(<class 'list'>, {'all_KL': [0.08, 0.126, 0.112, 0.094], 'all_L1': [0.125, 0.199, 0.221, 0.193]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.659 +- 0.070, 0.691 +- 0.057, 0.831 +- 0.048, 1.000 +- 0.000
suff++ class all_KL  =  0.725 +- 0.108, 0.762 +- 0.080, 0.918 +- 0.028, 1.000 +- 0.000
suff++_acc_int  =  0.598 +- 0.038, 0.668 +- 0.039, 0.743 +- 0.064
nec class all_L1  =  0.226 +- 0.061, 0.214 +- 0.040, 0.161 +- 0.047, 0.140 +- 0.045
nec class all_KL  =  0.137 +- 0.064, 0.129 +- 0.046, 0.079 +- 0.029, 0.063 +- 0.024
nec_acc_int  =  0.631 +- 0.064, 0.711 +- 0.065, 0.750 +- 0.068, 0.759 +- 0.066

Eval split test
suff++ class all_L1  =  0.676 +- 0.072, 0.684 +- 0.037, 0.816 +- 0.030, 1.000 +- 0.000
suff++ class all_KL  =  0.751 +- 0.098, 0.766 +- 0.070, 0.913 +- 0.029, 1.000 +- 0.000
suff++_acc_int  =  0.564 +- 0.022, 0.595 +- 0.027, 0.643 +- 0.039
nec class all_L1  =  0.215 +- 0.057, 0.213 +- 0.029, 0.177 +- 0.033, 0.157 +- 0.033
nec class all_KL  =  0.121 +- 0.055, 0.121 +- 0.043, 0.085 +- 0.032, 0.071 +- 0.029
nec_acc_int  =  0.590 +- 0.044, 0.621 +- 0.042, 0.641 +- 0.044, 0.649 +- 0.044


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.442 +- 0.010, 0.453 +- 0.013, 0.496 +- 0.002, 0.570 +- 0.023
Faith. Armon (L1)= 		  =  0.327 +- 0.061, 0.323 +- 0.046, 0.265 +- 0.066, 0.243 +- 0.071
Faith. GMean (L1)= 	  =  0.379 +- 0.035, 0.381 +- 0.028, 0.359 +- 0.047, 0.369 +- 0.065
Faith. Aritm (KL)= 		  =  0.431 +- 0.025, 0.445 +- 0.021, 0.498 +- 0.002, 0.531 +- 0.012
Faith. Armon (KL)= 		  =  0.219 +- 0.085, 0.215 +- 0.066, 0.143 +- 0.050, 0.117 +- 0.043
Faith. GMean (KL)= 	  =  0.298 +- 0.060, 0.304 +- 0.047, 0.263 +- 0.050, 0.244 +- 0.053

Eval split test
Faith. Aritm (L1)= 		  =  0.446 +- 0.009, 0.449 +- 0.008, 0.497 +- 0.003, 0.578 +- 0.016
Faith. Armon (L1)= 		  =  0.318 +- 0.061, 0.323 +- 0.030, 0.289 +- 0.044, 0.269 +- 0.050
Faith. GMean (L1)= 	  =  0.374 +- 0.035, 0.380 +- 0.017, 0.378 +- 0.031, 0.393 +- 0.043
Faith. Aritm (KL)= 		  =  0.436 +- 0.023, 0.444 +- 0.016, 0.499 +- 0.003, 0.536 +- 0.015
Faith. Armon (KL)= 		  =  0.199 +- 0.076, 0.205 +- 0.061, 0.153 +- 0.054, 0.132 +- 0.051
Faith. GMean (KL)= 	  =  0.288 +- 0.051, 0.297 +- 0.041, 0.271 +- 0.052, 0.260 +- 0.058
Computed for split load_split = id



Completed in  0:24:47.775866  for GSATvGIN LBAPcore/assay



DONE GSAT LBAPcore/assay
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 12:41:16 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:18 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:41:18 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 168...
[0m[1;37mINFO[0m: [1mCheckpoint 168: 
-----------------------------------
Train ACCURACY: 0.9513
Train Loss: 0.1416
ID Validation ACCURACY: 0.8979
ID Validation Loss: 0.3406
ID Test ACCURACY: 0.8910
ID Test Loss: 0.3538
OOD Validation ACCURACY: 0.7780
OOD Validation Loss: 0.8665
OOD Test ACCURACY: 0.2856
OOD Test Loss: 5.0562

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 94...
[0m[1;37mINFO[0m: [1mCheckpoint 94: 
-----------------------------------
Train ACCURACY: 0.8921
Train Loss: 0.3223
ID Validation ACCURACY: 0.8611
ID Validation Loss: 0.4189
ID Test ACCURACY: 0.8610
ID Test Loss: 0.4250
OOD Validation ACCURACY: 0.8180
OOD Validation Loss: 0.5733
OOD Test ACCURACY: 0.3071
OOD Test Loss: 3.0050

[0m[1;37mINFO[0m: [1mChartInfo 0.8910 0.2856 0.8610 0.3071 0.8611 0.8180[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.094
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.109
SUFF++ for r=0.3 class 0 = 0.806 +- 0.253 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.3 class 1 = 0.91 +- 0.253 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.3 class 2 = 0.759 +- 0.253 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.3 class 3 = 0.848 +- 0.253 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.3 class 4 = 0.68 +- 0.253 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.3 class 5 = 0.777 +- 0.253 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.3 class 6 = 0.83 +- 0.253 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.3 class 7 = 0.688 +- 0.253 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.3 class 8 = 0.816 +- 0.253 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.3 class 9 = 0.804 +- 0.253 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.3 all KL = 0.804 +- 0.253 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.3 all L1 = 0.793 +- 0.232 (in-sample avg dev_std = 0.264)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.132
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.118
SUFF++ for r=0.6 class 0 = 0.325 +- 0.243 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 1 = 0.611 +- 0.243 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 2 = 0.38 +- 0.243 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 3 = 0.394 +- 0.243 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 4 = 0.366 +- 0.243 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 5 = 0.354 +- 0.243 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 6 = 0.339 +- 0.243 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 7 = 0.382 +- 0.243 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 8 = 0.314 +- 0.243 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 9 = 0.357 +- 0.243 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 all KL = 0.307 +- 0.243 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 all L1 = 0.386 +- 0.174 (in-sample avg dev_std = 0.478)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.794
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.38
SUFF++ for r=0.9 class 0 = 0.272 +- 0.141 (in-sample avg dev_std = 0.693)
SUFF++ for r=0.9 class 1 = 0.276 +- 0.141 (in-sample avg dev_std = 0.693)
SUFF++ for r=0.9 class 2 = 0.346 +- 0.141 (in-sample avg dev_std = 0.693)
SUFF++ for r=0.9 class 3 = 0.303 +- 0.141 (in-sample avg dev_std = 0.693)
SUFF++ for r=0.9 class 4 = 0.365 +- 0.141 (in-sample avg dev_std = 0.693)
SUFF++ for r=0.9 class 5 = 0.297 +- 0.141 (in-sample avg dev_std = 0.693)
SUFF++ for r=0.9 class 6 = 0.334 +- 0.141 (in-sample avg dev_std = 0.693)
SUFF++ for r=0.9 class 7 = 0.475 +- 0.141 (in-sample avg dev_std = 0.693)
SUFF++ for r=0.9 class 8 = 0.309 +- 0.141 (in-sample avg dev_std = 0.693)
SUFF++ for r=0.9 class 9 = 0.314 +- 0.141 (in-sample avg dev_std = 0.693)
SUFF++ for r=0.9 all KL = 0.104 +- 0.141 (in-sample avg dev_std = 0.693)
SUFF++ for r=0.9 all L1 = 0.33 +- 0.110 (in-sample avg dev_std = 0.693)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.117
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.107
SUFF++ for r=0.3 class 0 = 0.482 +- 0.321 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 class 1 = 0.422 +- 0.321 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 class 2 = 0.578 +- 0.321 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 class 3 = 0.584 +- 0.321 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 class 4 = 0.717 +- 0.321 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 class 5 = 0.624 +- 0.321 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 class 6 = 0.635 +- 0.321 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 class 7 = 0.601 +- 0.321 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 class 8 = 0.66 +- 0.321 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 class 9 = 0.593 +- 0.321 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 all KL = 0.56 +- 0.321 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 all L1 = 0.586 +- 0.237 (in-sample avg dev_std = 0.456)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.119
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.108
SUFF++ for r=0.6 class 0 = 0.649 +- 0.252 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.6 class 1 = 0.733 +- 0.252 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.6 class 2 = 0.613 +- 0.252 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.6 class 3 = 0.628 +- 0.252 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.6 class 4 = 0.519 +- 0.252 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.6 class 5 = 0.585 +- 0.252 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.6 class 6 = 0.537 +- 0.252 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.6 class 7 = 0.567 +- 0.252 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.6 class 8 = 0.51 +- 0.252 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.6 class 9 = 0.466 +- 0.252 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.6 all KL = 0.386 +- 0.252 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.6 all L1 = 0.583 +- 0.192 (in-sample avg dev_std = 0.383)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.251
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.165
SUFF++ for r=0.9 class 0 = 0.349 +- 0.210 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.9 class 1 = 0.363 +- 0.210 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.9 class 2 = 0.562 +- 0.210 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.9 class 3 = 0.446 +- 0.210 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.9 class 4 = 0.533 +- 0.210 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.9 class 5 = 0.497 +- 0.210 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.9 class 6 = 0.471 +- 0.210 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.9 class 7 = 0.503 +- 0.210 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.9 class 8 = 0.38 +- 0.210 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.9 class 9 = 0.416 +- 0.210 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.9 all KL = 0.229 +- 0.210 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.9 all L1 = 0.451 +- 0.205 (in-sample avg dev_std = 0.407)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.094
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.11
NEC for r=0.3 class 0 = 0.267 +- 0.265 (in-sample avg dev_std = 0.315)
NEC for r=0.3 class 1 = 0.085 +- 0.265 (in-sample avg dev_std = 0.315)
NEC for r=0.3 class 2 = 0.274 +- 0.265 (in-sample avg dev_std = 0.315)
NEC for r=0.3 class 3 = 0.164 +- 0.265 (in-sample avg dev_std = 0.315)
NEC for r=0.3 class 4 = 0.341 +- 0.265 (in-sample avg dev_std = 0.315)
NEC for r=0.3 class 5 = 0.217 +- 0.265 (in-sample avg dev_std = 0.315)
NEC for r=0.3 class 6 = 0.204 +- 0.265 (in-sample avg dev_std = 0.315)
NEC for r=0.3 class 7 = 0.311 +- 0.265 (in-sample avg dev_std = 0.315)
NEC for r=0.3 class 8 = 0.217 +- 0.265 (in-sample avg dev_std = 0.315)
NEC for r=0.3 class 9 = 0.222 +- 0.265 (in-sample avg dev_std = 0.315)
NEC for r=0.3 all KL = 0.226 +- 0.265 (in-sample avg dev_std = 0.315)
NEC for r=0.3 all L1 = 0.228 +- 0.230 (in-sample avg dev_std = 0.315)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.132
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.134
NEC for r=0.6 class 0 = 0.63 +- 0.247 (in-sample avg dev_std = 0.381)
NEC for r=0.6 class 1 = 0.352 +- 0.247 (in-sample avg dev_std = 0.381)
NEC for r=0.6 class 2 = 0.526 +- 0.247 (in-sample avg dev_std = 0.381)
NEC for r=0.6 class 3 = 0.515 +- 0.247 (in-sample avg dev_std = 0.381)
NEC for r=0.6 class 4 = 0.532 +- 0.247 (in-sample avg dev_std = 0.381)
NEC for r=0.6 class 5 = 0.547 +- 0.247 (in-sample avg dev_std = 0.381)
NEC for r=0.6 class 6 = 0.578 +- 0.247 (in-sample avg dev_std = 0.381)
NEC for r=0.6 class 7 = 0.473 +- 0.247 (in-sample avg dev_std = 0.381)
NEC for r=0.6 class 8 = 0.574 +- 0.247 (in-sample avg dev_std = 0.381)
NEC for r=0.6 class 9 = 0.588 +- 0.247 (in-sample avg dev_std = 0.381)
NEC for r=0.6 all KL = 0.55 +- 0.247 (in-sample avg dev_std = 0.381)
NEC for r=0.6 all L1 = 0.528 +- 0.185 (in-sample avg dev_std = 0.381)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.794
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.651
NEC for r=0.9 class 0 = 0.564 +- 0.294 (in-sample avg dev_std = 0.444)
NEC for r=0.9 class 1 = 0.483 +- 0.294 (in-sample avg dev_std = 0.444)
NEC for r=0.9 class 2 = 0.433 +- 0.294 (in-sample avg dev_std = 0.444)
NEC for r=0.9 class 3 = 0.398 +- 0.294 (in-sample avg dev_std = 0.444)
NEC for r=0.9 class 4 = 0.394 +- 0.294 (in-sample avg dev_std = 0.444)
NEC for r=0.9 class 5 = 0.491 +- 0.294 (in-sample avg dev_std = 0.444)
NEC for r=0.9 class 6 = 0.489 +- 0.294 (in-sample avg dev_std = 0.444)
NEC for r=0.9 class 7 = 0.221 +- 0.294 (in-sample avg dev_std = 0.444)
NEC for r=0.9 class 8 = 0.318 +- 0.294 (in-sample avg dev_std = 0.444)
NEC for r=0.9 class 9 = 0.596 +- 0.294 (in-sample avg dev_std = 0.444)
NEC for r=0.9 all KL = 0.543 +- 0.294 (in-sample avg dev_std = 0.444)
NEC for r=0.9 all L1 = 0.435 +- 0.238 (in-sample avg dev_std = 0.444)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.915
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.834
NEC for r=1.0 class 0 = 0.129 +- 0.307 (in-sample avg dev_std = 0.337)
NEC for r=1.0 class 1 = 0.032 +- 0.307 (in-sample avg dev_std = 0.337)
NEC for r=1.0 class 2 = 0.34 +- 0.307 (in-sample avg dev_std = 0.337)
NEC for r=1.0 class 3 = 0.286 +- 0.307 (in-sample avg dev_std = 0.337)
NEC for r=1.0 class 4 = 0.17 +- 0.307 (in-sample avg dev_std = 0.337)
NEC for r=1.0 class 5 = 0.356 +- 0.307 (in-sample avg dev_std = 0.337)
NEC for r=1.0 class 6 = 0.311 +- 0.307 (in-sample avg dev_std = 0.337)
NEC for r=1.0 class 7 = 0.132 +- 0.307 (in-sample avg dev_std = 0.337)
NEC for r=1.0 class 8 = 0.239 +- 0.307 (in-sample avg dev_std = 0.337)
NEC for r=1.0 class 9 = 0.379 +- 0.307 (in-sample avg dev_std = 0.337)
NEC for r=1.0 all KL = 0.313 +- 0.307 (in-sample avg dev_std = 0.337)
NEC for r=1.0 all L1 = 0.232 +- 0.239 (in-sample avg dev_std = 0.337)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.117
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.109
NEC for r=0.3 class 0 = 0.464 +- 0.303 (in-sample avg dev_std = 0.387)
NEC for r=0.3 class 1 = 0.358 +- 0.303 (in-sample avg dev_std = 0.387)
NEC for r=0.3 class 2 = 0.411 +- 0.303 (in-sample avg dev_std = 0.387)
NEC for r=0.3 class 3 = 0.413 +- 0.303 (in-sample avg dev_std = 0.387)
NEC for r=0.3 class 4 = 0.293 +- 0.303 (in-sample avg dev_std = 0.387)
NEC for r=0.3 class 5 = 0.345 +- 0.303 (in-sample avg dev_std = 0.387)
NEC for r=0.3 class 6 = 0.36 +- 0.303 (in-sample avg dev_std = 0.387)
NEC for r=0.3 class 7 = 0.406 +- 0.303 (in-sample avg dev_std = 0.387)
NEC for r=0.3 class 8 = 0.339 +- 0.303 (in-sample avg dev_std = 0.387)
NEC for r=0.3 class 9 = 0.392 +- 0.303 (in-sample avg dev_std = 0.387)
NEC for r=0.3 all KL = 0.391 +- 0.303 (in-sample avg dev_std = 0.387)
NEC for r=0.3 all L1 = 0.379 +- 0.231 (in-sample avg dev_std = 0.387)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.119
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.113
NEC for r=0.6 class 0 = 0.227 +- 0.295 (in-sample avg dev_std = 0.257)
NEC for r=0.6 class 1 = 0.194 +- 0.295 (in-sample avg dev_std = 0.257)
NEC for r=0.6 class 2 = 0.294 +- 0.295 (in-sample avg dev_std = 0.257)
NEC for r=0.6 class 3 = 0.238 +- 0.295 (in-sample avg dev_std = 0.257)
NEC for r=0.6 class 4 = 0.431 +- 0.295 (in-sample avg dev_std = 0.257)
NEC for r=0.6 class 5 = 0.275 +- 0.295 (in-sample avg dev_std = 0.257)
NEC for r=0.6 class 6 = 0.367 +- 0.295 (in-sample avg dev_std = 0.257)
NEC for r=0.6 class 7 = 0.375 +- 0.295 (in-sample avg dev_std = 0.257)
NEC for r=0.6 class 8 = 0.396 +- 0.295 (in-sample avg dev_std = 0.257)
NEC for r=0.6 class 9 = 0.468 +- 0.295 (in-sample avg dev_std = 0.257)
NEC for r=0.6 all KL = 0.353 +- 0.295 (in-sample avg dev_std = 0.257)
NEC for r=0.6 all L1 = 0.324 +- 0.250 (in-sample avg dev_std = 0.257)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.251
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.238
NEC for r=0.9 class 0 = 0.562 +- 0.301 (in-sample avg dev_std = 0.392)
NEC for r=0.9 class 1 = 0.423 +- 0.301 (in-sample avg dev_std = 0.392)
NEC for r=0.9 class 2 = 0.366 +- 0.301 (in-sample avg dev_std = 0.392)
NEC for r=0.9 class 3 = 0.509 +- 0.301 (in-sample avg dev_std = 0.392)
NEC for r=0.9 class 4 = 0.424 +- 0.301 (in-sample avg dev_std = 0.392)
NEC for r=0.9 class 5 = 0.415 +- 0.301 (in-sample avg dev_std = 0.392)
NEC for r=0.9 class 6 = 0.497 +- 0.301 (in-sample avg dev_std = 0.392)
NEC for r=0.9 class 7 = 0.456 +- 0.301 (in-sample avg dev_std = 0.392)
NEC for r=0.9 class 8 = 0.567 +- 0.301 (in-sample avg dev_std = 0.392)
NEC for r=0.9 class 9 = 0.532 +- 0.301 (in-sample avg dev_std = 0.392)
NEC for r=0.9 all KL = 0.582 +- 0.301 (in-sample avg dev_std = 0.392)
NEC for r=0.9 all L1 = 0.475 +- 0.236 (in-sample avg dev_std = 0.392)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.3
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.344
NEC for r=1.0 class 0 = 0.529 +- 0.307 (in-sample avg dev_std = 0.321)
NEC for r=1.0 class 1 = 0.289 +- 0.307 (in-sample avg dev_std = 0.321)
NEC for r=1.0 class 2 = 0.299 +- 0.307 (in-sample avg dev_std = 0.321)
NEC for r=1.0 class 3 = 0.481 +- 0.307 (in-sample avg dev_std = 0.321)
NEC for r=1.0 class 4 = 0.454 +- 0.307 (in-sample avg dev_std = 0.321)
NEC for r=1.0 class 5 = 0.435 +- 0.307 (in-sample avg dev_std = 0.321)
NEC for r=1.0 class 6 = 0.499 +- 0.307 (in-sample avg dev_std = 0.321)
NEC for r=1.0 class 7 = 0.365 +- 0.307 (in-sample avg dev_std = 0.321)
NEC for r=1.0 class 8 = 0.543 +- 0.307 (in-sample avg dev_std = 0.321)
NEC for r=1.0 class 9 = 0.51 +- 0.307 (in-sample avg dev_std = 0.321)
NEC for r=1.0 all KL = 0.454 +- 0.307 (in-sample avg dev_std = 0.321)
NEC for r=1.0 all L1 = 0.438 +- 0.254 (in-sample avg dev_std = 0.321)
model_dirname= repr_GSATvGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 12:58:56 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:58:57 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:58:58 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 185...
[0m[1;37mINFO[0m: [1mCheckpoint 185: 
-----------------------------------
Train ACCURACY: 0.9519
Train Loss: 0.1382
ID Validation ACCURACY: 0.8961
ID Validation Loss: 0.3621
ID Test ACCURACY: 0.8871
ID Test Loss: 0.3798
OOD Validation ACCURACY: 0.7449
OOD Validation Loss: 1.1037
OOD Test ACCURACY: 0.3044
OOD Test Loss: 5.2755

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 172...
[0m[1;37mINFO[0m: [1mCheckpoint 172: 
-----------------------------------
Train ACCURACY: 0.9417
Train Loss: 0.1662
ID Validation ACCURACY: 0.8909
ID Validation Loss: 0.3620
ID Test ACCURACY: 0.8841
ID Test Loss: 0.3721
OOD Validation ACCURACY: 0.8134
OOD Validation Loss: 0.6389
OOD Test ACCURACY: 0.4137
OOD Test Loss: 2.6973

[0m[1;37mINFO[0m: [1mChartInfo 0.8871 0.3044 0.8841 0.4137 0.8909 0.8134[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.125
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.116
SUFF++ for r=0.3 class 0 = 0.389 +- 0.309 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.3 class 1 = 0.527 +- 0.309 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.3 class 2 = 0.46 +- 0.309 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.3 class 3 = 0.522 +- 0.309 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.3 class 4 = 0.563 +- 0.309 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.3 class 5 = 0.547 +- 0.309 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.3 class 6 = 0.532 +- 0.309 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.3 class 7 = 0.68 +- 0.309 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.3 class 8 = 0.45 +- 0.309 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.3 class 9 = 0.583 +- 0.309 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.3 all KL = 0.464 +- 0.309 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.3 all L1 = 0.526 +- 0.254 (in-sample avg dev_std = 0.416)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.127
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.108
SUFF++ for r=0.6 class 0 = 0.251 +- 0.226 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.6 class 1 = 0.396 +- 0.226 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.6 class 2 = 0.337 +- 0.226 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.6 class 3 = 0.349 +- 0.226 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.6 class 4 = 0.277 +- 0.226 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.6 class 5 = 0.338 +- 0.226 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.6 class 6 = 0.27 +- 0.226 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.6 class 7 = 0.331 +- 0.226 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.6 class 8 = 0.295 +- 0.226 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.6 class 9 = 0.307 +- 0.226 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.6 all KL = 0.221 +- 0.226 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.6 all L1 = 0.317 +- 0.163 (in-sample avg dev_std = 0.461)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.783
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.401
SUFF++ for r=0.9 class 0 = 0.27 +- 0.169 (in-sample avg dev_std = 0.762)
SUFF++ for r=0.9 class 1 = 0.337 +- 0.169 (in-sample avg dev_std = 0.762)
SUFF++ for r=0.9 class 2 = 0.28 +- 0.169 (in-sample avg dev_std = 0.762)
SUFF++ for r=0.9 class 3 = 0.305 +- 0.169 (in-sample avg dev_std = 0.762)
SUFF++ for r=0.9 class 4 = 0.31 +- 0.169 (in-sample avg dev_std = 0.762)
SUFF++ for r=0.9 class 5 = 0.31 +- 0.169 (in-sample avg dev_std = 0.762)
SUFF++ for r=0.9 class 6 = 0.277 +- 0.169 (in-sample avg dev_std = 0.762)
SUFF++ for r=0.9 class 7 = 0.538 +- 0.169 (in-sample avg dev_std = 0.762)
SUFF++ for r=0.9 class 8 = 0.313 +- 0.169 (in-sample avg dev_std = 0.762)
SUFF++ for r=0.9 class 9 = 0.318 +- 0.169 (in-sample avg dev_std = 0.762)
SUFF++ for r=0.9 all KL = 0.088 +- 0.169 (in-sample avg dev_std = 0.762)
SUFF++ for r=0.9 all L1 = 0.328 +- 0.131 (in-sample avg dev_std = 0.762)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.16
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.11
SUFF++ for r=0.3 class 0 = 0.662 +- 0.337 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.3 class 1 = 0.255 +- 0.337 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.3 class 2 = 0.58 +- 0.337 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.3 class 3 = 0.53 +- 0.337 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.3 class 4 = 0.452 +- 0.337 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.3 class 5 = 0.568 +- 0.337 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.3 class 6 = 0.413 +- 0.337 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.3 class 7 = 0.53 +- 0.337 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.3 class 8 = 0.516 +- 0.337 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.3 class 9 = 0.36 +- 0.337 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.3 all KL = 0.431 +- 0.337 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.3 all L1 = 0.485 +- 0.283 (in-sample avg dev_std = 0.365)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.199
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.135
SUFF++ for r=0.6 class 0 = 0.383 +- 0.283 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.6 class 1 = 0.317 +- 0.283 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.6 class 2 = 0.34 +- 0.283 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.6 class 3 = 0.346 +- 0.283 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.6 class 4 = 0.327 +- 0.283 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.6 class 5 = 0.404 +- 0.283 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.6 class 6 = 0.389 +- 0.283 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.6 class 7 = 0.424 +- 0.283 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.6 class 8 = 0.438 +- 0.283 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.6 class 9 = 0.424 +- 0.283 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.6 all KL = 0.287 +- 0.283 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.6 all L1 = 0.378 +- 0.214 (in-sample avg dev_std = 0.504)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.256
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.176
SUFF++ for r=0.9 class 0 = 0.277 +- 0.051 (in-sample avg dev_std = 0.713)
SUFF++ for r=0.9 class 1 = 0.356 +- 0.051 (in-sample avg dev_std = 0.713)
SUFF++ for r=0.9 class 2 = 0.279 +- 0.051 (in-sample avg dev_std = 0.713)
SUFF++ for r=0.9 class 3 = 0.291 +- 0.051 (in-sample avg dev_std = 0.713)
SUFF++ for r=0.9 class 4 = 0.247 +- 0.051 (in-sample avg dev_std = 0.713)
SUFF++ for r=0.9 class 5 = 0.269 +- 0.051 (in-sample avg dev_std = 0.713)
SUFF++ for r=0.9 class 6 = 0.249 +- 0.051 (in-sample avg dev_std = 0.713)
SUFF++ for r=0.9 class 7 = 0.271 +- 0.051 (in-sample avg dev_std = 0.713)
SUFF++ for r=0.9 class 8 = 0.255 +- 0.051 (in-sample avg dev_std = 0.713)
SUFF++ for r=0.9 class 9 = 0.265 +- 0.051 (in-sample avg dev_std = 0.713)
SUFF++ for r=0.9 all KL = 0.023 +- 0.051 (in-sample avg dev_std = 0.713)
SUFF++ for r=0.9 all L1 = 0.277 +- 0.090 (in-sample avg dev_std = 0.713)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.125
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.116
NEC for r=0.3 class 0 = 0.637 +- 0.310 (in-sample avg dev_std = 0.436)
NEC for r=0.3 class 1 = 0.457 +- 0.310 (in-sample avg dev_std = 0.436)
NEC for r=0.3 class 2 = 0.582 +- 0.310 (in-sample avg dev_std = 0.436)
NEC for r=0.3 class 3 = 0.51 +- 0.310 (in-sample avg dev_std = 0.436)
NEC for r=0.3 class 4 = 0.501 +- 0.310 (in-sample avg dev_std = 0.436)
NEC for r=0.3 class 5 = 0.51 +- 0.310 (in-sample avg dev_std = 0.436)
NEC for r=0.3 class 6 = 0.504 +- 0.310 (in-sample avg dev_std = 0.436)
NEC for r=0.3 class 7 = 0.376 +- 0.310 (in-sample avg dev_std = 0.436)
NEC for r=0.3 class 8 = 0.558 +- 0.310 (in-sample avg dev_std = 0.436)
NEC for r=0.3 class 9 = 0.453 +- 0.310 (in-sample avg dev_std = 0.436)
NEC for r=0.3 all KL = 0.594 +- 0.310 (in-sample avg dev_std = 0.436)
NEC for r=0.3 all L1 = 0.507 +- 0.238 (in-sample avg dev_std = 0.436)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.127
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.12
NEC for r=0.6 class 0 = 0.693 +- 0.199 (in-sample avg dev_std = 0.430)
NEC for r=0.6 class 1 = 0.625 +- 0.199 (in-sample avg dev_std = 0.430)
NEC for r=0.6 class 2 = 0.673 +- 0.199 (in-sample avg dev_std = 0.430)
NEC for r=0.6 class 3 = 0.616 +- 0.199 (in-sample avg dev_std = 0.430)
NEC for r=0.6 class 4 = 0.652 +- 0.199 (in-sample avg dev_std = 0.430)
NEC for r=0.6 class 5 = 0.656 +- 0.199 (in-sample avg dev_std = 0.430)
NEC for r=0.6 class 6 = 0.642 +- 0.199 (in-sample avg dev_std = 0.430)
NEC for r=0.6 class 7 = 0.616 +- 0.199 (in-sample avg dev_std = 0.430)
NEC for r=0.6 class 8 = 0.667 +- 0.199 (in-sample avg dev_std = 0.430)
NEC for r=0.6 class 9 = 0.634 +- 0.199 (in-sample avg dev_std = 0.430)
NEC for r=0.6 all KL = 0.757 +- 0.199 (in-sample avg dev_std = 0.430)
NEC for r=0.6 all L1 = 0.647 +- 0.146 (in-sample avg dev_std = 0.430)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.783
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.671
NEC for r=0.9 class 0 = 0.56 +- 0.311 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 1 = 0.181 +- 0.311 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 2 = 0.493 +- 0.311 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 3 = 0.381 +- 0.311 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 4 = 0.386 +- 0.311 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 5 = 0.379 +- 0.311 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 6 = 0.506 +- 0.311 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 7 = 0.455 +- 0.311 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 8 = 0.288 +- 0.311 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 9 = 0.617 +- 0.311 (in-sample avg dev_std = 0.441)
NEC for r=0.9 all KL = 0.541 +- 0.311 (in-sample avg dev_std = 0.441)
NEC for r=0.9 all L1 = 0.422 +- 0.253 (in-sample avg dev_std = 0.441)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.933
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.842
NEC for r=1.0 class 0 = 0.111 +- 0.311 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 1 = 0.007 +- 0.311 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 2 = 0.339 +- 0.311 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 3 = 0.314 +- 0.311 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 4 = 0.167 +- 0.311 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 5 = 0.301 +- 0.311 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 6 = 0.216 +- 0.311 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 7 = 0.277 +- 0.311 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 8 = 0.168 +- 0.311 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 9 = 0.357 +- 0.311 (in-sample avg dev_std = 0.345)
NEC for r=1.0 all KL = 0.309 +- 0.311 (in-sample avg dev_std = 0.345)
NEC for r=1.0 all L1 = 0.223 +- 0.237 (in-sample avg dev_std = 0.345)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.16
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.119
NEC for r=0.3 class 0 = 0.347 +- 0.339 (in-sample avg dev_std = 0.344)
NEC for r=0.3 class 1 = 0.658 +- 0.339 (in-sample avg dev_std = 0.344)
NEC for r=0.3 class 2 = 0.408 +- 0.339 (in-sample avg dev_std = 0.344)
NEC for r=0.3 class 3 = 0.478 +- 0.339 (in-sample avg dev_std = 0.344)
NEC for r=0.3 class 4 = 0.541 +- 0.339 (in-sample avg dev_std = 0.344)
NEC for r=0.3 class 5 = 0.428 +- 0.339 (in-sample avg dev_std = 0.344)
NEC for r=0.3 class 6 = 0.577 +- 0.339 (in-sample avg dev_std = 0.344)
NEC for r=0.3 class 7 = 0.449 +- 0.339 (in-sample avg dev_std = 0.344)
NEC for r=0.3 class 8 = 0.469 +- 0.339 (in-sample avg dev_std = 0.344)
NEC for r=0.3 class 9 = 0.613 +- 0.339 (in-sample avg dev_std = 0.344)
NEC for r=0.3 all KL = 0.553 +- 0.339 (in-sample avg dev_std = 0.344)
NEC for r=0.3 all L1 = 0.498 +- 0.277 (in-sample avg dev_std = 0.344)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.199
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.171
NEC for r=0.6 class 0 = 0.575 +- 0.285 (in-sample avg dev_std = 0.446)
NEC for r=0.6 class 1 = 0.498 +- 0.285 (in-sample avg dev_std = 0.446)
NEC for r=0.6 class 2 = 0.558 +- 0.285 (in-sample avg dev_std = 0.446)
NEC for r=0.6 class 3 = 0.593 +- 0.285 (in-sample avg dev_std = 0.446)
NEC for r=0.6 class 4 = 0.637 +- 0.285 (in-sample avg dev_std = 0.446)
NEC for r=0.6 class 5 = 0.573 +- 0.285 (in-sample avg dev_std = 0.446)
NEC for r=0.6 class 6 = 0.614 +- 0.285 (in-sample avg dev_std = 0.446)
NEC for r=0.6 class 7 = 0.584 +- 0.285 (in-sample avg dev_std = 0.446)
NEC for r=0.6 class 8 = 0.553 +- 0.285 (in-sample avg dev_std = 0.446)
NEC for r=0.6 class 9 = 0.581 +- 0.285 (in-sample avg dev_std = 0.446)
NEC for r=0.6 all KL = 0.673 +- 0.285 (in-sample avg dev_std = 0.446)
NEC for r=0.6 all L1 = 0.575 +- 0.223 (in-sample avg dev_std = 0.446)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.256
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.252
NEC for r=0.9 class 0 = 0.525 +- 0.326 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 1 = 0.194 +- 0.326 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 2 = 0.44 +- 0.326 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 3 = 0.429 +- 0.326 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 4 = 0.569 +- 0.326 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 5 = 0.49 +- 0.326 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 6 = 0.516 +- 0.326 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 7 = 0.532 +- 0.326 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 8 = 0.615 +- 0.326 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 9 = 0.606 +- 0.326 (in-sample avg dev_std = 0.439)
NEC for r=0.9 all KL = 0.603 +- 0.326 (in-sample avg dev_std = 0.439)
NEC for r=0.9 all L1 = 0.488 +- 0.266 (in-sample avg dev_std = 0.439)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.304
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.318
NEC for r=1.0 class 0 = 0.347 +- 0.356 (in-sample avg dev_std = 0.343)
NEC for r=1.0 class 1 = 0.29 +- 0.356 (in-sample avg dev_std = 0.343)
NEC for r=1.0 class 2 = 0.457 +- 0.356 (in-sample avg dev_std = 0.343)
NEC for r=1.0 class 3 = 0.368 +- 0.356 (in-sample avg dev_std = 0.343)
NEC for r=1.0 class 4 = 0.608 +- 0.356 (in-sample avg dev_std = 0.343)
NEC for r=1.0 class 5 = 0.512 +- 0.356 (in-sample avg dev_std = 0.343)
NEC for r=1.0 class 6 = 0.519 +- 0.356 (in-sample avg dev_std = 0.343)
NEC for r=1.0 class 7 = 0.475 +- 0.356 (in-sample avg dev_std = 0.343)
NEC for r=1.0 class 8 = 0.561 +- 0.356 (in-sample avg dev_std = 0.343)
NEC for r=1.0 class 9 = 0.546 +- 0.356 (in-sample avg dev_std = 0.343)
NEC for r=1.0 all KL = 0.512 +- 0.356 (in-sample avg dev_std = 0.343)
NEC for r=1.0 all L1 = 0.465 +- 0.292 (in-sample avg dev_std = 0.343)
model_dirname= repr_GSATvGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 13:15:59 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/28/2024 01:16:00 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 01:16:00 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 01:16:00 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 01:16:00 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 01:16:01 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 189...
[0m[1;37mINFO[0m: [1mCheckpoint 189: 
-----------------------------------
Train ACCURACY: 0.9534
Train Loss: 0.1343
ID Validation ACCURACY: 0.8954
ID Validation Loss: 0.3620
ID Test ACCURACY: 0.8914
ID Test Loss: 0.3791
OOD Validation ACCURACY: 0.7987
OOD Validation Loss: 0.7966
OOD Test ACCURACY: 0.2186
OOD Test Loss: 11.4348

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 175...
[0m[1;37mINFO[0m: [1mCheckpoint 175: 
-----------------------------------
Train ACCURACY: 0.9452
Train Loss: 0.1585
ID Validation ACCURACY: 0.8876
ID Validation Loss: 0.3718
ID Test ACCURACY: 0.8883
ID Test Loss: 0.3697
OOD Validation ACCURACY: 0.8087
OOD Validation Loss: 0.7290
OOD Test ACCURACY: 0.2657
OOD Test Loss: 10.3527

[0m[1;37mINFO[0m: [1mChartInfo 0.8914 0.2186 0.8883 0.2657 0.8876 0.8087[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.112
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.091
SUFF++ for r=0.3 class 0 = 0.546 +- 0.306 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.3 class 1 = 0.772 +- 0.306 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.3 class 2 = 0.461 +- 0.306 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.3 class 3 = 0.554 +- 0.306 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.3 class 4 = 0.676 +- 0.306 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.3 class 5 = 0.496 +- 0.306 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.3 class 6 = 0.616 +- 0.306 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.3 class 7 = 0.727 +- 0.306 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.3 class 8 = 0.544 +- 0.306 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.3 class 9 = 0.679 +- 0.306 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.3 all KL = 0.605 +- 0.306 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.3 all L1 = 0.611 +- 0.252 (in-sample avg dev_std = 0.362)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.134
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.109
SUFF++ for r=0.6 class 0 = 0.337 +- 0.177 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 class 1 = 0.305 +- 0.177 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 class 2 = 0.323 +- 0.177 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 class 3 = 0.329 +- 0.177 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 class 4 = 0.334 +- 0.177 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 class 5 = 0.321 +- 0.177 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 class 6 = 0.323 +- 0.177 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 class 7 = 0.37 +- 0.177 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 class 8 = 0.303 +- 0.177 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 class 9 = 0.343 +- 0.177 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 all KL = 0.253 +- 0.177 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 all L1 = 0.329 +- 0.104 (in-sample avg dev_std = 0.417)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.783
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.39
SUFF++ for r=0.9 class 0 = 0.28 +- 0.136 (in-sample avg dev_std = 0.759)
SUFF++ for r=0.9 class 1 = 0.307 +- 0.136 (in-sample avg dev_std = 0.759)
SUFF++ for r=0.9 class 2 = 0.298 +- 0.136 (in-sample avg dev_std = 0.759)
SUFF++ for r=0.9 class 3 = 0.287 +- 0.136 (in-sample avg dev_std = 0.759)
SUFF++ for r=0.9 class 4 = 0.29 +- 0.136 (in-sample avg dev_std = 0.759)
SUFF++ for r=0.9 class 5 = 0.284 +- 0.136 (in-sample avg dev_std = 0.759)
SUFF++ for r=0.9 class 6 = 0.286 +- 0.136 (in-sample avg dev_std = 0.759)
SUFF++ for r=0.9 class 7 = 0.314 +- 0.136 (in-sample avg dev_std = 0.759)
SUFF++ for r=0.9 class 8 = 0.309 +- 0.136 (in-sample avg dev_std = 0.759)
SUFF++ for r=0.9 class 9 = 0.488 +- 0.136 (in-sample avg dev_std = 0.759)
SUFF++ for r=0.9 all KL = 0.071 +- 0.136 (in-sample avg dev_std = 0.759)
SUFF++ for r=0.9 all L1 = 0.314 +- 0.116 (in-sample avg dev_std = 0.759)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.108
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.104
SUFF++ for r=0.3 class 0 = 0.623 +- 0.357 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.3 class 1 = 0.231 +- 0.357 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.3 class 2 = 0.569 +- 0.357 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.3 class 3 = 0.601 +- 0.357 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.3 class 4 = 0.416 +- 0.357 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.3 class 5 = 0.614 +- 0.357 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.3 class 6 = 0.482 +- 0.357 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.3 class 7 = 0.534 +- 0.357 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.3 class 8 = 0.571 +- 0.357 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.3 class 9 = 0.404 +- 0.357 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.3 all KL = 0.44 +- 0.357 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.3 all L1 = 0.502 +- 0.289 (in-sample avg dev_std = 0.264)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.131
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.12
SUFF++ for r=0.6 class 0 = 0.253 +- 0.148 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.6 class 1 = 0.206 +- 0.148 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.6 class 2 = 0.253 +- 0.148 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.6 class 3 = 0.239 +- 0.148 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.6 class 4 = 0.24 +- 0.148 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.6 class 5 = 0.245 +- 0.148 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.6 class 6 = 0.252 +- 0.148 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.6 class 7 = 0.24 +- 0.148 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.6 class 8 = 0.259 +- 0.148 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.6 class 9 = 0.224 +- 0.148 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.6 all KL = 0.1 +- 0.148 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.6 all L1 = 0.241 +- 0.091 (in-sample avg dev_std = 0.448)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.166
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.14
SUFF++ for r=0.9 class 0 = 0.229 +- 0.038 (in-sample avg dev_std = 0.499)
SUFF++ for r=0.9 class 1 = 0.218 +- 0.038 (in-sample avg dev_std = 0.499)
SUFF++ for r=0.9 class 2 = 0.248 +- 0.038 (in-sample avg dev_std = 0.499)
SUFF++ for r=0.9 class 3 = 0.23 +- 0.038 (in-sample avg dev_std = 0.499)
SUFF++ for r=0.9 class 4 = 0.219 +- 0.038 (in-sample avg dev_std = 0.499)
SUFF++ for r=0.9 class 5 = 0.238 +- 0.038 (in-sample avg dev_std = 0.499)
SUFF++ for r=0.9 class 6 = 0.225 +- 0.038 (in-sample avg dev_std = 0.499)
SUFF++ for r=0.9 class 7 = 0.226 +- 0.038 (in-sample avg dev_std = 0.499)
SUFF++ for r=0.9 class 8 = 0.206 +- 0.038 (in-sample avg dev_std = 0.499)
SUFF++ for r=0.9 class 9 = 0.221 +- 0.038 (in-sample avg dev_std = 0.499)
SUFF++ for r=0.9 all KL = 0.018 +- 0.038 (in-sample avg dev_std = 0.499)
SUFF++ for r=0.9 all L1 = 0.226 +- 0.075 (in-sample avg dev_std = 0.499)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.112
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.091
NEC for r=0.3 class 0 = 0.494 +- 0.313 (in-sample avg dev_std = 0.362)
NEC for r=0.3 class 1 = 0.217 +- 0.313 (in-sample avg dev_std = 0.362)
NEC for r=0.3 class 2 = 0.542 +- 0.313 (in-sample avg dev_std = 0.362)
NEC for r=0.3 class 3 = 0.428 +- 0.313 (in-sample avg dev_std = 0.362)
NEC for r=0.3 class 4 = 0.371 +- 0.313 (in-sample avg dev_std = 0.362)
NEC for r=0.3 class 5 = 0.457 +- 0.313 (in-sample avg dev_std = 0.362)
NEC for r=0.3 class 6 = 0.414 +- 0.313 (in-sample avg dev_std = 0.362)
NEC for r=0.3 class 7 = 0.283 +- 0.313 (in-sample avg dev_std = 0.362)
NEC for r=0.3 class 8 = 0.434 +- 0.313 (in-sample avg dev_std = 0.362)
NEC for r=0.3 class 9 = 0.367 +- 0.313 (in-sample avg dev_std = 0.362)
NEC for r=0.3 all KL = 0.416 +- 0.313 (in-sample avg dev_std = 0.362)
NEC for r=0.3 all L1 = 0.397 +- 0.237 (in-sample avg dev_std = 0.362)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.134
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.124
NEC for r=0.6 class 0 = 0.599 +- 0.218 (in-sample avg dev_std = 0.377)
NEC for r=0.6 class 1 = 0.683 +- 0.218 (in-sample avg dev_std = 0.377)
NEC for r=0.6 class 2 = 0.619 +- 0.218 (in-sample avg dev_std = 0.377)
NEC for r=0.6 class 3 = 0.622 +- 0.218 (in-sample avg dev_std = 0.377)
NEC for r=0.6 class 4 = 0.608 +- 0.218 (in-sample avg dev_std = 0.377)
NEC for r=0.6 class 5 = 0.616 +- 0.218 (in-sample avg dev_std = 0.377)
NEC for r=0.6 class 6 = 0.622 +- 0.218 (in-sample avg dev_std = 0.377)
NEC for r=0.6 class 7 = 0.59 +- 0.218 (in-sample avg dev_std = 0.377)
NEC for r=0.6 class 8 = 0.627 +- 0.218 (in-sample avg dev_std = 0.377)
NEC for r=0.6 class 9 = 0.631 +- 0.218 (in-sample avg dev_std = 0.377)
NEC for r=0.6 all KL = 0.678 +- 0.218 (in-sample avg dev_std = 0.377)
NEC for r=0.6 all L1 = 0.622 +- 0.144 (in-sample avg dev_std = 0.377)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.783
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.669
NEC for r=0.9 class 0 = 0.471 +- 0.289 (in-sample avg dev_std = 0.446)
NEC for r=0.9 class 1 = 0.371 +- 0.289 (in-sample avg dev_std = 0.446)
NEC for r=0.9 class 2 = 0.413 +- 0.289 (in-sample avg dev_std = 0.446)
NEC for r=0.9 class 3 = 0.461 +- 0.289 (in-sample avg dev_std = 0.446)
NEC for r=0.9 class 4 = 0.414 +- 0.289 (in-sample avg dev_std = 0.446)
NEC for r=0.9 class 5 = 0.469 +- 0.289 (in-sample avg dev_std = 0.446)
NEC for r=0.9 class 6 = 0.506 +- 0.289 (in-sample avg dev_std = 0.446)
NEC for r=0.9 class 7 = 0.331 +- 0.289 (in-sample avg dev_std = 0.446)
NEC for r=0.9 class 8 = 0.35 +- 0.289 (in-sample avg dev_std = 0.446)
NEC for r=0.9 class 9 = 0.547 +- 0.289 (in-sample avg dev_std = 0.446)
NEC for r=0.9 all KL = 0.551 +- 0.289 (in-sample avg dev_std = 0.446)
NEC for r=0.9 all L1 = 0.43 +- 0.236 (in-sample avg dev_std = 0.446)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.924
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.842
NEC for r=1.0 class 0 = 0.067 +- 0.300 (in-sample avg dev_std = 0.343)
NEC for r=1.0 class 1 = 0.04 +- 0.300 (in-sample avg dev_std = 0.343)
NEC for r=1.0 class 2 = 0.303 +- 0.300 (in-sample avg dev_std = 0.343)
NEC for r=1.0 class 3 = 0.333 +- 0.300 (in-sample avg dev_std = 0.343)
NEC for r=1.0 class 4 = 0.189 +- 0.300 (in-sample avg dev_std = 0.343)
NEC for r=1.0 class 5 = 0.342 +- 0.300 (in-sample avg dev_std = 0.343)
NEC for r=1.0 class 6 = 0.209 +- 0.300 (in-sample avg dev_std = 0.343)
NEC for r=1.0 class 7 = 0.146 +- 0.300 (in-sample avg dev_std = 0.343)
NEC for r=1.0 class 8 = 0.192 +- 0.300 (in-sample avg dev_std = 0.343)
NEC for r=1.0 class 9 = 0.348 +- 0.300 (in-sample avg dev_std = 0.343)
NEC for r=1.0 all KL = 0.305 +- 0.300 (in-sample avg dev_std = 0.343)
NEC for r=1.0 all L1 = 0.213 +- 0.227 (in-sample avg dev_std = 0.343)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.108
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.116
NEC for r=0.3 class 0 = 0.386 +- 0.353 (in-sample avg dev_std = 0.290)
NEC for r=0.3 class 1 = 0.712 +- 0.353 (in-sample avg dev_std = 0.290)
NEC for r=0.3 class 2 = 0.47 +- 0.353 (in-sample avg dev_std = 0.290)
NEC for r=0.3 class 3 = 0.427 +- 0.353 (in-sample avg dev_std = 0.290)
NEC for r=0.3 class 4 = 0.575 +- 0.353 (in-sample avg dev_std = 0.290)
NEC for r=0.3 class 5 = 0.396 +- 0.353 (in-sample avg dev_std = 0.290)
NEC for r=0.3 class 6 = 0.51 +- 0.353 (in-sample avg dev_std = 0.290)
NEC for r=0.3 class 7 = 0.476 +- 0.353 (in-sample avg dev_std = 0.290)
NEC for r=0.3 class 8 = 0.453 +- 0.353 (in-sample avg dev_std = 0.290)
NEC for r=0.3 class 9 = 0.573 +- 0.353 (in-sample avg dev_std = 0.290)
NEC for r=0.3 all KL = 0.567 +- 0.353 (in-sample avg dev_std = 0.290)
NEC for r=0.3 all L1 = 0.5 +- 0.277 (in-sample avg dev_std = 0.290)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.131
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.143
NEC for r=0.6 class 0 = 0.676 +- 0.237 (in-sample avg dev_std = 0.395)
NEC for r=0.6 class 1 = 0.664 +- 0.237 (in-sample avg dev_std = 0.395)
NEC for r=0.6 class 2 = 0.669 +- 0.237 (in-sample avg dev_std = 0.395)
NEC for r=0.6 class 3 = 0.682 +- 0.237 (in-sample avg dev_std = 0.395)
NEC for r=0.6 class 4 = 0.696 +- 0.237 (in-sample avg dev_std = 0.395)
NEC for r=0.6 class 5 = 0.706 +- 0.237 (in-sample avg dev_std = 0.395)
NEC for r=0.6 class 6 = 0.69 +- 0.237 (in-sample avg dev_std = 0.395)
NEC for r=0.6 class 7 = 0.708 +- 0.237 (in-sample avg dev_std = 0.395)
NEC for r=0.6 class 8 = 0.684 +- 0.237 (in-sample avg dev_std = 0.395)
NEC for r=0.6 class 9 = 0.708 +- 0.237 (in-sample avg dev_std = 0.395)
NEC for r=0.6 all KL = 0.82 +- 0.237 (in-sample avg dev_std = 0.395)
NEC for r=0.6 all L1 = 0.688 +- 0.180 (in-sample avg dev_std = 0.395)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.166
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.198
NEC for r=0.9 class 0 = 0.688 +- 0.242 (in-sample avg dev_std = 0.394)
NEC for r=0.9 class 1 = 0.659 +- 0.242 (in-sample avg dev_std = 0.394)
NEC for r=0.9 class 2 = 0.611 +- 0.242 (in-sample avg dev_std = 0.394)
NEC for r=0.9 class 3 = 0.667 +- 0.242 (in-sample avg dev_std = 0.394)
NEC for r=0.9 class 4 = 0.679 +- 0.242 (in-sample avg dev_std = 0.394)
NEC for r=0.9 class 5 = 0.652 +- 0.242 (in-sample avg dev_std = 0.394)
NEC for r=0.9 class 6 = 0.691 +- 0.242 (in-sample avg dev_std = 0.394)
NEC for r=0.9 class 7 = 0.661 +- 0.242 (in-sample avg dev_std = 0.394)
NEC for r=0.9 class 8 = 0.712 +- 0.242 (in-sample avg dev_std = 0.394)
NEC for r=0.9 class 9 = 0.697 +- 0.242 (in-sample avg dev_std = 0.394)
NEC for r=0.9 all KL = 0.813 +- 0.242 (in-sample avg dev_std = 0.394)
NEC for r=0.9 all L1 = 0.671 +- 0.194 (in-sample avg dev_std = 0.394)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.243
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.283
NEC for r=1.0 class 0 = 0.626 +- 0.305 (in-sample avg dev_std = 0.365)
NEC for r=1.0 class 1 = 0.626 +- 0.305 (in-sample avg dev_std = 0.365)
NEC for r=1.0 class 2 = 0.491 +- 0.305 (in-sample avg dev_std = 0.365)
NEC for r=1.0 class 3 = 0.615 +- 0.305 (in-sample avg dev_std = 0.365)
NEC for r=1.0 class 4 = 0.644 +- 0.305 (in-sample avg dev_std = 0.365)
NEC for r=1.0 class 5 = 0.651 +- 0.305 (in-sample avg dev_std = 0.365)
NEC for r=1.0 class 6 = 0.665 +- 0.305 (in-sample avg dev_std = 0.365)
NEC for r=1.0 class 7 = 0.597 +- 0.305 (in-sample avg dev_std = 0.365)
NEC for r=1.0 class 8 = 0.666 +- 0.305 (in-sample avg dev_std = 0.365)
NEC for r=1.0 class 9 = 0.683 +- 0.305 (in-sample avg dev_std = 0.365)
NEC for r=1.0 all KL = 0.75 +- 0.305 (in-sample avg dev_std = 0.365)
NEC for r=1.0 all L1 = 0.625 +- 0.242 (in-sample avg dev_std = 0.365)
model_dirname= repr_GSATvGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 13:33:07 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:33:08 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 01:33:09 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 197...
[0m[1;37mINFO[0m: [1mCheckpoint 197: 
-----------------------------------
Train ACCURACY: 0.9613
Train Loss: 0.1134
ID Validation ACCURACY: 0.8956
ID Validation Loss: 0.3556
ID Test ACCURACY: 0.8920
ID Test Loss: 0.3603
OOD Validation ACCURACY: 0.7163
OOD Validation Loss: 1.1427
OOD Test ACCURACY: 0.1731
OOD Test Loss: 12.4917

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 134...
[0m[1;37mINFO[0m: [1mCheckpoint 134: 
-----------------------------------
Train ACCURACY: 0.9177
Train Loss: 0.2366
ID Validation ACCURACY: 0.8739
ID Validation Loss: 0.3990
ID Test ACCURACY: 0.8733
ID Test Loss: 0.3982
OOD Validation ACCURACY: 0.7943
OOD Validation Loss: 0.6922
OOD Test ACCURACY: 0.3307
OOD Test Loss: 3.3639

[0m[1;37mINFO[0m: [1mChartInfo 0.8920 0.1731 0.8733 0.3307 0.8739 0.7943[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.126
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.116
SUFF++ for r=0.3 class 0 = 0.483 +- 0.211 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.3 class 1 = 0.298 +- 0.211 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.3 class 2 = 0.465 +- 0.211 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.3 class 3 = 0.41 +- 0.211 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.3 class 4 = 0.401 +- 0.211 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.3 class 5 = 0.424 +- 0.211 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.3 class 6 = 0.429 +- 0.211 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.3 class 7 = 0.427 +- 0.211 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.3 class 8 = 0.433 +- 0.211 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.3 class 9 = 0.432 +- 0.211 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.3 all KL = 0.312 +- 0.211 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.3 all L1 = 0.419 +- 0.136 (in-sample avg dev_std = 0.469)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.145
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.123
SUFF++ for r=0.6 class 0 = 0.48 +- 0.250 (in-sample avg dev_std = 0.434)
SUFF++ for r=0.6 class 1 = 0.285 +- 0.250 (in-sample avg dev_std = 0.434)
SUFF++ for r=0.6 class 2 = 0.561 +- 0.250 (in-sample avg dev_std = 0.434)
SUFF++ for r=0.6 class 3 = 0.539 +- 0.250 (in-sample avg dev_std = 0.434)
SUFF++ for r=0.6 class 4 = 0.453 +- 0.250 (in-sample avg dev_std = 0.434)
SUFF++ for r=0.6 class 5 = 0.463 +- 0.250 (in-sample avg dev_std = 0.434)
SUFF++ for r=0.6 class 6 = 0.441 +- 0.250 (in-sample avg dev_std = 0.434)
SUFF++ for r=0.6 class 7 = 0.452 +- 0.250 (in-sample avg dev_std = 0.434)
SUFF++ for r=0.6 class 8 = 0.604 +- 0.250 (in-sample avg dev_std = 0.434)
SUFF++ for r=0.6 class 9 = 0.479 +- 0.250 (in-sample avg dev_std = 0.434)
SUFF++ for r=0.6 all KL = 0.416 +- 0.250 (in-sample avg dev_std = 0.434)
SUFF++ for r=0.6 all L1 = 0.474 +- 0.190 (in-sample avg dev_std = 0.434)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.762
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.38
SUFF++ for r=0.9 class 0 = 0.287 +- 0.133 (in-sample avg dev_std = 0.682)
SUFF++ for r=0.9 class 1 = 0.274 +- 0.133 (in-sample avg dev_std = 0.682)
SUFF++ for r=0.9 class 2 = 0.378 +- 0.133 (in-sample avg dev_std = 0.682)
SUFF++ for r=0.9 class 3 = 0.283 +- 0.133 (in-sample avg dev_std = 0.682)
SUFF++ for r=0.9 class 4 = 0.286 +- 0.133 (in-sample avg dev_std = 0.682)
SUFF++ for r=0.9 class 5 = 0.287 +- 0.133 (in-sample avg dev_std = 0.682)
SUFF++ for r=0.9 class 6 = 0.328 +- 0.133 (in-sample avg dev_std = 0.682)
SUFF++ for r=0.9 class 7 = 0.445 +- 0.133 (in-sample avg dev_std = 0.682)
SUFF++ for r=0.9 class 8 = 0.314 +- 0.133 (in-sample avg dev_std = 0.682)
SUFF++ for r=0.9 class 9 = 0.38 +- 0.133 (in-sample avg dev_std = 0.682)
SUFF++ for r=0.9 all KL = 0.09 +- 0.133 (in-sample avg dev_std = 0.682)
SUFF++ for r=0.9 all L1 = 0.327 +- 0.113 (in-sample avg dev_std = 0.682)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.117
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.105
SUFF++ for r=0.3 class 0 = 0.438 +- 0.233 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.3 class 1 = 0.474 +- 0.233 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.3 class 2 = 0.455 +- 0.233 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.3 class 3 = 0.449 +- 0.233 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.3 class 4 = 0.471 +- 0.233 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.3 class 5 = 0.463 +- 0.233 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.3 class 6 = 0.464 +- 0.233 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.3 class 7 = 0.458 +- 0.233 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.3 class 8 = 0.45 +- 0.233 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.3 class 9 = 0.464 +- 0.233 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.3 all KL = 0.366 +- 0.233 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.3 all L1 = 0.459 +- 0.111 (in-sample avg dev_std = 0.421)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.117
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.111
SUFF++ for r=0.6 class 0 = 0.785 +- 0.262 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.6 class 1 = 0.422 +- 0.262 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.6 class 2 = 0.816 +- 0.262 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.6 class 3 = 0.765 +- 0.262 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.6 class 4 = 0.812 +- 0.262 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.6 class 5 = 0.828 +- 0.262 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.6 class 6 = 0.794 +- 0.262 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.6 class 7 = 0.748 +- 0.262 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.6 class 8 = 0.716 +- 0.262 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.6 class 9 = 0.656 +- 0.262 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.6 all KL = 0.726 +- 0.262 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.6 all L1 = 0.73 +- 0.251 (in-sample avg dev_std = 0.218)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.146
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.142
SUFF++ for r=0.9 class 0 = 0.404 +- 0.326 (in-sample avg dev_std = 0.381)
SUFF++ for r=0.9 class 1 = 0.318 +- 0.326 (in-sample avg dev_std = 0.381)
SUFF++ for r=0.9 class 2 = 0.684 +- 0.326 (in-sample avg dev_std = 0.381)
SUFF++ for r=0.9 class 3 = 0.591 +- 0.326 (in-sample avg dev_std = 0.381)
SUFF++ for r=0.9 class 4 = 0.613 +- 0.326 (in-sample avg dev_std = 0.381)
SUFF++ for r=0.9 class 5 = 0.604 +- 0.326 (in-sample avg dev_std = 0.381)
SUFF++ for r=0.9 class 6 = 0.575 +- 0.326 (in-sample avg dev_std = 0.381)
SUFF++ for r=0.9 class 7 = 0.57 +- 0.326 (in-sample avg dev_std = 0.381)
SUFF++ for r=0.9 class 8 = 0.518 +- 0.326 (in-sample avg dev_std = 0.381)
SUFF++ for r=0.9 class 9 = 0.482 +- 0.326 (in-sample avg dev_std = 0.381)
SUFF++ for r=0.9 all KL = 0.4 +- 0.326 (in-sample avg dev_std = 0.381)
SUFF++ for r=0.9 all L1 = 0.533 +- 0.256 (in-sample avg dev_std = 0.381)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.126
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.124
NEC for r=0.3 class 0 = 0.456 +- 0.269 (in-sample avg dev_std = 0.446)
NEC for r=0.3 class 1 = 0.606 +- 0.269 (in-sample avg dev_std = 0.446)
NEC for r=0.3 class 2 = 0.488 +- 0.269 (in-sample avg dev_std = 0.446)
NEC for r=0.3 class 3 = 0.54 +- 0.269 (in-sample avg dev_std = 0.446)
NEC for r=0.3 class 4 = 0.581 +- 0.269 (in-sample avg dev_std = 0.446)
NEC for r=0.3 class 5 = 0.555 +- 0.269 (in-sample avg dev_std = 0.446)
NEC for r=0.3 class 6 = 0.492 +- 0.269 (in-sample avg dev_std = 0.446)
NEC for r=0.3 class 7 = 0.496 +- 0.269 (in-sample avg dev_std = 0.446)
NEC for r=0.3 class 8 = 0.504 +- 0.269 (in-sample avg dev_std = 0.446)
NEC for r=0.3 class 9 = 0.522 +- 0.269 (in-sample avg dev_std = 0.446)
NEC for r=0.3 all KL = 0.565 +- 0.269 (in-sample avg dev_std = 0.446)
NEC for r=0.3 all L1 = 0.524 +- 0.203 (in-sample avg dev_std = 0.446)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.145
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.134
NEC for r=0.6 class 0 = 0.486 +- 0.278 (in-sample avg dev_std = 0.391)
NEC for r=0.6 class 1 = 0.654 +- 0.278 (in-sample avg dev_std = 0.391)
NEC for r=0.6 class 2 = 0.394 +- 0.278 (in-sample avg dev_std = 0.391)
NEC for r=0.6 class 3 = 0.4 +- 0.278 (in-sample avg dev_std = 0.391)
NEC for r=0.6 class 4 = 0.534 +- 0.278 (in-sample avg dev_std = 0.391)
NEC for r=0.6 class 5 = 0.497 +- 0.278 (in-sample avg dev_std = 0.391)
NEC for r=0.6 class 6 = 0.526 +- 0.278 (in-sample avg dev_std = 0.391)
NEC for r=0.6 class 7 = 0.51 +- 0.278 (in-sample avg dev_std = 0.391)
NEC for r=0.6 class 8 = 0.357 +- 0.278 (in-sample avg dev_std = 0.391)
NEC for r=0.6 class 9 = 0.503 +- 0.278 (in-sample avg dev_std = 0.391)
NEC for r=0.6 all KL = 0.515 +- 0.278 (in-sample avg dev_std = 0.391)
NEC for r=0.6 all L1 = 0.487 +- 0.218 (in-sample avg dev_std = 0.391)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.762
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.622
NEC for r=0.9 class 0 = 0.497 +- 0.299 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 1 = 0.541 +- 0.299 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 2 = 0.269 +- 0.299 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 3 = 0.45 +- 0.299 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 4 = 0.557 +- 0.299 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 5 = 0.559 +- 0.299 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 6 = 0.401 +- 0.299 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 7 = 0.364 +- 0.299 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 8 = 0.282 +- 0.299 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 9 = 0.569 +- 0.299 (in-sample avg dev_std = 0.441)
NEC for r=0.9 all KL = 0.562 +- 0.299 (in-sample avg dev_std = 0.441)
NEC for r=0.9 all L1 = 0.446 +- 0.245 (in-sample avg dev_std = 0.441)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.926
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.838
NEC for r=1.0 class 0 = 0.081 +- 0.306 (in-sample avg dev_std = 0.348)
NEC for r=1.0 class 1 = 0.05 +- 0.306 (in-sample avg dev_std = 0.348)
NEC for r=1.0 class 2 = 0.242 +- 0.306 (in-sample avg dev_std = 0.348)
NEC for r=1.0 class 3 = 0.321 +- 0.306 (in-sample avg dev_std = 0.348)
NEC for r=1.0 class 4 = 0.241 +- 0.306 (in-sample avg dev_std = 0.348)
NEC for r=1.0 class 5 = 0.429 +- 0.306 (in-sample avg dev_std = 0.348)
NEC for r=1.0 class 6 = 0.233 +- 0.306 (in-sample avg dev_std = 0.348)
NEC for r=1.0 class 7 = 0.242 +- 0.306 (in-sample avg dev_std = 0.348)
NEC for r=1.0 class 8 = 0.188 +- 0.306 (in-sample avg dev_std = 0.348)
NEC for r=1.0 class 9 = 0.322 +- 0.306 (in-sample avg dev_std = 0.348)
NEC for r=1.0 all KL = 0.325 +- 0.306 (in-sample avg dev_std = 0.348)
NEC for r=1.0 all L1 = 0.23 +- 0.237 (in-sample avg dev_std = 0.348)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.117
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.114
NEC for r=0.3 class 0 = 0.478 +- 0.271 (in-sample avg dev_std = 0.393)
NEC for r=0.3 class 1 = 0.475 +- 0.271 (in-sample avg dev_std = 0.393)
NEC for r=0.3 class 2 = 0.47 +- 0.271 (in-sample avg dev_std = 0.393)
NEC for r=0.3 class 3 = 0.457 +- 0.271 (in-sample avg dev_std = 0.393)
NEC for r=0.3 class 4 = 0.443 +- 0.271 (in-sample avg dev_std = 0.393)
NEC for r=0.3 class 5 = 0.438 +- 0.271 (in-sample avg dev_std = 0.393)
NEC for r=0.3 class 6 = 0.444 +- 0.271 (in-sample avg dev_std = 0.393)
NEC for r=0.3 class 7 = 0.513 +- 0.271 (in-sample avg dev_std = 0.393)
NEC for r=0.3 class 8 = 0.513 +- 0.271 (in-sample avg dev_std = 0.393)
NEC for r=0.3 class 9 = 0.491 +- 0.271 (in-sample avg dev_std = 0.393)
NEC for r=0.3 all KL = 0.533 +- 0.271 (in-sample avg dev_std = 0.393)
NEC for r=0.3 all L1 = 0.473 +- 0.186 (in-sample avg dev_std = 0.393)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.117
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.114
NEC for r=0.6 class 0 = 0.257 +- 0.266 (in-sample avg dev_std = 0.248)
NEC for r=0.6 class 1 = 0.536 +- 0.266 (in-sample avg dev_std = 0.248)
NEC for r=0.6 class 2 = 0.189 +- 0.266 (in-sample avg dev_std = 0.248)
NEC for r=0.6 class 3 = 0.246 +- 0.266 (in-sample avg dev_std = 0.248)
NEC for r=0.6 class 4 = 0.209 +- 0.266 (in-sample avg dev_std = 0.248)
NEC for r=0.6 class 5 = 0.178 +- 0.266 (in-sample avg dev_std = 0.248)
NEC for r=0.6 class 6 = 0.232 +- 0.266 (in-sample avg dev_std = 0.248)
NEC for r=0.6 class 7 = 0.268 +- 0.266 (in-sample avg dev_std = 0.248)
NEC for r=0.6 class 8 = 0.299 +- 0.266 (in-sample avg dev_std = 0.248)
NEC for r=0.6 class 9 = 0.349 +- 0.266 (in-sample avg dev_std = 0.248)
NEC for r=0.6 all KL = 0.3 +- 0.266 (in-sample avg dev_std = 0.248)
NEC for r=0.6 all L1 = 0.28 +- 0.240 (in-sample avg dev_std = 0.248)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.146
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.17
NEC for r=0.9 class 0 = 0.654 +- 0.286 (in-sample avg dev_std = 0.386)
NEC for r=0.9 class 1 = 0.52 +- 0.286 (in-sample avg dev_std = 0.386)
NEC for r=0.9 class 2 = 0.35 +- 0.286 (in-sample avg dev_std = 0.386)
NEC for r=0.9 class 3 = 0.446 +- 0.286 (in-sample avg dev_std = 0.386)
NEC for r=0.9 class 4 = 0.441 +- 0.286 (in-sample avg dev_std = 0.386)
NEC for r=0.9 class 5 = 0.448 +- 0.286 (in-sample avg dev_std = 0.386)
NEC for r=0.9 class 6 = 0.465 +- 0.286 (in-sample avg dev_std = 0.386)
NEC for r=0.9 class 7 = 0.499 +- 0.286 (in-sample avg dev_std = 0.386)
NEC for r=0.9 class 8 = 0.534 +- 0.286 (in-sample avg dev_std = 0.386)
NEC for r=0.9 class 9 = 0.544 +- 0.286 (in-sample avg dev_std = 0.386)
NEC for r=0.9 all KL = 0.687 +- 0.286 (in-sample avg dev_std = 0.386)
NEC for r=0.9 all L1 = 0.49 +- 0.230 (in-sample avg dev_std = 0.386)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.183
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.215
NEC for r=1.0 class 0 = 0.604 +- 0.340 (in-sample avg dev_std = 0.341)
NEC for r=1.0 class 1 = 0.428 +- 0.340 (in-sample avg dev_std = 0.341)
NEC for r=1.0 class 2 = 0.362 +- 0.340 (in-sample avg dev_std = 0.341)
NEC for r=1.0 class 3 = 0.437 +- 0.340 (in-sample avg dev_std = 0.341)
NEC for r=1.0 class 4 = 0.359 +- 0.340 (in-sample avg dev_std = 0.341)
NEC for r=1.0 class 5 = 0.5 +- 0.340 (in-sample avg dev_std = 0.341)
NEC for r=1.0 class 6 = 0.412 +- 0.340 (in-sample avg dev_std = 0.341)
NEC for r=1.0 class 7 = 0.465 +- 0.340 (in-sample avg dev_std = 0.341)
NEC for r=1.0 class 8 = 0.471 +- 0.340 (in-sample avg dev_std = 0.341)
NEC for r=1.0 class 9 = 0.391 +- 0.340 (in-sample avg dev_std = 0.341)
NEC for r=1.0 all KL = 0.618 +- 0.340 (in-sample avg dev_std = 0.341)
NEC for r=1.0 all L1 = 0.442 +- 0.269 (in-sample avg dev_std = 0.341)
model_dirname= repr_GSATvGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 13:50:16 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/28/2024 01:50:16 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 01:50:16 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 01:50:16 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 01:50:17 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 187...
[0m[1;37mINFO[0m: [1mCheckpoint 187: 
-----------------------------------
Train ACCURACY: 0.9609
Train Loss: 0.1130
ID Validation ACCURACY: 0.8967
ID Validation Loss: 0.3439
ID Test ACCURACY: 0.8937
ID Test Loss: 0.3554
OOD Validation ACCURACY: 0.7863
OOD Validation Loss: 0.8914
OOD Test ACCURACY: 0.2307
OOD Test Loss: 10.8940

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 127...
[0m[1;37mINFO[0m: [1mCheckpoint 127: 
-----------------------------------
Train ACCURACY: 0.9328
Train Loss: 0.1957
ID Validation ACCURACY: 0.8821
ID Validation Loss: 0.3581
ID Test ACCURACY: 0.8791
ID Test Loss: 0.3593
OOD Validation ACCURACY: 0.8147
OOD Validation Loss: 0.5922
OOD Test ACCURACY: 0.3769
OOD Test Loss: 3.0655

[0m[1;37mINFO[0m: [1mChartInfo 0.8937 0.2307 0.8791 0.3769 0.8821 0.8147[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.114
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.113
SUFF++ for r=0.3 class 0 = 0.409 +- 0.270 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.3 class 1 = 0.503 +- 0.270 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.3 class 2 = 0.441 +- 0.270 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.3 class 3 = 0.475 +- 0.270 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.3 class 4 = 0.439 +- 0.270 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.3 class 5 = 0.467 +- 0.270 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.3 class 6 = 0.475 +- 0.270 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.3 class 7 = 0.516 +- 0.270 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.3 class 8 = 0.384 +- 0.270 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.3 class 9 = 0.414 +- 0.270 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.3 all KL = 0.458 +- 0.270 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.3 all L1 = 0.454 +- 0.167 (in-sample avg dev_std = 0.419)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.18
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.128
SUFF++ for r=0.6 class 0 = 0.289 +- 0.177 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.6 class 1 = 0.395 +- 0.177 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.6 class 2 = 0.287 +- 0.177 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.6 class 3 = 0.318 +- 0.177 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.6 class 4 = 0.31 +- 0.177 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.6 class 5 = 0.33 +- 0.177 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.6 class 6 = 0.31 +- 0.177 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.6 class 7 = 0.356 +- 0.177 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.6 class 8 = 0.282 +- 0.177 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.6 class 9 = 0.293 +- 0.177 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.6 all KL = 0.207 +- 0.177 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.6 all L1 = 0.318 +- 0.104 (in-sample avg dev_std = 0.498)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.771
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.407
SUFF++ for r=0.9 class 0 = 0.254 +- 0.231 (in-sample avg dev_std = 0.721)
SUFF++ for r=0.9 class 1 = 0.761 +- 0.231 (in-sample avg dev_std = 0.721)
SUFF++ for r=0.9 class 2 = 0.306 +- 0.231 (in-sample avg dev_std = 0.721)
SUFF++ for r=0.9 class 3 = 0.284 +- 0.231 (in-sample avg dev_std = 0.721)
SUFF++ for r=0.9 class 4 = 0.299 +- 0.231 (in-sample avg dev_std = 0.721)
SUFF++ for r=0.9 class 5 = 0.249 +- 0.231 (in-sample avg dev_std = 0.721)
SUFF++ for r=0.9 class 6 = 0.278 +- 0.231 (in-sample avg dev_std = 0.721)
SUFF++ for r=0.9 class 7 = 0.353 +- 0.231 (in-sample avg dev_std = 0.721)
SUFF++ for r=0.9 class 8 = 0.308 +- 0.231 (in-sample avg dev_std = 0.721)
SUFF++ for r=0.9 class 9 = 0.262 +- 0.231 (in-sample avg dev_std = 0.721)
SUFF++ for r=0.9 all KL = 0.095 +- 0.231 (in-sample avg dev_std = 0.721)
SUFF++ for r=0.9 all L1 = 0.343 +- 0.188 (in-sample avg dev_std = 0.721)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.119
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.104
SUFF++ for r=0.3 class 0 = 0.383 +- 0.248 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.3 class 1 = 0.383 +- 0.248 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.3 class 2 = 0.39 +- 0.248 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.3 class 3 = 0.386 +- 0.248 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.3 class 4 = 0.407 +- 0.248 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.3 class 5 = 0.396 +- 0.248 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.3 class 6 = 0.378 +- 0.248 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.3 class 7 = 0.398 +- 0.248 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.3 class 8 = 0.401 +- 0.248 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.3 class 9 = 0.402 +- 0.248 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.3 all KL = 0.371 +- 0.248 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.3 all L1 = 0.392 +- 0.136 (in-sample avg dev_std = 0.399)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.184
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.151
SUFF++ for r=0.6 class 0 = 0.442 +- 0.209 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.6 class 1 = 0.303 +- 0.209 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.6 class 2 = 0.421 +- 0.209 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.6 class 3 = 0.382 +- 0.209 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.6 class 4 = 0.373 +- 0.209 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.6 class 5 = 0.383 +- 0.209 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.6 class 6 = 0.371 +- 0.209 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.6 class 7 = 0.376 +- 0.209 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.6 class 8 = 0.341 +- 0.209 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.6 class 9 = 0.3 +- 0.209 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.6 all KL = 0.221 +- 0.209 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.6 all L1 = 0.369 +- 0.137 (in-sample avg dev_std = 0.564)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.168
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.196
SUFF++ for r=0.9 class 0 = 0.272 +- 0.209 (in-sample avg dev_std = 0.547)
SUFF++ for r=0.9 class 1 = 0.535 +- 0.209 (in-sample avg dev_std = 0.547)
SUFF++ for r=0.9 class 2 = 0.318 +- 0.209 (in-sample avg dev_std = 0.547)
SUFF++ for r=0.9 class 3 = 0.312 +- 0.209 (in-sample avg dev_std = 0.547)
SUFF++ for r=0.9 class 4 = 0.246 +- 0.209 (in-sample avg dev_std = 0.547)
SUFF++ for r=0.9 class 5 = 0.284 +- 0.209 (in-sample avg dev_std = 0.547)
SUFF++ for r=0.9 class 6 = 0.259 +- 0.209 (in-sample avg dev_std = 0.547)
SUFF++ for r=0.9 class 7 = 0.318 +- 0.209 (in-sample avg dev_std = 0.547)
SUFF++ for r=0.9 class 8 = 0.244 +- 0.209 (in-sample avg dev_std = 0.547)
SUFF++ for r=0.9 class 9 = 0.27 +- 0.209 (in-sample avg dev_std = 0.547)
SUFF++ for r=0.9 all KL = 0.091 +- 0.209 (in-sample avg dev_std = 0.547)
SUFF++ for r=0.9 all L1 = 0.309 +- 0.193 (in-sample avg dev_std = 0.547)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.114
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.116
NEC for r=0.3 class 0 = 0.592 +- 0.275 (in-sample avg dev_std = 0.405)
NEC for r=0.3 class 1 = 0.441 +- 0.275 (in-sample avg dev_std = 0.405)
NEC for r=0.3 class 2 = 0.522 +- 0.275 (in-sample avg dev_std = 0.405)
NEC for r=0.3 class 3 = 0.53 +- 0.275 (in-sample avg dev_std = 0.405)
NEC for r=0.3 class 4 = 0.552 +- 0.275 (in-sample avg dev_std = 0.405)
NEC for r=0.3 class 5 = 0.525 +- 0.275 (in-sample avg dev_std = 0.405)
NEC for r=0.3 class 6 = 0.468 +- 0.275 (in-sample avg dev_std = 0.405)
NEC for r=0.3 class 7 = 0.466 +- 0.275 (in-sample avg dev_std = 0.405)
NEC for r=0.3 class 8 = 0.587 +- 0.275 (in-sample avg dev_std = 0.405)
NEC for r=0.3 class 9 = 0.556 +- 0.275 (in-sample avg dev_std = 0.405)
NEC for r=0.3 all KL = 0.538 +- 0.275 (in-sample avg dev_std = 0.405)
NEC for r=0.3 all L1 = 0.522 +- 0.182 (in-sample avg dev_std = 0.405)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.18
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.167
NEC for r=0.6 class 0 = 0.651 +- 0.233 (in-sample avg dev_std = 0.412)
NEC for r=0.6 class 1 = 0.515 +- 0.233 (in-sample avg dev_std = 0.412)
NEC for r=0.6 class 2 = 0.581 +- 0.233 (in-sample avg dev_std = 0.412)
NEC for r=0.6 class 3 = 0.595 +- 0.233 (in-sample avg dev_std = 0.412)
NEC for r=0.6 class 4 = 0.657 +- 0.233 (in-sample avg dev_std = 0.412)
NEC for r=0.6 class 5 = 0.627 +- 0.233 (in-sample avg dev_std = 0.412)
NEC for r=0.6 class 6 = 0.618 +- 0.233 (in-sample avg dev_std = 0.412)
NEC for r=0.6 class 7 = 0.531 +- 0.233 (in-sample avg dev_std = 0.412)
NEC for r=0.6 class 8 = 0.595 +- 0.233 (in-sample avg dev_std = 0.412)
NEC for r=0.6 class 9 = 0.641 +- 0.233 (in-sample avg dev_std = 0.412)
NEC for r=0.6 all KL = 0.657 +- 0.233 (in-sample avg dev_std = 0.412)
NEC for r=0.6 all L1 = 0.598 +- 0.158 (in-sample avg dev_std = 0.412)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.771
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.655
NEC for r=0.9 class 0 = 0.578 +- 0.299 (in-sample avg dev_std = 0.440)
NEC for r=0.9 class 1 = 0.281 +- 0.299 (in-sample avg dev_std = 0.440)
NEC for r=0.9 class 2 = 0.333 +- 0.299 (in-sample avg dev_std = 0.440)
NEC for r=0.9 class 3 = 0.414 +- 0.299 (in-sample avg dev_std = 0.440)
NEC for r=0.9 class 4 = 0.389 +- 0.299 (in-sample avg dev_std = 0.440)
NEC for r=0.9 class 5 = 0.555 +- 0.299 (in-sample avg dev_std = 0.440)
NEC for r=0.9 class 6 = 0.51 +- 0.299 (in-sample avg dev_std = 0.440)
NEC for r=0.9 class 7 = 0.342 +- 0.299 (in-sample avg dev_std = 0.440)
NEC for r=0.9 class 8 = 0.344 +- 0.299 (in-sample avg dev_std = 0.440)
NEC for r=0.9 class 9 = 0.593 +- 0.299 (in-sample avg dev_std = 0.440)
NEC for r=0.9 all KL = 0.544 +- 0.299 (in-sample avg dev_std = 0.440)
NEC for r=0.9 all L1 = 0.428 +- 0.246 (in-sample avg dev_std = 0.440)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.931
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.85
NEC for r=1.0 class 0 = 0.131 +- 0.302 (in-sample avg dev_std = 0.332)
NEC for r=1.0 class 1 = 0.037 +- 0.302 (in-sample avg dev_std = 0.332)
NEC for r=1.0 class 2 = 0.204 +- 0.302 (in-sample avg dev_std = 0.332)
NEC for r=1.0 class 3 = 0.282 +- 0.302 (in-sample avg dev_std = 0.332)
NEC for r=1.0 class 4 = 0.153 +- 0.302 (in-sample avg dev_std = 0.332)
NEC for r=1.0 class 5 = 0.371 +- 0.302 (in-sample avg dev_std = 0.332)
NEC for r=1.0 class 6 = 0.243 +- 0.302 (in-sample avg dev_std = 0.332)
NEC for r=1.0 class 7 = 0.219 +- 0.302 (in-sample avg dev_std = 0.332)
NEC for r=1.0 class 8 = 0.196 +- 0.302 (in-sample avg dev_std = 0.332)
NEC for r=1.0 class 9 = 0.373 +- 0.302 (in-sample avg dev_std = 0.332)
NEC for r=1.0 all KL = 0.293 +- 0.302 (in-sample avg dev_std = 0.332)
NEC for r=1.0 all L1 = 0.216 +- 0.236 (in-sample avg dev_std = 0.332)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.119
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.111
NEC for r=0.3 class 0 = 0.59 +- 0.273 (in-sample avg dev_std = 0.376)
NEC for r=0.3 class 1 = 0.56 +- 0.273 (in-sample avg dev_std = 0.376)
NEC for r=0.3 class 2 = 0.595 +- 0.273 (in-sample avg dev_std = 0.376)
NEC for r=0.3 class 3 = 0.607 +- 0.273 (in-sample avg dev_std = 0.376)
NEC for r=0.3 class 4 = 0.545 +- 0.273 (in-sample avg dev_std = 0.376)
NEC for r=0.3 class 5 = 0.582 +- 0.273 (in-sample avg dev_std = 0.376)
NEC for r=0.3 class 6 = 0.607 +- 0.273 (in-sample avg dev_std = 0.376)
NEC for r=0.3 class 7 = 0.577 +- 0.273 (in-sample avg dev_std = 0.376)
NEC for r=0.3 class 8 = 0.58 +- 0.273 (in-sample avg dev_std = 0.376)
NEC for r=0.3 class 9 = 0.527 +- 0.273 (in-sample avg dev_std = 0.376)
NEC for r=0.3 all KL = 0.593 +- 0.273 (in-sample avg dev_std = 0.376)
NEC for r=0.3 all L1 = 0.577 +- 0.171 (in-sample avg dev_std = 0.376)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.184
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.199
NEC for r=0.6 class 0 = 0.366 +- 0.338 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 1 = 0.336 +- 0.338 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 2 = 0.394 +- 0.338 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 3 = 0.436 +- 0.338 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 4 = 0.509 +- 0.338 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 5 = 0.447 +- 0.338 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 6 = 0.479 +- 0.338 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 7 = 0.522 +- 0.338 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 8 = 0.528 +- 0.338 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 9 = 0.585 +- 0.338 (in-sample avg dev_std = 0.359)
NEC for r=0.6 all KL = 0.545 +- 0.338 (in-sample avg dev_std = 0.359)
NEC for r=0.6 all L1 = 0.458 +- 0.279 (in-sample avg dev_std = 0.359)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.168
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.219
NEC for r=0.9 class 0 = 0.601 +- 0.338 (in-sample avg dev_std = 0.349)
NEC for r=0.9 class 1 = 0.357 +- 0.338 (in-sample avg dev_std = 0.349)
NEC for r=0.9 class 2 = 0.495 +- 0.338 (in-sample avg dev_std = 0.349)
NEC for r=0.9 class 3 = 0.519 +- 0.338 (in-sample avg dev_std = 0.349)
NEC for r=0.9 class 4 = 0.669 +- 0.338 (in-sample avg dev_std = 0.349)
NEC for r=0.9 class 5 = 0.558 +- 0.338 (in-sample avg dev_std = 0.349)
NEC for r=0.9 class 6 = 0.633 +- 0.338 (in-sample avg dev_std = 0.349)
NEC for r=0.9 class 7 = 0.604 +- 0.338 (in-sample avg dev_std = 0.349)
NEC for r=0.9 class 8 = 0.672 +- 0.338 (in-sample avg dev_std = 0.349)
NEC for r=0.9 class 9 = 0.675 +- 0.338 (in-sample avg dev_std = 0.349)
NEC for r=0.9 all KL = 0.671 +- 0.338 (in-sample avg dev_std = 0.349)
NEC for r=0.9 all L1 = 0.575 +- 0.279 (in-sample avg dev_std = 0.349)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.241
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.29
NEC for r=1.0 class 0 = 0.575 +- 0.306 (in-sample avg dev_std = 0.371)
NEC for r=1.0 class 1 = 0.441 +- 0.306 (in-sample avg dev_std = 0.371)
NEC for r=1.0 class 2 = 0.643 +- 0.306 (in-sample avg dev_std = 0.371)
NEC for r=1.0 class 3 = 0.622 +- 0.306 (in-sample avg dev_std = 0.371)
NEC for r=1.0 class 4 = 0.697 +- 0.306 (in-sample avg dev_std = 0.371)
NEC for r=1.0 class 5 = 0.627 +- 0.306 (in-sample avg dev_std = 0.371)
NEC for r=1.0 class 6 = 0.643 +- 0.306 (in-sample avg dev_std = 0.371)
NEC for r=1.0 class 7 = 0.713 +- 0.306 (in-sample avg dev_std = 0.371)
NEC for r=1.0 class 8 = 0.647 +- 0.306 (in-sample avg dev_std = 0.371)
NEC for r=1.0 class 9 = 0.697 +- 0.306 (in-sample avg dev_std = 0.371)
NEC for r=1.0 all KL = 0.743 +- 0.306 (in-sample avg dev_std = 0.371)
NEC for r=1.0 all L1 = 0.628 +- 0.242 (in-sample avg dev_std = 0.371)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.804, 0.307, 0.104, 1.0], 'all_L1': [0.793, 0.386, 0.33, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.464, 0.221, 0.088, 1.0], 'all_L1': [0.526, 0.317, 0.328, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.605, 0.253, 0.071, 1.0], 'all_L1': [0.611, 0.329, 0.314, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.312, 0.416, 0.09, 1.0], 'all_L1': [0.419, 0.474, 0.327, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.458, 0.207, 0.095, 1.0], 'all_L1': [0.454, 0.318, 0.343, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.226, 0.55, 0.543, 0.313], 'all_L1': [0.228, 0.528, 0.435, 0.232]}), defaultdict(<class 'list'>, {'all_KL': [0.594, 0.757, 0.541, 0.309], 'all_L1': [0.507, 0.647, 0.422, 0.223]}), defaultdict(<class 'list'>, {'all_KL': [0.416, 0.678, 0.551, 0.305], 'all_L1': [0.397, 0.622, 0.43, 0.213]}), defaultdict(<class 'list'>, {'all_KL': [0.565, 0.515, 0.562, 0.325], 'all_L1': [0.524, 0.487, 0.446, 0.23]}), defaultdict(<class 'list'>, {'all_KL': [0.538, 0.657, 0.544, 0.293], 'all_L1': [0.522, 0.598, 0.428, 0.216]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.56, 0.386, 0.229, 1.0], 'all_L1': [0.586, 0.583, 0.451, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.431, 0.287, 0.023, 1.0], 'all_L1': [0.485, 0.378, 0.277, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.44, 0.1, 0.018, 1.0], 'all_L1': [0.502, 0.241, 0.226, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.366, 0.726, 0.4, 1.0], 'all_L1': [0.459, 0.73, 0.533, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.371, 0.221, 0.091, 1.0], 'all_L1': [0.392, 0.369, 0.309, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.391, 0.353, 0.582, 0.454], 'all_L1': [0.379, 0.324, 0.475, 0.438]}), defaultdict(<class 'list'>, {'all_KL': [0.553, 0.673, 0.603, 0.512], 'all_L1': [0.498, 0.575, 0.488, 0.465]}), defaultdict(<class 'list'>, {'all_KL': [0.567, 0.82, 0.813, 0.75], 'all_L1': [0.5, 0.688, 0.671, 0.625]}), defaultdict(<class 'list'>, {'all_KL': [0.533, 0.3, 0.687, 0.618], 'all_L1': [0.473, 0.28, 0.49, 0.442]}), defaultdict(<class 'list'>, {'all_KL': [0.593, 0.545, 0.671, 0.743], 'all_L1': [0.577, 0.458, 0.575, 0.628]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.561 +- 0.134, 0.365 +- 0.060, 0.328 +- 0.009, 1.000 +- 0.000
suff++ class all_KL  =  0.529 +- 0.166, 0.281 +- 0.076, 0.090 +- 0.011, 1.000 +- 0.000
suff++_acc_int  =  0.109 +- 0.009, 0.117 +- 0.008, 0.392 +- 0.011
nec class all_L1  =  0.436 +- 0.114, 0.576 +- 0.060, 0.432 +- 0.008, 0.223 +- 0.007
nec class all_KL  =  0.468 +- 0.135, 0.631 +- 0.088, 0.548 +- 0.008, 0.309 +- 0.010
nec_acc_int  =  0.111 +- 0.011, 0.136 +- 0.017, 0.654 +- 0.018, 0.841 +- 0.005

Eval split test
suff++ class all_L1  =  0.485 +- 0.063, 0.460 +- 0.174, 0.359 +- 0.115, 1.000 +- 0.000
suff++ class all_KL  =  0.434 +- 0.070, 0.344 +- 0.212, 0.152 +- 0.145, 1.000 +- 0.000
suff++_acc_int  =  0.106 +- 0.002, 0.125 +- 0.016, 0.163 +- 0.021
nec class all_L1  =  0.485 +- 0.064, 0.465 +- 0.152, 0.540 +- 0.075, 0.520 +- 0.088
nec class all_KL  =  0.527 +- 0.071, 0.538 +- 0.194, 0.671 +- 0.081, 0.615 +- 0.119
nec_acc_int  =  0.114 +- 0.004, 0.148 +- 0.033, 0.215 +- 0.029, 0.290 +- 0.043


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.498 +- 0.016, 0.471 +- 0.011, 0.380 +- 0.006, 0.611 +- 0.004
Faith. Armon (L1)= 		  =  0.461 +- 0.056, 0.439 +- 0.023, 0.373 +- 0.006, 0.364 +- 0.010
Faith. GMean (L1)= 	  =  0.478 +- 0.030, 0.455 +- 0.014, 0.377 +- 0.006, 0.472 +- 0.008
Faith. Aritm (KL)= 		  =  0.498 +- 0.031, 0.456 +- 0.023, 0.319 +- 0.006, 0.655 +- 0.005
Faith. Armon (KL)= 		  =  0.453 +- 0.064, 0.376 +- 0.050, 0.154 +- 0.016, 0.472 +- 0.012
Faith. GMean (KL)= 	  =  0.474 +- 0.043, 0.413 +- 0.030, 0.221 +- 0.013, 0.556 +- 0.009

Eval split test
Faith. Aritm (L1)= 		  =  0.485 +- 0.012, 0.463 +- 0.030, 0.449 +- 0.041, 0.760 +- 0.044
Faith. Armon (L1)= 		  =  0.477 +- 0.016, 0.409 +- 0.032, 0.413 +- 0.065, 0.680 +- 0.075
Faith. GMean (L1)= 	  =  0.481 +- 0.013, 0.434 +- 0.023, 0.430 +- 0.051, 0.718 +- 0.060
Faith. Aritm (KL)= 		  =  0.480 +- 0.018, 0.441 +- 0.056, 0.412 +- 0.075, 0.808 +- 0.060
Faith. Armon (KL)= 		  =  0.466 +- 0.022, 0.338 +- 0.088, 0.215 +- 0.180, 0.755 +- 0.093
Faith. GMean (KL)= 	  =  0.473 +- 0.020, 0.382 +- 0.065, 0.275 +- 0.155, 0.781 +- 0.077
Computed for split load_split = id



Completed in  1:25:28.864830  for GSATvGIN GOODCMNIST/color



DONE GSAT GOODCMNIST/color
big_random.sh: line 31: syntax error near unexpected token `)'
