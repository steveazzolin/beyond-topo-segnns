nohup: ignoring input

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Apr  6 20:43:06 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:06 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:21 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:24 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:26 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:28 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:43:30 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 104...
[0m[1;37mINFO[0m: [1mCheckpoint 104: 
-----------------------------------
Train ACCURACY: 0.9199
Train Loss: 0.4046
ID Validation ACCURACY: 0.9187
ID Validation Loss: 0.4190
ID Test ACCURACY: 0.9173
ID Test Loss: 0.4155
OOD Validation ACCURACY: 0.8993
OOD Validation Loss: 0.4204
OOD Test ACCURACY: 0.8580
OOD Test Loss: 0.4743

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 137...
[0m[1;37mINFO[0m: [1mCheckpoint 137: 
-----------------------------------
Train ACCURACY: 0.9207
Train Loss: 0.3963
ID Validation ACCURACY: 0.9180
ID Validation Loss: 0.4080
ID Test ACCURACY: 0.9190
ID Test Loss: 0.4092
OOD Validation ACCURACY: 0.9230
OOD Validation Loss: 0.3561
OOD Test ACCURACY: 0.8053
OOD Test Loss: 0.5858

[0m[1;37mINFO[0m: [1mChartInfo 0.9173 0.8580 0.9190 0.8053 0.9180 0.9230[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.714
WIoU for r=0.3 = 0.649
F1 for r=0.6 = 0.611
WIoU for r=0.6 = 0.682
F1 for r=0.9 = 0.476
WIoU for r=0.9 = 0.684
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.684
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.868
WIoU for r=0.3 = 0.876
F1 for r=0.6 = 0.796
WIoU for r=0.6 = 1.000
F1 for r=0.9 = 0.618
WIoU for r=0.9 = 1.000
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 1.000
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.526
WIoU for r=0.3 = 0.402
F1 for r=0.6 = 0.697
WIoU for r=0.6 = 0.590
F1 for r=0.9 = 0.594
WIoU for r=0.9 = 0.612
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.612


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.646
Model XAI F1 of binarized graphs for r=0.3 =  0.713905
Model XAI WIoU of binarized graphs for r=0.3 =  0.6490375
len(reference) = 796
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.473
SUFF++ for r=0.3 class 0 = 0.407 +- 0.265 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.3 class 1 = 0.471 +- 0.265 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.3 class 2 = 0.588 +- 0.265 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.3 all KL = 0.41 +- 0.265 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.3 all L1 = 0.49 +- 0.185 (in-sample avg dev_std = 0.564)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.858
Model XAI F1 of binarized graphs for r=0.6 =  0.61069125
Model XAI WIoU of binarized graphs for r=0.6 =  0.681755
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.67
SUFF++ for r=0.6 class 0 = 0.462 +- 0.275 (in-sample avg dev_std = 0.484)
SUFF++ for r=0.6 class 1 = 0.62 +- 0.275 (in-sample avg dev_std = 0.484)
SUFF++ for r=0.6 class 2 = 0.67 +- 0.275 (in-sample avg dev_std = 0.484)
SUFF++ for r=0.6 all KL = 0.557 +- 0.275 (in-sample avg dev_std = 0.484)
SUFF++ for r=0.6 all L1 = 0.586 +- 0.198 (in-sample avg dev_std = 0.484)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.908
Model XAI F1 of binarized graphs for r=0.9 =  0.4756975
Model XAI WIoU of binarized graphs for r=0.9 =  0.68386125
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.862
SUFF++ for r=0.9 class 0 = 0.787 +- 0.153 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 class 1 = 0.748 +- 0.153 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 class 2 = 0.835 +- 0.153 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 all KL = 0.867 +- 0.153 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 all L1 = 0.791 +- 0.161 (in-sample avg dev_std = 0.235)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.585
Model XAI F1 of binarized graphs for r=0.3 =  0.86823125
Model XAI WIoU of binarized graphs for r=0.3 =  0.8763987499999999
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.512
SUFF++ for r=0.3 class 0 = 0.557 +- 0.302 (in-sample avg dev_std = 0.607)
SUFF++ for r=0.3 class 1 = 0.672 +- 0.302 (in-sample avg dev_std = 0.607)
SUFF++ for r=0.3 class 2 = 0.609 +- 0.302 (in-sample avg dev_std = 0.607)
SUFF++ for r=0.3 all KL = 0.448 +- 0.302 (in-sample avg dev_std = 0.607)
SUFF++ for r=0.3 all L1 = 0.612 +- 0.206 (in-sample avg dev_std = 0.607)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.899
Model XAI F1 of binarized graphs for r=0.6 =  0.79599125
Model XAI WIoU of binarized graphs for r=0.6 =  0.999965
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.9
SUFF++ for r=0.6 class 0 = 0.898 +- 0.177 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.6 class 1 = 0.805 +- 0.177 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.6 class 2 = 0.905 +- 0.177 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.6 all KL = 0.89 +- 0.177 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.6 all L1 = 0.869 +- 0.164 (in-sample avg dev_std = 0.273)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.897
Model XAI F1 of binarized graphs for r=0.9 =  0.61811125
Model XAI WIoU of binarized graphs for r=0.9 =  0.999965
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.914
SUFF++ for r=0.9 class 0 = 0.945 +- 0.081 (in-sample avg dev_std = 0.141)
SUFF++ for r=0.9 class 1 = 0.941 +- 0.081 (in-sample avg dev_std = 0.141)
SUFF++ for r=0.9 class 2 = 0.962 +- 0.081 (in-sample avg dev_std = 0.141)
SUFF++ for r=0.9 all KL = 0.977 +- 0.081 (in-sample avg dev_std = 0.141)
SUFF++ for r=0.9 all L1 = 0.95 +- 0.101 (in-sample avg dev_std = 0.141)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.361
Model XAI F1 of binarized graphs for r=0.3 =  0.52633625
Model XAI WIoU of binarized graphs for r=0.3 =  0.40198875
len(reference) = 790
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.367
SUFF++ for r=0.3 class 0 = 0.462 +- 0.234 (in-sample avg dev_std = 0.589)
SUFF++ for r=0.3 class 1 = 0.54 +- 0.234 (in-sample avg dev_std = 0.589)
SUFF++ for r=0.3 class 2 = 0.567 +- 0.234 (in-sample avg dev_std = 0.589)
SUFF++ for r=0.3 all KL = 0.467 +- 0.234 (in-sample avg dev_std = 0.589)
SUFF++ for r=0.3 all L1 = 0.523 +- 0.143 (in-sample avg dev_std = 0.589)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.69
Model XAI F1 of binarized graphs for r=0.6 =  0.6968725
Model XAI WIoU of binarized graphs for r=0.6 =  0.5898662499999999
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.691
SUFF++ for r=0.6 class 0 = 0.507 +- 0.281 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.6 class 1 = 0.706 +- 0.281 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.6 class 2 = 0.751 +- 0.281 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.6 all KL = 0.614 +- 0.281 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.6 all L1 = 0.654 +- 0.237 (in-sample avg dev_std = 0.471)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.875
Model XAI F1 of binarized graphs for r=0.9 =  0.59401375
Model XAI WIoU of binarized graphs for r=0.9 =  0.61249625
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.804
SUFF++ for r=0.9 class 0 = 0.715 +- 0.181 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.9 class 1 = 0.924 +- 0.181 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.9 class 2 = 0.841 +- 0.181 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.9 all KL = 0.868 +- 0.181 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.9 all L1 = 0.825 +- 0.195 (in-sample avg dev_std = 0.264)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.647
Model XAI F1 of binarized graphs for r=0.3 =  0.713905
Model XAI WIoU of binarized graphs for r=0.3 =  0.6490375
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.379
NEC for r=0.3 class 0 = 0.641 +- 0.235 (in-sample avg dev_std = 0.494)
NEC for r=0.3 class 1 = 0.58 +- 0.235 (in-sample avg dev_std = 0.494)
NEC for r=0.3 class 2 = 0.596 +- 0.235 (in-sample avg dev_std = 0.494)
NEC for r=0.3 all KL = 0.722 +- 0.235 (in-sample avg dev_std = 0.494)
NEC for r=0.3 all L1 = 0.605 +- 0.139 (in-sample avg dev_std = 0.494)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.863
Model XAI F1 of binarized graphs for r=0.6 =  0.61069125
Model XAI WIoU of binarized graphs for r=0.6 =  0.681755
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.445
NEC for r=0.6 class 0 = 0.602 +- 0.284 (in-sample avg dev_std = 0.474)
NEC for r=0.6 class 1 = 0.575 +- 0.284 (in-sample avg dev_std = 0.474)
NEC for r=0.6 class 2 = 0.574 +- 0.284 (in-sample avg dev_std = 0.474)
NEC for r=0.6 all KL = 0.634 +- 0.284 (in-sample avg dev_std = 0.474)
NEC for r=0.6 all L1 = 0.583 +- 0.160 (in-sample avg dev_std = 0.474)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.908
Model XAI F1 of binarized graphs for r=0.9 =  0.4756975
Model XAI WIoU of binarized graphs for r=0.9 =  0.68386125
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.528
NEC for r=0.9 class 0 = 0.503 +- 0.280 (in-sample avg dev_std = 0.514)
NEC for r=0.9 class 1 = 0.543 +- 0.280 (in-sample avg dev_std = 0.514)
NEC for r=0.9 class 2 = 0.544 +- 0.280 (in-sample avg dev_std = 0.514)
NEC for r=0.9 all KL = 0.542 +- 0.280 (in-sample avg dev_std = 0.514)
NEC for r=0.9 all L1 = 0.53 +- 0.159 (in-sample avg dev_std = 0.514)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.918
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.68368
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.544
NEC for r=1.0 class 0 = 0.478 +- 0.285 (in-sample avg dev_std = 0.507)
NEC for r=1.0 class 1 = 0.53 +- 0.285 (in-sample avg dev_std = 0.507)
NEC for r=1.0 class 2 = 0.52 +- 0.285 (in-sample avg dev_std = 0.507)
NEC for r=1.0 all KL = 0.512 +- 0.285 (in-sample avg dev_std = 0.507)
NEC for r=1.0 all L1 = 0.51 +- 0.166 (in-sample avg dev_std = 0.507)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.585
Model XAI F1 of binarized graphs for r=0.3 =  0.86823125
Model XAI WIoU of binarized graphs for r=0.3 =  0.8763987499999999
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.215
NEC for r=0.3 class 0 = 0.699 +- 0.179 (in-sample avg dev_std = 0.431)
NEC for r=0.3 class 1 = 0.707 +- 0.179 (in-sample avg dev_std = 0.431)
NEC for r=0.3 class 2 = 0.631 +- 0.179 (in-sample avg dev_std = 0.431)
NEC for r=0.3 all KL = 0.858 +- 0.179 (in-sample avg dev_std = 0.431)
NEC for r=0.3 all L1 = 0.679 +- 0.130 (in-sample avg dev_std = 0.431)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.899
Model XAI F1 of binarized graphs for r=0.6 =  0.79599125
Model XAI WIoU of binarized graphs for r=0.6 =  0.999965
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.501
NEC for r=0.6 class 0 = 0.558 +- 0.290 (in-sample avg dev_std = 0.610)
NEC for r=0.6 class 1 = 0.479 +- 0.290 (in-sample avg dev_std = 0.610)
NEC for r=0.6 class 2 = 0.514 +- 0.290 (in-sample avg dev_std = 0.610)
NEC for r=0.6 all KL = 0.625 +- 0.290 (in-sample avg dev_std = 0.610)
NEC for r=0.6 all L1 = 0.517 +- 0.170 (in-sample avg dev_std = 0.610)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.897
Model XAI F1 of binarized graphs for r=0.9 =  0.61811125
Model XAI WIoU of binarized graphs for r=0.9 =  0.999965
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.619
NEC for r=0.9 class 0 = 0.404 +- 0.237 (in-sample avg dev_std = 0.558)
NEC for r=0.9 class 1 = 0.342 +- 0.237 (in-sample avg dev_std = 0.558)
NEC for r=0.9 class 2 = 0.406 +- 0.237 (in-sample avg dev_std = 0.558)
NEC for r=0.9 all KL = 0.388 +- 0.237 (in-sample avg dev_std = 0.558)
NEC for r=0.9 all L1 = 0.384 +- 0.157 (in-sample avg dev_std = 0.558)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.897
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  0.999965
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.625
NEC for r=1.0 class 0 = 0.396 +- 0.224 (in-sample avg dev_std = 0.552)
NEC for r=1.0 class 1 = 0.337 +- 0.224 (in-sample avg dev_std = 0.552)
NEC for r=1.0 class 2 = 0.399 +- 0.224 (in-sample avg dev_std = 0.552)
NEC for r=1.0 all KL = 0.375 +- 0.224 (in-sample avg dev_std = 0.552)
NEC for r=1.0 all L1 = 0.378 +- 0.150 (in-sample avg dev_std = 0.552)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.36
Model XAI F1 of binarized graphs for r=0.3 =  0.52633625
Model XAI WIoU of binarized graphs for r=0.3 =  0.40198875
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.363
NEC for r=0.3 class 0 = 0.597 +- 0.288 (in-sample avg dev_std = 0.516)
NEC for r=0.3 class 1 = 0.486 +- 0.288 (in-sample avg dev_std = 0.516)
NEC for r=0.3 class 2 = 0.432 +- 0.288 (in-sample avg dev_std = 0.516)
NEC for r=0.3 all KL = 0.557 +- 0.288 (in-sample avg dev_std = 0.516)
NEC for r=0.3 all L1 = 0.505 +- 0.201 (in-sample avg dev_std = 0.516)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.691
Model XAI F1 of binarized graphs for r=0.6 =  0.6968725
Model XAI WIoU of binarized graphs for r=0.6 =  0.5898662499999999
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.483
NEC for r=0.6 class 0 = 0.657 +- 0.257 (in-sample avg dev_std = 0.596)
NEC for r=0.6 class 1 = 0.544 +- 0.257 (in-sample avg dev_std = 0.596)
NEC for r=0.6 class 2 = 0.559 +- 0.257 (in-sample avg dev_std = 0.596)
NEC for r=0.6 all KL = 0.707 +- 0.257 (in-sample avg dev_std = 0.596)
NEC for r=0.6 all L1 = 0.587 +- 0.160 (in-sample avg dev_std = 0.596)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.875
Model XAI F1 of binarized graphs for r=0.9 =  0.59401375
Model XAI WIoU of binarized graphs for r=0.9 =  0.61249625
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.627
NEC for r=0.9 class 0 = 0.496 +- 0.237 (in-sample avg dev_std = 0.612)
NEC for r=0.9 class 1 = 0.413 +- 0.237 (in-sample avg dev_std = 0.612)
NEC for r=0.9 class 2 = 0.495 +- 0.237 (in-sample avg dev_std = 0.612)
NEC for r=0.9 all KL = 0.557 +- 0.237 (in-sample avg dev_std = 0.612)
NEC for r=0.9 all L1 = 0.469 +- 0.152 (in-sample avg dev_std = 0.612)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.885
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.61246
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.657
NEC for r=1.0 class 0 = 0.47 +- 0.229 (in-sample avg dev_std = 0.595)
NEC for r=1.0 class 1 = 0.395 +- 0.229 (in-sample avg dev_std = 0.595)
NEC for r=1.0 class 2 = 0.45 +- 0.229 (in-sample avg dev_std = 0.595)
NEC for r=1.0 all KL = 0.504 +- 0.229 (in-sample avg dev_std = 0.595)
NEC for r=1.0 all L1 = 0.439 +- 0.142 (in-sample avg dev_std = 0.595)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Apr  6 20:47:33 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:33 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:48 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:50 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:53 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:55 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:47:57 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 154...
[0m[1;37mINFO[0m: [1mCheckpoint 154: 
-----------------------------------
Train ACCURACY: 0.9093
Train Loss: 0.4153
ID Validation ACCURACY: 0.9077
ID Validation Loss: 0.4259
ID Test ACCURACY: 0.9133
ID Test Loss: 0.4117
OOD Validation ACCURACY: 0.8497
OOD Validation Loss: 0.4942
OOD Test ACCURACY: 0.7820
OOD Test Loss: 0.6459

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 120...
[0m[1;37mINFO[0m: [1mCheckpoint 120: 
-----------------------------------
Train ACCURACY: 0.8288
Train Loss: 0.5416
ID Validation ACCURACY: 0.8220
ID Validation Loss: 0.5634
ID Test ACCURACY: 0.8233
ID Test Loss: 0.5510
OOD Validation ACCURACY: 0.8977
OOD Validation Loss: 0.4180
OOD Test ACCURACY: 0.7627
OOD Test Loss: 0.6773

[0m[1;37mINFO[0m: [1mChartInfo 0.9133 0.7820 0.8233 0.7627 0.8220 0.8977[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.697
WIoU for r=0.3 = 0.662
F1 for r=0.6 = 0.611
WIoU for r=0.6 = 0.771
F1 for r=0.9 = 0.476
WIoU for r=0.9 = 0.777
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.777
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.817
WIoU for r=0.3 = 0.860
F1 for r=0.6 = 0.699
WIoU for r=0.6 = 0.968
F1 for r=0.9 = 0.548
WIoU for r=0.9 = 0.926
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 0.920
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.450
WIoU for r=0.3 = 0.341
F1 for r=0.6 = 0.674
WIoU for r=0.6 = 0.550
F1 for r=0.9 = 0.594
WIoU for r=0.9 = 0.585
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.585


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.696
Model XAI F1 of binarized graphs for r=0.3 =  0.6971525
Model XAI WIoU of binarized graphs for r=0.3 =  0.6623300000000001
len(reference) = 796
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.492
SUFF++ for r=0.3 class 0 = 0.411 +- 0.252 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.3 class 1 = 0.493 +- 0.252 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.3 class 2 = 0.482 +- 0.252 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.3 all KL = 0.368 +- 0.252 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.3 all L1 = 0.463 +- 0.153 (in-sample avg dev_std = 0.618)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.858
Model XAI F1 of binarized graphs for r=0.6 =  0.61103125
Model XAI WIoU of binarized graphs for r=0.6 =  0.7706325
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.709
SUFF++ for r=0.6 class 0 = 0.533 +- 0.269 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.6 class 1 = 0.68 +- 0.269 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.6 class 2 = 0.664 +- 0.269 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.6 all KL = 0.599 +- 0.269 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.6 all L1 = 0.628 +- 0.190 (in-sample avg dev_std = 0.466)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.902
Model XAI F1 of binarized graphs for r=0.9 =  0.4756975
Model XAI WIoU of binarized graphs for r=0.9 =  0.77726125
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.873
SUFF++ for r=0.9 class 0 = 0.781 +- 0.136 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 class 1 = 0.832 +- 0.136 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 class 2 = 0.877 +- 0.136 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 all KL = 0.891 +- 0.136 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 all L1 = 0.831 +- 0.137 (in-sample avg dev_std = 0.245)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.59
Model XAI F1 of binarized graphs for r=0.3 =  0.81698375
Model XAI WIoU of binarized graphs for r=0.3 =  0.8603649999999999
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.513
SUFF++ for r=0.3 class 0 = 0.582 +- 0.317 (in-sample avg dev_std = 0.633)
SUFF++ for r=0.3 class 1 = 0.729 +- 0.317 (in-sample avg dev_std = 0.633)
SUFF++ for r=0.3 class 2 = 0.562 +- 0.317 (in-sample avg dev_std = 0.633)
SUFF++ for r=0.3 all KL = 0.46 +- 0.317 (in-sample avg dev_std = 0.633)
SUFF++ for r=0.3 all L1 = 0.624 +- 0.224 (in-sample avg dev_std = 0.633)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  0.69870125
Model XAI WIoU of binarized graphs for r=0.6 =  0.96752375
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.826
SUFF++ for r=0.6 class 0 = 0.772 +- 0.226 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.6 class 1 = 0.738 +- 0.226 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.6 class 2 = 0.883 +- 0.226 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.6 all KL = 0.797 +- 0.226 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.6 all L1 = 0.798 +- 0.191 (in-sample avg dev_std = 0.412)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.873
Model XAI F1 of binarized graphs for r=0.9 =  0.54811375
Model XAI WIoU of binarized graphs for r=0.9 =  0.9260474999999999
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.857
SUFF++ for r=0.9 class 0 = 0.815 +- 0.140 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 1 = 0.806 +- 0.140 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 2 = 0.924 +- 0.140 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 all KL = 0.913 +- 0.140 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 all L1 = 0.849 +- 0.165 (in-sample avg dev_std = 0.265)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.327
Model XAI F1 of binarized graphs for r=0.3 =  0.44971999999999995
Model XAI WIoU of binarized graphs for r=0.3 =  0.34082250000000003
len(reference) = 785
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.341
SUFF++ for r=0.3 class 0 = 0.419 +- 0.211 (in-sample avg dev_std = 0.627)
SUFF++ for r=0.3 class 1 = 0.436 +- 0.211 (in-sample avg dev_std = 0.627)
SUFF++ for r=0.3 class 2 = 0.418 +- 0.211 (in-sample avg dev_std = 0.627)
SUFF++ for r=0.3 all KL = 0.376 +- 0.211 (in-sample avg dev_std = 0.627)
SUFF++ for r=0.3 all L1 = 0.424 +- 0.112 (in-sample avg dev_std = 0.627)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.558
Model XAI F1 of binarized graphs for r=0.6 =  0.6737949999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.54979625
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.628
SUFF++ for r=0.6 class 0 = 0.573 +- 0.294 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 class 1 = 0.842 +- 0.294 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 class 2 = 0.537 +- 0.294 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 all KL = 0.627 +- 0.294 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 all L1 = 0.647 +- 0.243 (in-sample avg dev_std = 0.456)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.791
Model XAI F1 of binarized graphs for r=0.9 =  0.5939675
Model XAI WIoU of binarized graphs for r=0.9 =  0.58484875
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.694
SUFF++ for r=0.9 class 0 = 0.683 +- 0.212 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.9 class 1 = 0.948 +- 0.212 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.9 class 2 = 0.7 +- 0.212 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.9 all KL = 0.831 +- 0.212 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.9 all L1 = 0.774 +- 0.201 (in-sample avg dev_std = 0.351)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.695
Model XAI F1 of binarized graphs for r=0.3 =  0.6971525
Model XAI WIoU of binarized graphs for r=0.3 =  0.6623300000000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.372
NEC for r=0.3 class 0 = 0.639 +- 0.240 (in-sample avg dev_std = 0.478)
NEC for r=0.3 class 1 = 0.636 +- 0.240 (in-sample avg dev_std = 0.478)
NEC for r=0.3 class 2 = 0.634 +- 0.240 (in-sample avg dev_std = 0.478)
NEC for r=0.3 all KL = 0.711 +- 0.240 (in-sample avg dev_std = 0.478)
NEC for r=0.3 all L1 = 0.636 +- 0.133 (in-sample avg dev_std = 0.478)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.853
Model XAI F1 of binarized graphs for r=0.6 =  0.61103125
Model XAI WIoU of binarized graphs for r=0.6 =  0.7706325
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.46
NEC for r=0.6 class 0 = 0.569 +- 0.293 (in-sample avg dev_std = 0.481)
NEC for r=0.6 class 1 = 0.583 +- 0.293 (in-sample avg dev_std = 0.481)
NEC for r=0.6 class 2 = 0.59 +- 0.293 (in-sample avg dev_std = 0.481)
NEC for r=0.6 all KL = 0.624 +- 0.293 (in-sample avg dev_std = 0.481)
NEC for r=0.6 all L1 = 0.581 +- 0.154 (in-sample avg dev_std = 0.481)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.902
Model XAI F1 of binarized graphs for r=0.9 =  0.4756975
Model XAI WIoU of binarized graphs for r=0.9 =  0.77726125
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.552
NEC for r=0.9 class 0 = 0.511 +- 0.290 (in-sample avg dev_std = 0.531)
NEC for r=0.9 class 1 = 0.527 +- 0.290 (in-sample avg dev_std = 0.531)
NEC for r=0.9 class 2 = 0.515 +- 0.290 (in-sample avg dev_std = 0.531)
NEC for r=0.9 all KL = 0.533 +- 0.290 (in-sample avg dev_std = 0.531)
NEC for r=0.9 all L1 = 0.518 +- 0.156 (in-sample avg dev_std = 0.531)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.908
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.77724125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.568
NEC for r=1.0 class 0 = 0.488 +- 0.293 (in-sample avg dev_std = 0.523)
NEC for r=1.0 class 1 = 0.522 +- 0.293 (in-sample avg dev_std = 0.523)
NEC for r=1.0 class 2 = 0.484 +- 0.293 (in-sample avg dev_std = 0.523)
NEC for r=1.0 all KL = 0.506 +- 0.293 (in-sample avg dev_std = 0.523)
NEC for r=1.0 all L1 = 0.498 +- 0.162 (in-sample avg dev_std = 0.523)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.59
Model XAI F1 of binarized graphs for r=0.3 =  0.81698375
Model XAI WIoU of binarized graphs for r=0.3 =  0.8603649999999999
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.361
NEC for r=0.3 class 0 = 0.661 +- 0.223 (in-sample avg dev_std = 0.537)
NEC for r=0.3 class 1 = 0.71 +- 0.223 (in-sample avg dev_std = 0.537)
NEC for r=0.3 class 2 = 0.576 +- 0.223 (in-sample avg dev_std = 0.537)
NEC for r=0.3 all KL = 0.818 +- 0.223 (in-sample avg dev_std = 0.537)
NEC for r=0.3 all L1 = 0.649 +- 0.157 (in-sample avg dev_std = 0.537)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  0.69870125
Model XAI WIoU of binarized graphs for r=0.6 =  0.96752375
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.601
NEC for r=0.6 class 0 = 0.534 +- 0.289 (in-sample avg dev_std = 0.593)
NEC for r=0.6 class 1 = 0.497 +- 0.289 (in-sample avg dev_std = 0.593)
NEC for r=0.6 class 2 = 0.349 +- 0.289 (in-sample avg dev_std = 0.593)
NEC for r=0.6 all KL = 0.529 +- 0.289 (in-sample avg dev_std = 0.593)
NEC for r=0.6 all L1 = 0.46 +- 0.206 (in-sample avg dev_std = 0.593)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.873
Model XAI F1 of binarized graphs for r=0.9 =  0.54811375
Model XAI WIoU of binarized graphs for r=0.9 =  0.9260474999999999
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.639
NEC for r=0.9 class 0 = 0.457 +- 0.232 (in-sample avg dev_std = 0.515)
NEC for r=0.9 class 1 = 0.404 +- 0.232 (in-sample avg dev_std = 0.515)
NEC for r=0.9 class 2 = 0.286 +- 0.232 (in-sample avg dev_std = 0.515)
NEC for r=0.9 all KL = 0.365 +- 0.232 (in-sample avg dev_std = 0.515)
NEC for r=0.9 all L1 = 0.383 +- 0.181 (in-sample avg dev_std = 0.515)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.851
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  0.9202787499999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.633
NEC for r=1.0 class 0 = 0.422 +- 0.220 (in-sample avg dev_std = 0.487)
NEC for r=1.0 class 1 = 0.404 +- 0.220 (in-sample avg dev_std = 0.487)
NEC for r=1.0 class 2 = 0.271 +- 0.220 (in-sample avg dev_std = 0.487)
NEC for r=1.0 all KL = 0.336 +- 0.220 (in-sample avg dev_std = 0.487)
NEC for r=1.0 all L1 = 0.366 +- 0.177 (in-sample avg dev_std = 0.487)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.33
Model XAI F1 of binarized graphs for r=0.3 =  0.44971999999999995
Model XAI WIoU of binarized graphs for r=0.3 =  0.34082250000000003
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.413
NEC for r=0.3 class 0 = 0.595 +- 0.265 (in-sample avg dev_std = 0.503)
NEC for r=0.3 class 1 = 0.627 +- 0.265 (in-sample avg dev_std = 0.503)
NEC for r=0.3 class 2 = 0.604 +- 0.265 (in-sample avg dev_std = 0.503)
NEC for r=0.3 all KL = 0.641 +- 0.265 (in-sample avg dev_std = 0.503)
NEC for r=0.3 all L1 = 0.608 +- 0.171 (in-sample avg dev_std = 0.503)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.561
Model XAI F1 of binarized graphs for r=0.6 =  0.6737949999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.54979625
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.527
NEC for r=0.6 class 0 = 0.554 +- 0.266 (in-sample avg dev_std = 0.584)
NEC for r=0.6 class 1 = 0.395 +- 0.266 (in-sample avg dev_std = 0.584)
NEC for r=0.6 class 2 = 0.625 +- 0.266 (in-sample avg dev_std = 0.584)
NEC for r=0.6 all KL = 0.617 +- 0.266 (in-sample avg dev_std = 0.584)
NEC for r=0.6 all L1 = 0.527 +- 0.197 (in-sample avg dev_std = 0.584)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.791
Model XAI F1 of binarized graphs for r=0.9 =  0.5939675
Model XAI WIoU of binarized graphs for r=0.9 =  0.58484875
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.62
NEC for r=0.9 class 0 = 0.494 +- 0.215 (in-sample avg dev_std = 0.512)
NEC for r=0.9 class 1 = 0.37 +- 0.215 (in-sample avg dev_std = 0.512)
NEC for r=0.9 class 2 = 0.501 +- 0.215 (in-sample avg dev_std = 0.512)
NEC for r=0.9 all KL = 0.46 +- 0.215 (in-sample avg dev_std = 0.512)
NEC for r=0.9 all L1 = 0.456 +- 0.148 (in-sample avg dev_std = 0.512)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.811
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.5848425
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.629
NEC for r=1.0 class 0 = 0.47 +- 0.211 (in-sample avg dev_std = 0.509)
NEC for r=1.0 class 1 = 0.361 +- 0.211 (in-sample avg dev_std = 0.509)
NEC for r=1.0 class 2 = 0.49 +- 0.211 (in-sample avg dev_std = 0.509)
NEC for r=1.0 all KL = 0.426 +- 0.211 (in-sample avg dev_std = 0.509)
NEC for r=1.0 all L1 = 0.442 +- 0.142 (in-sample avg dev_std = 0.509)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Apr  6 20:52:04 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:04 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:19 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:21 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:23 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:25 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:52:28 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 182...
[0m[1;37mINFO[0m: [1mCheckpoint 182: 
-----------------------------------
Train ACCURACY: 0.9147
Train Loss: 0.4029
ID Validation ACCURACY: 0.9103
ID Validation Loss: 0.4205
ID Test ACCURACY: 0.9083
ID Test Loss: 0.4147
OOD Validation ACCURACY: 0.8440
OOD Validation Loss: 0.4769
OOD Test ACCURACY: 0.8217
OOD Test Loss: 0.6118

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 133...
[0m[1;37mINFO[0m: [1mCheckpoint 133: 
-----------------------------------
Train ACCURACY: 0.8890
Train Loss: 0.4742
ID Validation ACCURACY: 0.8847
ID Validation Loss: 0.4966
ID Test ACCURACY: 0.8883
ID Test Loss: 0.4729
OOD Validation ACCURACY: 0.9260
OOD Validation Loss: 0.3740
OOD Test ACCURACY: 0.6043
OOD Test Loss: 1.1293

[0m[1;37mINFO[0m: [1mChartInfo 0.9083 0.8217 0.8883 0.6043 0.8847 0.9260[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.705
WIoU for r=0.3 = 0.677
F1 for r=0.6 = 0.613
WIoU for r=0.6 = 0.788
F1 for r=0.9 = 0.475
WIoU for r=0.9 = 0.792
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.792
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.816
WIoU for r=0.3 = 0.874
F1 for r=0.6 = 0.667
WIoU for r=0.6 = 0.907
F1 for r=0.9 = 0.528
WIoU for r=0.9 = 0.894
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 0.893
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.452
WIoU for r=0.3 = 0.348
F1 for r=0.6 = 0.631
WIoU for r=0.6 = 0.524
F1 for r=0.9 = 0.593
WIoU for r=0.9 = 0.550
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.550


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.706
Model XAI F1 of binarized graphs for r=0.3 =  0.70495875
Model XAI WIoU of binarized graphs for r=0.3 =  0.6765549999999999
len(reference) = 789
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.494
SUFF++ for r=0.3 class 0 = 0.443 +- 0.252 (in-sample avg dev_std = 0.620)
SUFF++ for r=0.3 class 1 = 0.5 +- 0.252 (in-sample avg dev_std = 0.620)
SUFF++ for r=0.3 class 2 = 0.5 +- 0.252 (in-sample avg dev_std = 0.620)
SUFF++ for r=0.3 all KL = 0.376 +- 0.252 (in-sample avg dev_std = 0.620)
SUFF++ for r=0.3 all L1 = 0.482 +- 0.172 (in-sample avg dev_std = 0.620)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.879
Model XAI F1 of binarized graphs for r=0.6 =  0.6127625000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.78761375
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.73
SUFF++ for r=0.6 class 0 = 0.56 +- 0.291 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.6 class 1 = 0.651 +- 0.291 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.6 class 2 = 0.673 +- 0.291 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.6 all KL = 0.574 +- 0.291 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.6 all L1 = 0.63 +- 0.198 (in-sample avg dev_std = 0.489)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.901
Model XAI F1 of binarized graphs for r=0.9 =  0.47548
Model XAI WIoU of binarized graphs for r=0.9 =  0.79237125
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.864
SUFF++ for r=0.9 class 0 = 0.791 +- 0.189 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 class 1 = 0.794 +- 0.189 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 class 2 = 0.876 +- 0.189 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 all KL = 0.87 +- 0.189 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 all L1 = 0.821 +- 0.170 (in-sample avg dev_std = 0.252)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.637
Model XAI F1 of binarized graphs for r=0.3 =  0.8162462500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.87421625
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.551
SUFF++ for r=0.3 class 0 = 0.596 +- 0.337 (in-sample avg dev_std = 0.619)
SUFF++ for r=0.3 class 1 = 0.776 +- 0.337 (in-sample avg dev_std = 0.619)
SUFF++ for r=0.3 class 2 = 0.612 +- 0.337 (in-sample avg dev_std = 0.619)
SUFF++ for r=0.3 all KL = 0.479 +- 0.337 (in-sample avg dev_std = 0.619)
SUFF++ for r=0.3 all L1 = 0.661 +- 0.223 (in-sample avg dev_std = 0.619)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.875
Model XAI F1 of binarized graphs for r=0.6 =  0.66733375
Model XAI WIoU of binarized graphs for r=0.6 =  0.906575
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.82
SUFF++ for r=0.6 class 0 = 0.748 +- 0.234 (in-sample avg dev_std = 0.436)
SUFF++ for r=0.6 class 1 = 0.827 +- 0.234 (in-sample avg dev_std = 0.436)
SUFF++ for r=0.6 class 2 = 0.872 +- 0.234 (in-sample avg dev_std = 0.436)
SUFF++ for r=0.6 all KL = 0.783 +- 0.234 (in-sample avg dev_std = 0.436)
SUFF++ for r=0.6 all L1 = 0.816 +- 0.158 (in-sample avg dev_std = 0.436)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.871
Model XAI F1 of binarized graphs for r=0.9 =  0.5282399999999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.89367125
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.792
SUFF++ for r=0.9 class 0 = 0.742 +- 0.186 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.9 class 1 = 0.731 +- 0.186 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.9 class 2 = 0.918 +- 0.186 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.9 all KL = 0.848 +- 0.186 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.9 all L1 = 0.797 +- 0.196 (in-sample avg dev_std = 0.313)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.406
Model XAI F1 of binarized graphs for r=0.3 =  0.4519675
Model XAI WIoU of binarized graphs for r=0.3 =  0.34785875
len(reference) = 791
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.367
SUFF++ for r=0.3 class 0 = 0.413 +- 0.202 (in-sample avg dev_std = 0.603)
SUFF++ for r=0.3 class 1 = 0.42 +- 0.202 (in-sample avg dev_std = 0.603)
SUFF++ for r=0.3 class 2 = 0.402 +- 0.202 (in-sample avg dev_std = 0.603)
SUFF++ for r=0.3 all KL = 0.377 +- 0.202 (in-sample avg dev_std = 0.603)
SUFF++ for r=0.3 all L1 = 0.411 +- 0.110 (in-sample avg dev_std = 0.603)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.705
Model XAI F1 of binarized graphs for r=0.6 =  0.63138125
Model XAI WIoU of binarized graphs for r=0.6 =  0.5244925
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.637
SUFF++ for r=0.6 class 0 = 0.453 +- 0.284 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.6 class 1 = 0.715 +- 0.284 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.6 class 2 = 0.578 +- 0.284 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.6 all KL = 0.526 +- 0.284 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.6 all L1 = 0.579 +- 0.233 (in-sample avg dev_std = 0.516)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.841
Model XAI F1 of binarized graphs for r=0.9 =  0.5934699999999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.5497
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.77
SUFF++ for r=0.9 class 0 = 0.685 +- 0.194 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.9 class 1 = 0.861 +- 0.194 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.9 class 2 = 0.795 +- 0.194 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.9 all KL = 0.829 +- 0.194 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.9 all L1 = 0.779 +- 0.205 (in-sample avg dev_std = 0.323)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.705
Model XAI F1 of binarized graphs for r=0.3 =  0.70495875
Model XAI WIoU of binarized graphs for r=0.3 =  0.6765549999999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.379
NEC for r=0.3 class 0 = 0.656 +- 0.247 (in-sample avg dev_std = 0.487)
NEC for r=0.3 class 1 = 0.597 +- 0.247 (in-sample avg dev_std = 0.487)
NEC for r=0.3 class 2 = 0.647 +- 0.247 (in-sample avg dev_std = 0.487)
NEC for r=0.3 all KL = 0.723 +- 0.247 (in-sample avg dev_std = 0.487)
NEC for r=0.3 all L1 = 0.633 +- 0.140 (in-sample avg dev_std = 0.487)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.879
Model XAI F1 of binarized graphs for r=0.6 =  0.6127625000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.78761375
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.467
NEC for r=0.6 class 0 = 0.595 +- 0.284 (in-sample avg dev_std = 0.505)
NEC for r=0.6 class 1 = 0.574 +- 0.284 (in-sample avg dev_std = 0.505)
NEC for r=0.6 class 2 = 0.574 +- 0.284 (in-sample avg dev_std = 0.505)
NEC for r=0.6 all KL = 0.651 +- 0.284 (in-sample avg dev_std = 0.505)
NEC for r=0.6 all L1 = 0.581 +- 0.154 (in-sample avg dev_std = 0.505)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.901
Model XAI F1 of binarized graphs for r=0.9 =  0.47548
Model XAI WIoU of binarized graphs for r=0.9 =  0.79237125
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.564
NEC for r=0.9 class 0 = 0.509 +- 0.288 (in-sample avg dev_std = 0.554)
NEC for r=0.9 class 1 = 0.514 +- 0.288 (in-sample avg dev_std = 0.554)
NEC for r=0.9 class 2 = 0.498 +- 0.288 (in-sample avg dev_std = 0.554)
NEC for r=0.9 all KL = 0.544 +- 0.288 (in-sample avg dev_std = 0.554)
NEC for r=0.9 all L1 = 0.507 +- 0.159 (in-sample avg dev_std = 0.554)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.91
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.7923512500000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.562
NEC for r=1.0 class 0 = 0.505 +- 0.290 (in-sample avg dev_std = 0.535)
NEC for r=1.0 class 1 = 0.52 +- 0.290 (in-sample avg dev_std = 0.535)
NEC for r=1.0 class 2 = 0.494 +- 0.290 (in-sample avg dev_std = 0.535)
NEC for r=1.0 all KL = 0.535 +- 0.290 (in-sample avg dev_std = 0.535)
NEC for r=1.0 all L1 = 0.506 +- 0.163 (in-sample avg dev_std = 0.535)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.637
Model XAI F1 of binarized graphs for r=0.3 =  0.8162462500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.87421625
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.185
NEC for r=0.3 class 0 = 0.626 +- 0.243 (in-sample avg dev_std = 0.473)
NEC for r=0.3 class 1 = 0.732 +- 0.243 (in-sample avg dev_std = 0.473)
NEC for r=0.3 class 2 = 0.627 +- 0.243 (in-sample avg dev_std = 0.473)
NEC for r=0.3 all KL = 0.838 +- 0.243 (in-sample avg dev_std = 0.473)
NEC for r=0.3 all L1 = 0.661 +- 0.187 (in-sample avg dev_std = 0.473)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.875
Model XAI F1 of binarized graphs for r=0.6 =  0.66733375
Model XAI WIoU of binarized graphs for r=0.6 =  0.906575
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.535
NEC for r=0.6 class 0 = 0.546 +- 0.268 (in-sample avg dev_std = 0.659)
NEC for r=0.6 class 1 = 0.501 +- 0.268 (in-sample avg dev_std = 0.659)
NEC for r=0.6 class 2 = 0.403 +- 0.268 (in-sample avg dev_std = 0.659)
NEC for r=0.6 all KL = 0.604 +- 0.268 (in-sample avg dev_std = 0.659)
NEC for r=0.6 all L1 = 0.483 +- 0.173 (in-sample avg dev_std = 0.659)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.871
Model XAI F1 of binarized graphs for r=0.9 =  0.5282399999999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.89367125
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.614
NEC for r=0.9 class 0 = 0.445 +- 0.225 (in-sample avg dev_std = 0.578)
NEC for r=0.9 class 1 = 0.42 +- 0.225 (in-sample avg dev_std = 0.578)
NEC for r=0.9 class 2 = 0.308 +- 0.225 (in-sample avg dev_std = 0.578)
NEC for r=0.9 all KL = 0.413 +- 0.225 (in-sample avg dev_std = 0.578)
NEC for r=0.9 all L1 = 0.391 +- 0.162 (in-sample avg dev_std = 0.578)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.848
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  0.8925075000000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.578
NEC for r=1.0 class 0 = 0.444 +- 0.228 (in-sample avg dev_std = 0.553)
NEC for r=1.0 class 1 = 0.429 +- 0.228 (in-sample avg dev_std = 0.553)
NEC for r=1.0 class 2 = 0.317 +- 0.228 (in-sample avg dev_std = 0.553)
NEC for r=1.0 all KL = 0.408 +- 0.228 (in-sample avg dev_std = 0.553)
NEC for r=1.0 all L1 = 0.397 +- 0.166 (in-sample avg dev_std = 0.553)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.403
Model XAI F1 of binarized graphs for r=0.3 =  0.4519675
Model XAI WIoU of binarized graphs for r=0.3 =  0.34785875
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.418
NEC for r=0.3 class 0 = 0.594 +- 0.254 (in-sample avg dev_std = 0.523)
NEC for r=0.3 class 1 = 0.619 +- 0.254 (in-sample avg dev_std = 0.523)
NEC for r=0.3 class 2 = 0.555 +- 0.254 (in-sample avg dev_std = 0.523)
NEC for r=0.3 all KL = 0.617 +- 0.254 (in-sample avg dev_std = 0.523)
NEC for r=0.3 all L1 = 0.589 +- 0.171 (in-sample avg dev_std = 0.523)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.705
Model XAI F1 of binarized graphs for r=0.6 =  0.63138125
Model XAI WIoU of binarized graphs for r=0.6 =  0.5244925
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.562
NEC for r=0.6 class 0 = 0.558 +- 0.263 (in-sample avg dev_std = 0.598)
NEC for r=0.6 class 1 = 0.444 +- 0.263 (in-sample avg dev_std = 0.598)
NEC for r=0.6 class 2 = 0.619 +- 0.263 (in-sample avg dev_std = 0.598)
NEC for r=0.6 all KL = 0.64 +- 0.263 (in-sample avg dev_std = 0.598)
NEC for r=0.6 all L1 = 0.542 +- 0.171 (in-sample avg dev_std = 0.598)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.841
Model XAI F1 of binarized graphs for r=0.9 =  0.5934699999999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.5497
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.61
NEC for r=0.9 class 0 = 0.483 +- 0.237 (in-sample avg dev_std = 0.577)
NEC for r=0.9 class 1 = 0.402 +- 0.237 (in-sample avg dev_std = 0.577)
NEC for r=0.9 class 2 = 0.505 +- 0.237 (in-sample avg dev_std = 0.577)
NEC for r=0.9 all KL = 0.532 +- 0.237 (in-sample avg dev_std = 0.577)
NEC for r=0.9 all L1 = 0.464 +- 0.148 (in-sample avg dev_std = 0.577)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.835
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.5497025000000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.632
NEC for r=1.0 class 0 = 0.451 +- 0.221 (in-sample avg dev_std = 0.565)
NEC for r=1.0 class 1 = 0.389 +- 0.221 (in-sample avg dev_std = 0.565)
NEC for r=1.0 class 2 = 0.468 +- 0.221 (in-sample avg dev_std = 0.565)
NEC for r=1.0 all KL = 0.482 +- 0.221 (in-sample avg dev_std = 0.565)
NEC for r=1.0 all L1 = 0.437 +- 0.141 (in-sample avg dev_std = 0.565)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Apr  6 20:56:35 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/06/2024 08:56:35 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/06/2024 08:56:50 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/06/2024 08:56:53 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/06/2024 08:56:55 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/06/2024 08:56:58 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 08:57:00 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 166...
[0m[1;37mINFO[0m: [1mCheckpoint 166: 
-----------------------------------
Train ACCURACY: 0.9206
Train Loss: 0.4075
ID Validation ACCURACY: 0.9150
ID Validation Loss: 0.4315
ID Test ACCURACY: 0.9157
ID Test Loss: 0.4215
OOD Validation ACCURACY: 0.8893
OOD Validation Loss: 0.4249
OOD Test ACCURACY: 0.7647
OOD Test Loss: 0.6361

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 133...
[0m[1;37mINFO[0m: [1mCheckpoint 133: 
-----------------------------------
Train ACCURACY: 0.8867
Train Loss: 0.4496
ID Validation ACCURACY: 0.8873
ID Validation Loss: 0.4598
ID Test ACCURACY: 0.8847
ID Test Loss: 0.4508
OOD Validation ACCURACY: 0.9143
OOD Validation Loss: 0.3926
OOD Test ACCURACY: 0.5360
OOD Test Loss: 1.0543

[0m[1;37mINFO[0m: [1mChartInfo 0.9157 0.7647 0.8847 0.5360 0.8873 0.9143[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.717
WIoU for r=0.3 = 0.704
F1 for r=0.6 = 0.614
WIoU for r=0.6 = 0.770
F1 for r=0.9 = 0.476
WIoU for r=0.9 = 0.772
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.772
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.826
WIoU for r=0.3 = 0.836
F1 for r=0.6 = 0.745
WIoU for r=0.6 = 1.000
F1 for r=0.9 = 0.581
WIoU for r=0.9 = 1.000
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 1.000
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.455
WIoU for r=0.3 = 0.363
F1 for r=0.6 = 0.689
WIoU for r=0.6 = 0.582
F1 for r=0.9 = 0.594
WIoU for r=0.9 = 0.597
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.597


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.715
Model XAI F1 of binarized graphs for r=0.3 =  0.7172387499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.7044274999999999
len(reference) = 794
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.517
SUFF++ for r=0.3 class 0 = 0.486 +- 0.270 (in-sample avg dev_std = 0.616)
SUFF++ for r=0.3 class 1 = 0.6 +- 0.270 (in-sample avg dev_std = 0.616)
SUFF++ for r=0.3 class 2 = 0.507 +- 0.270 (in-sample avg dev_std = 0.616)
SUFF++ for r=0.3 all KL = 0.391 +- 0.270 (in-sample avg dev_std = 0.616)
SUFF++ for r=0.3 all L1 = 0.532 +- 0.186 (in-sample avg dev_std = 0.616)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.896
Model XAI F1 of binarized graphs for r=0.6 =  0.61384125
Model XAI WIoU of binarized graphs for r=0.6 =  0.77034625
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.725
SUFF++ for r=0.6 class 0 = 0.53 +- 0.280 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.6 class 1 = 0.702 +- 0.280 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.6 class 2 = 0.655 +- 0.280 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.6 all KL = 0.568 +- 0.280 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.6 all L1 = 0.63 +- 0.189 (in-sample avg dev_std = 0.507)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.908
Model XAI F1 of binarized graphs for r=0.9 =  0.47577375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.772045
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.863
SUFF++ for r=0.9 class 0 = 0.784 +- 0.177 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 1 = 0.815 +- 0.177 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 2 = 0.857 +- 0.177 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 all KL = 0.87 +- 0.177 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 all L1 = 0.819 +- 0.164 (in-sample avg dev_std = 0.265)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.658
Model XAI F1 of binarized graphs for r=0.3 =  0.8255250000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.8362699999999998
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.56
SUFF++ for r=0.3 class 0 = 0.553 +- 0.315 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.3 class 1 = 0.731 +- 0.315 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.3 class 2 = 0.532 +- 0.315 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.3 all KL = 0.439 +- 0.315 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.3 all L1 = 0.605 +- 0.217 (in-sample avg dev_std = 0.580)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.887
Model XAI F1 of binarized graphs for r=0.6 =  0.7452737500000001
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.849
SUFF++ for r=0.6 class 0 = 0.842 +- 0.211 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.6 class 1 = 0.777 +- 0.211 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.6 class 2 = 0.853 +- 0.211 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.6 all KL = 0.816 +- 0.211 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.6 all L1 = 0.824 +- 0.174 (in-sample avg dev_std = 0.362)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.889
Model XAI F1 of binarized graphs for r=0.9 =  0.5813425
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.764
SUFF++ for r=0.9 class 0 = 0.779 +- 0.240 (in-sample avg dev_std = 0.370)
SUFF++ for r=0.9 class 1 = 0.751 +- 0.240 (in-sample avg dev_std = 0.370)
SUFF++ for r=0.9 class 2 = 0.787 +- 0.240 (in-sample avg dev_std = 0.370)
SUFF++ for r=0.9 all KL = 0.787 +- 0.240 (in-sample avg dev_std = 0.370)
SUFF++ for r=0.9 all L1 = 0.772 +- 0.210 (in-sample avg dev_std = 0.370)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.332
Model XAI F1 of binarized graphs for r=0.3 =  0.4547425
Model XAI WIoU of binarized graphs for r=0.3 =  0.36314875
len(reference) = 790
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.363
SUFF++ for r=0.3 class 0 = 0.539 +- 0.219 (in-sample avg dev_std = 0.573)
SUFF++ for r=0.3 class 1 = 0.444 +- 0.219 (in-sample avg dev_std = 0.573)
SUFF++ for r=0.3 class 2 = 0.43 +- 0.219 (in-sample avg dev_std = 0.573)
SUFF++ for r=0.3 all KL = 0.419 +- 0.219 (in-sample avg dev_std = 0.573)
SUFF++ for r=0.3 all L1 = 0.472 +- 0.146 (in-sample avg dev_std = 0.573)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.707
Model XAI F1 of binarized graphs for r=0.6 =  0.6894562500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.5821974999999999
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.686
SUFF++ for r=0.6 class 0 = 0.535 +- 0.281 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.6 class 1 = 0.826 +- 0.281 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.6 class 2 = 0.679 +- 0.281 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.6 all KL = 0.63 +- 0.281 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.6 all L1 = 0.677 +- 0.229 (in-sample avg dev_std = 0.461)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.769
Model XAI F1 of binarized graphs for r=0.9 =  0.593825
Model XAI WIoU of binarized graphs for r=0.9 =  0.5965775
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.7
SUFF++ for r=0.9 class 0 = 0.66 +- 0.168 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 class 1 = 0.957 +- 0.168 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 class 2 = 0.799 +- 0.168 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 all KL = 0.871 +- 0.168 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 all L1 = 0.803 +- 0.187 (in-sample avg dev_std = 0.246)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.719
Model XAI F1 of binarized graphs for r=0.3 =  0.7172387499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.7044274999999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.371
NEC for r=0.3 class 0 = 0.616 +- 0.269 (in-sample avg dev_std = 0.499)
NEC for r=0.3 class 1 = 0.515 +- 0.269 (in-sample avg dev_std = 0.499)
NEC for r=0.3 class 2 = 0.623 +- 0.269 (in-sample avg dev_std = 0.499)
NEC for r=0.3 all KL = 0.703 +- 0.269 (in-sample avg dev_std = 0.499)
NEC for r=0.3 all L1 = 0.585 +- 0.192 (in-sample avg dev_std = 0.499)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.896
Model XAI F1 of binarized graphs for r=0.6 =  0.61384125
Model XAI WIoU of binarized graphs for r=0.6 =  0.77034625
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.445
NEC for r=0.6 class 0 = 0.597 +- 0.285 (in-sample avg dev_std = 0.520)
NEC for r=0.6 class 1 = 0.552 +- 0.285 (in-sample avg dev_std = 0.520)
NEC for r=0.6 class 2 = 0.615 +- 0.285 (in-sample avg dev_std = 0.520)
NEC for r=0.6 all KL = 0.662 +- 0.285 (in-sample avg dev_std = 0.520)
NEC for r=0.6 all L1 = 0.588 +- 0.161 (in-sample avg dev_std = 0.520)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.908
Model XAI F1 of binarized graphs for r=0.9 =  0.47577375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.772045
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.525
NEC for r=0.9 class 0 = 0.517 +- 0.295 (in-sample avg dev_std = 0.555)
NEC for r=0.9 class 1 = 0.515 +- 0.295 (in-sample avg dev_std = 0.555)
NEC for r=0.9 class 2 = 0.547 +- 0.295 (in-sample avg dev_std = 0.555)
NEC for r=0.9 all KL = 0.566 +- 0.295 (in-sample avg dev_std = 0.555)
NEC for r=0.9 all L1 = 0.527 +- 0.165 (in-sample avg dev_std = 0.555)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.914
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.772045
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.534
NEC for r=1.0 class 0 = 0.506 +- 0.288 (in-sample avg dev_std = 0.536)
NEC for r=1.0 class 1 = 0.507 +- 0.288 (in-sample avg dev_std = 0.536)
NEC for r=1.0 class 2 = 0.542 +- 0.288 (in-sample avg dev_std = 0.536)
NEC for r=1.0 all KL = 0.544 +- 0.288 (in-sample avg dev_std = 0.536)
NEC for r=1.0 all L1 = 0.519 +- 0.166 (in-sample avg dev_std = 0.536)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.658
Model XAI F1 of binarized graphs for r=0.3 =  0.8255250000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.8362699999999998
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.225
NEC for r=0.3 class 0 = 0.646 +- 0.246 (in-sample avg dev_std = 0.524)
NEC for r=0.3 class 1 = 0.685 +- 0.246 (in-sample avg dev_std = 0.524)
NEC for r=0.3 class 2 = 0.576 +- 0.246 (in-sample avg dev_std = 0.524)
NEC for r=0.3 all KL = 0.797 +- 0.246 (in-sample avg dev_std = 0.524)
NEC for r=0.3 all L1 = 0.636 +- 0.162 (in-sample avg dev_std = 0.524)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.887
Model XAI F1 of binarized graphs for r=0.6 =  0.7452737500000001
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.525
NEC for r=0.6 class 0 = 0.481 +- 0.311 (in-sample avg dev_std = 0.611)
NEC for r=0.6 class 1 = 0.472 +- 0.311 (in-sample avg dev_std = 0.611)
NEC for r=0.6 class 2 = 0.496 +- 0.311 (in-sample avg dev_std = 0.611)
NEC for r=0.6 all KL = 0.631 +- 0.311 (in-sample avg dev_std = 0.611)
NEC for r=0.6 all L1 = 0.483 +- 0.190 (in-sample avg dev_std = 0.611)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.889
Model XAI F1 of binarized graphs for r=0.9 =  0.5813425
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.629
NEC for r=0.9 class 0 = 0.377 +- 0.252 (in-sample avg dev_std = 0.591)
NEC for r=0.9 class 1 = 0.373 +- 0.252 (in-sample avg dev_std = 0.591)
NEC for r=0.9 class 2 = 0.41 +- 0.252 (in-sample avg dev_std = 0.591)
NEC for r=0.9 all KL = 0.451 +- 0.252 (in-sample avg dev_std = 0.591)
NEC for r=0.9 all L1 = 0.386 +- 0.158 (in-sample avg dev_std = 0.591)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.89
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  1.0
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.631
NEC for r=1.0 class 0 = 0.374 +- 0.249 (in-sample avg dev_std = 0.586)
NEC for r=1.0 class 1 = 0.385 +- 0.249 (in-sample avg dev_std = 0.586)
NEC for r=1.0 class 2 = 0.415 +- 0.249 (in-sample avg dev_std = 0.586)
NEC for r=1.0 all KL = 0.447 +- 0.249 (in-sample avg dev_std = 0.586)
NEC for r=1.0 all L1 = 0.391 +- 0.156 (in-sample avg dev_std = 0.586)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.315
Model XAI F1 of binarized graphs for r=0.3 =  0.4547425
Model XAI WIoU of binarized graphs for r=0.3 =  0.36314875
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.44
NEC for r=0.3 class 0 = 0.531 +- 0.259 (in-sample avg dev_std = 0.483)
NEC for r=0.3 class 1 = 0.584 +- 0.259 (in-sample avg dev_std = 0.483)
NEC for r=0.3 class 2 = 0.617 +- 0.259 (in-sample avg dev_std = 0.483)
NEC for r=0.3 all KL = 0.62 +- 0.259 (in-sample avg dev_std = 0.483)
NEC for r=0.3 all L1 = 0.577 +- 0.175 (in-sample avg dev_std = 0.483)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.705
Model XAI F1 of binarized graphs for r=0.6 =  0.6894562500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.5821974999999999
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.509
NEC for r=0.6 class 0 = 0.574 +- 0.288 (in-sample avg dev_std = 0.563)
NEC for r=0.6 class 1 = 0.379 +- 0.288 (in-sample avg dev_std = 0.563)
NEC for r=0.6 class 2 = 0.612 +- 0.288 (in-sample avg dev_std = 0.563)
NEC for r=0.6 all KL = 0.626 +- 0.288 (in-sample avg dev_std = 0.563)
NEC for r=0.6 all L1 = 0.524 +- 0.200 (in-sample avg dev_std = 0.563)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.769
Model XAI F1 of binarized graphs for r=0.9 =  0.593825
Model XAI WIoU of binarized graphs for r=0.9 =  0.5965775
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.603
NEC for r=0.9 class 0 = 0.51 +- 0.219 (in-sample avg dev_std = 0.526)
NEC for r=0.9 class 1 = 0.356 +- 0.219 (in-sample avg dev_std = 0.526)
NEC for r=0.9 class 2 = 0.512 +- 0.219 (in-sample avg dev_std = 0.526)
NEC for r=0.9 all KL = 0.491 +- 0.219 (in-sample avg dev_std = 0.526)
NEC for r=0.9 all L1 = 0.461 +- 0.157 (in-sample avg dev_std = 0.526)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.783
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.5967075
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.615
NEC for r=1.0 class 0 = 0.491 +- 0.214 (in-sample avg dev_std = 0.510)
NEC for r=1.0 class 1 = 0.346 +- 0.214 (in-sample avg dev_std = 0.510)
NEC for r=1.0 class 2 = 0.497 +- 0.214 (in-sample avg dev_std = 0.510)
NEC for r=1.0 all KL = 0.452 +- 0.214 (in-sample avg dev_std = 0.510)
NEC for r=1.0 all L1 = 0.446 +- 0.149 (in-sample avg dev_std = 0.510)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Apr  6 21:01:02 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:02 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:17 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:19 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:22 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:24 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/06/2024 09:01:26 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 147...
[0m[1;37mINFO[0m: [1mCheckpoint 147: 
-----------------------------------
Train ACCURACY: 0.9203
Train Loss: 0.3905
ID Validation ACCURACY: 0.9223
ID Validation Loss: 0.3955
ID Test ACCURACY: 0.9180
ID Test Loss: 0.4033
OOD Validation ACCURACY: 0.8893
OOD Validation Loss: 0.4035
OOD Test ACCURACY: 0.7510
OOD Test Loss: 0.7925

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 106...
[0m[1;37mINFO[0m: [1mCheckpoint 106: 
-----------------------------------
Train ACCURACY: 0.8950
Train Loss: 0.4249
ID Validation ACCURACY: 0.8940
ID Validation Loss: 0.4447
ID Test ACCURACY: 0.8920
ID Test Loss: 0.4247
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.3254
OOD Test ACCURACY: 0.6273
OOD Test Loss: 1.0432

[0m[1;37mINFO[0m: [1mChartInfo 0.9180 0.7510 0.8920 0.6273 0.8940 0.9317[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.709
WIoU for r=0.3 = 0.671
F1 for r=0.6 = 0.613
WIoU for r=0.6 = 0.736
F1 for r=0.9 = 0.476
WIoU for r=0.9 = 0.736
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.736
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.843
WIoU for r=0.3 = 0.851
F1 for r=0.6 = 0.783
WIoU for r=0.6 = 1.000
F1 for r=0.9 = 0.615
WIoU for r=0.9 = 1.000
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 1.000
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.421
WIoU for r=0.3 = 0.307
F1 for r=0.6 = 0.635
WIoU for r=0.6 = 0.524
F1 for r=0.9 = 0.594
WIoU for r=0.9 = 0.523
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.523


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.714
Model XAI F1 of binarized graphs for r=0.3 =  0.70916
Model XAI WIoU of binarized graphs for r=0.3 =  0.670595
len(reference) = 796
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.503
SUFF++ for r=0.3 class 0 = 0.382 +- 0.259 (in-sample avg dev_std = 0.621)
SUFF++ for r=0.3 class 1 = 0.513 +- 0.259 (in-sample avg dev_std = 0.621)
SUFF++ for r=0.3 class 2 = 0.528 +- 0.259 (in-sample avg dev_std = 0.621)
SUFF++ for r=0.3 all KL = 0.348 +- 0.259 (in-sample avg dev_std = 0.621)
SUFF++ for r=0.3 all L1 = 0.476 +- 0.184 (in-sample avg dev_std = 0.621)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.879
Model XAI F1 of binarized graphs for r=0.6 =  0.6125125
Model XAI WIoU of binarized graphs for r=0.6 =  0.73621375
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.708
SUFF++ for r=0.6 class 0 = 0.489 +- 0.266 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.6 class 1 = 0.708 +- 0.266 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.6 class 2 = 0.674 +- 0.266 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.6 all KL = 0.566 +- 0.266 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.6 all L1 = 0.627 +- 0.207 (in-sample avg dev_std = 0.467)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.913
Model XAI F1 of binarized graphs for r=0.9 =  0.47577375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.7363362499999999
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.817
SUFF++ for r=0.9 class 0 = 0.734 +- 0.194 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.9 class 1 = 0.785 +- 0.194 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.9 class 2 = 0.817 +- 0.194 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.9 all KL = 0.831 +- 0.194 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.9 all L1 = 0.78 +- 0.189 (in-sample avg dev_std = 0.287)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.636
Model XAI F1 of binarized graphs for r=0.3 =  0.8433975000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.8511299999999999
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.565
SUFF++ for r=0.3 class 0 = 0.593 +- 0.300 (in-sample avg dev_std = 0.599)
SUFF++ for r=0.3 class 1 = 0.728 +- 0.300 (in-sample avg dev_std = 0.599)
SUFF++ for r=0.3 class 2 = 0.615 +- 0.300 (in-sample avg dev_std = 0.599)
SUFF++ for r=0.3 all KL = 0.45 +- 0.300 (in-sample avg dev_std = 0.599)
SUFF++ for r=0.3 all L1 = 0.645 +- 0.219 (in-sample avg dev_std = 0.599)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.892
Model XAI F1 of binarized graphs for r=0.6 =  0.7831112499999999
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.885
SUFF++ for r=0.6 class 0 = 0.887 +- 0.213 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.6 class 1 = 0.875 +- 0.213 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.6 class 2 = 0.915 +- 0.213 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.6 all KL = 0.887 +- 0.213 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.6 all L1 = 0.893 +- 0.157 (in-sample avg dev_std = 0.311)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.894
Model XAI F1 of binarized graphs for r=0.9 =  0.6147775
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.898
SUFF++ for r=0.9 class 0 = 0.947 +- 0.092 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.9 class 1 = 0.949 +- 0.092 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.9 class 2 = 0.968 +- 0.092 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.9 all KL = 0.976 +- 0.092 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.9 all L1 = 0.955 +- 0.094 (in-sample avg dev_std = 0.158)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.363
Model XAI F1 of binarized graphs for r=0.3 =  0.421355
Model XAI WIoU of binarized graphs for r=0.3 =  0.30686
len(reference) = 787
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.364
SUFF++ for r=0.3 class 0 = 0.43 +- 0.207 (in-sample avg dev_std = 0.570)
SUFF++ for r=0.3 class 1 = 0.436 +- 0.207 (in-sample avg dev_std = 0.570)
SUFF++ for r=0.3 class 2 = 0.448 +- 0.207 (in-sample avg dev_std = 0.570)
SUFF++ for r=0.3 all KL = 0.428 +- 0.207 (in-sample avg dev_std = 0.570)
SUFF++ for r=0.3 all L1 = 0.438 +- 0.116 (in-sample avg dev_std = 0.570)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.725
Model XAI F1 of binarized graphs for r=0.6 =  0.635275
Model XAI WIoU of binarized graphs for r=0.6 =  0.5241925
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.635
SUFF++ for r=0.6 class 0 = 0.486 +- 0.285 (in-sample avg dev_std = 0.454)
SUFF++ for r=0.6 class 1 = 0.793 +- 0.285 (in-sample avg dev_std = 0.454)
SUFF++ for r=0.6 class 2 = 0.652 +- 0.285 (in-sample avg dev_std = 0.454)
SUFF++ for r=0.6 all KL = 0.611 +- 0.285 (in-sample avg dev_std = 0.454)
SUFF++ for r=0.6 all L1 = 0.641 +- 0.243 (in-sample avg dev_std = 0.454)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.76
Model XAI F1 of binarized graphs for r=0.9 =  0.59382375
Model XAI WIoU of binarized graphs for r=0.9 =  0.5226475
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.67
SUFF++ for r=0.9 class 0 = 0.649 +- 0.182 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 1 = 0.976 +- 0.182 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 2 = 0.732 +- 0.182 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 all KL = 0.856 +- 0.182 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 all L1 = 0.783 +- 0.217 (in-sample avg dev_std = 0.276)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.715
Model XAI F1 of binarized graphs for r=0.3 =  0.70916
Model XAI WIoU of binarized graphs for r=0.3 =  0.670595
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.398
NEC for r=0.3 class 0 = 0.637 +- 0.224 (in-sample avg dev_std = 0.571)
NEC for r=0.3 class 1 = 0.597 +- 0.224 (in-sample avg dev_std = 0.571)
NEC for r=0.3 class 2 = 0.622 +- 0.224 (in-sample avg dev_std = 0.571)
NEC for r=0.3 all KL = 0.757 +- 0.224 (in-sample avg dev_std = 0.571)
NEC for r=0.3 all L1 = 0.619 +- 0.134 (in-sample avg dev_std = 0.571)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.879
Model XAI F1 of binarized graphs for r=0.6 =  0.6125125
Model XAI WIoU of binarized graphs for r=0.6 =  0.73621375
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.477
NEC for r=0.6 class 0 = 0.597 +- 0.283 (in-sample avg dev_std = 0.534)
NEC for r=0.6 class 1 = 0.544 +- 0.283 (in-sample avg dev_std = 0.534)
NEC for r=0.6 class 2 = 0.586 +- 0.283 (in-sample avg dev_std = 0.534)
NEC for r=0.6 all KL = 0.658 +- 0.283 (in-sample avg dev_std = 0.534)
NEC for r=0.6 all L1 = 0.576 +- 0.161 (in-sample avg dev_std = 0.534)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.911
Model XAI F1 of binarized graphs for r=0.9 =  0.47577375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.7363362499999999
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.587
NEC for r=0.9 class 0 = 0.508 +- 0.291 (in-sample avg dev_std = 0.553)
NEC for r=0.9 class 1 = 0.501 +- 0.291 (in-sample avg dev_std = 0.553)
NEC for r=0.9 class 2 = 0.523 +- 0.291 (in-sample avg dev_std = 0.553)
NEC for r=0.9 all KL = 0.555 +- 0.291 (in-sample avg dev_std = 0.553)
NEC for r=0.9 all L1 = 0.511 +- 0.159 (in-sample avg dev_std = 0.553)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.916
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.7362112500000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.588
NEC for r=1.0 class 0 = 0.506 +- 0.287 (in-sample avg dev_std = 0.545)
NEC for r=1.0 class 1 = 0.5 +- 0.287 (in-sample avg dev_std = 0.545)
NEC for r=1.0 class 2 = 0.509 +- 0.287 (in-sample avg dev_std = 0.545)
NEC for r=1.0 all KL = 0.543 +- 0.287 (in-sample avg dev_std = 0.545)
NEC for r=1.0 all L1 = 0.505 +- 0.158 (in-sample avg dev_std = 0.545)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.636
Model XAI F1 of binarized graphs for r=0.3 =  0.8433975000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.8511299999999999
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.225
NEC for r=0.3 class 0 = 0.637 +- 0.274 (in-sample avg dev_std = 0.561)
NEC for r=0.3 class 1 = 0.698 +- 0.274 (in-sample avg dev_std = 0.561)
NEC for r=0.3 class 2 = 0.566 +- 0.274 (in-sample avg dev_std = 0.561)
NEC for r=0.3 all KL = 0.811 +- 0.274 (in-sample avg dev_std = 0.561)
NEC for r=0.3 all L1 = 0.633 +- 0.210 (in-sample avg dev_std = 0.561)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.892
Model XAI F1 of binarized graphs for r=0.6 =  0.7831112499999999
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.567
NEC for r=0.6 class 0 = 0.472 +- 0.258 (in-sample avg dev_std = 0.674)
NEC for r=0.6 class 1 = 0.496 +- 0.258 (in-sample avg dev_std = 0.674)
NEC for r=0.6 class 2 = 0.44 +- 0.258 (in-sample avg dev_std = 0.674)
NEC for r=0.6 all KL = 0.621 +- 0.258 (in-sample avg dev_std = 0.674)
NEC for r=0.6 all L1 = 0.469 +- 0.160 (in-sample avg dev_std = 0.674)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.894
Model XAI F1 of binarized graphs for r=0.9 =  0.6147775
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.658
NEC for r=0.9 class 0 = 0.364 +- 0.213 (in-sample avg dev_std = 0.605)
NEC for r=0.9 class 1 = 0.406 +- 0.213 (in-sample avg dev_std = 0.605)
NEC for r=0.9 class 2 = 0.339 +- 0.213 (in-sample avg dev_std = 0.605)
NEC for r=0.9 all KL = 0.408 +- 0.213 (in-sample avg dev_std = 0.605)
NEC for r=0.9 all L1 = 0.369 +- 0.150 (in-sample avg dev_std = 0.605)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.894
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  1.0
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.669
NEC for r=1.0 class 0 = 0.344 +- 0.208 (in-sample avg dev_std = 0.599)
NEC for r=1.0 class 1 = 0.405 +- 0.208 (in-sample avg dev_std = 0.599)
NEC for r=1.0 class 2 = 0.341 +- 0.208 (in-sample avg dev_std = 0.599)
NEC for r=1.0 all KL = 0.4 +- 0.208 (in-sample avg dev_std = 0.599)
NEC for r=1.0 all L1 = 0.363 +- 0.148 (in-sample avg dev_std = 0.599)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.363
Model XAI F1 of binarized graphs for r=0.3 =  0.421355
Model XAI WIoU of binarized graphs for r=0.3 =  0.30686
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.43
NEC for r=0.3 class 0 = 0.598 +- 0.256 (in-sample avg dev_std = 0.496)
NEC for r=0.3 class 1 = 0.567 +- 0.256 (in-sample avg dev_std = 0.496)
NEC for r=0.3 class 2 = 0.538 +- 0.256 (in-sample avg dev_std = 0.496)
NEC for r=0.3 all KL = 0.579 +- 0.256 (in-sample avg dev_std = 0.496)
NEC for r=0.3 all L1 = 0.568 +- 0.178 (in-sample avg dev_std = 0.496)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.725
Model XAI F1 of binarized graphs for r=0.6 =  0.635275
Model XAI WIoU of binarized graphs for r=0.6 =  0.5241925
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.644
NEC for r=0.6 class 0 = 0.539 +- 0.283 (in-sample avg dev_std = 0.528)
NEC for r=0.6 class 1 = 0.353 +- 0.283 (in-sample avg dev_std = 0.528)
NEC for r=0.6 class 2 = 0.522 +- 0.283 (in-sample avg dev_std = 0.528)
NEC for r=0.6 all KL = 0.566 +- 0.283 (in-sample avg dev_std = 0.528)
NEC for r=0.6 all L1 = 0.473 +- 0.200 (in-sample avg dev_std = 0.528)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.76
Model XAI F1 of binarized graphs for r=0.9 =  0.59382375
Model XAI WIoU of binarized graphs for r=0.9 =  0.5226475
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.641
NEC for r=0.9 class 0 = 0.473 +- 0.220 (in-sample avg dev_std = 0.512)
NEC for r=0.9 class 1 = 0.266 +- 0.220 (in-sample avg dev_std = 0.512)
NEC for r=0.9 class 2 = 0.489 +- 0.220 (in-sample avg dev_std = 0.512)
NEC for r=0.9 all KL = 0.442 +- 0.220 (in-sample avg dev_std = 0.512)
NEC for r=0.9 all L1 = 0.412 +- 0.177 (in-sample avg dev_std = 0.512)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.772
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.5226037499999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.67
NEC for r=1.0 class 0 = 0.449 +- 0.209 (in-sample avg dev_std = 0.500)
NEC for r=1.0 class 1 = 0.271 +- 0.209 (in-sample avg dev_std = 0.500)
NEC for r=1.0 class 2 = 0.448 +- 0.209 (in-sample avg dev_std = 0.500)
NEC for r=1.0 all KL = 0.404 +- 0.209 (in-sample avg dev_std = 0.500)
NEC for r=1.0 all L1 = 0.391 +- 0.168 (in-sample avg dev_std = 0.500)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.41, 0.557, 0.867, 1.0], 'all_L1': [0.49, 0.586, 0.791, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.368, 0.599, 0.891, 1.0], 'all_L1': [0.463, 0.628, 0.831, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.376, 0.574, 0.87, 1.0], 'all_L1': [0.482, 0.63, 0.821, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.391, 0.568, 0.87, 1.0], 'all_L1': [0.532, 0.63, 0.819, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.348, 0.566, 0.831, 1.0], 'all_L1': [0.476, 0.627, 0.78, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.722, 0.634, 0.542, 0.512], 'all_L1': [0.605, 0.583, 0.53, 0.51]}), defaultdict(<class 'list'>, {'all_KL': [0.711, 0.624, 0.533, 0.506], 'all_L1': [0.636, 0.581, 0.518, 0.498]}), defaultdict(<class 'list'>, {'all_KL': [0.723, 0.651, 0.544, 0.535], 'all_L1': [0.633, 0.581, 0.507, 0.506]}), defaultdict(<class 'list'>, {'all_KL': [0.703, 0.662, 0.566, 0.544], 'all_L1': [0.585, 0.588, 0.527, 0.519]}), defaultdict(<class 'list'>, {'all_KL': [0.757, 0.658, 0.555, 0.543], 'all_L1': [0.619, 0.576, 0.511, 0.505]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.448, 0.89, 0.977, 1.0], 'all_L1': [0.612, 0.869, 0.95, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.46, 0.797, 0.913, 1.0], 'all_L1': [0.624, 0.798, 0.849, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.479, 0.783, 0.848, 1.0], 'all_L1': [0.661, 0.816, 0.797, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.439, 0.816, 0.787, 1.0], 'all_L1': [0.605, 0.824, 0.772, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.45, 0.887, 0.976, 1.0], 'all_L1': [0.645, 0.893, 0.955, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.858, 0.625, 0.388, 0.375], 'all_L1': [0.679, 0.517, 0.384, 0.378]}), defaultdict(<class 'list'>, {'all_KL': [0.818, 0.529, 0.365, 0.336], 'all_L1': [0.649, 0.46, 0.383, 0.366]}), defaultdict(<class 'list'>, {'all_KL': [0.838, 0.604, 0.413, 0.408], 'all_L1': [0.661, 0.483, 0.391, 0.397]}), defaultdict(<class 'list'>, {'all_KL': [0.797, 0.631, 0.451, 0.447], 'all_L1': [0.636, 0.483, 0.386, 0.391]}), defaultdict(<class 'list'>, {'all_KL': [0.811, 0.621, 0.408, 0.4], 'all_L1': [0.633, 0.469, 0.369, 0.363]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.467, 0.614, 0.868, 1.0], 'all_L1': [0.523, 0.654, 0.825, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.376, 0.627, 0.831, 1.0], 'all_L1': [0.424, 0.647, 0.774, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.377, 0.526, 0.829, 1.0], 'all_L1': [0.411, 0.579, 0.779, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.419, 0.63, 0.871, 1.0], 'all_L1': [0.472, 0.677, 0.803, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.428, 0.611, 0.856, 1.0], 'all_L1': [0.438, 0.641, 0.783, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.557, 0.707, 0.557, 0.504], 'all_L1': [0.505, 0.587, 0.469, 0.439]}), defaultdict(<class 'list'>, {'all_KL': [0.641, 0.617, 0.46, 0.426], 'all_L1': [0.608, 0.527, 0.456, 0.442]}), defaultdict(<class 'list'>, {'all_KL': [0.617, 0.64, 0.532, 0.482], 'all_L1': [0.589, 0.542, 0.464, 0.437]}), defaultdict(<class 'list'>, {'all_KL': [0.62, 0.626, 0.491, 0.452], 'all_L1': [0.577, 0.524, 0.461, 0.446]}), defaultdict(<class 'list'>, {'all_KL': [0.579, 0.566, 0.442, 0.404], 'all_L1': [0.568, 0.473, 0.412, 0.391]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.489 +- 0.023, 0.620 +- 0.017, 0.808 +- 0.019, 1.000 +- 0.000
suff++ class all_KL  =  0.379 +- 0.021, 0.573 +- 0.014, 0.866 +- 0.019, 1.000 +- 0.000
suff++_acc_int  =  0.496 +- 0.014, 0.708 +- 0.021, 0.856 +- 0.020
nec class all_L1  =  0.616 +- 0.019, 0.582 +- 0.004, 0.519 +- 0.009, 0.508 +- 0.007
nec class all_KL  =  0.723 +- 0.018, 0.646 +- 0.015, 0.548 +- 0.011, 0.528 +- 0.016
nec_acc_int  =  0.380 +- 0.010, 0.459 +- 0.013, 0.551 +- 0.023, 0.559 +- 0.019

Eval split val
suff++ class all_L1  =  0.629 +- 0.021, 0.840 +- 0.035, 0.865 +- 0.076, 1.000 +- 0.000
suff++ class all_KL  =  0.455 +- 0.014, 0.835 +- 0.045, 0.900 +- 0.074, 1.000 +- 0.000
suff++_acc_int  =  0.540 +- 0.023, 0.856 +- 0.032, 0.845 +- 0.058
nec class all_L1  =  0.652 +- 0.017, 0.482 +- 0.019, 0.383 +- 0.007, 0.379 +- 0.013
nec class all_KL  =  0.824 +- 0.021, 0.602 +- 0.038, 0.405 +- 0.029, 0.393 +- 0.037
nec_acc_int  =  0.242 +- 0.061, 0.546 +- 0.035, 0.632 +- 0.015, 0.627 +- 0.029

Eval split test
suff++ class all_L1  =  0.454 +- 0.040, 0.640 +- 0.033, 0.793 +- 0.019, 1.000 +- 0.000
suff++ class all_KL  =  0.413 +- 0.034, 0.602 +- 0.038, 0.851 +- 0.018, 1.000 +- 0.000
suff++_acc_int  =  0.360 +- 0.010, 0.655 +- 0.027, 0.728 +- 0.051
nec class all_L1  =  0.569 +- 0.035, 0.531 +- 0.037, 0.452 +- 0.021, 0.431 +- 0.020
nec class all_KL  =  0.603 +- 0.030, 0.631 +- 0.045, 0.496 +- 0.043, 0.454 +- 0.036
nec_acc_int  =  0.413 +- 0.027, 0.545 +- 0.056, 0.620 +- 0.013, 0.640 +- 0.020


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.552 +- 0.005, 0.601 +- 0.009, 0.663 +- 0.010, 0.754 +- 0.003
Faith. Armon (L1)= 		  =  0.544 +- 0.008, 0.600 +- 0.008, 0.632 +- 0.009, 0.673 +- 0.006
Faith. GMean (L1)= 	  =  0.548 +- 0.006, 0.601 +- 0.008, 0.647 +- 0.009, 0.712 +- 0.005
Faith. Aritm (KL)= 		  =  0.551 +- 0.009, 0.609 +- 0.007, 0.707 +- 0.008, 0.764 +- 0.008
Faith. Armon (KL)= 		  =  0.496 +- 0.016, 0.607 +- 0.007, 0.671 +- 0.008, 0.691 +- 0.014
Faith. GMean (KL)= 	  =  0.523 +- 0.012, 0.608 +- 0.007, 0.689 +- 0.007, 0.727 +- 0.011

Eval split val
Faith. Aritm (L1)= 		  =  0.640 +- 0.013, 0.661 +- 0.023, 0.624 +- 0.035, 0.689 +- 0.007
Faith. Armon (L1)= 		  =  0.640 +- 0.013, 0.613 +- 0.021, 0.529 +- 0.011, 0.550 +- 0.014
Faith. GMean (L1)= 	  =  0.640 +- 0.013, 0.636 +- 0.021, 0.574 +- 0.022, 0.616 +- 0.011
Faith. Aritm (KL)= 		  =  0.640 +- 0.015, 0.718 +- 0.036, 0.653 +- 0.029, 0.697 +- 0.018
Faith. Armon (KL)= 		  =  0.586 +- 0.014, 0.699 +- 0.037, 0.556 +- 0.019, 0.563 +- 0.038
Faith. GMean (KL)= 	  =  0.613 +- 0.014, 0.709 +- 0.036, 0.602 +- 0.019, 0.626 +- 0.029

Eval split test
Faith. Aritm (L1)= 		  =  0.512 +- 0.009, 0.585 +- 0.024, 0.623 +- 0.017, 0.715 +- 0.010
Faith. Armon (L1)= 		  =  0.502 +- 0.013, 0.579 +- 0.026, 0.576 +- 0.020, 0.602 +- 0.020
Faith. GMean (L1)= 	  =  0.507 +- 0.011, 0.582 +- 0.025, 0.599 +- 0.018, 0.656 +- 0.016
Faith. Aritm (KL)= 		  =  0.508 +- 0.008, 0.616 +- 0.028, 0.674 +- 0.025, 0.727 +- 0.018
Faith. Armon (KL)= 		  =  0.488 +- 0.015, 0.614 +- 0.029, 0.626 +- 0.035, 0.623 +- 0.034
Faith. GMean (KL)= 	  =  0.498 +- 0.011, 0.615 +- 0.029, 0.649 +- 0.030, 0.673 +- 0.027
Computed for split load_split = id



Completed in  0:22:23.659515  for LECIGIN GOODMotif/basis



DONE LECI GOODMotif/basis





[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 13:19:28 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:28 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:40 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:42 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:44 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:47 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 01:19:53 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 193...
[0m[1;37mINFO[0m: [1mCheckpoint 193: 
-----------------------------------
Train ACCURACY: 0.8868
Train Loss: 0.4263
ID Validation ACCURACY: 0.8903
ID Validation Loss: 0.4063
ID Test ACCURACY: 0.8870
ID Test Loss: 0.4328
OOD Validation ACCURACY: 0.7457
OOD Validation Loss: 5.4460
OOD Test ACCURACY: 0.5017
OOD Test Loss: 29.7885

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 167...
[0m[1;37mINFO[0m: [1mCheckpoint 167: 
-----------------------------------
Train ACCURACY: 0.8296
Train Loss: 0.5063
ID Validation ACCURACY: 0.8310
ID Validation Loss: 0.4794
ID Test ACCURACY: 0.8297
ID Test Loss: 0.5080
OOD Validation ACCURACY: 0.8050
OOD Validation Loss: 2.5637
OOD Test ACCURACY: 0.6360
OOD Test Loss: 14.4751

[0m[1;37mINFO[0m: [1mChartInfo 0.8870 0.5017 0.8297 0.6360 0.8310 0.8050[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.591
WIoU for r=0.3 = 0.468
F1 for r=0.6 = 0.624
WIoU for r=0.6 = 0.566
F1 for r=0.9 = 0.522
WIoU for r=0.9 = 0.552
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.548
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.434
WIoU for r=0.3 = 0.390
F1 for r=0.6 = 0.322
WIoU for r=0.6 = 0.340
F1 for r=0.9 = 0.255
WIoU for r=0.9 = 0.324
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.320
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.248
WIoU for r=0.3 = 0.287
F1 for r=0.6 = 0.158
WIoU for r=0.6 = 0.259
F1 for r=0.9 = 0.121
WIoU for r=0.9 = 0.255
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.255


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.429
Model XAI F1 of binarized graphs for r=0.3 =  0.5914262499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.46822875
len(reference) = 776
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.368
SUFF++ for r=0.3 class 0 = 0.642 +- 0.186 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.3 class 1 = 0.664 +- 0.186 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.3 class 2 = 0.621 +- 0.186 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.3 all KL = 0.78 +- 0.186 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.3 all L1 = 0.642 +- 0.134 (in-sample avg dev_std = 0.324)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.674
Model XAI F1 of binarized graphs for r=0.6 =  0.62419125
Model XAI WIoU of binarized graphs for r=0.6 =  0.5659825
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.625
SUFF++ for r=0.6 class 0 = 0.574 +- 0.287 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.6 class 1 = 0.758 +- 0.287 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.6 class 2 = 0.653 +- 0.287 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.6 all KL = 0.664 +- 0.287 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.6 all L1 = 0.66 +- 0.238 (in-sample avg dev_std = 0.486)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.841
Model XAI F1 of binarized graphs for r=0.9 =  0.5224212500000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.552335
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.799
SUFF++ for r=0.9 class 0 = 0.779 +- 0.238 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 class 1 = 0.831 +- 0.238 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 class 2 = 0.889 +- 0.238 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 all KL = 0.859 +- 0.238 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 all L1 = 0.833 +- 0.225 (in-sample avg dev_std = 0.268)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.529
Model XAI F1 of binarized graphs for r=0.3 =  0.4343362500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.38957875000000003
len(reference) = 799
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.518
SUFF++ for r=0.3 class 0 = 0.684 +- 0.211 (in-sample avg dev_std = 0.363)
SUFF++ for r=0.3 class 1 = 0.728 +- 0.211 (in-sample avg dev_std = 0.363)
SUFF++ for r=0.3 class 2 = 0.662 +- 0.211 (in-sample avg dev_std = 0.363)
SUFF++ for r=0.3 all KL = 0.767 +- 0.211 (in-sample avg dev_std = 0.363)
SUFF++ for r=0.3 all L1 = 0.692 +- 0.183 (in-sample avg dev_std = 0.363)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.631
Model XAI F1 of binarized graphs for r=0.6 =  0.32235625
Model XAI WIoU of binarized graphs for r=0.6 =  0.34001750000000003
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.634
SUFF++ for r=0.6 class 0 = 0.601 +- 0.280 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 class 1 = 0.696 +- 0.280 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 class 2 = 0.714 +- 0.280 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 all KL = 0.69 +- 0.280 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 all L1 = 0.67 +- 0.234 (in-sample avg dev_std = 0.468)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.717
Model XAI F1 of binarized graphs for r=0.9 =  0.25451750000000006
Model XAI WIoU of binarized graphs for r=0.9 =  0.3236212500000001
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.645
SUFF++ for r=0.9 class 0 = 0.785 +- 0.225 (in-sample avg dev_std = 0.306)
SUFF++ for r=0.9 class 1 = 0.841 +- 0.225 (in-sample avg dev_std = 0.306)
SUFF++ for r=0.9 class 2 = 0.907 +- 0.225 (in-sample avg dev_std = 0.306)
SUFF++ for r=0.9 all KL = 0.865 +- 0.225 (in-sample avg dev_std = 0.306)
SUFF++ for r=0.9 all L1 = 0.843 +- 0.205 (in-sample avg dev_std = 0.306)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.495
Model XAI F1 of binarized graphs for r=0.3 =  0.24753500000000003
Model XAI WIoU of binarized graphs for r=0.3 =  0.28713374999999997
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.478
SUFF++ for r=0.3 class 0 = 0.613 +- 0.195 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.3 class 1 = 0.622 +- 0.195 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.3 class 2 = 0.607 +- 0.195 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.3 all KL = 0.681 +- 0.195 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.3 all L1 = 0.614 +- 0.139 (in-sample avg dev_std = 0.488)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.544
Model XAI F1 of binarized graphs for r=0.6 =  0.1578675
Model XAI WIoU of binarized graphs for r=0.6 =  0.25918125000000003
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.423
SUFF++ for r=0.6 class 0 = 0.56 +- 0.301 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.6 class 1 = 0.593 +- 0.301 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.6 class 2 = 0.638 +- 0.301 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.6 all KL = 0.607 +- 0.301 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.6 all L1 = 0.596 +- 0.216 (in-sample avg dev_std = 0.482)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.517
Model XAI F1 of binarized graphs for r=0.9 =  0.12124125000000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.255415
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.498
SUFF++ for r=0.9 class 0 = 0.797 +- 0.247 (in-sample avg dev_std = 0.325)
SUFF++ for r=0.9 class 1 = 0.793 +- 0.247 (in-sample avg dev_std = 0.325)
SUFF++ for r=0.9 class 2 = 0.859 +- 0.247 (in-sample avg dev_std = 0.325)
SUFF++ for r=0.9 all KL = 0.825 +- 0.247 (in-sample avg dev_std = 0.325)
SUFF++ for r=0.9 all L1 = 0.816 +- 0.208 (in-sample avg dev_std = 0.325)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.434
Model XAI F1 of binarized graphs for r=0.3 =  0.5914262499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.46822875
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.31
NEC for r=0.3 class 0 = 0.391 +- 0.247 (in-sample avg dev_std = 0.280)
NEC for r=0.3 class 1 = 0.357 +- 0.247 (in-sample avg dev_std = 0.280)
NEC for r=0.3 class 2 = 0.405 +- 0.247 (in-sample avg dev_std = 0.280)
NEC for r=0.3 all KL = 0.252 +- 0.247 (in-sample avg dev_std = 0.280)
NEC for r=0.3 all L1 = 0.385 +- 0.178 (in-sample avg dev_std = 0.280)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.674
Model XAI F1 of binarized graphs for r=0.6 =  0.62419125
Model XAI WIoU of binarized graphs for r=0.6 =  0.5659825
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.437
NEC for r=0.6 class 0 = 0.584 +- 0.290 (in-sample avg dev_std = 0.540)
NEC for r=0.6 class 1 = 0.426 +- 0.290 (in-sample avg dev_std = 0.540)
NEC for r=0.6 class 2 = 0.61 +- 0.290 (in-sample avg dev_std = 0.540)
NEC for r=0.6 all KL = 0.568 +- 0.290 (in-sample avg dev_std = 0.540)
NEC for r=0.6 all L1 = 0.542 +- 0.209 (in-sample avg dev_std = 0.540)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.841
Model XAI F1 of binarized graphs for r=0.9 =  0.5224212500000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.552335
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.505
NEC for r=0.9 class 0 = 0.611 +- 0.265 (in-sample avg dev_std = 0.592)
NEC for r=0.9 class 1 = 0.43 +- 0.265 (in-sample avg dev_std = 0.592)
NEC for r=0.9 class 2 = 0.6 +- 0.265 (in-sample avg dev_std = 0.592)
NEC for r=0.9 all KL = 0.593 +- 0.265 (in-sample avg dev_std = 0.592)
NEC for r=0.9 all L1 = 0.549 +- 0.190 (in-sample avg dev_std = 0.592)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.879
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.5484025
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.528
NEC for r=1.0 class 0 = 0.58 +- 0.278 (in-sample avg dev_std = 0.604)
NEC for r=1.0 class 1 = 0.396 +- 0.278 (in-sample avg dev_std = 0.604)
NEC for r=1.0 class 2 = 0.579 +- 0.278 (in-sample avg dev_std = 0.604)
NEC for r=1.0 all KL = 0.564 +- 0.278 (in-sample avg dev_std = 0.604)
NEC for r=1.0 all L1 = 0.52 +- 0.201 (in-sample avg dev_std = 0.604)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.529
Model XAI F1 of binarized graphs for r=0.3 =  0.4343362500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.38957875000000003
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.347
NEC for r=0.3 class 0 = 0.431 +- 0.295 (in-sample avg dev_std = 0.313)
NEC for r=0.3 class 1 = 0.427 +- 0.295 (in-sample avg dev_std = 0.313)
NEC for r=0.3 class 2 = 0.51 +- 0.295 (in-sample avg dev_std = 0.313)
NEC for r=0.3 all KL = 0.388 +- 0.295 (in-sample avg dev_std = 0.313)
NEC for r=0.3 all L1 = 0.455 +- 0.218 (in-sample avg dev_std = 0.313)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.631
Model XAI F1 of binarized graphs for r=0.6 =  0.32235625
Model XAI WIoU of binarized graphs for r=0.6 =  0.34001750000000003
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.446
NEC for r=0.6 class 0 = 0.468 +- 0.307 (in-sample avg dev_std = 0.455)
NEC for r=0.6 class 1 = 0.343 +- 0.307 (in-sample avg dev_std = 0.455)
NEC for r=0.6 class 2 = 0.613 +- 0.307 (in-sample avg dev_std = 0.455)
NEC for r=0.6 all KL = 0.457 +- 0.307 (in-sample avg dev_std = 0.455)
NEC for r=0.6 all L1 = 0.473 +- 0.227 (in-sample avg dev_std = 0.455)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.717
Model XAI F1 of binarized graphs for r=0.9 =  0.25451750000000006
Model XAI WIoU of binarized graphs for r=0.9 =  0.3236212500000001
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.493
NEC for r=0.9 class 0 = 0.447 +- 0.279 (in-sample avg dev_std = 0.502)
NEC for r=0.9 class 1 = 0.276 +- 0.279 (in-sample avg dev_std = 0.502)
NEC for r=0.9 class 2 = 0.46 +- 0.279 (in-sample avg dev_std = 0.502)
NEC for r=0.9 all KL = 0.418 +- 0.279 (in-sample avg dev_std = 0.502)
NEC for r=0.9 all L1 = 0.394 +- 0.250 (in-sample avg dev_std = 0.502)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.769
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.32036625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.502
NEC for r=1.0 class 0 = 0.458 +- 0.306 (in-sample avg dev_std = 0.462)
NEC for r=1.0 class 1 = 0.275 +- 0.306 (in-sample avg dev_std = 0.462)
NEC for r=1.0 class 2 = 0.434 +- 0.306 (in-sample avg dev_std = 0.462)
NEC for r=1.0 all KL = 0.37 +- 0.306 (in-sample avg dev_std = 0.462)
NEC for r=1.0 all L1 = 0.389 +- 0.264 (in-sample avg dev_std = 0.462)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.495
Model XAI F1 of binarized graphs for r=0.3 =  0.24753500000000003
Model XAI WIoU of binarized graphs for r=0.3 =  0.28713374999999997
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.318
NEC for r=0.3 class 0 = 0.392 +- 0.304 (in-sample avg dev_std = 0.214)
NEC for r=0.3 class 1 = 0.34 +- 0.304 (in-sample avg dev_std = 0.214)
NEC for r=0.3 class 2 = 0.422 +- 0.304 (in-sample avg dev_std = 0.214)
NEC for r=0.3 all KL = 0.299 +- 0.304 (in-sample avg dev_std = 0.214)
NEC for r=0.3 all L1 = 0.384 +- 0.236 (in-sample avg dev_std = 0.214)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.544
Model XAI F1 of binarized graphs for r=0.6 =  0.1578675
Model XAI WIoU of binarized graphs for r=0.6 =  0.25918125000000003
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.347
NEC for r=0.6 class 0 = 0.484 +- 0.294 (in-sample avg dev_std = 0.234)
NEC for r=0.6 class 1 = 0.408 +- 0.294 (in-sample avg dev_std = 0.234)
NEC for r=0.6 class 2 = 0.413 +- 0.294 (in-sample avg dev_std = 0.234)
NEC for r=0.6 all KL = 0.372 +- 0.294 (in-sample avg dev_std = 0.234)
NEC for r=0.6 all L1 = 0.435 +- 0.245 (in-sample avg dev_std = 0.234)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.519
Model XAI F1 of binarized graphs for r=0.9 =  0.12124125000000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.255415
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.351
NEC for r=0.9 class 0 = 0.416 +- 0.361 (in-sample avg dev_std = 0.233)
NEC for r=0.9 class 1 = 0.345 +- 0.361 (in-sample avg dev_std = 0.233)
NEC for r=0.9 class 2 = 0.317 +- 0.361 (in-sample avg dev_std = 0.233)
NEC for r=0.9 all KL = 0.375 +- 0.361 (in-sample avg dev_std = 0.233)
NEC for r=0.9 all L1 = 0.36 +- 0.299 (in-sample avg dev_std = 0.233)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.489
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.25462125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.343
NEC for r=1.0 class 0 = 0.448 +- 0.392 (in-sample avg dev_std = 0.192)
NEC for r=1.0 class 1 = 0.392 +- 0.392 (in-sample avg dev_std = 0.192)
NEC for r=1.0 class 2 = 0.368 +- 0.392 (in-sample avg dev_std = 0.192)
NEC for r=1.0 all KL = 0.497 +- 0.392 (in-sample avg dev_std = 0.192)
NEC for r=1.0 all L1 = 0.404 +- 0.318 (in-sample avg dev_std = 0.192)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 13:25:56 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/07/2024 01:25:56 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:08 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:10 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:12 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:15 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 01:26:21 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 138...
[0m[1;37mINFO[0m: [1mCheckpoint 138: 
-----------------------------------
Train ACCURACY: 0.8933
Train Loss: 0.3734
ID Validation ACCURACY: 0.8993
ID Validation Loss: 0.3605
ID Test ACCURACY: 0.8947
ID Test Loss: 0.3748
OOD Validation ACCURACY: 0.7443
OOD Validation Loss: 0.8304
OOD Test ACCURACY: 0.3473
OOD Test Loss: 19.0323

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 157...
[0m[1;37mINFO[0m: [1mCheckpoint 157: 
-----------------------------------
Train ACCURACY: 0.8452
Train Loss: 0.7879
ID Validation ACCURACY: 0.8510
ID Validation Loss: 0.7727
ID Test ACCURACY: 0.8510
ID Test Loss: 0.7561
OOD Validation ACCURACY: 0.8023
OOD Validation Loss: 4.4919
OOD Test ACCURACY: 0.4070
OOD Test Loss: 19.4874

[0m[1;37mINFO[0m: [1mChartInfo 0.8947 0.3473 0.8510 0.4070 0.8510 0.8023[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.597
WIoU for r=0.3 = 0.476
F1 for r=0.6 = 0.624
WIoU for r=0.6 = 0.559
F1 for r=0.9 = 0.523
WIoU for r=0.9 = 0.551
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.547
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.464
WIoU for r=0.3 = 0.384
F1 for r=0.6 = 0.336
WIoU for r=0.6 = 0.303
F1 for r=0.9 = 0.257
WIoU for r=0.9 = 0.275
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.269
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.238
WIoU for r=0.3 = 0.172
F1 for r=0.6 = 0.150
WIoU for r=0.6 = 0.104
F1 for r=0.9 = 0.115
WIoU for r=0.9 = 0.086
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.086


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.41
Model XAI F1 of binarized graphs for r=0.3 =  0.5969487499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.47582
len(reference) = 778
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.357
SUFF++ for r=0.3 class 0 = 0.633 +- 0.229 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.3 class 1 = 0.644 +- 0.229 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.3 class 2 = 0.621 +- 0.229 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.3 all KL = 0.753 +- 0.229 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.3 all L1 = 0.632 +- 0.157 (in-sample avg dev_std = 0.364)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.65
Model XAI F1 of binarized graphs for r=0.6 =  0.6240725
Model XAI WIoU of binarized graphs for r=0.6 =  0.5588
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.595
SUFF++ for r=0.6 class 0 = 0.588 +- 0.287 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.6 class 1 = 0.758 +- 0.287 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.6 class 2 = 0.676 +- 0.287 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.6 all KL = 0.675 +- 0.287 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.6 all L1 = 0.673 +- 0.236 (in-sample avg dev_std = 0.488)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.848
Model XAI F1 of binarized graphs for r=0.9 =  0.5233399999999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.5513800000000001
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.804
SUFF++ for r=0.9 class 0 = 0.755 +- 0.247 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 1 = 0.844 +- 0.247 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 2 = 0.881 +- 0.247 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 all KL = 0.855 +- 0.247 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 all L1 = 0.826 +- 0.236 (in-sample avg dev_std = 0.260)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.561
Model XAI F1 of binarized graphs for r=0.3 =  0.46369125000000005
Model XAI WIoU of binarized graphs for r=0.3 =  0.38444500000000004
len(reference) = 799
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.526
SUFF++ for r=0.3 class 0 = 0.572 +- 0.253 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.3 class 1 = 0.609 +- 0.253 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.3 class 2 = 0.593 +- 0.253 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.3 all KL = 0.625 +- 0.253 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.3 all L1 = 0.591 +- 0.209 (in-sample avg dev_std = 0.486)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.663
Model XAI F1 of binarized graphs for r=0.6 =  0.33606250000000004
Model XAI WIoU of binarized graphs for r=0.6 =  0.30344125
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.599
SUFF++ for r=0.6 class 0 = 0.54 +- 0.300 (in-sample avg dev_std = 0.511)
SUFF++ for r=0.6 class 1 = 0.641 +- 0.300 (in-sample avg dev_std = 0.511)
SUFF++ for r=0.6 class 2 = 0.697 +- 0.300 (in-sample avg dev_std = 0.511)
SUFF++ for r=0.6 all KL = 0.613 +- 0.300 (in-sample avg dev_std = 0.511)
SUFF++ for r=0.6 all L1 = 0.625 +- 0.240 (in-sample avg dev_std = 0.511)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.724
Model XAI F1 of binarized graphs for r=0.9 =  0.25698875
Model XAI WIoU of binarized graphs for r=0.9 =  0.2751
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.7
SUFF++ for r=0.9 class 0 = 0.662 +- 0.228 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.9 class 1 = 0.845 +- 0.228 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.9 class 2 = 0.785 +- 0.228 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.9 all KL = 0.818 +- 0.228 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.9 all L1 = 0.763 +- 0.231 (in-sample avg dev_std = 0.280)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.433
Model XAI F1 of binarized graphs for r=0.3 =  0.23758125
Model XAI WIoU of binarized graphs for r=0.3 =  0.17244875
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.457
SUFF++ for r=0.3 class 0 = 0.542 +- 0.242 (in-sample avg dev_std = 0.571)
SUFF++ for r=0.3 class 1 = 0.607 +- 0.242 (in-sample avg dev_std = 0.571)
SUFF++ for r=0.3 class 2 = 0.684 +- 0.242 (in-sample avg dev_std = 0.571)
SUFF++ for r=0.3 all KL = 0.586 +- 0.242 (in-sample avg dev_std = 0.571)
SUFF++ for r=0.3 all L1 = 0.609 +- 0.177 (in-sample avg dev_std = 0.571)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.375
Model XAI F1 of binarized graphs for r=0.6 =  0.14950875
Model XAI WIoU of binarized graphs for r=0.6 =  0.10425124999999999
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.407
SUFF++ for r=0.6 class 0 = 0.627 +- 0.326 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 class 1 = 0.635 +- 0.326 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 class 2 = 0.773 +- 0.326 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 all KL = 0.635 +- 0.326 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 all L1 = 0.676 +- 0.248 (in-sample avg dev_std = 0.456)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.341
Model XAI F1 of binarized graphs for r=0.9 =  0.1154175
Model XAI WIoU of binarized graphs for r=0.9 =  0.08645625000000003
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.345
SUFF++ for r=0.9 class 0 = 0.92 +- 0.080 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.9 class 1 = 0.905 +- 0.080 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.9 class 2 = 0.951 +- 0.080 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.9 all KL = 0.958 +- 0.080 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.9 all L1 = 0.924 +- 0.113 (in-sample avg dev_std = 0.163)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.41
Model XAI F1 of binarized graphs for r=0.3 =  0.5969487499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.47582
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.328
NEC for r=0.3 class 0 = 0.373 +- 0.262 (in-sample avg dev_std = 0.329)
NEC for r=0.3 class 1 = 0.399 +- 0.262 (in-sample avg dev_std = 0.329)
NEC for r=0.3 class 2 = 0.402 +- 0.262 (in-sample avg dev_std = 0.329)
NEC for r=0.3 all KL = 0.277 +- 0.262 (in-sample avg dev_std = 0.329)
NEC for r=0.3 all L1 = 0.391 +- 0.192 (in-sample avg dev_std = 0.329)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.65
Model XAI F1 of binarized graphs for r=0.6 =  0.6240725
Model XAI WIoU of binarized graphs for r=0.6 =  0.5588
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.435
NEC for r=0.6 class 0 = 0.56 +- 0.274 (in-sample avg dev_std = 0.541)
NEC for r=0.6 class 1 = 0.409 +- 0.274 (in-sample avg dev_std = 0.541)
NEC for r=0.6 class 2 = 0.593 +- 0.274 (in-sample avg dev_std = 0.541)
NEC for r=0.6 all KL = 0.551 +- 0.274 (in-sample avg dev_std = 0.541)
NEC for r=0.6 all L1 = 0.522 +- 0.210 (in-sample avg dev_std = 0.541)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.848
Model XAI F1 of binarized graphs for r=0.9 =  0.5233399999999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.5513800000000001
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.501
NEC for r=0.9 class 0 = 0.617 +- 0.244 (in-sample avg dev_std = 0.599)
NEC for r=0.9 class 1 = 0.412 +- 0.244 (in-sample avg dev_std = 0.599)
NEC for r=0.9 class 2 = 0.587 +- 0.244 (in-sample avg dev_std = 0.599)
NEC for r=0.9 all KL = 0.57 +- 0.244 (in-sample avg dev_std = 0.599)
NEC for r=0.9 all L1 = 0.541 +- 0.185 (in-sample avg dev_std = 0.599)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.895
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.5473587500000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.527
NEC for r=1.0 class 0 = 0.593 +- 0.253 (in-sample avg dev_std = 0.594)
NEC for r=1.0 class 1 = 0.405 +- 0.253 (in-sample avg dev_std = 0.594)
NEC for r=1.0 class 2 = 0.574 +- 0.253 (in-sample avg dev_std = 0.594)
NEC for r=1.0 all KL = 0.55 +- 0.253 (in-sample avg dev_std = 0.594)
NEC for r=1.0 all L1 = 0.526 +- 0.195 (in-sample avg dev_std = 0.594)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.56
Model XAI F1 of binarized graphs for r=0.3 =  0.46369125000000005
Model XAI WIoU of binarized graphs for r=0.3 =  0.38444500000000004
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.362
NEC for r=0.3 class 0 = 0.509 +- 0.254 (in-sample avg dev_std = 0.458)
NEC for r=0.3 class 1 = 0.514 +- 0.254 (in-sample avg dev_std = 0.458)
NEC for r=0.3 class 2 = 0.596 +- 0.254 (in-sample avg dev_std = 0.458)
NEC for r=0.3 all KL = 0.513 +- 0.254 (in-sample avg dev_std = 0.458)
NEC for r=0.3 all L1 = 0.539 +- 0.173 (in-sample avg dev_std = 0.458)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.664
Model XAI F1 of binarized graphs for r=0.6 =  0.33606250000000004
Model XAI WIoU of binarized graphs for r=0.6 =  0.30344125
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.435
NEC for r=0.6 class 0 = 0.512 +- 0.277 (in-sample avg dev_std = 0.494)
NEC for r=0.6 class 1 = 0.416 +- 0.277 (in-sample avg dev_std = 0.494)
NEC for r=0.6 class 2 = 0.625 +- 0.277 (in-sample avg dev_std = 0.494)
NEC for r=0.6 all KL = 0.532 +- 0.277 (in-sample avg dev_std = 0.494)
NEC for r=0.6 all L1 = 0.516 +- 0.223 (in-sample avg dev_std = 0.494)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.725
Model XAI F1 of binarized graphs for r=0.9 =  0.25698875
Model XAI WIoU of binarized graphs for r=0.9 =  0.2751
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.491
NEC for r=0.9 class 0 = 0.528 +- 0.258 (in-sample avg dev_std = 0.494)
NEC for r=0.9 class 1 = 0.357 +- 0.258 (in-sample avg dev_std = 0.494)
NEC for r=0.9 class 2 = 0.523 +- 0.258 (in-sample avg dev_std = 0.494)
NEC for r=0.9 all KL = 0.456 +- 0.258 (in-sample avg dev_std = 0.494)
NEC for r=0.9 all L1 = 0.469 +- 0.223 (in-sample avg dev_std = 0.494)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.776
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.26922625000000006
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.506
NEC for r=1.0 class 0 = 0.558 +- 0.265 (in-sample avg dev_std = 0.468)
NEC for r=1.0 class 1 = 0.377 +- 0.265 (in-sample avg dev_std = 0.468)
NEC for r=1.0 class 2 = 0.525 +- 0.265 (in-sample avg dev_std = 0.468)
NEC for r=1.0 all KL = 0.46 +- 0.265 (in-sample avg dev_std = 0.468)
NEC for r=1.0 all L1 = 0.486 +- 0.224 (in-sample avg dev_std = 0.468)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.433
Model XAI F1 of binarized graphs for r=0.3 =  0.23758125
Model XAI WIoU of binarized graphs for r=0.3 =  0.17244875
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.342
NEC for r=0.3 class 0 = 0.379 +- 0.290 (in-sample avg dev_std = 0.411)
NEC for r=0.3 class 1 = 0.357 +- 0.290 (in-sample avg dev_std = 0.411)
NEC for r=0.3 class 2 = 0.38 +- 0.290 (in-sample avg dev_std = 0.411)
NEC for r=0.3 all KL = 0.329 +- 0.290 (in-sample avg dev_std = 0.411)
NEC for r=0.3 all L1 = 0.372 +- 0.236 (in-sample avg dev_std = 0.411)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.375
Model XAI F1 of binarized graphs for r=0.6 =  0.14950875
Model XAI WIoU of binarized graphs for r=0.6 =  0.10425124999999999
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.362
NEC for r=0.6 class 0 = 0.473 +- 0.395 (in-sample avg dev_std = 0.441)
NEC for r=0.6 class 1 = 0.426 +- 0.395 (in-sample avg dev_std = 0.441)
NEC for r=0.6 class 2 = 0.42 +- 0.395 (in-sample avg dev_std = 0.441)
NEC for r=0.6 all KL = 0.487 +- 0.395 (in-sample avg dev_std = 0.441)
NEC for r=0.6 all L1 = 0.44 +- 0.286 (in-sample avg dev_std = 0.441)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.341
Model XAI F1 of binarized graphs for r=0.9 =  0.1154175
Model XAI WIoU of binarized graphs for r=0.9 =  0.08645625000000003
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.333
NEC for r=0.9 class 0 = 0.156 +- 0.213 (in-sample avg dev_std = 0.267)
NEC for r=0.9 class 1 = 0.174 +- 0.213 (in-sample avg dev_std = 0.267)
NEC for r=0.9 class 2 = 0.169 +- 0.213 (in-sample avg dev_std = 0.267)
NEC for r=0.9 all KL = 0.146 +- 0.213 (in-sample avg dev_std = 0.267)
NEC for r=0.9 all L1 = 0.166 +- 0.214 (in-sample avg dev_std = 0.267)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.352
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.08567875000000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.34
NEC for r=1.0 class 0 = 0.185 +- 0.319 (in-sample avg dev_std = 0.308)
NEC for r=1.0 class 1 = 0.159 +- 0.319 (in-sample avg dev_std = 0.308)
NEC for r=1.0 class 2 = 0.207 +- 0.319 (in-sample avg dev_std = 0.308)
NEC for r=1.0 all KL = 0.21 +- 0.319 (in-sample avg dev_std = 0.308)
NEC for r=1.0 all L1 = 0.183 +- 0.263 (in-sample avg dev_std = 0.308)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 13:32:28 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:28 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:40 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:42 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:44 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:47 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 01:32:54 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 52...
[0m[1;37mINFO[0m: [1mCheckpoint 52: 
-----------------------------------
Train ACCURACY: 0.8962
Train Loss: 0.3853
ID Validation ACCURACY: 0.9043
ID Validation Loss: 0.3623
ID Test ACCURACY: 0.8960
ID Test Loss: 0.3830
OOD Validation ACCURACY: 0.7817
OOD Validation Loss: 0.7805
OOD Test ACCURACY: 0.6063
OOD Test Loss: 2.6911

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 184...
[0m[1;37mINFO[0m: [1mCheckpoint 184: 
-----------------------------------
Train ACCURACY: 0.8508
Train Loss: 0.4639
ID Validation ACCURACY: 0.8667
ID Validation Loss: 0.4374
ID Test ACCURACY: 0.8593
ID Test Loss: 0.4592
OOD Validation ACCURACY: 0.8360
OOD Validation Loss: 0.8923
OOD Test ACCURACY: 0.4013
OOD Test Loss: 4.3777

[0m[1;37mINFO[0m: [1mChartInfo 0.8960 0.6063 0.8593 0.4013 0.8667 0.8360[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.527
WIoU for r=0.3 = 0.452
F1 for r=0.6 = 0.563
WIoU for r=0.6 = 0.569
F1 for r=0.9 = 0.516
WIoU for r=0.9 = 0.585
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.585
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.366
WIoU for r=0.3 = 0.498
F1 for r=0.6 = 0.290
WIoU for r=0.6 = 0.515
F1 for r=0.9 = 0.251
WIoU for r=0.9 = 0.517
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.517
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.187
WIoU for r=0.3 = 0.278
F1 for r=0.6 = 0.136
WIoU for r=0.6 = 0.256
F1 for r=0.9 = 0.117
WIoU for r=0.9 = 0.247
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.245


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.426
Model XAI F1 of binarized graphs for r=0.3 =  0.52662125
Model XAI WIoU of binarized graphs for r=0.3 =  0.45201875
len(reference) = 763
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.376
SUFF++ for r=0.3 class 0 = 0.733 +- 0.165 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.3 class 1 = 0.77 +- 0.165 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.3 class 2 = 0.713 +- 0.165 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.3 all KL = 0.862 +- 0.165 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.3 all L1 = 0.738 +- 0.125 (in-sample avg dev_std = 0.298)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.545
Model XAI F1 of binarized graphs for r=0.6 =  0.56328625
Model XAI WIoU of binarized graphs for r=0.6 =  0.56858875
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.542
SUFF++ for r=0.6 class 0 = 0.702 +- 0.239 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.6 class 1 = 0.859 +- 0.239 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.6 class 2 = 0.74 +- 0.239 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.6 all KL = 0.802 +- 0.239 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.6 all L1 = 0.765 +- 0.197 (in-sample avg dev_std = 0.407)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.789
Model XAI F1 of binarized graphs for r=0.9 =  0.51569625
Model XAI WIoU of binarized graphs for r=0.9 =  0.58517
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.793
SUFF++ for r=0.9 class 0 = 0.86 +- 0.145 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 class 1 = 0.901 +- 0.145 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 class 2 = 0.898 +- 0.145 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 all KL = 0.925 +- 0.145 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 all L1 = 0.886 +- 0.156 (in-sample avg dev_std = 0.249)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.615
Model XAI F1 of binarized graphs for r=0.3 =  0.36630624999999994
Model XAI WIoU of binarized graphs for r=0.3 =  0.49790625000000005
len(reference) = 797
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.536
SUFF++ for r=0.3 class 0 = 0.682 +- 0.156 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.3 class 1 = 0.776 +- 0.156 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.3 class 2 = 0.713 +- 0.156 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.3 all KL = 0.835 +- 0.156 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.3 all L1 = 0.724 +- 0.160 (in-sample avg dev_std = 0.336)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.636
Model XAI F1 of binarized graphs for r=0.6 =  0.29027625
Model XAI WIoU of binarized graphs for r=0.6 =  0.51535125
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.59
SUFF++ for r=0.6 class 0 = 0.738 +- 0.202 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.6 class 1 = 0.795 +- 0.202 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.6 class 2 = 0.762 +- 0.202 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.6 all KL = 0.814 +- 0.202 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.6 all L1 = 0.765 +- 0.187 (in-sample avg dev_std = 0.365)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.757
Model XAI F1 of binarized graphs for r=0.9 =  0.25071
Model XAI WIoU of binarized graphs for r=0.9 =  0.5174249999999999
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.702
SUFF++ for r=0.9 class 0 = 0.776 +- 0.152 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.9 class 1 = 0.875 +- 0.152 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.9 class 2 = 0.85 +- 0.152 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.9 all KL = 0.895 +- 0.152 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.9 all L1 = 0.833 +- 0.171 (in-sample avg dev_std = 0.269)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.521
Model XAI F1 of binarized graphs for r=0.3 =  0.18718625000000003
Model XAI WIoU of binarized graphs for r=0.3 =  0.27809125
len(reference) = 796
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.474
SUFF++ for r=0.3 class 0 = 0.525 +- 0.208 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.3 class 1 = 0.608 +- 0.208 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.3 class 2 = 0.596 +- 0.208 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.3 all KL = 0.678 +- 0.208 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.3 all L1 = 0.576 +- 0.180 (in-sample avg dev_std = 0.426)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.514
Model XAI F1 of binarized graphs for r=0.6 =  0.13622250000000002
Model XAI WIoU of binarized graphs for r=0.6 =  0.25599
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.444
SUFF++ for r=0.6 class 0 = 0.656 +- 0.223 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.6 class 1 = 0.705 +- 0.223 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.6 class 2 = 0.715 +- 0.223 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.6 all KL = 0.724 +- 0.223 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.6 all L1 = 0.692 +- 0.213 (in-sample avg dev_std = 0.350)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.535
Model XAI F1 of binarized graphs for r=0.9 =  0.11737375
Model XAI WIoU of binarized graphs for r=0.9 =  0.24731375
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.492
SUFF++ for r=0.9 class 0 = 0.741 +- 0.215 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.9 class 1 = 0.778 +- 0.215 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.9 class 2 = 0.808 +- 0.215 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.9 all KL = 0.833 +- 0.215 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.9 all L1 = 0.775 +- 0.231 (in-sample avg dev_std = 0.273)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.423
Model XAI F1 of binarized graphs for r=0.3 =  0.52662125
Model XAI WIoU of binarized graphs for r=0.3 =  0.45201875
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.346
NEC for r=0.3 class 0 = 0.304 +- 0.229 (in-sample avg dev_std = 0.236)
NEC for r=0.3 class 1 = 0.295 +- 0.229 (in-sample avg dev_std = 0.236)
NEC for r=0.3 class 2 = 0.32 +- 0.229 (in-sample avg dev_std = 0.236)
NEC for r=0.3 all KL = 0.179 +- 0.229 (in-sample avg dev_std = 0.236)
NEC for r=0.3 all L1 = 0.306 +- 0.188 (in-sample avg dev_std = 0.236)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.545
Model XAI F1 of binarized graphs for r=0.6 =  0.56328625
Model XAI WIoU of binarized graphs for r=0.6 =  0.56858875
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.431
NEC for r=0.6 class 0 = 0.401 +- 0.283 (in-sample avg dev_std = 0.460)
NEC for r=0.6 class 1 = 0.326 +- 0.283 (in-sample avg dev_std = 0.460)
NEC for r=0.6 class 2 = 0.44 +- 0.283 (in-sample avg dev_std = 0.460)
NEC for r=0.6 all KL = 0.357 +- 0.283 (in-sample avg dev_std = 0.460)
NEC for r=0.6 all L1 = 0.39 +- 0.223 (in-sample avg dev_std = 0.460)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.789
Model XAI F1 of binarized graphs for r=0.9 =  0.51569625
Model XAI WIoU of binarized graphs for r=0.9 =  0.58517
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.523
NEC for r=0.9 class 0 = 0.565 +- 0.280 (in-sample avg dev_std = 0.552)
NEC for r=0.9 class 1 = 0.38 +- 0.280 (in-sample avg dev_std = 0.552)
NEC for r=0.9 class 2 = 0.591 +- 0.280 (in-sample avg dev_std = 0.552)
NEC for r=0.9 all KL = 0.518 +- 0.280 (in-sample avg dev_std = 0.552)
NEC for r=0.9 all L1 = 0.514 +- 0.203 (in-sample avg dev_std = 0.552)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.905
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.584885
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.589
NEC for r=1.0 class 0 = 0.555 +- 0.280 (in-sample avg dev_std = 0.562)
NEC for r=1.0 class 1 = 0.355 +- 0.280 (in-sample avg dev_std = 0.562)
NEC for r=1.0 class 2 = 0.573 +- 0.280 (in-sample avg dev_std = 0.562)
NEC for r=1.0 all KL = 0.501 +- 0.280 (in-sample avg dev_std = 0.562)
NEC for r=1.0 all L1 = 0.496 +- 0.202 (in-sample avg dev_std = 0.562)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.614
Model XAI F1 of binarized graphs for r=0.3 =  0.36630624999999994
Model XAI WIoU of binarized graphs for r=0.3 =  0.49790625000000005
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.382
NEC for r=0.3 class 0 = 0.441 +- 0.298 (in-sample avg dev_std = 0.283)
NEC for r=0.3 class 1 = 0.341 +- 0.298 (in-sample avg dev_std = 0.283)
NEC for r=0.3 class 2 = 0.48 +- 0.298 (in-sample avg dev_std = 0.283)
NEC for r=0.3 all KL = 0.308 +- 0.298 (in-sample avg dev_std = 0.283)
NEC for r=0.3 all L1 = 0.42 +- 0.218 (in-sample avg dev_std = 0.283)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.636
Model XAI F1 of binarized graphs for r=0.6 =  0.29027625
Model XAI WIoU of binarized graphs for r=0.6 =  0.51535125
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.497
NEC for r=0.6 class 0 = 0.424 +- 0.273 (in-sample avg dev_std = 0.483)
NEC for r=0.6 class 1 = 0.253 +- 0.273 (in-sample avg dev_std = 0.483)
NEC for r=0.6 class 2 = 0.477 +- 0.273 (in-sample avg dev_std = 0.483)
NEC for r=0.6 all KL = 0.349 +- 0.273 (in-sample avg dev_std = 0.483)
NEC for r=0.6 all L1 = 0.384 +- 0.208 (in-sample avg dev_std = 0.483)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.757
Model XAI F1 of binarized graphs for r=0.9 =  0.25071
Model XAI WIoU of binarized graphs for r=0.9 =  0.5174249999999999
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.529
NEC for r=0.9 class 0 = 0.483 +- 0.270 (in-sample avg dev_std = 0.477)
NEC for r=0.9 class 1 = 0.253 +- 0.270 (in-sample avg dev_std = 0.477)
NEC for r=0.9 class 2 = 0.523 +- 0.270 (in-sample avg dev_std = 0.477)
NEC for r=0.9 all KL = 0.383 +- 0.270 (in-sample avg dev_std = 0.477)
NEC for r=0.9 all L1 = 0.419 +- 0.218 (in-sample avg dev_std = 0.477)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.822
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.51653125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.545
NEC for r=1.0 class 0 = 0.485 +- 0.293 (in-sample avg dev_std = 0.473)
NEC for r=1.0 class 1 = 0.247 +- 0.293 (in-sample avg dev_std = 0.473)
NEC for r=1.0 class 2 = 0.486 +- 0.293 (in-sample avg dev_std = 0.473)
NEC for r=1.0 all KL = 0.369 +- 0.293 (in-sample avg dev_std = 0.473)
NEC for r=1.0 all L1 = 0.405 +- 0.232 (in-sample avg dev_std = 0.473)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.522
Model XAI F1 of binarized graphs for r=0.3 =  0.18718625000000003
Model XAI WIoU of binarized graphs for r=0.3 =  0.27809125
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.366
NEC for r=0.3 class 0 = 0.437 +- 0.258 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 1 = 0.35 +- 0.258 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 2 = 0.457 +- 0.258 (in-sample avg dev_std = 0.293)
NEC for r=0.3 all KL = 0.29 +- 0.258 (in-sample avg dev_std = 0.293)
NEC for r=0.3 all L1 = 0.414 +- 0.194 (in-sample avg dev_std = 0.293)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.514
Model XAI F1 of binarized graphs for r=0.6 =  0.13622250000000002
Model XAI WIoU of binarized graphs for r=0.6 =  0.25599
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.425
NEC for r=0.6 class 0 = 0.299 +- 0.217 (in-sample avg dev_std = 0.299)
NEC for r=0.6 class 1 = 0.222 +- 0.217 (in-sample avg dev_std = 0.299)
NEC for r=0.6 class 2 = 0.323 +- 0.217 (in-sample avg dev_std = 0.299)
NEC for r=0.6 all KL = 0.209 +- 0.217 (in-sample avg dev_std = 0.299)
NEC for r=0.6 all L1 = 0.28 +- 0.217 (in-sample avg dev_std = 0.299)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.535
Model XAI F1 of binarized graphs for r=0.9 =  0.11737375
Model XAI WIoU of binarized graphs for r=0.9 =  0.24731375
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.456
NEC for r=0.9 class 0 = 0.336 +- 0.262 (in-sample avg dev_std = 0.343)
NEC for r=0.9 class 1 = 0.268 +- 0.262 (in-sample avg dev_std = 0.343)
NEC for r=0.9 class 2 = 0.344 +- 0.262 (in-sample avg dev_std = 0.343)
NEC for r=0.9 all KL = 0.272 +- 0.262 (in-sample avg dev_std = 0.343)
NEC for r=0.9 all L1 = 0.316 +- 0.235 (in-sample avg dev_std = 0.343)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.614
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.24541000000000002
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.455
NEC for r=1.0 class 0 = 0.401 +- 0.225 (in-sample avg dev_std = 0.315)
NEC for r=1.0 class 1 = 0.29 +- 0.225 (in-sample avg dev_std = 0.315)
NEC for r=1.0 class 2 = 0.43 +- 0.225 (in-sample avg dev_std = 0.315)
NEC for r=1.0 all KL = 0.284 +- 0.225 (in-sample avg dev_std = 0.315)
NEC for r=1.0 all L1 = 0.372 +- 0.223 (in-sample avg dev_std = 0.315)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 13:38:48 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/07/2024 01:38:48 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:00 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:01 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:03 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:07 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 01:39:13 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 169...
[0m[1;37mINFO[0m: [1mCheckpoint 169: 
-----------------------------------
Train ACCURACY: 0.9292
Train Loss: 0.2964
ID Validation ACCURACY: 0.9363
ID Validation Loss: 0.2924
ID Test ACCURACY: 0.9300
ID Test Loss: 0.3058
OOD Validation ACCURACY: 0.9060
OOD Validation Loss: 0.3917
OOD Test ACCURACY: 0.6020
OOD Test Loss: 1.1717

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 132...
[0m[1;37mINFO[0m: [1mCheckpoint 132: 
-----------------------------------
Train ACCURACY: 0.9289
Train Loss: 0.3040
ID Validation ACCURACY: 0.9353
ID Validation Loss: 0.2952
ID Test ACCURACY: 0.9313
ID Test Loss: 0.3088
OOD Validation ACCURACY: 0.9193
OOD Validation Loss: 0.3703
OOD Test ACCURACY: 0.6457
OOD Test Loss: 1.2464

[0m[1;37mINFO[0m: [1mChartInfo 0.9300 0.6020 0.9313 0.6457 0.9353 0.9193[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.537
WIoU for r=0.3 = 0.466
F1 for r=0.6 = 0.559
WIoU for r=0.6 = 0.587
F1 for r=0.9 = 0.508
WIoU for r=0.9 = 0.605
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.608
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.365
WIoU for r=0.3 = 0.500
F1 for r=0.6 = 0.283
WIoU for r=0.6 = 0.513
F1 for r=0.9 = 0.247
WIoU for r=0.9 = 0.517
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.518
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.192
WIoU for r=0.3 = 0.434
F1 for r=0.6 = 0.139
WIoU for r=0.6 = 0.437
F1 for r=0.9 = 0.118
WIoU for r=0.9 = 0.438
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.438


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.459
Model XAI F1 of binarized graphs for r=0.3 =  0.5368975
Model XAI WIoU of binarized graphs for r=0.3 =  0.46645375
len(reference) = 771
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.39
SUFF++ for r=0.3 class 0 = 0.659 +- 0.190 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.3 class 1 = 0.694 +- 0.190 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.3 class 2 = 0.654 +- 0.190 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.3 all KL = 0.788 +- 0.190 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.3 all L1 = 0.669 +- 0.133 (in-sample avg dev_std = 0.399)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.582
Model XAI F1 of binarized graphs for r=0.6 =  0.55928875
Model XAI WIoU of binarized graphs for r=0.6 =  0.586735
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.549
SUFF++ for r=0.6 class 0 = 0.676 +- 0.235 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 class 1 = 0.774 +- 0.235 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 class 2 = 0.681 +- 0.235 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 all KL = 0.763 +- 0.235 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 all L1 = 0.71 +- 0.201 (in-sample avg dev_std = 0.429)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.743
Model XAI F1 of binarized graphs for r=0.9 =  0.50751875
Model XAI WIoU of binarized graphs for r=0.9 =  0.6052875
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.752
SUFF++ for r=0.9 class 0 = 0.873 +- 0.176 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.9 class 1 = 0.902 +- 0.176 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.9 class 2 = 0.904 +- 0.176 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.9 all KL = 0.91 +- 0.176 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.9 all L1 = 0.893 +- 0.162 (in-sample avg dev_std = 0.289)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.603
Model XAI F1 of binarized graphs for r=0.3 =  0.36548875
Model XAI WIoU of binarized graphs for r=0.3 =  0.49992125000000004
len(reference) = 793
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.542
SUFF++ for r=0.3 class 0 = 0.704 +- 0.169 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 class 1 = 0.753 +- 0.169 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 class 2 = 0.701 +- 0.169 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 all KL = 0.81 +- 0.169 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 all L1 = 0.719 +- 0.138 (in-sample avg dev_std = 0.415)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.627
Model XAI F1 of binarized graphs for r=0.6 =  0.28321625
Model XAI WIoU of binarized graphs for r=0.6 =  0.51303
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.553
SUFF++ for r=0.6 class 0 = 0.661 +- 0.212 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.6 class 1 = 0.708 +- 0.212 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.6 class 2 = 0.702 +- 0.212 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.6 all KL = 0.762 +- 0.212 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.6 all L1 = 0.69 +- 0.193 (in-sample avg dev_std = 0.391)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.709
Model XAI F1 of binarized graphs for r=0.9 =  0.24705000000000002
Model XAI WIoU of binarized graphs for r=0.9 =  0.51742125
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.671
SUFF++ for r=0.9 class 0 = 0.728 +- 0.206 (in-sample avg dev_std = 0.368)
SUFF++ for r=0.9 class 1 = 0.809 +- 0.206 (in-sample avg dev_std = 0.368)
SUFF++ for r=0.9 class 2 = 0.852 +- 0.206 (in-sample avg dev_std = 0.368)
SUFF++ for r=0.9 all KL = 0.825 +- 0.206 (in-sample avg dev_std = 0.368)
SUFF++ for r=0.9 all L1 = 0.795 +- 0.195 (in-sample avg dev_std = 0.368)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.571
Model XAI F1 of binarized graphs for r=0.3 =  0.19170875
Model XAI WIoU of binarized graphs for r=0.3 =  0.43353375
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.505
SUFF++ for r=0.3 class 0 = 0.625 +- 0.178 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.3 class 1 = 0.658 +- 0.178 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.3 class 2 = 0.718 +- 0.178 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.3 all KL = 0.765 +- 0.178 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.3 all L1 = 0.666 +- 0.156 (in-sample avg dev_std = 0.414)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.529
Model XAI F1 of binarized graphs for r=0.6 =  0.13902625000000002
Model XAI WIoU of binarized graphs for r=0.6 =  0.43746750000000006
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.438
SUFF++ for r=0.6 class 0 = 0.639 +- 0.183 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.6 class 1 = 0.698 +- 0.183 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.6 class 2 = 0.733 +- 0.183 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.6 all KL = 0.755 +- 0.183 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.6 all L1 = 0.689 +- 0.200 (in-sample avg dev_std = 0.364)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.482
Model XAI F1 of binarized graphs for r=0.9 =  0.11805625000000002
Model XAI WIoU of binarized graphs for r=0.9 =  0.43845625
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.434
SUFF++ for r=0.9 class 0 = 0.776 +- 0.222 (in-sample avg dev_std = 0.376)
SUFF++ for r=0.9 class 1 = 0.793 +- 0.222 (in-sample avg dev_std = 0.376)
SUFF++ for r=0.9 class 2 = 0.859 +- 0.222 (in-sample avg dev_std = 0.376)
SUFF++ for r=0.9 all KL = 0.819 +- 0.222 (in-sample avg dev_std = 0.376)
SUFF++ for r=0.9 all L1 = 0.808 +- 0.193 (in-sample avg dev_std = 0.376)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.464
Model XAI F1 of binarized graphs for r=0.3 =  0.5368975
Model XAI WIoU of binarized graphs for r=0.3 =  0.46645375
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.359
NEC for r=0.3 class 0 = 0.359 +- 0.276 (in-sample avg dev_std = 0.289)
NEC for r=0.3 class 1 = 0.274 +- 0.276 (in-sample avg dev_std = 0.289)
NEC for r=0.3 class 2 = 0.362 +- 0.276 (in-sample avg dev_std = 0.289)
NEC for r=0.3 all KL = 0.221 +- 0.276 (in-sample avg dev_std = 0.289)
NEC for r=0.3 all L1 = 0.333 +- 0.212 (in-sample avg dev_std = 0.289)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.582
Model XAI F1 of binarized graphs for r=0.6 =  0.55928875
Model XAI WIoU of binarized graphs for r=0.6 =  0.586735
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.437
NEC for r=0.6 class 0 = 0.447 +- 0.291 (in-sample avg dev_std = 0.467)
NEC for r=0.6 class 1 = 0.349 +- 0.291 (in-sample avg dev_std = 0.467)
NEC for r=0.6 class 2 = 0.469 +- 0.291 (in-sample avg dev_std = 0.467)
NEC for r=0.6 all KL = 0.383 +- 0.291 (in-sample avg dev_std = 0.467)
NEC for r=0.6 all L1 = 0.422 +- 0.211 (in-sample avg dev_std = 0.467)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.743
Model XAI F1 of binarized graphs for r=0.9 =  0.50751875
Model XAI WIoU of binarized graphs for r=0.9 =  0.6052875
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.515
NEC for r=0.9 class 0 = 0.529 +- 0.285 (in-sample avg dev_std = 0.574)
NEC for r=0.9 class 1 = 0.348 +- 0.285 (in-sample avg dev_std = 0.574)
NEC for r=0.9 class 2 = 0.559 +- 0.285 (in-sample avg dev_std = 0.574)
NEC for r=0.9 all KL = 0.507 +- 0.285 (in-sample avg dev_std = 0.574)
NEC for r=0.9 all L1 = 0.481 +- 0.217 (in-sample avg dev_std = 0.574)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.936
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.60849875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.579
NEC for r=1.0 class 0 = 0.587 +- 0.293 (in-sample avg dev_std = 0.628)
NEC for r=1.0 class 1 = 0.321 +- 0.293 (in-sample avg dev_std = 0.628)
NEC for r=1.0 class 2 = 0.584 +- 0.293 (in-sample avg dev_std = 0.628)
NEC for r=1.0 all KL = 0.572 +- 0.293 (in-sample avg dev_std = 0.628)
NEC for r=1.0 all L1 = 0.5 +- 0.226 (in-sample avg dev_std = 0.628)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.6
Model XAI F1 of binarized graphs for r=0.3 =  0.36548875
Model XAI WIoU of binarized graphs for r=0.3 =  0.49992125000000004
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.361
NEC for r=0.3 class 0 = 0.45 +- 0.330 (in-sample avg dev_std = 0.301)
NEC for r=0.3 class 1 = 0.322 +- 0.330 (in-sample avg dev_std = 0.301)
NEC for r=0.3 class 2 = 0.439 +- 0.330 (in-sample avg dev_std = 0.301)
NEC for r=0.3 all KL = 0.325 +- 0.330 (in-sample avg dev_std = 0.301)
NEC for r=0.3 all L1 = 0.404 +- 0.241 (in-sample avg dev_std = 0.301)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.627
Model XAI F1 of binarized graphs for r=0.6 =  0.28321625
Model XAI WIoU of binarized graphs for r=0.6 =  0.51303
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.45
NEC for r=0.6 class 0 = 0.434 +- 0.266 (in-sample avg dev_std = 0.456)
NEC for r=0.6 class 1 = 0.293 +- 0.266 (in-sample avg dev_std = 0.456)
NEC for r=0.6 class 2 = 0.465 +- 0.266 (in-sample avg dev_std = 0.456)
NEC for r=0.6 all KL = 0.328 +- 0.266 (in-sample avg dev_std = 0.456)
NEC for r=0.6 all L1 = 0.396 +- 0.187 (in-sample avg dev_std = 0.456)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.709
Model XAI F1 of binarized graphs for r=0.9 =  0.24705000000000002
Model XAI WIoU of binarized graphs for r=0.9 =  0.51742125
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.507
NEC for r=0.9 class 0 = 0.432 +- 0.277 (in-sample avg dev_std = 0.475)
NEC for r=0.9 class 1 = 0.25 +- 0.277 (in-sample avg dev_std = 0.475)
NEC for r=0.9 class 2 = 0.441 +- 0.277 (in-sample avg dev_std = 0.475)
NEC for r=0.9 all KL = 0.356 +- 0.277 (in-sample avg dev_std = 0.475)
NEC for r=0.9 all L1 = 0.374 +- 0.232 (in-sample avg dev_std = 0.475)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.926
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.51758375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.551
NEC for r=1.0 class 0 = 0.604 +- 0.322 (in-sample avg dev_std = 0.528)
NEC for r=1.0 class 1 = 0.24 +- 0.322 (in-sample avg dev_std = 0.528)
NEC for r=1.0 class 2 = 0.602 +- 0.322 (in-sample avg dev_std = 0.528)
NEC for r=1.0 all KL = 0.514 +- 0.322 (in-sample avg dev_std = 0.528)
NEC for r=1.0 all L1 = 0.481 +- 0.246 (in-sample avg dev_std = 0.528)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.57
Model XAI F1 of binarized graphs for r=0.3 =  0.19170875
Model XAI WIoU of binarized graphs for r=0.3 =  0.43353375
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.364
NEC for r=0.3 class 0 = 0.355 +- 0.255 (in-sample avg dev_std = 0.267)
NEC for r=0.3 class 1 = 0.271 +- 0.255 (in-sample avg dev_std = 0.267)
NEC for r=0.3 class 2 = 0.376 +- 0.255 (in-sample avg dev_std = 0.267)
NEC for r=0.3 all KL = 0.214 +- 0.255 (in-sample avg dev_std = 0.267)
NEC for r=0.3 all L1 = 0.333 +- 0.209 (in-sample avg dev_std = 0.267)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.529
Model XAI F1 of binarized graphs for r=0.6 =  0.13902625000000002
Model XAI WIoU of binarized graphs for r=0.6 =  0.43746750000000006
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.395
NEC for r=0.6 class 0 = 0.311 +- 0.193 (in-sample avg dev_std = 0.347)
NEC for r=0.6 class 1 = 0.239 +- 0.193 (in-sample avg dev_std = 0.347)
NEC for r=0.6 class 2 = 0.342 +- 0.193 (in-sample avg dev_std = 0.347)
NEC for r=0.6 all KL = 0.199 +- 0.193 (in-sample avg dev_std = 0.347)
NEC for r=0.6 all L1 = 0.296 +- 0.187 (in-sample avg dev_std = 0.347)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.482
Model XAI F1 of binarized graphs for r=0.9 =  0.11805625000000002
Model XAI WIoU of binarized graphs for r=0.9 =  0.43845625
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.397
NEC for r=0.9 class 0 = 0.285 +- 0.238 (in-sample avg dev_std = 0.349)
NEC for r=0.9 class 1 = 0.223 +- 0.238 (in-sample avg dev_std = 0.349)
NEC for r=0.9 class 2 = 0.304 +- 0.238 (in-sample avg dev_std = 0.349)
NEC for r=0.9 all KL = 0.22 +- 0.238 (in-sample avg dev_std = 0.349)
NEC for r=0.9 all L1 = 0.27 +- 0.201 (in-sample avg dev_std = 0.349)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.596
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.43824624999999995
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.434
NEC for r=1.0 class 0 = 0.533 +- 0.360 (in-sample avg dev_std = 0.340)
NEC for r=1.0 class 1 = 0.406 +- 0.360 (in-sample avg dev_std = 0.340)
NEC for r=1.0 class 2 = 0.536 +- 0.360 (in-sample avg dev_std = 0.340)
NEC for r=1.0 all KL = 0.495 +- 0.360 (in-sample avg dev_std = 0.340)
NEC for r=1.0 all L1 = 0.491 +- 0.261 (in-sample avg dev_std = 0.340)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 13:45:07 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:07 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:19 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:21 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:23 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:26 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 01:45:33 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 121...
[0m[1;37mINFO[0m: [1mCheckpoint 121: 
-----------------------------------
Train ACCURACY: 0.9277
Train Loss: 0.3045
ID Validation ACCURACY: 0.9360
ID Validation Loss: 0.2927
ID Test ACCURACY: 0.9303
ID Test Loss: 0.3051
OOD Validation ACCURACY: 0.9160
OOD Validation Loss: 0.3805
OOD Test ACCURACY: 0.6473
OOD Test Loss: 0.9928

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 88...
[0m[1;37mINFO[0m: [1mCheckpoint 88: 
-----------------------------------
Train ACCURACY: 0.9278
Train Loss: 0.3080
ID Validation ACCURACY: 0.9353
ID Validation Loss: 0.2959
ID Test ACCURACY: 0.9303
ID Test Loss: 0.3113
OOD Validation ACCURACY: 0.9190
OOD Validation Loss: 0.3687
OOD Test ACCURACY: 0.6710
OOD Test Loss: 0.9696

[0m[1;37mINFO[0m: [1mChartInfo 0.9303 0.6473 0.9303 0.6710 0.9353 0.9190[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.534
WIoU for r=0.3 = 0.450
F1 for r=0.6 = 0.589
WIoU for r=0.6 = 0.595
F1 for r=0.9 = 0.513
WIoU for r=0.9 = 0.597
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.599
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.401
WIoU for r=0.3 = 0.533
F1 for r=0.6 = 0.315
WIoU for r=0.6 = 0.544
F1 for r=0.9 = 0.254
WIoU for r=0.9 = 0.543
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.543
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.203
WIoU for r=0.3 = 0.378
F1 for r=0.6 = 0.150
WIoU for r=0.6 = 0.382
F1 for r=0.9 = 0.120
WIoU for r=0.9 = 0.378
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.376


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.393
Model XAI F1 of binarized graphs for r=0.3 =  0.53422875
Model XAI WIoU of binarized graphs for r=0.3 =  0.45024250000000005
len(reference) = 776
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.36
SUFF++ for r=0.3 class 0 = 0.667 +- 0.183 (in-sample avg dev_std = 0.373)
SUFF++ for r=0.3 class 1 = 0.672 +- 0.183 (in-sample avg dev_std = 0.373)
SUFF++ for r=0.3 class 2 = 0.644 +- 0.183 (in-sample avg dev_std = 0.373)
SUFF++ for r=0.3 all KL = 0.796 +- 0.183 (in-sample avg dev_std = 0.373)
SUFF++ for r=0.3 all L1 = 0.661 +- 0.143 (in-sample avg dev_std = 0.373)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.629
Model XAI F1 of binarized graphs for r=0.6 =  0.5892512500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.59451375
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.612
SUFF++ for r=0.6 class 0 = 0.724 +- 0.250 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 class 1 = 0.829 +- 0.250 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 class 2 = 0.751 +- 0.250 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 all KL = 0.796 +- 0.250 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 all L1 = 0.767 +- 0.211 (in-sample avg dev_std = 0.396)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.796
Model XAI F1 of binarized graphs for r=0.9 =  0.51335875
Model XAI WIoU of binarized graphs for r=0.9 =  0.5974675
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.78
SUFF++ for r=0.9 class 0 = 0.859 +- 0.208 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.9 class 1 = 0.878 +- 0.208 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.9 class 2 = 0.895 +- 0.208 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.9 all KL = 0.887 +- 0.208 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.9 all L1 = 0.877 +- 0.178 (in-sample avg dev_std = 0.301)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.607
Model XAI F1 of binarized graphs for r=0.3 =  0.40136375
Model XAI WIoU of binarized graphs for r=0.3 =  0.53250625
len(reference) = 799
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.556
SUFF++ for r=0.3 class 0 = 0.652 +- 0.206 (in-sample avg dev_std = 0.477)
SUFF++ for r=0.3 class 1 = 0.691 +- 0.206 (in-sample avg dev_std = 0.477)
SUFF++ for r=0.3 class 2 = 0.651 +- 0.206 (in-sample avg dev_std = 0.477)
SUFF++ for r=0.3 all KL = 0.734 +- 0.206 (in-sample avg dev_std = 0.477)
SUFF++ for r=0.3 all L1 = 0.665 +- 0.177 (in-sample avg dev_std = 0.477)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.696
Model XAI F1 of binarized graphs for r=0.6 =  0.3145675
Model XAI WIoU of binarized graphs for r=0.6 =  0.5441199999999999
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.634
SUFF++ for r=0.6 class 0 = 0.702 +- 0.252 (in-sample avg dev_std = 0.422)
SUFF++ for r=0.6 class 1 = 0.758 +- 0.252 (in-sample avg dev_std = 0.422)
SUFF++ for r=0.6 class 2 = 0.748 +- 0.252 (in-sample avg dev_std = 0.422)
SUFF++ for r=0.6 all KL = 0.762 +- 0.252 (in-sample avg dev_std = 0.422)
SUFF++ for r=0.6 all L1 = 0.736 +- 0.216 (in-sample avg dev_std = 0.422)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.772
Model XAI F1 of binarized graphs for r=0.9 =  0.25437
Model XAI WIoU of binarized graphs for r=0.9 =  0.54269
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.747
SUFF++ for r=0.9 class 0 = 0.792 +- 0.221 (in-sample avg dev_std = 0.318)
SUFF++ for r=0.9 class 1 = 0.858 +- 0.221 (in-sample avg dev_std = 0.318)
SUFF++ for r=0.9 class 2 = 0.854 +- 0.221 (in-sample avg dev_std = 0.318)
SUFF++ for r=0.9 all KL = 0.839 +- 0.221 (in-sample avg dev_std = 0.318)
SUFF++ for r=0.9 all L1 = 0.835 +- 0.167 (in-sample avg dev_std = 0.318)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.534
Model XAI F1 of binarized graphs for r=0.3 =  0.20306000000000002
Model XAI WIoU of binarized graphs for r=0.3 =  0.37838750000000004
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.474
SUFF++ for r=0.3 class 0 = 0.549 +- 0.285 (in-sample avg dev_std = 0.581)
SUFF++ for r=0.3 class 1 = 0.553 +- 0.285 (in-sample avg dev_std = 0.581)
SUFF++ for r=0.3 class 2 = 0.605 +- 0.285 (in-sample avg dev_std = 0.581)
SUFF++ for r=0.3 all KL = 0.504 +- 0.285 (in-sample avg dev_std = 0.581)
SUFF++ for r=0.3 all L1 = 0.568 +- 0.185 (in-sample avg dev_std = 0.581)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.565
Model XAI F1 of binarized graphs for r=0.6 =  0.15049125
Model XAI WIoU of binarized graphs for r=0.6 =  0.38237375
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.496
SUFF++ for r=0.6 class 0 = 0.562 +- 0.303 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.6 class 1 = 0.604 +- 0.303 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.6 class 2 = 0.609 +- 0.303 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.6 all KL = 0.575 +- 0.303 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.6 all L1 = 0.591 +- 0.261 (in-sample avg dev_std = 0.423)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.611
Model XAI F1 of binarized graphs for r=0.9 =  0.11995875
Model XAI WIoU of binarized graphs for r=0.9 =  0.37764749999999997
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.587
SUFF++ for r=0.9 class 0 = 0.802 +- 0.258 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.9 class 1 = 0.782 +- 0.258 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.9 class 2 = 0.796 +- 0.258 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.9 all KL = 0.784 +- 0.258 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.9 all L1 = 0.793 +- 0.188 (in-sample avg dev_std = 0.339)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.395
Model XAI F1 of binarized graphs for r=0.3 =  0.53422875
Model XAI WIoU of binarized graphs for r=0.3 =  0.45024250000000005
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.35
NEC for r=0.3 class 0 = 0.362 +- 0.234 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 1 = 0.337 +- 0.234 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 2 = 0.367 +- 0.234 (in-sample avg dev_std = 0.293)
NEC for r=0.3 all KL = 0.22 +- 0.234 (in-sample avg dev_std = 0.293)
NEC for r=0.3 all L1 = 0.356 +- 0.187 (in-sample avg dev_std = 0.293)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.629
Model XAI F1 of binarized graphs for r=0.6 =  0.5892512500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.59451375
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.434
NEC for r=0.6 class 0 = 0.497 +- 0.307 (in-sample avg dev_std = 0.465)
NEC for r=0.6 class 1 = 0.404 +- 0.307 (in-sample avg dev_std = 0.465)
NEC for r=0.6 class 2 = 0.515 +- 0.307 (in-sample avg dev_std = 0.465)
NEC for r=0.6 all KL = 0.463 +- 0.307 (in-sample avg dev_std = 0.465)
NEC for r=0.6 all L1 = 0.473 +- 0.232 (in-sample avg dev_std = 0.465)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.796
Model XAI F1 of binarized graphs for r=0.9 =  0.51335875
Model XAI WIoU of binarized graphs for r=0.9 =  0.5974675
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.533
NEC for r=0.9 class 0 = 0.547 +- 0.270 (in-sample avg dev_std = 0.583)
NEC for r=0.9 class 1 = 0.413 +- 0.270 (in-sample avg dev_std = 0.583)
NEC for r=0.9 class 2 = 0.57 +- 0.270 (in-sample avg dev_std = 0.583)
NEC for r=0.9 all KL = 0.544 +- 0.270 (in-sample avg dev_std = 0.583)
NEC for r=0.9 all L1 = 0.511 +- 0.201 (in-sample avg dev_std = 0.583)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.936
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.5991175000000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.572
NEC for r=1.0 class 0 = 0.574 +- 0.264 (in-sample avg dev_std = 0.633)
NEC for r=1.0 class 1 = 0.393 +- 0.264 (in-sample avg dev_std = 0.633)
NEC for r=1.0 class 2 = 0.589 +- 0.264 (in-sample avg dev_std = 0.633)
NEC for r=1.0 all KL = 0.587 +- 0.264 (in-sample avg dev_std = 0.633)
NEC for r=1.0 all L1 = 0.52 +- 0.197 (in-sample avg dev_std = 0.633)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.606
Model XAI F1 of binarized graphs for r=0.3 =  0.40136375
Model XAI WIoU of binarized graphs for r=0.3 =  0.53250625
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.393
NEC for r=0.3 class 0 = 0.512 +- 0.313 (in-sample avg dev_std = 0.326)
NEC for r=0.3 class 1 = 0.335 +- 0.313 (in-sample avg dev_std = 0.326)
NEC for r=0.3 class 2 = 0.49 +- 0.313 (in-sample avg dev_std = 0.326)
NEC for r=0.3 all KL = 0.361 +- 0.313 (in-sample avg dev_std = 0.326)
NEC for r=0.3 all L1 = 0.445 +- 0.233 (in-sample avg dev_std = 0.326)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.696
Model XAI F1 of binarized graphs for r=0.6 =  0.3145675
Model XAI WIoU of binarized graphs for r=0.6 =  0.5441199999999999
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.492
NEC for r=0.6 class 0 = 0.472 +- 0.295 (in-sample avg dev_std = 0.477)
NEC for r=0.6 class 1 = 0.281 +- 0.295 (in-sample avg dev_std = 0.477)
NEC for r=0.6 class 2 = 0.51 +- 0.295 (in-sample avg dev_std = 0.477)
NEC for r=0.6 all KL = 0.398 +- 0.295 (in-sample avg dev_std = 0.477)
NEC for r=0.6 all L1 = 0.42 +- 0.225 (in-sample avg dev_std = 0.477)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.772
Model XAI F1 of binarized graphs for r=0.9 =  0.25437
Model XAI WIoU of binarized graphs for r=0.9 =  0.54269
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.564
NEC for r=0.9 class 0 = 0.449 +- 0.308 (in-sample avg dev_std = 0.499)
NEC for r=0.9 class 1 = 0.222 +- 0.308 (in-sample avg dev_std = 0.499)
NEC for r=0.9 class 2 = 0.468 +- 0.308 (in-sample avg dev_std = 0.499)
NEC for r=0.9 all KL = 0.392 +- 0.308 (in-sample avg dev_std = 0.499)
NEC for r=0.9 all L1 = 0.379 +- 0.248 (in-sample avg dev_std = 0.499)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.935
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.5428324999999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.587
NEC for r=1.0 class 0 = 0.59 +- 0.299 (in-sample avg dev_std = 0.552)
NEC for r=1.0 class 1 = 0.277 +- 0.299 (in-sample avg dev_std = 0.552)
NEC for r=1.0 class 2 = 0.564 +- 0.299 (in-sample avg dev_std = 0.552)
NEC for r=1.0 all KL = 0.491 +- 0.299 (in-sample avg dev_std = 0.552)
NEC for r=1.0 all L1 = 0.477 +- 0.228 (in-sample avg dev_std = 0.552)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.533
Model XAI F1 of binarized graphs for r=0.3 =  0.20306000000000002
Model XAI WIoU of binarized graphs for r=0.3 =  0.37838750000000004
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.373
NEC for r=0.3 class 0 = 0.447 +- 0.309 (in-sample avg dev_std = 0.329)
NEC for r=0.3 class 1 = 0.332 +- 0.309 (in-sample avg dev_std = 0.329)
NEC for r=0.3 class 2 = 0.412 +- 0.309 (in-sample avg dev_std = 0.329)
NEC for r=0.3 all KL = 0.354 +- 0.309 (in-sample avg dev_std = 0.329)
NEC for r=0.3 all L1 = 0.396 +- 0.268 (in-sample avg dev_std = 0.329)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.565
Model XAI F1 of binarized graphs for r=0.6 =  0.15049125
Model XAI WIoU of binarized graphs for r=0.6 =  0.38237375
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.426
NEC for r=0.6 class 0 = 0.48 +- 0.324 (in-sample avg dev_std = 0.371)
NEC for r=0.6 class 1 = 0.356 +- 0.324 (in-sample avg dev_std = 0.371)
NEC for r=0.6 class 2 = 0.449 +- 0.324 (in-sample avg dev_std = 0.371)
NEC for r=0.6 all KL = 0.402 +- 0.324 (in-sample avg dev_std = 0.371)
NEC for r=0.6 all L1 = 0.427 +- 0.271 (in-sample avg dev_std = 0.371)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.611
Model XAI F1 of binarized graphs for r=0.9 =  0.11995875
Model XAI WIoU of binarized graphs for r=0.9 =  0.37764749999999997
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.454
NEC for r=0.9 class 0 = 0.372 +- 0.287 (in-sample avg dev_std = 0.389)
NEC for r=0.9 class 1 = 0.258 +- 0.287 (in-sample avg dev_std = 0.389)
NEC for r=0.9 class 2 = 0.342 +- 0.287 (in-sample avg dev_std = 0.389)
NEC for r=0.9 all KL = 0.325 +- 0.287 (in-sample avg dev_std = 0.389)
NEC for r=0.9 all L1 = 0.324 +- 0.235 (in-sample avg dev_std = 0.389)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.634
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.3764575
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.48
NEC for r=1.0 class 0 = 0.497 +- 0.303 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 1 = 0.443 +- 0.303 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 2 = 0.495 +- 0.303 (in-sample avg dev_std = 0.385)
NEC for r=1.0 all KL = 0.442 +- 0.303 (in-sample avg dev_std = 0.385)
NEC for r=1.0 all L1 = 0.478 +- 0.210 (in-sample avg dev_std = 0.385)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.78, 0.664, 0.859, 1.0], 'all_L1': [0.642, 0.66, 0.833, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.753, 0.675, 0.855, 1.0], 'all_L1': [0.632, 0.673, 0.826, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.862, 0.802, 0.925, 1.0], 'all_L1': [0.738, 0.765, 0.886, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.788, 0.763, 0.91, 1.0], 'all_L1': [0.669, 0.71, 0.893, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.796, 0.796, 0.887, 1.0], 'all_L1': [0.661, 0.767, 0.877, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.252, 0.568, 0.593, 0.564], 'all_L1': [0.385, 0.542, 0.549, 0.52]}), defaultdict(<class 'list'>, {'all_KL': [0.277, 0.551, 0.57, 0.55], 'all_L1': [0.391, 0.522, 0.541, 0.526]}), defaultdict(<class 'list'>, {'all_KL': [0.179, 0.357, 0.518, 0.501], 'all_L1': [0.306, 0.39, 0.514, 0.496]}), defaultdict(<class 'list'>, {'all_KL': [0.221, 0.383, 0.507, 0.572], 'all_L1': [0.333, 0.422, 0.481, 0.5]}), defaultdict(<class 'list'>, {'all_KL': [0.22, 0.463, 0.544, 0.587], 'all_L1': [0.356, 0.473, 0.511, 0.52]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.767, 0.69, 0.865, 1.0], 'all_L1': [0.692, 0.67, 0.843, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.625, 0.613, 0.818, 1.0], 'all_L1': [0.591, 0.625, 0.763, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.835, 0.814, 0.895, 1.0], 'all_L1': [0.724, 0.765, 0.833, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.81, 0.762, 0.825, 1.0], 'all_L1': [0.719, 0.69, 0.795, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.734, 0.762, 0.839, 1.0], 'all_L1': [0.665, 0.736, 0.835, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.388, 0.457, 0.418, 0.37], 'all_L1': [0.455, 0.473, 0.394, 0.389]}), defaultdict(<class 'list'>, {'all_KL': [0.513, 0.532, 0.456, 0.46], 'all_L1': [0.539, 0.516, 0.469, 0.486]}), defaultdict(<class 'list'>, {'all_KL': [0.308, 0.349, 0.383, 0.369], 'all_L1': [0.42, 0.384, 0.419, 0.405]}), defaultdict(<class 'list'>, {'all_KL': [0.325, 0.328, 0.356, 0.514], 'all_L1': [0.404, 0.396, 0.374, 0.481]}), defaultdict(<class 'list'>, {'all_KL': [0.361, 0.398, 0.392, 0.491], 'all_L1': [0.445, 0.42, 0.379, 0.477]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.681, 0.607, 0.825, 1.0], 'all_L1': [0.614, 0.596, 0.816, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.586, 0.635, 0.958, 1.0], 'all_L1': [0.609, 0.676, 0.924, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.678, 0.724, 0.833, 1.0], 'all_L1': [0.576, 0.692, 0.775, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.765, 0.755, 0.819, 1.0], 'all_L1': [0.666, 0.689, 0.808, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.504, 0.575, 0.784, 1.0], 'all_L1': [0.568, 0.591, 0.793, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.299, 0.372, 0.375, 0.497], 'all_L1': [0.384, 0.435, 0.36, 0.404]}), defaultdict(<class 'list'>, {'all_KL': [0.329, 0.487, 0.146, 0.21], 'all_L1': [0.372, 0.44, 0.166, 0.183]}), defaultdict(<class 'list'>, {'all_KL': [0.29, 0.209, 0.272, 0.284], 'all_L1': [0.414, 0.28, 0.316, 0.372]}), defaultdict(<class 'list'>, {'all_KL': [0.214, 0.199, 0.22, 0.495], 'all_L1': [0.333, 0.296, 0.27, 0.491]}), defaultdict(<class 'list'>, {'all_KL': [0.354, 0.402, 0.325, 0.442], 'all_L1': [0.396, 0.427, 0.324, 0.478]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.668 +- 0.037, 0.715 +- 0.045, 0.863 +- 0.028, 1.000 +- 0.000
suff++ class all_KL  =  0.796 +- 0.036, 0.740 +- 0.059, 0.887 +- 0.027, 1.000 +- 0.000
suff++_acc_int  =  0.370 +- 0.012, 0.584 +- 0.034, 0.786 +- 0.018
nec class all_L1  =  0.354 +- 0.032, 0.470 +- 0.058, 0.519 +- 0.024, 0.512 +- 0.012
nec class all_KL  =  0.230 +- 0.033, 0.464 +- 0.085, 0.546 +- 0.032, 0.555 +- 0.029
nec_acc_int  =  0.339 +- 0.018, 0.435 +- 0.002, 0.515 +- 0.012, 0.559 +- 0.026

Eval split val
suff++ class all_L1  =  0.678 +- 0.048, 0.697 +- 0.049, 0.814 +- 0.030, 1.000 +- 0.000
suff++ class all_KL  =  0.754 +- 0.073, 0.728 +- 0.070, 0.848 +- 0.028, 1.000 +- 0.000
suff++_acc_int  =  0.536 +- 0.013, 0.602 +- 0.030, 0.693 +- 0.034
nec class all_L1  =  0.453 +- 0.047, 0.438 +- 0.050, 0.407 +- 0.035, 0.448 +- 0.042
nec class all_KL  =  0.379 +- 0.073, 0.413 +- 0.074, 0.401 +- 0.034, 0.441 +- 0.061
nec_acc_int  =  0.369 +- 0.016, 0.464 +- 0.025, 0.517 +- 0.027, 0.538 +- 0.031

Eval split test
suff++ class all_L1  =  0.607 +- 0.035, 0.649 +- 0.045, 0.823 +- 0.052, 1.000 +- 0.000
suff++ class all_KL  =  0.643 +- 0.090, 0.659 +- 0.069, 0.844 +- 0.060, 1.000 +- 0.000
suff++_acc_int  =  0.478 +- 0.015, 0.442 +- 0.030, 0.471 +- 0.080
nec class all_L1  =  0.380 +- 0.027, 0.376 +- 0.072, 0.287 +- 0.067, 0.386 +- 0.111
nec class all_KL  =  0.297 +- 0.047, 0.334 +- 0.113, 0.268 +- 0.080, 0.386 +- 0.117
nec_acc_int  =  0.353 +- 0.020, 0.391 +- 0.032, 0.398 +- 0.051, 0.410 +- 0.058


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.511 +- 0.007, 0.592 +- 0.019, 0.691 +- 0.006, 0.756 +- 0.006
Faith. Armon (L1)= 		  =  0.461 +- 0.020, 0.563 +- 0.033, 0.647 +- 0.012, 0.678 +- 0.011
Faith. GMean (L1)= 	  =  0.485 +- 0.011, 0.577 +- 0.025, 0.669 +- 0.007, 0.716 +- 0.008
Faith. Aritm (KL)= 		  =  0.513 +- 0.006, 0.602 +- 0.022, 0.717 +- 0.006, 0.777 +- 0.015
Faith. Armon (KL)= 		  =  0.354 +- 0.037, 0.562 +- 0.050, 0.675 +- 0.017, 0.713 +- 0.025
Faith. GMean (KL)= 	  =  0.426 +- 0.022, 0.581 +- 0.036, 0.696 +- 0.011, 0.745 +- 0.020

Eval split val
Faith. Aritm (L1)= 		  =  0.565 +- 0.007, 0.567 +- 0.013, 0.610 +- 0.014, 0.724 +- 0.021
Faith. Armon (L1)= 		  =  0.539 +- 0.016, 0.534 +- 0.024, 0.541 +- 0.026, 0.617 +- 0.040
Faith. GMean (L1)= 	  =  0.552 +- 0.010, 0.550 +- 0.016, 0.575 +- 0.019, 0.668 +- 0.032
Faith. Aritm (KL)= 		  =  0.567 +- 0.010, 0.571 +- 0.013, 0.625 +- 0.019, 0.720 +- 0.030
Faith. Armon (KL)= 		  =  0.495 +- 0.041, 0.518 +- 0.040, 0.543 +- 0.030, 0.609 +- 0.059
Faith. GMean (KL)= 	  =  0.529 +- 0.023, 0.543 +- 0.025, 0.583 +- 0.024, 0.662 +- 0.046

Eval split test
Faith. Aritm (L1)= 		  =  0.493 +- 0.006, 0.512 +- 0.025, 0.555 +- 0.018, 0.693 +- 0.055
Faith. Armon (L1)= 		  =  0.465 +- 0.013, 0.469 +- 0.053, 0.419 +- 0.075, 0.547 +- 0.126
Faith. GMean (L1)= 	  =  0.479 +- 0.007, 0.490 +- 0.039, 0.480 +- 0.051, 0.613 +- 0.099
Faith. Aritm (KL)= 		  =  0.470 +- 0.024, 0.497 +- 0.033, 0.556 +- 0.026, 0.693 +- 0.059
Faith. Armon (KL)= 		  =  0.399 +- 0.032, 0.425 +- 0.091, 0.397 +- 0.091, 0.546 +- 0.128
Faith. GMean (KL)= 	  =  0.432 +- 0.017, 0.458 +- 0.063, 0.467 +- 0.063, 0.613 +- 0.100
Computed for split load_split = id



Completed in  0:32:05.293952  for LECIvGIN GOODMotif/size



DONE LECI GOODMotif/size

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 13:51:45 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:51:45 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 106...
[0m[1;37mINFO[0m: [1mCheckpoint 106: 
-----------------------------------
Train ACCURACY: 0.9077
Train Loss: 0.4320
ID Validation ACCURACY: 0.9117
ID Validation Loss: 0.4033
ID Test ACCURACY: 0.9047
ID Test Loss: 0.4417
OOD Validation ACCURACY: 0.9277
OOD Validation Loss: 0.3670
OOD Test ACCURACY: 0.9023
OOD Test Loss: 0.4492

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 130...
[0m[1;37mINFO[0m: [1mCheckpoint 130: 
-----------------------------------
Train ACCURACY: 0.8641
Train Loss: 0.4637
ID Validation ACCURACY: 0.8727
ID Validation Loss: 0.4477
ID Test ACCURACY: 0.8610
ID Test Loss: 0.4772
OOD Validation ACCURACY: 0.9313
OOD Validation Loss: 0.3851
OOD Test ACCURACY: 0.7927
OOD Test Loss: 0.6936

[0m[1;37mINFO[0m: [1mChartInfo 0.9047 0.9023 0.8610 0.7927 0.8727 0.9313[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.703
WIoU for r=0.3 = 0.648
F1 for r=0.6 = 0.619
WIoU for r=0.6 = 0.695
F1 for r=0.9 = 0.481
WIoU for r=0.9 = 0.698
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.698
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.668
WIoU for r=0.3 = 0.854
F1 for r=0.6 = 0.409
WIoU for r=0.6 = 0.854
F1 for r=0.9 = 0.295
WIoU for r=0.9 = 0.854
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.854
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.657
WIoU for r=0.3 = 0.530
F1 for r=0.6 = 0.505
WIoU for r=0.6 = 0.469
F1 for r=0.9 = 0.424
WIoU for r=0.9 = 0.451
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.446


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.595
Model XAI F1 of binarized graphs for r=0.3 =  0.7031687500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.64835625
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.494
SUFF++ for r=0.3 class 0 = 0.452 +- 0.254 (in-sample avg dev_std = 0.632)
SUFF++ for r=0.3 class 1 = 0.597 +- 0.254 (in-sample avg dev_std = 0.632)
SUFF++ for r=0.3 class 2 = 0.508 +- 0.254 (in-sample avg dev_std = 0.632)
SUFF++ for r=0.3 all KL = 0.34 +- 0.254 (in-sample avg dev_std = 0.632)
SUFF++ for r=0.3 all L1 = 0.519 +- 0.176 (in-sample avg dev_std = 0.632)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.889
Model XAI F1 of binarized graphs for r=0.6 =  0.61872875
Model XAI WIoU of binarized graphs for r=0.6 =  0.6953875
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.734
SUFF++ for r=0.6 class 0 = 0.565 +- 0.284 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.6 class 1 = 0.654 +- 0.284 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.6 class 2 = 0.66 +- 0.284 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.6 all KL = 0.496 +- 0.284 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.6 all L1 = 0.627 +- 0.196 (in-sample avg dev_std = 0.550)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.923
Model XAI F1 of binarized graphs for r=0.9 =  0.48123875
Model XAI WIoU of binarized graphs for r=0.9 =  0.6979962500000001
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.851
SUFF++ for r=0.9 class 0 = 0.828 +- 0.245 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.9 class 1 = 0.79 +- 0.245 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.9 class 2 = 0.777 +- 0.245 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.9 all KL = 0.804 +- 0.245 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.9 all L1 = 0.799 +- 0.202 (in-sample avg dev_std = 0.315)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.926
Model XAI F1 of binarized graphs for r=0.3 =  0.6684100000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.8543600000000001
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.592
SUFF++ for r=0.3 class 0 = 0.298 +- 0.298 (in-sample avg dev_std = 0.678)
SUFF++ for r=0.3 class 1 = 0.684 +- 0.298 (in-sample avg dev_std = 0.678)
SUFF++ for r=0.3 class 2 = 0.55 +- 0.298 (in-sample avg dev_std = 0.678)
SUFF++ for r=0.3 all KL = 0.318 +- 0.298 (in-sample avg dev_std = 0.678)
SUFF++ for r=0.3 all L1 = 0.509 +- 0.227 (in-sample avg dev_std = 0.678)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.929
Model XAI F1 of binarized graphs for r=0.6 =  0.4094175
Model XAI WIoU of binarized graphs for r=0.6 =  0.8538062500000001
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.676
SUFF++ for r=0.6 class 0 = 0.514 +- 0.215 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.6 class 1 = 0.541 +- 0.215 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.6 class 2 = 0.67 +- 0.215 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.6 all KL = 0.552 +- 0.215 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.6 all L1 = 0.576 +- 0.153 (in-sample avg dev_std = 0.554)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.929
Model XAI F1 of binarized graphs for r=0.9 =  0.29536875
Model XAI WIoU of binarized graphs for r=0.9 =  0.8538050000000001
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.83
SUFF++ for r=0.9 class 0 = 0.762 +- 0.186 (in-sample avg dev_std = 0.340)
SUFF++ for r=0.9 class 1 = 0.706 +- 0.186 (in-sample avg dev_std = 0.340)
SUFF++ for r=0.9 class 2 = 0.789 +- 0.186 (in-sample avg dev_std = 0.340)
SUFF++ for r=0.9 all KL = 0.825 +- 0.186 (in-sample avg dev_std = 0.340)
SUFF++ for r=0.9 all L1 = 0.753 +- 0.147 (in-sample avg dev_std = 0.340)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.676
Model XAI F1 of binarized graphs for r=0.3 =  0.65747625
Model XAI WIoU of binarized graphs for r=0.3 =  0.5303524999999999
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.551
SUFF++ for r=0.3 class 0 = 0.425 +- 0.288 (in-sample avg dev_std = 0.673)
SUFF++ for r=0.3 class 1 = 0.556 +- 0.288 (in-sample avg dev_std = 0.673)
SUFF++ for r=0.3 class 2 = 0.497 +- 0.288 (in-sample avg dev_std = 0.673)
SUFF++ for r=0.3 all KL = 0.28 +- 0.288 (in-sample avg dev_std = 0.673)
SUFF++ for r=0.3 all L1 = 0.494 +- 0.201 (in-sample avg dev_std = 0.673)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.841
Model XAI F1 of binarized graphs for r=0.6 =  0.50526125
Model XAI WIoU of binarized graphs for r=0.6 =  0.4688525
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.717
SUFF++ for r=0.6 class 0 = 0.531 +- 0.303 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.6 class 1 = 0.66 +- 0.303 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.6 class 2 = 0.668 +- 0.303 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.6 all KL = 0.466 +- 0.303 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.6 all L1 = 0.621 +- 0.199 (in-sample avg dev_std = 0.593)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.9
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.45053000000000004
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.846
SUFF++ for r=0.9 class 0 = 0.743 +- 0.148 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.9 class 1 = 0.817 +- 0.148 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.9 class 2 = 0.836 +- 0.148 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.9 all KL = 0.866 +- 0.148 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.9 all L1 = 0.8 +- 0.166 (in-sample avg dev_std = 0.208)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.594
Model XAI F1 of binarized graphs for r=0.3 =  0.7031687500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.64835625
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.372
NEC for r=0.3 class 0 = 0.636 +- 0.219 (in-sample avg dev_std = 0.534)
NEC for r=0.3 class 1 = 0.531 +- 0.219 (in-sample avg dev_std = 0.534)
NEC for r=0.3 class 2 = 0.632 +- 0.219 (in-sample avg dev_std = 0.534)
NEC for r=0.3 all KL = 0.784 +- 0.219 (in-sample avg dev_std = 0.534)
NEC for r=0.3 all L1 = 0.599 +- 0.155 (in-sample avg dev_std = 0.534)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.892
Model XAI F1 of binarized graphs for r=0.6 =  0.61872875
Model XAI WIoU of binarized graphs for r=0.6 =  0.6953875
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.438
NEC for r=0.6 class 0 = 0.612 +- 0.242 (in-sample avg dev_std = 0.579)
NEC for r=0.6 class 1 = 0.621 +- 0.242 (in-sample avg dev_std = 0.579)
NEC for r=0.6 class 2 = 0.614 +- 0.242 (in-sample avg dev_std = 0.579)
NEC for r=0.6 all KL = 0.758 +- 0.242 (in-sample avg dev_std = 0.579)
NEC for r=0.6 all L1 = 0.616 +- 0.136 (in-sample avg dev_std = 0.579)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.921
Model XAI F1 of binarized graphs for r=0.9 =  0.48123875
Model XAI WIoU of binarized graphs for r=0.9 =  0.6979962500000001
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.523
NEC for r=0.9 class 0 = 0.522 +- 0.274 (in-sample avg dev_std = 0.631)
NEC for r=0.9 class 1 = 0.561 +- 0.274 (in-sample avg dev_std = 0.631)
NEC for r=0.9 class 2 = 0.556 +- 0.274 (in-sample avg dev_std = 0.631)
NEC for r=0.9 all KL = 0.668 +- 0.274 (in-sample avg dev_std = 0.631)
NEC for r=0.9 all L1 = 0.546 +- 0.158 (in-sample avg dev_std = 0.631)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.92
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.6979962500000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.537
NEC for r=1.0 class 0 = 0.505 +- 0.281 (in-sample avg dev_std = 0.619)
NEC for r=1.0 class 1 = 0.554 +- 0.281 (in-sample avg dev_std = 0.619)
NEC for r=1.0 class 2 = 0.556 +- 0.281 (in-sample avg dev_std = 0.619)
NEC for r=1.0 all KL = 0.652 +- 0.281 (in-sample avg dev_std = 0.619)
NEC for r=1.0 all L1 = 0.538 +- 0.164 (in-sample avg dev_std = 0.619)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.926
Model XAI F1 of binarized graphs for r=0.3 =  0.6684100000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.8543600000000001
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.386
NEC for r=0.3 class 0 = 0.72 +- 0.124 (in-sample avg dev_std = 0.591)
NEC for r=0.3 class 1 = 0.662 +- 0.124 (in-sample avg dev_std = 0.591)
NEC for r=0.3 class 2 = 0.687 +- 0.124 (in-sample avg dev_std = 0.591)
NEC for r=0.3 all KL = 0.881 +- 0.124 (in-sample avg dev_std = 0.591)
NEC for r=0.3 all L1 = 0.69 +- 0.089 (in-sample avg dev_std = 0.591)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.929
Model XAI F1 of binarized graphs for r=0.6 =  0.4094175
Model XAI WIoU of binarized graphs for r=0.6 =  0.8538062500000001
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.484
NEC for r=0.6 class 0 = 0.603 +- 0.214 (in-sample avg dev_std = 0.599)
NEC for r=0.6 class 1 = 0.573 +- 0.214 (in-sample avg dev_std = 0.599)
NEC for r=0.6 class 2 = 0.568 +- 0.214 (in-sample avg dev_std = 0.599)
NEC for r=0.6 all KL = 0.629 +- 0.214 (in-sample avg dev_std = 0.599)
NEC for r=0.6 all L1 = 0.582 +- 0.118 (in-sample avg dev_std = 0.599)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.929
Model XAI F1 of binarized graphs for r=0.9 =  0.29536875
Model XAI WIoU of binarized graphs for r=0.9 =  0.8538050000000001
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.556
NEC for r=0.9 class 0 = 0.467 +- 0.229 (in-sample avg dev_std = 0.558)
NEC for r=0.9 class 1 = 0.537 +- 0.229 (in-sample avg dev_std = 0.558)
NEC for r=0.9 class 2 = 0.511 +- 0.229 (in-sample avg dev_std = 0.558)
NEC for r=0.9 all KL = 0.487 +- 0.229 (in-sample avg dev_std = 0.558)
NEC for r=0.9 all L1 = 0.505 +- 0.130 (in-sample avg dev_std = 0.558)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.929
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.8538050000000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.567
NEC for r=1.0 class 0 = 0.436 +- 0.224 (in-sample avg dev_std = 0.532)
NEC for r=1.0 class 1 = 0.54 +- 0.224 (in-sample avg dev_std = 0.532)
NEC for r=1.0 class 2 = 0.496 +- 0.224 (in-sample avg dev_std = 0.532)
NEC for r=1.0 all KL = 0.457 +- 0.224 (in-sample avg dev_std = 0.532)
NEC for r=1.0 all L1 = 0.49 +- 0.137 (in-sample avg dev_std = 0.532)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.676
Model XAI F1 of binarized graphs for r=0.3 =  0.65747625
Model XAI WIoU of binarized graphs for r=0.3 =  0.5303524999999999
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.413
NEC for r=0.3 class 0 = 0.639 +- 0.260 (in-sample avg dev_std = 0.670)
NEC for r=0.3 class 1 = 0.595 +- 0.260 (in-sample avg dev_std = 0.670)
NEC for r=0.3 class 2 = 0.67 +- 0.260 (in-sample avg dev_std = 0.670)
NEC for r=0.3 all KL = 0.809 +- 0.260 (in-sample avg dev_std = 0.670)
NEC for r=0.3 all L1 = 0.634 +- 0.187 (in-sample avg dev_std = 0.670)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.841
Model XAI F1 of binarized graphs for r=0.6 =  0.50526125
Model XAI WIoU of binarized graphs for r=0.6 =  0.4688525
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.485
NEC for r=0.6 class 0 = 0.499 +- 0.251 (in-sample avg dev_std = 0.660)
NEC for r=0.6 class 1 = 0.65 +- 0.251 (in-sample avg dev_std = 0.660)
NEC for r=0.6 class 2 = 0.517 +- 0.251 (in-sample avg dev_std = 0.660)
NEC for r=0.6 all KL = 0.712 +- 0.251 (in-sample avg dev_std = 0.660)
NEC for r=0.6 all L1 = 0.557 +- 0.196 (in-sample avg dev_std = 0.660)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.9
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.45053000000000004
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.619
NEC for r=0.9 class 0 = 0.432 +- 0.287 (in-sample avg dev_std = 0.585)
NEC for r=0.9 class 1 = 0.516 +- 0.287 (in-sample avg dev_std = 0.585)
NEC for r=0.9 class 2 = 0.394 +- 0.287 (in-sample avg dev_std = 0.585)
NEC for r=0.9 all KL = 0.527 +- 0.287 (in-sample avg dev_std = 0.585)
NEC for r=0.9 all L1 = 0.448 +- 0.180 (in-sample avg dev_std = 0.585)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.9
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.44623125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.646
NEC for r=1.0 class 0 = 0.411 +- 0.304 (in-sample avg dev_std = 0.607)
NEC for r=1.0 class 1 = 0.512 +- 0.304 (in-sample avg dev_std = 0.607)
NEC for r=1.0 class 2 = 0.349 +- 0.304 (in-sample avg dev_std = 0.607)
NEC for r=1.0 all KL = 0.503 +- 0.304 (in-sample avg dev_std = 0.607)
NEC for r=1.0 all L1 = 0.425 +- 0.187 (in-sample avg dev_std = 0.607)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 13:55:37 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:55:37 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 188...
[0m[1;37mINFO[0m: [1mCheckpoint 188: 
-----------------------------------
Train ACCURACY: 0.9162
Train Loss: 0.4093
ID Validation ACCURACY: 0.9230
ID Validation Loss: 0.3818
ID Test ACCURACY: 0.9110
ID Test Loss: 0.4274
OOD Validation ACCURACY: 0.9130
OOD Validation Loss: 0.4851
OOD Test ACCURACY: 0.8380
OOD Test Loss: 0.4985

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 119...
[0m[1;37mINFO[0m: [1mCheckpoint 119: 
-----------------------------------
Train ACCURACY: 0.8970
Train Loss: 0.4289
ID Validation ACCURACY: 0.9023
ID Validation Loss: 0.4071
ID Test ACCURACY: 0.8917
ID Test Loss: 0.4442
OOD Validation ACCURACY: 0.9293
OOD Validation Loss: 0.4515
OOD Test ACCURACY: 0.8837
OOD Test Loss: 0.4862

[0m[1;37mINFO[0m: [1mChartInfo 0.9110 0.8380 0.8917 0.8837 0.9023 0.9293[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.723
WIoU for r=0.3 = 0.689
F1 for r=0.6 = 0.619
WIoU for r=0.6 = 0.738
F1 for r=0.9 = 0.481
WIoU for r=0.9 = 0.742
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.742
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.668
WIoU for r=0.3 = 0.989
F1 for r=0.6 = 0.409
WIoU for r=0.6 = 0.989
F1 for r=0.9 = 0.295
WIoU for r=0.9 = 0.989
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.989
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.722
WIoU for r=0.3 = 0.763
F1 for r=0.6 = 0.544
WIoU for r=0.6 = 0.748
F1 for r=0.9 = 0.424
WIoU for r=0.9 = 0.738
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.738


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.644
Model XAI F1 of binarized graphs for r=0.3 =  0.72330375
Model XAI WIoU of binarized graphs for r=0.3 =  0.6891325
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.506
SUFF++ for r=0.3 class 0 = 0.455 +- 0.289 (in-sample avg dev_std = 0.598)
SUFF++ for r=0.3 class 1 = 0.618 +- 0.289 (in-sample avg dev_std = 0.598)
SUFF++ for r=0.3 class 2 = 0.526 +- 0.289 (in-sample avg dev_std = 0.598)
SUFF++ for r=0.3 all KL = 0.421 +- 0.289 (in-sample avg dev_std = 0.598)
SUFF++ for r=0.3 all L1 = 0.533 +- 0.199 (in-sample avg dev_std = 0.598)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.901
Model XAI F1 of binarized graphs for r=0.6 =  0.61944
Model XAI WIoU of binarized graphs for r=0.6 =  0.7380074999999999
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.77
SUFF++ for r=0.6 class 0 = 0.583 +- 0.260 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.6 class 1 = 0.754 +- 0.260 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.6 class 2 = 0.692 +- 0.260 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.6 all KL = 0.63 +- 0.260 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.6 all L1 = 0.676 +- 0.199 (in-sample avg dev_std = 0.446)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.931
Model XAI F1 of binarized graphs for r=0.9 =  0.48113
Model XAI WIoU of binarized graphs for r=0.9 =  0.7419687500000001
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.891
SUFF++ for r=0.9 class 0 = 0.812 +- 0.176 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.9 class 1 = 0.826 +- 0.176 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.9 class 2 = 0.873 +- 0.176 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.9 all KL = 0.889 +- 0.176 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.9 all L1 = 0.837 +- 0.167 (in-sample avg dev_std = 0.227)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.928
Model XAI F1 of binarized graphs for r=0.3 =  0.6683025
Model XAI WIoU of binarized graphs for r=0.3 =  0.9887774999999999
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.607
SUFF++ for r=0.3 class 0 = 0.317 +- 0.332 (in-sample avg dev_std = 0.589)
SUFF++ for r=0.3 class 1 = 0.663 +- 0.332 (in-sample avg dev_std = 0.589)
SUFF++ for r=0.3 class 2 = 0.507 +- 0.332 (in-sample avg dev_std = 0.589)
SUFF++ for r=0.3 all KL = 0.363 +- 0.332 (in-sample avg dev_std = 0.589)
SUFF++ for r=0.3 all L1 = 0.494 +- 0.205 (in-sample avg dev_std = 0.589)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.929
Model XAI F1 of binarized graphs for r=0.6 =  0.40867125000000004
Model XAI WIoU of binarized graphs for r=0.6 =  0.9887762499999999
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.72
SUFF++ for r=0.6 class 0 = 0.456 +- 0.229 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 class 1 = 0.596 +- 0.229 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 class 2 = 0.656 +- 0.229 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 all KL = 0.597 +- 0.229 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 all L1 = 0.569 +- 0.143 (in-sample avg dev_std = 0.443)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.925
Model XAI F1 of binarized graphs for r=0.9 =  0.29536875
Model XAI WIoU of binarized graphs for r=0.9 =  0.9887762499999999
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.826
SUFF++ for r=0.9 class 0 = 0.701 +- 0.186 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.9 class 1 = 0.728 +- 0.186 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.9 class 2 = 0.76 +- 0.186 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.9 all KL = 0.83 +- 0.186 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.9 all L1 = 0.73 +- 0.152 (in-sample avg dev_std = 0.283)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.68
Model XAI F1 of binarized graphs for r=0.3 =  0.7222637500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.7625525000000001
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.581
SUFF++ for r=0.3 class 0 = 0.426 +- 0.303 (in-sample avg dev_std = 0.622)
SUFF++ for r=0.3 class 1 = 0.669 +- 0.303 (in-sample avg dev_std = 0.622)
SUFF++ for r=0.3 class 2 = 0.566 +- 0.303 (in-sample avg dev_std = 0.622)
SUFF++ for r=0.3 all KL = 0.46 +- 0.303 (in-sample avg dev_std = 0.622)
SUFF++ for r=0.3 all L1 = 0.556 +- 0.194 (in-sample avg dev_std = 0.622)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.836
Model XAI F1 of binarized graphs for r=0.6 =  0.5438937500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.7480374999999999
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.732
SUFF++ for r=0.6 class 0 = 0.592 +- 0.263 (in-sample avg dev_std = 0.505)
SUFF++ for r=0.6 class 1 = 0.76 +- 0.263 (in-sample avg dev_std = 0.505)
SUFF++ for r=0.6 class 2 = 0.66 +- 0.263 (in-sample avg dev_std = 0.505)
SUFF++ for r=0.6 all KL = 0.65 +- 0.263 (in-sample avg dev_std = 0.505)
SUFF++ for r=0.6 all L1 = 0.672 +- 0.169 (in-sample avg dev_std = 0.505)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.842
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.7378275000000001
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.859
SUFF++ for r=0.9 class 0 = 0.861 +- 0.087 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.9 class 1 = 0.884 +- 0.087 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.9 class 2 = 0.943 +- 0.087 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.9 all KL = 0.941 +- 0.087 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.9 all L1 = 0.896 +- 0.112 (in-sample avg dev_std = 0.193)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.642
Model XAI F1 of binarized graphs for r=0.3 =  0.72330375
Model XAI WIoU of binarized graphs for r=0.3 =  0.6891325
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.33
NEC for r=0.3 class 0 = 0.633 +- 0.290 (in-sample avg dev_std = 0.458)
NEC for r=0.3 class 1 = 0.488 +- 0.290 (in-sample avg dev_std = 0.458)
NEC for r=0.3 class 2 = 0.6 +- 0.290 (in-sample avg dev_std = 0.458)
NEC for r=0.3 all KL = 0.678 +- 0.290 (in-sample avg dev_std = 0.458)
NEC for r=0.3 all L1 = 0.573 +- 0.205 (in-sample avg dev_std = 0.458)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.897
Model XAI F1 of binarized graphs for r=0.6 =  0.61944
Model XAI WIoU of binarized graphs for r=0.6 =  0.7380074999999999
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.438
NEC for r=0.6 class 0 = 0.621 +- 0.288 (in-sample avg dev_std = 0.530)
NEC for r=0.6 class 1 = 0.582 +- 0.288 (in-sample avg dev_std = 0.530)
NEC for r=0.6 class 2 = 0.608 +- 0.288 (in-sample avg dev_std = 0.530)
NEC for r=0.6 all KL = 0.696 +- 0.288 (in-sample avg dev_std = 0.530)
NEC for r=0.6 all L1 = 0.604 +- 0.159 (in-sample avg dev_std = 0.530)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.931
Model XAI F1 of binarized graphs for r=0.9 =  0.48113
Model XAI WIoU of binarized graphs for r=0.9 =  0.7419687500000001
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.548
NEC for r=0.9 class 0 = 0.535 +- 0.292 (in-sample avg dev_std = 0.578)
NEC for r=0.9 class 1 = 0.515 +- 0.292 (in-sample avg dev_std = 0.578)
NEC for r=0.9 class 2 = 0.518 +- 0.292 (in-sample avg dev_std = 0.578)
NEC for r=0.9 all KL = 0.574 +- 0.292 (in-sample avg dev_std = 0.578)
NEC for r=0.9 all L1 = 0.522 +- 0.161 (in-sample avg dev_std = 0.578)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.934
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.7419687500000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.537
NEC for r=1.0 class 0 = 0.534 +- 0.291 (in-sample avg dev_std = 0.566)
NEC for r=1.0 class 1 = 0.525 +- 0.291 (in-sample avg dev_std = 0.566)
NEC for r=1.0 class 2 = 0.522 +- 0.291 (in-sample avg dev_std = 0.566)
NEC for r=1.0 all KL = 0.576 +- 0.291 (in-sample avg dev_std = 0.566)
NEC for r=1.0 all L1 = 0.527 +- 0.162 (in-sample avg dev_std = 0.566)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.928
Model XAI F1 of binarized graphs for r=0.3 =  0.6683025
Model XAI WIoU of binarized graphs for r=0.3 =  0.9887774999999999
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.385
NEC for r=0.3 class 0 = 0.742 +- 0.262 (in-sample avg dev_std = 0.528)
NEC for r=0.3 class 1 = 0.536 +- 0.262 (in-sample avg dev_std = 0.528)
NEC for r=0.3 class 2 = 0.702 +- 0.262 (in-sample avg dev_std = 0.528)
NEC for r=0.3 all KL = 0.775 +- 0.262 (in-sample avg dev_std = 0.528)
NEC for r=0.3 all L1 = 0.661 +- 0.139 (in-sample avg dev_std = 0.528)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.929
Model XAI F1 of binarized graphs for r=0.6 =  0.40867125000000004
Model XAI WIoU of binarized graphs for r=0.6 =  0.9887762499999999
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.517
NEC for r=0.6 class 0 = 0.621 +- 0.251 (in-sample avg dev_std = 0.531)
NEC for r=0.6 class 1 = 0.48 +- 0.251 (in-sample avg dev_std = 0.531)
NEC for r=0.6 class 2 = 0.544 +- 0.251 (in-sample avg dev_std = 0.531)
NEC for r=0.6 all KL = 0.55 +- 0.251 (in-sample avg dev_std = 0.531)
NEC for r=0.6 all L1 = 0.549 +- 0.123 (in-sample avg dev_std = 0.531)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.925
Model XAI F1 of binarized graphs for r=0.9 =  0.29536875
Model XAI WIoU of binarized graphs for r=0.9 =  0.9887762499999999
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.589
NEC for r=0.9 class 0 = 0.504 +- 0.230 (in-sample avg dev_std = 0.496)
NEC for r=0.9 class 1 = 0.438 +- 0.230 (in-sample avg dev_std = 0.496)
NEC for r=0.9 class 2 = 0.488 +- 0.230 (in-sample avg dev_std = 0.496)
NEC for r=0.9 all KL = 0.421 +- 0.230 (in-sample avg dev_std = 0.496)
NEC for r=0.9 all L1 = 0.477 +- 0.116 (in-sample avg dev_std = 0.496)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.915
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.9887762499999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.592
NEC for r=1.0 class 0 = 0.495 +- 0.225 (in-sample avg dev_std = 0.478)
NEC for r=1.0 class 1 = 0.421 +- 0.225 (in-sample avg dev_std = 0.478)
NEC for r=1.0 class 2 = 0.482 +- 0.225 (in-sample avg dev_std = 0.478)
NEC for r=1.0 all KL = 0.394 +- 0.225 (in-sample avg dev_std = 0.478)
NEC for r=1.0 all L1 = 0.466 +- 0.117 (in-sample avg dev_std = 0.478)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.68
Model XAI F1 of binarized graphs for r=0.3 =  0.7222637500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.7625525000000001
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.389
NEC for r=0.3 class 0 = 0.674 +- 0.247 (in-sample avg dev_std = 0.522)
NEC for r=0.3 class 1 = 0.55 +- 0.247 (in-sample avg dev_std = 0.522)
NEC for r=0.3 class 2 = 0.622 +- 0.247 (in-sample avg dev_std = 0.522)
NEC for r=0.3 all KL = 0.705 +- 0.247 (in-sample avg dev_std = 0.522)
NEC for r=0.3 all L1 = 0.614 +- 0.151 (in-sample avg dev_std = 0.522)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.836
Model XAI F1 of binarized graphs for r=0.6 =  0.5438937500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.7480374999999999
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.494
NEC for r=0.6 class 0 = 0.553 +- 0.329 (in-sample avg dev_std = 0.577)
NEC for r=0.6 class 1 = 0.489 +- 0.329 (in-sample avg dev_std = 0.577)
NEC for r=0.6 class 2 = 0.578 +- 0.329 (in-sample avg dev_std = 0.577)
NEC for r=0.6 all KL = 0.585 +- 0.329 (in-sample avg dev_std = 0.577)
NEC for r=0.6 all L1 = 0.539 +- 0.174 (in-sample avg dev_std = 0.577)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.842
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.7378275000000001
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.577
NEC for r=0.9 class 0 = 0.465 +- 0.319 (in-sample avg dev_std = 0.595)
NEC for r=0.9 class 1 = 0.446 +- 0.319 (in-sample avg dev_std = 0.595)
NEC for r=0.9 class 2 = 0.464 +- 0.319 (in-sample avg dev_std = 0.595)
NEC for r=0.9 all KL = 0.495 +- 0.319 (in-sample avg dev_std = 0.595)
NEC for r=0.9 all L1 = 0.458 +- 0.171 (in-sample avg dev_std = 0.595)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.846
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.7378275000000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.586
NEC for r=1.0 class 0 = 0.455 +- 0.317 (in-sample avg dev_std = 0.594)
NEC for r=1.0 class 1 = 0.43 +- 0.317 (in-sample avg dev_std = 0.594)
NEC for r=1.0 class 2 = 0.46 +- 0.317 (in-sample avg dev_std = 0.594)
NEC for r=1.0 all KL = 0.493 +- 0.317 (in-sample avg dev_std = 0.594)
NEC for r=1.0 all L1 = 0.448 +- 0.164 (in-sample avg dev_std = 0.594)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 13:59:26 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 01:59:26 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 171...
[0m[1;37mINFO[0m: [1mCheckpoint 171: 
-----------------------------------
Train ACCURACY: 0.9011
Train Loss: 0.4339
ID Validation ACCURACY: 0.9127
ID Validation Loss: 0.4039
ID Test ACCURACY: 0.9043
ID Test Loss: 0.4420
OOD Validation ACCURACY: 0.9230
OOD Validation Loss: 0.4746
OOD Test ACCURACY: 0.8267
OOD Test Loss: 0.4981

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 143...
[0m[1;37mINFO[0m: [1mCheckpoint 143: 
-----------------------------------
Train ACCURACY: 0.8969
Train Loss: 0.4316
ID Validation ACCURACY: 0.9050
ID Validation Loss: 0.4049
ID Test ACCURACY: 0.8977
ID Test Loss: 0.4367
OOD Validation ACCURACY: 0.9297
OOD Validation Loss: 0.4768
OOD Test ACCURACY: 0.8177
OOD Test Loss: 0.5880

[0m[1;37mINFO[0m: [1mChartInfo 0.9043 0.8267 0.8977 0.8177 0.9050 0.9297[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.721
WIoU for r=0.3 = 0.671
F1 for r=0.6 = 0.619
WIoU for r=0.6 = 0.708
F1 for r=0.9 = 0.480
WIoU for r=0.9 = 0.708
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.708
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.660
WIoU for r=0.3 = 0.969
F1 for r=0.6 = 0.405
WIoU for r=0.6 = 0.969
F1 for r=0.9 = 0.295
WIoU for r=0.9 = 0.969
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.969
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.738
WIoU for r=0.3 = 0.844
F1 for r=0.6 = 0.542
WIoU for r=0.6 = 0.788
F1 for r=0.9 = 0.422
WIoU for r=0.9 = 0.788
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.788


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.679
Model XAI F1 of binarized graphs for r=0.3 =  0.72068
Model XAI WIoU of binarized graphs for r=0.3 =  0.6709037499999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.493
SUFF++ for r=0.3 class 0 = 0.397 +- 0.285 (in-sample avg dev_std = 0.608)
SUFF++ for r=0.3 class 1 = 0.617 +- 0.285 (in-sample avg dev_std = 0.608)
SUFF++ for r=0.3 class 2 = 0.506 +- 0.285 (in-sample avg dev_std = 0.608)
SUFF++ for r=0.3 all KL = 0.403 +- 0.285 (in-sample avg dev_std = 0.608)
SUFF++ for r=0.3 all L1 = 0.507 +- 0.190 (in-sample avg dev_std = 0.608)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  0.61928875
Model XAI WIoU of binarized graphs for r=0.6 =  0.7082999999999999
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.73
SUFF++ for r=0.6 class 0 = 0.52 +- 0.280 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.6 class 1 = 0.703 +- 0.280 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.6 class 2 = 0.707 +- 0.280 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.6 all KL = 0.603 +- 0.280 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.6 all L1 = 0.643 +- 0.219 (in-sample avg dev_std = 0.480)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.915
Model XAI F1 of binarized graphs for r=0.9 =  0.48036874999999996
Model XAI WIoU of binarized graphs for r=0.9 =  0.70813625
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.875
SUFF++ for r=0.9 class 0 = 0.799 +- 0.170 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 class 1 = 0.802 +- 0.170 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 class 2 = 0.864 +- 0.170 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 all KL = 0.875 +- 0.170 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 all L1 = 0.821 +- 0.172 (in-sample avg dev_std = 0.239)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.916
Model XAI F1 of binarized graphs for r=0.3 =  0.66022875
Model XAI WIoU of binarized graphs for r=0.3 =  0.96929875
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.573
SUFF++ for r=0.3 class 0 = 0.293 +- 0.297 (in-sample avg dev_std = 0.613)
SUFF++ for r=0.3 class 1 = 0.597 +- 0.297 (in-sample avg dev_std = 0.613)
SUFF++ for r=0.3 class 2 = 0.559 +- 0.297 (in-sample avg dev_std = 0.613)
SUFF++ for r=0.3 all KL = 0.357 +- 0.297 (in-sample avg dev_std = 0.613)
SUFF++ for r=0.3 all L1 = 0.482 +- 0.198 (in-sample avg dev_std = 0.613)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.92
Model XAI F1 of binarized graphs for r=0.6 =  0.40536874999999994
Model XAI WIoU of binarized graphs for r=0.6 =  0.968555
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.697
SUFF++ for r=0.6 class 0 = 0.427 +- 0.234 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.6 class 1 = 0.595 +- 0.234 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.6 class 2 = 0.679 +- 0.234 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.6 all KL = 0.602 +- 0.234 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.6 all L1 = 0.567 +- 0.160 (in-sample avg dev_std = 0.445)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.921
Model XAI F1 of binarized graphs for r=0.9 =  0.2948675
Model XAI WIoU of binarized graphs for r=0.9 =  0.968555
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.828
SUFF++ for r=0.9 class 0 = 0.704 +- 0.152 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.9 class 1 = 0.678 +- 0.152 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.9 class 2 = 0.83 +- 0.152 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.9 all KL = 0.852 +- 0.152 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.9 all L1 = 0.738 +- 0.144 (in-sample avg dev_std = 0.272)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.582
Model XAI F1 of binarized graphs for r=0.3 =  0.7384787499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.8435512499999999
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.564
SUFF++ for r=0.3 class 0 = 0.391 +- 0.297 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.3 class 1 = 0.654 +- 0.297 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.3 class 2 = 0.562 +- 0.297 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.3 all KL = 0.433 +- 0.297 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.3 all L1 = 0.538 +- 0.196 (in-sample avg dev_std = 0.618)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.812
Model XAI F1 of binarized graphs for r=0.6 =  0.54176625
Model XAI WIoU of binarized graphs for r=0.6 =  0.7881325
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.781
SUFF++ for r=0.6 class 0 = 0.618 +- 0.214 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.6 class 1 = 0.688 +- 0.214 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.6 class 2 = 0.784 +- 0.214 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.6 all KL = 0.689 +- 0.214 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.6 all L1 = 0.697 +- 0.170 (in-sample avg dev_std = 0.424)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.816
Model XAI F1 of binarized graphs for r=0.9 =  0.4221725
Model XAI WIoU of binarized graphs for r=0.9 =  0.78806125
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.842
SUFF++ for r=0.9 class 0 = 0.706 +- 0.144 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.9 class 1 = 0.804 +- 0.144 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.9 class 2 = 0.874 +- 0.144 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.9 all KL = 0.854 +- 0.144 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.9 all L1 = 0.796 +- 0.154 (in-sample avg dev_std = 0.272)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.678
Model XAI F1 of binarized graphs for r=0.3 =  0.72068
Model XAI WIoU of binarized graphs for r=0.3 =  0.6709037499999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.374
NEC for r=0.3 class 0 = 0.66 +- 0.282 (in-sample avg dev_std = 0.485)
NEC for r=0.3 class 1 = 0.492 +- 0.282 (in-sample avg dev_std = 0.485)
NEC for r=0.3 class 2 = 0.545 +- 0.282 (in-sample avg dev_std = 0.485)
NEC for r=0.3 all KL = 0.66 +- 0.282 (in-sample avg dev_std = 0.485)
NEC for r=0.3 all L1 = 0.566 +- 0.207 (in-sample avg dev_std = 0.485)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  0.61928875
Model XAI WIoU of binarized graphs for r=0.6 =  0.7082999999999999
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.463
NEC for r=0.6 class 0 = 0.626 +- 0.288 (in-sample avg dev_std = 0.543)
NEC for r=0.6 class 1 = 0.546 +- 0.288 (in-sample avg dev_std = 0.543)
NEC for r=0.6 class 2 = 0.599 +- 0.288 (in-sample avg dev_std = 0.543)
NEC for r=0.6 all KL = 0.675 +- 0.288 (in-sample avg dev_std = 0.543)
NEC for r=0.6 all L1 = 0.59 +- 0.164 (in-sample avg dev_std = 0.543)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.915
Model XAI F1 of binarized graphs for r=0.9 =  0.48036874999999996
Model XAI WIoU of binarized graphs for r=0.9 =  0.70813625
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.55
NEC for r=0.9 class 0 = 0.556 +- 0.290 (in-sample avg dev_std = 0.581)
NEC for r=0.9 class 1 = 0.502 +- 0.290 (in-sample avg dev_std = 0.581)
NEC for r=0.9 class 2 = 0.526 +- 0.290 (in-sample avg dev_std = 0.581)
NEC for r=0.9 all KL = 0.579 +- 0.290 (in-sample avg dev_std = 0.581)
NEC for r=0.9 all L1 = 0.528 +- 0.161 (in-sample avg dev_std = 0.581)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.92
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.70813625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.557
NEC for r=1.0 class 0 = 0.534 +- 0.289 (in-sample avg dev_std = 0.577)
NEC for r=1.0 class 1 = 0.5 +- 0.289 (in-sample avg dev_std = 0.577)
NEC for r=1.0 class 2 = 0.512 +- 0.289 (in-sample avg dev_std = 0.577)
NEC for r=1.0 all KL = 0.561 +- 0.289 (in-sample avg dev_std = 0.577)
NEC for r=1.0 all L1 = 0.516 +- 0.163 (in-sample avg dev_std = 0.577)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.916
Model XAI F1 of binarized graphs for r=0.3 =  0.66022875
Model XAI WIoU of binarized graphs for r=0.3 =  0.96929875
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.403
NEC for r=0.3 class 0 = 0.714 +- 0.259 (in-sample avg dev_std = 0.501)
NEC for r=0.3 class 1 = 0.543 +- 0.259 (in-sample avg dev_std = 0.501)
NEC for r=0.3 class 2 = 0.692 +- 0.259 (in-sample avg dev_std = 0.501)
NEC for r=0.3 all KL = 0.754 +- 0.259 (in-sample avg dev_std = 0.501)
NEC for r=0.3 all L1 = 0.651 +- 0.133 (in-sample avg dev_std = 0.501)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.92
Model XAI F1 of binarized graphs for r=0.6 =  0.40536874999999994
Model XAI WIoU of binarized graphs for r=0.6 =  0.968555
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.51
NEC for r=0.6 class 0 = 0.619 +- 0.261 (in-sample avg dev_std = 0.504)
NEC for r=0.6 class 1 = 0.453 +- 0.261 (in-sample avg dev_std = 0.504)
NEC for r=0.6 class 2 = 0.551 +- 0.261 (in-sample avg dev_std = 0.504)
NEC for r=0.6 all KL = 0.524 +- 0.261 (in-sample avg dev_std = 0.504)
NEC for r=0.6 all L1 = 0.542 +- 0.135 (in-sample avg dev_std = 0.504)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.921
Model XAI F1 of binarized graphs for r=0.9 =  0.2948675
Model XAI WIoU of binarized graphs for r=0.9 =  0.968555
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.571
NEC for r=0.9 class 0 = 0.527 +- 0.219 (in-sample avg dev_std = 0.479)
NEC for r=0.9 class 1 = 0.432 +- 0.219 (in-sample avg dev_std = 0.479)
NEC for r=0.9 class 2 = 0.456 +- 0.219 (in-sample avg dev_std = 0.479)
NEC for r=0.9 all KL = 0.389 +- 0.219 (in-sample avg dev_std = 0.479)
NEC for r=0.9 all L1 = 0.472 +- 0.122 (in-sample avg dev_std = 0.479)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.921
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.968555
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.591
NEC for r=1.0 class 0 = 0.514 +- 0.212 (in-sample avg dev_std = 0.465)
NEC for r=1.0 class 1 = 0.42 +- 0.212 (in-sample avg dev_std = 0.465)
NEC for r=1.0 class 2 = 0.424 +- 0.212 (in-sample avg dev_std = 0.465)
NEC for r=1.0 all KL = 0.361 +- 0.212 (in-sample avg dev_std = 0.465)
NEC for r=1.0 all L1 = 0.453 +- 0.124 (in-sample avg dev_std = 0.465)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.582
Model XAI F1 of binarized graphs for r=0.3 =  0.7384787499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.8435512499999999
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.401
NEC for r=0.3 class 0 = 0.617 +- 0.324 (in-sample avg dev_std = 0.513)
NEC for r=0.3 class 1 = 0.392 +- 0.324 (in-sample avg dev_std = 0.513)
NEC for r=0.3 class 2 = 0.403 +- 0.324 (in-sample avg dev_std = 0.513)
NEC for r=0.3 all KL = 0.532 +- 0.324 (in-sample avg dev_std = 0.513)
NEC for r=0.3 all L1 = 0.468 +- 0.240 (in-sample avg dev_std = 0.513)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.812
Model XAI F1 of binarized graphs for r=0.6 =  0.54176625
Model XAI WIoU of binarized graphs for r=0.6 =  0.7881325
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.51
NEC for r=0.6 class 0 = 0.593 +- 0.306 (in-sample avg dev_std = 0.602)
NEC for r=0.6 class 1 = 0.5 +- 0.306 (in-sample avg dev_std = 0.602)
NEC for r=0.6 class 2 = 0.568 +- 0.306 (in-sample avg dev_std = 0.602)
NEC for r=0.6 all KL = 0.6 +- 0.306 (in-sample avg dev_std = 0.602)
NEC for r=0.6 all L1 = 0.553 +- 0.171 (in-sample avg dev_std = 0.602)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.816
Model XAI F1 of binarized graphs for r=0.9 =  0.4221725
Model XAI WIoU of binarized graphs for r=0.9 =  0.78806125
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.606
NEC for r=0.9 class 0 = 0.493 +- 0.290 (in-sample avg dev_std = 0.579)
NEC for r=0.9 class 1 = 0.441 +- 0.290 (in-sample avg dev_std = 0.579)
NEC for r=0.9 class 2 = 0.449 +- 0.290 (in-sample avg dev_std = 0.579)
NEC for r=0.9 all KL = 0.475 +- 0.290 (in-sample avg dev_std = 0.579)
NEC for r=0.9 all L1 = 0.461 +- 0.160 (in-sample avg dev_std = 0.579)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.825
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.78806125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.613
NEC for r=1.0 class 0 = 0.484 +- 0.292 (in-sample avg dev_std = 0.598)
NEC for r=1.0 class 1 = 0.423 +- 0.292 (in-sample avg dev_std = 0.598)
NEC for r=1.0 class 2 = 0.432 +- 0.292 (in-sample avg dev_std = 0.598)
NEC for r=1.0 all KL = 0.47 +- 0.292 (in-sample avg dev_std = 0.598)
NEC for r=1.0 all L1 = 0.446 +- 0.165 (in-sample avg dev_std = 0.598)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 14:03:15 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 04/07/2024 02:03:15 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/07/2024 02:03:15 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 02:03:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:03:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:03:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:03:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:03:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:03:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:03:16 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:03:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:03:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:03:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:03:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:03:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:03:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:03:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:03:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:03:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:03:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:03:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:03:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:03:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:03:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:03:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:03:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:03:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:03:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:03:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:03:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:03:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:03:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:03:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:03:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:03:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:03:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:03:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:03:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:03:16 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 134...
[0m[1;37mINFO[0m: [1mCheckpoint 134: 
-----------------------------------
Train ACCURACY: 0.8988
Train Loss: 0.4539
ID Validation ACCURACY: 0.9030
ID Validation Loss: 0.4374
ID Test ACCURACY: 0.8997
ID Test Loss: 0.4667
OOD Validation ACCURACY: 0.9270
OOD Validation Loss: 0.4777
OOD Test ACCURACY: 0.8460
OOD Test Loss: 0.5987

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 137...
[0m[1;37mINFO[0m: [1mCheckpoint 137: 
-----------------------------------
Train ACCURACY: 0.8639
Train Loss: 0.4728
ID Validation ACCURACY: 0.8680
ID Validation Loss: 0.4616
ID Test ACCURACY: 0.8647
ID Test Loss: 0.4806
OOD Validation ACCURACY: 0.9313
OOD Validation Loss: 0.4486
OOD Test ACCURACY: 0.7277
OOD Test Loss: 0.7415

[0m[1;37mINFO[0m: [1mChartInfo 0.8997 0.8460 0.8647 0.7277 0.8680 0.9313[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.727
WIoU for r=0.3 = 0.698
F1 for r=0.6 = 0.623
WIoU for r=0.6 = 0.780
F1 for r=0.9 = 0.481
WIoU for r=0.9 = 0.783
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.783
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.668
WIoU for r=0.3 = 0.989
F1 for r=0.6 = 0.409
WIoU for r=0.6 = 0.989
F1 for r=0.9 = 0.295
WIoU for r=0.9 = 0.989
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.989
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.606
WIoU for r=0.3 = 0.491
F1 for r=0.6 = 0.539
WIoU for r=0.6 = 0.495
F1 for r=0.9 = 0.422
WIoU for r=0.9 = 0.439
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.427


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.63
Model XAI F1 of binarized graphs for r=0.3 =  0.72697375
Model XAI WIoU of binarized graphs for r=0.3 =  0.69803375
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.466
SUFF++ for r=0.3 class 0 = 0.484 +- 0.284 (in-sample avg dev_std = 0.588)
SUFF++ for r=0.3 class 1 = 0.645 +- 0.284 (in-sample avg dev_std = 0.588)
SUFF++ for r=0.3 class 2 = 0.46 +- 0.284 (in-sample avg dev_std = 0.588)
SUFF++ for r=0.3 all KL = 0.428 +- 0.284 (in-sample avg dev_std = 0.588)
SUFF++ for r=0.3 all L1 = 0.53 +- 0.181 (in-sample avg dev_std = 0.588)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.894
Model XAI F1 of binarized graphs for r=0.6 =  0.62260625
Model XAI WIoU of binarized graphs for r=0.6 =  0.7796225
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.71
SUFF++ for r=0.6 class 0 = 0.572 +- 0.277 (in-sample avg dev_std = 0.525)
SUFF++ for r=0.6 class 1 = 0.677 +- 0.277 (in-sample avg dev_std = 0.525)
SUFF++ for r=0.6 class 2 = 0.599 +- 0.277 (in-sample avg dev_std = 0.525)
SUFF++ for r=0.6 all KL = 0.562 +- 0.277 (in-sample avg dev_std = 0.525)
SUFF++ for r=0.6 all L1 = 0.616 +- 0.183 (in-sample avg dev_std = 0.525)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.911
Model XAI F1 of binarized graphs for r=0.9 =  0.48078
Model XAI WIoU of binarized graphs for r=0.9 =  0.7833025
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.851
SUFF++ for r=0.9 class 0 = 0.789 +- 0.201 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.9 class 1 = 0.79 +- 0.201 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.9 class 2 = 0.769 +- 0.201 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.9 all KL = 0.833 +- 0.201 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.9 all L1 = 0.783 +- 0.172 (in-sample avg dev_std = 0.289)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.926
Model XAI F1 of binarized graphs for r=0.3 =  0.6683025
Model XAI WIoU of binarized graphs for r=0.3 =  0.9893199999999999
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.644
SUFF++ for r=0.3 class 0 = 0.369 +- 0.302 (in-sample avg dev_std = 0.638)
SUFF++ for r=0.3 class 1 = 0.637 +- 0.302 (in-sample avg dev_std = 0.638)
SUFF++ for r=0.3 class 2 = 0.524 +- 0.302 (in-sample avg dev_std = 0.638)
SUFF++ for r=0.3 all KL = 0.384 +- 0.302 (in-sample avg dev_std = 0.638)
SUFF++ for r=0.3 all L1 = 0.509 +- 0.179 (in-sample avg dev_std = 0.638)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.93
Model XAI F1 of binarized graphs for r=0.6 =  0.40870874999999995
Model XAI WIoU of binarized graphs for r=0.6 =  0.9893199999999999
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.729
SUFF++ for r=0.6 class 0 = 0.594 +- 0.200 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.6 class 1 = 0.614 +- 0.200 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.6 class 2 = 0.616 +- 0.200 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.6 all KL = 0.666 +- 0.200 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.6 all L1 = 0.608 +- 0.125 (in-sample avg dev_std = 0.437)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.929
Model XAI F1 of binarized graphs for r=0.9 =  0.29536875
Model XAI WIoU of binarized graphs for r=0.9 =  0.9893199999999999
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.782
SUFF++ for r=0.9 class 0 = 0.713 +- 0.183 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 class 1 = 0.762 +- 0.183 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 class 2 = 0.721 +- 0.183 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 all KL = 0.833 +- 0.183 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 all L1 = 0.732 +- 0.161 (in-sample avg dev_std = 0.300)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.466
Model XAI F1 of binarized graphs for r=0.3 =  0.6062337500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.4910975000000001
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.465
SUFF++ for r=0.3 class 0 = 0.524 +- 0.249 (in-sample avg dev_std = 0.607)
SUFF++ for r=0.3 class 1 = 0.529 +- 0.249 (in-sample avg dev_std = 0.607)
SUFF++ for r=0.3 class 2 = 0.532 +- 0.249 (in-sample avg dev_std = 0.607)
SUFF++ for r=0.3 all KL = 0.414 +- 0.249 (in-sample avg dev_std = 0.607)
SUFF++ for r=0.3 all L1 = 0.528 +- 0.174 (in-sample avg dev_std = 0.607)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.749
Model XAI F1 of binarized graphs for r=0.6 =  0.53889875
Model XAI WIoU of binarized graphs for r=0.6 =  0.49522000000000005
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.684
SUFF++ for r=0.6 class 0 = 0.565 +- 0.252 (in-sample avg dev_std = 0.513)
SUFF++ for r=0.6 class 1 = 0.562 +- 0.252 (in-sample avg dev_std = 0.513)
SUFF++ for r=0.6 class 2 = 0.632 +- 0.252 (in-sample avg dev_std = 0.513)
SUFF++ for r=0.6 all KL = 0.527 +- 0.252 (in-sample avg dev_std = 0.513)
SUFF++ for r=0.6 all L1 = 0.587 +- 0.183 (in-sample avg dev_std = 0.513)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.855
Model XAI F1 of binarized graphs for r=0.9 =  0.42220625
Model XAI WIoU of binarized graphs for r=0.9 =  0.43915000000000004
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.8
SUFF++ for r=0.9 class 0 = 0.825 +- 0.197 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 class 1 = 0.624 +- 0.197 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 class 2 = 0.705 +- 0.197 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 all KL = 0.764 +- 0.197 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 all L1 = 0.716 +- 0.162 (in-sample avg dev_std = 0.300)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.63
Model XAI F1 of binarized graphs for r=0.3 =  0.72697375
Model XAI WIoU of binarized graphs for r=0.3 =  0.69803375
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.36
NEC for r=0.3 class 0 = 0.631 +- 0.297 (in-sample avg dev_std = 0.475)
NEC for r=0.3 class 1 = 0.495 +- 0.297 (in-sample avg dev_std = 0.475)
NEC for r=0.3 class 2 = 0.658 +- 0.297 (in-sample avg dev_std = 0.475)
NEC for r=0.3 all KL = 0.686 +- 0.297 (in-sample avg dev_std = 0.475)
NEC for r=0.3 all L1 = 0.594 +- 0.200 (in-sample avg dev_std = 0.475)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.895
Model XAI F1 of binarized graphs for r=0.6 =  0.62260625
Model XAI WIoU of binarized graphs for r=0.6 =  0.7796225
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.457
NEC for r=0.6 class 0 = 0.606 +- 0.283 (in-sample avg dev_std = 0.509)
NEC for r=0.6 class 1 = 0.575 +- 0.283 (in-sample avg dev_std = 0.509)
NEC for r=0.6 class 2 = 0.638 +- 0.283 (in-sample avg dev_std = 0.509)
NEC for r=0.6 all KL = 0.673 +- 0.283 (in-sample avg dev_std = 0.509)
NEC for r=0.6 all L1 = 0.606 +- 0.152 (in-sample avg dev_std = 0.509)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.911
Model XAI F1 of binarized graphs for r=0.9 =  0.48078
Model XAI WIoU of binarized graphs for r=0.9 =  0.7833025
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.511
NEC for r=0.9 class 0 = 0.525 +- 0.286 (in-sample avg dev_std = 0.519)
NEC for r=0.9 class 1 = 0.524 +- 0.286 (in-sample avg dev_std = 0.519)
NEC for r=0.9 class 2 = 0.58 +- 0.286 (in-sample avg dev_std = 0.519)
NEC for r=0.9 all KL = 0.567 +- 0.286 (in-sample avg dev_std = 0.519)
NEC for r=0.9 all L1 = 0.543 +- 0.151 (in-sample avg dev_std = 0.519)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.913
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.7833025
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.529
NEC for r=1.0 class 0 = 0.517 +- 0.288 (in-sample avg dev_std = 0.522)
NEC for r=1.0 class 1 = 0.519 +- 0.288 (in-sample avg dev_std = 0.522)
NEC for r=1.0 class 2 = 0.549 +- 0.288 (in-sample avg dev_std = 0.522)
NEC for r=1.0 all KL = 0.542 +- 0.288 (in-sample avg dev_std = 0.522)
NEC for r=1.0 all L1 = 0.528 +- 0.152 (in-sample avg dev_std = 0.522)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.926
Model XAI F1 of binarized graphs for r=0.3 =  0.6683025
Model XAI WIoU of binarized graphs for r=0.3 =  0.9893199999999999
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.384
NEC for r=0.3 class 0 = 0.729 +- 0.210 (in-sample avg dev_std = 0.547)
NEC for r=0.3 class 1 = 0.59 +- 0.210 (in-sample avg dev_std = 0.547)
NEC for r=0.3 class 2 = 0.679 +- 0.210 (in-sample avg dev_std = 0.547)
NEC for r=0.3 all KL = 0.789 +- 0.210 (in-sample avg dev_std = 0.547)
NEC for r=0.3 all L1 = 0.667 +- 0.111 (in-sample avg dev_std = 0.547)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.93
Model XAI F1 of binarized graphs for r=0.6 =  0.40870874999999995
Model XAI WIoU of binarized graphs for r=0.6 =  0.9893199999999999
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.51
NEC for r=0.6 class 0 = 0.577 +- 0.237 (in-sample avg dev_std = 0.533)
NEC for r=0.6 class 1 = 0.497 +- 0.237 (in-sample avg dev_std = 0.533)
NEC for r=0.6 class 2 = 0.545 +- 0.237 (in-sample avg dev_std = 0.533)
NEC for r=0.6 all KL = 0.519 +- 0.237 (in-sample avg dev_std = 0.533)
NEC for r=0.6 all L1 = 0.54 +- 0.119 (in-sample avg dev_std = 0.533)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.929
Model XAI F1 of binarized graphs for r=0.9 =  0.29536875
Model XAI WIoU of binarized graphs for r=0.9 =  0.9893199999999999
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.565
NEC for r=0.9 class 0 = 0.466 +- 0.217 (in-sample avg dev_std = 0.475)
NEC for r=0.9 class 1 = 0.448 +- 0.217 (in-sample avg dev_std = 0.475)
NEC for r=0.9 class 2 = 0.509 +- 0.217 (in-sample avg dev_std = 0.475)
NEC for r=0.9 all KL = 0.396 +- 0.217 (in-sample avg dev_std = 0.475)
NEC for r=0.9 all L1 = 0.475 +- 0.121 (in-sample avg dev_std = 0.475)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.929
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.9893199999999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.572
NEC for r=1.0 class 0 = 0.436 +- 0.209 (in-sample avg dev_std = 0.449)
NEC for r=1.0 class 1 = 0.415 +- 0.209 (in-sample avg dev_std = 0.449)
NEC for r=1.0 class 2 = 0.496 +- 0.209 (in-sample avg dev_std = 0.449)
NEC for r=1.0 all KL = 0.353 +- 0.209 (in-sample avg dev_std = 0.449)
NEC for r=1.0 all L1 = 0.449 +- 0.121 (in-sample avg dev_std = 0.449)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.466
Model XAI F1 of binarized graphs for r=0.3 =  0.6062337500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.4910975000000001
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.438
NEC for r=0.3 class 0 = 0.636 +- 0.279 (in-sample avg dev_std = 0.625)
NEC for r=0.3 class 1 = 0.511 +- 0.279 (in-sample avg dev_std = 0.625)
NEC for r=0.3 class 2 = 0.484 +- 0.279 (in-sample avg dev_std = 0.625)
NEC for r=0.3 all KL = 0.667 +- 0.279 (in-sample avg dev_std = 0.625)
NEC for r=0.3 all L1 = 0.542 +- 0.206 (in-sample avg dev_std = 0.625)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.749
Model XAI F1 of binarized graphs for r=0.6 =  0.53889875
Model XAI WIoU of binarized graphs for r=0.6 =  0.49522000000000005
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.462
NEC for r=0.6 class 0 = 0.559 +- 0.266 (in-sample avg dev_std = 0.599)
NEC for r=0.6 class 1 = 0.624 +- 0.266 (in-sample avg dev_std = 0.599)
NEC for r=0.6 class 2 = 0.603 +- 0.266 (in-sample avg dev_std = 0.599)
NEC for r=0.6 all KL = 0.681 +- 0.266 (in-sample avg dev_std = 0.599)
NEC for r=0.6 all L1 = 0.596 +- 0.162 (in-sample avg dev_std = 0.599)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.855
Model XAI F1 of binarized graphs for r=0.9 =  0.42220625
Model XAI WIoU of binarized graphs for r=0.9 =  0.43915000000000004
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.582
NEC for r=0.9 class 0 = 0.41 +- 0.265 (in-sample avg dev_std = 0.543)
NEC for r=0.9 class 1 = 0.518 +- 0.265 (in-sample avg dev_std = 0.543)
NEC for r=0.9 class 2 = 0.489 +- 0.265 (in-sample avg dev_std = 0.543)
NEC for r=0.9 all KL = 0.505 +- 0.265 (in-sample avg dev_std = 0.543)
NEC for r=0.9 all L1 = 0.473 +- 0.144 (in-sample avg dev_std = 0.543)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.858
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.42748125000000003
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.603
NEC for r=1.0 class 0 = 0.384 +- 0.250 (in-sample avg dev_std = 0.534)
NEC for r=1.0 class 1 = 0.5 +- 0.250 (in-sample avg dev_std = 0.534)
NEC for r=1.0 class 2 = 0.471 +- 0.250 (in-sample avg dev_std = 0.534)
NEC for r=1.0 all KL = 0.469 +- 0.250 (in-sample avg dev_std = 0.534)
NEC for r=1.0 all L1 = 0.453 +- 0.142 (in-sample avg dev_std = 0.534)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 14:07:05 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:07:05 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 150...
[0m[1;37mINFO[0m: [1mCheckpoint 150: 
-----------------------------------
Train ACCURACY: 0.9096
Train Loss: 0.4091
ID Validation ACCURACY: 0.9127
ID Validation Loss: 0.3875
ID Test ACCURACY: 0.9030
ID Test Loss: 0.4331
OOD Validation ACCURACY: 0.9240
OOD Validation Loss: 0.4585
OOD Test ACCURACY: 0.8997
OOD Test Loss: 0.4258

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 109...
[0m[1;37mINFO[0m: [1mCheckpoint 109: 
-----------------------------------
Train ACCURACY: 0.8893
Train Loss: 0.4702
ID Validation ACCURACY: 0.8970
ID Validation Loss: 0.4634
ID Test ACCURACY: 0.8937
ID Test Loss: 0.4939
OOD Validation ACCURACY: 0.9293
OOD Validation Loss: 0.4938
OOD Test ACCURACY: 0.8903
OOD Test Loss: 0.4810

[0m[1;37mINFO[0m: [1mChartInfo 0.9030 0.8997 0.8937 0.8903 0.8970 0.9293[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.701
WIoU for r=0.3 = 0.665
F1 for r=0.6 = 0.621
WIoU for r=0.6 = 0.766
F1 for r=0.9 = 0.481
WIoU for r=0.9 = 0.763
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.763
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.660
WIoU for r=0.3 = 0.994
F1 for r=0.6 = 0.405
WIoU for r=0.6 = 0.994
F1 for r=0.9 = 0.295
WIoU for r=0.9 = 0.994
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.994
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.754
WIoU for r=0.3 = 0.700
F1 for r=0.6 = 0.563
WIoU for r=0.6 = 0.683
F1 for r=0.9 = 0.423
WIoU for r=0.9 = 0.679
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.679


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.506
Model XAI F1 of binarized graphs for r=0.3 =  0.70054
Model XAI WIoU of binarized graphs for r=0.3 =  0.6645574999999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.416
SUFF++ for r=0.3 class 0 = 0.45 +- 0.261 (in-sample avg dev_std = 0.594)
SUFF++ for r=0.3 class 1 = 0.53 +- 0.261 (in-sample avg dev_std = 0.594)
SUFF++ for r=0.3 class 2 = 0.523 +- 0.261 (in-sample avg dev_std = 0.594)
SUFF++ for r=0.3 all KL = 0.421 +- 0.261 (in-sample avg dev_std = 0.594)
SUFF++ for r=0.3 all L1 = 0.501 +- 0.168 (in-sample avg dev_std = 0.594)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.885
Model XAI F1 of binarized graphs for r=0.6 =  0.6206425
Model XAI WIoU of binarized graphs for r=0.6 =  0.766305
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.685
SUFF++ for r=0.6 class 0 = 0.479 +- 0.283 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.6 class 1 = 0.638 +- 0.283 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.6 class 2 = 0.68 +- 0.283 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.6 all KL = 0.557 +- 0.283 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.6 all L1 = 0.599 +- 0.200 (in-sample avg dev_std = 0.532)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.918
Model XAI F1 of binarized graphs for r=0.9 =  0.48080124999999996
Model XAI WIoU of binarized graphs for r=0.9 =  0.76308875
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.852
SUFF++ for r=0.9 class 0 = 0.75 +- 0.194 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 1 = 0.821 +- 0.194 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 2 = 0.809 +- 0.194 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 all KL = 0.836 +- 0.194 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 all L1 = 0.794 +- 0.169 (in-sample avg dev_std = 0.276)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.875
Model XAI F1 of binarized graphs for r=0.3 =  0.6601137499999998
Model XAI WIoU of binarized graphs for r=0.3 =  0.99426
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.519
SUFF++ for r=0.3 class 0 = 0.32 +- 0.253 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.3 class 1 = 0.481 +- 0.253 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.3 class 2 = 0.686 +- 0.253 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.3 all KL = 0.432 +- 0.253 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.3 all L1 = 0.496 +- 0.206 (in-sample avg dev_std = 0.567)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.896
Model XAI F1 of binarized graphs for r=0.6 =  0.40472250000000004
Model XAI WIoU of binarized graphs for r=0.6 =  0.9941675000000001
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.624
SUFF++ for r=0.6 class 0 = 0.453 +- 0.206 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.6 class 1 = 0.571 +- 0.206 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.6 class 2 = 0.741 +- 0.206 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.6 all KL = 0.667 +- 0.206 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.6 all L1 = 0.589 +- 0.170 (in-sample avg dev_std = 0.426)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.921
Model XAI F1 of binarized graphs for r=0.9 =  0.29473
Model XAI WIoU of binarized graphs for r=0.9 =  0.9941437500000001
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.857
SUFF++ for r=0.9 class 0 = 0.732 +- 0.113 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.9 class 1 = 0.799 +- 0.113 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.9 class 2 = 0.81 +- 0.113 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.9 all KL = 0.889 +- 0.113 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.9 all L1 = 0.78 +- 0.110 (in-sample avg dev_std = 0.273)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.539
Model XAI F1 of binarized graphs for r=0.3 =  0.75380875
Model XAI WIoU of binarized graphs for r=0.3 =  0.69999875
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.512
SUFF++ for r=0.3 class 0 = 0.361 +- 0.300 (in-sample avg dev_std = 0.608)
SUFF++ for r=0.3 class 1 = 0.488 +- 0.300 (in-sample avg dev_std = 0.608)
SUFF++ for r=0.3 class 2 = 0.531 +- 0.300 (in-sample avg dev_std = 0.608)
SUFF++ for r=0.3 all KL = 0.363 +- 0.300 (in-sample avg dev_std = 0.608)
SUFF++ for r=0.3 all L1 = 0.461 +- 0.217 (in-sample avg dev_std = 0.608)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.875
Model XAI F1 of binarized graphs for r=0.6 =  0.56255375
Model XAI WIoU of binarized graphs for r=0.6 =  0.6830687499999999
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.656
SUFF++ for r=0.6 class 0 = 0.5 +- 0.255 (in-sample avg dev_std = 0.540)
SUFF++ for r=0.6 class 1 = 0.566 +- 0.255 (in-sample avg dev_std = 0.540)
SUFF++ for r=0.6 class 2 = 0.732 +- 0.255 (in-sample avg dev_std = 0.540)
SUFF++ for r=0.6 all KL = 0.573 +- 0.255 (in-sample avg dev_std = 0.540)
SUFF++ for r=0.6 all L1 = 0.6 +- 0.174 (in-sample avg dev_std = 0.540)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.906
Model XAI F1 of binarized graphs for r=0.9 =  0.4234712500000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.678605
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.826
SUFF++ for r=0.9 class 0 = 0.711 +- 0.141 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 class 1 = 0.697 +- 0.141 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 class 2 = 0.847 +- 0.141 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 all KL = 0.841 +- 0.141 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 all L1 = 0.752 +- 0.163 (in-sample avg dev_std = 0.248)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.496
Model XAI F1 of binarized graphs for r=0.3 =  0.70054
Model XAI WIoU of binarized graphs for r=0.3 =  0.6645574999999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.346
NEC for r=0.3 class 0 = 0.603 +- 0.264 (in-sample avg dev_std = 0.512)
NEC for r=0.3 class 1 = 0.563 +- 0.264 (in-sample avg dev_std = 0.512)
NEC for r=0.3 class 2 = 0.587 +- 0.264 (in-sample avg dev_std = 0.512)
NEC for r=0.3 all KL = 0.667 +- 0.264 (in-sample avg dev_std = 0.512)
NEC for r=0.3 all L1 = 0.585 +- 0.159 (in-sample avg dev_std = 0.512)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.885
Model XAI F1 of binarized graphs for r=0.6 =  0.6206425
Model XAI WIoU of binarized graphs for r=0.6 =  0.766305
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.446
NEC for r=0.6 class 0 = 0.611 +- 0.279 (in-sample avg dev_std = 0.531)
NEC for r=0.6 class 1 = 0.602 +- 0.279 (in-sample avg dev_std = 0.531)
NEC for r=0.6 class 2 = 0.563 +- 0.279 (in-sample avg dev_std = 0.531)
NEC for r=0.6 all KL = 0.658 +- 0.279 (in-sample avg dev_std = 0.531)
NEC for r=0.6 all L1 = 0.592 +- 0.160 (in-sample avg dev_std = 0.531)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.918
Model XAI F1 of binarized graphs for r=0.9 =  0.48080124999999996
Model XAI WIoU of binarized graphs for r=0.9 =  0.76308875
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.535
NEC for r=0.9 class 0 = 0.552 +- 0.280 (in-sample avg dev_std = 0.555)
NEC for r=0.9 class 1 = 0.498 +- 0.280 (in-sample avg dev_std = 0.555)
NEC for r=0.9 class 2 = 0.529 +- 0.280 (in-sample avg dev_std = 0.555)
NEC for r=0.9 all KL = 0.557 +- 0.280 (in-sample avg dev_std = 0.555)
NEC for r=0.9 all L1 = 0.526 +- 0.162 (in-sample avg dev_std = 0.555)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.921
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.76308875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.551
NEC for r=1.0 class 0 = 0.529 +- 0.287 (in-sample avg dev_std = 0.534)
NEC for r=1.0 class 1 = 0.481 +- 0.287 (in-sample avg dev_std = 0.534)
NEC for r=1.0 class 2 = 0.524 +- 0.287 (in-sample avg dev_std = 0.534)
NEC for r=1.0 all KL = 0.527 +- 0.287 (in-sample avg dev_std = 0.534)
NEC for r=1.0 all L1 = 0.511 +- 0.172 (in-sample avg dev_std = 0.534)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.875
Model XAI F1 of binarized graphs for r=0.3 =  0.6601137499999998
Model XAI WIoU of binarized graphs for r=0.3 =  0.99426
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.342
NEC for r=0.3 class 0 = 0.708 +- 0.200 (in-sample avg dev_std = 0.502)
NEC for r=0.3 class 1 = 0.702 +- 0.200 (in-sample avg dev_std = 0.502)
NEC for r=0.3 class 2 = 0.534 +- 0.200 (in-sample avg dev_std = 0.502)
NEC for r=0.3 all KL = 0.728 +- 0.200 (in-sample avg dev_std = 0.502)
NEC for r=0.3 all L1 = 0.648 +- 0.140 (in-sample avg dev_std = 0.502)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.896
Model XAI F1 of binarized graphs for r=0.6 =  0.40472250000000004
Model XAI WIoU of binarized graphs for r=0.6 =  0.9941675000000001
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.453
NEC for r=0.6 class 0 = 0.625 +- 0.213 (in-sample avg dev_std = 0.502)
NEC for r=0.6 class 1 = 0.544 +- 0.213 (in-sample avg dev_std = 0.502)
NEC for r=0.6 class 2 = 0.451 +- 0.213 (in-sample avg dev_std = 0.502)
NEC for r=0.6 all KL = 0.496 +- 0.213 (in-sample avg dev_std = 0.502)
NEC for r=0.6 all L1 = 0.54 +- 0.138 (in-sample avg dev_std = 0.502)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.921
Model XAI F1 of binarized graphs for r=0.9 =  0.29473
Model XAI WIoU of binarized graphs for r=0.9 =  0.9941437500000001
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.53
NEC for r=0.9 class 0 = 0.502 +- 0.190 (in-sample avg dev_std = 0.468)
NEC for r=0.9 class 1 = 0.485 +- 0.190 (in-sample avg dev_std = 0.468)
NEC for r=0.9 class 2 = 0.435 +- 0.190 (in-sample avg dev_std = 0.468)
NEC for r=0.9 all KL = 0.377 +- 0.190 (in-sample avg dev_std = 0.468)
NEC for r=0.9 all L1 = 0.474 +- 0.115 (in-sample avg dev_std = 0.468)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.925
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.9941437500000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.572
NEC for r=1.0 class 0 = 0.466 +- 0.185 (in-sample avg dev_std = 0.441)
NEC for r=1.0 class 1 = 0.448 +- 0.185 (in-sample avg dev_std = 0.441)
NEC for r=1.0 class 2 = 0.427 +- 0.185 (in-sample avg dev_std = 0.441)
NEC for r=1.0 all KL = 0.328 +- 0.185 (in-sample avg dev_std = 0.441)
NEC for r=1.0 all L1 = 0.447 +- 0.115 (in-sample avg dev_std = 0.441)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.539
Model XAI F1 of binarized graphs for r=0.3 =  0.75380875
Model XAI WIoU of binarized graphs for r=0.3 =  0.69999875
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.403
NEC for r=0.3 class 0 = 0.655 +- 0.198 (in-sample avg dev_std = 0.566)
NEC for r=0.3 class 1 = 0.638 +- 0.198 (in-sample avg dev_std = 0.566)
NEC for r=0.3 class 2 = 0.597 +- 0.198 (in-sample avg dev_std = 0.566)
NEC for r=0.3 all KL = 0.763 +- 0.198 (in-sample avg dev_std = 0.566)
NEC for r=0.3 all L1 = 0.63 +- 0.132 (in-sample avg dev_std = 0.566)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.875
Model XAI F1 of binarized graphs for r=0.6 =  0.56255375
Model XAI WIoU of binarized graphs for r=0.6 =  0.6830687499999999
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.5
NEC for r=0.6 class 0 = 0.57 +- 0.262 (in-sample avg dev_std = 0.547)
NEC for r=0.6 class 1 = 0.536 +- 0.262 (in-sample avg dev_std = 0.547)
NEC for r=0.6 class 2 = 0.493 +- 0.262 (in-sample avg dev_std = 0.547)
NEC for r=0.6 all KL = 0.578 +- 0.262 (in-sample avg dev_std = 0.547)
NEC for r=0.6 all L1 = 0.533 +- 0.156 (in-sample avg dev_std = 0.547)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.906
Model XAI F1 of binarized graphs for r=0.9 =  0.4234712500000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.678605
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.597
NEC for r=0.9 class 0 = 0.472 +- 0.275 (in-sample avg dev_std = 0.551)
NEC for r=0.9 class 1 = 0.448 +- 0.275 (in-sample avg dev_std = 0.551)
NEC for r=0.9 class 2 = 0.438 +- 0.275 (in-sample avg dev_std = 0.551)
NEC for r=0.9 all KL = 0.448 +- 0.275 (in-sample avg dev_std = 0.551)
NEC for r=0.9 all L1 = 0.452 +- 0.152 (in-sample avg dev_std = 0.551)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.904
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.678605
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.601
NEC for r=1.0 class 0 = 0.474 +- 0.268 (in-sample avg dev_std = 0.543)
NEC for r=1.0 class 1 = 0.451 +- 0.268 (in-sample avg dev_std = 0.543)
NEC for r=1.0 class 2 = 0.414 +- 0.268 (in-sample avg dev_std = 0.543)
NEC for r=1.0 all KL = 0.439 +- 0.268 (in-sample avg dev_std = 0.543)
NEC for r=1.0 all L1 = 0.446 +- 0.148 (in-sample avg dev_std = 0.543)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.34, 0.496, 0.804, 1.0], 'all_L1': [0.519, 0.627, 0.799, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.421, 0.63, 0.889, 1.0], 'all_L1': [0.533, 0.676, 0.837, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.403, 0.603, 0.875, 1.0], 'all_L1': [0.507, 0.643, 0.821, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.428, 0.562, 0.833, 1.0], 'all_L1': [0.53, 0.616, 0.783, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.421, 0.557, 0.836, 1.0], 'all_L1': [0.501, 0.599, 0.794, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.784, 0.758, 0.668, 0.652], 'all_L1': [0.599, 0.616, 0.546, 0.538]}), defaultdict(<class 'list'>, {'all_KL': [0.678, 0.696, 0.574, 0.576], 'all_L1': [0.573, 0.604, 0.522, 0.527]}), defaultdict(<class 'list'>, {'all_KL': [0.66, 0.675, 0.579, 0.561], 'all_L1': [0.566, 0.59, 0.528, 0.516]}), defaultdict(<class 'list'>, {'all_KL': [0.686, 0.673, 0.567, 0.542], 'all_L1': [0.594, 0.606, 0.543, 0.528]}), defaultdict(<class 'list'>, {'all_KL': [0.667, 0.658, 0.557, 0.527], 'all_L1': [0.585, 0.592, 0.526, 0.511]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.318, 0.552, 0.825, 1.0], 'all_L1': [0.509, 0.576, 0.753, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.363, 0.597, 0.83, 1.0], 'all_L1': [0.494, 0.569, 0.73, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.357, 0.602, 0.852, 1.0], 'all_L1': [0.482, 0.567, 0.738, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.384, 0.666, 0.833, 1.0], 'all_L1': [0.509, 0.608, 0.732, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.432, 0.667, 0.889, 1.0], 'all_L1': [0.496, 0.589, 0.78, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.881, 0.629, 0.487, 0.457], 'all_L1': [0.69, 0.582, 0.505, 0.49]}), defaultdict(<class 'list'>, {'all_KL': [0.775, 0.55, 0.421, 0.394], 'all_L1': [0.661, 0.549, 0.477, 0.466]}), defaultdict(<class 'list'>, {'all_KL': [0.754, 0.524, 0.389, 0.361], 'all_L1': [0.651, 0.542, 0.472, 0.453]}), defaultdict(<class 'list'>, {'all_KL': [0.789, 0.519, 0.396, 0.353], 'all_L1': [0.667, 0.54, 0.475, 0.449]}), defaultdict(<class 'list'>, {'all_KL': [0.728, 0.496, 0.377, 0.328], 'all_L1': [0.648, 0.54, 0.474, 0.447]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.28, 0.466, 0.866, 1.0], 'all_L1': [0.494, 0.621, 0.8, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.46, 0.65, 0.941, 1.0], 'all_L1': [0.556, 0.672, 0.896, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.433, 0.689, 0.854, 1.0], 'all_L1': [0.538, 0.697, 0.796, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.414, 0.527, 0.764, 1.0], 'all_L1': [0.528, 0.587, 0.716, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.363, 0.573, 0.841, 1.0], 'all_L1': [0.461, 0.6, 0.752, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.809, 0.712, 0.527, 0.503], 'all_L1': [0.634, 0.557, 0.448, 0.425]}), defaultdict(<class 'list'>, {'all_KL': [0.705, 0.585, 0.495, 0.493], 'all_L1': [0.614, 0.539, 0.458, 0.448]}), defaultdict(<class 'list'>, {'all_KL': [0.532, 0.6, 0.475, 0.47], 'all_L1': [0.468, 0.553, 0.461, 0.446]}), defaultdict(<class 'list'>, {'all_KL': [0.667, 0.681, 0.505, 0.469], 'all_L1': [0.542, 0.596, 0.473, 0.453]}), defaultdict(<class 'list'>, {'all_KL': [0.763, 0.578, 0.448, 0.439], 'all_L1': [0.63, 0.533, 0.452, 0.446]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.518 +- 0.012, 0.632 +- 0.026, 0.807 +- 0.020, 1.000 +- 0.000
suff++ class all_KL  =  0.403 +- 0.032, 0.570 +- 0.046, 0.847 +- 0.031, 1.000 +- 0.000
suff++_acc_int  =  0.475 +- 0.032, 0.726 +- 0.028, 0.864 +- 0.016
nec class all_L1  =  0.583 +- 0.012, 0.602 +- 0.010, 0.533 +- 0.010, 0.524 +- 0.010
nec class all_KL  =  0.695 +- 0.045, 0.692 +- 0.035, 0.589 +- 0.040, 0.572 +- 0.043
nec_acc_int  =  0.356 +- 0.017, 0.449 +- 0.010, 0.533 +- 0.015, 0.542 +- 0.010

Eval split val
suff++ class all_L1  =  0.498 +- 0.010, 0.582 +- 0.015, 0.747 +- 0.019, 1.000 +- 0.000
suff++ class all_KL  =  0.371 +- 0.037, 0.617 +- 0.044, 0.846 +- 0.023, 1.000 +- 0.000
suff++_acc_int  =  0.587 +- 0.041, 0.689 +- 0.037, 0.824 +- 0.024
nec class all_L1  =  0.663 +- 0.015, 0.551 +- 0.016, 0.481 +- 0.012, 0.461 +- 0.016
nec class all_KL  =  0.785 +- 0.052, 0.544 +- 0.046, 0.414 +- 0.039, 0.379 +- 0.045
nec_acc_int  =  0.380 +- 0.020, 0.495 +- 0.024, 0.562 +- 0.019, 0.579 +- 0.010

Eval split test
suff++ class all_L1  =  0.515 +- 0.034, 0.635 +- 0.042, 0.792 +- 0.060, 1.000 +- 0.000
suff++ class all_KL  =  0.390 +- 0.063, 0.581 +- 0.081, 0.853 +- 0.057, 1.000 +- 0.000
suff++_acc_int  =  0.534 +- 0.042, 0.714 +- 0.043, 0.835 +- 0.020
nec class all_L1  =  0.578 +- 0.064, 0.556 +- 0.022, 0.458 +- 0.009, 0.444 +- 0.010
nec class all_KL  =  0.695 +- 0.095, 0.631 +- 0.055, 0.490 +- 0.027, 0.475 +- 0.022
nec_acc_int  =  0.409 +- 0.016, 0.490 +- 0.016, 0.596 +- 0.016, 0.610 +- 0.020


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.551 +- 0.010, 0.617 +- 0.014, 0.670 +- 0.007, 0.762 +- 0.005
Faith. Armon (L1)= 		  =  0.549 +- 0.010, 0.616 +- 0.014, 0.642 +- 0.005, 0.688 +- 0.008
Faith. GMean (L1)= 	  =  0.550 +- 0.010, 0.617 +- 0.014, 0.656 +- 0.006, 0.724 +- 0.007
Faith. Aritm (KL)= 		  =  0.549 +- 0.011, 0.631 +- 0.019, 0.718 +- 0.017, 0.786 +- 0.022
Faith. Armon (KL)= 		  =  0.508 +- 0.019, 0.623 +- 0.023, 0.693 +- 0.022, 0.726 +- 0.034
Faith. GMean (KL)= 	  =  0.528 +- 0.010, 0.627 +- 0.021, 0.706 +- 0.019, 0.756 +- 0.028

Eval split val
Faith. Aritm (L1)= 		  =  0.581 +- 0.012, 0.566 +- 0.009, 0.614 +- 0.012, 0.730 +- 0.008
Faith. Armon (L1)= 		  =  0.569 +- 0.011, 0.565 +- 0.009, 0.585 +- 0.011, 0.631 +- 0.015
Faith. GMean (L1)= 	  =  0.575 +- 0.012, 0.566 +- 0.009, 0.599 +- 0.011, 0.679 +- 0.012
Faith. Aritm (KL)= 		  =  0.578 +- 0.015, 0.580 +- 0.011, 0.630 +- 0.014, 0.689 +- 0.022
Faith. Armon (KL)= 		  =  0.501 +- 0.026, 0.575 +- 0.010, 0.554 +- 0.031, 0.548 +- 0.046
Faith. GMean (KL)= 	  =  0.538 +- 0.015, 0.577 +- 0.010, 0.591 +- 0.022, 0.614 +- 0.036

Eval split test
Faith. Aritm (L1)= 		  =  0.547 +- 0.028, 0.595 +- 0.019, 0.625 +- 0.029, 0.722 +- 0.005
Faith. Armon (L1)= 		  =  0.541 +- 0.027, 0.592 +- 0.017, 0.580 +- 0.015, 0.615 +- 0.009
Faith. GMean (L1)= 	  =  0.544 +- 0.027, 0.594 +- 0.018, 0.602 +- 0.021, 0.666 +- 0.007
Faith. Aritm (KL)= 		  =  0.543 +- 0.034, 0.606 +- 0.024, 0.672 +- 0.031, 0.737 +- 0.011
Faith. Armon (KL)= 		  =  0.491 +- 0.046, 0.598 +- 0.028, 0.621 +- 0.027, 0.644 +- 0.021
Faith. GMean (KL)= 	  =  0.515 +- 0.035, 0.602 +- 0.026, 0.646 +- 0.028, 0.689 +- 0.016
Computed for split load_split = id



Completed in  0:19:11.817052  for LECIGIN GOODMotif2/basis



DONE LECI GOODMotif2/basis

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 14:11:09 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:11:11 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 171...
[0m[1;37mINFO[0m: [1mCheckpoint 171: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0751
ID Validation ACCURACY: 0.8762
ID Validation Loss: 0.4772
ID Test ACCURACY: 0.8732
ID Test Loss: 0.5405
OOD Validation ACCURACY: 0.8785
OOD Validation Loss: 0.6693
OOD Test ACCURACY: 0.8286
OOD Test Loss: 1.1668

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 155...
[0m[1;37mINFO[0m: [1mCheckpoint 155: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0752
ID Validation ACCURACY: 0.8738
ID Validation Loss: 0.4331
ID Test ACCURACY: 0.8747
ID Test Loss: 0.4825
OOD Validation ACCURACY: 0.8831
OOD Validation Loss: 0.5611
OOD Test ACCURACY: 0.8341
OOD Test Loss: 0.9574

[0m[1;37mINFO[0m: [1mChartInfo 0.8732 0.8286 0.8747 0.8341 0.8738 0.8831[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 04/07/2024 02:11:14 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.87
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.853
SUFF++ for r=0.6 class 0.0 = 0.883 +- 0.280 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.6 class 1.0 = 0.929 +- 0.280 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.6 all KL = 0.858 +- 0.280 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.6 all L1 = 0.91 +- 0.168 (in-sample avg dev_std = 0.277)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.856
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.871
SUFF++ for r=0.9 class 0.0 = 0.936 +- 0.185 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 class 1.0 = 0.945 +- 0.185 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 all KL = 0.941 +- 0.185 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 all L1 = 0.941 +- 0.160 (in-sample avg dev_std = 0.152)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.797
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 790
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.775
SUFF++ for r=0.3 class 0.0 = 0.86 +- 0.307 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.3 class 1.0 = 0.89 +- 0.307 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.3 all KL = 0.795 +- 0.307 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.3 all L1 = 0.875 +- 0.175 (in-sample avg dev_std = 0.371)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.85
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.83
SUFF++ for r=0.6 class 0.0 = 0.905 +- 0.226 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.6 class 1.0 = 0.937 +- 0.226 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.6 all KL = 0.891 +- 0.226 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.6 all L1 = 0.921 +- 0.155 (in-sample avg dev_std = 0.238)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.88
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.876
SUFF++ for r=0.9 class 0.0 = 0.937 +- 0.189 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 class 1.0 = 0.953 +- 0.189 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 all KL = 0.916 +- 0.189 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 all L1 = 0.945 +- 0.116 (in-sample avg dev_std = 0.240)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.762
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.732
SUFF++ for r=0.3 class 0.0 = 0.836 +- 0.273 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.3 class 1.0 = 0.913 +- 0.273 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.3 all KL = 0.813 +- 0.273 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.3 all L1 = 0.876 +- 0.178 (in-sample avg dev_std = 0.338)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.811
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.797
SUFF++ for r=0.6 class 0.0 = 0.87 +- 0.220 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.6 class 1.0 = 0.926 +- 0.220 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.6 all KL = 0.876 +- 0.220 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.6 all L1 = 0.899 +- 0.174 (in-sample avg dev_std = 0.242)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.834
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.832
SUFF++ for r=0.9 class 0.0 = 0.938 +- 0.135 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.9 class 1.0 = 0.965 +- 0.135 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.9 all KL = 0.953 +- 0.135 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.9 all L1 = 0.952 +- 0.111 (in-sample avg dev_std = 0.172)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.87
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.869
NEC for r=0.6 class 0.0 = 0.085 +- 0.163 (in-sample avg dev_std = 0.141)
NEC for r=0.6 class 1.0 = 0.047 +- 0.163 (in-sample avg dev_std = 0.141)
NEC for r=0.6 all KL = 0.06 +- 0.163 (in-sample avg dev_std = 0.141)
NEC for r=0.6 all L1 = 0.063 +- 0.145 (in-sample avg dev_std = 0.141)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.867
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.868
NEC for r=0.9 class 0.0 = 0.051 +- 0.174 (in-sample avg dev_std = 0.117)
NEC for r=0.9 class 1.0 = 0.045 +- 0.174 (in-sample avg dev_std = 0.117)
NEC for r=0.9 all KL = 0.048 +- 0.174 (in-sample avg dev_std = 0.117)
NEC for r=0.9 all L1 = 0.047 +- 0.150 (in-sample avg dev_std = 0.117)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.884
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.871
NEC for r=1.0 class 0.0 = 0.029 +- 0.131 (in-sample avg dev_std = 0.108)
NEC for r=1.0 class 1.0 = 0.03 +- 0.131 (in-sample avg dev_std = 0.108)
NEC for r=1.0 all KL = 0.026 +- 0.131 (in-sample avg dev_std = 0.108)
NEC for r=1.0 all L1 = 0.029 +- 0.113 (in-sample avg dev_std = 0.108)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.799
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.795
NEC for r=0.3 class 0.0 = 0.114 +- 0.195 (in-sample avg dev_std = 0.169)
NEC for r=0.3 class 1.0 = 0.062 +- 0.195 (in-sample avg dev_std = 0.169)
NEC for r=0.3 all KL = 0.085 +- 0.195 (in-sample avg dev_std = 0.169)
NEC for r=0.3 all L1 = 0.087 +- 0.175 (in-sample avg dev_std = 0.169)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.85
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.841
NEC for r=0.6 class 0.0 = 0.064 +- 0.138 (in-sample avg dev_std = 0.143)
NEC for r=0.6 class 1.0 = 0.039 +- 0.138 (in-sample avg dev_std = 0.143)
NEC for r=0.6 all KL = 0.044 +- 0.138 (in-sample avg dev_std = 0.143)
NEC for r=0.6 all L1 = 0.051 +- 0.133 (in-sample avg dev_std = 0.143)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.88
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.874
NEC for r=0.9 class 0.0 = 0.048 +- 0.113 (in-sample avg dev_std = 0.122)
NEC for r=0.9 class 1.0 = 0.024 +- 0.113 (in-sample avg dev_std = 0.122)
NEC for r=0.9 all KL = 0.029 +- 0.113 (in-sample avg dev_std = 0.122)
NEC for r=0.9 all L1 = 0.035 +- 0.106 (in-sample avg dev_std = 0.122)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.889
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.879
NEC for r=1.0 class 0.0 = 0.042 +- 0.092 (in-sample avg dev_std = 0.092)
NEC for r=1.0 class 1.0 = 0.018 +- 0.092 (in-sample avg dev_std = 0.092)
NEC for r=1.0 all KL = 0.019 +- 0.092 (in-sample avg dev_std = 0.092)
NEC for r=1.0 all L1 = 0.029 +- 0.092 (in-sample avg dev_std = 0.092)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.762
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.753
NEC for r=0.3 class 0.0 = 0.128 +- 0.210 (in-sample avg dev_std = 0.181)
NEC for r=0.3 class 1.0 = 0.061 +- 0.210 (in-sample avg dev_std = 0.181)
NEC for r=0.3 all KL = 0.09 +- 0.210 (in-sample avg dev_std = 0.181)
NEC for r=0.3 all L1 = 0.093 +- 0.185 (in-sample avg dev_std = 0.181)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.811
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.8
NEC for r=0.6 class 0.0 = 0.095 +- 0.152 (in-sample avg dev_std = 0.138)
NEC for r=0.6 class 1.0 = 0.051 +- 0.152 (in-sample avg dev_std = 0.138)
NEC for r=0.6 all KL = 0.056 +- 0.152 (in-sample avg dev_std = 0.138)
NEC for r=0.6 all L1 = 0.072 +- 0.161 (in-sample avg dev_std = 0.138)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.834
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.836
NEC for r=0.9 class 0.0 = 0.056 +- 0.103 (in-sample avg dev_std = 0.118)
NEC for r=0.9 class 1.0 = 0.035 +- 0.103 (in-sample avg dev_std = 0.118)
NEC for r=0.9 all KL = 0.032 +- 0.103 (in-sample avg dev_std = 0.118)
NEC for r=0.9 all L1 = 0.045 +- 0.114 (in-sample avg dev_std = 0.118)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.836
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.833
NEC for r=1.0 class 0.0 = 0.043 +- 0.080 (in-sample avg dev_std = 0.097)
NEC for r=1.0 class 1.0 = 0.022 +- 0.080 (in-sample avg dev_std = 0.097)
NEC for r=1.0 all KL = 0.02 +- 0.080 (in-sample avg dev_std = 0.097)
NEC for r=1.0 all L1 = 0.032 +- 0.092 (in-sample avg dev_std = 0.097)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 14:14:07 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:14:08 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:14:09 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 199...
[0m[1;37mINFO[0m: [1mCheckpoint 199: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0750
ID Validation ACCURACY: 0.8810
ID Validation Loss: 0.5004
ID Test ACCURACY: 0.8753
ID Test Loss: 0.5729
OOD Validation ACCURACY: 0.8835
OOD Validation Loss: 0.6764
OOD Test ACCURACY: 0.8298
OOD Test Loss: 1.2856

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 198...
[0m[1;37mINFO[0m: [1mCheckpoint 198: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0751
ID Validation ACCURACY: 0.8795
ID Validation Loss: 0.4785
ID Test ACCURACY: 0.8753
ID Test Loss: 0.5475
OOD Validation ACCURACY: 0.8846
OOD Validation Loss: 0.6262
OOD Test ACCURACY: 0.8300
OOD Test Loss: 1.0355

[0m[1;37mINFO[0m: [1mChartInfo 0.8753 0.8298 0.8753 0.8300 0.8795 0.8846[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 04/07/2024 02:14:10 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.867
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.868
SUFF++ for r=0.6 class 0.0 = 0.927 +- 0.196 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.6 class 1.0 = 0.948 +- 0.196 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.6 all KL = 0.922 +- 0.196 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.6 all L1 = 0.939 +- 0.130 (in-sample avg dev_std = 0.201)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.883
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.88
SUFF++ for r=0.9 class 0.0 = 0.94 +- 0.147 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.9 class 1.0 = 0.989 +- 0.147 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.9 all KL = 0.967 +- 0.147 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.9 all L1 = 0.967 +- 0.118 (in-sample avg dev_std = 0.111)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.797
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 790
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.778
SUFF++ for r=0.3 class 0.0 = 0.899 +- 0.210 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.3 class 1.0 = 0.916 +- 0.210 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.3 all KL = 0.881 +- 0.210 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.3 all L1 = 0.908 +- 0.138 (in-sample avg dev_std = 0.288)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.845
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.828
SUFF++ for r=0.6 class 0.0 = 0.924 +- 0.174 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.6 class 1.0 = 0.952 +- 0.174 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.6 all KL = 0.929 +- 0.174 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.6 all L1 = 0.938 +- 0.134 (in-sample avg dev_std = 0.205)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.874
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.87
SUFF++ for r=0.9 class 0.0 = 0.954 +- 0.123 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.9 class 1.0 = 0.97 +- 0.123 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.9 all KL = 0.956 +- 0.123 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.9 all L1 = 0.962 +- 0.092 (in-sample avg dev_std = 0.186)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.769
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.74
SUFF++ for r=0.3 class 0.0 = 0.873 +- 0.202 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.3 class 1.0 = 0.931 +- 0.202 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.3 all KL = 0.884 +- 0.202 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.3 all L1 = 0.903 +- 0.149 (in-sample avg dev_std = 0.281)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.799
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.785
SUFF++ for r=0.6 class 0.0 = 0.892 +- 0.161 (in-sample avg dev_std = 0.206)
SUFF++ for r=0.6 class 1.0 = 0.95 +- 0.161 (in-sample avg dev_std = 0.206)
SUFF++ for r=0.6 all KL = 0.922 +- 0.161 (in-sample avg dev_std = 0.206)
SUFF++ for r=0.6 all L1 = 0.922 +- 0.147 (in-sample avg dev_std = 0.206)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.839
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.833
SUFF++ for r=0.9 class 0.0 = 0.958 +- 0.103 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.9 class 1.0 = 0.964 +- 0.103 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.9 all KL = 0.967 +- 0.103 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.9 all L1 = 0.961 +- 0.101 (in-sample avg dev_std = 0.159)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.867
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.873
NEC for r=0.6 class 0.0 = 0.065 +- 0.122 (in-sample avg dev_std = 0.114)
NEC for r=0.6 class 1.0 = 0.039 +- 0.122 (in-sample avg dev_std = 0.114)
NEC for r=0.6 all KL = 0.041 +- 0.122 (in-sample avg dev_std = 0.114)
NEC for r=0.6 all L1 = 0.05 +- 0.123 (in-sample avg dev_std = 0.114)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.884
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.875
NEC for r=0.9 class 0.0 = 0.051 +- 0.148 (in-sample avg dev_std = 0.087)
NEC for r=0.9 class 1.0 = 0.019 +- 0.148 (in-sample avg dev_std = 0.087)
NEC for r=0.9 all KL = 0.033 +- 0.148 (in-sample avg dev_std = 0.087)
NEC for r=0.9 all L1 = 0.032 +- 0.118 (in-sample avg dev_std = 0.087)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.881
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.873
NEC for r=1.0 class 0.0 = 0.041 +- 0.135 (in-sample avg dev_std = 0.073)
NEC for r=1.0 class 1.0 = 0.017 +- 0.135 (in-sample avg dev_std = 0.073)
NEC for r=1.0 all KL = 0.026 +- 0.135 (in-sample avg dev_std = 0.073)
NEC for r=1.0 all L1 = 0.027 +- 0.110 (in-sample avg dev_std = 0.073)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.799
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.801
NEC for r=0.3 class 0.0 = 0.083 +- 0.140 (in-sample avg dev_std = 0.127)
NEC for r=0.3 class 1.0 = 0.047 +- 0.140 (in-sample avg dev_std = 0.127)
NEC for r=0.3 all KL = 0.051 +- 0.140 (in-sample avg dev_std = 0.127)
NEC for r=0.3 all L1 = 0.064 +- 0.135 (in-sample avg dev_std = 0.127)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.845
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.839
NEC for r=0.6 class 0.0 = 0.055 +- 0.106 (in-sample avg dev_std = 0.124)
NEC for r=0.6 class 1.0 = 0.028 +- 0.106 (in-sample avg dev_std = 0.124)
NEC for r=0.6 all KL = 0.029 +- 0.106 (in-sample avg dev_std = 0.124)
NEC for r=0.6 all L1 = 0.041 +- 0.113 (in-sample avg dev_std = 0.124)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.874
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.868
NEC for r=0.9 class 0.0 = 0.04 +- 0.098 (in-sample avg dev_std = 0.101)
NEC for r=0.9 class 1.0 = 0.025 +- 0.098 (in-sample avg dev_std = 0.101)
NEC for r=0.9 all KL = 0.022 +- 0.098 (in-sample avg dev_std = 0.101)
NEC for r=0.9 all L1 = 0.032 +- 0.101 (in-sample avg dev_std = 0.101)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.882
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.875
NEC for r=1.0 class 0.0 = 0.034 +- 0.087 (in-sample avg dev_std = 0.078)
NEC for r=1.0 class 1.0 = 0.019 +- 0.087 (in-sample avg dev_std = 0.078)
NEC for r=1.0 all KL = 0.017 +- 0.087 (in-sample avg dev_std = 0.078)
NEC for r=1.0 all L1 = 0.026 +- 0.089 (in-sample avg dev_std = 0.078)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.769
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.764
NEC for r=0.3 class 0.0 = 0.088 +- 0.125 (in-sample avg dev_std = 0.140)
NEC for r=0.3 class 1.0 = 0.041 +- 0.125 (in-sample avg dev_std = 0.140)
NEC for r=0.3 all KL = 0.042 +- 0.125 (in-sample avg dev_std = 0.140)
NEC for r=0.3 all L1 = 0.064 +- 0.134 (in-sample avg dev_std = 0.140)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.799
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.792
NEC for r=0.6 class 0.0 = 0.08 +- 0.109 (in-sample avg dev_std = 0.126)
NEC for r=0.6 class 1.0 = 0.034 +- 0.109 (in-sample avg dev_std = 0.126)
NEC for r=0.6 all KL = 0.035 +- 0.109 (in-sample avg dev_std = 0.126)
NEC for r=0.6 all L1 = 0.056 +- 0.130 (in-sample avg dev_std = 0.126)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.839
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.838
NEC for r=0.9 class 0.0 = 0.052 +- 0.109 (in-sample avg dev_std = 0.120)
NEC for r=0.9 class 1.0 = 0.039 +- 0.109 (in-sample avg dev_std = 0.120)
NEC for r=0.9 all KL = 0.032 +- 0.109 (in-sample avg dev_std = 0.120)
NEC for r=0.9 all L1 = 0.045 +- 0.119 (in-sample avg dev_std = 0.120)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.839
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.838
NEC for r=1.0 class 0.0 = 0.05 +- 0.093 (in-sample avg dev_std = 0.105)
NEC for r=1.0 class 1.0 = 0.031 +- 0.093 (in-sample avg dev_std = 0.105)
NEC for r=1.0 all KL = 0.027 +- 0.093 (in-sample avg dev_std = 0.105)
NEC for r=1.0 all L1 = 0.04 +- 0.110 (in-sample avg dev_std = 0.105)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 14:17:05 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:17:07 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 159...
[0m[1;37mINFO[0m: [1mCheckpoint 159: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0752
ID Validation ACCURACY: 0.8796
ID Validation Loss: 0.4389
ID Test ACCURACY: 0.8757
ID Test Loss: 0.4942
OOD Validation ACCURACY: 0.8781
OOD Validation Loss: 0.5616
OOD Test ACCURACY: 0.8223
OOD Test Loss: 0.8763

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 97...
[0m[1;37mINFO[0m: [1mCheckpoint 97: 
-----------------------------------
Train ACCURACY: 0.9488
Train Loss: 0.0772
ID Validation ACCURACY: 0.8764
ID Validation Loss: 0.3801
ID Test ACCURACY: 0.8732
ID Test Loss: 0.4337
OOD Validation ACCURACY: 0.8807
OOD Validation Loss: 0.4866
OOD Test ACCURACY: 0.8229
OOD Test Loss: 0.8869

[0m[1;37mINFO[0m: [1mChartInfo 0.8757 0.8223 0.8732 0.8229 0.8764 0.8807[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 04/07/2024 02:17:08 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.865
SUFF++ for r=0.6 class 0.0 = 0.924 +- 0.211 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.6 class 1.0 = 0.947 +- 0.211 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.6 all KL = 0.913 +- 0.211 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.6 all L1 = 0.938 +- 0.132 (in-sample avg dev_std = 0.228)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.867
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.866
SUFF++ for r=0.9 class 0.0 = 0.942 +- 0.106 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.9 class 1.0 = 0.969 +- 0.106 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.9 all KL = 0.971 +- 0.106 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.9 all L1 = 0.957 +- 0.114 (in-sample avg dev_std = 0.111)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.78
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 790
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.761
SUFF++ for r=0.3 class 0.0 = 0.896 +- 0.228 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.3 class 1.0 = 0.917 +- 0.228 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.3 all KL = 0.871 +- 0.228 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.3 all L1 = 0.907 +- 0.141 (in-sample avg dev_std = 0.294)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.846
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.824
SUFF++ for r=0.6 class 0.0 = 0.925 +- 0.168 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.6 class 1.0 = 0.956 +- 0.168 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.6 all KL = 0.935 +- 0.168 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.6 all L1 = 0.941 +- 0.125 (in-sample avg dev_std = 0.185)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.875
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.873
SUFF++ for r=0.9 class 0.0 = 0.95 +- 0.104 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.9 class 1.0 = 0.964 +- 0.104 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.9 all KL = 0.962 +- 0.104 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.9 all L1 = 0.957 +- 0.096 (in-sample avg dev_std = 0.172)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.759
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.741
SUFF++ for r=0.3 class 0.0 = 0.876 +- 0.169 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.3 class 1.0 = 0.939 +- 0.169 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.3 all KL = 0.907 +- 0.169 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.3 all L1 = 0.909 +- 0.141 (in-sample avg dev_std = 0.243)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.798
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.78
SUFF++ for r=0.6 class 0.0 = 0.894 +- 0.152 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.6 class 1.0 = 0.945 +- 0.152 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.6 all KL = 0.928 +- 0.152 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.6 all L1 = 0.92 +- 0.142 (in-sample avg dev_std = 0.192)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.832
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.832
SUFF++ for r=0.9 class 0.0 = 0.949 +- 0.074 (in-sample avg dev_std = 0.134)
SUFF++ for r=0.9 class 1.0 = 0.967 +- 0.074 (in-sample avg dev_std = 0.134)
SUFF++ for r=0.9 all KL = 0.973 +- 0.074 (in-sample avg dev_std = 0.134)
SUFF++ for r=0.9 all L1 = 0.958 +- 0.090 (in-sample avg dev_std = 0.134)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.873
NEC for r=0.6 class 0.0 = 0.061 +- 0.125 (in-sample avg dev_std = 0.124)
NEC for r=0.6 class 1.0 = 0.035 +- 0.125 (in-sample avg dev_std = 0.124)
NEC for r=0.6 all KL = 0.04 +- 0.125 (in-sample avg dev_std = 0.124)
NEC for r=0.6 all L1 = 0.046 +- 0.112 (in-sample avg dev_std = 0.124)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.874
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.864
NEC for r=0.9 class 0.0 = 0.062 +- 0.144 (in-sample avg dev_std = 0.127)
NEC for r=0.9 class 1.0 = 0.035 +- 0.144 (in-sample avg dev_std = 0.127)
NEC for r=0.9 all KL = 0.036 +- 0.144 (in-sample avg dev_std = 0.127)
NEC for r=0.9 all L1 = 0.047 +- 0.134 (in-sample avg dev_std = 0.127)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.877
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.864
NEC for r=1.0 class 0.0 = 0.058 +- 0.133 (in-sample avg dev_std = 0.115)
NEC for r=1.0 class 1.0 = 0.028 +- 0.133 (in-sample avg dev_std = 0.115)
NEC for r=1.0 all KL = 0.029 +- 0.133 (in-sample avg dev_std = 0.115)
NEC for r=1.0 all L1 = 0.04 +- 0.124 (in-sample avg dev_std = 0.115)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.781
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.782
NEC for r=0.3 class 0.0 = 0.099 +- 0.176 (in-sample avg dev_std = 0.155)
NEC for r=0.3 class 1.0 = 0.055 +- 0.176 (in-sample avg dev_std = 0.155)
NEC for r=0.3 all KL = 0.069 +- 0.176 (in-sample avg dev_std = 0.155)
NEC for r=0.3 all L1 = 0.076 +- 0.149 (in-sample avg dev_std = 0.155)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.846
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.835
NEC for r=0.6 class 0.0 = 0.058 +- 0.103 (in-sample avg dev_std = 0.124)
NEC for r=0.6 class 1.0 = 0.032 +- 0.103 (in-sample avg dev_std = 0.124)
NEC for r=0.6 all KL = 0.029 +- 0.103 (in-sample avg dev_std = 0.124)
NEC for r=0.6 all L1 = 0.044 +- 0.112 (in-sample avg dev_std = 0.124)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.875
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.868
NEC for r=0.9 class 0.0 = 0.046 +- 0.088 (in-sample avg dev_std = 0.101)
NEC for r=0.9 class 1.0 = 0.031 +- 0.088 (in-sample avg dev_std = 0.101)
NEC for r=0.9 all KL = 0.022 +- 0.088 (in-sample avg dev_std = 0.101)
NEC for r=0.9 all L1 = 0.038 +- 0.106 (in-sample avg dev_std = 0.101)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.882
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.872
NEC for r=1.0 class 0.0 = 0.045 +- 0.073 (in-sample avg dev_std = 0.092)
NEC for r=1.0 class 1.0 = 0.026 +- 0.073 (in-sample avg dev_std = 0.092)
NEC for r=1.0 all KL = 0.017 +- 0.073 (in-sample avg dev_std = 0.092)
NEC for r=1.0 all L1 = 0.035 +- 0.093 (in-sample avg dev_std = 0.092)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.759
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.759
NEC for r=0.3 class 0.0 = 0.101 +- 0.127 (in-sample avg dev_std = 0.134)
NEC for r=0.3 class 1.0 = 0.05 +- 0.127 (in-sample avg dev_std = 0.134)
NEC for r=0.3 all KL = 0.047 +- 0.127 (in-sample avg dev_std = 0.134)
NEC for r=0.3 all L1 = 0.075 +- 0.138 (in-sample avg dev_std = 0.134)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.798
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.787
NEC for r=0.6 class 0.0 = 0.082 +- 0.108 (in-sample avg dev_std = 0.118)
NEC for r=0.6 class 1.0 = 0.044 +- 0.108 (in-sample avg dev_std = 0.118)
NEC for r=0.6 all KL = 0.036 +- 0.108 (in-sample avg dev_std = 0.118)
NEC for r=0.6 all L1 = 0.062 +- 0.128 (in-sample avg dev_std = 0.118)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.832
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.829
NEC for r=0.9 class 0.0 = 0.064 +- 0.088 (in-sample avg dev_std = 0.107)
NEC for r=0.9 class 1.0 = 0.039 +- 0.088 (in-sample avg dev_std = 0.107)
NEC for r=0.9 all KL = 0.029 +- 0.088 (in-sample avg dev_std = 0.107)
NEC for r=0.9 all L1 = 0.051 +- 0.111 (in-sample avg dev_std = 0.107)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.831
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.829
NEC for r=1.0 class 0.0 = 0.057 +- 0.077 (in-sample avg dev_std = 0.093)
NEC for r=1.0 class 1.0 = 0.035 +- 0.077 (in-sample avg dev_std = 0.093)
NEC for r=1.0 all KL = 0.024 +- 0.077 (in-sample avg dev_std = 0.093)
NEC for r=1.0 all L1 = 0.046 +- 0.103 (in-sample avg dev_std = 0.093)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 14:20:03 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:20:04 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 142...
[0m[1;37mINFO[0m: [1mCheckpoint 142: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0758
ID Validation ACCURACY: 0.8795
ID Validation Loss: 0.3939
ID Test ACCURACY: 0.8734
ID Test Loss: 0.4467
OOD Validation ACCURACY: 0.8811
OOD Validation Loss: 0.5654
OOD Test ACCURACY: 0.8098
OOD Test Loss: 1.1500

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 193...
[0m[1;37mINFO[0m: [1mCheckpoint 193: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0751
ID Validation ACCURACY: 0.8776
ID Validation Loss: 0.4561
ID Test ACCURACY: 0.8779
ID Test Loss: 0.5161
OOD Validation ACCURACY: 0.8846
OOD Validation Loss: 0.6825
OOD Test ACCURACY: 0.8120
OOD Test Loss: 1.3717

[0m[1;37mINFO[0m: [1mChartInfo 0.8734 0.8098 0.8779 0.8120 0.8776 0.8846[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 04/07/2024 02:20:06 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.87
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.85
SUFF++ for r=0.6 class 0.0 = 0.918 +- 0.177 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.6 class 1.0 = 0.943 +- 0.177 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.6 all KL = 0.927 +- 0.177 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.6 all L1 = 0.933 +- 0.126 (in-sample avg dev_std = 0.213)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.878
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.872
SUFF++ for r=0.9 class 0.0 = 0.94 +- 0.110 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.9 class 1.0 = 0.964 +- 0.110 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.9 all KL = 0.968 +- 0.110 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.9 all L1 = 0.953 +- 0.122 (in-sample avg dev_std = 0.111)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.796
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 790
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.773
SUFF++ for r=0.3 class 0.0 = 0.888 +- 0.183 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.3 class 1.0 = 0.914 +- 0.183 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.3 all KL = 0.894 +- 0.183 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.3 all L1 = 0.902 +- 0.133 (in-sample avg dev_std = 0.268)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.834
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.82
SUFF++ for r=0.6 class 0.0 = 0.917 +- 0.158 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.6 class 1.0 = 0.946 +- 0.158 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.6 all KL = 0.934 +- 0.158 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.6 all L1 = 0.932 +- 0.131 (in-sample avg dev_std = 0.193)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.884
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.877
SUFF++ for r=0.9 class 0.0 = 0.948 +- 0.096 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.9 class 1.0 = 0.969 +- 0.096 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.9 all KL = 0.963 +- 0.096 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.9 all L1 = 0.959 +- 0.086 (in-sample avg dev_std = 0.168)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.755
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.732
SUFF++ for r=0.3 class 0.0 = 0.868 +- 0.172 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 class 1.0 = 0.935 +- 0.172 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 all KL = 0.901 +- 0.172 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 all L1 = 0.903 +- 0.137 (in-sample avg dev_std = 0.252)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.788
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.768
SUFF++ for r=0.6 class 0.0 = 0.867 +- 0.155 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.6 class 1.0 = 0.954 +- 0.155 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.6 all KL = 0.923 +- 0.155 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.6 all L1 = 0.912 +- 0.149 (in-sample avg dev_std = 0.193)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.822
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.82
SUFF++ for r=0.9 class 0.0 = 0.942 +- 0.068 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.9 class 1.0 = 0.976 +- 0.068 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.9 all KL = 0.975 +- 0.068 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.9 all L1 = 0.96 +- 0.085 (in-sample avg dev_std = 0.124)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.87
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.86
NEC for r=0.6 class 0.0 = 0.071 +- 0.124 (in-sample avg dev_std = 0.118)
NEC for r=0.6 class 1.0 = 0.048 +- 0.124 (in-sample avg dev_std = 0.118)
NEC for r=0.6 all KL = 0.043 +- 0.124 (in-sample avg dev_std = 0.118)
NEC for r=0.6 all L1 = 0.057 +- 0.119 (in-sample avg dev_std = 0.118)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.877
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.866
NEC for r=0.9 class 0.0 = 0.06 +- 0.141 (in-sample avg dev_std = 0.092)
NEC for r=0.9 class 1.0 = 0.032 +- 0.141 (in-sample avg dev_std = 0.092)
NEC for r=0.9 all KL = 0.035 +- 0.141 (in-sample avg dev_std = 0.092)
NEC for r=0.9 all L1 = 0.044 +- 0.132 (in-sample avg dev_std = 0.092)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.884
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.866
NEC for r=1.0 class 0.0 = 0.055 +- 0.133 (in-sample avg dev_std = 0.074)
NEC for r=1.0 class 1.0 = 0.025 +- 0.133 (in-sample avg dev_std = 0.074)
NEC for r=1.0 all KL = 0.028 +- 0.133 (in-sample avg dev_std = 0.074)
NEC for r=1.0 all L1 = 0.038 +- 0.125 (in-sample avg dev_std = 0.074)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.798
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.795
NEC for r=0.3 class 0.0 = 0.103 +- 0.141 (in-sample avg dev_std = 0.123)
NEC for r=0.3 class 1.0 = 0.06 +- 0.141 (in-sample avg dev_std = 0.123)
NEC for r=0.3 all KL = 0.058 +- 0.141 (in-sample avg dev_std = 0.123)
NEC for r=0.3 all L1 = 0.081 +- 0.147 (in-sample avg dev_std = 0.123)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.834
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.837
NEC for r=0.6 class 0.0 = 0.063 +- 0.087 (in-sample avg dev_std = 0.107)
NEC for r=0.6 class 1.0 = 0.033 +- 0.087 (in-sample avg dev_std = 0.107)
NEC for r=0.6 all KL = 0.026 +- 0.087 (in-sample avg dev_std = 0.107)
NEC for r=0.6 all L1 = 0.048 +- 0.110 (in-sample avg dev_std = 0.107)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.884
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.879
NEC for r=0.9 class 0.0 = 0.048 +- 0.078 (in-sample avg dev_std = 0.095)
NEC for r=0.9 class 1.0 = 0.027 +- 0.078 (in-sample avg dev_std = 0.095)
NEC for r=0.9 all KL = 0.021 +- 0.078 (in-sample avg dev_std = 0.095)
NEC for r=0.9 all L1 = 0.037 +- 0.094 (in-sample avg dev_std = 0.095)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.886
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.885
NEC for r=1.0 class 0.0 = 0.039 +- 0.068 (in-sample avg dev_std = 0.084)
NEC for r=1.0 class 1.0 = 0.02 +- 0.068 (in-sample avg dev_std = 0.084)
NEC for r=1.0 all KL = 0.016 +- 0.068 (in-sample avg dev_std = 0.084)
NEC for r=1.0 all L1 = 0.029 +- 0.076 (in-sample avg dev_std = 0.084)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.755
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.757
NEC for r=0.3 class 0.0 = 0.091 +- 0.097 (in-sample avg dev_std = 0.117)
NEC for r=0.3 class 1.0 = 0.044 +- 0.097 (in-sample avg dev_std = 0.117)
NEC for r=0.3 all KL = 0.035 +- 0.097 (in-sample avg dev_std = 0.117)
NEC for r=0.3 all L1 = 0.067 +- 0.120 (in-sample avg dev_std = 0.117)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.788
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.78
NEC for r=0.6 class 0.0 = 0.082 +- 0.088 (in-sample avg dev_std = 0.113)
NEC for r=0.6 class 1.0 = 0.039 +- 0.088 (in-sample avg dev_std = 0.113)
NEC for r=0.6 all KL = 0.031 +- 0.088 (in-sample avg dev_std = 0.113)
NEC for r=0.6 all L1 = 0.06 +- 0.122 (in-sample avg dev_std = 0.113)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.822
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.819
NEC for r=0.9 class 0.0 = 0.067 +- 0.071 (in-sample avg dev_std = 0.086)
NEC for r=0.9 class 1.0 = 0.029 +- 0.071 (in-sample avg dev_std = 0.086)
NEC for r=0.9 all KL = 0.023 +- 0.071 (in-sample avg dev_std = 0.086)
NEC for r=0.9 all L1 = 0.048 +- 0.102 (in-sample avg dev_std = 0.086)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.822
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.824
NEC for r=1.0 class 0.0 = 0.063 +- 0.069 (in-sample avg dev_std = 0.093)
NEC for r=1.0 class 1.0 = 0.028 +- 0.069 (in-sample avg dev_std = 0.093)
NEC for r=1.0 all KL = 0.021 +- 0.069 (in-sample avg dev_std = 0.093)
NEC for r=1.0 all L1 = 0.045 +- 0.102 (in-sample avg dev_std = 0.093)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 14:23:01 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:23:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:23:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:03 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:23:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:23:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:23:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:03 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:23:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:23:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:23:03 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 192...
[0m[1;37mINFO[0m: [1mCheckpoint 192: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0750
ID Validation ACCURACY: 0.8781
ID Validation Loss: 0.5140
ID Test ACCURACY: 0.8742
ID Test Loss: 0.5848
OOD Validation ACCURACY: 0.8821
OOD Validation Loss: 0.6982
OOD Test ACCURACY: 0.8264
OOD Test Loss: 1.2184

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 191...
[0m[1;37mINFO[0m: [1mCheckpoint 191: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0750
ID Validation ACCURACY: 0.8755
ID Validation Loss: 0.4966
ID Test ACCURACY: 0.8761
ID Test Loss: 0.5645
OOD Validation ACCURACY: 0.8860
OOD Validation Loss: 0.6638
OOD Test ACCURACY: 0.8338
OOD Test Loss: 1.0510

[0m[1;37mINFO[0m: [1mChartInfo 0.8742 0.8264 0.8761 0.8338 0.8755 0.8860[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 04/07/2024 02:23:04 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.874
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.861
SUFF++ for r=0.6 class 0.0 = 0.918 +- 0.200 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.6 class 1.0 = 0.96 +- 0.200 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.6 all KL = 0.923 +- 0.200 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.6 all L1 = 0.943 +- 0.133 (in-sample avg dev_std = 0.219)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.872
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.872
SUFF++ for r=0.9 class 0.0 = 0.94 +- 0.136 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 class 1.0 = 0.966 +- 0.136 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 all KL = 0.963 +- 0.136 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 all L1 = 0.954 +- 0.135 (in-sample avg dev_std = 0.107)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.811
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 790
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.785
SUFF++ for r=0.3 class 0.0 = 0.884 +- 0.232 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.3 class 1.0 = 0.931 +- 0.232 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.3 all KL = 0.871 +- 0.232 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.3 all L1 = 0.908 +- 0.151 (in-sample avg dev_std = 0.294)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.855
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.833
SUFF++ for r=0.6 class 0.0 = 0.917 +- 0.181 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.6 class 1.0 = 0.957 +- 0.181 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.6 all KL = 0.929 +- 0.181 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.6 all L1 = 0.938 +- 0.142 (in-sample avg dev_std = 0.198)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.884
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.874
SUFF++ for r=0.9 class 0.0 = 0.951 +- 0.128 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.9 class 1.0 = 0.968 +- 0.128 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.9 all KL = 0.953 +- 0.128 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.9 all L1 = 0.96 +- 0.094 (in-sample avg dev_std = 0.184)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.754
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.742
SUFF++ for r=0.3 class 0.0 = 0.881 +- 0.206 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.3 class 1.0 = 0.942 +- 0.206 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.3 all KL = 0.888 +- 0.206 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.3 all L1 = 0.913 +- 0.141 (in-sample avg dev_std = 0.269)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.809
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.794
SUFF++ for r=0.6 class 0.0 = 0.892 +- 0.166 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.6 class 1.0 = 0.95 +- 0.166 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.6 all KL = 0.922 +- 0.166 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.6 all L1 = 0.922 +- 0.145 (in-sample avg dev_std = 0.204)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.836
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.832
SUFF++ for r=0.9 class 0.0 = 0.947 +- 0.105 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 class 1.0 = 0.973 +- 0.105 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 all KL = 0.966 +- 0.105 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 all L1 = 0.961 +- 0.095 (in-sample avg dev_std = 0.152)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.874
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.872
NEC for r=0.6 class 0.0 = 0.077 +- 0.146 (in-sample avg dev_std = 0.106)
NEC for r=0.6 class 1.0 = 0.024 +- 0.146 (in-sample avg dev_std = 0.106)
NEC for r=0.6 all KL = 0.044 +- 0.146 (in-sample avg dev_std = 0.106)
NEC for r=0.6 all L1 = 0.046 +- 0.125 (in-sample avg dev_std = 0.106)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.877
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.871
NEC for r=0.9 class 0.0 = 0.047 +- 0.133 (in-sample avg dev_std = 0.098)
NEC for r=0.9 class 1.0 = 0.033 +- 0.133 (in-sample avg dev_std = 0.098)
NEC for r=0.9 all KL = 0.031 +- 0.133 (in-sample avg dev_std = 0.098)
NEC for r=0.9 all L1 = 0.039 +- 0.130 (in-sample avg dev_std = 0.098)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.881
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.871
NEC for r=1.0 class 0.0 = 0.037 +- 0.128 (in-sample avg dev_std = 0.097)
NEC for r=1.0 class 1.0 = 0.032 +- 0.128 (in-sample avg dev_std = 0.097)
NEC for r=1.0 all KL = 0.026 +- 0.128 (in-sample avg dev_std = 0.097)
NEC for r=1.0 all L1 = 0.034 +- 0.120 (in-sample avg dev_std = 0.097)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.812
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.806
NEC for r=0.3 class 0.0 = 0.091 +- 0.165 (in-sample avg dev_std = 0.144)
NEC for r=0.3 class 1.0 = 0.048 +- 0.165 (in-sample avg dev_std = 0.144)
NEC for r=0.3 all KL = 0.061 +- 0.165 (in-sample avg dev_std = 0.144)
NEC for r=0.3 all L1 = 0.069 +- 0.150 (in-sample avg dev_std = 0.144)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.855
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.845
NEC for r=0.6 class 0.0 = 0.057 +- 0.111 (in-sample avg dev_std = 0.128)
NEC for r=0.6 class 1.0 = 0.029 +- 0.111 (in-sample avg dev_std = 0.128)
NEC for r=0.6 all KL = 0.03 +- 0.111 (in-sample avg dev_std = 0.128)
NEC for r=0.6 all L1 = 0.042 +- 0.117 (in-sample avg dev_std = 0.128)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.884
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.882
NEC for r=0.9 class 0.0 = 0.04 +- 0.087 (in-sample avg dev_std = 0.090)
NEC for r=0.9 class 1.0 = 0.026 +- 0.087 (in-sample avg dev_std = 0.090)
NEC for r=0.9 all KL = 0.02 +- 0.087 (in-sample avg dev_std = 0.090)
NEC for r=0.9 all L1 = 0.032 +- 0.097 (in-sample avg dev_std = 0.090)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.89
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.881
NEC for r=1.0 class 0.0 = 0.04 +- 0.094 (in-sample avg dev_std = 0.090)
NEC for r=1.0 class 1.0 = 0.023 +- 0.094 (in-sample avg dev_std = 0.090)
NEC for r=1.0 all KL = 0.02 +- 0.094 (in-sample avg dev_std = 0.090)
NEC for r=1.0 all L1 = 0.031 +- 0.101 (in-sample avg dev_std = 0.090)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.754
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.76
NEC for r=0.3 class 0.0 = 0.092 +- 0.132 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 1.0 = 0.036 +- 0.132 (in-sample avg dev_std = 0.142)
NEC for r=0.3 all KL = 0.044 +- 0.132 (in-sample avg dev_std = 0.142)
NEC for r=0.3 all L1 = 0.063 +- 0.134 (in-sample avg dev_std = 0.142)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.809
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.8
NEC for r=0.6 class 0.0 = 0.076 +- 0.119 (in-sample avg dev_std = 0.128)
NEC for r=0.6 class 1.0 = 0.041 +- 0.119 (in-sample avg dev_std = 0.128)
NEC for r=0.6 all KL = 0.039 +- 0.119 (in-sample avg dev_std = 0.128)
NEC for r=0.6 all L1 = 0.058 +- 0.129 (in-sample avg dev_std = 0.128)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.836
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.829
NEC for r=0.9 class 0.0 = 0.064 +- 0.096 (in-sample avg dev_std = 0.114)
NEC for r=0.9 class 1.0 = 0.029 +- 0.096 (in-sample avg dev_std = 0.114)
NEC for r=0.9 all KL = 0.029 +- 0.096 (in-sample avg dev_std = 0.114)
NEC for r=0.9 all L1 = 0.046 +- 0.116 (in-sample avg dev_std = 0.114)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.832
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.838
NEC for r=1.0 class 0.0 = 0.059 +- 0.102 (in-sample avg dev_std = 0.110)
NEC for r=1.0 class 1.0 = 0.03 +- 0.102 (in-sample avg dev_std = 0.110)
NEC for r=1.0 all KL = 0.028 +- 0.102 (in-sample avg dev_std = 0.110)
NEC for r=1.0 all L1 = 0.044 +- 0.116 (in-sample avg dev_std = 0.110)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.858, 0.941, 1.0], 'all_L1': [0.91, 0.941, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.922, 0.967, 1.0], 'all_L1': [0.939, 0.967, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.913, 0.971, 1.0], 'all_L1': [0.938, 0.957, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.927, 0.968, 1.0], 'all_L1': [0.933, 0.953, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.923, 0.963, 1.0], 'all_L1': [0.943, 0.954, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.06, 0.048, 0.026], 'all_L1': [0.063, 0.047, 0.029]}), defaultdict(<class 'list'>, {'all_KL': [0.041, 0.033, 0.026], 'all_L1': [0.05, 0.032, 0.027]}), defaultdict(<class 'list'>, {'all_KL': [0.04, 0.036, 0.029], 'all_L1': [0.046, 0.047, 0.04]}), defaultdict(<class 'list'>, {'all_KL': [0.043, 0.035, 0.028], 'all_L1': [0.057, 0.044, 0.038]}), defaultdict(<class 'list'>, {'all_KL': [0.044, 0.031, 0.026], 'all_L1': [0.046, 0.039, 0.034]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.795, 0.891, 0.916, 1.0], 'all_L1': [0.875, 0.921, 0.945, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.881, 0.929, 0.956, 1.0], 'all_L1': [0.908, 0.938, 0.962, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.871, 0.935, 0.962, 1.0], 'all_L1': [0.907, 0.941, 0.957, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.894, 0.934, 0.963, 1.0], 'all_L1': [0.902, 0.932, 0.959, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.871, 0.929, 0.953, 1.0], 'all_L1': [0.908, 0.938, 0.96, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.085, 0.044, 0.029, 0.019], 'all_L1': [0.087, 0.051, 0.035, 0.029]}), defaultdict(<class 'list'>, {'all_KL': [0.051, 0.029, 0.022, 0.017], 'all_L1': [0.064, 0.041, 0.032, 0.026]}), defaultdict(<class 'list'>, {'all_KL': [0.069, 0.029, 0.022, 0.017], 'all_L1': [0.076, 0.044, 0.038, 0.035]}), defaultdict(<class 'list'>, {'all_KL': [0.058, 0.026, 0.021, 0.016], 'all_L1': [0.081, 0.048, 0.037, 0.029]}), defaultdict(<class 'list'>, {'all_KL': [0.061, 0.03, 0.02, 0.02], 'all_L1': [0.069, 0.042, 0.032, 0.031]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.813, 0.876, 0.953, 1.0], 'all_L1': [0.876, 0.899, 0.952, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.884, 0.922, 0.967, 1.0], 'all_L1': [0.903, 0.922, 0.961, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.907, 0.928, 0.973, 1.0], 'all_L1': [0.909, 0.92, 0.958, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.901, 0.923, 0.975, 1.0], 'all_L1': [0.903, 0.912, 0.96, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.888, 0.922, 0.966, 1.0], 'all_L1': [0.913, 0.922, 0.961, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.09, 0.056, 0.032, 0.02], 'all_L1': [0.093, 0.072, 0.045, 0.032]}), defaultdict(<class 'list'>, {'all_KL': [0.042, 0.035, 0.032, 0.027], 'all_L1': [0.064, 0.056, 0.045, 0.04]}), defaultdict(<class 'list'>, {'all_KL': [0.047, 0.036, 0.029, 0.024], 'all_L1': [0.075, 0.062, 0.051, 0.046]}), defaultdict(<class 'list'>, {'all_KL': [0.035, 0.031, 0.023, 0.021], 'all_L1': [0.067, 0.06, 0.048, 0.045]}), defaultdict(<class 'list'>, {'all_KL': [0.044, 0.039, 0.029, 0.028], 'all_L1': [0.063, 0.058, 0.046, 0.044]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.933 +- 0.012, 0.954 +- 0.008, 1.000 +- 0.000
suff++ class all_KL  =  0.909 +- 0.026, 0.962 +- 0.011, 1.000 +- 0.000
suff++_acc_int  =  0.859 +- 0.007, 0.872 +- 0.004
nec class all_L1  =  0.052 +- 0.007, 0.042 +- 0.006, 0.034 +- 0.005
nec class all_KL  =  0.046 +- 0.007, 0.037 +- 0.006, 0.027 +- 0.001
nec_acc_int  =  0.870 +- 0.005, 0.869 +- 0.004, 0.869 +- 0.003

Eval split val
suff++ class all_L1  =  0.900 +- 0.013, 0.934 +- 0.007, 0.957 +- 0.006, 1.000 +- 0.000
suff++ class all_KL  =  0.862 +- 0.035, 0.924 +- 0.016, 0.950 +- 0.017, 1.000 +- 0.000
suff++_acc_int  =  0.774 +- 0.008, 0.827 +- 0.005, 0.874 +- 0.003
nec class all_L1  =  0.075 +- 0.008, 0.045 +- 0.004, 0.035 +- 0.002, 0.030 +- 0.003
nec class all_KL  =  0.065 +- 0.012, 0.032 +- 0.006, 0.023 +- 0.003, 0.018 +- 0.001
nec_acc_int  =  0.796 +- 0.008, 0.839 +- 0.004, 0.874 +- 0.006, 0.879 +- 0.005

Eval split test
suff++ class all_L1  =  0.901 +- 0.013, 0.915 +- 0.009, 0.958 +- 0.003, 1.000 +- 0.000
suff++ class all_KL  =  0.879 +- 0.034, 0.914 +- 0.019, 0.967 +- 0.008, 1.000 +- 0.000
suff++_acc_int  =  0.737 +- 0.004, 0.785 +- 0.010, 0.830 +- 0.005
nec class all_L1  =  0.072 +- 0.011, 0.062 +- 0.006, 0.047 +- 0.002, 0.041 +- 0.005
nec class all_KL  =  0.052 +- 0.020, 0.039 +- 0.009, 0.029 +- 0.003, 0.024 +- 0.003
nec_acc_int  =  0.759 +- 0.004, 0.792 +- 0.008, 0.830 +- 0.007, 0.832 +- 0.006


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.493 +- 0.003, 0.498 +- 0.003, 0.517 +- 0.003
Faith. Armon (L1)= 		  =  0.099 +- 0.012, 0.080 +- 0.011, 0.065 +- 0.009
Faith. GMean (L1)= 	  =  0.221 +- 0.013, 0.199 +- 0.013, 0.183 +- 0.014
Faith. Aritm (KL)= 		  =  0.477 +- 0.009, 0.499 +- 0.003, 0.514 +- 0.001
Faith. Armon (KL)= 		  =  0.087 +- 0.013, 0.070 +- 0.011, 0.053 +- 0.002
Faith. GMean (KL)= 	  =  0.203 +- 0.013, 0.187 +- 0.014, 0.164 +- 0.004

Eval split val
Faith. Aritm (L1)= 		  =  0.488 +- 0.004, 0.490 +- 0.002, 0.496 +- 0.003, 0.515 +- 0.001
Faith. Armon (L1)= 		  =  0.139 +- 0.014, 0.086 +- 0.007, 0.067 +- 0.005, 0.058 +- 0.006
Faith. GMean (L1)= 	  =  0.260 +- 0.013, 0.205 +- 0.008, 0.182 +- 0.006, 0.173 +- 0.008
Faith. Aritm (KL)= 		  =  0.464 +- 0.012, 0.478 +- 0.005, 0.486 +- 0.007, 0.509 +- 0.001
Faith. Armon (KL)= 		  =  0.120 +- 0.020, 0.061 +- 0.012, 0.045 +- 0.006, 0.035 +- 0.003
Faith. GMean (KL)= 	  =  0.235 +- 0.016, 0.170 +- 0.015, 0.147 +- 0.009, 0.133 +- 0.005

Eval split test
Faith. Aritm (L1)= 		  =  0.487 +- 0.003, 0.488 +- 0.002, 0.503 +- 0.002, 0.521 +- 0.003
Faith. Armon (L1)= 		  =  0.134 +- 0.019, 0.115 +- 0.010, 0.090 +- 0.004, 0.079 +- 0.009
Faith. GMean (L1)= 	  =  0.255 +- 0.017, 0.237 +- 0.009, 0.212 +- 0.005, 0.203 +- 0.013
Faith. Aritm (KL)= 		  =  0.465 +- 0.008, 0.477 +- 0.006, 0.498 +- 0.003, 0.512 +- 0.002
Faith. Armon (KL)= 		  =  0.097 +- 0.034, 0.075 +- 0.016, 0.056 +- 0.006, 0.047 +- 0.006
Faith. GMean (KL)= 	  =  0.209 +- 0.032, 0.189 +- 0.018, 0.167 +- 0.009, 0.155 +- 0.010
Computed for split load_split = id



Completed in  0:14:50.106815  for LECIvGIN GOODSST2/length



DONE LECI GOODSST2/length

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 14:26:16 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:17 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:19 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:20 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:22 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:25 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:26:27 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 67...
[0m[1;37mINFO[0m: [1mCheckpoint 67: 
-----------------------------------
Train ACCURACY: 0.9996
Train Loss: 0.0019
ID Validation ACCURACY: 0.6913
ID Validation Loss: 2.0131
ID Test ACCURACY: 0.6787
ID Test Loss: 2.1331
OOD Validation ACCURACY: 0.5972
OOD Validation Loss: 2.8178
OOD Test ACCURACY: 0.5566
OOD Test Loss: 3.9666

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 17...
[0m[1;37mINFO[0m: [1mCheckpoint 17: 
-----------------------------------
Train ACCURACY: 0.9004
Train Loss: 0.2795
ID Validation ACCURACY: 0.6625
ID Validation Loss: 0.9229
ID Test ACCURACY: 0.6931
ID Test Loss: 0.9534
OOD Validation ACCURACY: 0.6235
OOD Validation Loss: 1.2698
OOD Test ACCURACY: 0.5704
OOD Test Loss: 1.9723

[0m[1;37mINFO[0m: [1mChartInfo 0.6787 0.5566 0.6931 0.5704 0.6625 0.6235[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.657
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.591
SUFF++ for r=0.3 class 0 = 0.621 +- 0.311 (in-sample avg dev_std = 0.594)
SUFF++ for r=0.3 class 1 = 0.709 +- 0.311 (in-sample avg dev_std = 0.594)
SUFF++ for r=0.3 class 2 = 0.64 +- 0.311 (in-sample avg dev_std = 0.594)
SUFF++ for r=0.3 all KL = 0.503 +- 0.311 (in-sample avg dev_std = 0.594)
SUFF++ for r=0.3 all L1 = 0.668 +- 0.211 (in-sample avg dev_std = 0.594)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.69
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.64
SUFF++ for r=0.6 class 0 = 0.758 +- 0.290 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.6 class 1 = 0.801 +- 0.290 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.6 class 2 = 0.758 +- 0.290 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.6 all KL = 0.693 +- 0.290 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.6 all L1 = 0.778 +- 0.201 (in-sample avg dev_std = 0.441)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.689
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.673
SUFF++ for r=0.9 class 0 = 0.914 +- 0.125 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.9 class 1 = 0.899 +- 0.125 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.9 class 2 = 0.896 +- 0.125 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.9 all KL = 0.93 +- 0.125 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.9 all L1 = 0.902 +- 0.142 (in-sample avg dev_std = 0.208)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.561
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.553
SUFF++ for r=0.3 class 0 = 0.631 +- 0.294 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.3 class 1 = 0.664 +- 0.294 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.3 class 2 = 0.591 +- 0.294 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.3 all KL = 0.489 +- 0.294 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.3 all L1 = 0.64 +- 0.216 (in-sample avg dev_std = 0.582)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.592
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.582
SUFF++ for r=0.6 class 0 = 0.76 +- 0.254 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.6 class 1 = 0.773 +- 0.254 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.6 class 2 = 0.72 +- 0.254 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.6 all KL = 0.721 +- 0.254 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.6 all L1 = 0.759 +- 0.210 (in-sample avg dev_std = 0.411)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.605
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.592
SUFF++ for r=0.9 class 0 = 0.895 +- 0.136 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.9 class 1 = 0.881 +- 0.136 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.9 class 2 = 0.865 +- 0.136 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.9 all KL = 0.92 +- 0.136 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.9 all L1 = 0.881 +- 0.163 (in-sample avg dev_std = 0.204)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.506
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.48
SUFF++ for r=0.3 class 0 = 0.624 +- 0.268 (in-sample avg dev_std = 0.623)
SUFF++ for r=0.3 class 1 = 0.602 +- 0.268 (in-sample avg dev_std = 0.623)
SUFF++ for r=0.3 class 2 = 0.567 +- 0.268 (in-sample avg dev_std = 0.623)
SUFF++ for r=0.3 all KL = 0.414 +- 0.268 (in-sample avg dev_std = 0.623)
SUFF++ for r=0.3 all L1 = 0.599 +- 0.206 (in-sample avg dev_std = 0.623)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.534
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.522
SUFF++ for r=0.6 class 0 = 0.767 +- 0.267 (in-sample avg dev_std = 0.453)
SUFF++ for r=0.6 class 1 = 0.735 +- 0.267 (in-sample avg dev_std = 0.453)
SUFF++ for r=0.6 class 2 = 0.7 +- 0.267 (in-sample avg dev_std = 0.453)
SUFF++ for r=0.6 all KL = 0.666 +- 0.267 (in-sample avg dev_std = 0.453)
SUFF++ for r=0.6 all L1 = 0.735 +- 0.216 (in-sample avg dev_std = 0.453)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.545
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.537
SUFF++ for r=0.9 class 0 = 0.914 +- 0.135 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.9 class 1 = 0.876 +- 0.135 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.9 class 2 = 0.87 +- 0.135 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.9 all KL = 0.919 +- 0.135 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.9 all L1 = 0.884 +- 0.162 (in-sample avg dev_std = 0.197)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.657
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.635
NEC for r=0.3 class 0 = 0.236 +- 0.309 (in-sample avg dev_std = 0.348)
NEC for r=0.3 class 1 = 0.224 +- 0.309 (in-sample avg dev_std = 0.348)
NEC for r=0.3 class 2 = 0.24 +- 0.309 (in-sample avg dev_std = 0.348)
NEC for r=0.3 all KL = 0.259 +- 0.309 (in-sample avg dev_std = 0.348)
NEC for r=0.3 all L1 = 0.232 +- 0.248 (in-sample avg dev_std = 0.348)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.69
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.663
NEC for r=0.6 class 0 = 0.161 +- 0.236 (in-sample avg dev_std = 0.268)
NEC for r=0.6 class 1 = 0.157 +- 0.236 (in-sample avg dev_std = 0.268)
NEC for r=0.6 class 2 = 0.139 +- 0.236 (in-sample avg dev_std = 0.268)
NEC for r=0.6 all KL = 0.149 +- 0.236 (in-sample avg dev_std = 0.268)
NEC for r=0.6 all L1 = 0.153 +- 0.205 (in-sample avg dev_std = 0.268)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.69
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.67
NEC for r=0.9 class 0 = 0.103 +- 0.151 (in-sample avg dev_std = 0.184)
NEC for r=0.9 class 1 = 0.102 +- 0.151 (in-sample avg dev_std = 0.184)
NEC for r=0.9 class 2 = 0.107 +- 0.151 (in-sample avg dev_std = 0.184)
NEC for r=0.9 all KL = 0.073 +- 0.151 (in-sample avg dev_std = 0.184)
NEC for r=0.9 all L1 = 0.104 +- 0.163 (in-sample avg dev_std = 0.184)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.688
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.676
NEC for r=1.0 class 0 = 0.096 +- 0.134 (in-sample avg dev_std = 0.181)
NEC for r=1.0 class 1 = 0.09 +- 0.134 (in-sample avg dev_std = 0.181)
NEC for r=1.0 class 2 = 0.084 +- 0.134 (in-sample avg dev_std = 0.181)
NEC for r=1.0 all KL = 0.06 +- 0.134 (in-sample avg dev_std = 0.181)
NEC for r=1.0 all L1 = 0.09 +- 0.149 (in-sample avg dev_std = 0.181)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.561
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.568
NEC for r=0.3 class 0 = 0.31 +- 0.334 (in-sample avg dev_std = 0.394)
NEC for r=0.3 class 1 = 0.298 +- 0.334 (in-sample avg dev_std = 0.394)
NEC for r=0.3 class 2 = 0.332 +- 0.334 (in-sample avg dev_std = 0.394)
NEC for r=0.3 all KL = 0.351 +- 0.334 (in-sample avg dev_std = 0.394)
NEC for r=0.3 all L1 = 0.308 +- 0.273 (in-sample avg dev_std = 0.394)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.592
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.585
NEC for r=0.6 class 0 = 0.202 +- 0.251 (in-sample avg dev_std = 0.293)
NEC for r=0.6 class 1 = 0.198 +- 0.251 (in-sample avg dev_std = 0.293)
NEC for r=0.6 class 2 = 0.221 +- 0.251 (in-sample avg dev_std = 0.293)
NEC for r=0.6 all KL = 0.192 +- 0.251 (in-sample avg dev_std = 0.293)
NEC for r=0.6 all L1 = 0.204 +- 0.232 (in-sample avg dev_std = 0.293)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.605
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.594
NEC for r=0.9 class 0 = 0.12 +- 0.162 (in-sample avg dev_std = 0.197)
NEC for r=0.9 class 1 = 0.129 +- 0.162 (in-sample avg dev_std = 0.197)
NEC for r=0.9 class 2 = 0.151 +- 0.162 (in-sample avg dev_std = 0.197)
NEC for r=0.9 all KL = 0.094 +- 0.162 (in-sample avg dev_std = 0.197)
NEC for r=0.9 all L1 = 0.132 +- 0.184 (in-sample avg dev_std = 0.197)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.605
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.601
NEC for r=1.0 class 0 = 0.115 +- 0.155 (in-sample avg dev_std = 0.199)
NEC for r=1.0 class 1 = 0.125 +- 0.155 (in-sample avg dev_std = 0.199)
NEC for r=1.0 class 2 = 0.135 +- 0.155 (in-sample avg dev_std = 0.199)
NEC for r=1.0 all KL = 0.088 +- 0.155 (in-sample avg dev_std = 0.199)
NEC for r=1.0 all L1 = 0.124 +- 0.179 (in-sample avg dev_std = 0.199)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.506
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.521
NEC for r=0.3 class 0 = 0.27 +- 0.321 (in-sample avg dev_std = 0.390)
NEC for r=0.3 class 1 = 0.296 +- 0.321 (in-sample avg dev_std = 0.390)
NEC for r=0.3 class 2 = 0.31 +- 0.321 (in-sample avg dev_std = 0.390)
NEC for r=0.3 all KL = 0.329 +- 0.321 (in-sample avg dev_std = 0.390)
NEC for r=0.3 all L1 = 0.293 +- 0.264 (in-sample avg dev_std = 0.390)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.534
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.528
NEC for r=0.6 class 0 = 0.152 +- 0.243 (in-sample avg dev_std = 0.288)
NEC for r=0.6 class 1 = 0.206 +- 0.243 (in-sample avg dev_std = 0.288)
NEC for r=0.6 class 2 = 0.226 +- 0.243 (in-sample avg dev_std = 0.288)
NEC for r=0.6 all KL = 0.182 +- 0.243 (in-sample avg dev_std = 0.288)
NEC for r=0.6 all L1 = 0.197 +- 0.229 (in-sample avg dev_std = 0.288)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.545
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.538
NEC for r=0.9 class 0 = 0.091 +- 0.166 (in-sample avg dev_std = 0.208)
NEC for r=0.9 class 1 = 0.134 +- 0.166 (in-sample avg dev_std = 0.208)
NEC for r=0.9 class 2 = 0.142 +- 0.166 (in-sample avg dev_std = 0.208)
NEC for r=0.9 all KL = 0.093 +- 0.166 (in-sample avg dev_std = 0.208)
NEC for r=0.9 all L1 = 0.125 +- 0.181 (in-sample avg dev_std = 0.208)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.551
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.543
NEC for r=1.0 class 0 = 0.087 +- 0.148 (in-sample avg dev_std = 0.200)
NEC for r=1.0 class 1 = 0.119 +- 0.148 (in-sample avg dev_std = 0.200)
NEC for r=1.0 class 2 = 0.12 +- 0.148 (in-sample avg dev_std = 0.200)
NEC for r=1.0 all KL = 0.08 +- 0.148 (in-sample avg dev_std = 0.200)
NEC for r=1.0 all L1 = 0.111 +- 0.165 (in-sample avg dev_std = 0.200)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 14:31:10 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:10 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:12 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:13 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:13 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:15 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:31:16 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 20...
[0m[1;37mINFO[0m: [1mCheckpoint 20: 
-----------------------------------
Train ACCURACY: 0.9201
Train Loss: 0.2250
ID Validation ACCURACY: 0.6949
ID Validation Loss: 1.0071
ID Test ACCURACY: 0.6841
ID Test Loss: 1.0211
OOD Validation ACCURACY: 0.6297
OOD Validation Loss: 1.2650
OOD Test ACCURACY: 0.5916
OOD Test Loss: 1.6996

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 6...
[0m[1;37mINFO[0m: [1mCheckpoint 6: 
-----------------------------------
Train ACCURACY: 0.7459
Train Loss: 0.5974
ID Validation ACCURACY: 0.6805
ID Validation Loss: 0.7660
ID Test ACCURACY: 0.6895
ID Test Loss: 0.7495
OOD Validation ACCURACY: 0.6403
OOD Validation Loss: 0.8572
OOD Test ACCURACY: 0.6095
OOD Test Loss: 1.0455

[0m[1;37mINFO[0m: [1mChartInfo 0.6841 0.5916 0.6895 0.6095 0.6805 0.6403[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.626
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.577
SUFF++ for r=0.3 class 0 = 0.648 +- 0.136 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.3 class 1 = 0.697 +- 0.136 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.3 class 2 = 0.727 +- 0.136 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.3 all KL = 0.816 +- 0.136 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.3 all L1 = 0.693 +- 0.123 (in-sample avg dev_std = 0.341)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.668
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.624
SUFF++ for r=0.6 class 0 = 0.727 +- 0.136 (in-sample avg dev_std = 0.306)
SUFF++ for r=0.6 class 1 = 0.762 +- 0.136 (in-sample avg dev_std = 0.306)
SUFF++ for r=0.6 class 2 = 0.778 +- 0.136 (in-sample avg dev_std = 0.306)
SUFF++ for r=0.6 all KL = 0.85 +- 0.136 (in-sample avg dev_std = 0.306)
SUFF++ for r=0.6 all L1 = 0.758 +- 0.138 (in-sample avg dev_std = 0.306)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.673
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.674
SUFF++ for r=0.9 class 0 = 0.87 +- 0.052 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.9 class 1 = 0.898 +- 0.052 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.9 class 2 = 0.899 +- 0.052 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.9 all KL = 0.965 +- 0.052 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.9 all L1 = 0.892 +- 0.098 (in-sample avg dev_std = 0.137)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.576
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.575
SUFF++ for r=0.3 class 0 = 0.719 +- 0.103 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.3 class 1 = 0.752 +- 0.103 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.3 class 2 = 0.734 +- 0.103 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.3 all KL = 0.886 +- 0.103 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.3 all L1 = 0.74 +- 0.109 (in-sample avg dev_std = 0.238)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.621
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.61
SUFF++ for r=0.6 class 0 = 0.773 +- 0.088 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.6 class 1 = 0.81 +- 0.088 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.6 class 2 = 0.776 +- 0.088 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.6 all KL = 0.909 +- 0.088 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.6 all L1 = 0.793 +- 0.121 (in-sample avg dev_std = 0.208)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.625
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.635
SUFF++ for r=0.9 class 0 = 0.877 +- 0.045 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.9 class 1 = 0.893 +- 0.045 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.9 class 2 = 0.868 +- 0.045 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.9 all KL = 0.965 +- 0.045 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.9 all L1 = 0.884 +- 0.100 (in-sample avg dev_std = 0.125)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.553
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.554
SUFF++ for r=0.3 class 0 = 0.74 +- 0.097 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.3 class 1 = 0.767 +- 0.097 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.3 class 2 = 0.739 +- 0.097 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.3 all KL = 0.896 +- 0.097 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.3 all L1 = 0.753 +- 0.104 (in-sample avg dev_std = 0.229)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.584
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.57
SUFF++ for r=0.6 class 0 = 0.794 +- 0.100 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.6 class 1 = 0.794 +- 0.100 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.6 class 2 = 0.771 +- 0.100 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.6 all KL = 0.896 +- 0.100 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.6 all L1 = 0.788 +- 0.121 (in-sample avg dev_std = 0.235)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.59
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.587
SUFF++ for r=0.9 class 0 = 0.892 +- 0.048 (in-sample avg dev_std = 0.134)
SUFF++ for r=0.9 class 1 = 0.887 +- 0.048 (in-sample avg dev_std = 0.134)
SUFF++ for r=0.9 class 2 = 0.886 +- 0.048 (in-sample avg dev_std = 0.134)
SUFF++ for r=0.9 all KL = 0.965 +- 0.048 (in-sample avg dev_std = 0.134)
SUFF++ for r=0.9 all L1 = 0.888 +- 0.100 (in-sample avg dev_std = 0.134)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.626
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.617
NEC for r=0.3 class 0 = 0.253 +- 0.117 (in-sample avg dev_std = 0.201)
NEC for r=0.3 class 1 = 0.233 +- 0.117 (in-sample avg dev_std = 0.201)
NEC for r=0.3 class 2 = 0.233 +- 0.117 (in-sample avg dev_std = 0.201)
NEC for r=0.3 all KL = 0.104 +- 0.117 (in-sample avg dev_std = 0.201)
NEC for r=0.3 all L1 = 0.238 +- 0.138 (in-sample avg dev_std = 0.201)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.668
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.646
NEC for r=0.6 class 0 = 0.217 +- 0.110 (in-sample avg dev_std = 0.182)
NEC for r=0.6 class 1 = 0.165 +- 0.110 (in-sample avg dev_std = 0.182)
NEC for r=0.6 class 2 = 0.166 +- 0.110 (in-sample avg dev_std = 0.182)
NEC for r=0.6 all KL = 0.076 +- 0.110 (in-sample avg dev_std = 0.182)
NEC for r=0.6 all L1 = 0.178 +- 0.135 (in-sample avg dev_std = 0.182)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.673
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.661
NEC for r=0.9 class 0 = 0.148 +- 0.070 (in-sample avg dev_std = 0.123)
NEC for r=0.9 class 1 = 0.103 +- 0.070 (in-sample avg dev_std = 0.123)
NEC for r=0.9 class 2 = 0.124 +- 0.070 (in-sample avg dev_std = 0.123)
NEC for r=0.9 all KL = 0.041 +- 0.070 (in-sample avg dev_std = 0.123)
NEC for r=0.9 all L1 = 0.12 +- 0.110 (in-sample avg dev_std = 0.123)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.693
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.666
NEC for r=1.0 class 0 = 0.128 +- 0.076 (in-sample avg dev_std = 0.123)
NEC for r=1.0 class 1 = 0.096 +- 0.076 (in-sample avg dev_std = 0.123)
NEC for r=1.0 class 2 = 0.111 +- 0.076 (in-sample avg dev_std = 0.123)
NEC for r=1.0 all KL = 0.038 +- 0.076 (in-sample avg dev_std = 0.123)
NEC for r=1.0 all L1 = 0.108 +- 0.111 (in-sample avg dev_std = 0.123)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.576
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.6
NEC for r=0.3 class 0 = 0.257 +- 0.106 (in-sample avg dev_std = 0.187)
NEC for r=0.3 class 1 = 0.247 +- 0.106 (in-sample avg dev_std = 0.187)
NEC for r=0.3 class 2 = 0.238 +- 0.106 (in-sample avg dev_std = 0.187)
NEC for r=0.3 all KL = 0.099 +- 0.106 (in-sample avg dev_std = 0.187)
NEC for r=0.3 all L1 = 0.248 +- 0.127 (in-sample avg dev_std = 0.187)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.621
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.62
NEC for r=0.6 class 0 = 0.206 +- 0.094 (in-sample avg dev_std = 0.161)
NEC for r=0.6 class 1 = 0.169 +- 0.094 (in-sample avg dev_std = 0.161)
NEC for r=0.6 class 2 = 0.195 +- 0.094 (in-sample avg dev_std = 0.161)
NEC for r=0.6 all KL = 0.073 +- 0.094 (in-sample avg dev_std = 0.161)
NEC for r=0.6 all L1 = 0.184 +- 0.130 (in-sample avg dev_std = 0.161)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.625
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.629
NEC for r=0.9 class 0 = 0.133 +- 0.060 (in-sample avg dev_std = 0.113)
NEC for r=0.9 class 1 = 0.112 +- 0.060 (in-sample avg dev_std = 0.113)
NEC for r=0.9 class 2 = 0.129 +- 0.060 (in-sample avg dev_std = 0.113)
NEC for r=0.9 all KL = 0.039 +- 0.060 (in-sample avg dev_std = 0.113)
NEC for r=0.9 all L1 = 0.121 +- 0.110 (in-sample avg dev_std = 0.113)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.629
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.636
NEC for r=1.0 class 0 = 0.14 +- 0.070 (in-sample avg dev_std = 0.132)
NEC for r=1.0 class 1 = 0.102 +- 0.070 (in-sample avg dev_std = 0.132)
NEC for r=1.0 class 2 = 0.129 +- 0.070 (in-sample avg dev_std = 0.132)
NEC for r=1.0 all KL = 0.044 +- 0.070 (in-sample avg dev_std = 0.132)
NEC for r=1.0 all L1 = 0.117 +- 0.115 (in-sample avg dev_std = 0.132)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.553
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.566
NEC for r=0.3 class 0 = 0.252 +- 0.101 (in-sample avg dev_std = 0.175)
NEC for r=0.3 class 1 = 0.225 +- 0.101 (in-sample avg dev_std = 0.175)
NEC for r=0.3 class 2 = 0.244 +- 0.101 (in-sample avg dev_std = 0.175)
NEC for r=0.3 all KL = 0.092 +- 0.101 (in-sample avg dev_std = 0.175)
NEC for r=0.3 all L1 = 0.237 +- 0.126 (in-sample avg dev_std = 0.175)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.584
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.579
NEC for r=0.6 class 0 = 0.162 +- 0.084 (in-sample avg dev_std = 0.153)
NEC for r=0.6 class 1 = 0.174 +- 0.084 (in-sample avg dev_std = 0.153)
NEC for r=0.6 class 2 = 0.185 +- 0.084 (in-sample avg dev_std = 0.153)
NEC for r=0.6 all KL = 0.065 +- 0.084 (in-sample avg dev_std = 0.153)
NEC for r=0.6 all L1 = 0.174 +- 0.127 (in-sample avg dev_std = 0.153)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.59
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.585
NEC for r=0.9 class 0 = 0.115 +- 0.068 (in-sample avg dev_std = 0.121)
NEC for r=0.9 class 1 = 0.12 +- 0.068 (in-sample avg dev_std = 0.121)
NEC for r=0.9 class 2 = 0.126 +- 0.068 (in-sample avg dev_std = 0.121)
NEC for r=0.9 all KL = 0.041 +- 0.068 (in-sample avg dev_std = 0.121)
NEC for r=0.9 all L1 = 0.12 +- 0.117 (in-sample avg dev_std = 0.121)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.601
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.585
NEC for r=1.0 class 0 = 0.119 +- 0.086 (in-sample avg dev_std = 0.142)
NEC for r=1.0 class 1 = 0.116 +- 0.086 (in-sample avg dev_std = 0.142)
NEC for r=1.0 class 2 = 0.129 +- 0.086 (in-sample avg dev_std = 0.142)
NEC for r=1.0 all KL = 0.049 +- 0.086 (in-sample avg dev_std = 0.142)
NEC for r=1.0 all L1 = 0.12 +- 0.131 (in-sample avg dev_std = 0.142)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 14:35:59 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 04/07/2024 02:35:59 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:01 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:02 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:02 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:04 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:36:06 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 18...
[0m[1;37mINFO[0m: [1mCheckpoint 18: 
-----------------------------------
Train ACCURACY: 0.9139
Train Loss: 0.2503
ID Validation ACCURACY: 0.7076
ID Validation Loss: 0.8689
ID Test ACCURACY: 0.6895
ID Test Loss: 0.9759
OOD Validation ACCURACY: 0.6409
OOD Validation Loss: 1.2142
OOD Test ACCURACY: 0.5854
OOD Test Loss: 1.6093

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 26...
[0m[1;37mINFO[0m: [1mCheckpoint 26: 
-----------------------------------
Train ACCURACY: 0.9382
Train Loss: 0.1587
ID Validation ACCURACY: 0.6968
ID Validation Loss: 1.0487
ID Test ACCURACY: 0.6661
ID Test Loss: 1.2152
OOD Validation ACCURACY: 0.6521
OOD Validation Loss: 1.4007
OOD Test ACCURACY: 0.5909
OOD Test Loss: 1.8758

[0m[1;37mINFO[0m: [1mChartInfo 0.6895 0.5854 0.6661 0.5909 0.6968 0.6521[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.659
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.599
SUFF++ for r=0.3 class 0 = 0.678 +- 0.142 (in-sample avg dev_std = 0.370)
SUFF++ for r=0.3 class 1 = 0.71 +- 0.142 (in-sample avg dev_std = 0.370)
SUFF++ for r=0.3 class 2 = 0.648 +- 0.142 (in-sample avg dev_std = 0.370)
SUFF++ for r=0.3 all KL = 0.795 +- 0.142 (in-sample avg dev_std = 0.370)
SUFF++ for r=0.3 all L1 = 0.685 +- 0.135 (in-sample avg dev_std = 0.370)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.679
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.638
SUFF++ for r=0.6 class 0 = 0.762 +- 0.145 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.6 class 1 = 0.783 +- 0.145 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.6 class 2 = 0.716 +- 0.145 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.6 all KL = 0.843 +- 0.145 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.6 all L1 = 0.759 +- 0.152 (in-sample avg dev_std = 0.317)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.702
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.696
SUFF++ for r=0.9 class 0 = 0.893 +- 0.063 (in-sample avg dev_std = 0.150)
SUFF++ for r=0.9 class 1 = 0.892 +- 0.063 (in-sample avg dev_std = 0.150)
SUFF++ for r=0.9 class 2 = 0.876 +- 0.063 (in-sample avg dev_std = 0.150)
SUFF++ for r=0.9 all KL = 0.961 +- 0.063 (in-sample avg dev_std = 0.150)
SUFF++ for r=0.9 all L1 = 0.888 +- 0.104 (in-sample avg dev_std = 0.150)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.618
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.588
SUFF++ for r=0.3 class 0 = 0.673 +- 0.134 (in-sample avg dev_std = 0.318)
SUFF++ for r=0.3 class 1 = 0.725 +- 0.134 (in-sample avg dev_std = 0.318)
SUFF++ for r=0.3 class 2 = 0.669 +- 0.134 (in-sample avg dev_std = 0.318)
SUFF++ for r=0.3 all KL = 0.818 +- 0.134 (in-sample avg dev_std = 0.318)
SUFF++ for r=0.3 all L1 = 0.7 +- 0.136 (in-sample avg dev_std = 0.318)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.642
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.617
SUFF++ for r=0.6 class 0 = 0.762 +- 0.130 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.6 class 1 = 0.794 +- 0.130 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.6 class 2 = 0.734 +- 0.130 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.6 all KL = 0.868 +- 0.130 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.6 all L1 = 0.773 +- 0.152 (in-sample avg dev_std = 0.270)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.649
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.642
SUFF++ for r=0.9 class 0 = 0.857 +- 0.072 (in-sample avg dev_std = 0.150)
SUFF++ for r=0.9 class 1 = 0.877 +- 0.072 (in-sample avg dev_std = 0.150)
SUFF++ for r=0.9 class 2 = 0.85 +- 0.072 (in-sample avg dev_std = 0.150)
SUFF++ for r=0.9 all KL = 0.949 +- 0.072 (in-sample avg dev_std = 0.150)
SUFF++ for r=0.9 all L1 = 0.866 +- 0.128 (in-sample avg dev_std = 0.150)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.562
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.564
SUFF++ for r=0.3 class 0 = 0.718 +- 0.115 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.3 class 1 = 0.754 +- 0.115 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.3 class 2 = 0.696 +- 0.115 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.3 all KL = 0.861 +- 0.115 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.3 all L1 = 0.73 +- 0.129 (in-sample avg dev_std = 0.273)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.59
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.569
SUFF++ for r=0.6 class 0 = 0.805 +- 0.111 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.6 class 1 = 0.8 +- 0.111 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.6 class 2 = 0.76 +- 0.111 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.6 all KL = 0.888 +- 0.111 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.6 all L1 = 0.791 +- 0.147 (in-sample avg dev_std = 0.248)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.598
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.59
SUFF++ for r=0.9 class 0 = 0.875 +- 0.079 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.9 class 1 = 0.869 +- 0.079 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.9 class 2 = 0.843 +- 0.079 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.9 all KL = 0.944 +- 0.079 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.9 all L1 = 0.864 +- 0.131 (in-sample avg dev_std = 0.162)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.659
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.642
NEC for r=0.3 class 0 = 0.26 +- 0.127 (in-sample avg dev_std = 0.215)
NEC for r=0.3 class 1 = 0.212 +- 0.127 (in-sample avg dev_std = 0.215)
NEC for r=0.3 class 2 = 0.253 +- 0.127 (in-sample avg dev_std = 0.215)
NEC for r=0.3 all KL = 0.107 +- 0.127 (in-sample avg dev_std = 0.215)
NEC for r=0.3 all L1 = 0.235 +- 0.142 (in-sample avg dev_std = 0.215)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.679
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.671
NEC for r=0.6 class 0 = 0.202 +- 0.106 (in-sample avg dev_std = 0.194)
NEC for r=0.6 class 1 = 0.16 +- 0.106 (in-sample avg dev_std = 0.194)
NEC for r=0.6 class 2 = 0.192 +- 0.106 (in-sample avg dev_std = 0.194)
NEC for r=0.6 all KL = 0.081 +- 0.106 (in-sample avg dev_std = 0.194)
NEC for r=0.6 all L1 = 0.179 +- 0.139 (in-sample avg dev_std = 0.194)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.703
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.694
NEC for r=0.9 class 0 = 0.126 +- 0.069 (in-sample avg dev_std = 0.142)
NEC for r=0.9 class 1 = 0.114 +- 0.069 (in-sample avg dev_std = 0.142)
NEC for r=0.9 class 2 = 0.126 +- 0.069 (in-sample avg dev_std = 0.142)
NEC for r=0.9 all KL = 0.042 +- 0.069 (in-sample avg dev_std = 0.142)
NEC for r=0.9 all L1 = 0.12 +- 0.110 (in-sample avg dev_std = 0.142)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.704
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.699
NEC for r=1.0 class 0 = 0.118 +- 0.073 (in-sample avg dev_std = 0.132)
NEC for r=1.0 class 1 = 0.1 +- 0.073 (in-sample avg dev_std = 0.132)
NEC for r=1.0 class 2 = 0.105 +- 0.073 (in-sample avg dev_std = 0.132)
NEC for r=1.0 all KL = 0.037 +- 0.073 (in-sample avg dev_std = 0.132)
NEC for r=1.0 all L1 = 0.106 +- 0.107 (in-sample avg dev_std = 0.132)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.618
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.622
NEC for r=0.3 class 0 = 0.275 +- 0.124 (in-sample avg dev_std = 0.215)
NEC for r=0.3 class 1 = 0.227 +- 0.124 (in-sample avg dev_std = 0.215)
NEC for r=0.3 class 2 = 0.276 +- 0.124 (in-sample avg dev_std = 0.215)
NEC for r=0.3 all KL = 0.119 +- 0.124 (in-sample avg dev_std = 0.215)
NEC for r=0.3 all L1 = 0.249 +- 0.148 (in-sample avg dev_std = 0.215)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.642
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.641
NEC for r=0.6 class 0 = 0.203 +- 0.118 (in-sample avg dev_std = 0.196)
NEC for r=0.6 class 1 = 0.166 +- 0.118 (in-sample avg dev_std = 0.196)
NEC for r=0.6 class 2 = 0.216 +- 0.118 (in-sample avg dev_std = 0.196)
NEC for r=0.6 all KL = 0.087 +- 0.118 (in-sample avg dev_std = 0.196)
NEC for r=0.6 all L1 = 0.186 +- 0.149 (in-sample avg dev_std = 0.196)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.649
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.64
NEC for r=0.9 class 0 = 0.144 +- 0.075 (in-sample avg dev_std = 0.145)
NEC for r=0.9 class 1 = 0.122 +- 0.075 (in-sample avg dev_std = 0.145)
NEC for r=0.9 class 2 = 0.146 +- 0.075 (in-sample avg dev_std = 0.145)
NEC for r=0.9 all KL = 0.051 +- 0.075 (in-sample avg dev_std = 0.145)
NEC for r=0.9 all L1 = 0.132 +- 0.130 (in-sample avg dev_std = 0.145)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.641
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.64
NEC for r=1.0 class 0 = 0.128 +- 0.070 (in-sample avg dev_std = 0.132)
NEC for r=1.0 class 1 = 0.109 +- 0.070 (in-sample avg dev_std = 0.132)
NEC for r=1.0 class 2 = 0.128 +- 0.070 (in-sample avg dev_std = 0.132)
NEC for r=1.0 all KL = 0.043 +- 0.070 (in-sample avg dev_std = 0.132)
NEC for r=1.0 all L1 = 0.118 +- 0.123 (in-sample avg dev_std = 0.132)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.562
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.566
NEC for r=0.3 class 0 = 0.248 +- 0.110 (in-sample avg dev_std = 0.199)
NEC for r=0.3 class 1 = 0.216 +- 0.110 (in-sample avg dev_std = 0.199)
NEC for r=0.3 class 2 = 0.256 +- 0.110 (in-sample avg dev_std = 0.199)
NEC for r=0.3 all KL = 0.1 +- 0.110 (in-sample avg dev_std = 0.199)
NEC for r=0.3 all L1 = 0.234 +- 0.138 (in-sample avg dev_std = 0.199)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.59
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.586
NEC for r=0.6 class 0 = 0.173 +- 0.101 (in-sample avg dev_std = 0.179)
NEC for r=0.6 class 1 = 0.169 +- 0.101 (in-sample avg dev_std = 0.179)
NEC for r=0.6 class 2 = 0.188 +- 0.101 (in-sample avg dev_std = 0.179)
NEC for r=0.6 all KL = 0.076 +- 0.101 (in-sample avg dev_std = 0.179)
NEC for r=0.6 all L1 = 0.175 +- 0.146 (in-sample avg dev_std = 0.179)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.598
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.595
NEC for r=0.9 class 0 = 0.122 +- 0.077 (in-sample avg dev_std = 0.136)
NEC for r=0.9 class 1 = 0.113 +- 0.077 (in-sample avg dev_std = 0.136)
NEC for r=0.9 class 2 = 0.146 +- 0.077 (in-sample avg dev_std = 0.136)
NEC for r=0.9 all KL = 0.046 +- 0.077 (in-sample avg dev_std = 0.136)
NEC for r=0.9 all L1 = 0.123 +- 0.126 (in-sample avg dev_std = 0.136)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.594
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.589
NEC for r=1.0 class 0 = 0.119 +- 0.081 (in-sample avg dev_std = 0.137)
NEC for r=1.0 class 1 = 0.108 +- 0.081 (in-sample avg dev_std = 0.137)
NEC for r=1.0 class 2 = 0.138 +- 0.081 (in-sample avg dev_std = 0.137)
NEC for r=1.0 all KL = 0.046 +- 0.081 (in-sample avg dev_std = 0.137)
NEC for r=1.0 all L1 = 0.118 +- 0.131 (in-sample avg dev_std = 0.137)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 14:40:49 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:49 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:51 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:51 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:52 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:53 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:40:55 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 29...
[0m[1;37mINFO[0m: [1mCheckpoint 29: 
-----------------------------------
Train ACCURACY: 0.9764
Train Loss: 0.0983
ID Validation ACCURACY: 0.7040
ID Validation Loss: 1.0781
ID Test ACCURACY: 0.6841
ID Test Loss: 1.1423
OOD Validation ACCURACY: 0.6151
OOD Validation Loss: 1.3992
OOD Test ACCURACY: 0.5724
OOD Test Loss: 1.9331

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 9...
[0m[1;37mINFO[0m: [1mCheckpoint 9: 
-----------------------------------
Train ACCURACY: 0.7807
Train Loss: 0.5276
ID Validation ACCURACY: 0.6859
ID Validation Loss: 0.7585
ID Test ACCURACY: 0.6787
ID Test Loss: 0.7813
OOD Validation ACCURACY: 0.6415
OOD Validation Loss: 0.8864
OOD Test ACCURACY: 0.5964
OOD Test Loss: 1.0649

[0m[1;37mINFO[0m: [1mChartInfo 0.6841 0.5724 0.6787 0.5964 0.6859 0.6415[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.677
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.603
SUFF++ for r=0.3 class 0 = 0.715 +- 0.147 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.3 class 1 = 0.716 +- 0.147 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.3 class 2 = 0.71 +- 0.147 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.3 all KL = 0.817 +- 0.147 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.3 all L1 = 0.714 +- 0.126 (in-sample avg dev_std = 0.337)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.684
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.655
SUFF++ for r=0.6 class 0 = 0.79 +- 0.121 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.6 class 1 = 0.797 +- 0.121 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.6 class 2 = 0.783 +- 0.121 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.6 all KL = 0.879 +- 0.121 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.6 all L1 = 0.791 +- 0.131 (in-sample avg dev_std = 0.264)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.706
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.697
SUFF++ for r=0.9 class 0 = 0.888 +- 0.048 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.9 class 1 = 0.903 +- 0.048 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.9 class 2 = 0.895 +- 0.048 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.9 all KL = 0.962 +- 0.048 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.9 all L1 = 0.897 +- 0.090 (in-sample avg dev_std = 0.159)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.562
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.565
SUFF++ for r=0.3 class 0 = 0.74 +- 0.117 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.3 class 1 = 0.732 +- 0.117 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.3 class 2 = 0.696 +- 0.117 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.3 all KL = 0.851 +- 0.117 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.3 all L1 = 0.726 +- 0.122 (in-sample avg dev_std = 0.280)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.594
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.584
SUFF++ for r=0.6 class 0 = 0.775 +- 0.104 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.6 class 1 = 0.786 +- 0.104 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.6 class 2 = 0.764 +- 0.104 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.6 all KL = 0.886 +- 0.104 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.6 all L1 = 0.779 +- 0.127 (in-sample avg dev_std = 0.252)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.601
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.606
SUFF++ for r=0.9 class 0 = 0.882 +- 0.047 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.9 class 1 = 0.884 +- 0.047 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.9 class 2 = 0.879 +- 0.047 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.9 all KL = 0.961 +- 0.047 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.9 all L1 = 0.883 +- 0.094 (in-sample avg dev_std = 0.144)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.54
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.524
SUFF++ for r=0.3 class 0 = 0.742 +- 0.136 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.3 class 1 = 0.71 +- 0.136 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.3 class 2 = 0.685 +- 0.136 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.3 all KL = 0.827 +- 0.136 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.3 all L1 = 0.712 +- 0.123 (in-sample avg dev_std = 0.317)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.539
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.532
SUFF++ for r=0.6 class 0 = 0.791 +- 0.134 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.6 class 1 = 0.73 +- 0.134 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.6 class 2 = 0.723 +- 0.134 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.6 all KL = 0.832 +- 0.134 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.6 all L1 = 0.744 +- 0.139 (in-sample avg dev_std = 0.320)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.564
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.563
SUFF++ for r=0.9 class 0 = 0.894 +- 0.050 (in-sample avg dev_std = 0.143)
SUFF++ for r=0.9 class 1 = 0.877 +- 0.050 (in-sample avg dev_std = 0.143)
SUFF++ for r=0.9 class 2 = 0.889 +- 0.050 (in-sample avg dev_std = 0.143)
SUFF++ for r=0.9 all KL = 0.962 +- 0.050 (in-sample avg dev_std = 0.143)
SUFF++ for r=0.9 all L1 = 0.884 +- 0.099 (in-sample avg dev_std = 0.143)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.677
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.652
NEC for r=0.3 class 0 = 0.253 +- 0.152 (in-sample avg dev_std = 0.208)
NEC for r=0.3 class 1 = 0.229 +- 0.152 (in-sample avg dev_std = 0.208)
NEC for r=0.3 class 2 = 0.252 +- 0.152 (in-sample avg dev_std = 0.208)
NEC for r=0.3 all KL = 0.123 +- 0.152 (in-sample avg dev_std = 0.208)
NEC for r=0.3 all L1 = 0.241 +- 0.154 (in-sample avg dev_std = 0.208)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.684
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.665
NEC for r=0.6 class 0 = 0.171 +- 0.100 (in-sample avg dev_std = 0.165)
NEC for r=0.6 class 1 = 0.159 +- 0.100 (in-sample avg dev_std = 0.165)
NEC for r=0.6 class 2 = 0.192 +- 0.100 (in-sample avg dev_std = 0.165)
NEC for r=0.6 all KL = 0.073 +- 0.100 (in-sample avg dev_std = 0.165)
NEC for r=0.6 all L1 = 0.171 +- 0.137 (in-sample avg dev_std = 0.165)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.706
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.687
NEC for r=0.9 class 0 = 0.114 +- 0.074 (in-sample avg dev_std = 0.121)
NEC for r=0.9 class 1 = 0.105 +- 0.074 (in-sample avg dev_std = 0.121)
NEC for r=0.9 class 2 = 0.112 +- 0.074 (in-sample avg dev_std = 0.121)
NEC for r=0.9 all KL = 0.039 +- 0.074 (in-sample avg dev_std = 0.121)
NEC for r=0.9 all L1 = 0.109 +- 0.115 (in-sample avg dev_std = 0.121)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.703
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.685
NEC for r=1.0 class 0 = 0.105 +- 0.082 (in-sample avg dev_std = 0.138)
NEC for r=1.0 class 1 = 0.098 +- 0.082 (in-sample avg dev_std = 0.138)
NEC for r=1.0 class 2 = 0.108 +- 0.082 (in-sample avg dev_std = 0.138)
NEC for r=1.0 all KL = 0.041 +- 0.082 (in-sample avg dev_std = 0.138)
NEC for r=1.0 all L1 = 0.103 +- 0.114 (in-sample avg dev_std = 0.138)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.562
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.581
NEC for r=0.3 class 0 = 0.263 +- 0.132 (in-sample avg dev_std = 0.206)
NEC for r=0.3 class 1 = 0.262 +- 0.132 (in-sample avg dev_std = 0.206)
NEC for r=0.3 class 2 = 0.276 +- 0.132 (in-sample avg dev_std = 0.206)
NEC for r=0.3 all KL = 0.13 +- 0.132 (in-sample avg dev_std = 0.206)
NEC for r=0.3 all L1 = 0.265 +- 0.150 (in-sample avg dev_std = 0.206)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.594
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.595
NEC for r=0.6 class 0 = 0.208 +- 0.103 (in-sample avg dev_std = 0.172)
NEC for r=0.6 class 1 = 0.183 +- 0.103 (in-sample avg dev_std = 0.172)
NEC for r=0.6 class 2 = 0.186 +- 0.103 (in-sample avg dev_std = 0.172)
NEC for r=0.6 all KL = 0.081 +- 0.103 (in-sample avg dev_std = 0.172)
NEC for r=0.6 all L1 = 0.19 +- 0.140 (in-sample avg dev_std = 0.172)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.601
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.608
NEC for r=0.9 class 0 = 0.138 +- 0.076 (in-sample avg dev_std = 0.128)
NEC for r=0.9 class 1 = 0.118 +- 0.076 (in-sample avg dev_std = 0.128)
NEC for r=0.9 class 2 = 0.137 +- 0.076 (in-sample avg dev_std = 0.128)
NEC for r=0.9 all KL = 0.047 +- 0.076 (in-sample avg dev_std = 0.128)
NEC for r=0.9 all L1 = 0.127 +- 0.122 (in-sample avg dev_std = 0.128)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.604
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.605
NEC for r=1.0 class 0 = 0.14 +- 0.101 (in-sample avg dev_std = 0.146)
NEC for r=1.0 class 1 = 0.121 +- 0.101 (in-sample avg dev_std = 0.146)
NEC for r=1.0 class 2 = 0.135 +- 0.101 (in-sample avg dev_std = 0.146)
NEC for r=1.0 all KL = 0.057 +- 0.101 (in-sample avg dev_std = 0.146)
NEC for r=1.0 all L1 = 0.129 +- 0.136 (in-sample avg dev_std = 0.146)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.54
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.545
NEC for r=0.3 class 0 = 0.26 +- 0.133 (in-sample avg dev_std = 0.216)
NEC for r=0.3 class 1 = 0.266 +- 0.133 (in-sample avg dev_std = 0.216)
NEC for r=0.3 class 2 = 0.259 +- 0.133 (in-sample avg dev_std = 0.216)
NEC for r=0.3 all KL = 0.132 +- 0.133 (in-sample avg dev_std = 0.216)
NEC for r=0.3 all L1 = 0.262 +- 0.145 (in-sample avg dev_std = 0.216)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.539
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.556
NEC for r=0.6 class 0 = 0.165 +- 0.107 (in-sample avg dev_std = 0.172)
NEC for r=0.6 class 1 = 0.201 +- 0.107 (in-sample avg dev_std = 0.172)
NEC for r=0.6 class 2 = 0.186 +- 0.107 (in-sample avg dev_std = 0.172)
NEC for r=0.6 all KL = 0.084 +- 0.107 (in-sample avg dev_std = 0.172)
NEC for r=0.6 all L1 = 0.188 +- 0.144 (in-sample avg dev_std = 0.172)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.564
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.566
NEC for r=0.9 class 0 = 0.121 +- 0.080 (in-sample avg dev_std = 0.132)
NEC for r=0.9 class 1 = 0.145 +- 0.080 (in-sample avg dev_std = 0.132)
NEC for r=0.9 class 2 = 0.119 +- 0.080 (in-sample avg dev_std = 0.132)
NEC for r=0.9 all KL = 0.049 +- 0.080 (in-sample avg dev_std = 0.132)
NEC for r=0.9 all L1 = 0.132 +- 0.127 (in-sample avg dev_std = 0.132)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.569
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.574
NEC for r=1.0 class 0 = 0.124 +- 0.093 (in-sample avg dev_std = 0.153)
NEC for r=1.0 class 1 = 0.141 +- 0.093 (in-sample avg dev_std = 0.153)
NEC for r=1.0 class 2 = 0.125 +- 0.093 (in-sample avg dev_std = 0.153)
NEC for r=1.0 all KL = 0.056 +- 0.093 (in-sample avg dev_std = 0.153)
NEC for r=1.0 all L1 = 0.133 +- 0.139 (in-sample avg dev_std = 0.153)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 14:45:38 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:38 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:41 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:41 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:42 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:43 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:45:44 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 20...
[0m[1;37mINFO[0m: [1mCheckpoint 20: 
-----------------------------------
Train ACCURACY: 0.9347
Train Loss: 0.2081
ID Validation ACCURACY: 0.6968
ID Validation Loss: 0.9057
ID Test ACCURACY: 0.6787
ID Test Loss: 1.0057
OOD Validation ACCURACY: 0.6308
OOD Validation Loss: 1.1621
OOD Test ACCURACY: 0.5683
OOD Test Loss: 1.6111

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 11...
[0m[1;37mINFO[0m: [1mCheckpoint 11: 
-----------------------------------
Train ACCURACY: 0.8336
Train Loss: 0.4248
ID Validation ACCURACY: 0.6841
ID Validation Loss: 0.7984
ID Test ACCURACY: 0.6787
ID Test Loss: 0.8109
OOD Validation ACCURACY: 0.6459
OOD Validation Loss: 0.9402
OOD Test ACCURACY: 0.5978
OOD Test Loss: 1.1689

[0m[1;37mINFO[0m: [1mChartInfo 0.6787 0.5683 0.6787 0.5978 0.6841 0.6459[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.642
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.596
SUFF++ for r=0.3 class 0 = 0.717 +- 0.127 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.3 class 1 = 0.752 +- 0.127 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.3 class 2 = 0.697 +- 0.127 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.3 all KL = 0.857 +- 0.127 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.3 all L1 = 0.728 +- 0.113 (in-sample avg dev_std = 0.292)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.666
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.636
SUFF++ for r=0.6 class 0 = 0.749 +- 0.129 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.6 class 1 = 0.804 +- 0.129 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.6 class 2 = 0.748 +- 0.129 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.6 all KL = 0.876 +- 0.129 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.6 all L1 = 0.775 +- 0.130 (in-sample avg dev_std = 0.269)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.682
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.681
SUFF++ for r=0.9 class 0 = 0.889 +- 0.052 (in-sample avg dev_std = 0.130)
SUFF++ for r=0.9 class 1 = 0.908 +- 0.052 (in-sample avg dev_std = 0.130)
SUFF++ for r=0.9 class 2 = 0.895 +- 0.052 (in-sample avg dev_std = 0.130)
SUFF++ for r=0.9 all KL = 0.97 +- 0.052 (in-sample avg dev_std = 0.130)
SUFF++ for r=0.9 all L1 = 0.9 +- 0.091 (in-sample avg dev_std = 0.130)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.625
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.615
SUFF++ for r=0.3 class 0 = 0.784 +- 0.068 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.3 class 1 = 0.818 +- 0.068 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.3 class 2 = 0.778 +- 0.068 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.3 all KL = 0.934 +- 0.068 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.3 all L1 = 0.801 +- 0.090 (in-sample avg dev_std = 0.181)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.651
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.636
SUFF++ for r=0.6 class 0 = 0.803 +- 0.063 (in-sample avg dev_std = 0.177)
SUFF++ for r=0.6 class 1 = 0.837 +- 0.063 (in-sample avg dev_std = 0.177)
SUFF++ for r=0.6 class 2 = 0.781 +- 0.063 (in-sample avg dev_std = 0.177)
SUFF++ for r=0.6 all KL = 0.935 +- 0.063 (in-sample avg dev_std = 0.177)
SUFF++ for r=0.6 all L1 = 0.816 +- 0.097 (in-sample avg dev_std = 0.177)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.637
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.638
SUFF++ for r=0.9 class 0 = 0.898 +- 0.031 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.9 class 1 = 0.899 +- 0.031 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.9 class 2 = 0.886 +- 0.031 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.9 all KL = 0.975 +- 0.031 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.9 all L1 = 0.896 +- 0.079 (in-sample avg dev_std = 0.108)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.587
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.556
SUFF++ for r=0.3 class 0 = 0.768 +- 0.081 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.3 class 1 = 0.785 +- 0.081 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.3 class 2 = 0.733 +- 0.081 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.3 all KL = 0.908 +- 0.081 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.3 all L1 = 0.768 +- 0.093 (in-sample avg dev_std = 0.223)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.591
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.573
SUFF++ for r=0.6 class 0 = 0.825 +- 0.070 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.6 class 1 = 0.816 +- 0.070 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.6 class 2 = 0.78 +- 0.070 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.6 all KL = 0.923 +- 0.070 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.6 all L1 = 0.809 +- 0.102 (in-sample avg dev_std = 0.203)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.562
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.568
SUFF++ for r=0.9 class 0 = 0.919 +- 0.032 (in-sample avg dev_std = 0.109)
SUFF++ for r=0.9 class 1 = 0.901 +- 0.032 (in-sample avg dev_std = 0.109)
SUFF++ for r=0.9 class 2 = 0.892 +- 0.032 (in-sample avg dev_std = 0.109)
SUFF++ for r=0.9 all KL = 0.976 +- 0.032 (in-sample avg dev_std = 0.109)
SUFF++ for r=0.9 all L1 = 0.903 +- 0.082 (in-sample avg dev_std = 0.109)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.642
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.625
NEC for r=0.3 class 0 = 0.247 +- 0.109 (in-sample avg dev_std = 0.170)
NEC for r=0.3 class 1 = 0.208 +- 0.109 (in-sample avg dev_std = 0.170)
NEC for r=0.3 class 2 = 0.25 +- 0.109 (in-sample avg dev_std = 0.170)
NEC for r=0.3 all KL = 0.09 +- 0.109 (in-sample avg dev_std = 0.170)
NEC for r=0.3 all L1 = 0.229 +- 0.136 (in-sample avg dev_std = 0.170)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.666
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.659
NEC for r=0.6 class 0 = 0.203 +- 0.113 (in-sample avg dev_std = 0.172)
NEC for r=0.6 class 1 = 0.153 +- 0.113 (in-sample avg dev_std = 0.172)
NEC for r=0.6 class 2 = 0.2 +- 0.113 (in-sample avg dev_std = 0.172)
NEC for r=0.6 all KL = 0.075 +- 0.113 (in-sample avg dev_std = 0.172)
NEC for r=0.6 all L1 = 0.178 +- 0.137 (in-sample avg dev_std = 0.172)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.684
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.674
NEC for r=0.9 class 0 = 0.133 +- 0.075 (in-sample avg dev_std = 0.121)
NEC for r=0.9 class 1 = 0.106 +- 0.075 (in-sample avg dev_std = 0.121)
NEC for r=0.9 class 2 = 0.119 +- 0.075 (in-sample avg dev_std = 0.121)
NEC for r=0.9 all KL = 0.038 +- 0.075 (in-sample avg dev_std = 0.121)
NEC for r=0.9 all L1 = 0.116 +- 0.108 (in-sample avg dev_std = 0.121)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.693
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.678
NEC for r=1.0 class 0 = 0.122 +- 0.077 (in-sample avg dev_std = 0.122)
NEC for r=1.0 class 1 = 0.099 +- 0.077 (in-sample avg dev_std = 0.122)
NEC for r=1.0 class 2 = 0.111 +- 0.077 (in-sample avg dev_std = 0.122)
NEC for r=1.0 all KL = 0.037 +- 0.077 (in-sample avg dev_std = 0.122)
NEC for r=1.0 all L1 = 0.108 +- 0.112 (in-sample avg dev_std = 0.122)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.625
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.632
NEC for r=0.3 class 0 = 0.217 +- 0.070 (in-sample avg dev_std = 0.144)
NEC for r=0.3 class 1 = 0.182 +- 0.070 (in-sample avg dev_std = 0.144)
NEC for r=0.3 class 2 = 0.229 +- 0.070 (in-sample avg dev_std = 0.144)
NEC for r=0.3 all KL = 0.061 +- 0.070 (in-sample avg dev_std = 0.144)
NEC for r=0.3 all L1 = 0.2 +- 0.109 (in-sample avg dev_std = 0.144)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.651
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.638
NEC for r=0.6 class 0 = 0.157 +- 0.062 (in-sample avg dev_std = 0.122)
NEC for r=0.6 class 1 = 0.134 +- 0.062 (in-sample avg dev_std = 0.122)
NEC for r=0.6 class 2 = 0.176 +- 0.062 (in-sample avg dev_std = 0.122)
NEC for r=0.6 all KL = 0.042 +- 0.062 (in-sample avg dev_std = 0.122)
NEC for r=0.6 all L1 = 0.149 +- 0.106 (in-sample avg dev_std = 0.122)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.637
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.639
NEC for r=0.9 class 0 = 0.113 +- 0.043 (in-sample avg dev_std = 0.096)
NEC for r=0.9 class 1 = 0.105 +- 0.043 (in-sample avg dev_std = 0.096)
NEC for r=0.9 class 2 = 0.12 +- 0.043 (in-sample avg dev_std = 0.096)
NEC for r=0.9 all KL = 0.029 +- 0.043 (in-sample avg dev_std = 0.096)
NEC for r=0.9 all L1 = 0.11 +- 0.097 (in-sample avg dev_std = 0.096)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.631
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.637
NEC for r=1.0 class 0 = 0.118 +- 0.063 (in-sample avg dev_std = 0.117)
NEC for r=1.0 class 1 = 0.113 +- 0.063 (in-sample avg dev_std = 0.117)
NEC for r=1.0 class 2 = 0.126 +- 0.063 (in-sample avg dev_std = 0.117)
NEC for r=1.0 all KL = 0.038 +- 0.063 (in-sample avg dev_std = 0.117)
NEC for r=1.0 all L1 = 0.117 +- 0.113 (in-sample avg dev_std = 0.117)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.587
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.573
NEC for r=0.3 class 0 = 0.203 +- 0.075 (in-sample avg dev_std = 0.143)
NEC for r=0.3 class 1 = 0.189 +- 0.075 (in-sample avg dev_std = 0.143)
NEC for r=0.3 class 2 = 0.229 +- 0.075 (in-sample avg dev_std = 0.143)
NEC for r=0.3 all KL = 0.063 +- 0.075 (in-sample avg dev_std = 0.143)
NEC for r=0.3 all L1 = 0.203 +- 0.109 (in-sample avg dev_std = 0.143)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.591
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.58
NEC for r=0.6 class 0 = 0.149 +- 0.058 (in-sample avg dev_std = 0.115)
NEC for r=0.6 class 1 = 0.139 +- 0.058 (in-sample avg dev_std = 0.115)
NEC for r=0.6 class 2 = 0.171 +- 0.058 (in-sample avg dev_std = 0.115)
NEC for r=0.6 all KL = 0.044 +- 0.058 (in-sample avg dev_std = 0.115)
NEC for r=0.6 all L1 = 0.15 +- 0.105 (in-sample avg dev_std = 0.115)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.562
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.574
NEC for r=0.9 class 0 = 0.103 +- 0.051 (in-sample avg dev_std = 0.101)
NEC for r=0.9 class 1 = 0.118 +- 0.051 (in-sample avg dev_std = 0.101)
NEC for r=0.9 class 2 = 0.125 +- 0.051 (in-sample avg dev_std = 0.101)
NEC for r=0.9 all KL = 0.034 +- 0.051 (in-sample avg dev_std = 0.101)
NEC for r=0.9 all L1 = 0.116 +- 0.105 (in-sample avg dev_std = 0.101)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.567
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.571
NEC for r=1.0 class 0 = 0.104 +- 0.065 (in-sample avg dev_std = 0.118)
NEC for r=1.0 class 1 = 0.117 +- 0.065 (in-sample avg dev_std = 0.118)
NEC for r=1.0 class 2 = 0.127 +- 0.065 (in-sample avg dev_std = 0.118)
NEC for r=1.0 all KL = 0.04 +- 0.065 (in-sample avg dev_std = 0.118)
NEC for r=1.0 all L1 = 0.116 +- 0.118 (in-sample avg dev_std = 0.118)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.503, 0.693, 0.93, 1.0], 'all_L1': [0.668, 0.778, 0.902, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.816, 0.85, 0.965, 1.0], 'all_L1': [0.693, 0.758, 0.892, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.795, 0.843, 0.961, 1.0], 'all_L1': [0.685, 0.759, 0.888, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.817, 0.879, 0.962, 1.0], 'all_L1': [0.714, 0.791, 0.897, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.857, 0.876, 0.97, 1.0], 'all_L1': [0.728, 0.775, 0.9, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.259, 0.149, 0.073, 0.06], 'all_L1': [0.232, 0.153, 0.104, 0.09]}), defaultdict(<class 'list'>, {'all_KL': [0.104, 0.076, 0.041, 0.038], 'all_L1': [0.238, 0.178, 0.12, 0.108]}), defaultdict(<class 'list'>, {'all_KL': [0.107, 0.081, 0.042, 0.037], 'all_L1': [0.235, 0.179, 0.12, 0.106]}), defaultdict(<class 'list'>, {'all_KL': [0.123, 0.073, 0.039, 0.041], 'all_L1': [0.241, 0.171, 0.109, 0.103]}), defaultdict(<class 'list'>, {'all_KL': [0.09, 0.075, 0.038, 0.037], 'all_L1': [0.229, 0.178, 0.116, 0.108]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.489, 0.721, 0.92, 1.0], 'all_L1': [0.64, 0.759, 0.881, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.886, 0.909, 0.965, 1.0], 'all_L1': [0.74, 0.793, 0.884, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.818, 0.868, 0.949, 1.0], 'all_L1': [0.7, 0.773, 0.866, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.851, 0.886, 0.961, 1.0], 'all_L1': [0.726, 0.779, 0.883, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.934, 0.935, 0.975, 1.0], 'all_L1': [0.801, 0.816, 0.896, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.351, 0.192, 0.094, 0.088], 'all_L1': [0.308, 0.204, 0.132, 0.124]}), defaultdict(<class 'list'>, {'all_KL': [0.099, 0.073, 0.039, 0.044], 'all_L1': [0.248, 0.184, 0.121, 0.117]}), defaultdict(<class 'list'>, {'all_KL': [0.119, 0.087, 0.051, 0.043], 'all_L1': [0.249, 0.186, 0.132, 0.118]}), defaultdict(<class 'list'>, {'all_KL': [0.13, 0.081, 0.047, 0.057], 'all_L1': [0.265, 0.19, 0.127, 0.129]}), defaultdict(<class 'list'>, {'all_KL': [0.061, 0.042, 0.029, 0.038], 'all_L1': [0.2, 0.149, 0.11, 0.117]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.414, 0.666, 0.919, 1.0], 'all_L1': [0.599, 0.735, 0.884, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.896, 0.896, 0.965, 1.0], 'all_L1': [0.753, 0.788, 0.888, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.861, 0.888, 0.944, 1.0], 'all_L1': [0.73, 0.791, 0.864, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.827, 0.832, 0.962, 1.0], 'all_L1': [0.712, 0.744, 0.884, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.908, 0.923, 0.976, 1.0], 'all_L1': [0.768, 0.809, 0.903, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.329, 0.182, 0.093, 0.08], 'all_L1': [0.293, 0.197, 0.125, 0.111]}), defaultdict(<class 'list'>, {'all_KL': [0.092, 0.065, 0.041, 0.049], 'all_L1': [0.237, 0.174, 0.12, 0.12]}), defaultdict(<class 'list'>, {'all_KL': [0.1, 0.076, 0.046, 0.046], 'all_L1': [0.234, 0.175, 0.123, 0.118]}), defaultdict(<class 'list'>, {'all_KL': [0.132, 0.084, 0.049, 0.056], 'all_L1': [0.262, 0.188, 0.132, 0.133]}), defaultdict(<class 'list'>, {'all_KL': [0.063, 0.044, 0.034, 0.04], 'all_L1': [0.203, 0.15, 0.116, 0.116]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.698 +- 0.021, 0.772 +- 0.012, 0.896 +- 0.005, 1.000 +- 0.000
suff++ class all_KL  =  0.758 +- 0.129, 0.828 +- 0.069, 0.958 +- 0.014, 1.000 +- 0.000
suff++_acc_int  =  0.593 +- 0.009, 0.639 +- 0.010, 0.685 +- 0.010
nec class all_L1  =  0.235 +- 0.004, 0.172 +- 0.010, 0.114 +- 0.006, 0.103 +- 0.007
nec class all_KL  =  0.137 +- 0.062, 0.091 +- 0.029, 0.047 +- 0.013, 0.043 +- 0.009
nec_acc_int  =  0.634 +- 0.012, 0.661 +- 0.008, 0.677 +- 0.012, 0.681 +- 0.011

Eval split val
suff++ class all_L1  =  0.721 +- 0.053, 0.784 +- 0.019, 0.882 +- 0.010, 1.000 +- 0.000
suff++ class all_KL  =  0.796 +- 0.158, 0.864 +- 0.075, 0.954 +- 0.019, 1.000 +- 0.000
suff++_acc_int  =  0.579 +- 0.021, 0.606 +- 0.020, 0.622 +- 0.020
nec class all_L1  =  0.254 +- 0.035, 0.183 +- 0.018, 0.124 +- 0.008, 0.121 +- 0.005
nec class all_KL  =  0.152 +- 0.102, 0.095 +- 0.051, 0.052 +- 0.022, 0.054 +- 0.018
nec_acc_int  =  0.601 +- 0.024, 0.616 +- 0.023, 0.622 +- 0.018, 0.624 +- 0.017

Eval split test
suff++ class all_L1  =  0.712 +- 0.060, 0.773 +- 0.029, 0.885 +- 0.012, 1.000 +- 0.000
suff++ class all_KL  =  0.781 +- 0.186, 0.841 +- 0.092, 0.953 +- 0.020, 1.000 +- 0.000
suff++_acc_int  =  0.536 +- 0.031, 0.554 +- 0.022, 0.569 +- 0.019
nec class all_L1  =  0.246 +- 0.030, 0.177 +- 0.016, 0.123 +- 0.005, 0.120 +- 0.007
nec class all_KL  =  0.143 +- 0.095, 0.090 +- 0.048, 0.053 +- 0.021, 0.054 +- 0.014
nec_acc_int  =  0.554 +- 0.019, 0.566 +- 0.021, 0.572 +- 0.020, 0.572 +- 0.016


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.466 +- 0.011, 0.472 +- 0.006, 0.505 +- 0.002, 0.552 +- 0.003
Faith. Armon (L1)= 		  =  0.351 +- 0.005, 0.281 +- 0.013, 0.202 +- 0.010, 0.187 +- 0.011
Faith. GMean (L1)= 	  =  0.405 +- 0.007, 0.364 +- 0.010, 0.319 +- 0.008, 0.321 +- 0.011
Faith. Aritm (KL)= 		  =  0.447 +- 0.034, 0.460 +- 0.020, 0.502 +- 0.001, 0.521 +- 0.004
Faith. Armon (KL)= 		  =  0.218 +- 0.064, 0.161 +- 0.042, 0.089 +- 0.024, 0.082 +- 0.016
Faith. GMean (KL)= 	  =  0.308 +- 0.029, 0.269 +- 0.026, 0.209 +- 0.026, 0.205 +- 0.020

Eval split val
Faith. Aritm (L1)= 		  =  0.488 +- 0.011, 0.483 +- 0.003, 0.503 +- 0.003, 0.561 +- 0.002
Faith. Armon (L1)= 		  =  0.373 +- 0.031, 0.296 +- 0.023, 0.218 +- 0.013, 0.216 +- 0.008
Faith. GMean (L1)= 	  =  0.426 +- 0.016, 0.378 +- 0.015, 0.331 +- 0.010, 0.348 +- 0.007
Faith. Aritm (KL)= 		  =  0.474 +- 0.029, 0.479 +- 0.012, 0.503 +- 0.002, 0.527 +- 0.009
Faith. Armon (KL)= 		  =  0.227 +- 0.098, 0.165 +- 0.074, 0.098 +- 0.039, 0.102 +- 0.032
Faith. GMean (KL)= 	  =  0.319 +- 0.057, 0.274 +- 0.056, 0.218 +- 0.042, 0.229 +- 0.037

Eval split test
Faith. Aritm (L1)= 		  =  0.479 +- 0.017, 0.475 +- 0.008, 0.504 +- 0.006, 0.560 +- 0.004
Faith. Armon (L1)= 		  =  0.363 +- 0.025, 0.287 +- 0.019, 0.216 +- 0.008, 0.214 +- 0.012
Faith. GMean (L1)= 	  =  0.416 +- 0.012, 0.369 +- 0.011, 0.330 +- 0.006, 0.346 +- 0.010
Faith. Aritm (KL)= 		  =  0.462 +- 0.046, 0.466 +- 0.023, 0.503 +- 0.004, 0.527 +- 0.007
Faith. Armon (KL)= 		  =  0.212 +- 0.085, 0.157 +- 0.069, 0.099 +- 0.036, 0.103 +- 0.025
Faith. GMean (KL)= 	  =  0.304 +- 0.044, 0.263 +- 0.048, 0.220 +- 0.038, 0.231 +- 0.028
Computed for split load_split = id



Completed in  0:24:18.128595  for LECIvGIN GOODTwitter/length



DONE LECI GOODTwitter/length

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 14:50:49 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 04/07/2024 02:50:49 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/07/2024 02:50:53 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/07/2024 02:50:56 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/07/2024 02:50:59 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:01 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:01 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:51:02 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 173...
[0m[1;37mINFO[0m: [1mCheckpoint 173: 
-----------------------------------
Train ROC-AUC: 0.9923
Train Loss: 0.0410
ID Validation ROC-AUC: 0.8459
ID Validation Loss: 0.1578
ID Test ROC-AUC: 0.8062
ID Test Loss: 0.1517
OOD Validation ROC-AUC: 0.7360
OOD Validation Loss: 0.1621
OOD Test ROC-AUC: 0.6792
OOD Test Loss: 0.1219

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 53...
[0m[1;37mINFO[0m: [1mCheckpoint 53: 
-----------------------------------
Train ROC-AUC: 0.9014
Train Loss: 0.0989
ID Validation ROC-AUC: 0.8203
ID Validation Loss: 0.1281
ID Test ROC-AUC: 0.8137
ID Test Loss: 0.1121
OOD Validation ROC-AUC: 0.7751
OOD Validation Loss: 0.1065
OOD Test ROC-AUC: 0.7337
OOD Test Loss: 0.0844

[0m[1;37mINFO[0m: [1mChartInfo 0.8062 0.6792 0.8137 0.7337 0.8203 0.7751[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 04/07/2024 02:51:04 PM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 04/07/2024 02:51:07 PM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 04/07/2024 02:51:08 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.672
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 340
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.581
SUFF++ for r=0.3 class 0.0 = 0.946 +- 0.044 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.3 class 1.0 = 0.892 +- 0.044 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.3 all KL = 0.968 +- 0.044 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.3 all L1 = 0.919 +- 0.081 (in-sample avg dev_std = 0.106)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.797
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.734
SUFF++ for r=0.6 class 0.0 = 0.964 +- 0.134 (in-sample avg dev_std = 0.175)
SUFF++ for r=0.6 class 1.0 = 0.819 +- 0.134 (in-sample avg dev_std = 0.175)
SUFF++ for r=0.6 all KL = 0.936 +- 0.134 (in-sample avg dev_std = 0.175)
SUFF++ for r=0.6 all L1 = 0.891 +- 0.166 (in-sample avg dev_std = 0.175)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.859
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.843
SUFF++ for r=0.9 class 0.0 = 0.992 +- 0.113 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.9 class 1.0 = 0.916 +- 0.113 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.9 all KL = 0.969 +- 0.113 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.9 all L1 = 0.954 +- 0.105 (in-sample avg dev_std = 0.159)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.697
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 243
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.593
SUFF++ for r=0.3 class 0.0 = 0.948 +- 0.049 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.3 class 1.0 = 0.9 +- 0.049 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.3 all KL = 0.972 +- 0.049 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.3 all L1 = 0.924 +- 0.085 (in-sample avg dev_std = 0.089)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.719
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.683
SUFF++ for r=0.6 class 0.0 = 0.971 +- 0.113 (in-sample avg dev_std = 0.161)
SUFF++ for r=0.6 class 1.0 = 0.848 +- 0.113 (in-sample avg dev_std = 0.161)
SUFF++ for r=0.6 all KL = 0.951 +- 0.113 (in-sample avg dev_std = 0.161)
SUFF++ for r=0.6 all L1 = 0.909 +- 0.153 (in-sample avg dev_std = 0.161)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.72
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.718
SUFF++ for r=0.9 class 0.0 = 0.988 +- 0.139 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.9 class 1.0 = 0.921 +- 0.139 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.9 all KL = 0.962 +- 0.139 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.9 all L1 = 0.954 +- 0.117 (in-sample avg dev_std = 0.181)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.583
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 147
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.552
SUFF++ for r=0.3 class 0.0 = 0.941 +- 0.028 (in-sample avg dev_std = 0.063)
SUFF++ for r=0.3 class 1.0 = 0.931 +- 0.028 (in-sample avg dev_std = 0.063)
SUFF++ for r=0.3 all KL = 0.978 +- 0.028 (in-sample avg dev_std = 0.063)
SUFF++ for r=0.3 all L1 = 0.936 +- 0.068 (in-sample avg dev_std = 0.063)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.618
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.574
SUFF++ for r=0.6 class 0.0 = 0.967 +- 0.094 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.6 class 1.0 = 0.889 +- 0.094 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.6 all KL = 0.961 +- 0.094 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.6 all L1 = 0.928 +- 0.129 (in-sample avg dev_std = 0.108)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.661
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.665
SUFF++ for r=0.9 class 0.0 = 0.981 +- 0.094 (in-sample avg dev_std = 0.121)
SUFF++ for r=0.9 class 1.0 = 0.966 +- 0.094 (in-sample avg dev_std = 0.121)
SUFF++ for r=0.9 all KL = 0.978 +- 0.094 (in-sample avg dev_std = 0.121)
SUFF++ for r=0.9 all L1 = 0.973 +- 0.084 (in-sample avg dev_std = 0.121)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.676
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.665
NEC for r=0.3 class 0.0 = 0.044 +- 0.034 (in-sample avg dev_std = 0.067)
NEC for r=0.3 class 1.0 = 0.081 +- 0.034 (in-sample avg dev_std = 0.067)
NEC for r=0.3 all KL = 0.018 +- 0.034 (in-sample avg dev_std = 0.067)
NEC for r=0.3 all L1 = 0.062 +- 0.068 (in-sample avg dev_std = 0.067)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.797
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.749
NEC for r=0.6 class 0.0 = 0.036 +- 0.138 (in-sample avg dev_std = 0.185)
NEC for r=0.6 class 1.0 = 0.186 +- 0.138 (in-sample avg dev_std = 0.185)
NEC for r=0.6 all KL = 0.067 +- 0.138 (in-sample avg dev_std = 0.185)
NEC for r=0.6 all L1 = 0.111 +- 0.168 (in-sample avg dev_std = 0.185)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.859
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.793
NEC for r=0.9 class 0.0 = 0.033 +- 0.263 (in-sample avg dev_std = 0.297)
NEC for r=0.9 class 1.0 = 0.262 +- 0.263 (in-sample avg dev_std = 0.297)
NEC for r=0.9 all KL = 0.154 +- 0.263 (in-sample avg dev_std = 0.297)
NEC for r=0.9 all L1 = 0.147 +- 0.221 (in-sample avg dev_std = 0.297)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.865
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.797
NEC for r=1.0 class 0.0 = 0.029 +- 0.279 (in-sample avg dev_std = 0.301)
NEC for r=1.0 class 1.0 = 0.265 +- 0.279 (in-sample avg dev_std = 0.301)
NEC for r=1.0 all KL = 0.169 +- 0.279 (in-sample avg dev_std = 0.301)
NEC for r=1.0 all L1 = 0.147 +- 0.223 (in-sample avg dev_std = 0.301)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.691
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.685
NEC for r=0.3 class 0.0 = 0.049 +- 0.030 (in-sample avg dev_std = 0.070)
NEC for r=0.3 class 1.0 = 0.08 +- 0.030 (in-sample avg dev_std = 0.070)
NEC for r=0.3 all KL = 0.019 +- 0.030 (in-sample avg dev_std = 0.070)
NEC for r=0.3 all L1 = 0.064 +- 0.064 (in-sample avg dev_std = 0.070)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.719
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.723
NEC for r=0.6 class 0.0 = 0.041 +- 0.112 (in-sample avg dev_std = 0.161)
NEC for r=0.6 class 1.0 = 0.15 +- 0.112 (in-sample avg dev_std = 0.161)
NEC for r=0.6 all KL = 0.056 +- 0.112 (in-sample avg dev_std = 0.161)
NEC for r=0.6 all L1 = 0.096 +- 0.149 (in-sample avg dev_std = 0.161)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.72
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.715
NEC for r=0.9 class 0.0 = 0.037 +- 0.231 (in-sample avg dev_std = 0.186)
NEC for r=0.9 class 1.0 = 0.181 +- 0.231 (in-sample avg dev_std = 0.186)
NEC for r=0.9 all KL = 0.107 +- 0.231 (in-sample avg dev_std = 0.186)
NEC for r=0.9 all L1 = 0.109 +- 0.198 (in-sample avg dev_std = 0.186)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.713
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.706
NEC for r=1.0 class 0.0 = 0.033 +- 0.242 (in-sample avg dev_std = 0.215)
NEC for r=1.0 class 1.0 = 0.184 +- 0.242 (in-sample avg dev_std = 0.215)
NEC for r=1.0 all KL = 0.117 +- 0.242 (in-sample avg dev_std = 0.215)
NEC for r=1.0 all L1 = 0.108 +- 0.196 (in-sample avg dev_std = 0.215)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.589
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.575
NEC for r=0.3 class 0.0 = 0.053 +- 0.041 (in-sample avg dev_std = 0.078)
NEC for r=0.3 class 1.0 = 0.069 +- 0.041 (in-sample avg dev_std = 0.078)
NEC for r=0.3 all KL = 0.021 +- 0.041 (in-sample avg dev_std = 0.078)
NEC for r=0.3 all L1 = 0.061 +- 0.072 (in-sample avg dev_std = 0.078)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.618
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.594
NEC for r=0.6 class 0.0 = 0.034 +- 0.093 (in-sample avg dev_std = 0.122)
NEC for r=0.6 class 1.0 = 0.099 +- 0.093 (in-sample avg dev_std = 0.122)
NEC for r=0.6 all KL = 0.037 +- 0.093 (in-sample avg dev_std = 0.122)
NEC for r=0.6 all L1 = 0.067 +- 0.116 (in-sample avg dev_std = 0.122)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.661
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.625
NEC for r=0.9 class 0.0 = 0.032 +- 0.190 (in-sample avg dev_std = 0.188)
NEC for r=0.9 class 1.0 = 0.104 +- 0.190 (in-sample avg dev_std = 0.188)
NEC for r=0.9 all KL = 0.07 +- 0.190 (in-sample avg dev_std = 0.188)
NEC for r=0.9 all L1 = 0.068 +- 0.155 (in-sample avg dev_std = 0.188)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.689
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.628
NEC for r=1.0 class 0.0 = 0.019 +- 0.208 (in-sample avg dev_std = 0.191)
NEC for r=1.0 class 1.0 = 0.104 +- 0.208 (in-sample avg dev_std = 0.191)
NEC for r=1.0 all KL = 0.071 +- 0.208 (in-sample avg dev_std = 0.191)
NEC for r=1.0 all L1 = 0.061 +- 0.158 (in-sample avg dev_std = 0.191)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 14:52:21 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:21 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:24 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:27 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:30 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:52:33 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 121...
[0m[1;37mINFO[0m: [1mCheckpoint 121: 
-----------------------------------
Train ROC-AUC: 0.9710
Train Loss: 0.0713
ID Validation ROC-AUC: 0.8526
ID Validation Loss: 0.1392
ID Test ROC-AUC: 0.7996
ID Test Loss: 0.1358
OOD Validation ROC-AUC: 0.7613
OOD Validation Loss: 0.1391
OOD Test ROC-AUC: 0.7520
OOD Test Loss: 0.0942

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 50...
[0m[1;37mINFO[0m: [1mCheckpoint 50: 
-----------------------------------
Train ROC-AUC: 0.9037
Train Loss: 0.0960
ID Validation ROC-AUC: 0.8175
ID Validation Loss: 0.1281
ID Test ROC-AUC: 0.8267
ID Test Loss: 0.1115
OOD Validation ROC-AUC: 0.7871
OOD Validation Loss: 0.1090
OOD Test ROC-AUC: 0.7157
OOD Test Loss: 0.0855

[0m[1;37mINFO[0m: [1mChartInfo 0.7996 0.7520 0.8267 0.7157 0.8175 0.7871[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 04/07/2024 02:52:34 PM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 04/07/2024 02:52:36 PM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 04/07/2024 02:52:38 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.682
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 339
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.572
SUFF++ for r=0.3 class 0.0 = 0.934 +- 0.038 (in-sample avg dev_std = 0.102)
SUFF++ for r=0.3 class 1.0 = 0.883 +- 0.038 (in-sample avg dev_std = 0.102)
SUFF++ for r=0.3 all KL = 0.973 +- 0.038 (in-sample avg dev_std = 0.102)
SUFF++ for r=0.3 all L1 = 0.908 +- 0.077 (in-sample avg dev_std = 0.102)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.786
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.708
SUFF++ for r=0.6 class 0.0 = 0.965 +- 0.086 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.6 class 1.0 = 0.832 +- 0.086 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.6 all KL = 0.956 +- 0.086 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.6 all L1 = 0.899 +- 0.141 (in-sample avg dev_std = 0.136)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.845
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.833
SUFF++ for r=0.9 class 0.0 = 0.992 +- 0.098 (in-sample avg dev_std = 0.141)
SUFF++ for r=0.9 class 1.0 = 0.911 +- 0.098 (in-sample avg dev_std = 0.141)
SUFF++ for r=0.9 all KL = 0.972 +- 0.098 (in-sample avg dev_std = 0.141)
SUFF++ for r=0.9 all L1 = 0.951 +- 0.112 (in-sample avg dev_std = 0.141)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.652
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 245
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.554
SUFF++ for r=0.3 class 0.0 = 0.927 +- 0.046 (in-sample avg dev_std = 0.115)
SUFF++ for r=0.3 class 1.0 = 0.877 +- 0.046 (in-sample avg dev_std = 0.115)
SUFF++ for r=0.3 all KL = 0.97 +- 0.046 (in-sample avg dev_std = 0.115)
SUFF++ for r=0.3 all L1 = 0.901 +- 0.081 (in-sample avg dev_std = 0.115)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.715
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.665
SUFF++ for r=0.6 class 0.0 = 0.964 +- 0.066 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.6 class 1.0 = 0.863 +- 0.066 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.6 all KL = 0.966 +- 0.066 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.6 all L1 = 0.913 +- 0.119 (in-sample avg dev_std = 0.129)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.733
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.727
SUFF++ for r=0.9 class 0.0 = 0.993 +- 0.059 (in-sample avg dev_std = 0.096)
SUFF++ for r=0.9 class 1.0 = 0.941 +- 0.059 (in-sample avg dev_std = 0.096)
SUFF++ for r=0.9 all KL = 0.984 +- 0.059 (in-sample avg dev_std = 0.096)
SUFF++ for r=0.9 all L1 = 0.967 +- 0.073 (in-sample avg dev_std = 0.096)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.614
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 149
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.554
SUFF++ for r=0.3 class 0.0 = 0.929 +- 0.025 (in-sample avg dev_std = 0.078)
SUFF++ for r=0.3 class 1.0 = 0.908 +- 0.025 (in-sample avg dev_std = 0.078)
SUFF++ for r=0.3 all KL = 0.979 +- 0.025 (in-sample avg dev_std = 0.078)
SUFF++ for r=0.3 all L1 = 0.919 +- 0.052 (in-sample avg dev_std = 0.078)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.705
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.653
SUFF++ for r=0.6 class 0.0 = 0.968 +- 0.050 (in-sample avg dev_std = 0.090)
SUFF++ for r=0.6 class 1.0 = 0.903 +- 0.050 (in-sample avg dev_std = 0.090)
SUFF++ for r=0.6 all KL = 0.977 +- 0.050 (in-sample avg dev_std = 0.090)
SUFF++ for r=0.6 all L1 = 0.936 +- 0.092 (in-sample avg dev_std = 0.090)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.766
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.748
SUFF++ for r=0.9 class 0.0 = 0.997 +- 0.035 (in-sample avg dev_std = 0.056)
SUFF++ for r=0.9 class 1.0 = 0.974 +- 0.035 (in-sample avg dev_std = 0.056)
SUFF++ for r=0.9 all KL = 0.994 +- 0.035 (in-sample avg dev_std = 0.056)
SUFF++ for r=0.9 all L1 = 0.985 +- 0.039 (in-sample avg dev_std = 0.056)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.67
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.645
NEC for r=0.3 class 0.0 = 0.06 +- 0.018 (in-sample avg dev_std = 0.056)
NEC for r=0.3 class 1.0 = 0.083 +- 0.018 (in-sample avg dev_std = 0.056)
NEC for r=0.3 all KL = 0.013 +- 0.018 (in-sample avg dev_std = 0.056)
NEC for r=0.3 all L1 = 0.072 +- 0.057 (in-sample avg dev_std = 0.056)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.786
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.746
NEC for r=0.6 class 0.0 = 0.031 +- 0.091 (in-sample avg dev_std = 0.135)
NEC for r=0.6 class 1.0 = 0.15 +- 0.091 (in-sample avg dev_std = 0.135)
NEC for r=0.6 all KL = 0.039 +- 0.091 (in-sample avg dev_std = 0.135)
NEC for r=0.6 all L1 = 0.091 +- 0.135 (in-sample avg dev_std = 0.135)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.845
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.793
NEC for r=0.9 class 0.0 = 0.019 +- 0.215 (in-sample avg dev_std = 0.227)
NEC for r=0.9 class 1.0 = 0.233 +- 0.215 (in-sample avg dev_std = 0.227)
NEC for r=0.9 all KL = 0.107 +- 0.215 (in-sample avg dev_std = 0.227)
NEC for r=0.9 all L1 = 0.126 +- 0.204 (in-sample avg dev_std = 0.227)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.863
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.806
NEC for r=1.0 class 0.0 = 0.016 +- 0.251 (in-sample avg dev_std = 0.262)
NEC for r=1.0 class 1.0 = 0.249 +- 0.251 (in-sample avg dev_std = 0.262)
NEC for r=1.0 all KL = 0.132 +- 0.251 (in-sample avg dev_std = 0.262)
NEC for r=1.0 all L1 = 0.132 +- 0.217 (in-sample avg dev_std = 0.262)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.645
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.652
NEC for r=0.3 class 0.0 = 0.053 +- 0.017 (in-sample avg dev_std = 0.056)
NEC for r=0.3 class 1.0 = 0.077 +- 0.017 (in-sample avg dev_std = 0.056)
NEC for r=0.3 all KL = 0.011 +- 0.017 (in-sample avg dev_std = 0.056)
NEC for r=0.3 all L1 = 0.065 +- 0.048 (in-sample avg dev_std = 0.056)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.715
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.704
NEC for r=0.6 class 0.0 = 0.029 +- 0.057 (in-sample avg dev_std = 0.099)
NEC for r=0.6 class 1.0 = 0.115 +- 0.057 (in-sample avg dev_std = 0.099)
NEC for r=0.6 all KL = 0.024 +- 0.057 (in-sample avg dev_std = 0.099)
NEC for r=0.6 all L1 = 0.072 +- 0.105 (in-sample avg dev_std = 0.099)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.733
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.706
NEC for r=0.9 class 0.0 = 0.022 +- 0.141 (in-sample avg dev_std = 0.159)
NEC for r=0.9 class 1.0 = 0.152 +- 0.141 (in-sample avg dev_std = 0.159)
NEC for r=0.9 all KL = 0.063 +- 0.141 (in-sample avg dev_std = 0.159)
NEC for r=0.9 all L1 = 0.087 +- 0.151 (in-sample avg dev_std = 0.159)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.745
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.732
NEC for r=1.0 class 0.0 = 0.022 +- 0.178 (in-sample avg dev_std = 0.181)
NEC for r=1.0 class 1.0 = 0.163 +- 0.178 (in-sample avg dev_std = 0.181)
NEC for r=1.0 all KL = 0.084 +- 0.178 (in-sample avg dev_std = 0.181)
NEC for r=1.0 all L1 = 0.092 +- 0.161 (in-sample avg dev_std = 0.181)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.613
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.621
NEC for r=0.3 class 0.0 = 0.058 +- 0.015 (in-sample avg dev_std = 0.059)
NEC for r=0.3 class 1.0 = 0.065 +- 0.015 (in-sample avg dev_std = 0.059)
NEC for r=0.3 all KL = 0.011 +- 0.015 (in-sample avg dev_std = 0.059)
NEC for r=0.3 all L1 = 0.061 +- 0.043 (in-sample avg dev_std = 0.059)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.705
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.659
NEC for r=0.6 class 0.0 = 0.026 +- 0.069 (in-sample avg dev_std = 0.118)
NEC for r=0.6 class 1.0 = 0.087 +- 0.069 (in-sample avg dev_std = 0.118)
NEC for r=0.6 all KL = 0.023 +- 0.069 (in-sample avg dev_std = 0.118)
NEC for r=0.6 all L1 = 0.056 +- 0.092 (in-sample avg dev_std = 0.118)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.766
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.713
NEC for r=0.9 class 0.0 = 0.012 +- 0.145 (in-sample avg dev_std = 0.148)
NEC for r=0.9 class 1.0 = 0.085 +- 0.145 (in-sample avg dev_std = 0.148)
NEC for r=0.9 all KL = 0.043 +- 0.145 (in-sample avg dev_std = 0.148)
NEC for r=0.9 all L1 = 0.049 +- 0.119 (in-sample avg dev_std = 0.148)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.768
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.724
NEC for r=1.0 class 0.0 = 0.009 +- 0.170 (in-sample avg dev_std = 0.174)
NEC for r=1.0 class 1.0 = 0.092 +- 0.170 (in-sample avg dev_std = 0.174)
NEC for r=1.0 all KL = 0.051 +- 0.170 (in-sample avg dev_std = 0.174)
NEC for r=1.0 all L1 = 0.05 +- 0.125 (in-sample avg dev_std = 0.174)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 14:53:49 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 04/07/2024 02:53:50 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/07/2024 02:53:53 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/07/2024 02:53:56 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/07/2024 02:53:59 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:54:02 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 126...
[0m[1;37mINFO[0m: [1mCheckpoint 126: 
-----------------------------------
Train ROC-AUC: 0.9701
Train Loss: 0.0706
ID Validation ROC-AUC: 0.8330
ID Validation Loss: 0.1409
ID Test ROC-AUC: 0.8429
ID Test Loss: 0.1165
OOD Validation ROC-AUC: 0.7600
OOD Validation Loss: 0.1232
OOD Test ROC-AUC: 0.7059
OOD Test Loss: 0.0934

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 101...
[0m[1;37mINFO[0m: [1mCheckpoint 101: 
-----------------------------------
Train ROC-AUC: 0.9417
Train Loss: 0.0879
ID Validation ROC-AUC: 0.8157
ID Validation Loss: 0.1418
ID Test ROC-AUC: 0.7987
ID Test Loss: 0.1294
OOD Validation ROC-AUC: 0.7798
OOD Validation Loss: 0.1255
OOD Test ROC-AUC: 0.7014
OOD Test Loss: 0.0943

[0m[1;37mINFO[0m: [1mChartInfo 0.8429 0.7059 0.7987 0.7014 0.8157 0.7798[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 04/07/2024 02:54:03 PM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 04/07/2024 02:54:05 PM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 04/07/2024 02:54:06 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.677
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 339
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.585
SUFF++ for r=0.3 class 0.0 = 0.944 +- 0.020 (in-sample avg dev_std = 0.072)
SUFF++ for r=0.3 class 1.0 = 0.911 +- 0.020 (in-sample avg dev_std = 0.072)
SUFF++ for r=0.3 all KL = 0.983 +- 0.020 (in-sample avg dev_std = 0.072)
SUFF++ for r=0.3 all L1 = 0.927 +- 0.055 (in-sample avg dev_std = 0.072)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.813
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.746
SUFF++ for r=0.6 class 0.0 = 0.971 +- 0.067 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.6 class 1.0 = 0.866 +- 0.067 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.6 all KL = 0.97 +- 0.067 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.6 all L1 = 0.919 +- 0.118 (in-sample avg dev_std = 0.119)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.859
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.844
SUFF++ for r=0.9 class 0.0 = 0.995 +- 0.089 (in-sample avg dev_std = 0.153)
SUFF++ for r=0.9 class 1.0 = 0.909 +- 0.089 (in-sample avg dev_std = 0.153)
SUFF++ for r=0.9 all KL = 0.974 +- 0.089 (in-sample avg dev_std = 0.153)
SUFF++ for r=0.9 all L1 = 0.952 +- 0.114 (in-sample avg dev_std = 0.153)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.72
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 239
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.607
SUFF++ for r=0.3 class 0.0 = 0.945 +- 0.020 (in-sample avg dev_std = 0.069)
SUFF++ for r=0.3 class 1.0 = 0.912 +- 0.020 (in-sample avg dev_std = 0.069)
SUFF++ for r=0.3 all KL = 0.984 +- 0.020 (in-sample avg dev_std = 0.069)
SUFF++ for r=0.3 all L1 = 0.928 +- 0.053 (in-sample avg dev_std = 0.069)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.744
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.71
SUFF++ for r=0.6 class 0.0 = 0.971 +- 0.068 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.6 class 1.0 = 0.871 +- 0.068 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.6 all KL = 0.971 +- 0.068 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.6 all L1 = 0.921 +- 0.122 (in-sample avg dev_std = 0.119)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.756
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.739
SUFF++ for r=0.9 class 0.0 = 0.994 +- 0.052 (in-sample avg dev_std = 0.100)
SUFF++ for r=0.9 class 1.0 = 0.938 +- 0.052 (in-sample avg dev_std = 0.100)
SUFF++ for r=0.9 all KL = 0.987 +- 0.052 (in-sample avg dev_std = 0.100)
SUFF++ for r=0.9 all L1 = 0.966 +- 0.079 (in-sample avg dev_std = 0.100)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.613
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 148
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.532
SUFF++ for r=0.3 class 0.0 = 0.943 +- 0.018 (in-sample avg dev_std = 0.056)
SUFF++ for r=0.3 class 1.0 = 0.927 +- 0.018 (in-sample avg dev_std = 0.056)
SUFF++ for r=0.3 all KL = 0.985 +- 0.018 (in-sample avg dev_std = 0.056)
SUFF++ for r=0.3 all L1 = 0.936 +- 0.046 (in-sample avg dev_std = 0.056)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.719
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.618
SUFF++ for r=0.6 class 0.0 = 0.972 +- 0.069 (in-sample avg dev_std = 0.099)
SUFF++ for r=0.6 class 1.0 = 0.905 +- 0.069 (in-sample avg dev_std = 0.099)
SUFF++ for r=0.6 all KL = 0.976 +- 0.069 (in-sample avg dev_std = 0.099)
SUFF++ for r=0.6 all L1 = 0.939 +- 0.106 (in-sample avg dev_std = 0.099)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.726
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 161
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.717
SUFF++ for r=0.9 class 0.0 = 0.994 +- 0.080 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.9 class 1.0 = 0.939 +- 0.080 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.9 all KL = 0.981 +- 0.080 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.9 all L1 = 0.966 +- 0.091 (in-sample avg dev_std = 0.135)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.666
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.648
NEC for r=0.3 class 0.0 = 0.051 +- 0.017 (in-sample avg dev_std = 0.050)
NEC for r=0.3 class 1.0 = 0.073 +- 0.017 (in-sample avg dev_std = 0.050)
NEC for r=0.3 all KL = 0.011 +- 0.017 (in-sample avg dev_std = 0.050)
NEC for r=0.3 all L1 = 0.062 +- 0.054 (in-sample avg dev_std = 0.050)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.813
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.751
NEC for r=0.6 class 0.0 = 0.021 +- 0.085 (in-sample avg dev_std = 0.118)
NEC for r=0.6 class 1.0 = 0.138 +- 0.085 (in-sample avg dev_std = 0.118)
NEC for r=0.6 all KL = 0.034 +- 0.085 (in-sample avg dev_std = 0.118)
NEC for r=0.6 all L1 = 0.08 +- 0.135 (in-sample avg dev_std = 0.118)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.859
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.791
NEC for r=0.9 class 0.0 = 0.016 +- 0.195 (in-sample avg dev_std = 0.221)
NEC for r=0.9 class 1.0 = 0.211 +- 0.195 (in-sample avg dev_std = 0.221)
NEC for r=0.9 all KL = 0.09 +- 0.195 (in-sample avg dev_std = 0.221)
NEC for r=0.9 all L1 = 0.113 +- 0.199 (in-sample avg dev_std = 0.221)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.861
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.797
NEC for r=1.0 class 0.0 = 0.018 +- 0.222 (in-sample avg dev_std = 0.247)
NEC for r=1.0 class 1.0 = 0.233 +- 0.222 (in-sample avg dev_std = 0.247)
NEC for r=1.0 all KL = 0.112 +- 0.222 (in-sample avg dev_std = 0.247)
NEC for r=1.0 all L1 = 0.125 +- 0.211 (in-sample avg dev_std = 0.247)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.704
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.684
NEC for r=0.3 class 0.0 = 0.043 +- 0.010 (in-sample avg dev_std = 0.041)
NEC for r=0.3 class 1.0 = 0.064 +- 0.010 (in-sample avg dev_std = 0.041)
NEC for r=0.3 all KL = 0.008 +- 0.010 (in-sample avg dev_std = 0.041)
NEC for r=0.3 all L1 = 0.054 +- 0.040 (in-sample avg dev_std = 0.041)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.744
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.749
NEC for r=0.6 class 0.0 = 0.023 +- 0.069 (in-sample avg dev_std = 0.102)
NEC for r=0.6 class 1.0 = 0.121 +- 0.069 (in-sample avg dev_std = 0.102)
NEC for r=0.6 all KL = 0.026 +- 0.069 (in-sample avg dev_std = 0.102)
NEC for r=0.6 all L1 = 0.072 +- 0.117 (in-sample avg dev_std = 0.102)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.756
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.738
NEC for r=0.9 class 0.0 = 0.019 +- 0.159 (in-sample avg dev_std = 0.185)
NEC for r=0.9 class 1.0 = 0.173 +- 0.159 (in-sample avg dev_std = 0.185)
NEC for r=0.9 all KL = 0.067 +- 0.159 (in-sample avg dev_std = 0.185)
NEC for r=0.9 all L1 = 0.096 +- 0.173 (in-sample avg dev_std = 0.185)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.766
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.741
NEC for r=1.0 class 0.0 = 0.02 +- 0.171 (in-sample avg dev_std = 0.195)
NEC for r=1.0 class 1.0 = 0.19 +- 0.171 (in-sample avg dev_std = 0.195)
NEC for r=1.0 all KL = 0.082 +- 0.171 (in-sample avg dev_std = 0.195)
NEC for r=1.0 all L1 = 0.105 +- 0.185 (in-sample avg dev_std = 0.195)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.613
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.589
NEC for r=0.3 class 0.0 = 0.044 +- 0.019 (in-sample avg dev_std = 0.048)
NEC for r=0.3 class 1.0 = 0.061 +- 0.019 (in-sample avg dev_std = 0.048)
NEC for r=0.3 all KL = 0.009 +- 0.019 (in-sample avg dev_std = 0.048)
NEC for r=0.3 all L1 = 0.053 +- 0.048 (in-sample avg dev_std = 0.048)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.719
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.678
NEC for r=0.6 class 0.0 = 0.021 +- 0.056 (in-sample avg dev_std = 0.085)
NEC for r=0.6 class 1.0 = 0.085 +- 0.056 (in-sample avg dev_std = 0.085)
NEC for r=0.6 all KL = 0.019 +- 0.056 (in-sample avg dev_std = 0.085)
NEC for r=0.6 all L1 = 0.053 +- 0.102 (in-sample avg dev_std = 0.085)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.728
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.683
NEC for r=0.9 class 0.0 = 0.013 +- 0.162 (in-sample avg dev_std = 0.169)
NEC for r=0.9 class 1.0 = 0.121 +- 0.162 (in-sample avg dev_std = 0.169)
NEC for r=0.9 all KL = 0.051 +- 0.162 (in-sample avg dev_std = 0.169)
NEC for r=0.9 all L1 = 0.067 +- 0.150 (in-sample avg dev_std = 0.169)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.717
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.684
NEC for r=1.0 class 0.0 = 0.014 +- 0.200 (in-sample avg dev_std = 0.190)
NEC for r=1.0 class 1.0 = 0.131 +- 0.200 (in-sample avg dev_std = 0.190)
NEC for r=1.0 all KL = 0.066 +- 0.200 (in-sample avg dev_std = 0.190)
NEC for r=1.0 all L1 = 0.073 +- 0.170 (in-sample avg dev_std = 0.190)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 14:55:19 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:19 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:22 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:26 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:28 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:55:31 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 143...
[0m[1;37mINFO[0m: [1mCheckpoint 143: 
-----------------------------------
Train ROC-AUC: 0.9793
Train Loss: 0.0613
ID Validation ROC-AUC: 0.8456
ID Validation Loss: 0.1501
ID Test ROC-AUC: 0.8055
ID Test Loss: 0.1348
OOD Validation ROC-AUC: 0.7453
OOD Validation Loss: 0.1579
OOD Test ROC-AUC: 0.7238
OOD Test Loss: 0.1098

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 123...
[0m[1;37mINFO[0m: [1mCheckpoint 123: 
-----------------------------------
Train ROC-AUC: 0.9652
Train Loss: 0.0835
ID Validation ROC-AUC: 0.8234
ID Validation Loss: 0.1556
ID Test ROC-AUC: 0.8100
ID Test Loss: 0.1307
OOD Validation ROC-AUC: 0.7813
OOD Validation Loss: 0.1347
OOD Test ROC-AUC: 0.7610
OOD Test Loss: 0.0941

[0m[1;37mINFO[0m: [1mChartInfo 0.8055 0.7238 0.8100 0.7610 0.8234 0.7813[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 04/07/2024 02:55:33 PM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 04/07/2024 02:55:35 PM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 04/07/2024 02:55:37 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.704
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 339
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.589
SUFF++ for r=0.3 class 0.0 = 0.911 +- 0.046 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.3 class 1.0 = 0.853 +- 0.046 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.3 all KL = 0.96 +- 0.046 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.3 all L1 = 0.881 +- 0.084 (in-sample avg dev_std = 0.137)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.815
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.764
SUFF++ for r=0.6 class 0.0 = 0.956 +- 0.075 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.6 class 1.0 = 0.83 +- 0.075 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.6 all KL = 0.956 +- 0.075 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.6 all L1 = 0.893 +- 0.129 (in-sample avg dev_std = 0.145)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.859
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.85
SUFF++ for r=0.9 class 0.0 = 0.992 +- 0.077 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.9 class 1.0 = 0.923 +- 0.077 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.9 all KL = 0.98 +- 0.077 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.9 all L1 = 0.957 +- 0.091 (in-sample avg dev_std = 0.128)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.636
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 244
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.56
SUFF++ for r=0.3 class 0.0 = 0.915 +- 0.034 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.3 class 1.0 = 0.878 +- 0.034 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.3 all KL = 0.969 +- 0.034 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.3 all L1 = 0.896 +- 0.073 (in-sample avg dev_std = 0.113)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.695
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.642
SUFF++ for r=0.6 class 0.0 = 0.95 +- 0.073 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.6 class 1.0 = 0.857 +- 0.073 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.6 all KL = 0.958 +- 0.073 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.6 all L1 = 0.903 +- 0.124 (in-sample avg dev_std = 0.147)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.748
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.743
SUFF++ for r=0.9 class 0.0 = 0.993 +- 0.029 (in-sample avg dev_std = 0.070)
SUFF++ for r=0.9 class 1.0 = 0.95 +- 0.029 (in-sample avg dev_std = 0.070)
SUFF++ for r=0.9 all KL = 0.991 +- 0.029 (in-sample avg dev_std = 0.070)
SUFF++ for r=0.9 all L1 = 0.971 +- 0.058 (in-sample avg dev_std = 0.070)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.548
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 153
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.518
SUFF++ for r=0.3 class 0.0 = 0.902 +- 0.041 (in-sample avg dev_std = 0.117)
SUFF++ for r=0.3 class 1.0 = 0.879 +- 0.041 (in-sample avg dev_std = 0.117)
SUFF++ for r=0.3 all KL = 0.962 +- 0.041 (in-sample avg dev_std = 0.117)
SUFF++ for r=0.3 all L1 = 0.89 +- 0.072 (in-sample avg dev_std = 0.117)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.659
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.609
SUFF++ for r=0.6 class 0.0 = 0.96 +- 0.102 (in-sample avg dev_std = 0.140)
SUFF++ for r=0.6 class 1.0 = 0.879 +- 0.102 (in-sample avg dev_std = 0.140)
SUFF++ for r=0.6 all KL = 0.96 +- 0.102 (in-sample avg dev_std = 0.140)
SUFF++ for r=0.6 all L1 = 0.92 +- 0.124 (in-sample avg dev_std = 0.140)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.732
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.733
SUFF++ for r=0.9 class 0.0 = 0.994 +- 0.057 (in-sample avg dev_std = 0.093)
SUFF++ for r=0.9 class 1.0 = 0.961 +- 0.057 (in-sample avg dev_std = 0.093)
SUFF++ for r=0.9 all KL = 0.988 +- 0.057 (in-sample avg dev_std = 0.093)
SUFF++ for r=0.9 all L1 = 0.977 +- 0.059 (in-sample avg dev_std = 0.093)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.684
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.682
NEC for r=0.3 class 0.0 = 0.071 +- 0.024 (in-sample avg dev_std = 0.068)
NEC for r=0.3 class 1.0 = 0.094 +- 0.024 (in-sample avg dev_std = 0.068)
NEC for r=0.3 all KL = 0.017 +- 0.024 (in-sample avg dev_std = 0.068)
NEC for r=0.3 all L1 = 0.083 +- 0.065 (in-sample avg dev_std = 0.068)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.815
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.77
NEC for r=0.6 class 0.0 = 0.036 +- 0.084 (in-sample avg dev_std = 0.143)
NEC for r=0.6 class 1.0 = 0.149 +- 0.084 (in-sample avg dev_std = 0.143)
NEC for r=0.6 all KL = 0.037 +- 0.084 (in-sample avg dev_std = 0.143)
NEC for r=0.6 all L1 = 0.092 +- 0.129 (in-sample avg dev_std = 0.143)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.859
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.811
NEC for r=0.9 class 0.0 = 0.028 +- 0.179 (in-sample avg dev_std = 0.231)
NEC for r=0.9 class 1.0 = 0.216 +- 0.179 (in-sample avg dev_std = 0.231)
NEC for r=0.9 all KL = 0.09 +- 0.179 (in-sample avg dev_std = 0.231)
NEC for r=0.9 all L1 = 0.122 +- 0.187 (in-sample avg dev_std = 0.231)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.866
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.814
NEC for r=1.0 class 0.0 = 0.023 +- 0.215 (in-sample avg dev_std = 0.265)
NEC for r=1.0 class 1.0 = 0.227 +- 0.215 (in-sample avg dev_std = 0.265)
NEC for r=1.0 all KL = 0.11 +- 0.215 (in-sample avg dev_std = 0.265)
NEC for r=1.0 all L1 = 0.125 +- 0.201 (in-sample avg dev_std = 0.265)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.624
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.658
NEC for r=0.3 class 0.0 = 0.069 +- 0.022 (in-sample avg dev_std = 0.068)
NEC for r=0.3 class 1.0 = 0.085 +- 0.022 (in-sample avg dev_std = 0.068)
NEC for r=0.3 all KL = 0.016 +- 0.022 (in-sample avg dev_std = 0.068)
NEC for r=0.3 all L1 = 0.077 +- 0.054 (in-sample avg dev_std = 0.068)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.695
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.692
NEC for r=0.6 class 0.0 = 0.036 +- 0.044 (in-sample avg dev_std = 0.105)
NEC for r=0.6 class 1.0 = 0.111 +- 0.044 (in-sample avg dev_std = 0.105)
NEC for r=0.6 all KL = 0.025 +- 0.044 (in-sample avg dev_std = 0.105)
NEC for r=0.6 all L1 = 0.073 +- 0.093 (in-sample avg dev_std = 0.105)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.748
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.744
NEC for r=0.9 class 0.0 = 0.027 +- 0.075 (in-sample avg dev_std = 0.142)
NEC for r=0.9 class 1.0 = 0.107 +- 0.075 (in-sample avg dev_std = 0.142)
NEC for r=0.9 all KL = 0.036 +- 0.075 (in-sample avg dev_std = 0.142)
NEC for r=0.9 all L1 = 0.067 +- 0.105 (in-sample avg dev_std = 0.142)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.738
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.742
NEC for r=1.0 class 0.0 = 0.027 +- 0.094 (in-sample avg dev_std = 0.158)
NEC for r=1.0 class 1.0 = 0.123 +- 0.094 (in-sample avg dev_std = 0.158)
NEC for r=1.0 all KL = 0.046 +- 0.094 (in-sample avg dev_std = 0.158)
NEC for r=1.0 all L1 = 0.075 +- 0.121 (in-sample avg dev_std = 0.158)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.535
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.566
NEC for r=0.3 class 0.0 = 0.068 +- 0.028 (in-sample avg dev_std = 0.084)
NEC for r=0.3 class 1.0 = 0.084 +- 0.028 (in-sample avg dev_std = 0.084)
NEC for r=0.3 all KL = 0.018 +- 0.028 (in-sample avg dev_std = 0.084)
NEC for r=0.3 all L1 = 0.076 +- 0.063 (in-sample avg dev_std = 0.084)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.659
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.648
NEC for r=0.6 class 0.0 = 0.039 +- 0.080 (in-sample avg dev_std = 0.116)
NEC for r=0.6 class 1.0 = 0.098 +- 0.080 (in-sample avg dev_std = 0.116)
NEC for r=0.6 all KL = 0.031 +- 0.080 (in-sample avg dev_std = 0.116)
NEC for r=0.6 all L1 = 0.069 +- 0.104 (in-sample avg dev_std = 0.116)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.732
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.721
NEC for r=0.9 class 0.0 = 0.015 +- 0.100 (in-sample avg dev_std = 0.146)
NEC for r=0.9 class 1.0 = 0.092 +- 0.100 (in-sample avg dev_std = 0.146)
NEC for r=0.9 all KL = 0.038 +- 0.100 (in-sample avg dev_std = 0.146)
NEC for r=0.9 all L1 = 0.053 +- 0.108 (in-sample avg dev_std = 0.146)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.743
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.727
NEC for r=1.0 class 0.0 = 0.011 +- 0.122 (in-sample avg dev_std = 0.145)
NEC for r=1.0 class 1.0 = 0.089 +- 0.122 (in-sample avg dev_std = 0.145)
NEC for r=1.0 all KL = 0.038 +- 0.122 (in-sample avg dev_std = 0.145)
NEC for r=1.0 all L1 = 0.05 +- 0.107 (in-sample avg dev_std = 0.145)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 14:56:50 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 04/07/2024 02:56:50 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/07/2024 02:56:53 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/07/2024 02:56:56 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/07/2024 02:56:59 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 02:57:02 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 140...
[0m[1;37mINFO[0m: [1mCheckpoint 140: 
-----------------------------------
Train ROC-AUC: 0.9746
Train Loss: 0.0672
ID Validation ROC-AUC: 0.8419
ID Validation Loss: 0.1412
ID Test ROC-AUC: 0.8028
ID Test Loss: 0.1301
OOD Validation ROC-AUC: 0.7447
OOD Validation Loss: 0.1352
OOD Test ROC-AUC: 0.7243
OOD Test Loss: 0.0925

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 191...
[0m[1;37mINFO[0m: [1mCheckpoint 191: 
-----------------------------------
Train ROC-AUC: 0.9905
Train Loss: 0.0444
ID Validation ROC-AUC: 0.8359
ID Validation Loss: 0.1532
ID Test ROC-AUC: 0.7955
ID Test Loss: 0.1437
OOD Validation ROC-AUC: 0.7701
OOD Validation Loss: 0.1443
OOD Test ROC-AUC: 0.7345
OOD Test Loss: 0.1002

[0m[1;37mINFO[0m: [1mChartInfo 0.8028 0.7243 0.7955 0.7345 0.8359 0.7701[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 04/07/2024 02:57:03 PM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 04/07/2024 02:57:06 PM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 04/07/2024 02:57:07 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.715
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 339
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.606
SUFF++ for r=0.3 class 0.0 = 0.912 +- 0.039 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.3 class 1.0 = 0.863 +- 0.039 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.3 all KL = 0.968 +- 0.039 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.3 all L1 = 0.887 +- 0.079 (in-sample avg dev_std = 0.118)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.818
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.751
SUFF++ for r=0.6 class 0.0 = 0.955 +- 0.050 (in-sample avg dev_std = 0.123)
SUFF++ for r=0.6 class 1.0 = 0.851 +- 0.050 (in-sample avg dev_std = 0.123)
SUFF++ for r=0.6 all KL = 0.968 +- 0.050 (in-sample avg dev_std = 0.123)
SUFF++ for r=0.6 all L1 = 0.903 +- 0.108 (in-sample avg dev_std = 0.123)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.858
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.847
SUFF++ for r=0.9 class 0.0 = 0.994 +- 0.075 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.9 class 1.0 = 0.921 +- 0.075 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.9 all KL = 0.979 +- 0.075 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.9 all L1 = 0.957 +- 0.098 (in-sample avg dev_std = 0.136)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.654
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 243
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.551
SUFF++ for r=0.3 class 0.0 = 0.918 +- 0.033 (in-sample avg dev_std = 0.110)
SUFF++ for r=0.3 class 1.0 = 0.874 +- 0.033 (in-sample avg dev_std = 0.110)
SUFF++ for r=0.3 all KL = 0.972 +- 0.033 (in-sample avg dev_std = 0.110)
SUFF++ for r=0.3 all L1 = 0.896 +- 0.071 (in-sample avg dev_std = 0.110)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.735
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.69
SUFF++ for r=0.6 class 0.0 = 0.963 +- 0.034 (in-sample avg dev_std = 0.100)
SUFF++ for r=0.6 class 1.0 = 0.889 +- 0.034 (in-sample avg dev_std = 0.100)
SUFF++ for r=0.6 all KL = 0.979 +- 0.034 (in-sample avg dev_std = 0.100)
SUFF++ for r=0.6 all L1 = 0.926 +- 0.085 (in-sample avg dev_std = 0.100)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.747
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.737
SUFF++ for r=0.9 class 0.0 = 0.993 +- 0.049 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.9 class 1.0 = 0.94 +- 0.049 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.9 all KL = 0.988 +- 0.049 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.9 all L1 = 0.967 +- 0.082 (in-sample avg dev_std = 0.089)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.61
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 144
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.578
SUFF++ for r=0.3 class 0.0 = 0.914 +- 0.031 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.3 class 1.0 = 0.885 +- 0.031 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.3 all KL = 0.972 +- 0.031 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.3 all L1 = 0.899 +- 0.066 (in-sample avg dev_std = 0.112)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.708
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.678
SUFF++ for r=0.6 class 0.0 = 0.957 +- 0.079 (in-sample avg dev_std = 0.109)
SUFF++ for r=0.6 class 1.0 = 0.883 +- 0.079 (in-sample avg dev_std = 0.109)
SUFF++ for r=0.6 all KL = 0.97 +- 0.079 (in-sample avg dev_std = 0.109)
SUFF++ for r=0.6 all L1 = 0.92 +- 0.108 (in-sample avg dev_std = 0.109)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.747
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.746
SUFF++ for r=0.9 class 0.0 = 0.995 +- 0.021 (in-sample avg dev_std = 0.069)
SUFF++ for r=0.9 class 1.0 = 0.955 +- 0.021 (in-sample avg dev_std = 0.069)
SUFF++ for r=0.9 all KL = 0.992 +- 0.021 (in-sample avg dev_std = 0.069)
SUFF++ for r=0.9 all L1 = 0.975 +- 0.054 (in-sample avg dev_std = 0.069)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.712
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.688
NEC for r=0.3 class 0.0 = 0.067 +- 0.019 (in-sample avg dev_std = 0.065)
NEC for r=0.3 class 1.0 = 0.087 +- 0.019 (in-sample avg dev_std = 0.065)
NEC for r=0.3 all KL = 0.013 +- 0.019 (in-sample avg dev_std = 0.065)
NEC for r=0.3 all L1 = 0.077 +- 0.054 (in-sample avg dev_std = 0.065)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.818
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.763
NEC for r=0.6 class 0.0 = 0.042 +- 0.072 (in-sample avg dev_std = 0.128)
NEC for r=0.6 class 1.0 = 0.145 +- 0.072 (in-sample avg dev_std = 0.128)
NEC for r=0.6 all KL = 0.035 +- 0.072 (in-sample avg dev_std = 0.128)
NEC for r=0.6 all L1 = 0.093 +- 0.121 (in-sample avg dev_std = 0.128)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.858
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.796
NEC for r=0.9 class 0.0 = 0.026 +- 0.181 (in-sample avg dev_std = 0.228)
NEC for r=0.9 class 1.0 = 0.224 +- 0.181 (in-sample avg dev_std = 0.228)
NEC for r=0.9 all KL = 0.093 +- 0.181 (in-sample avg dev_std = 0.228)
NEC for r=0.9 all L1 = 0.125 +- 0.194 (in-sample avg dev_std = 0.228)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.861
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.793
NEC for r=1.0 class 0.0 = 0.02 +- 0.215 (in-sample avg dev_std = 0.256)
NEC for r=1.0 class 1.0 = 0.239 +- 0.215 (in-sample avg dev_std = 0.256)
NEC for r=1.0 all KL = 0.112 +- 0.215 (in-sample avg dev_std = 0.256)
NEC for r=1.0 all L1 = 0.13 +- 0.210 (in-sample avg dev_std = 0.256)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.65
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.661
NEC for r=0.3 class 0.0 = 0.063 +- 0.013 (in-sample avg dev_std = 0.057)
NEC for r=0.3 class 1.0 = 0.077 +- 0.013 (in-sample avg dev_std = 0.057)
NEC for r=0.3 all KL = 0.011 +- 0.013 (in-sample avg dev_std = 0.057)
NEC for r=0.3 all L1 = 0.07 +- 0.046 (in-sample avg dev_std = 0.057)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.735
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.726
NEC for r=0.6 class 0.0 = 0.034 +- 0.034 (in-sample avg dev_std = 0.075)
NEC for r=0.6 class 1.0 = 0.085 +- 0.034 (in-sample avg dev_std = 0.075)
NEC for r=0.6 all KL = 0.015 +- 0.034 (in-sample avg dev_std = 0.075)
NEC for r=0.6 all L1 = 0.059 +- 0.076 (in-sample avg dev_std = 0.075)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.747
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.737
NEC for r=0.9 class 0.0 = 0.022 +- 0.113 (in-sample avg dev_std = 0.155)
NEC for r=0.9 class 1.0 = 0.152 +- 0.113 (in-sample avg dev_std = 0.155)
NEC for r=0.9 all KL = 0.05 +- 0.113 (in-sample avg dev_std = 0.155)
NEC for r=0.9 all L1 = 0.087 +- 0.154 (in-sample avg dev_std = 0.155)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.741
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.728
NEC for r=1.0 class 0.0 = 0.017 +- 0.128 (in-sample avg dev_std = 0.171)
NEC for r=1.0 class 1.0 = 0.164 +- 0.128 (in-sample avg dev_std = 0.171)
NEC for r=1.0 all KL = 0.06 +- 0.128 (in-sample avg dev_std = 0.171)
NEC for r=1.0 all L1 = 0.091 +- 0.163 (in-sample avg dev_std = 0.171)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.6
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.604
NEC for r=0.3 class 0.0 = 0.06 +- 0.043 (in-sample avg dev_std = 0.086)
NEC for r=0.3 class 1.0 = 0.098 +- 0.043 (in-sample avg dev_std = 0.086)
NEC for r=0.3 all KL = 0.017 +- 0.043 (in-sample avg dev_std = 0.086)
NEC for r=0.3 all L1 = 0.079 +- 0.073 (in-sample avg dev_std = 0.086)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.708
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.664
NEC for r=0.6 class 0.0 = 0.035 +- 0.076 (in-sample avg dev_std = 0.111)
NEC for r=0.6 class 1.0 = 0.102 +- 0.076 (in-sample avg dev_std = 0.111)
NEC for r=0.6 all KL = 0.025 +- 0.076 (in-sample avg dev_std = 0.111)
NEC for r=0.6 all L1 = 0.069 +- 0.104 (in-sample avg dev_std = 0.111)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.747
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.719
NEC for r=0.9 class 0.0 = 0.015 +- 0.145 (in-sample avg dev_std = 0.177)
NEC for r=0.9 class 1.0 = 0.126 +- 0.145 (in-sample avg dev_std = 0.177)
NEC for r=0.9 all KL = 0.047 +- 0.145 (in-sample avg dev_std = 0.177)
NEC for r=0.9 all L1 = 0.07 +- 0.141 (in-sample avg dev_std = 0.177)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.765
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.724
NEC for r=1.0 class 0.0 = 0.011 +- 0.155 (in-sample avg dev_std = 0.182)
NEC for r=1.0 class 1.0 = 0.133 +- 0.155 (in-sample avg dev_std = 0.182)
NEC for r=1.0 all KL = 0.055 +- 0.155 (in-sample avg dev_std = 0.182)
NEC for r=1.0 all L1 = 0.072 +- 0.146 (in-sample avg dev_std = 0.182)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.968, 0.936, 0.969, 1.0], 'all_L1': [0.919, 0.891, 0.954, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.973, 0.956, 0.972, 1.0], 'all_L1': [0.908, 0.899, 0.951, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.983, 0.97, 0.974, 1.0], 'all_L1': [0.927, 0.919, 0.952, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.96, 0.956, 0.98, 1.0], 'all_L1': [0.881, 0.893, 0.957, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.968, 0.968, 0.979, 1.0], 'all_L1': [0.887, 0.903, 0.957, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.018, 0.067, 0.154, 0.169], 'all_L1': [0.062, 0.111, 0.147, 0.147]}), defaultdict(<class 'list'>, {'all_KL': [0.013, 0.039, 0.107, 0.132], 'all_L1': [0.072, 0.091, 0.126, 0.132]}), defaultdict(<class 'list'>, {'all_KL': [0.011, 0.034, 0.09, 0.112], 'all_L1': [0.062, 0.08, 0.113, 0.125]}), defaultdict(<class 'list'>, {'all_KL': [0.017, 0.037, 0.09, 0.11], 'all_L1': [0.083, 0.092, 0.122, 0.125]}), defaultdict(<class 'list'>, {'all_KL': [0.013, 0.035, 0.093, 0.112], 'all_L1': [0.077, 0.093, 0.125, 0.13]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.972, 0.951, 0.962, 1.0], 'all_L1': [0.924, 0.909, 0.954, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.97, 0.966, 0.984, 1.0], 'all_L1': [0.901, 0.913, 0.967, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.984, 0.971, 0.987, 1.0], 'all_L1': [0.928, 0.921, 0.966, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.969, 0.958, 0.991, 1.0], 'all_L1': [0.896, 0.903, 0.971, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.972, 0.979, 0.988, 1.0], 'all_L1': [0.896, 0.926, 0.967, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.019, 0.056, 0.107, 0.117], 'all_L1': [0.064, 0.096, 0.109, 0.108]}), defaultdict(<class 'list'>, {'all_KL': [0.011, 0.024, 0.063, 0.084], 'all_L1': [0.065, 0.072, 0.087, 0.092]}), defaultdict(<class 'list'>, {'all_KL': [0.008, 0.026, 0.067, 0.082], 'all_L1': [0.054, 0.072, 0.096, 0.105]}), defaultdict(<class 'list'>, {'all_KL': [0.016, 0.025, 0.036, 0.046], 'all_L1': [0.077, 0.073, 0.067, 0.075]}), defaultdict(<class 'list'>, {'all_KL': [0.011, 0.015, 0.05, 0.06], 'all_L1': [0.07, 0.059, 0.087, 0.091]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.978, 0.961, 0.978, 1.0], 'all_L1': [0.936, 0.928, 0.973, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.979, 0.977, 0.994, 1.0], 'all_L1': [0.919, 0.936, 0.985, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.985, 0.976, 0.981, 1.0], 'all_L1': [0.936, 0.939, 0.966, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.962, 0.96, 0.988, 1.0], 'all_L1': [0.89, 0.92, 0.977, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.972, 0.97, 0.992, 1.0], 'all_L1': [0.899, 0.92, 0.975, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.021, 0.037, 0.07, 0.071], 'all_L1': [0.061, 0.067, 0.068, 0.061]}), defaultdict(<class 'list'>, {'all_KL': [0.011, 0.023, 0.043, 0.051], 'all_L1': [0.061, 0.056, 0.049, 0.05]}), defaultdict(<class 'list'>, {'all_KL': [0.009, 0.019, 0.051, 0.066], 'all_L1': [0.053, 0.053, 0.067, 0.073]}), defaultdict(<class 'list'>, {'all_KL': [0.018, 0.031, 0.038, 0.038], 'all_L1': [0.076, 0.069, 0.053, 0.05]}), defaultdict(<class 'list'>, {'all_KL': [0.017, 0.025, 0.047, 0.055], 'all_L1': [0.079, 0.069, 0.07, 0.072]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.904 +- 0.018, 0.901 +- 0.010, 0.954 +- 0.002, 1.000 +- 0.000
suff++ class all_KL  =  0.970 +- 0.008, 0.957 +- 0.012, 0.975 +- 0.004, 1.000 +- 0.000
suff++_acc_int  =  0.587 +- 0.011, 0.741 +- 0.019, 0.844 +- 0.006
nec class all_L1  =  0.071 +- 0.008, 0.093 +- 0.010, 0.127 +- 0.011, 0.132 +- 0.008
nec class all_KL  =  0.014 +- 0.003, 0.042 +- 0.012, 0.107 +- 0.024, 0.127 +- 0.022
nec_acc_int  =  0.666 +- 0.017, 0.756 +- 0.009, 0.797 +- 0.007, 0.801 +- 0.008

Eval split val
suff++ class all_L1  =  0.909 +- 0.014, 0.914 +- 0.008, 0.965 +- 0.006, 1.000 +- 0.000
suff++ class all_KL  =  0.973 +- 0.005, 0.965 +- 0.010, 0.982 +- 0.010, 1.000 +- 0.000
suff++_acc_int  =  0.573 +- 0.023, 0.678 +- 0.023, 0.733 +- 0.009
nec class all_L1  =  0.066 +- 0.008, 0.074 +- 0.012, 0.089 +- 0.014, 0.094 +- 0.012
nec class all_KL  =  0.013 +- 0.004, 0.029 +- 0.014, 0.065 +- 0.024, 0.078 +- 0.024
nec_acc_int  =  0.668 +- 0.014, 0.719 +- 0.020, 0.728 +- 0.015, 0.730 +- 0.013

Eval split test
suff++ class all_L1  =  0.916 +- 0.019, 0.929 +- 0.008, 0.975 +- 0.006, 1.000 +- 0.000
suff++ class all_KL  =  0.975 +- 0.008, 0.969 +- 0.007, 0.987 +- 0.006, 1.000 +- 0.000
suff++_acc_int  =  0.547 +- 0.021, 0.626 +- 0.036, 0.722 +- 0.031
nec class all_L1  =  0.066 +- 0.010, 0.063 +- 0.007, 0.061 +- 0.009, 0.061 +- 0.010
nec class all_KL  =  0.015 +- 0.004, 0.027 +- 0.006, 0.050 +- 0.011, 0.056 +- 0.012
nec_acc_int  =  0.591 +- 0.019, 0.649 +- 0.029, 0.692 +- 0.036, 0.698 +- 0.038


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.488 +- 0.005, 0.497 +- 0.003, 0.540 +- 0.006, 0.566 +- 0.004
Faith. Armon (L1)= 		  =  0.132 +- 0.014, 0.169 +- 0.016, 0.223 +- 0.017, 0.233 +- 0.013
Faith. GMean (L1)= 	  =  0.253 +- 0.012, 0.290 +- 0.014, 0.347 +- 0.015, 0.363 +- 0.011
Faith. Aritm (KL)= 		  =  0.492 +- 0.003, 0.500 +- 0.002, 0.541 +- 0.011, 0.564 +- 0.011
Faith. Armon (KL)= 		  =  0.028 +- 0.005, 0.081 +- 0.022, 0.192 +- 0.038, 0.225 +- 0.035
Faith. GMean (KL)= 	  =  0.118 +- 0.011, 0.199 +- 0.026, 0.321 +- 0.034, 0.355 +- 0.030

Eval split val
Faith. Aritm (L1)= 		  =  0.488 +- 0.004, 0.494 +- 0.005, 0.527 +- 0.004, 0.547 +- 0.006
Faith. Armon (L1)= 		  =  0.123 +- 0.013, 0.137 +- 0.020, 0.163 +- 0.023, 0.172 +- 0.020
Faith. GMean (L1)= 	  =  0.244 +- 0.013, 0.260 +- 0.020, 0.292 +- 0.022, 0.306 +- 0.019
Faith. Aritm (KL)= 		  =  0.493 +- 0.002, 0.497 +- 0.004, 0.524 +- 0.007, 0.539 +- 0.012
Faith. Armon (KL)= 		  =  0.026 +- 0.008, 0.056 +- 0.026, 0.120 +- 0.041, 0.143 +- 0.041
Faith. GMean (KL)= 	  =  0.111 +- 0.017, 0.164 +- 0.036, 0.248 +- 0.044, 0.276 +- 0.043

Eval split test
Faith. Aritm (L1)= 		  =  0.491 +- 0.005, 0.496 +- 0.001, 0.518 +- 0.003, 0.531 +- 0.005
Faith. Armon (L1)= 		  =  0.123 +- 0.017, 0.118 +- 0.012, 0.115 +- 0.015, 0.115 +- 0.018
Faith. GMean (L1)= 	  =  0.245 +- 0.016, 0.241 +- 0.012, 0.244 +- 0.017, 0.247 +- 0.020
Faith. Aritm (KL)= 		  =  0.495 +- 0.003, 0.498 +- 0.002, 0.518 +- 0.004, 0.528 +- 0.006
Faith. Armon (KL)= 		  =  0.030 +- 0.009, 0.052 +- 0.012, 0.095 +- 0.020, 0.106 +- 0.021
Faith. GMean (KL)= 	  =  0.120 +- 0.018, 0.161 +- 0.018, 0.220 +- 0.023, 0.236 +- 0.025
Computed for split load_split = id



Completed in  0:07:32.353395  for LECIvGIN GOODHIV/scaffold



DONE LECI GOODHIV/scaffold

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 14:58:36 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 04/07/2024 02:58:36 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/07/2024 02:59:08 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/07/2024 02:59:18 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/07/2024 02:59:29 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/07/2024 02:59:45 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 03:00:01 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 154...
[0m[1;37mINFO[0m: [1mCheckpoint 154: 
-----------------------------------
Train ROC-AUC: 0.9727
Train Loss: 0.1378
ID Validation ROC-AUC: 0.9248
ID Validation Loss: 0.2674
ID Test ROC-AUC: 0.9280
ID Test Loss: 0.2650
OOD Validation ROC-AUC: 0.6550
OOD Validation Loss: 0.4948
OOD Test ROC-AUC: 0.7073
OOD Test Loss: 0.6679

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 56...
[0m[1;37mINFO[0m: [1mCheckpoint 56: 
-----------------------------------
Train ROC-AUC: 0.9313
Train Loss: 0.2369
ID Validation ROC-AUC: 0.9115
ID Validation Loss: 0.2655
ID Test ROC-AUC: 0.9145
ID Test Loss: 0.2678
OOD Validation ROC-AUC: 0.7016
OOD Validation Loss: 0.3203
OOD Test ROC-AUC: 0.7225
OOD Test Loss: 0.5195

[0m[1;37mINFO[0m: [1mChartInfo 0.9280 0.7073 0.9145 0.7225 0.9115 0.7016[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 04/07/2024 03:00:04 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 04/07/2024 03:00:09 PM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 04/07/2024 03:00:13 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.718
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.652
SUFF++ for r=0.3 class 0.0 = 0.632 +- 0.203 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.3 class 1.0 = 0.698 +- 0.203 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.3 all KL = 0.728 +- 0.203 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.3 all L1 = 0.691 +- 0.156 (in-sample avg dev_std = 0.412)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.844
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.784
SUFF++ for r=0.6 class 0.0 = 0.66 +- 0.164 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.6 class 1.0 = 0.868 +- 0.164 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.6 all KL = 0.878 +- 0.164 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.6 all L1 = 0.844 +- 0.182 (in-sample avg dev_std = 0.261)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.909
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.874
SUFF++ for r=0.9 class 0.0 = 0.686 +- 0.131 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.9 class 1.0 = 0.925 +- 0.131 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.9 all KL = 0.933 +- 0.131 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.9 all L1 = 0.897 +- 0.165 (in-sample avg dev_std = 0.190)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.647
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.586
SUFF++ for r=0.3 class 0.0 = 0.634 +- 0.189 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.3 class 1.0 = 0.654 +- 0.189 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.3 all KL = 0.743 +- 0.189 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.3 all L1 = 0.652 +- 0.140 (in-sample avg dev_std = 0.424)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.656
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 799
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.655
SUFF++ for r=0.6 class 0.0 = 0.686 +- 0.181 (in-sample avg dev_std = 0.318)
SUFF++ for r=0.6 class 1.0 = 0.765 +- 0.181 (in-sample avg dev_std = 0.318)
SUFF++ for r=0.6 all KL = 0.821 +- 0.181 (in-sample avg dev_std = 0.318)
SUFF++ for r=0.6 all L1 = 0.759 +- 0.191 (in-sample avg dev_std = 0.318)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.688
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.675
SUFF++ for r=0.9 class 0.0 = 0.746 +- 0.153 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 class 1.0 = 0.841 +- 0.153 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 all KL = 0.898 +- 0.153 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 all L1 = 0.833 +- 0.186 (in-sample avg dev_std = 0.222)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.627
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.574
SUFF++ for r=0.3 class 0.0 = 0.621 +- 0.191 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.3 class 1.0 = 0.652 +- 0.191 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.3 all KL = 0.726 +- 0.191 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.3 all L1 = 0.647 +- 0.150 (in-sample avg dev_std = 0.430)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.656
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.624
SUFF++ for r=0.6 class 0.0 = 0.69 +- 0.185 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.6 class 1.0 = 0.782 +- 0.185 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.6 all KL = 0.821 +- 0.185 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.6 all L1 = 0.767 +- 0.194 (in-sample avg dev_std = 0.324)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.697
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.656
SUFF++ for r=0.9 class 0.0 = 0.75 +- 0.156 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.9 class 1.0 = 0.847 +- 0.156 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.9 all KL = 0.891 +- 0.156 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.9 all L1 = 0.831 +- 0.191 (in-sample avg dev_std = 0.236)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.718
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.67
NEC for r=0.3 class 0.0 = 0.365 +- 0.235 (in-sample avg dev_std = 0.372)
NEC for r=0.3 class 1.0 = 0.319 +- 0.235 (in-sample avg dev_std = 0.372)
NEC for r=0.3 all KL = 0.281 +- 0.235 (in-sample avg dev_std = 0.372)
NEC for r=0.3 all L1 = 0.325 +- 0.180 (in-sample avg dev_std = 0.372)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.844
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.804
NEC for r=0.6 class 0.0 = 0.35 +- 0.200 (in-sample avg dev_std = 0.262)
NEC for r=0.6 class 1.0 = 0.15 +- 0.200 (in-sample avg dev_std = 0.262)
NEC for r=0.6 all KL = 0.149 +- 0.200 (in-sample avg dev_std = 0.262)
NEC for r=0.6 all L1 = 0.174 +- 0.189 (in-sample avg dev_std = 0.262)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.909
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.865
NEC for r=0.9 class 0.0 = 0.319 +- 0.155 (in-sample avg dev_std = 0.220)
NEC for r=0.9 class 1.0 = 0.088 +- 0.155 (in-sample avg dev_std = 0.220)
NEC for r=0.9 all KL = 0.087 +- 0.155 (in-sample avg dev_std = 0.220)
NEC for r=0.9 all L1 = 0.115 +- 0.169 (in-sample avg dev_std = 0.220)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.921
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.868
NEC for r=1.0 class 0.0 = 0.327 +- 0.151 (in-sample avg dev_std = 0.225)
NEC for r=1.0 class 1.0 = 0.079 +- 0.151 (in-sample avg dev_std = 0.225)
NEC for r=1.0 all KL = 0.078 +- 0.151 (in-sample avg dev_std = 0.225)
NEC for r=1.0 all L1 = 0.107 +- 0.163 (in-sample avg dev_std = 0.225)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.647
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.578
NEC for r=0.3 class 0.0 = 0.421 +- 0.213 (in-sample avg dev_std = 0.377)
NEC for r=0.3 class 1.0 = 0.367 +- 0.213 (in-sample avg dev_std = 0.377)
NEC for r=0.3 all KL = 0.27 +- 0.213 (in-sample avg dev_std = 0.377)
NEC for r=0.3 all L1 = 0.371 +- 0.171 (in-sample avg dev_std = 0.377)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.66
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.65
NEC for r=0.6 class 0.0 = 0.336 +- 0.200 (in-sample avg dev_std = 0.317)
NEC for r=0.6 class 1.0 = 0.246 +- 0.200 (in-sample avg dev_std = 0.317)
NEC for r=0.6 all KL = 0.191 +- 0.200 (in-sample avg dev_std = 0.317)
NEC for r=0.6 all L1 = 0.254 +- 0.198 (in-sample avg dev_std = 0.317)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.688
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.672
NEC for r=0.9 class 0.0 = 0.282 +- 0.163 (in-sample avg dev_std = 0.260)
NEC for r=0.9 class 1.0 = 0.176 +- 0.163 (in-sample avg dev_std = 0.260)
NEC for r=0.9 all KL = 0.127 +- 0.163 (in-sample avg dev_std = 0.260)
NEC for r=0.9 all L1 = 0.185 +- 0.188 (in-sample avg dev_std = 0.260)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.664
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.666
NEC for r=1.0 class 0.0 = 0.276 +- 0.171 (in-sample avg dev_std = 0.286)
NEC for r=1.0 class 1.0 = 0.184 +- 0.171 (in-sample avg dev_std = 0.286)
NEC for r=1.0 all KL = 0.129 +- 0.171 (in-sample avg dev_std = 0.286)
NEC for r=1.0 all L1 = 0.192 +- 0.194 (in-sample avg dev_std = 0.286)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.627
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.583
NEC for r=0.3 class 0.0 = 0.391 +- 0.221 (in-sample avg dev_std = 0.377)
NEC for r=0.3 class 1.0 = 0.359 +- 0.221 (in-sample avg dev_std = 0.377)
NEC for r=0.3 all KL = 0.277 +- 0.221 (in-sample avg dev_std = 0.377)
NEC for r=0.3 all L1 = 0.364 +- 0.179 (in-sample avg dev_std = 0.377)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.656
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.65
NEC for r=0.6 class 0.0 = 0.316 +- 0.205 (in-sample avg dev_std = 0.313)
NEC for r=0.6 class 1.0 = 0.237 +- 0.205 (in-sample avg dev_std = 0.313)
NEC for r=0.6 all KL = 0.198 +- 0.205 (in-sample avg dev_std = 0.313)
NEC for r=0.6 all L1 = 0.25 +- 0.197 (in-sample avg dev_std = 0.313)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.697
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.679
NEC for r=0.9 class 0.0 = 0.247 +- 0.165 (in-sample avg dev_std = 0.264)
NEC for r=0.9 class 1.0 = 0.168 +- 0.165 (in-sample avg dev_std = 0.264)
NEC for r=0.9 all KL = 0.127 +- 0.165 (in-sample avg dev_std = 0.264)
NEC for r=0.9 all L1 = 0.181 +- 0.187 (in-sample avg dev_std = 0.264)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.708
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.698
NEC for r=1.0 class 0.0 = 0.261 +- 0.175 (in-sample avg dev_std = 0.282)
NEC for r=1.0 class 1.0 = 0.173 +- 0.175 (in-sample avg dev_std = 0.282)
NEC for r=1.0 all KL = 0.13 +- 0.175 (in-sample avg dev_std = 0.282)
NEC for r=1.0 all L1 = 0.188 +- 0.194 (in-sample avg dev_std = 0.282)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 15:04:42 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 04/07/2024 03:04:42 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/07/2024 03:05:13 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/07/2024 03:05:24 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/07/2024 03:05:34 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/07/2024 03:05:51 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:06:06 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 03:06:07 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 145...
[0m[1;37mINFO[0m: [1mCheckpoint 145: 
-----------------------------------
Train ROC-AUC: 0.9651
Train Loss: 0.1565
ID Validation ROC-AUC: 0.9232
ID Validation Loss: 0.2486
ID Test ROC-AUC: 0.9247
ID Test Loss: 0.2522
OOD Validation ROC-AUC: 0.6738
OOD Validation Loss: 0.4349
OOD Test ROC-AUC: 0.7050
OOD Test Loss: 0.6209

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 30...
[0m[1;37mINFO[0m: [1mCheckpoint 30: 
-----------------------------------
Train ROC-AUC: 0.9095
Train Loss: 0.2555
ID Validation ROC-AUC: 0.8966
ID Validation Loss: 0.2709
ID Test ROC-AUC: 0.8993
ID Test Loss: 0.2732
OOD Validation ROC-AUC: 0.6989
OOD Validation Loss: 0.3054
OOD Test ROC-AUC: 0.7302
OOD Test Loss: 0.4911

[0m[1;37mINFO[0m: [1mChartInfo 0.9247 0.7050 0.8993 0.7302 0.8966 0.6989[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 04/07/2024 03:06:08 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 04/07/2024 03:06:13 PM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 04/07/2024 03:06:17 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.539
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.549
SUFF++ for r=0.3 class 0.0 = 0.65 +- 0.147 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.3 class 1.0 = 0.638 +- 0.147 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.3 all KL = 0.792 +- 0.147 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.3 all L1 = 0.639 +- 0.120 (in-sample avg dev_std = 0.387)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.788
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.747
SUFF++ for r=0.6 class 0.0 = 0.631 +- 0.205 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.6 class 1.0 = 0.693 +- 0.205 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.6 all KL = 0.748 +- 0.205 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.6 all L1 = 0.685 +- 0.187 (in-sample avg dev_std = 0.393)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.907
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.862
SUFF++ for r=0.9 class 0.0 = 0.754 +- 0.151 (in-sample avg dev_std = 0.212)
SUFF++ for r=0.9 class 1.0 = 0.895 +- 0.151 (in-sample avg dev_std = 0.212)
SUFF++ for r=0.9 all KL = 0.917 +- 0.151 (in-sample avg dev_std = 0.212)
SUFF++ for r=0.9 all L1 = 0.878 +- 0.160 (in-sample avg dev_std = 0.212)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.546
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.524
SUFF++ for r=0.3 class 0.0 = 0.674 +- 0.122 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.3 class 1.0 = 0.68 +- 0.122 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.3 all KL = 0.836 +- 0.122 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.3 all L1 = 0.679 +- 0.122 (in-sample avg dev_std = 0.341)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.652
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.605
SUFF++ for r=0.6 class 0.0 = 0.667 +- 0.169 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.6 class 1.0 = 0.651 +- 0.169 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.6 all KL = 0.758 +- 0.169 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.6 all L1 = 0.652 +- 0.149 (in-sample avg dev_std = 0.411)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.654
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.653
SUFF++ for r=0.9 class 0.0 = 0.771 +- 0.162 (in-sample avg dev_std = 0.254)
SUFF++ for r=0.9 class 1.0 = 0.816 +- 0.162 (in-sample avg dev_std = 0.254)
SUFF++ for r=0.9 all KL = 0.888 +- 0.162 (in-sample avg dev_std = 0.254)
SUFF++ for r=0.9 all L1 = 0.812 +- 0.175 (in-sample avg dev_std = 0.254)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.473
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.495
SUFF++ for r=0.3 class 0.0 = 0.66 +- 0.135 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.3 class 1.0 = 0.661 +- 0.135 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.3 all KL = 0.819 +- 0.135 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.3 all L1 = 0.661 +- 0.120 (in-sample avg dev_std = 0.355)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.603
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.591
SUFF++ for r=0.6 class 0.0 = 0.625 +- 0.193 (in-sample avg dev_std = 0.418)
SUFF++ for r=0.6 class 1.0 = 0.647 +- 0.193 (in-sample avg dev_std = 0.418)
SUFF++ for r=0.6 all KL = 0.733 +- 0.193 (in-sample avg dev_std = 0.418)
SUFF++ for r=0.6 all L1 = 0.643 +- 0.155 (in-sample avg dev_std = 0.418)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.667
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.657
SUFF++ for r=0.9 class 0.0 = 0.78 +- 0.175 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 class 1.0 = 0.818 +- 0.175 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 all KL = 0.876 +- 0.175 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 all L1 = 0.811 +- 0.184 (in-sample avg dev_std = 0.266)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.539
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.549
NEC for r=0.3 class 0.0 = 0.249 +- 0.136 (in-sample avg dev_std = 0.265)
NEC for r=0.3 class 1.0 = 0.289 +- 0.136 (in-sample avg dev_std = 0.265)
NEC for r=0.3 all KL = 0.13 +- 0.136 (in-sample avg dev_std = 0.265)
NEC for r=0.3 all L1 = 0.284 +- 0.142 (in-sample avg dev_std = 0.265)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.788
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.753
NEC for r=0.6 class 0.0 = 0.274 +- 0.222 (in-sample avg dev_std = 0.337)
NEC for r=0.6 class 1.0 = 0.293 +- 0.222 (in-sample avg dev_std = 0.337)
NEC for r=0.6 all KL = 0.221 +- 0.222 (in-sample avg dev_std = 0.337)
NEC for r=0.6 all L1 = 0.291 +- 0.189 (in-sample avg dev_std = 0.337)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.907
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.866
NEC for r=0.9 class 0.0 = 0.256 +- 0.189 (in-sample avg dev_std = 0.265)
NEC for r=0.9 class 1.0 = 0.144 +- 0.189 (in-sample avg dev_std = 0.265)
NEC for r=0.9 all KL = 0.133 +- 0.189 (in-sample avg dev_std = 0.265)
NEC for r=0.9 all L1 = 0.157 +- 0.170 (in-sample avg dev_std = 0.265)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.91
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.872
NEC for r=1.0 class 0.0 = 0.232 +- 0.164 (in-sample avg dev_std = 0.238)
NEC for r=1.0 class 1.0 = 0.105 +- 0.164 (in-sample avg dev_std = 0.238)
NEC for r=1.0 all KL = 0.094 +- 0.164 (in-sample avg dev_std = 0.238)
NEC for r=1.0 all L1 = 0.12 +- 0.156 (in-sample avg dev_std = 0.238)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.546
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.514
NEC for r=0.3 class 0.0 = 0.296 +- 0.115 (in-sample avg dev_std = 0.230)
NEC for r=0.3 class 1.0 = 0.262 +- 0.115 (in-sample avg dev_std = 0.230)
NEC for r=0.3 all KL = 0.109 +- 0.115 (in-sample avg dev_std = 0.230)
NEC for r=0.3 all L1 = 0.265 +- 0.137 (in-sample avg dev_std = 0.230)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.652
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.604
NEC for r=0.6 class 0.0 = 0.308 +- 0.189 (in-sample avg dev_std = 0.329)
NEC for r=0.6 class 1.0 = 0.313 +- 0.189 (in-sample avg dev_std = 0.329)
NEC for r=0.6 all KL = 0.199 +- 0.189 (in-sample avg dev_std = 0.329)
NEC for r=0.6 all L1 = 0.313 +- 0.166 (in-sample avg dev_std = 0.329)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.654
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.643
NEC for r=0.9 class 0.0 = 0.253 +- 0.171 (in-sample avg dev_std = 0.305)
NEC for r=0.9 class 1.0 = 0.218 +- 0.171 (in-sample avg dev_std = 0.305)
NEC for r=0.9 all KL = 0.156 +- 0.171 (in-sample avg dev_std = 0.305)
NEC for r=0.9 all L1 = 0.221 +- 0.170 (in-sample avg dev_std = 0.305)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.672
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.66
NEC for r=1.0 class 0.0 = 0.223 +- 0.155 (in-sample avg dev_std = 0.284)
NEC for r=1.0 class 1.0 = 0.178 +- 0.155 (in-sample avg dev_std = 0.284)
NEC for r=1.0 all KL = 0.118 +- 0.155 (in-sample avg dev_std = 0.284)
NEC for r=1.0 all L1 = 0.182 +- 0.169 (in-sample avg dev_std = 0.284)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.473
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.48
NEC for r=0.3 class 0.0 = 0.27 +- 0.131 (in-sample avg dev_std = 0.243)
NEC for r=0.3 class 1.0 = 0.273 +- 0.131 (in-sample avg dev_std = 0.243)
NEC for r=0.3 all KL = 0.119 +- 0.131 (in-sample avg dev_std = 0.243)
NEC for r=0.3 all L1 = 0.272 +- 0.144 (in-sample avg dev_std = 0.243)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.603
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.604
NEC for r=0.6 class 0.0 = 0.332 +- 0.212 (in-sample avg dev_std = 0.331)
NEC for r=0.6 class 1.0 = 0.321 +- 0.212 (in-sample avg dev_std = 0.331)
NEC for r=0.6 all KL = 0.22 +- 0.212 (in-sample avg dev_std = 0.331)
NEC for r=0.6 all L1 = 0.323 +- 0.182 (in-sample avg dev_std = 0.331)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.667
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.668
NEC for r=0.9 class 0.0 = 0.25 +- 0.190 (in-sample avg dev_std = 0.303)
NEC for r=0.9 class 1.0 = 0.225 +- 0.190 (in-sample avg dev_std = 0.303)
NEC for r=0.9 all KL = 0.168 +- 0.190 (in-sample avg dev_std = 0.303)
NEC for r=0.9 all L1 = 0.229 +- 0.184 (in-sample avg dev_std = 0.303)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.694
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.681
NEC for r=1.0 class 0.0 = 0.226 +- 0.169 (in-sample avg dev_std = 0.297)
NEC for r=1.0 class 1.0 = 0.182 +- 0.169 (in-sample avg dev_std = 0.297)
NEC for r=1.0 all KL = 0.133 +- 0.169 (in-sample avg dev_std = 0.297)
NEC for r=1.0 all L1 = 0.189 +- 0.171 (in-sample avg dev_std = 0.297)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 15:10:47 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 04/07/2024 03:10:47 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/07/2024 03:11:19 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/07/2024 03:11:29 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/07/2024 03:11:40 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/07/2024 03:11:56 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 03:12:12 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 119...
[0m[1;37mINFO[0m: [1mCheckpoint 119: 
-----------------------------------
Train ROC-AUC: 0.9599
Train Loss: 0.1725
ID Validation ROC-AUC: 0.9219
ID Validation Loss: 0.2486
ID Test ROC-AUC: 0.9238
ID Test Loss: 0.2502
OOD Validation ROC-AUC: 0.6637
OOD Validation Loss: 0.3933
OOD Test ROC-AUC: 0.7126
OOD Test Loss: 0.5743

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 24...
[0m[1;37mINFO[0m: [1mCheckpoint 24: 
-----------------------------------
Train ROC-AUC: 0.9060
Train Loss: 0.2554
ID Validation ROC-AUC: 0.8940
ID Validation Loss: 0.2686
ID Test ROC-AUC: 0.8978
ID Test Loss: 0.2703
OOD Validation ROC-AUC: 0.6978
OOD Validation Loss: 0.2989
OOD Test ROC-AUC: 0.7280
OOD Test Loss: 0.4799

[0m[1;37mINFO[0m: [1mChartInfo 0.9238 0.7126 0.8978 0.7280 0.8940 0.6978[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 04/07/2024 03:12:14 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 04/07/2024 03:12:19 PM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 04/07/2024 03:12:23 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.67
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.648
SUFF++ for r=0.3 class 0.0 = 0.697 +- 0.144 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.3 class 1.0 = 0.706 +- 0.144 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.3 all KL = 0.829 +- 0.144 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.3 all L1 = 0.705 +- 0.133 (in-sample avg dev_std = 0.328)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.814
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.789
SUFF++ for r=0.6 class 0.0 = 0.692 +- 0.130 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.6 class 1.0 = 0.855 +- 0.130 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.6 all KL = 0.886 +- 0.130 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.6 all L1 = 0.836 +- 0.160 (in-sample avg dev_std = 0.230)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.897
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.88
SUFF++ for r=0.9 class 0.0 = 0.762 +- 0.104 (in-sample avg dev_std = 0.138)
SUFF++ for r=0.9 class 1.0 = 0.937 +- 0.104 (in-sample avg dev_std = 0.138)
SUFF++ for r=0.9 all KL = 0.952 +- 0.104 (in-sample avg dev_std = 0.138)
SUFF++ for r=0.9 all L1 = 0.917 +- 0.136 (in-sample avg dev_std = 0.138)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.591
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.572
SUFF++ for r=0.3 class 0.0 = 0.698 +- 0.120 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.3 class 1.0 = 0.694 +- 0.120 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.3 all KL = 0.838 +- 0.120 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.3 all L1 = 0.695 +- 0.118 (in-sample avg dev_std = 0.337)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.66
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.633
SUFF++ for r=0.6 class 0.0 = 0.709 +- 0.129 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.6 class 1.0 = 0.77 +- 0.129 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.6 all KL = 0.858 +- 0.129 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.6 all L1 = 0.764 +- 0.165 (in-sample avg dev_std = 0.267)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.669
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.664
SUFF++ for r=0.9 class 0.0 = 0.808 +- 0.112 (in-sample avg dev_std = 0.173)
SUFF++ for r=0.9 class 1.0 = 0.864 +- 0.112 (in-sample avg dev_std = 0.173)
SUFF++ for r=0.9 all KL = 0.929 +- 0.112 (in-sample avg dev_std = 0.173)
SUFF++ for r=0.9 all L1 = 0.859 +- 0.156 (in-sample avg dev_std = 0.173)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.567
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.579
SUFF++ for r=0.3 class 0.0 = 0.686 +- 0.137 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.3 class 1.0 = 0.701 +- 0.137 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.3 all KL = 0.829 +- 0.137 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.3 all L1 = 0.698 +- 0.125 (in-sample avg dev_std = 0.337)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.653
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.653
SUFF++ for r=0.6 class 0.0 = 0.709 +- 0.134 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.6 class 1.0 = 0.79 +- 0.134 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.6 all KL = 0.859 +- 0.134 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.6 all L1 = 0.776 +- 0.167 (in-sample avg dev_std = 0.276)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.719
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.688
SUFF++ for r=0.9 class 0.0 = 0.77 +- 0.120 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.9 class 1.0 = 0.87 +- 0.120 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.9 all KL = 0.922 +- 0.120 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.9 all L1 = 0.853 +- 0.158 (in-sample avg dev_std = 0.186)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.67
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.647
NEC for r=0.3 class 0.0 = 0.289 +- 0.167 (in-sample avg dev_std = 0.294)
NEC for r=0.3 class 1.0 = 0.301 +- 0.167 (in-sample avg dev_std = 0.294)
NEC for r=0.3 all KL = 0.173 +- 0.167 (in-sample avg dev_std = 0.294)
NEC for r=0.3 all L1 = 0.299 +- 0.146 (in-sample avg dev_std = 0.294)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.814
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.786
NEC for r=0.6 class 0.0 = 0.291 +- 0.164 (in-sample avg dev_std = 0.231)
NEC for r=0.6 class 1.0 = 0.168 +- 0.164 (in-sample avg dev_std = 0.231)
NEC for r=0.6 all KL = 0.137 +- 0.164 (in-sample avg dev_std = 0.231)
NEC for r=0.6 all L1 = 0.183 +- 0.161 (in-sample avg dev_std = 0.231)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.897
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.878
NEC for r=0.9 class 0.0 = 0.232 +- 0.103 (in-sample avg dev_std = 0.149)
NEC for r=0.9 class 1.0 = 0.07 +- 0.103 (in-sample avg dev_std = 0.149)
NEC for r=0.9 all KL = 0.054 +- 0.103 (in-sample avg dev_std = 0.149)
NEC for r=0.9 all L1 = 0.089 +- 0.129 (in-sample avg dev_std = 0.149)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.916
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.881
NEC for r=1.0 class 0.0 = 0.221 +- 0.087 (in-sample avg dev_std = 0.142)
NEC for r=1.0 class 1.0 = 0.052 +- 0.087 (in-sample avg dev_std = 0.142)
NEC for r=1.0 all KL = 0.04 +- 0.087 (in-sample avg dev_std = 0.142)
NEC for r=1.0 all L1 = 0.072 +- 0.120 (in-sample avg dev_std = 0.142)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.591
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.589
NEC for r=0.3 class 0.0 = 0.3 +- 0.143 (in-sample avg dev_std = 0.286)
NEC for r=0.3 class 1.0 = 0.304 +- 0.143 (in-sample avg dev_std = 0.286)
NEC for r=0.3 all KL = 0.155 +- 0.143 (in-sample avg dev_std = 0.286)
NEC for r=0.3 all L1 = 0.304 +- 0.141 (in-sample avg dev_std = 0.286)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.66
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.641
NEC for r=0.6 class 0.0 = 0.257 +- 0.136 (in-sample avg dev_std = 0.253)
NEC for r=0.6 class 1.0 = 0.235 +- 0.136 (in-sample avg dev_std = 0.253)
NEC for r=0.6 all KL = 0.142 +- 0.136 (in-sample avg dev_std = 0.253)
NEC for r=0.6 all L1 = 0.237 +- 0.150 (in-sample avg dev_std = 0.253)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.669
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.665
NEC for r=0.9 class 0.0 = 0.205 +- 0.117 (in-sample avg dev_std = 0.207)
NEC for r=0.9 class 1.0 = 0.15 +- 0.117 (in-sample avg dev_std = 0.207)
NEC for r=0.9 all KL = 0.087 +- 0.117 (in-sample avg dev_std = 0.207)
NEC for r=0.9 all L1 = 0.155 +- 0.150 (in-sample avg dev_std = 0.207)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.68
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.674
NEC for r=1.0 class 0.0 = 0.171 +- 0.093 (in-sample avg dev_std = 0.184)
NEC for r=1.0 class 1.0 = 0.121 +- 0.093 (in-sample avg dev_std = 0.184)
NEC for r=1.0 all KL = 0.062 +- 0.093 (in-sample avg dev_std = 0.184)
NEC for r=1.0 all L1 = 0.125 +- 0.137 (in-sample avg dev_std = 0.184)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.567
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.564
NEC for r=0.3 class 0.0 = 0.282 +- 0.156 (in-sample avg dev_std = 0.281)
NEC for r=0.3 class 1.0 = 0.307 +- 0.156 (in-sample avg dev_std = 0.281)
NEC for r=0.3 all KL = 0.167 +- 0.156 (in-sample avg dev_std = 0.281)
NEC for r=0.3 all L1 = 0.303 +- 0.139 (in-sample avg dev_std = 0.281)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.653
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.639
NEC for r=0.6 class 0.0 = 0.296 +- 0.155 (in-sample avg dev_std = 0.257)
NEC for r=0.6 class 1.0 = 0.218 +- 0.155 (in-sample avg dev_std = 0.257)
NEC for r=0.6 all KL = 0.151 +- 0.155 (in-sample avg dev_std = 0.257)
NEC for r=0.6 all L1 = 0.231 +- 0.160 (in-sample avg dev_std = 0.257)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.719
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.691
NEC for r=0.9 class 0.0 = 0.243 +- 0.116 (in-sample avg dev_std = 0.195)
NEC for r=0.9 class 1.0 = 0.135 +- 0.116 (in-sample avg dev_std = 0.195)
NEC for r=0.9 all KL = 0.085 +- 0.116 (in-sample avg dev_std = 0.195)
NEC for r=0.9 all L1 = 0.153 +- 0.154 (in-sample avg dev_std = 0.195)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.731
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.7
NEC for r=1.0 class 0.0 = 0.216 +- 0.112 (in-sample avg dev_std = 0.184)
NEC for r=1.0 class 1.0 = 0.119 +- 0.112 (in-sample avg dev_std = 0.184)
NEC for r=1.0 all KL = 0.07 +- 0.112 (in-sample avg dev_std = 0.184)
NEC for r=1.0 all L1 = 0.135 +- 0.152 (in-sample avg dev_std = 0.184)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 15:16:53 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 04/07/2024 03:16:54 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/07/2024 03:17:24 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/07/2024 03:17:35 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/07/2024 03:17:45 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:01 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 03:18:17 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 136...
[0m[1;37mINFO[0m: [1mCheckpoint 136: 
-----------------------------------
Train ROC-AUC: 0.9683
Train Loss: 0.1544
ID Validation ROC-AUC: 0.9248
ID Validation Loss: 0.2444
ID Test ROC-AUC: 0.9244
ID Test Loss: 0.2478
OOD Validation ROC-AUC: 0.6793
OOD Validation Loss: 0.3957
OOD Test ROC-AUC: 0.7158
OOD Test Loss: 0.5602

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 92...
[0m[1;37mINFO[0m: [1mCheckpoint 92: 
-----------------------------------
Train ROC-AUC: 0.9510
Train Loss: 0.1952
ID Validation ROC-AUC: 0.9178
ID Validation Loss: 0.2653
ID Test ROC-AUC: 0.9200
ID Test Loss: 0.2655
OOD Validation ROC-AUC: 0.6963
OOD Validation Loss: 0.3695
OOD Test ROC-AUC: 0.7235
OOD Test Loss: 0.5689

[0m[1;37mINFO[0m: [1mChartInfo 0.9244 0.7158 0.9200 0.7235 0.9178 0.6963[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 04/07/2024 03:18:19 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 04/07/2024 03:18:24 PM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 04/07/2024 03:18:28 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.712
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.656
SUFF++ for r=0.3 class 0.0 = 0.686 +- 0.116 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.3 class 1.0 = 0.748 +- 0.116 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.3 all KL = 0.862 +- 0.116 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.3 all L1 = 0.74 +- 0.116 (in-sample avg dev_std = 0.277)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.846
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.81
SUFF++ for r=0.6 class 0.0 = 0.694 +- 0.106 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.6 class 1.0 = 0.876 +- 0.106 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.6 all KL = 0.911 +- 0.106 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.6 all L1 = 0.854 +- 0.146 (in-sample avg dev_std = 0.208)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.915
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.894
SUFF++ for r=0.9 class 0.0 = 0.775 +- 0.089 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.9 class 1.0 = 0.928 +- 0.089 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.9 all KL = 0.957 +- 0.089 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.9 all L1 = 0.91 +- 0.126 (in-sample avg dev_std = 0.148)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.554
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.541
SUFF++ for r=0.3 class 0.0 = 0.714 +- 0.103 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.3 class 1.0 = 0.732 +- 0.103 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.3 all KL = 0.873 +- 0.103 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.3 all L1 = 0.731 +- 0.109 (in-sample avg dev_std = 0.285)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.62
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.616
SUFF++ for r=0.6 class 0.0 = 0.766 +- 0.111 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.6 class 1.0 = 0.798 +- 0.111 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.6 all KL = 0.885 +- 0.111 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.6 all L1 = 0.796 +- 0.146 (in-sample avg dev_std = 0.248)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.65
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.65
SUFF++ for r=0.9 class 0.0 = 0.836 +- 0.110 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.9 class 1.0 = 0.86 +- 0.110 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.9 all KL = 0.935 +- 0.110 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.9 all L1 = 0.858 +- 0.145 (in-sample avg dev_std = 0.194)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.606
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.586
SUFF++ for r=0.3 class 0.0 = 0.718 +- 0.102 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.3 class 1.0 = 0.732 +- 0.102 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.3 all KL = 0.872 +- 0.102 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.3 all L1 = 0.73 +- 0.108 (in-sample avg dev_std = 0.287)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.664
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.653
SUFF++ for r=0.6 class 0.0 = 0.728 +- 0.112 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.6 class 1.0 = 0.798 +- 0.112 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.6 all KL = 0.879 +- 0.112 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.6 all L1 = 0.786 +- 0.148 (in-sample avg dev_std = 0.264)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.705
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.687
SUFF++ for r=0.9 class 0.0 = 0.791 +- 0.121 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.9 class 1.0 = 0.854 +- 0.121 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.9 all KL = 0.923 +- 0.121 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.9 all L1 = 0.843 +- 0.150 (in-sample avg dev_std = 0.216)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.712
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.701
NEC for r=0.3 class 0.0 = 0.279 +- 0.115 (in-sample avg dev_std = 0.207)
NEC for r=0.3 class 1.0 = 0.217 +- 0.115 (in-sample avg dev_std = 0.207)
NEC for r=0.3 all KL = 0.101 +- 0.115 (in-sample avg dev_std = 0.207)
NEC for r=0.3 all L1 = 0.224 +- 0.127 (in-sample avg dev_std = 0.207)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.846
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.817
NEC for r=0.6 class 0.0 = 0.29 +- 0.145 (in-sample avg dev_std = 0.223)
NEC for r=0.6 class 1.0 = 0.153 +- 0.145 (in-sample avg dev_std = 0.223)
NEC for r=0.6 all KL = 0.123 +- 0.145 (in-sample avg dev_std = 0.223)
NEC for r=0.6 all L1 = 0.169 +- 0.146 (in-sample avg dev_std = 0.223)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.915
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.868
NEC for r=0.9 class 0.0 = 0.294 +- 0.116 (in-sample avg dev_std = 0.196)
NEC for r=0.9 class 1.0 = 0.101 +- 0.116 (in-sample avg dev_std = 0.196)
NEC for r=0.9 all KL = 0.076 +- 0.116 (in-sample avg dev_std = 0.196)
NEC for r=0.9 all L1 = 0.123 +- 0.149 (in-sample avg dev_std = 0.196)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.918
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.871
NEC for r=1.0 class 0.0 = 0.272 +- 0.120 (in-sample avg dev_std = 0.197)
NEC for r=1.0 class 1.0 = 0.084 +- 0.120 (in-sample avg dev_std = 0.197)
NEC for r=1.0 all KL = 0.068 +- 0.120 (in-sample avg dev_std = 0.197)
NEC for r=1.0 all L1 = 0.106 +- 0.143 (in-sample avg dev_std = 0.197)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.554
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.546
NEC for r=0.3 class 0.0 = 0.262 +- 0.114 (in-sample avg dev_std = 0.223)
NEC for r=0.3 class 1.0 = 0.242 +- 0.114 (in-sample avg dev_std = 0.223)
NEC for r=0.3 all KL = 0.102 +- 0.114 (in-sample avg dev_std = 0.223)
NEC for r=0.3 all L1 = 0.244 +- 0.126 (in-sample avg dev_std = 0.223)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.62
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.607
NEC for r=0.6 class 0.0 = 0.256 +- 0.151 (in-sample avg dev_std = 0.258)
NEC for r=0.6 class 1.0 = 0.224 +- 0.151 (in-sample avg dev_std = 0.258)
NEC for r=0.6 all KL = 0.141 +- 0.151 (in-sample avg dev_std = 0.258)
NEC for r=0.6 all L1 = 0.227 +- 0.154 (in-sample avg dev_std = 0.258)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.65
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.636
NEC for r=0.9 class 0.0 = 0.224 +- 0.128 (in-sample avg dev_std = 0.250)
NEC for r=0.9 class 1.0 = 0.184 +- 0.128 (in-sample avg dev_std = 0.250)
NEC for r=0.9 all KL = 0.106 +- 0.128 (in-sample avg dev_std = 0.250)
NEC for r=0.9 all L1 = 0.187 +- 0.151 (in-sample avg dev_std = 0.250)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.666
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.655
NEC for r=1.0 class 0.0 = 0.246 +- 0.125 (in-sample avg dev_std = 0.239)
NEC for r=1.0 class 1.0 = 0.161 +- 0.125 (in-sample avg dev_std = 0.239)
NEC for r=1.0 all KL = 0.091 +- 0.125 (in-sample avg dev_std = 0.239)
NEC for r=1.0 all L1 = 0.168 +- 0.156 (in-sample avg dev_std = 0.239)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.606
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.609
NEC for r=0.3 class 0.0 = 0.244 +- 0.098 (in-sample avg dev_std = 0.218)
NEC for r=0.3 class 1.0 = 0.244 +- 0.098 (in-sample avg dev_std = 0.218)
NEC for r=0.3 all KL = 0.098 +- 0.098 (in-sample avg dev_std = 0.218)
NEC for r=0.3 all L1 = 0.244 +- 0.121 (in-sample avg dev_std = 0.218)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.664
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.66
NEC for r=0.6 class 0.0 = 0.292 +- 0.145 (in-sample avg dev_std = 0.260)
NEC for r=0.6 class 1.0 = 0.222 +- 0.145 (in-sample avg dev_std = 0.260)
NEC for r=0.6 all KL = 0.142 +- 0.145 (in-sample avg dev_std = 0.260)
NEC for r=0.6 all L1 = 0.234 +- 0.152 (in-sample avg dev_std = 0.260)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.705
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.688
NEC for r=0.9 class 0.0 = 0.262 +- 0.142 (in-sample avg dev_std = 0.262)
NEC for r=0.9 class 1.0 = 0.196 +- 0.142 (in-sample avg dev_std = 0.262)
NEC for r=0.9 all KL = 0.123 +- 0.142 (in-sample avg dev_std = 0.262)
NEC for r=0.9 all L1 = 0.207 +- 0.164 (in-sample avg dev_std = 0.262)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.726
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.703
NEC for r=1.0 class 0.0 = 0.266 +- 0.143 (in-sample avg dev_std = 0.255)
NEC for r=1.0 class 1.0 = 0.17 +- 0.143 (in-sample avg dev_std = 0.255)
NEC for r=1.0 all KL = 0.107 +- 0.143 (in-sample avg dev_std = 0.255)
NEC for r=1.0 all L1 = 0.186 +- 0.168 (in-sample avg dev_std = 0.255)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 15:22:58 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 04/07/2024 03:22:58 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/07/2024 03:23:29 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/07/2024 03:23:40 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/07/2024 03:23:51 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:07 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 03:24:22 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 166...
[0m[1;37mINFO[0m: [1mCheckpoint 166: 
-----------------------------------
Train ROC-AUC: 0.9712
Train Loss: 0.1682
ID Validation ROC-AUC: 0.9235
ID Validation Loss: 0.3171
ID Test ROC-AUC: 0.9267
ID Test Loss: 0.3191
OOD Validation ROC-AUC: 0.6651
OOD Validation Loss: 0.5310
OOD Test ROC-AUC: 0.7146
OOD Test Loss: 0.7641

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 26...
[0m[1;37mINFO[0m: [1mCheckpoint 26: 
-----------------------------------
Train ROC-AUC: 0.9105
Train Loss: 0.2495
ID Validation ROC-AUC: 0.8984
ID Validation Loss: 0.2622
ID Test ROC-AUC: 0.9001
ID Test Loss: 0.2660
OOD Validation ROC-AUC: 0.7015
OOD Validation Loss: 0.2936
OOD Test ROC-AUC: 0.7252
OOD Test Loss: 0.4753

[0m[1;37mINFO[0m: [1mChartInfo 0.9267 0.7146 0.9001 0.7252 0.8984 0.7015[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 04/07/2024 03:24:25 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 04/07/2024 03:24:30 PM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 04/07/2024 03:24:34 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.568
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.56
SUFF++ for r=0.3 class 0.0 = 0.645 +- 0.183 (in-sample avg dev_std = 0.435)
SUFF++ for r=0.3 class 1.0 = 0.621 +- 0.183 (in-sample avg dev_std = 0.435)
SUFF++ for r=0.3 all KL = 0.731 +- 0.183 (in-sample avg dev_std = 0.435)
SUFF++ for r=0.3 all L1 = 0.624 +- 0.131 (in-sample avg dev_std = 0.435)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.784
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.742
SUFF++ for r=0.6 class 0.0 = 0.628 +- 0.198 (in-sample avg dev_std = 0.400)
SUFF++ for r=0.6 class 1.0 = 0.726 +- 0.198 (in-sample avg dev_std = 0.400)
SUFF++ for r=0.6 all KL = 0.766 +- 0.198 (in-sample avg dev_std = 0.400)
SUFF++ for r=0.6 all L1 = 0.715 +- 0.186 (in-sample avg dev_std = 0.400)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.871
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.837
SUFF++ for r=0.9 class 0.0 = 0.785 +- 0.149 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.9 class 1.0 = 0.895 +- 0.149 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.9 all KL = 0.922 +- 0.149 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.9 all L1 = 0.882 +- 0.156 (in-sample avg dev_std = 0.205)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.443
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.496
SUFF++ for r=0.3 class 0.0 = 0.649 +- 0.181 (in-sample avg dev_std = 0.431)
SUFF++ for r=0.3 class 1.0 = 0.637 +- 0.181 (in-sample avg dev_std = 0.431)
SUFF++ for r=0.3 all KL = 0.743 +- 0.181 (in-sample avg dev_std = 0.431)
SUFF++ for r=0.3 all L1 = 0.638 +- 0.132 (in-sample avg dev_std = 0.431)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.561
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 799
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.592
SUFF++ for r=0.6 class 0.0 = 0.649 +- 0.190 (in-sample avg dev_std = 0.404)
SUFF++ for r=0.6 class 1.0 = 0.679 +- 0.190 (in-sample avg dev_std = 0.404)
SUFF++ for r=0.6 all KL = 0.756 +- 0.190 (in-sample avg dev_std = 0.404)
SUFF++ for r=0.6 all L1 = 0.676 +- 0.181 (in-sample avg dev_std = 0.404)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.643
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.619
SUFF++ for r=0.9 class 0.0 = 0.801 +- 0.162 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.9 class 1.0 = 0.84 +- 0.162 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.9 all KL = 0.898 +- 0.162 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.9 all L1 = 0.837 +- 0.178 (in-sample avg dev_std = 0.236)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.55
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.53
SUFF++ for r=0.3 class 0.0 = 0.64 +- 0.172 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.3 class 1.0 = 0.639 +- 0.172 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.3 all KL = 0.741 +- 0.172 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.3 all L1 = 0.639 +- 0.130 (in-sample avg dev_std = 0.433)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.63
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.604
SUFF++ for r=0.6 class 0.0 = 0.651 +- 0.193 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 class 1.0 = 0.677 +- 0.193 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 all KL = 0.744 +- 0.193 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 all L1 = 0.673 +- 0.172 (in-sample avg dev_std = 0.417)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.672
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.646
SUFF++ for r=0.9 class 0.0 = 0.806 +- 0.172 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 1.0 = 0.851 +- 0.172 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 all KL = 0.896 +- 0.172 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 all L1 = 0.843 +- 0.175 (in-sample avg dev_std = 0.243)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.568
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.516
NEC for r=0.3 class 0.0 = 0.389 +- 0.195 (in-sample avg dev_std = 0.372)
NEC for r=0.3 class 1.0 = 0.37 +- 0.195 (in-sample avg dev_std = 0.372)
NEC for r=0.3 all KL = 0.255 +- 0.195 (in-sample avg dev_std = 0.372)
NEC for r=0.3 all L1 = 0.373 +- 0.157 (in-sample avg dev_std = 0.372)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.784
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.741
NEC for r=0.6 class 0.0 = 0.385 +- 0.213 (in-sample avg dev_std = 0.390)
NEC for r=0.6 class 1.0 = 0.299 +- 0.213 (in-sample avg dev_std = 0.390)
NEC for r=0.6 all KL = 0.257 +- 0.213 (in-sample avg dev_std = 0.390)
NEC for r=0.6 all L1 = 0.309 +- 0.188 (in-sample avg dev_std = 0.390)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.871
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.831
NEC for r=0.9 class 0.0 = 0.292 +- 0.185 (in-sample avg dev_std = 0.275)
NEC for r=0.9 class 1.0 = 0.141 +- 0.185 (in-sample avg dev_std = 0.275)
NEC for r=0.9 all KL = 0.131 +- 0.185 (in-sample avg dev_std = 0.275)
NEC for r=0.9 all L1 = 0.158 +- 0.178 (in-sample avg dev_std = 0.275)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.89
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.832
NEC for r=1.0 class 0.0 = 0.27 +- 0.173 (in-sample avg dev_std = 0.253)
NEC for r=1.0 class 1.0 = 0.109 +- 0.173 (in-sample avg dev_std = 0.253)
NEC for r=1.0 all KL = 0.107 +- 0.173 (in-sample avg dev_std = 0.253)
NEC for r=1.0 all L1 = 0.128 +- 0.169 (in-sample avg dev_std = 0.253)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.443
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.517
NEC for r=0.3 class 0.0 = 0.411 +- 0.195 (in-sample avg dev_std = 0.363)
NEC for r=0.3 class 1.0 = 0.363 +- 0.195 (in-sample avg dev_std = 0.363)
NEC for r=0.3 all KL = 0.254 +- 0.195 (in-sample avg dev_std = 0.363)
NEC for r=0.3 all L1 = 0.367 +- 0.157 (in-sample avg dev_std = 0.363)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.567
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.571
NEC for r=0.6 class 0.0 = 0.392 +- 0.201 (in-sample avg dev_std = 0.390)
NEC for r=0.6 class 1.0 = 0.328 +- 0.201 (in-sample avg dev_std = 0.390)
NEC for r=0.6 all KL = 0.252 +- 0.201 (in-sample avg dev_std = 0.390)
NEC for r=0.6 all L1 = 0.333 +- 0.178 (in-sample avg dev_std = 0.390)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.643
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.642
NEC for r=0.9 class 0.0 = 0.249 +- 0.184 (in-sample avg dev_std = 0.305)
NEC for r=0.9 class 1.0 = 0.207 +- 0.184 (in-sample avg dev_std = 0.305)
NEC for r=0.9 all KL = 0.157 +- 0.184 (in-sample avg dev_std = 0.305)
NEC for r=0.9 all L1 = 0.21 +- 0.185 (in-sample avg dev_std = 0.305)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.658
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.639
NEC for r=1.0 class 0.0 = 0.212 +- 0.172 (in-sample avg dev_std = 0.272)
NEC for r=1.0 class 1.0 = 0.159 +- 0.172 (in-sample avg dev_std = 0.272)
NEC for r=1.0 all KL = 0.121 +- 0.172 (in-sample avg dev_std = 0.272)
NEC for r=1.0 all L1 = 0.163 +- 0.173 (in-sample avg dev_std = 0.272)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.55
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.495
NEC for r=0.3 class 0.0 = 0.372 +- 0.198 (in-sample avg dev_std = 0.368)
NEC for r=0.3 class 1.0 = 0.366 +- 0.198 (in-sample avg dev_std = 0.368)
NEC for r=0.3 all KL = 0.256 +- 0.198 (in-sample avg dev_std = 0.368)
NEC for r=0.3 all L1 = 0.367 +- 0.159 (in-sample avg dev_std = 0.368)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.63
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.593
NEC for r=0.6 class 0.0 = 0.351 +- 0.205 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 1.0 = 0.335 +- 0.205 (in-sample avg dev_std = 0.387)
NEC for r=0.6 all KL = 0.26 +- 0.205 (in-sample avg dev_std = 0.387)
NEC for r=0.6 all L1 = 0.338 +- 0.174 (in-sample avg dev_std = 0.387)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.672
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.653
NEC for r=0.9 class 0.0 = 0.293 +- 0.203 (in-sample avg dev_std = 0.329)
NEC for r=0.9 class 1.0 = 0.21 +- 0.203 (in-sample avg dev_std = 0.329)
NEC for r=0.9 all KL = 0.181 +- 0.203 (in-sample avg dev_std = 0.329)
NEC for r=0.9 all L1 = 0.224 +- 0.193 (in-sample avg dev_std = 0.329)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.699
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.666
NEC for r=1.0 class 0.0 = 0.244 +- 0.185 (in-sample avg dev_std = 0.294)
NEC for r=1.0 class 1.0 = 0.169 +- 0.185 (in-sample avg dev_std = 0.294)
NEC for r=1.0 all KL = 0.14 +- 0.185 (in-sample avg dev_std = 0.294)
NEC for r=1.0 all L1 = 0.181 +- 0.183 (in-sample avg dev_std = 0.294)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.728, 0.878, 0.933, 1.0], 'all_L1': [0.691, 0.844, 0.897, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.792, 0.748, 0.917, 1.0], 'all_L1': [0.639, 0.685, 0.878, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.829, 0.886, 0.952, 1.0], 'all_L1': [0.705, 0.836, 0.917, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.862, 0.911, 0.957, 1.0], 'all_L1': [0.74, 0.854, 0.91, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.731, 0.766, 0.922, 1.0], 'all_L1': [0.624, 0.715, 0.882, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.281, 0.149, 0.087, 0.078], 'all_L1': [0.325, 0.174, 0.115, 0.107]}), defaultdict(<class 'list'>, {'all_KL': [0.13, 0.221, 0.133, 0.094], 'all_L1': [0.284, 0.291, 0.157, 0.12]}), defaultdict(<class 'list'>, {'all_KL': [0.173, 0.137, 0.054, 0.04], 'all_L1': [0.299, 0.183, 0.089, 0.072]}), defaultdict(<class 'list'>, {'all_KL': [0.101, 0.123, 0.076, 0.068], 'all_L1': [0.224, 0.169, 0.123, 0.106]}), defaultdict(<class 'list'>, {'all_KL': [0.255, 0.257, 0.131, 0.107], 'all_L1': [0.373, 0.309, 0.158, 0.128]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.743, 0.821, 0.898, 1.0], 'all_L1': [0.652, 0.759, 0.833, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.836, 0.758, 0.888, 1.0], 'all_L1': [0.679, 0.652, 0.812, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.838, 0.858, 0.929, 1.0], 'all_L1': [0.695, 0.764, 0.859, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.873, 0.885, 0.935, 1.0], 'all_L1': [0.731, 0.796, 0.858, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.743, 0.756, 0.898, 1.0], 'all_L1': [0.638, 0.676, 0.837, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.27, 0.191, 0.127, 0.129], 'all_L1': [0.371, 0.254, 0.185, 0.192]}), defaultdict(<class 'list'>, {'all_KL': [0.109, 0.199, 0.156, 0.118], 'all_L1': [0.265, 0.313, 0.221, 0.182]}), defaultdict(<class 'list'>, {'all_KL': [0.155, 0.142, 0.087, 0.062], 'all_L1': [0.304, 0.237, 0.155, 0.125]}), defaultdict(<class 'list'>, {'all_KL': [0.102, 0.141, 0.106, 0.091], 'all_L1': [0.244, 0.227, 0.187, 0.168]}), defaultdict(<class 'list'>, {'all_KL': [0.254, 0.252, 0.157, 0.121], 'all_L1': [0.367, 0.333, 0.21, 0.163]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.726, 0.821, 0.891, 1.0], 'all_L1': [0.647, 0.767, 0.831, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.819, 0.733, 0.876, 1.0], 'all_L1': [0.661, 0.643, 0.811, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.829, 0.859, 0.922, 1.0], 'all_L1': [0.698, 0.776, 0.853, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.872, 0.879, 0.923, 1.0], 'all_L1': [0.73, 0.786, 0.843, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.741, 0.744, 0.896, 1.0], 'all_L1': [0.639, 0.673, 0.843, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.277, 0.198, 0.127, 0.13], 'all_L1': [0.364, 0.25, 0.181, 0.188]}), defaultdict(<class 'list'>, {'all_KL': [0.119, 0.22, 0.168, 0.133], 'all_L1': [0.272, 0.323, 0.229, 0.189]}), defaultdict(<class 'list'>, {'all_KL': [0.167, 0.151, 0.085, 0.07], 'all_L1': [0.303, 0.231, 0.153, 0.135]}), defaultdict(<class 'list'>, {'all_KL': [0.098, 0.142, 0.123, 0.107], 'all_L1': [0.244, 0.234, 0.207, 0.186]}), defaultdict(<class 'list'>, {'all_KL': [0.256, 0.26, 0.181, 0.14], 'all_L1': [0.367, 0.338, 0.224, 0.181]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.680 +- 0.043, 0.787 +- 0.072, 0.897 +- 0.015, 1.000 +- 0.000
suff++ class all_KL  =  0.788 +- 0.053, 0.838 +- 0.067, 0.936 +- 0.016, 1.000 +- 0.000
suff++_acc_int  =  0.613 +- 0.048, 0.775 +- 0.026, 0.870 +- 0.019
nec class all_L1  =  0.301 +- 0.049, 0.225 +- 0.062, 0.128 +- 0.026, 0.107 +- 0.019
nec class all_KL  =  0.188 +- 0.070, 0.177 +- 0.052, 0.096 +- 0.031, 0.077 +- 0.023
nec_acc_int  =  0.617 +- 0.072, 0.780 +- 0.029, 0.862 +- 0.016, 0.865 +- 0.017

Eval split val
suff++ class all_L1  =  0.679 +- 0.033, 0.729 +- 0.055, 0.840 +- 0.017, 1.000 +- 0.000
suff++ class all_KL  =  0.807 +- 0.054, 0.816 +- 0.052, 0.910 +- 0.019, 1.000 +- 0.000
suff++_acc_int  =  0.544 +- 0.033, 0.620 +- 0.022, 0.652 +- 0.019
nec class all_L1  =  0.310 +- 0.052, 0.273 +- 0.042, 0.192 +- 0.023, 0.166 +- 0.023
nec class all_KL  =  0.178 +- 0.071, 0.185 +- 0.041, 0.127 +- 0.027, 0.104 +- 0.025
nec_acc_int  =  0.549 +- 0.030, 0.615 +- 0.028, 0.652 +- 0.014, 0.659 +- 0.012

Eval split test
suff++ class all_L1  =  0.675 +- 0.034, 0.729 +- 0.059, 0.836 +- 0.014, 1.000 +- 0.000
suff++ class all_KL  =  0.797 +- 0.055, 0.807 +- 0.059, 0.902 +- 0.018, 1.000 +- 0.000
suff++_acc_int  =  0.553 +- 0.035, 0.625 +- 0.025, 0.667 +- 0.017
nec class all_L1  =  0.310 +- 0.049, 0.275 +- 0.046, 0.199 +- 0.028, 0.176 +- 0.021
nec class all_KL  =  0.183 +- 0.072, 0.194 +- 0.044, 0.137 +- 0.034, 0.116 +- 0.026
nec_acc_int  =  0.546 +- 0.050, 0.629 +- 0.026, 0.676 +- 0.014, 0.690 +- 0.014


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.490 +- 0.017, 0.506 +- 0.009, 0.513 +- 0.007, 0.553 +- 0.010
Faith. Armon (L1)= 		  =  0.413 +- 0.042, 0.342 +- 0.064, 0.223 +- 0.040, 0.192 +- 0.032
Faith. GMean (L1)= 	  =  0.450 +- 0.029, 0.414 +- 0.037, 0.337 +- 0.033, 0.325 +- 0.031
Faith. Aritm (KL)= 		  =  0.488 +- 0.016, 0.508 +- 0.012, 0.516 +- 0.009, 0.539 +- 0.011
Faith. Armon (KL)= 		  =  0.295 +- 0.086, 0.287 +- 0.065, 0.173 +- 0.051, 0.143 +- 0.040
Faith. GMean (KL)= 	  =  0.376 +- 0.061, 0.379 +- 0.040, 0.296 +- 0.047, 0.275 +- 0.044

Eval split val
Faith. Aritm (L1)= 		  =  0.495 +- 0.014, 0.501 +- 0.010, 0.516 +- 0.007, 0.583 +- 0.011
Faith. Armon (L1)= 		  =  0.422 +- 0.043, 0.393 +- 0.036, 0.311 +- 0.030, 0.284 +- 0.034
Faith. GMean (L1)= 	  =  0.456 +- 0.029, 0.443 +- 0.018, 0.400 +- 0.021, 0.406 +- 0.029
Faith. Aritm (KL)= 		  =  0.492 +- 0.012, 0.500 +- 0.012, 0.518 +- 0.007, 0.552 +- 0.012
Faith. Armon (KL)= 		  =  0.282 +- 0.090, 0.298 +- 0.051, 0.221 +- 0.042, 0.188 +- 0.041
Faith. GMean (KL)= 	  =  0.369 +- 0.063, 0.385 +- 0.032, 0.337 +- 0.035, 0.320 +- 0.041

Eval split test
Faith. Aritm (L1)= 		  =  0.493 +- 0.014, 0.502 +- 0.010, 0.517 +- 0.011, 0.588 +- 0.010
Faith. Armon (L1)= 		  =  0.421 +- 0.041, 0.395 +- 0.038, 0.320 +- 0.037, 0.298 +- 0.031
Faith. GMean (L1)= 	  =  0.455 +- 0.028, 0.445 +- 0.020, 0.406 +- 0.028, 0.418 +- 0.026
Faith. Aritm (KL)= 		  =  0.490 +- 0.012, 0.501 +- 0.012, 0.519 +- 0.012, 0.558 +- 0.013
Faith. Armon (KL)= 		  =  0.289 +- 0.090, 0.309 +- 0.052, 0.236 +- 0.052, 0.207 +- 0.042
Faith. GMean (KL)= 	  =  0.372 +- 0.063, 0.392 +- 0.032, 0.348 +- 0.043, 0.338 +- 0.040
Computed for split load_split = id



Completed in  0:30:28.789986  for LECIvGIN LBAPcore/assay



DONE LECI LBAPcore/assay

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 15:29:21 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 03:29:23 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 181...
[0m[1;37mINFO[0m: [1mCheckpoint 181: 
-----------------------------------
Train ACCURACY: 0.9982
Train Loss: 0.0116
ID Validation ACCURACY: 0.9041
ID Validation Loss: 0.3838
ID Test ACCURACY: 0.9016
ID Test Loss: 0.4021
OOD Validation ACCURACY: 0.8686
OOD Validation Loss: 0.5562
OOD Test ACCURACY: 0.5691
OOD Test Loss: 5.0866

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 143...
[0m[1;37mINFO[0m: [1mCheckpoint 143: 
-----------------------------------
Train ACCURACY: 0.9945
Train Loss: 0.0234
ID Validation ACCURACY: 0.9013
ID Validation Loss: 0.3604
ID Test ACCURACY: 0.9033
ID Test Loss: 0.3697
OOD Validation ACCURACY: 0.8911
OOD Validation Loss: 0.4327
OOD Test ACCURACY: 0.7119
OOD Test Loss: 1.6593

[0m[1;37mINFO[0m: [1mChartInfo 0.9016 0.5691 0.9033 0.7119 0.9013 0.8911[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.099
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.099
SUFF++ for r=0.3 class 0 = 0.513 +- 0.120 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.3 class 1 = 0.488 +- 0.120 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.3 class 2 = 0.502 +- 0.120 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.3 class 3 = 0.487 +- 0.120 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.3 class 4 = 0.503 +- 0.120 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.3 class 5 = 0.505 +- 0.120 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.3 class 6 = 0.497 +- 0.120 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.3 class 7 = 0.49 +- 0.120 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.3 class 8 = 0.501 +- 0.120 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.3 class 9 = 0.487 +- 0.120 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.3 all KL = 0.624 +- 0.120 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.3 all L1 = 0.497 +- 0.071 (in-sample avg dev_std = 0.391)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.203
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.17
SUFF++ for r=0.6 class 0 = 0.34 +- 0.204 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 class 1 = 0.438 +- 0.204 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 class 2 = 0.391 +- 0.204 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 class 3 = 0.34 +- 0.204 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 class 4 = 0.41 +- 0.204 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 class 5 = 0.375 +- 0.204 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 class 6 = 0.377 +- 0.204 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 class 7 = 0.379 +- 0.204 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 class 8 = 0.369 +- 0.204 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 class 9 = 0.369 +- 0.204 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 all KL = 0.303 +- 0.204 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 all L1 = 0.379 +- 0.135 (in-sample avg dev_std = 0.402)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.809
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.753
SUFF++ for r=0.9 class 0 = 0.923 +- 0.244 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 1 = 0.956 +- 0.244 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 2 = 0.757 +- 0.244 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 3 = 0.712 +- 0.244 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 4 = 0.851 +- 0.244 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 5 = 0.731 +- 0.244 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 6 = 0.788 +- 0.244 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 7 = 0.827 +- 0.244 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 8 = 0.813 +- 0.244 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 9 = 0.748 +- 0.244 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 all KL = 0.822 +- 0.244 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 all L1 = 0.813 +- 0.213 (in-sample avg dev_std = 0.263)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.105
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.11
SUFF++ for r=0.3 class 0 = 0.528 +- 0.112 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.3 class 1 = 0.485 +- 0.112 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.3 class 2 = 0.512 +- 0.112 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.3 class 3 = 0.515 +- 0.112 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.3 class 4 = 0.503 +- 0.112 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.3 class 5 = 0.511 +- 0.112 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.3 class 6 = 0.503 +- 0.112 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.3 class 7 = 0.499 +- 0.112 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.3 class 8 = 0.503 +- 0.112 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.3 class 9 = 0.501 +- 0.112 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.3 all KL = 0.637 +- 0.112 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.3 all L1 = 0.505 +- 0.069 (in-sample avg dev_std = 0.388)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.2
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.158
SUFF++ for r=0.6 class 0 = 0.358 +- 0.196 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 class 1 = 0.466 +- 0.196 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 class 2 = 0.379 +- 0.196 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 class 3 = 0.386 +- 0.196 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 class 4 = 0.4 +- 0.196 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 class 5 = 0.416 +- 0.196 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 class 6 = 0.358 +- 0.196 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 class 7 = 0.417 +- 0.196 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 class 8 = 0.378 +- 0.196 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 class 9 = 0.359 +- 0.196 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 all KL = 0.313 +- 0.196 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 all L1 = 0.393 +- 0.132 (in-sample avg dev_std = 0.396)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.781
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.732
SUFF++ for r=0.9 class 0 = 0.916 +- 0.263 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 class 1 = 0.951 +- 0.263 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 class 2 = 0.734 +- 0.263 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 class 3 = 0.73 +- 0.263 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 class 4 = 0.776 +- 0.263 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 class 5 = 0.728 +- 0.263 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 class 6 = 0.758 +- 0.263 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 class 7 = 0.89 +- 0.263 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 class 8 = 0.758 +- 0.263 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 class 9 = 0.746 +- 0.263 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 all KL = 0.801 +- 0.263 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 all L1 = 0.801 +- 0.224 (in-sample avg dev_std = 0.296)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.11
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.104
SUFF++ for r=0.3 class 0 = 0.538 +- 0.104 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 1 = 0.521 +- 0.104 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 2 = 0.538 +- 0.104 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 3 = 0.522 +- 0.104 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 4 = 0.53 +- 0.104 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 5 = 0.527 +- 0.104 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 6 = 0.536 +- 0.104 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 7 = 0.519 +- 0.104 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 8 = 0.542 +- 0.104 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 9 = 0.54 +- 0.104 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 all KL = 0.69 +- 0.104 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 all L1 = 0.531 +- 0.075 (in-sample avg dev_std = 0.342)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.174
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.155
SUFF++ for r=0.6 class 0 = 0.465 +- 0.215 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 class 1 = 0.439 +- 0.215 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 class 2 = 0.447 +- 0.215 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 class 3 = 0.417 +- 0.215 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 class 4 = 0.445 +- 0.215 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 class 5 = 0.42 +- 0.215 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 class 6 = 0.442 +- 0.215 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 class 7 = 0.429 +- 0.215 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 class 8 = 0.393 +- 0.215 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 class 9 = 0.401 +- 0.215 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 all KL = 0.381 +- 0.215 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 all L1 = 0.43 +- 0.137 (in-sample avg dev_std = 0.415)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.595
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.56
SUFF++ for r=0.9 class 0 = 0.78 +- 0.279 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.9 class 1 = 0.934 +- 0.279 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.9 class 2 = 0.703 +- 0.279 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.9 class 3 = 0.7 +- 0.279 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.9 class 4 = 0.741 +- 0.279 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.9 class 5 = 0.647 +- 0.279 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.9 class 6 = 0.751 +- 0.279 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.9 class 7 = 0.826 +- 0.279 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.9 class 8 = 0.66 +- 0.279 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.9 class 9 = 0.68 +- 0.279 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.9 all KL = 0.752 +- 0.279 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.9 all L1 = 0.745 +- 0.239 (in-sample avg dev_std = 0.337)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.099
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.099
NEC for r=0.3 class 0 = 0.366 +- 0.091 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 1 = 0.345 +- 0.091 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 2 = 0.353 +- 0.091 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 3 = 0.381 +- 0.091 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 4 = 0.361 +- 0.091 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 5 = 0.349 +- 0.091 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 6 = 0.388 +- 0.091 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 7 = 0.373 +- 0.091 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 8 = 0.359 +- 0.091 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 9 = 0.367 +- 0.091 (in-sample avg dev_std = 0.158)
NEC for r=0.3 all KL = 0.167 +- 0.091 (in-sample avg dev_std = 0.158)
NEC for r=0.3 all L1 = 0.364 +- 0.090 (in-sample avg dev_std = 0.158)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.203
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.157
NEC for r=0.6 class 0 = 0.571 +- 0.233 (in-sample avg dev_std = 0.319)
NEC for r=0.6 class 1 = 0.507 +- 0.233 (in-sample avg dev_std = 0.319)
NEC for r=0.6 class 2 = 0.448 +- 0.233 (in-sample avg dev_std = 0.319)
NEC for r=0.6 class 3 = 0.526 +- 0.233 (in-sample avg dev_std = 0.319)
NEC for r=0.6 class 4 = 0.488 +- 0.233 (in-sample avg dev_std = 0.319)
NEC for r=0.6 class 5 = 0.459 +- 0.233 (in-sample avg dev_std = 0.319)
NEC for r=0.6 class 6 = 0.518 +- 0.233 (in-sample avg dev_std = 0.319)
NEC for r=0.6 class 7 = 0.51 +- 0.233 (in-sample avg dev_std = 0.319)
NEC for r=0.6 class 8 = 0.543 +- 0.233 (in-sample avg dev_std = 0.319)
NEC for r=0.6 class 9 = 0.541 +- 0.233 (in-sample avg dev_std = 0.319)
NEC for r=0.6 all KL = 0.476 +- 0.233 (in-sample avg dev_std = 0.319)
NEC for r=0.6 all L1 = 0.512 +- 0.172 (in-sample avg dev_std = 0.319)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.809
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.608
NEC for r=0.9 class 0 = 0.319 +- 0.331 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 1 = 0.146 +- 0.331 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 2 = 0.385 +- 0.331 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 3 = 0.597 +- 0.331 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 4 = 0.285 +- 0.331 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 5 = 0.506 +- 0.331 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 6 = 0.492 +- 0.331 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 7 = 0.407 +- 0.331 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 8 = 0.392 +- 0.331 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 9 = 0.538 +- 0.331 (in-sample avg dev_std = 0.456)
NEC for r=0.9 all KL = 0.573 +- 0.331 (in-sample avg dev_std = 0.456)
NEC for r=0.9 all L1 = 0.403 +- 0.268 (in-sample avg dev_std = 0.456)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.955
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.835
NEC for r=1.0 class 0 = 0.097 +- 0.369 (in-sample avg dev_std = 0.406)
NEC for r=1.0 class 1 = 0.024 +- 0.369 (in-sample avg dev_std = 0.406)
NEC for r=1.0 class 2 = 0.27 +- 0.369 (in-sample avg dev_std = 0.406)
NEC for r=1.0 class 3 = 0.381 +- 0.369 (in-sample avg dev_std = 0.406)
NEC for r=1.0 class 4 = 0.168 +- 0.369 (in-sample avg dev_std = 0.406)
NEC for r=1.0 class 5 = 0.343 +- 0.369 (in-sample avg dev_std = 0.406)
NEC for r=1.0 class 6 = 0.319 +- 0.369 (in-sample avg dev_std = 0.406)
NEC for r=1.0 class 7 = 0.15 +- 0.369 (in-sample avg dev_std = 0.406)
NEC for r=1.0 class 8 = 0.202 +- 0.369 (in-sample avg dev_std = 0.406)
NEC for r=1.0 class 9 = 0.387 +- 0.369 (in-sample avg dev_std = 0.406)
NEC for r=1.0 all KL = 0.399 +- 0.369 (in-sample avg dev_std = 0.406)
NEC for r=1.0 all L1 = 0.23 +- 0.257 (in-sample avg dev_std = 0.406)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.105
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.103
NEC for r=0.3 class 0 = 0.362 +- 0.092 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 1 = 0.345 +- 0.092 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 2 = 0.394 +- 0.092 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 3 = 0.368 +- 0.092 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 4 = 0.347 +- 0.092 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 5 = 0.383 +- 0.092 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 6 = 0.362 +- 0.092 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 7 = 0.355 +- 0.092 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 8 = 0.387 +- 0.092 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 9 = 0.358 +- 0.092 (in-sample avg dev_std = 0.158)
NEC for r=0.3 all KL = 0.167 +- 0.092 (in-sample avg dev_std = 0.158)
NEC for r=0.3 all L1 = 0.365 +- 0.090 (in-sample avg dev_std = 0.158)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.2
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.148
NEC for r=0.6 class 0 = 0.547 +- 0.219 (in-sample avg dev_std = 0.330)
NEC for r=0.6 class 1 = 0.492 +- 0.219 (in-sample avg dev_std = 0.330)
NEC for r=0.6 class 2 = 0.49 +- 0.219 (in-sample avg dev_std = 0.330)
NEC for r=0.6 class 3 = 0.507 +- 0.219 (in-sample avg dev_std = 0.330)
NEC for r=0.6 class 4 = 0.514 +- 0.219 (in-sample avg dev_std = 0.330)
NEC for r=0.6 class 5 = 0.477 +- 0.219 (in-sample avg dev_std = 0.330)
NEC for r=0.6 class 6 = 0.483 +- 0.219 (in-sample avg dev_std = 0.330)
NEC for r=0.6 class 7 = 0.469 +- 0.219 (in-sample avg dev_std = 0.330)
NEC for r=0.6 class 8 = 0.553 +- 0.219 (in-sample avg dev_std = 0.330)
NEC for r=0.6 class 9 = 0.549 +- 0.219 (in-sample avg dev_std = 0.330)
NEC for r=0.6 all KL = 0.476 +- 0.219 (in-sample avg dev_std = 0.330)
NEC for r=0.6 all L1 = 0.508 +- 0.165 (in-sample avg dev_std = 0.330)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.781
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.581
NEC for r=0.9 class 0 = 0.412 +- 0.356 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 1 = 0.109 +- 0.356 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 2 = 0.439 +- 0.356 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 3 = 0.633 +- 0.356 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 4 = 0.371 +- 0.356 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 5 = 0.543 +- 0.356 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 6 = 0.535 +- 0.356 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 7 = 0.26 +- 0.356 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 8 = 0.474 +- 0.356 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 9 = 0.54 +- 0.356 (in-sample avg dev_std = 0.458)
NEC for r=0.9 all KL = 0.593 +- 0.356 (in-sample avg dev_std = 0.458)
NEC for r=0.9 all L1 = 0.426 +- 0.285 (in-sample avg dev_std = 0.458)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.906
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.795
NEC for r=1.0 class 0 = 0.122 +- 0.372 (in-sample avg dev_std = 0.415)
NEC for r=1.0 class 1 = 0.034 +- 0.372 (in-sample avg dev_std = 0.415)
NEC for r=1.0 class 2 = 0.305 +- 0.372 (in-sample avg dev_std = 0.415)
NEC for r=1.0 class 3 = 0.376 +- 0.372 (in-sample avg dev_std = 0.415)
NEC for r=1.0 class 4 = 0.257 +- 0.372 (in-sample avg dev_std = 0.415)
NEC for r=1.0 class 5 = 0.339 +- 0.372 (in-sample avg dev_std = 0.415)
NEC for r=1.0 class 6 = 0.346 +- 0.372 (in-sample avg dev_std = 0.415)
NEC for r=1.0 class 7 = 0.101 +- 0.372 (in-sample avg dev_std = 0.415)
NEC for r=1.0 class 8 = 0.342 +- 0.372 (in-sample avg dev_std = 0.415)
NEC for r=1.0 class 9 = 0.423 +- 0.372 (in-sample avg dev_std = 0.415)
NEC for r=1.0 all KL = 0.415 +- 0.372 (in-sample avg dev_std = 0.415)
NEC for r=1.0 all L1 = 0.261 +- 0.268 (in-sample avg dev_std = 0.415)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.11
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.106
NEC for r=0.3 class 0 = 0.375 +- 0.086 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 1 = 0.357 +- 0.086 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 2 = 0.375 +- 0.086 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 3 = 0.383 +- 0.086 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 4 = 0.366 +- 0.086 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 5 = 0.359 +- 0.086 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 6 = 0.372 +- 0.086 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 7 = 0.383 +- 0.086 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 8 = 0.369 +- 0.086 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 9 = 0.359 +- 0.086 (in-sample avg dev_std = 0.158)
NEC for r=0.3 all KL = 0.168 +- 0.086 (in-sample avg dev_std = 0.158)
NEC for r=0.3 all L1 = 0.37 +- 0.090 (in-sample avg dev_std = 0.158)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.174
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.143
NEC for r=0.6 class 0 = 0.346 +- 0.235 (in-sample avg dev_std = 0.326)
NEC for r=0.6 class 1 = 0.49 +- 0.235 (in-sample avg dev_std = 0.326)
NEC for r=0.6 class 2 = 0.389 +- 0.235 (in-sample avg dev_std = 0.326)
NEC for r=0.6 class 3 = 0.431 +- 0.235 (in-sample avg dev_std = 0.326)
NEC for r=0.6 class 4 = 0.455 +- 0.235 (in-sample avg dev_std = 0.326)
NEC for r=0.6 class 5 = 0.433 +- 0.235 (in-sample avg dev_std = 0.326)
NEC for r=0.6 class 6 = 0.443 +- 0.235 (in-sample avg dev_std = 0.326)
NEC for r=0.6 class 7 = 0.431 +- 0.235 (in-sample avg dev_std = 0.326)
NEC for r=0.6 class 8 = 0.506 +- 0.235 (in-sample avg dev_std = 0.326)
NEC for r=0.6 class 9 = 0.529 +- 0.235 (in-sample avg dev_std = 0.326)
NEC for r=0.6 all KL = 0.398 +- 0.235 (in-sample avg dev_std = 0.326)
NEC for r=0.6 all L1 = 0.445 +- 0.192 (in-sample avg dev_std = 0.326)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.595
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.448
NEC for r=0.9 class 0 = 0.626 +- 0.348 (in-sample avg dev_std = 0.428)
NEC for r=0.9 class 1 = 0.115 +- 0.348 (in-sample avg dev_std = 0.428)
NEC for r=0.9 class 2 = 0.494 +- 0.348 (in-sample avg dev_std = 0.428)
NEC for r=0.9 class 3 = 0.591 +- 0.348 (in-sample avg dev_std = 0.428)
NEC for r=0.9 class 4 = 0.446 +- 0.348 (in-sample avg dev_std = 0.428)
NEC for r=0.9 class 5 = 0.629 +- 0.348 (in-sample avg dev_std = 0.428)
NEC for r=0.9 class 6 = 0.579 +- 0.348 (in-sample avg dev_std = 0.428)
NEC for r=0.9 class 7 = 0.307 +- 0.348 (in-sample avg dev_std = 0.428)
NEC for r=0.9 class 8 = 0.64 +- 0.348 (in-sample avg dev_std = 0.428)
NEC for r=0.9 class 9 = 0.568 +- 0.348 (in-sample avg dev_std = 0.428)
NEC for r=0.9 all KL = 0.631 +- 0.348 (in-sample avg dev_std = 0.428)
NEC for r=0.9 all L1 = 0.494 +- 0.285 (in-sample avg dev_std = 0.428)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.571
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.585
NEC for r=1.0 class 0 = 0.359 +- 0.391 (in-sample avg dev_std = 0.425)
NEC for r=1.0 class 1 = 0.049 +- 0.391 (in-sample avg dev_std = 0.425)
NEC for r=1.0 class 2 = 0.524 +- 0.391 (in-sample avg dev_std = 0.425)
NEC for r=1.0 class 3 = 0.488 +- 0.391 (in-sample avg dev_std = 0.425)
NEC for r=1.0 class 4 = 0.58 +- 0.391 (in-sample avg dev_std = 0.425)
NEC for r=1.0 class 5 = 0.518 +- 0.391 (in-sample avg dev_std = 0.425)
NEC for r=1.0 class 6 = 0.471 +- 0.391 (in-sample avg dev_std = 0.425)
NEC for r=1.0 class 7 = 0.304 +- 0.391 (in-sample avg dev_std = 0.425)
NEC for r=1.0 class 8 = 0.624 +- 0.391 (in-sample avg dev_std = 0.425)
NEC for r=1.0 class 9 = 0.531 +- 0.391 (in-sample avg dev_std = 0.425)
NEC for r=1.0 all KL = 0.598 +- 0.391 (in-sample avg dev_std = 0.425)
NEC for r=1.0 all L1 = 0.439 +- 0.313 (in-sample avg dev_std = 0.425)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 15:51:03 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 03:51:04 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 03:51:05 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 153...
[0m[1;37mINFO[0m: [1mCheckpoint 153: 
-----------------------------------
Train ACCURACY: 0.9895
Train Loss: 0.0368
ID Validation ACCURACY: 0.8991
ID Validation Loss: 0.3644
ID Test ACCURACY: 0.8936
ID Test Loss: 0.3839
OOD Validation ACCURACY: 0.8770
OOD Validation Loss: 0.4499
OOD Test ACCURACY: 0.4940
OOD Test Loss: 2.9614

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 161...
[0m[1;37mINFO[0m: [1mCheckpoint 161: 
-----------------------------------
Train ACCURACY: 0.9911
Train Loss: 0.0328
ID Validation ACCURACY: 0.8986
ID Validation Loss: 0.3696
ID Test ACCURACY: 0.8951
ID Test Loss: 0.3805
OOD Validation ACCURACY: 0.8856
OOD Validation Loss: 0.4241
OOD Test ACCURACY: 0.5491
OOD Test Loss: 2.5001

[0m[1;37mINFO[0m: [1mChartInfo 0.8936 0.4940 0.8951 0.5491 0.8986 0.8856[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.096
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.093
SUFF++ for r=0.3 class 0 = 0.601 +- 0.103 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.3 class 1 = 0.597 +- 0.103 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.3 class 2 = 0.581 +- 0.103 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.3 class 3 = 0.584 +- 0.103 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.3 class 4 = 0.578 +- 0.103 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.3 class 5 = 0.587 +- 0.103 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.3 class 6 = 0.579 +- 0.103 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.3 class 7 = 0.582 +- 0.103 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.3 class 8 = 0.606 +- 0.103 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.3 class 9 = 0.585 +- 0.103 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.3 all KL = 0.771 +- 0.103 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.3 all L1 = 0.588 +- 0.098 (in-sample avg dev_std = 0.326)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.169
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.105
SUFF++ for r=0.6 class 0 = 0.38 +- 0.226 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 class 1 = 0.429 +- 0.226 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 class 2 = 0.401 +- 0.226 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 class 3 = 0.37 +- 0.226 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 class 4 = 0.401 +- 0.226 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 class 5 = 0.398 +- 0.226 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 class 6 = 0.429 +- 0.226 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 class 7 = 0.384 +- 0.226 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 class 8 = 0.417 +- 0.226 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 class 9 = 0.409 +- 0.226 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 all KL = 0.378 +- 0.226 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 all L1 = 0.402 +- 0.151 (in-sample avg dev_std = 0.346)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.805
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.752
SUFF++ for r=0.9 class 0 = 0.915 +- 0.237 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 1 = 0.925 +- 0.237 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 2 = 0.768 +- 0.237 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 3 = 0.711 +- 0.237 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 4 = 0.808 +- 0.237 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 5 = 0.708 +- 0.237 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 6 = 0.775 +- 0.237 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 7 = 0.828 +- 0.237 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 8 = 0.795 +- 0.237 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 9 = 0.759 +- 0.237 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 all KL = 0.818 +- 0.237 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 all L1 = 0.802 +- 0.206 (in-sample avg dev_std = 0.285)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.095
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.099
SUFF++ for r=0.3 class 0 = 0.606 +- 0.103 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.3 class 1 = 0.607 +- 0.103 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.3 class 2 = 0.606 +- 0.103 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.3 class 3 = 0.6 +- 0.103 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.3 class 4 = 0.609 +- 0.103 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.3 class 5 = 0.599 +- 0.103 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.3 class 6 = 0.586 +- 0.103 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.3 class 7 = 0.595 +- 0.103 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.3 class 8 = 0.597 +- 0.103 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.3 class 9 = 0.616 +- 0.103 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.3 all KL = 0.782 +- 0.103 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.3 all L1 = 0.602 +- 0.103 (in-sample avg dev_std = 0.322)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.141
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.114
SUFF++ for r=0.6 class 0 = 0.418 +- 0.229 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.6 class 1 = 0.429 +- 0.229 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.6 class 2 = 0.441 +- 0.229 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.6 class 3 = 0.437 +- 0.229 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.6 class 4 = 0.441 +- 0.229 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.6 class 5 = 0.42 +- 0.229 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.6 class 6 = 0.403 +- 0.229 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.6 class 7 = 0.434 +- 0.229 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.6 class 8 = 0.431 +- 0.229 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.6 class 9 = 0.424 +- 0.229 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.6 all KL = 0.436 +- 0.229 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.6 all L1 = 0.428 +- 0.158 (in-sample avg dev_std = 0.304)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.806
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.752
SUFF++ for r=0.9 class 0 = 0.898 +- 0.221 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 1 = 0.931 +- 0.221 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 2 = 0.771 +- 0.221 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 3 = 0.769 +- 0.221 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 4 = 0.783 +- 0.221 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 5 = 0.736 +- 0.221 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 6 = 0.747 +- 0.221 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 7 = 0.875 +- 0.221 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 8 = 0.798 +- 0.221 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 9 = 0.783 +- 0.221 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 all KL = 0.833 +- 0.221 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 all L1 = 0.812 +- 0.205 (in-sample avg dev_std = 0.260)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.095
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.096
SUFF++ for r=0.3 class 0 = 0.633 +- 0.090 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.3 class 1 = 0.636 +- 0.090 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.3 class 2 = 0.614 +- 0.090 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.3 class 3 = 0.612 +- 0.090 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.3 class 4 = 0.626 +- 0.090 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.3 class 5 = 0.623 +- 0.090 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.3 class 6 = 0.642 +- 0.090 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.3 class 7 = 0.628 +- 0.090 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.3 class 8 = 0.643 +- 0.090 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.3 class 9 = 0.637 +- 0.090 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.3 all KL = 0.812 +- 0.090 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.3 all L1 = 0.63 +- 0.098 (in-sample avg dev_std = 0.293)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.131
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.112
SUFF++ for r=0.6 class 0 = 0.571 +- 0.244 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.6 class 1 = 0.477 +- 0.244 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.6 class 2 = 0.58 +- 0.244 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.6 class 3 = 0.54 +- 0.244 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.6 class 4 = 0.583 +- 0.244 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.6 class 5 = 0.549 +- 0.244 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.6 class 6 = 0.628 +- 0.244 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.6 class 7 = 0.506 +- 0.244 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.6 class 8 = 0.496 +- 0.244 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.6 class 9 = 0.512 +- 0.244 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.6 all KL = 0.552 +- 0.244 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.6 all L1 = 0.543 +- 0.192 (in-sample avg dev_std = 0.298)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.426
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.398
SUFF++ for r=0.9 class 0 = 0.763 +- 0.211 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 class 1 = 0.876 +- 0.211 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 class 2 = 0.831 +- 0.211 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 class 3 = 0.713 +- 0.211 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 class 4 = 0.812 +- 0.211 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 class 5 = 0.717 +- 0.211 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 class 6 = 0.71 +- 0.211 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 class 7 = 0.763 +- 0.211 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 class 8 = 0.709 +- 0.211 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 class 9 = 0.745 +- 0.211 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 all KL = 0.818 +- 0.211 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 all L1 = 0.766 +- 0.202 (in-sample avg dev_std = 0.281)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.096
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.091
NEC for r=0.3 class 0 = 0.296 +- 0.097 (in-sample avg dev_std = 0.137)
NEC for r=0.3 class 1 = 0.293 +- 0.097 (in-sample avg dev_std = 0.137)
NEC for r=0.3 class 2 = 0.317 +- 0.097 (in-sample avg dev_std = 0.137)
NEC for r=0.3 class 3 = 0.309 +- 0.097 (in-sample avg dev_std = 0.137)
NEC for r=0.3 class 4 = 0.315 +- 0.097 (in-sample avg dev_std = 0.137)
NEC for r=0.3 class 5 = 0.296 +- 0.097 (in-sample avg dev_std = 0.137)
NEC for r=0.3 class 6 = 0.319 +- 0.097 (in-sample avg dev_std = 0.137)
NEC for r=0.3 class 7 = 0.31 +- 0.097 (in-sample avg dev_std = 0.137)
NEC for r=0.3 class 8 = 0.281 +- 0.097 (in-sample avg dev_std = 0.137)
NEC for r=0.3 class 9 = 0.305 +- 0.097 (in-sample avg dev_std = 0.137)
NEC for r=0.3 all KL = 0.133 +- 0.097 (in-sample avg dev_std = 0.137)
NEC for r=0.3 all L1 = 0.304 +- 0.097 (in-sample avg dev_std = 0.137)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.169
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.122
NEC for r=0.6 class 0 = 0.541 +- 0.231 (in-sample avg dev_std = 0.300)
NEC for r=0.6 class 1 = 0.469 +- 0.231 (in-sample avg dev_std = 0.300)
NEC for r=0.6 class 2 = 0.508 +- 0.231 (in-sample avg dev_std = 0.300)
NEC for r=0.6 class 3 = 0.555 +- 0.231 (in-sample avg dev_std = 0.300)
NEC for r=0.6 class 4 = 0.513 +- 0.231 (in-sample avg dev_std = 0.300)
NEC for r=0.6 class 5 = 0.535 +- 0.231 (in-sample avg dev_std = 0.300)
NEC for r=0.6 class 6 = 0.481 +- 0.231 (in-sample avg dev_std = 0.300)
NEC for r=0.6 class 7 = 0.528 +- 0.231 (in-sample avg dev_std = 0.300)
NEC for r=0.6 class 8 = 0.495 +- 0.231 (in-sample avg dev_std = 0.300)
NEC for r=0.6 class 9 = 0.521 +- 0.231 (in-sample avg dev_std = 0.300)
NEC for r=0.6 all KL = 0.458 +- 0.231 (in-sample avg dev_std = 0.300)
NEC for r=0.6 all L1 = 0.514 +- 0.165 (in-sample avg dev_std = 0.300)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.805
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.611
NEC for r=0.9 class 0 = 0.367 +- 0.312 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 1 = 0.194 +- 0.312 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 2 = 0.319 +- 0.312 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 3 = 0.584 +- 0.312 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 4 = 0.346 +- 0.312 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 5 = 0.566 +- 0.312 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 6 = 0.449 +- 0.312 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 7 = 0.43 +- 0.312 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 8 = 0.443 +- 0.312 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 9 = 0.453 +- 0.312 (in-sample avg dev_std = 0.432)
NEC for r=0.9 all KL = 0.54 +- 0.312 (in-sample avg dev_std = 0.432)
NEC for r=0.9 all L1 = 0.411 +- 0.254 (in-sample avg dev_std = 0.432)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.955
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.838
NEC for r=1.0 class 0 = 0.119 +- 0.338 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 1 = 0.02 +- 0.338 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 2 = 0.21 +- 0.338 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 3 = 0.338 +- 0.338 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 4 = 0.169 +- 0.338 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 5 = 0.401 +- 0.338 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 6 = 0.336 +- 0.338 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 7 = 0.21 +- 0.338 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 8 = 0.238 +- 0.338 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 9 = 0.341 +- 0.338 (in-sample avg dev_std = 0.385)
NEC for r=1.0 all KL = 0.364 +- 0.338 (in-sample avg dev_std = 0.385)
NEC for r=1.0 all L1 = 0.233 +- 0.247 (in-sample avg dev_std = 0.385)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.095
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.098
NEC for r=0.3 class 0 = 0.298 +- 0.094 (in-sample avg dev_std = 0.134)
NEC for r=0.3 class 1 = 0.287 +- 0.094 (in-sample avg dev_std = 0.134)
NEC for r=0.3 class 2 = 0.304 +- 0.094 (in-sample avg dev_std = 0.134)
NEC for r=0.3 class 3 = 0.299 +- 0.094 (in-sample avg dev_std = 0.134)
NEC for r=0.3 class 4 = 0.282 +- 0.094 (in-sample avg dev_std = 0.134)
NEC for r=0.3 class 5 = 0.296 +- 0.094 (in-sample avg dev_std = 0.134)
NEC for r=0.3 class 6 = 0.317 +- 0.094 (in-sample avg dev_std = 0.134)
NEC for r=0.3 class 7 = 0.31 +- 0.094 (in-sample avg dev_std = 0.134)
NEC for r=0.3 class 8 = 0.298 +- 0.094 (in-sample avg dev_std = 0.134)
NEC for r=0.3 class 9 = 0.293 +- 0.094 (in-sample avg dev_std = 0.134)
NEC for r=0.3 all KL = 0.129 +- 0.094 (in-sample avg dev_std = 0.134)
NEC for r=0.3 all L1 = 0.298 +- 0.100 (in-sample avg dev_std = 0.134)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.141
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.115
NEC for r=0.6 class 0 = 0.527 +- 0.217 (in-sample avg dev_std = 0.311)
NEC for r=0.6 class 1 = 0.48 +- 0.217 (in-sample avg dev_std = 0.311)
NEC for r=0.6 class 2 = 0.478 +- 0.217 (in-sample avg dev_std = 0.311)
NEC for r=0.6 class 3 = 0.527 +- 0.217 (in-sample avg dev_std = 0.311)
NEC for r=0.6 class 4 = 0.499 +- 0.217 (in-sample avg dev_std = 0.311)
NEC for r=0.6 class 5 = 0.541 +- 0.217 (in-sample avg dev_std = 0.311)
NEC for r=0.6 class 6 = 0.541 +- 0.217 (in-sample avg dev_std = 0.311)
NEC for r=0.6 class 7 = 0.506 +- 0.217 (in-sample avg dev_std = 0.311)
NEC for r=0.6 class 8 = 0.527 +- 0.217 (in-sample avg dev_std = 0.311)
NEC for r=0.6 class 9 = 0.504 +- 0.217 (in-sample avg dev_std = 0.311)
NEC for r=0.6 all KL = 0.446 +- 0.217 (in-sample avg dev_std = 0.311)
NEC for r=0.6 all L1 = 0.512 +- 0.163 (in-sample avg dev_std = 0.311)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.806
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.57
NEC for r=0.9 class 0 = 0.476 +- 0.321 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 1 = 0.143 +- 0.321 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 2 = 0.375 +- 0.321 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 3 = 0.581 +- 0.321 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 4 = 0.401 +- 0.321 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 5 = 0.553 +- 0.321 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 6 = 0.527 +- 0.321 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 7 = 0.411 +- 0.321 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 8 = 0.424 +- 0.321 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 9 = 0.486 +- 0.321 (in-sample avg dev_std = 0.450)
NEC for r=0.9 all KL = 0.569 +- 0.321 (in-sample avg dev_std = 0.450)
NEC for r=0.9 all L1 = 0.433 +- 0.261 (in-sample avg dev_std = 0.450)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.896
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.788
NEC for r=1.0 class 0 = 0.199 +- 0.340 (in-sample avg dev_std = 0.395)
NEC for r=1.0 class 1 = 0.036 +- 0.340 (in-sample avg dev_std = 0.395)
NEC for r=1.0 class 2 = 0.293 +- 0.340 (in-sample avg dev_std = 0.395)
NEC for r=1.0 class 3 = 0.368 +- 0.340 (in-sample avg dev_std = 0.395)
NEC for r=1.0 class 4 = 0.272 +- 0.340 (in-sample avg dev_std = 0.395)
NEC for r=1.0 class 5 = 0.315 +- 0.340 (in-sample avg dev_std = 0.395)
NEC for r=1.0 class 6 = 0.337 +- 0.340 (in-sample avg dev_std = 0.395)
NEC for r=1.0 class 7 = 0.189 +- 0.340 (in-sample avg dev_std = 0.395)
NEC for r=1.0 class 8 = 0.275 +- 0.340 (in-sample avg dev_std = 0.395)
NEC for r=1.0 class 9 = 0.32 +- 0.340 (in-sample avg dev_std = 0.395)
NEC for r=1.0 all KL = 0.374 +- 0.340 (in-sample avg dev_std = 0.395)
NEC for r=1.0 all L1 = 0.257 +- 0.253 (in-sample avg dev_std = 0.395)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.095
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.099
NEC for r=0.3 class 0 = 0.288 +- 0.078 (in-sample avg dev_std = 0.117)
NEC for r=0.3 class 1 = 0.246 +- 0.078 (in-sample avg dev_std = 0.117)
NEC for r=0.3 class 2 = 0.289 +- 0.078 (in-sample avg dev_std = 0.117)
NEC for r=0.3 class 3 = 0.287 +- 0.078 (in-sample avg dev_std = 0.117)
NEC for r=0.3 class 4 = 0.279 +- 0.078 (in-sample avg dev_std = 0.117)
NEC for r=0.3 class 5 = 0.269 +- 0.078 (in-sample avg dev_std = 0.117)
NEC for r=0.3 class 6 = 0.271 +- 0.078 (in-sample avg dev_std = 0.117)
NEC for r=0.3 class 7 = 0.271 +- 0.078 (in-sample avg dev_std = 0.117)
NEC for r=0.3 class 8 = 0.259 +- 0.078 (in-sample avg dev_std = 0.117)
NEC for r=0.3 class 9 = 0.278 +- 0.078 (in-sample avg dev_std = 0.117)
NEC for r=0.3 all KL = 0.109 +- 0.078 (in-sample avg dev_std = 0.117)
NEC for r=0.3 all L1 = 0.274 +- 0.096 (in-sample avg dev_std = 0.117)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.131
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.12
NEC for r=0.6 class 0 = 0.385 +- 0.192 (in-sample avg dev_std = 0.268)
NEC for r=0.6 class 1 = 0.382 +- 0.192 (in-sample avg dev_std = 0.268)
NEC for r=0.6 class 2 = 0.344 +- 0.192 (in-sample avg dev_std = 0.268)
NEC for r=0.6 class 3 = 0.371 +- 0.192 (in-sample avg dev_std = 0.268)
NEC for r=0.6 class 4 = 0.344 +- 0.192 (in-sample avg dev_std = 0.268)
NEC for r=0.6 class 5 = 0.381 +- 0.192 (in-sample avg dev_std = 0.268)
NEC for r=0.6 class 6 = 0.332 +- 0.192 (in-sample avg dev_std = 0.268)
NEC for r=0.6 class 7 = 0.408 +- 0.192 (in-sample avg dev_std = 0.268)
NEC for r=0.6 class 8 = 0.405 +- 0.192 (in-sample avg dev_std = 0.268)
NEC for r=0.6 class 9 = 0.421 +- 0.192 (in-sample avg dev_std = 0.268)
NEC for r=0.6 all KL = 0.312 +- 0.192 (in-sample avg dev_std = 0.268)
NEC for r=0.6 all L1 = 0.377 +- 0.181 (in-sample avg dev_std = 0.268)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.426
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.274
NEC for r=0.9 class 0 = 0.388 +- 0.320 (in-sample avg dev_std = 0.346)
NEC for r=0.9 class 1 = 0.292 +- 0.320 (in-sample avg dev_std = 0.346)
NEC for r=0.9 class 2 = 0.27 +- 0.320 (in-sample avg dev_std = 0.346)
NEC for r=0.9 class 3 = 0.454 +- 0.320 (in-sample avg dev_std = 0.346)
NEC for r=0.9 class 4 = 0.356 +- 0.320 (in-sample avg dev_std = 0.346)
NEC for r=0.9 class 5 = 0.489 +- 0.320 (in-sample avg dev_std = 0.346)
NEC for r=0.9 class 6 = 0.474 +- 0.320 (in-sample avg dev_std = 0.346)
NEC for r=0.9 class 7 = 0.436 +- 0.320 (in-sample avg dev_std = 0.346)
NEC for r=0.9 class 8 = 0.489 +- 0.320 (in-sample avg dev_std = 0.346)
NEC for r=0.9 class 9 = 0.454 +- 0.320 (in-sample avg dev_std = 0.346)
NEC for r=0.9 all KL = 0.436 +- 0.320 (in-sample avg dev_std = 0.346)
NEC for r=0.9 all L1 = 0.407 +- 0.273 (in-sample avg dev_std = 0.346)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.5
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.378
NEC for r=1.0 class 0 = 0.402 +- 0.332 (in-sample avg dev_std = 0.378)
NEC for r=1.0 class 1 = 0.186 +- 0.332 (in-sample avg dev_std = 0.378)
NEC for r=1.0 class 2 = 0.183 +- 0.332 (in-sample avg dev_std = 0.378)
NEC for r=1.0 class 3 = 0.466 +- 0.332 (in-sample avg dev_std = 0.378)
NEC for r=1.0 class 4 = 0.352 +- 0.332 (in-sample avg dev_std = 0.378)
NEC for r=1.0 class 5 = 0.453 +- 0.332 (in-sample avg dev_std = 0.378)
NEC for r=1.0 class 6 = 0.519 +- 0.332 (in-sample avg dev_std = 0.378)
NEC for r=1.0 class 7 = 0.389 +- 0.332 (in-sample avg dev_std = 0.378)
NEC for r=1.0 class 8 = 0.507 +- 0.332 (in-sample avg dev_std = 0.378)
NEC for r=1.0 class 9 = 0.52 +- 0.332 (in-sample avg dev_std = 0.378)
NEC for r=1.0 all KL = 0.451 +- 0.332 (in-sample avg dev_std = 0.378)
NEC for r=1.0 all L1 = 0.392 +- 0.274 (in-sample avg dev_std = 0.378)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 16:12:50 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:51 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:51 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:51 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 04:12:52 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 189...
[0m[1;37mINFO[0m: [1mCheckpoint 189: 
-----------------------------------
Train ACCURACY: 0.9977
Train Loss: 0.0122
ID Validation ACCURACY: 0.9020
ID Validation Loss: 0.4048
ID Test ACCURACY: 0.8964
ID Test Loss: 0.4180
OOD Validation ACCURACY: 0.8684
OOD Validation Loss: 0.5222
OOD Test ACCURACY: 0.3916
OOD Test Loss: 6.8162

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 97...
[0m[1;37mINFO[0m: [1mCheckpoint 97: 
-----------------------------------
Train ACCURACY: 0.9677
Train Loss: 0.0990
ID Validation ACCURACY: 0.8980
ID Validation Loss: 0.3369
ID Test ACCURACY: 0.8956
ID Test Loss: 0.3387
OOD Validation ACCURACY: 0.8854
OOD Validation Loss: 0.3793
OOD Test ACCURACY: 0.7431
OOD Test Loss: 1.0135

[0m[1;37mINFO[0m: [1mChartInfo 0.8964 0.3916 0.8956 0.7431 0.8980 0.8854[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.087
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.1
SUFF++ for r=0.3 class 0 = 0.489 +- 0.174 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.3 class 1 = 0.46 +- 0.174 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.3 class 2 = 0.472 +- 0.174 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.3 class 3 = 0.448 +- 0.174 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.3 class 4 = 0.459 +- 0.174 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.3 class 5 = 0.464 +- 0.174 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.3 class 6 = 0.47 +- 0.174 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.3 class 7 = 0.449 +- 0.174 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.3 class 8 = 0.463 +- 0.174 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.3 class 9 = 0.45 +- 0.174 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.3 all KL = 0.537 +- 0.174 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.3 all L1 = 0.462 +- 0.105 (in-sample avg dev_std = 0.452)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.216
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.152
SUFF++ for r=0.6 class 0 = 0.312 +- 0.216 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 class 1 = 0.335 +- 0.216 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 class 2 = 0.352 +- 0.216 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 class 3 = 0.355 +- 0.216 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 class 4 = 0.391 +- 0.216 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 class 5 = 0.336 +- 0.216 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 class 6 = 0.378 +- 0.216 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 class 7 = 0.335 +- 0.216 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 class 8 = 0.415 +- 0.216 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 class 9 = 0.381 +- 0.216 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 all KL = 0.273 +- 0.216 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 all L1 = 0.358 +- 0.140 (in-sample avg dev_std = 0.456)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.816
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.757
SUFF++ for r=0.9 class 0 = 0.939 +- 0.255 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 class 1 = 0.956 +- 0.255 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 class 2 = 0.764 +- 0.255 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 class 3 = 0.729 +- 0.255 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 class 4 = 0.817 +- 0.255 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 class 5 = 0.683 +- 0.255 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 class 6 = 0.8 +- 0.255 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 class 7 = 0.812 +- 0.255 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 class 8 = 0.852 +- 0.255 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 class 9 = 0.778 +- 0.255 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 all KL = 0.815 +- 0.255 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.9 all L1 = 0.816 +- 0.215 (in-sample avg dev_std = 0.281)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.095
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.101
SUFF++ for r=0.3 class 0 = 0.455 +- 0.171 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.3 class 1 = 0.462 +- 0.171 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.3 class 2 = 0.465 +- 0.171 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.3 class 3 = 0.457 +- 0.171 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.3 class 4 = 0.436 +- 0.171 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.3 class 5 = 0.45 +- 0.171 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.3 class 6 = 0.438 +- 0.171 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.3 class 7 = 0.446 +- 0.171 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.3 class 8 = 0.433 +- 0.171 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.3 class 9 = 0.473 +- 0.171 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.3 all KL = 0.515 +- 0.171 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.3 all L1 = 0.452 +- 0.097 (in-sample avg dev_std = 0.471)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.195
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.148
SUFF++ for r=0.6 class 0 = 0.397 +- 0.240 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 class 1 = 0.386 +- 0.240 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 class 2 = 0.388 +- 0.240 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 class 3 = 0.369 +- 0.240 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 class 4 = 0.435 +- 0.240 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 class 5 = 0.385 +- 0.240 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 class 6 = 0.424 +- 0.240 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 class 7 = 0.382 +- 0.240 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 class 8 = 0.45 +- 0.240 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 class 9 = 0.395 +- 0.240 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 all KL = 0.32 +- 0.240 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 all L1 = 0.401 +- 0.170 (in-sample avg dev_std = 0.429)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.785
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.731
SUFF++ for r=0.9 class 0 = 0.891 +- 0.253 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 1 = 0.959 +- 0.253 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 2 = 0.712 +- 0.253 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 3 = 0.736 +- 0.253 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 4 = 0.787 +- 0.253 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 5 = 0.73 +- 0.253 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 6 = 0.751 +- 0.253 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 7 = 0.834 +- 0.253 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 8 = 0.813 +- 0.253 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 9 = 0.775 +- 0.253 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 all KL = 0.809 +- 0.253 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 all L1 = 0.802 +- 0.219 (in-sample avg dev_std = 0.285)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.119
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.115
SUFF++ for r=0.3 class 0 = 0.492 +- 0.173 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 class 1 = 0.421 +- 0.173 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 class 2 = 0.484 +- 0.173 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 class 3 = 0.474 +- 0.173 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 class 4 = 0.468 +- 0.173 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 class 5 = 0.465 +- 0.173 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 class 6 = 0.446 +- 0.173 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 class 7 = 0.468 +- 0.173 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 class 8 = 0.444 +- 0.173 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 class 9 = 0.425 +- 0.173 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 all KL = 0.485 +- 0.173 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 all L1 = 0.459 +- 0.109 (in-sample avg dev_std = 0.462)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.186
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.174
SUFF++ for r=0.6 class 0 = 0.432 +- 0.249 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 class 1 = 0.452 +- 0.249 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 class 2 = 0.418 +- 0.249 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 class 3 = 0.439 +- 0.249 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 class 4 = 0.415 +- 0.249 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 class 5 = 0.432 +- 0.249 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 class 6 = 0.401 +- 0.249 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 class 7 = 0.427 +- 0.249 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 class 8 = 0.397 +- 0.249 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 class 9 = 0.372 +- 0.249 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 all KL = 0.364 +- 0.249 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 all L1 = 0.419 +- 0.176 (in-sample avg dev_std = 0.443)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.381
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.347
SUFF++ for r=0.9 class 0 = 0.701 +- 0.272 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.9 class 1 = 0.805 +- 0.272 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.9 class 2 = 0.751 +- 0.272 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.9 class 3 = 0.622 +- 0.272 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.9 class 4 = 0.696 +- 0.272 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.9 class 5 = 0.732 +- 0.272 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.9 class 6 = 0.679 +- 0.272 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.9 class 7 = 0.718 +- 0.272 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.9 class 8 = 0.651 +- 0.272 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.9 class 9 = 0.674 +- 0.272 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.9 all KL = 0.72 +- 0.272 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.9 all L1 = 0.704 +- 0.223 (in-sample avg dev_std = 0.385)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.087
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.105
NEC for r=0.3 class 0 = 0.41 +- 0.149 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 1 = 0.421 +- 0.149 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 2 = 0.406 +- 0.149 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 3 = 0.427 +- 0.149 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 4 = 0.404 +- 0.149 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 5 = 0.384 +- 0.149 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 6 = 0.41 +- 0.149 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 7 = 0.402 +- 0.149 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 8 = 0.415 +- 0.149 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 9 = 0.429 +- 0.149 (in-sample avg dev_std = 0.232)
NEC for r=0.3 all KL = 0.26 +- 0.149 (in-sample avg dev_std = 0.232)
NEC for r=0.3 all L1 = 0.411 +- 0.122 (in-sample avg dev_std = 0.232)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.216
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.177
NEC for r=0.6 class 0 = 0.592 +- 0.228 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 1 = 0.472 +- 0.228 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 2 = 0.536 +- 0.228 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 3 = 0.512 +- 0.228 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 4 = 0.461 +- 0.228 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 5 = 0.539 +- 0.228 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 6 = 0.532 +- 0.228 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 7 = 0.538 +- 0.228 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 8 = 0.493 +- 0.228 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 9 = 0.523 +- 0.228 (in-sample avg dev_std = 0.351)
NEC for r=0.6 all KL = 0.523 +- 0.228 (in-sample avg dev_std = 0.351)
NEC for r=0.6 all L1 = 0.519 +- 0.168 (in-sample avg dev_std = 0.351)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.816
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.639
NEC for r=0.9 class 0 = 0.287 +- 0.339 (in-sample avg dev_std = 0.452)
NEC for r=0.9 class 1 = 0.117 +- 0.339 (in-sample avg dev_std = 0.452)
NEC for r=0.9 class 2 = 0.396 +- 0.339 (in-sample avg dev_std = 0.452)
NEC for r=0.9 class 3 = 0.488 +- 0.339 (in-sample avg dev_std = 0.452)
NEC for r=0.9 class 4 = 0.404 +- 0.339 (in-sample avg dev_std = 0.452)
NEC for r=0.9 class 5 = 0.588 +- 0.339 (in-sample avg dev_std = 0.452)
NEC for r=0.9 class 6 = 0.46 +- 0.339 (in-sample avg dev_std = 0.452)
NEC for r=0.9 class 7 = 0.379 +- 0.339 (in-sample avg dev_std = 0.452)
NEC for r=0.9 class 8 = 0.322 +- 0.339 (in-sample avg dev_std = 0.452)
NEC for r=0.9 class 9 = 0.418 +- 0.339 (in-sample avg dev_std = 0.452)
NEC for r=0.9 all KL = 0.536 +- 0.339 (in-sample avg dev_std = 0.452)
NEC for r=0.9 all L1 = 0.38 +- 0.271 (in-sample avg dev_std = 0.452)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.952
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.849
NEC for r=1.0 class 0 = 0.074 +- 0.365 (in-sample avg dev_std = 0.411)
NEC for r=1.0 class 1 = 0.018 +- 0.365 (in-sample avg dev_std = 0.411)
NEC for r=1.0 class 2 = 0.258 +- 0.365 (in-sample avg dev_std = 0.411)
NEC for r=1.0 class 3 = 0.275 +- 0.365 (in-sample avg dev_std = 0.411)
NEC for r=1.0 class 4 = 0.204 +- 0.365 (in-sample avg dev_std = 0.411)
NEC for r=1.0 class 5 = 0.38 +- 0.365 (in-sample avg dev_std = 0.411)
NEC for r=1.0 class 6 = 0.281 +- 0.365 (in-sample avg dev_std = 0.411)
NEC for r=1.0 class 7 = 0.2 +- 0.365 (in-sample avg dev_std = 0.411)
NEC for r=1.0 class 8 = 0.161 +- 0.365 (in-sample avg dev_std = 0.411)
NEC for r=1.0 class 9 = 0.276 +- 0.365 (in-sample avg dev_std = 0.411)
NEC for r=1.0 all KL = 0.375 +- 0.365 (in-sample avg dev_std = 0.411)
NEC for r=1.0 all L1 = 0.208 +- 0.240 (in-sample avg dev_std = 0.411)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.095
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.111
NEC for r=0.3 class 0 = 0.422 +- 0.153 (in-sample avg dev_std = 0.231)
NEC for r=0.3 class 1 = 0.403 +- 0.153 (in-sample avg dev_std = 0.231)
NEC for r=0.3 class 2 = 0.419 +- 0.153 (in-sample avg dev_std = 0.231)
NEC for r=0.3 class 3 = 0.409 +- 0.153 (in-sample avg dev_std = 0.231)
NEC for r=0.3 class 4 = 0.419 +- 0.153 (in-sample avg dev_std = 0.231)
NEC for r=0.3 class 5 = 0.405 +- 0.153 (in-sample avg dev_std = 0.231)
NEC for r=0.3 class 6 = 0.431 +- 0.153 (in-sample avg dev_std = 0.231)
NEC for r=0.3 class 7 = 0.41 +- 0.153 (in-sample avg dev_std = 0.231)
NEC for r=0.3 class 8 = 0.44 +- 0.153 (in-sample avg dev_std = 0.231)
NEC for r=0.3 class 9 = 0.415 +- 0.153 (in-sample avg dev_std = 0.231)
NEC for r=0.3 all KL = 0.265 +- 0.153 (in-sample avg dev_std = 0.231)
NEC for r=0.3 all L1 = 0.417 +- 0.123 (in-sample avg dev_std = 0.231)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.195
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.162
NEC for r=0.6 class 0 = 0.533 +- 0.227 (in-sample avg dev_std = 0.355)
NEC for r=0.6 class 1 = 0.412 +- 0.227 (in-sample avg dev_std = 0.355)
NEC for r=0.6 class 2 = 0.561 +- 0.227 (in-sample avg dev_std = 0.355)
NEC for r=0.6 class 3 = 0.504 +- 0.227 (in-sample avg dev_std = 0.355)
NEC for r=0.6 class 4 = 0.484 +- 0.227 (in-sample avg dev_std = 0.355)
NEC for r=0.6 class 5 = 0.519 +- 0.227 (in-sample avg dev_std = 0.355)
NEC for r=0.6 class 6 = 0.507 +- 0.227 (in-sample avg dev_std = 0.355)
NEC for r=0.6 class 7 = 0.523 +- 0.227 (in-sample avg dev_std = 0.355)
NEC for r=0.6 class 8 = 0.461 +- 0.227 (in-sample avg dev_std = 0.355)
NEC for r=0.6 class 9 = 0.536 +- 0.227 (in-sample avg dev_std = 0.355)
NEC for r=0.6 all KL = 0.511 +- 0.227 (in-sample avg dev_std = 0.355)
NEC for r=0.6 all L1 = 0.503 +- 0.175 (in-sample avg dev_std = 0.355)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.785
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.574
NEC for r=0.9 class 0 = 0.445 +- 0.341 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 1 = 0.119 +- 0.341 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 2 = 0.437 +- 0.341 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 3 = 0.559 +- 0.341 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 4 = 0.434 +- 0.341 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 5 = 0.565 +- 0.341 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 6 = 0.506 +- 0.341 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 7 = 0.349 +- 0.341 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 8 = 0.321 +- 0.341 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 9 = 0.493 +- 0.341 (in-sample avg dev_std = 0.450)
NEC for r=0.9 all KL = 0.57 +- 0.341 (in-sample avg dev_std = 0.450)
NEC for r=0.9 all L1 = 0.418 +- 0.275 (in-sample avg dev_std = 0.450)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.93
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.785
NEC for r=1.0 class 0 = 0.165 +- 0.372 (in-sample avg dev_std = 0.428)
NEC for r=1.0 class 1 = 0.02 +- 0.372 (in-sample avg dev_std = 0.428)
NEC for r=1.0 class 2 = 0.311 +- 0.372 (in-sample avg dev_std = 0.428)
NEC for r=1.0 class 3 = 0.393 +- 0.372 (in-sample avg dev_std = 0.428)
NEC for r=1.0 class 4 = 0.313 +- 0.372 (in-sample avg dev_std = 0.428)
NEC for r=1.0 class 5 = 0.348 +- 0.372 (in-sample avg dev_std = 0.428)
NEC for r=1.0 class 6 = 0.357 +- 0.372 (in-sample avg dev_std = 0.428)
NEC for r=1.0 class 7 = 0.196 +- 0.372 (in-sample avg dev_std = 0.428)
NEC for r=1.0 class 8 = 0.262 +- 0.372 (in-sample avg dev_std = 0.428)
NEC for r=1.0 class 9 = 0.366 +- 0.372 (in-sample avg dev_std = 0.428)
NEC for r=1.0 all KL = 0.424 +- 0.372 (in-sample avg dev_std = 0.428)
NEC for r=1.0 all L1 = 0.27 +- 0.271 (in-sample avg dev_std = 0.428)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.119
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.123
NEC for r=0.3 class 0 = 0.37 +- 0.148 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 1 = 0.409 +- 0.148 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 2 = 0.381 +- 0.148 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 3 = 0.4 +- 0.148 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 4 = 0.408 +- 0.148 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 5 = 0.392 +- 0.148 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 6 = 0.412 +- 0.148 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 7 = 0.367 +- 0.148 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 8 = 0.415 +- 0.148 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 9 = 0.437 +- 0.148 (in-sample avg dev_std = 0.220)
NEC for r=0.3 all KL = 0.248 +- 0.148 (in-sample avg dev_std = 0.220)
NEC for r=0.3 all L1 = 0.399 +- 0.124 (in-sample avg dev_std = 0.220)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.186
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.178
NEC for r=0.6 class 0 = 0.508 +- 0.242 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 1 = 0.429 +- 0.242 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 2 = 0.483 +- 0.242 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 3 = 0.513 +- 0.242 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 4 = 0.469 +- 0.242 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 5 = 0.491 +- 0.242 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 6 = 0.478 +- 0.242 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 7 = 0.498 +- 0.242 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 8 = 0.462 +- 0.242 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 9 = 0.504 +- 0.242 (in-sample avg dev_std = 0.359)
NEC for r=0.6 all KL = 0.468 +- 0.242 (in-sample avg dev_std = 0.359)
NEC for r=0.6 all L1 = 0.483 +- 0.179 (in-sample avg dev_std = 0.359)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.381
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.277
NEC for r=0.9 class 0 = 0.526 +- 0.312 (in-sample avg dev_std = 0.431)
NEC for r=0.9 class 1 = 0.384 +- 0.312 (in-sample avg dev_std = 0.431)
NEC for r=0.9 class 2 = 0.382 +- 0.312 (in-sample avg dev_std = 0.431)
NEC for r=0.9 class 3 = 0.515 +- 0.312 (in-sample avg dev_std = 0.431)
NEC for r=0.9 class 4 = 0.44 +- 0.312 (in-sample avg dev_std = 0.431)
NEC for r=0.9 class 5 = 0.498 +- 0.312 (in-sample avg dev_std = 0.431)
NEC for r=0.9 class 6 = 0.555 +- 0.312 (in-sample avg dev_std = 0.431)
NEC for r=0.9 class 7 = 0.485 +- 0.312 (in-sample avg dev_std = 0.431)
NEC for r=0.9 class 8 = 0.535 +- 0.312 (in-sample avg dev_std = 0.431)
NEC for r=0.9 class 9 = 0.569 +- 0.312 (in-sample avg dev_std = 0.431)
NEC for r=0.9 all KL = 0.581 +- 0.312 (in-sample avg dev_std = 0.431)
NEC for r=0.9 all L1 = 0.487 +- 0.253 (in-sample avg dev_std = 0.431)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.394
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.341
NEC for r=1.0 class 0 = 0.614 +- 0.345 (in-sample avg dev_std = 0.418)
NEC for r=1.0 class 1 = 0.279 +- 0.345 (in-sample avg dev_std = 0.418)
NEC for r=1.0 class 2 = 0.336 +- 0.345 (in-sample avg dev_std = 0.418)
NEC for r=1.0 class 3 = 0.476 +- 0.345 (in-sample avg dev_std = 0.418)
NEC for r=1.0 class 4 = 0.544 +- 0.345 (in-sample avg dev_std = 0.418)
NEC for r=1.0 class 5 = 0.474 +- 0.345 (in-sample avg dev_std = 0.418)
NEC for r=1.0 class 6 = 0.589 +- 0.345 (in-sample avg dev_std = 0.418)
NEC for r=1.0 class 7 = 0.425 +- 0.345 (in-sample avg dev_std = 0.418)
NEC for r=1.0 class 8 = 0.538 +- 0.345 (in-sample avg dev_std = 0.418)
NEC for r=1.0 class 9 = 0.573 +- 0.345 (in-sample avg dev_std = 0.418)
NEC for r=1.0 all KL = 0.593 +- 0.345 (in-sample avg dev_std = 0.418)
NEC for r=1.0 all L1 = 0.481 +- 0.286 (in-sample avg dev_std = 0.418)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 16:34:38 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:38 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:38 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 04:34:39 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 181...
[0m[1;37mINFO[0m: [1mCheckpoint 181: 
-----------------------------------
Train ACCURACY: 0.9970
Train Loss: 0.0158
ID Validation ACCURACY: 0.9020
ID Validation Loss: 0.3897
ID Test ACCURACY: 0.8953
ID Test Loss: 0.4044
OOD Validation ACCURACY: 0.8734
OOD Validation Loss: 0.5272
OOD Test ACCURACY: 0.6619
OOD Test Loss: 1.9791

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 118...
[0m[1;37mINFO[0m: [1mCheckpoint 118: 
-----------------------------------
Train ACCURACY: 0.9799
Train Loss: 0.0665
ID Validation ACCURACY: 0.8979
ID Validation Loss: 0.3461
ID Test ACCURACY: 0.8966
ID Test Loss: 0.3492
OOD Validation ACCURACY: 0.8897
OOD Validation Loss: 0.3708
OOD Test ACCURACY: 0.7326
OOD Test Loss: 1.0225

[0m[1;37mINFO[0m: [1mChartInfo 0.8953 0.6619 0.8966 0.7326 0.8979 0.8897[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.095
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.093
SUFF++ for r=0.3 class 0 = 0.655 +- 0.106 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.3 class 1 = 0.655 +- 0.106 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.3 class 2 = 0.636 +- 0.106 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.3 class 3 = 0.617 +- 0.106 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.3 class 4 = 0.618 +- 0.106 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.3 class 5 = 0.647 +- 0.106 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.3 class 6 = 0.622 +- 0.106 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.3 class 7 = 0.631 +- 0.106 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.3 class 8 = 0.641 +- 0.106 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.3 class 9 = 0.63 +- 0.106 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.3 all KL = 0.814 +- 0.106 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.3 all L1 = 0.635 +- 0.099 (in-sample avg dev_std = 0.238)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.192
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.14
SUFF++ for r=0.6 class 0 = 0.337 +- 0.234 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.6 class 1 = 0.384 +- 0.234 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.6 class 2 = 0.361 +- 0.234 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.6 class 3 = 0.374 +- 0.234 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.6 class 4 = 0.426 +- 0.234 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.6 class 5 = 0.392 +- 0.234 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.6 class 6 = 0.419 +- 0.234 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.6 class 7 = 0.355 +- 0.234 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.6 class 8 = 0.411 +- 0.234 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.6 class 9 = 0.36 +- 0.234 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.6 all KL = 0.306 +- 0.234 (in-sample avg dev_std = 0.398)
SUFF++ for r=0.6 all L1 = 0.381 +- 0.148 (in-sample avg dev_std = 0.398)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.817
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.759
SUFF++ for r=0.9 class 0 = 0.964 +- 0.257 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 class 1 = 0.976 +- 0.257 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 class 2 = 0.761 +- 0.257 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 class 3 = 0.765 +- 0.257 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 class 4 = 0.848 +- 0.257 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 class 5 = 0.716 +- 0.257 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 class 6 = 0.764 +- 0.257 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 class 7 = 0.801 +- 0.257 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 class 8 = 0.858 +- 0.257 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 class 9 = 0.698 +- 0.257 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 all KL = 0.819 +- 0.257 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 all L1 = 0.819 +- 0.216 (in-sample avg dev_std = 0.279)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.099
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.1
SUFF++ for r=0.3 class 0 = 0.653 +- 0.112 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.3 class 1 = 0.643 +- 0.112 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.3 class 2 = 0.644 +- 0.112 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.3 class 3 = 0.645 +- 0.112 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.3 class 4 = 0.635 +- 0.112 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.3 class 5 = 0.644 +- 0.112 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.3 class 6 = 0.615 +- 0.112 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.3 class 7 = 0.628 +- 0.112 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.3 class 8 = 0.608 +- 0.112 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.3 class 9 = 0.639 +- 0.112 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.3 all KL = 0.813 +- 0.112 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.3 all L1 = 0.635 +- 0.105 (in-sample avg dev_std = 0.237)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.168
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.131
SUFF++ for r=0.6 class 0 = 0.36 +- 0.227 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.6 class 1 = 0.382 +- 0.227 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.6 class 2 = 0.396 +- 0.227 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.6 class 3 = 0.404 +- 0.227 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.6 class 4 = 0.385 +- 0.227 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.6 class 5 = 0.384 +- 0.227 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.6 class 6 = 0.412 +- 0.227 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.6 class 7 = 0.379 +- 0.227 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.6 class 8 = 0.42 +- 0.227 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.6 class 9 = 0.394 +- 0.227 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.6 all KL = 0.347 +- 0.227 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.6 all L1 = 0.392 +- 0.139 (in-sample avg dev_std = 0.367)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.796
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.752
SUFF++ for r=0.9 class 0 = 0.924 +- 0.251 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.9 class 1 = 0.966 +- 0.251 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.9 class 2 = 0.694 +- 0.251 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.9 class 3 = 0.794 +- 0.251 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.9 class 4 = 0.786 +- 0.251 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.9 class 5 = 0.723 +- 0.251 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.9 class 6 = 0.773 +- 0.251 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.9 class 7 = 0.84 +- 0.251 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.9 class 8 = 0.773 +- 0.251 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.9 class 9 = 0.769 +- 0.251 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.9 all KL = 0.81 +- 0.251 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.9 all L1 = 0.807 +- 0.214 (in-sample avg dev_std = 0.273)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.108
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.106
SUFF++ for r=0.3 class 0 = 0.621 +- 0.120 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 class 1 = 0.605 +- 0.120 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 class 2 = 0.625 +- 0.120 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 class 3 = 0.621 +- 0.120 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 class 4 = 0.625 +- 0.120 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 class 5 = 0.605 +- 0.120 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 class 6 = 0.608 +- 0.120 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 class 7 = 0.605 +- 0.120 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 class 8 = 0.617 +- 0.120 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 class 9 = 0.626 +- 0.120 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 all KL = 0.797 +- 0.120 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 all L1 = 0.616 +- 0.101 (in-sample avg dev_std = 0.252)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.154
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.136
SUFF++ for r=0.6 class 0 = 0.363 +- 0.228 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 class 1 = 0.435 +- 0.228 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 class 2 = 0.381 +- 0.228 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 class 3 = 0.379 +- 0.228 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 class 4 = 0.42 +- 0.228 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 class 5 = 0.399 +- 0.228 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 class 6 = 0.427 +- 0.228 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 class 7 = 0.381 +- 0.228 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 class 8 = 0.377 +- 0.228 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 class 9 = 0.44 +- 0.228 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 all KL = 0.39 +- 0.228 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 all L1 = 0.4 +- 0.145 (in-sample avg dev_std = 0.348)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.626
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.567
SUFF++ for r=0.9 class 0 = 0.754 +- 0.248 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 1 = 0.951 +- 0.248 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 2 = 0.693 +- 0.248 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 3 = 0.692 +- 0.248 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 4 = 0.725 +- 0.248 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 5 = 0.66 +- 0.248 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 6 = 0.752 +- 0.248 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 7 = 0.815 +- 0.248 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 8 = 0.714 +- 0.248 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 9 = 0.669 +- 0.248 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 all KL = 0.771 +- 0.248 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 all L1 = 0.746 +- 0.222 (in-sample avg dev_std = 0.303)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.095
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.095
NEC for r=0.3 class 0 = 0.279 +- 0.104 (in-sample avg dev_std = 0.144)
NEC for r=0.3 class 1 = 0.312 +- 0.104 (in-sample avg dev_std = 0.144)
NEC for r=0.3 class 2 = 0.303 +- 0.104 (in-sample avg dev_std = 0.144)
NEC for r=0.3 class 3 = 0.308 +- 0.104 (in-sample avg dev_std = 0.144)
NEC for r=0.3 class 4 = 0.303 +- 0.104 (in-sample avg dev_std = 0.144)
NEC for r=0.3 class 5 = 0.281 +- 0.104 (in-sample avg dev_std = 0.144)
NEC for r=0.3 class 6 = 0.319 +- 0.104 (in-sample avg dev_std = 0.144)
NEC for r=0.3 class 7 = 0.305 +- 0.104 (in-sample avg dev_std = 0.144)
NEC for r=0.3 class 8 = 0.304 +- 0.104 (in-sample avg dev_std = 0.144)
NEC for r=0.3 class 9 = 0.303 +- 0.104 (in-sample avg dev_std = 0.144)
NEC for r=0.3 all KL = 0.139 +- 0.104 (in-sample avg dev_std = 0.144)
NEC for r=0.3 all L1 = 0.302 +- 0.086 (in-sample avg dev_std = 0.144)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.192
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.138
NEC for r=0.6 class 0 = 0.553 +- 0.227 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 1 = 0.537 +- 0.227 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 2 = 0.522 +- 0.227 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 3 = 0.518 +- 0.227 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 4 = 0.48 +- 0.227 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 5 = 0.496 +- 0.227 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 6 = 0.492 +- 0.227 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 7 = 0.537 +- 0.227 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 8 = 0.493 +- 0.227 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 9 = 0.527 +- 0.227 (in-sample avg dev_std = 0.360)
NEC for r=0.6 all KL = 0.495 +- 0.227 (in-sample avg dev_std = 0.360)
NEC for r=0.6 all L1 = 0.517 +- 0.163 (in-sample avg dev_std = 0.360)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.817
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.608
NEC for r=0.9 class 0 = 0.293 +- 0.337 (in-sample avg dev_std = 0.472)
NEC for r=0.9 class 1 = 0.163 +- 0.337 (in-sample avg dev_std = 0.472)
NEC for r=0.9 class 2 = 0.539 +- 0.337 (in-sample avg dev_std = 0.472)
NEC for r=0.9 class 3 = 0.515 +- 0.337 (in-sample avg dev_std = 0.472)
NEC for r=0.9 class 4 = 0.301 +- 0.337 (in-sample avg dev_std = 0.472)
NEC for r=0.9 class 5 = 0.552 +- 0.337 (in-sample avg dev_std = 0.472)
NEC for r=0.9 class 6 = 0.445 +- 0.337 (in-sample avg dev_std = 0.472)
NEC for r=0.9 class 7 = 0.448 +- 0.337 (in-sample avg dev_std = 0.472)
NEC for r=0.9 class 8 = 0.333 +- 0.337 (in-sample avg dev_std = 0.472)
NEC for r=0.9 class 9 = 0.532 +- 0.337 (in-sample avg dev_std = 0.472)
NEC for r=0.9 all KL = 0.591 +- 0.337 (in-sample avg dev_std = 0.472)
NEC for r=0.9 all L1 = 0.408 +- 0.270 (in-sample avg dev_std = 0.472)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.951
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.823
NEC for r=1.0 class 0 = 0.088 +- 0.369 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 1 = 0.008 +- 0.369 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 2 = 0.332 +- 0.369 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 3 = 0.269 +- 0.369 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 4 = 0.168 +- 0.369 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 5 = 0.366 +- 0.369 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 6 = 0.327 +- 0.369 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 7 = 0.209 +- 0.369 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 8 = 0.179 +- 0.369 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 9 = 0.449 +- 0.369 (in-sample avg dev_std = 0.414)
NEC for r=1.0 all KL = 0.4 +- 0.369 (in-sample avg dev_std = 0.414)
NEC for r=1.0 all L1 = 0.234 +- 0.253 (in-sample avg dev_std = 0.414)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.099
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.105
NEC for r=0.3 class 0 = 0.284 +- 0.106 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 1 = 0.332 +- 0.106 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 2 = 0.308 +- 0.106 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 3 = 0.297 +- 0.106 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 4 = 0.297 +- 0.106 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 5 = 0.279 +- 0.106 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 6 = 0.332 +- 0.106 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 7 = 0.313 +- 0.106 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 8 = 0.313 +- 0.106 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 9 = 0.317 +- 0.106 (in-sample avg dev_std = 0.142)
NEC for r=0.3 all KL = 0.145 +- 0.106 (in-sample avg dev_std = 0.142)
NEC for r=0.3 all L1 = 0.308 +- 0.095 (in-sample avg dev_std = 0.142)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.168
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.121
NEC for r=0.6 class 0 = 0.547 +- 0.213 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 1 = 0.57 +- 0.213 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 2 = 0.485 +- 0.213 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 3 = 0.489 +- 0.213 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 4 = 0.51 +- 0.213 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 5 = 0.518 +- 0.213 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 6 = 0.498 +- 0.213 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 7 = 0.529 +- 0.213 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 8 = 0.491 +- 0.213 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 9 = 0.539 +- 0.213 (in-sample avg dev_std = 0.348)
NEC for r=0.6 all KL = 0.484 +- 0.213 (in-sample avg dev_std = 0.348)
NEC for r=0.6 all L1 = 0.518 +- 0.148 (in-sample avg dev_std = 0.348)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.796
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.6
NEC for r=0.9 class 0 = 0.362 +- 0.331 (in-sample avg dev_std = 0.469)
NEC for r=0.9 class 1 = 0.124 +- 0.331 (in-sample avg dev_std = 0.469)
NEC for r=0.9 class 2 = 0.507 +- 0.331 (in-sample avg dev_std = 0.469)
NEC for r=0.9 class 3 = 0.54 +- 0.331 (in-sample avg dev_std = 0.469)
NEC for r=0.9 class 4 = 0.388 +- 0.331 (in-sample avg dev_std = 0.469)
NEC for r=0.9 class 5 = 0.556 +- 0.331 (in-sample avg dev_std = 0.469)
NEC for r=0.9 class 6 = 0.486 +- 0.331 (in-sample avg dev_std = 0.469)
NEC for r=0.9 class 7 = 0.38 +- 0.331 (in-sample avg dev_std = 0.469)
NEC for r=0.9 class 8 = 0.468 +- 0.331 (in-sample avg dev_std = 0.469)
NEC for r=0.9 class 9 = 0.561 +- 0.331 (in-sample avg dev_std = 0.469)
NEC for r=0.9 all KL = 0.611 +- 0.331 (in-sample avg dev_std = 0.469)
NEC for r=0.9 all L1 = 0.432 +- 0.270 (in-sample avg dev_std = 0.469)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.921
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.79
NEC for r=1.0 class 0 = 0.112 +- 0.363 (in-sample avg dev_std = 0.417)
NEC for r=1.0 class 1 = 0.019 +- 0.363 (in-sample avg dev_std = 0.417)
NEC for r=1.0 class 2 = 0.38 +- 0.363 (in-sample avg dev_std = 0.417)
NEC for r=1.0 class 3 = 0.354 +- 0.363 (in-sample avg dev_std = 0.417)
NEC for r=1.0 class 4 = 0.256 +- 0.363 (in-sample avg dev_std = 0.417)
NEC for r=1.0 class 5 = 0.298 +- 0.363 (in-sample avg dev_std = 0.417)
NEC for r=1.0 class 6 = 0.321 +- 0.363 (in-sample avg dev_std = 0.417)
NEC for r=1.0 class 7 = 0.196 +- 0.363 (in-sample avg dev_std = 0.417)
NEC for r=1.0 class 8 = 0.292 +- 0.363 (in-sample avg dev_std = 0.417)
NEC for r=1.0 class 9 = 0.438 +- 0.363 (in-sample avg dev_std = 0.417)
NEC for r=1.0 all KL = 0.421 +- 0.363 (in-sample avg dev_std = 0.417)
NEC for r=1.0 all L1 = 0.264 +- 0.265 (in-sample avg dev_std = 0.417)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.108
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.1
NEC for r=0.3 class 0 = 0.307 +- 0.118 (in-sample avg dev_std = 0.149)
NEC for r=0.3 class 1 = 0.315 +- 0.118 (in-sample avg dev_std = 0.149)
NEC for r=0.3 class 2 = 0.298 +- 0.118 (in-sample avg dev_std = 0.149)
NEC for r=0.3 class 3 = 0.307 +- 0.118 (in-sample avg dev_std = 0.149)
NEC for r=0.3 class 4 = 0.344 +- 0.118 (in-sample avg dev_std = 0.149)
NEC for r=0.3 class 5 = 0.308 +- 0.118 (in-sample avg dev_std = 0.149)
NEC for r=0.3 class 6 = 0.326 +- 0.118 (in-sample avg dev_std = 0.149)
NEC for r=0.3 class 7 = 0.314 +- 0.118 (in-sample avg dev_std = 0.149)
NEC for r=0.3 class 8 = 0.327 +- 0.118 (in-sample avg dev_std = 0.149)
NEC for r=0.3 class 9 = 0.322 +- 0.118 (in-sample avg dev_std = 0.149)
NEC for r=0.3 all KL = 0.149 +- 0.118 (in-sample avg dev_std = 0.149)
NEC for r=0.3 all L1 = 0.316 +- 0.101 (in-sample avg dev_std = 0.149)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.154
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.129
NEC for r=0.6 class 0 = 0.549 +- 0.217 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 1 = 0.506 +- 0.217 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 2 = 0.544 +- 0.217 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 3 = 0.524 +- 0.217 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 4 = 0.532 +- 0.217 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 5 = 0.542 +- 0.217 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 6 = 0.536 +- 0.217 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 7 = 0.557 +- 0.217 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 8 = 0.572 +- 0.217 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 9 = 0.518 +- 0.217 (in-sample avg dev_std = 0.353)
NEC for r=0.6 all KL = 0.509 +- 0.217 (in-sample avg dev_std = 0.353)
NEC for r=0.6 all L1 = 0.538 +- 0.144 (in-sample avg dev_std = 0.353)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.626
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.424
NEC for r=0.9 class 0 = 0.639 +- 0.311 (in-sample avg dev_std = 0.437)
NEC for r=0.9 class 1 = 0.186 +- 0.311 (in-sample avg dev_std = 0.437)
NEC for r=0.9 class 2 = 0.48 +- 0.311 (in-sample avg dev_std = 0.437)
NEC for r=0.9 class 3 = 0.614 +- 0.311 (in-sample avg dev_std = 0.437)
NEC for r=0.9 class 4 = 0.412 +- 0.311 (in-sample avg dev_std = 0.437)
NEC for r=0.9 class 5 = 0.587 +- 0.311 (in-sample avg dev_std = 0.437)
NEC for r=0.9 class 6 = 0.458 +- 0.311 (in-sample avg dev_std = 0.437)
NEC for r=0.9 class 7 = 0.463 +- 0.311 (in-sample avg dev_std = 0.437)
NEC for r=0.9 class 8 = 0.567 +- 0.311 (in-sample avg dev_std = 0.437)
NEC for r=0.9 class 9 = 0.621 +- 0.311 (in-sample avg dev_std = 0.437)
NEC for r=0.9 all KL = 0.625 +- 0.311 (in-sample avg dev_std = 0.437)
NEC for r=0.9 all L1 = 0.499 +- 0.256 (in-sample avg dev_std = 0.437)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.678
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.585
NEC for r=1.0 class 0 = 0.521 +- 0.355 (in-sample avg dev_std = 0.444)
NEC for r=1.0 class 1 = 0.038 +- 0.355 (in-sample avg dev_std = 0.444)
NEC for r=1.0 class 2 = 0.379 +- 0.355 (in-sample avg dev_std = 0.444)
NEC for r=1.0 class 3 = 0.472 +- 0.355 (in-sample avg dev_std = 0.444)
NEC for r=1.0 class 4 = 0.405 +- 0.355 (in-sample avg dev_std = 0.444)
NEC for r=1.0 class 5 = 0.507 +- 0.355 (in-sample avg dev_std = 0.444)
NEC for r=1.0 class 6 = 0.426 +- 0.355 (in-sample avg dev_std = 0.444)
NEC for r=1.0 class 7 = 0.337 +- 0.355 (in-sample avg dev_std = 0.444)
NEC for r=1.0 class 8 = 0.551 +- 0.355 (in-sample avg dev_std = 0.444)
NEC for r=1.0 class 9 = 0.585 +- 0.355 (in-sample avg dev_std = 0.444)
NEC for r=1.0 all KL = 0.564 +- 0.355 (in-sample avg dev_std = 0.444)
NEC for r=1.0 all L1 = 0.417 +- 0.285 (in-sample avg dev_std = 0.444)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 16:56:36 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 04:56:37 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 158...
[0m[1;37mINFO[0m: [1mCheckpoint 158: 
-----------------------------------
Train ACCURACY: 0.9950
Train Loss: 0.0231
ID Validation ACCURACY: 0.9024
ID Validation Loss: 0.3659
ID Test ACCURACY: 0.8969
ID Test Loss: 0.3748
OOD Validation ACCURACY: 0.8824
OOD Validation Loss: 0.4311
OOD Test ACCURACY: 0.7293
OOD Test Loss: 1.2294

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 136...
[0m[1;37mINFO[0m: [1mCheckpoint 136: 
-----------------------------------
Train ACCURACY: 0.9895
Train Loss: 0.0364
ID Validation ACCURACY: 0.8990
ID Validation Loss: 0.3635
ID Test ACCURACY: 0.9014
ID Test Loss: 0.3583
OOD Validation ACCURACY: 0.8921
OOD Validation Loss: 0.4134
OOD Test ACCURACY: 0.7336
OOD Test Loss: 1.4819

[0m[1;37mINFO[0m: [1mChartInfo 0.8969 0.7293 0.9014 0.7336 0.8990 0.8921[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.105
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.088
SUFF++ for r=0.3 class 0 = 0.544 +- 0.128 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.3 class 1 = 0.563 +- 0.128 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.3 class 2 = 0.548 +- 0.128 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.3 class 3 = 0.53 +- 0.128 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.3 class 4 = 0.547 +- 0.128 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.3 class 5 = 0.565 +- 0.128 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.3 class 6 = 0.538 +- 0.128 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.3 class 7 = 0.547 +- 0.128 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.3 class 8 = 0.557 +- 0.128 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.3 class 9 = 0.539 +- 0.128 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.3 all KL = 0.666 +- 0.128 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.3 all L1 = 0.548 +- 0.094 (in-sample avg dev_std = 0.360)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.18
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.136
SUFF++ for r=0.6 class 0 = 0.36 +- 0.226 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 class 1 = 0.427 +- 0.226 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 class 2 = 0.436 +- 0.226 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 class 3 = 0.409 +- 0.226 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 class 4 = 0.394 +- 0.226 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 class 5 = 0.392 +- 0.226 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 class 6 = 0.404 +- 0.226 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 class 7 = 0.398 +- 0.226 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 class 8 = 0.404 +- 0.226 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 class 9 = 0.39 +- 0.226 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 all KL = 0.404 +- 0.226 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 all L1 = 0.402 +- 0.148 (in-sample avg dev_std = 0.353)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.821
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.771
SUFF++ for r=0.9 class 0 = 0.958 +- 0.241 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 1 = 0.906 +- 0.241 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 2 = 0.77 +- 0.241 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 3 = 0.733 +- 0.241 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 4 = 0.825 +- 0.241 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 5 = 0.699 +- 0.241 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 6 = 0.79 +- 0.241 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 7 = 0.809 +- 0.241 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 8 = 0.84 +- 0.241 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 9 = 0.751 +- 0.241 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 all KL = 0.82 +- 0.241 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 all L1 = 0.811 +- 0.206 (in-sample avg dev_std = 0.276)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.102
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.101
SUFF++ for r=0.3 class 0 = 0.556 +- 0.133 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.3 class 1 = 0.539 +- 0.133 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.3 class 2 = 0.544 +- 0.133 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.3 class 3 = 0.539 +- 0.133 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.3 class 4 = 0.533 +- 0.133 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.3 class 5 = 0.536 +- 0.133 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.3 class 6 = 0.508 +- 0.133 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.3 class 7 = 0.543 +- 0.133 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.3 class 8 = 0.51 +- 0.133 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.3 class 9 = 0.543 +- 0.133 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.3 all KL = 0.646 +- 0.133 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.3 all L1 = 0.535 +- 0.089 (in-sample avg dev_std = 0.380)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.175
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.12
SUFF++ for r=0.6 class 0 = 0.429 +- 0.228 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.6 class 1 = 0.432 +- 0.228 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.6 class 2 = 0.429 +- 0.228 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.6 class 3 = 0.407 +- 0.228 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.6 class 4 = 0.408 +- 0.228 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.6 class 5 = 0.405 +- 0.228 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.6 class 6 = 0.41 +- 0.228 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.6 class 7 = 0.401 +- 0.228 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.6 class 8 = 0.411 +- 0.228 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.6 class 9 = 0.398 +- 0.228 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.6 all KL = 0.421 +- 0.228 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.6 all L1 = 0.413 +- 0.149 (in-sample avg dev_std = 0.367)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.796
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.747
SUFF++ for r=0.9 class 0 = 0.902 +- 0.235 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 1 = 0.934 +- 0.235 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 2 = 0.751 +- 0.235 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 3 = 0.763 +- 0.235 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 4 = 0.764 +- 0.235 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 5 = 0.721 +- 0.235 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 6 = 0.773 +- 0.235 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 7 = 0.811 +- 0.235 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 8 = 0.803 +- 0.235 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 9 = 0.762 +- 0.235 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 all KL = 0.812 +- 0.235 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 all L1 = 0.8 +- 0.207 (in-sample avg dev_std = 0.270)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.09
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.098
SUFF++ for r=0.3 class 0 = 0.525 +- 0.146 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.3 class 1 = 0.512 +- 0.146 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.3 class 2 = 0.531 +- 0.146 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.3 class 3 = 0.521 +- 0.146 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.3 class 4 = 0.51 +- 0.146 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.3 class 5 = 0.505 +- 0.146 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.3 class 6 = 0.529 +- 0.146 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.3 class 7 = 0.524 +- 0.146 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.3 class 8 = 0.527 +- 0.146 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.3 class 9 = 0.516 +- 0.146 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.3 all KL = 0.628 +- 0.146 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.3 all L1 = 0.52 +- 0.098 (in-sample avg dev_std = 0.411)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.174
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.129
SUFF++ for r=0.6 class 0 = 0.44 +- 0.235 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.6 class 1 = 0.383 +- 0.235 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.6 class 2 = 0.419 +- 0.235 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.6 class 3 = 0.449 +- 0.235 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.6 class 4 = 0.409 +- 0.235 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.6 class 5 = 0.401 +- 0.235 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.6 class 6 = 0.429 +- 0.235 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.6 class 7 = 0.43 +- 0.235 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.6 class 8 = 0.415 +- 0.235 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.6 class 9 = 0.385 +- 0.235 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.6 all KL = 0.391 +- 0.235 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.6 all L1 = 0.416 +- 0.154 (in-sample avg dev_std = 0.394)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.632
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.559
SUFF++ for r=0.9 class 0 = 0.689 +- 0.259 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 class 1 = 0.777 +- 0.259 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 class 2 = 0.688 +- 0.259 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 class 3 = 0.655 +- 0.259 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 class 4 = 0.754 +- 0.259 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 class 5 = 0.642 +- 0.259 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 class 6 = 0.79 +- 0.259 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 class 7 = 0.737 +- 0.259 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 class 8 = 0.648 +- 0.259 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 class 9 = 0.68 +- 0.259 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 all KL = 0.728 +- 0.259 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.9 all L1 = 0.707 +- 0.221 (in-sample avg dev_std = 0.346)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.105
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.09
NEC for r=0.3 class 0 = 0.321 +- 0.078 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 1 = 0.322 +- 0.078 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 2 = 0.322 +- 0.078 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 3 = 0.351 +- 0.078 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 4 = 0.332 +- 0.078 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 5 = 0.312 +- 0.078 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 6 = 0.337 +- 0.078 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 7 = 0.322 +- 0.078 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 8 = 0.326 +- 0.078 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 9 = 0.341 +- 0.078 (in-sample avg dev_std = 0.145)
NEC for r=0.3 all KL = 0.143 +- 0.078 (in-sample avg dev_std = 0.145)
NEC for r=0.3 all L1 = 0.329 +- 0.080 (in-sample avg dev_std = 0.145)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.18
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.147
NEC for r=0.6 class 0 = 0.536 +- 0.192 (in-sample avg dev_std = 0.322)
NEC for r=0.6 class 1 = 0.509 +- 0.192 (in-sample avg dev_std = 0.322)
NEC for r=0.6 class 2 = 0.481 +- 0.192 (in-sample avg dev_std = 0.322)
NEC for r=0.6 class 3 = 0.528 +- 0.192 (in-sample avg dev_std = 0.322)
NEC for r=0.6 class 4 = 0.517 +- 0.192 (in-sample avg dev_std = 0.322)
NEC for r=0.6 class 5 = 0.509 +- 0.192 (in-sample avg dev_std = 0.322)
NEC for r=0.6 class 6 = 0.514 +- 0.192 (in-sample avg dev_std = 0.322)
NEC for r=0.6 class 7 = 0.535 +- 0.192 (in-sample avg dev_std = 0.322)
NEC for r=0.6 class 8 = 0.503 +- 0.192 (in-sample avg dev_std = 0.322)
NEC for r=0.6 class 9 = 0.51 +- 0.192 (in-sample avg dev_std = 0.322)
NEC for r=0.6 all KL = 0.441 +- 0.192 (in-sample avg dev_std = 0.322)
NEC for r=0.6 all L1 = 0.514 +- 0.134 (in-sample avg dev_std = 0.322)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.821
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.626
NEC for r=0.9 class 0 = 0.263 +- 0.314 (in-sample avg dev_std = 0.440)
NEC for r=0.9 class 1 = 0.255 +- 0.314 (in-sample avg dev_std = 0.440)
NEC for r=0.9 class 2 = 0.442 +- 0.314 (in-sample avg dev_std = 0.440)
NEC for r=0.9 class 3 = 0.546 +- 0.314 (in-sample avg dev_std = 0.440)
NEC for r=0.9 class 4 = 0.319 +- 0.314 (in-sample avg dev_std = 0.440)
NEC for r=0.9 class 5 = 0.58 +- 0.314 (in-sample avg dev_std = 0.440)
NEC for r=0.9 class 6 = 0.487 +- 0.314 (in-sample avg dev_std = 0.440)
NEC for r=0.9 class 7 = 0.381 +- 0.314 (in-sample avg dev_std = 0.440)
NEC for r=0.9 class 8 = 0.332 +- 0.314 (in-sample avg dev_std = 0.440)
NEC for r=0.9 class 9 = 0.507 +- 0.314 (in-sample avg dev_std = 0.440)
NEC for r=0.9 all KL = 0.557 +- 0.314 (in-sample avg dev_std = 0.440)
NEC for r=0.9 all L1 = 0.407 +- 0.258 (in-sample avg dev_std = 0.440)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.96
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.843
NEC for r=1.0 class 0 = 0.108 +- 0.348 (in-sample avg dev_std = 0.398)
NEC for r=1.0 class 1 = 0.047 +- 0.348 (in-sample avg dev_std = 0.398)
NEC for r=1.0 class 2 = 0.233 +- 0.348 (in-sample avg dev_std = 0.398)
NEC for r=1.0 class 3 = 0.297 +- 0.348 (in-sample avg dev_std = 0.398)
NEC for r=1.0 class 4 = 0.171 +- 0.348 (in-sample avg dev_std = 0.398)
NEC for r=1.0 class 5 = 0.39 +- 0.348 (in-sample avg dev_std = 0.398)
NEC for r=1.0 class 6 = 0.274 +- 0.348 (in-sample avg dev_std = 0.398)
NEC for r=1.0 class 7 = 0.205 +- 0.348 (in-sample avg dev_std = 0.398)
NEC for r=1.0 class 8 = 0.201 +- 0.348 (in-sample avg dev_std = 0.398)
NEC for r=1.0 class 9 = 0.35 +- 0.348 (in-sample avg dev_std = 0.398)
NEC for r=1.0 all KL = 0.37 +- 0.348 (in-sample avg dev_std = 0.398)
NEC for r=1.0 all L1 = 0.223 +- 0.241 (in-sample avg dev_std = 0.398)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.102
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.102
NEC for r=0.3 class 0 = 0.315 +- 0.085 (in-sample avg dev_std = 0.149)
NEC for r=0.3 class 1 = 0.337 +- 0.085 (in-sample avg dev_std = 0.149)
NEC for r=0.3 class 2 = 0.337 +- 0.085 (in-sample avg dev_std = 0.149)
NEC for r=0.3 class 3 = 0.326 +- 0.085 (in-sample avg dev_std = 0.149)
NEC for r=0.3 class 4 = 0.316 +- 0.085 (in-sample avg dev_std = 0.149)
NEC for r=0.3 class 5 = 0.342 +- 0.085 (in-sample avg dev_std = 0.149)
NEC for r=0.3 class 6 = 0.353 +- 0.085 (in-sample avg dev_std = 0.149)
NEC for r=0.3 class 7 = 0.335 +- 0.085 (in-sample avg dev_std = 0.149)
NEC for r=0.3 class 8 = 0.349 +- 0.085 (in-sample avg dev_std = 0.149)
NEC for r=0.3 class 9 = 0.343 +- 0.085 (in-sample avg dev_std = 0.149)
NEC for r=0.3 all KL = 0.15 +- 0.085 (in-sample avg dev_std = 0.149)
NEC for r=0.3 all L1 = 0.335 +- 0.085 (in-sample avg dev_std = 0.149)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.175
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.141
NEC for r=0.6 class 0 = 0.468 +- 0.186 (in-sample avg dev_std = 0.317)
NEC for r=0.6 class 1 = 0.492 +- 0.186 (in-sample avg dev_std = 0.317)
NEC for r=0.6 class 2 = 0.487 +- 0.186 (in-sample avg dev_std = 0.317)
NEC for r=0.6 class 3 = 0.509 +- 0.186 (in-sample avg dev_std = 0.317)
NEC for r=0.6 class 4 = 0.505 +- 0.186 (in-sample avg dev_std = 0.317)
NEC for r=0.6 class 5 = 0.508 +- 0.186 (in-sample avg dev_std = 0.317)
NEC for r=0.6 class 6 = 0.53 +- 0.186 (in-sample avg dev_std = 0.317)
NEC for r=0.6 class 7 = 0.509 +- 0.186 (in-sample avg dev_std = 0.317)
NEC for r=0.6 class 8 = 0.492 +- 0.186 (in-sample avg dev_std = 0.317)
NEC for r=0.6 class 9 = 0.519 +- 0.186 (in-sample avg dev_std = 0.317)
NEC for r=0.6 all KL = 0.425 +- 0.186 (in-sample avg dev_std = 0.317)
NEC for r=0.6 all L1 = 0.502 +- 0.139 (in-sample avg dev_std = 0.317)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.796
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.611
NEC for r=0.9 class 0 = 0.446 +- 0.308 (in-sample avg dev_std = 0.451)
NEC for r=0.9 class 1 = 0.189 +- 0.308 (in-sample avg dev_std = 0.451)
NEC for r=0.9 class 2 = 0.447 +- 0.308 (in-sample avg dev_std = 0.451)
NEC for r=0.9 class 3 = 0.522 +- 0.308 (in-sample avg dev_std = 0.451)
NEC for r=0.9 class 4 = 0.406 +- 0.308 (in-sample avg dev_std = 0.451)
NEC for r=0.9 class 5 = 0.528 +- 0.308 (in-sample avg dev_std = 0.451)
NEC for r=0.9 class 6 = 0.473 +- 0.308 (in-sample avg dev_std = 0.451)
NEC for r=0.9 class 7 = 0.364 +- 0.308 (in-sample avg dev_std = 0.451)
NEC for r=0.9 class 8 = 0.42 +- 0.308 (in-sample avg dev_std = 0.451)
NEC for r=0.9 class 9 = 0.493 +- 0.308 (in-sample avg dev_std = 0.451)
NEC for r=0.9 all KL = 0.588 +- 0.308 (in-sample avg dev_std = 0.451)
NEC for r=0.9 all L1 = 0.424 +- 0.251 (in-sample avg dev_std = 0.451)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.926
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.808
NEC for r=1.0 class 0 = 0.168 +- 0.348 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 1 = 0.048 +- 0.348 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 2 = 0.303 +- 0.348 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 3 = 0.366 +- 0.348 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 4 = 0.302 +- 0.348 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 5 = 0.317 +- 0.348 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 6 = 0.285 +- 0.348 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 7 = 0.18 +- 0.348 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 8 = 0.307 +- 0.348 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 9 = 0.31 +- 0.348 (in-sample avg dev_std = 0.393)
NEC for r=1.0 all KL = 0.386 +- 0.348 (in-sample avg dev_std = 0.393)
NEC for r=1.0 all L1 = 0.255 +- 0.255 (in-sample avg dev_std = 0.393)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.09
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.101
NEC for r=0.3 class 0 = 0.348 +- 0.085 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 1 = 0.344 +- 0.085 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 2 = 0.325 +- 0.085 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 3 = 0.338 +- 0.085 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 4 = 0.344 +- 0.085 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 5 = 0.342 +- 0.085 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 6 = 0.342 +- 0.085 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 7 = 0.336 +- 0.085 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 8 = 0.331 +- 0.085 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 9 = 0.347 +- 0.085 (in-sample avg dev_std = 0.142)
NEC for r=0.3 all KL = 0.151 +- 0.085 (in-sample avg dev_std = 0.142)
NEC for r=0.3 all L1 = 0.339 +- 0.088 (in-sample avg dev_std = 0.142)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.174
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.142
NEC for r=0.6 class 0 = 0.408 +- 0.204 (in-sample avg dev_std = 0.331)
NEC for r=0.6 class 1 = 0.52 +- 0.204 (in-sample avg dev_std = 0.331)
NEC for r=0.6 class 2 = 0.471 +- 0.204 (in-sample avg dev_std = 0.331)
NEC for r=0.6 class 3 = 0.474 +- 0.204 (in-sample avg dev_std = 0.331)
NEC for r=0.6 class 4 = 0.514 +- 0.204 (in-sample avg dev_std = 0.331)
NEC for r=0.6 class 5 = 0.484 +- 0.204 (in-sample avg dev_std = 0.331)
NEC for r=0.6 class 6 = 0.494 +- 0.204 (in-sample avg dev_std = 0.331)
NEC for r=0.6 class 7 = 0.512 +- 0.204 (in-sample avg dev_std = 0.331)
NEC for r=0.6 class 8 = 0.495 +- 0.204 (in-sample avg dev_std = 0.331)
NEC for r=0.6 class 9 = 0.539 +- 0.204 (in-sample avg dev_std = 0.331)
NEC for r=0.6 all KL = 0.435 +- 0.204 (in-sample avg dev_std = 0.331)
NEC for r=0.6 all L1 = 0.491 +- 0.153 (in-sample avg dev_std = 0.331)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.632
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.396
NEC for r=0.9 class 0 = 0.631 +- 0.297 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 1 = 0.465 +- 0.297 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 2 = 0.477 +- 0.297 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 3 = 0.631 +- 0.297 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 4 = 0.381 +- 0.297 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 5 = 0.645 +- 0.297 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 6 = 0.456 +- 0.297 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 7 = 0.546 +- 0.297 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 8 = 0.606 +- 0.297 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 9 = 0.566 +- 0.297 (in-sample avg dev_std = 0.426)
NEC for r=0.9 all KL = 0.656 +- 0.297 (in-sample avg dev_std = 0.426)
NEC for r=0.9 all L1 = 0.539 +- 0.244 (in-sample avg dev_std = 0.426)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.759
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.612
NEC for r=1.0 class 0 = 0.639 +- 0.343 (in-sample avg dev_std = 0.439)
NEC for r=1.0 class 1 = 0.173 +- 0.343 (in-sample avg dev_std = 0.439)
NEC for r=1.0 class 2 = 0.424 +- 0.343 (in-sample avg dev_std = 0.439)
NEC for r=1.0 class 3 = 0.49 +- 0.343 (in-sample avg dev_std = 0.439)
NEC for r=1.0 class 4 = 0.4 +- 0.343 (in-sample avg dev_std = 0.439)
NEC for r=1.0 class 5 = 0.494 +- 0.343 (in-sample avg dev_std = 0.439)
NEC for r=1.0 class 6 = 0.324 +- 0.343 (in-sample avg dev_std = 0.439)
NEC for r=1.0 class 7 = 0.34 +- 0.343 (in-sample avg dev_std = 0.439)
NEC for r=1.0 class 8 = 0.606 +- 0.343 (in-sample avg dev_std = 0.439)
NEC for r=1.0 class 9 = 0.49 +- 0.343 (in-sample avg dev_std = 0.439)
NEC for r=1.0 all KL = 0.575 +- 0.343 (in-sample avg dev_std = 0.439)
NEC for r=1.0 all L1 = 0.435 +- 0.275 (in-sample avg dev_std = 0.439)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.624, 0.303, 0.822, 1.0], 'all_L1': [0.497, 0.379, 0.813, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.771, 0.378, 0.818, 1.0], 'all_L1': [0.588, 0.402, 0.802, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.537, 0.273, 0.815, 1.0], 'all_L1': [0.462, 0.358, 0.816, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.814, 0.306, 0.819, 1.0], 'all_L1': [0.635, 0.381, 0.819, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.666, 0.404, 0.82, 1.0], 'all_L1': [0.548, 0.402, 0.811, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.167, 0.476, 0.573, 0.399], 'all_L1': [0.364, 0.512, 0.403, 0.23]}), defaultdict(<class 'list'>, {'all_KL': [0.133, 0.458, 0.54, 0.364], 'all_L1': [0.304, 0.514, 0.411, 0.233]}), defaultdict(<class 'list'>, {'all_KL': [0.26, 0.523, 0.536, 0.375], 'all_L1': [0.411, 0.519, 0.38, 0.208]}), defaultdict(<class 'list'>, {'all_KL': [0.139, 0.495, 0.591, 0.4], 'all_L1': [0.302, 0.517, 0.408, 0.234]}), defaultdict(<class 'list'>, {'all_KL': [0.143, 0.441, 0.557, 0.37], 'all_L1': [0.329, 0.514, 0.407, 0.223]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.637, 0.313, 0.801, 1.0], 'all_L1': [0.505, 0.393, 0.801, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.782, 0.436, 0.833, 1.0], 'all_L1': [0.602, 0.428, 0.812, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.515, 0.32, 0.809, 1.0], 'all_L1': [0.452, 0.401, 0.802, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.813, 0.347, 0.81, 1.0], 'all_L1': [0.635, 0.392, 0.807, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.646, 0.421, 0.812, 1.0], 'all_L1': [0.535, 0.413, 0.8, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.167, 0.476, 0.593, 0.415], 'all_L1': [0.365, 0.508, 0.426, 0.261]}), defaultdict(<class 'list'>, {'all_KL': [0.129, 0.446, 0.569, 0.374], 'all_L1': [0.298, 0.512, 0.433, 0.257]}), defaultdict(<class 'list'>, {'all_KL': [0.265, 0.511, 0.57, 0.424], 'all_L1': [0.417, 0.503, 0.418, 0.27]}), defaultdict(<class 'list'>, {'all_KL': [0.145, 0.484, 0.611, 0.421], 'all_L1': [0.308, 0.518, 0.432, 0.264]}), defaultdict(<class 'list'>, {'all_KL': [0.15, 0.425, 0.588, 0.386], 'all_L1': [0.335, 0.502, 0.424, 0.255]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.69, 0.381, 0.752, 1.0], 'all_L1': [0.531, 0.43, 0.745, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.812, 0.552, 0.818, 1.0], 'all_L1': [0.63, 0.543, 0.766, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.485, 0.364, 0.72, 1.0], 'all_L1': [0.459, 0.419, 0.704, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.797, 0.39, 0.771, 1.0], 'all_L1': [0.616, 0.4, 0.746, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.628, 0.391, 0.728, 1.0], 'all_L1': [0.52, 0.416, 0.707, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.168, 0.398, 0.631, 0.598], 'all_L1': [0.37, 0.445, 0.494, 0.439]}), defaultdict(<class 'list'>, {'all_KL': [0.109, 0.312, 0.436, 0.451], 'all_L1': [0.274, 0.377, 0.407, 0.392]}), defaultdict(<class 'list'>, {'all_KL': [0.248, 0.468, 0.581, 0.593], 'all_L1': [0.399, 0.483, 0.487, 0.481]}), defaultdict(<class 'list'>, {'all_KL': [0.149, 0.509, 0.625, 0.564], 'all_L1': [0.316, 0.538, 0.499, 0.417]}), defaultdict(<class 'list'>, {'all_KL': [0.151, 0.435, 0.656, 0.575], 'all_L1': [0.339, 0.491, 0.539, 0.435]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.546 +- 0.062, 0.384 +- 0.016, 0.812 +- 0.006, 1.000 +- 0.000
suff++ class all_KL  =  0.682 +- 0.100, 0.333 +- 0.050, 0.819 +- 0.002, 1.000 +- 0.000
suff++_acc_int  =  0.094 +- 0.004, 0.140 +- 0.021, 0.759 +- 0.007
nec class all_L1  =  0.342 +- 0.041, 0.515 +- 0.002, 0.402 +- 0.011, 0.226 +- 0.010
nec class all_KL  =  0.168 +- 0.047, 0.479 +- 0.029, 0.559 +- 0.021, 0.382 +- 0.015
nec_acc_int  =  0.096 +- 0.006, 0.148 +- 0.018, 0.618 +- 0.012, 0.838 +- 0.009

Eval split val
suff++ class all_L1  =  0.546 +- 0.066, 0.405 +- 0.014, 0.804 +- 0.004, 1.000 +- 0.000
suff++ class all_KL  =  0.679 +- 0.108, 0.367 +- 0.051, 0.813 +- 0.011, 1.000 +- 0.000
suff++_acc_int  =  0.102 +- 0.004, 0.134 +- 0.016, 0.743 +- 0.009
nec class all_L1  =  0.345 +- 0.043, 0.509 +- 0.006, 0.427 +- 0.005, 0.261 +- 0.005
nec class all_KL  =  0.171 +- 0.048, 0.468 +- 0.030, 0.586 +- 0.016, 0.404 +- 0.020
nec_acc_int  =  0.104 +- 0.004, 0.137 +- 0.017, 0.587 +- 0.016, 0.793 +- 0.008

Eval split test
suff++ class all_L1  =  0.551 +- 0.064, 0.442 +- 0.052, 0.734 +- 0.024, 1.000 +- 0.000
suff++ class all_KL  =  0.682 +- 0.120, 0.416 +- 0.069, 0.758 +- 0.035, 1.000 +- 0.000
suff++_acc_int  =  0.104 +- 0.007, 0.141 +- 0.021, 0.486 +- 0.094
nec class all_L1  =  0.340 +- 0.043, 0.467 +- 0.054, 0.485 +- 0.043, 0.433 +- 0.029
nec class all_KL  =  0.165 +- 0.046, 0.424 +- 0.067, 0.586 +- 0.079, 0.556 +- 0.054
nec_acc_int  =  0.106 +- 0.009, 0.142 +- 0.020, 0.364 +- 0.074, 0.500 +- 0.116


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.444 +- 0.013, 0.450 +- 0.008, 0.607 +- 0.005, 0.613 +- 0.005
Faith. Armon (L1)= 		  =  0.415 +- 0.012, 0.440 +- 0.010, 0.538 +- 0.010, 0.368 +- 0.013
Faith. GMean (L1)= 	  =  0.429 +- 0.006, 0.445 +- 0.009, 0.571 +- 0.007, 0.475 +- 0.010
Faith. Aritm (KL)= 		  =  0.425 +- 0.033, 0.406 +- 0.013, 0.689 +- 0.011, 0.691 +- 0.008
Faith. Armon (KL)= 		  =  0.263 +- 0.045, 0.389 +- 0.025, 0.664 +- 0.015, 0.552 +- 0.016
Faith. GMean (KL)= 	  =  0.332 +- 0.022, 0.397 +- 0.019, 0.677 +- 0.013, 0.618 +- 0.012

Eval split val
Faith. Aritm (L1)= 		  =  0.445 +- 0.014, 0.457 +- 0.007, 0.616 +- 0.005, 0.631 +- 0.003
Faith. Armon (L1)= 		  =  0.417 +- 0.012, 0.451 +- 0.008, 0.558 +- 0.006, 0.414 +- 0.007
Faith. GMean (L1)= 	  =  0.431 +- 0.007, 0.454 +- 0.008, 0.586 +- 0.005, 0.511 +- 0.005
Faith. Aritm (KL)= 		  =  0.425 +- 0.036, 0.418 +- 0.015, 0.700 +- 0.007, 0.702 +- 0.010
Faith. Armon (KL)= 		  =  0.265 +- 0.045, 0.408 +- 0.022, 0.681 +- 0.009, 0.575 +- 0.021
Faith. GMean (KL)= 	  =  0.334 +- 0.021, 0.413 +- 0.018, 0.690 +- 0.008, 0.635 +- 0.016

Eval split test
Faith. Aritm (L1)= 		  =  0.445 +- 0.014, 0.454 +- 0.010, 0.609 +- 0.015, 0.716 +- 0.015
Faith. Armon (L1)= 		  =  0.415 +- 0.018, 0.448 +- 0.007, 0.582 +- 0.028, 0.604 +- 0.028
Faith. GMean (L1)= 	  =  0.430 +- 0.011, 0.451 +- 0.008, 0.596 +- 0.021, 0.658 +- 0.022
Faith. Aritm (KL)= 		  =  0.424 +- 0.041, 0.420 +- 0.020, 0.672 +- 0.028, 0.778 +- 0.027
Faith. Armon (KL)= 		  =  0.257 +- 0.044, 0.410 +- 0.018, 0.656 +- 0.047, 0.713 +- 0.047
Faith. GMean (KL)= 	  =  0.327 +- 0.021, 0.415 +- 0.018, 0.664 +- 0.037, 0.745 +- 0.038
Computed for split load_split = id



Completed in  1:49:16.814598  for LECIvGIN GOODCMNIST/color



DONE LECI GOODCMNIST/color
DONE all :)
