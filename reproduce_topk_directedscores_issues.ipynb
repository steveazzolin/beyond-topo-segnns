{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TopK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.utils import degree, cumsum, scatter, to_undirected\n",
    "import torch_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_sort(src: torch.Tensor, index: torch.Tensor, dim=0, descending=False, eps=1e-12):\n",
    "    f_src = src.float()\n",
    "    f_min, f_max = f_src.min(dim)[0], f_src.max(dim)[0]\n",
    "    norm = (f_src - f_min) / (f_max - f_min + eps) + index.float() * (-1) ** int(descending)\n",
    "    perm = norm.argsort(dim=dim, descending=descending)\n",
    "\n",
    "    return src[perm], perm\n",
    "\n",
    "def sparse_topk(src: torch.Tensor, index: torch.Tensor, ratio: float, dim=0, descending=False, eps=1e-12):\n",
    "    rank, perm = sparse_sort(src, index, dim, descending, eps)\n",
    "    num_nodes = degree(index, dtype=torch.long)\n",
    "    k = (ratio * num_nodes.to(float)).ceil().to(torch.long)\n",
    "    start_indices = torch.cat([torch.zeros((1, ), device=src.device, dtype=torch.long), num_nodes.cumsum(0)])\n",
    "    mask = [torch.arange(k[i], dtype=torch.long, device=src.device) + start_indices[i] for i in range(len(num_nodes))]\n",
    "    mask = torch.cat(mask, dim=0)\n",
    "    mask = torch.zeros_like(index, device=index.device).index_fill(0, mask, 1).bool()\n",
    "    topk_perm = perm[mask]\n",
    "    exc_perm = perm[~mask]\n",
    "\n",
    "    return topk_perm, exc_perm, rank, perm, mask\n",
    "\n",
    "def topK(x, ratio, batch, min_score, tol=1e-7, debug=False):\n",
    "    if min_score is not None:\n",
    "        # Make sure that we do not drop all nodes in a graph.\n",
    "        scores_max = scatter(x, batch, reduce='max')[batch] - tol\n",
    "        scores_min = scores_max.clamp(max=min_score)\n",
    "\n",
    "        perm = (x > scores_min).nonzero().view(-1)\n",
    "        return perm\n",
    "\n",
    "    if ratio >= 1.:\n",
    "        return torch.arange(x.shape[0], device=x.device), torch.tensor([], dtype=torch.long), None, None\n",
    "\n",
    "    if ratio is not None:\n",
    "        num_nodes = scatter(batch.new_ones(x.size(0)), batch, reduce='sum')\n",
    "        if ratio >= 1:\n",
    "            k = num_nodes.new_full((num_nodes.size(0), ), int(ratio))\n",
    "        else:\n",
    "            k = (float(ratio) * num_nodes.to(x.dtype)).ceil().to(torch.long)\n",
    "\n",
    "        x, x_perm = torch.sort(x.view(-1), descending=True, stable=True)\n",
    "        batch = batch[x_perm]\n",
    "        batch, batch_perm = torch.sort(batch, descending=False, stable=True)\n",
    "\n",
    "        arange = torch.arange(x.size(0), dtype=torch.long, device=x.device)\n",
    "        ptr = cumsum(num_nodes)\n",
    "        batched_arange = arange - ptr[batch]\n",
    "        mask = batched_arange < k[batch]\n",
    "\n",
    "        return x_perm[batch_perm[mask]], x_perm[batch_perm[~mask]].sort()[0], x_perm, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using version 2.4.0 for PyG\n",
      "Using version 2.1.0+cu121 for Torch\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using version {torch_geometric.__version__} for PyG\")\n",
    "print(f\"Using version {torch.__version__} for Torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3\n",
    "ratio = 0.5\n",
    "edge_score_single = torch.tensor([0.9, 0.9, 0.9, 0.9], device=\"cuda\")\n",
    "edge_score = edge_score_single.repeat_interleave(N)\n",
    "batch = torch.cat([\n",
    "    torch.full_like(edge_score_single, fill_value=i, dtype=torch.int64, device=\"cuda\")\n",
    "        for i in range(N)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the original topk function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  0,  7,  6, 11, 10], device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_kept, idx_dropped, _, perm, mask = sparse_topk(edge_score, batch, ratio, descending=True)\n",
    "idx_kept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the stable version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 4, 5, 8, 9], device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_kept, idx_dropped, perm, mask = topK(edge_score, ratio, batch, min_score=None)\n",
    "idx_kept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stable version picks alsways the first elements as top candidates, while *sparse_topk* picks arbitrarly the first and the last elements inside each batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directed edge scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using version 2.4.0 for PyG\n",
      "Using version 2.1.0+cu121 for Torch\n",
      "Using version 0.6.18+pt21cu121 for TorchSparse\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using version {torch_geometric.__version__} for PyG\")\n",
    "print(f\"Using version {torch.__version__} for Torch\")\n",
    "print(f\"Using version {torch_sparse.__version__} for TorchSparse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.tensor([\n",
    "    [0,1,2,1],\n",
    "    [1,0,1,2]\n",
    "])\n",
    "att = torch.tensor([0., 1., 0.6, 0.8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the original version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 1.0000, 0.6000, 0.8000])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_avg = (att + torch_sparse.transpose(edge_index, att, 4, 4, coalesced=False)[1]) / 2\n",
    "att_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our fixed version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000, 0.5000, 0.7000, 0.7000])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, att_avg = to_undirected(edge_index, att, reduce=\"mean\")\n",
    "att_avg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
